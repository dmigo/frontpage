{"link":"http://arxiv.org/abs/2301.10213v1","created":"2023-01-24","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":356636794,"_task_hash":-1420897602,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674650125,"text":"Database Reconstruction Is Not So Easy and Is Different from Reidentification\nIn recent years, it has been claimed that releasing accurate statistical information on a database is likely to allow its complete reconstruction. Differential privacy has been suggested as the appropriate methodology to prevent these attacks. These claims have recently been taken very seriously by the U.S. Census Bureau and led them to adopt differential privacy for releasing U.S. Census data. This in turn has caused consternation among users of the Census data due to the lack of accuracy of the protected outputs. It has also brought legal action against the U.S. Department of Commerce. In this paper, we trace the origins of the claim that releasing information on a database automatically makes it vulnerable to being exposed by reconstruction attacks and we show that this claim is, in fact, incorrect. We also show that reconstruction can be averted by properly using traditional statistical disclosure control (SDC) techniques. We further show that the geographic level at which exact counts are released is even more relevant to protection than the actual SDC method employed. Finally, we caution against confusing reconstruction and reidentification: using the quality of reconstruction as a metric of reidentification results in exaggerated reidentification risk figures."}
{"link":"http://arxiv.org/abs/2301.09460v1","created":"2023-01-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1463154053,"_task_hash":-1930567928,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674650127,"text":"HRVQA: A Visual Question Answering Benchmark for High-Resolution Aerial Images\nVisual question answering (VQA) is an important and challenging multimodal task in computer vision. Recently, a few efforts have been made to bring VQA task to aerial images, due to its potential real-world applications in disaster monitoring, urban planning, and digital earth product generation. However, not only the huge variation in the appearance, scale and orientation of the concepts in aerial images, but also the scarcity of the well-annotated datasets restricts the development of VQA in this domain. In this paper, we introduce a new dataset, HRVQA, which provides collected 53512 aerial images of 1024*1024 pixels and semi-automatically generated 1070240 QA pairs. To benchmark the understanding capability of VQA models for aerial images, we evaluate the relevant methods on HRVQA. Moreover, we propose a novel model, GFTransformer, with gated attention modules and a mutual fusion module. The experiments show that the proposed dataset is quite challenging, especially the specific attribute related questions. Our method achieves superior performance in comparison to the previous state-of-the-art approaches. The dataset and the source code will be released at https://hrvqa.nl/."}
{"link":"http://arxiv.org/abs/2301.10018v1","created":"2023-01-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-996062394,"_task_hash":751405418,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674650128,"text":"GyroFlow+: Gyroscope-Guided Unsupervised Deep Homography and Optical Flow Learning\nExisting homography and optical flow methods are erroneous in challenging scenes, such as fog, rain, night, and snow because the basic assumptions such as brightness and gradient constancy are broken. To address this issue, we present an unsupervised learning approach that fuses gyroscope into homography and optical flow learning. Specifically, we first convert gyroscope readings into motion fields named gyro field. Second, we design a self-guided fusion module (SGF) to fuse the background motion extracted from the gyro field with the optical flow and guide the network to focus on motion details. Meanwhile, we propose a homography decoder module (HD) to combine gyro field and intermediate results of SGF to produce the homography. To the best of our knowledge, this is the first deep learning framework that fuses gyroscope data and image content for both deep homography and optical flow learning. To validate our method, we propose a new dataset that covers regular and challenging scenes. Experiments show that our method outperforms the state-of-the-art methods in both regular and challenging scenes."}
{"link":"http://arxiv.org/abs/2301.09279v1","created":"2023-01-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1471250243,"_task_hash":-218120446,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674650130,"text":"StockEmotions: Discover Investor Emotions for Financial Sentiment Analysis and Multivariate Time Series\nThere has been growing interest in applying NLP techniques in the financial domain, however, resources are extremely limited. This paper introduces StockEmotions, a new dataset for detecting emotions in the stock market that consists of 10,000 English comments collected from StockTwits, a financial social media platform. Inspired by behavioral finance, it proposes 12 fine-grained emotion classes that span the roller coaster of investor emotion. Unlike existing financial sentiment datasets, StockEmotions presents granular features such as investor sentiment classes, fine-grained emotions, emojis, and time series data. To demonstrate the usability of the dataset, we perform a dataset analysis and conduct experimental downstream tasks. For financial sentiment/emotion classification tasks, DistilBERT outperforms other baselines, and for multivariate time series forecasting, a Temporal Attention LSTM model combining price index, text, and emotion features achieves the best performance than using a single feature."}
{"link":"http://arxiv.org/abs/2301.09201v1","created":"2023-01-22","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":650738062,"_task_hash":-467947993,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674650421,"text":"SPEC5G: A Dataset for 5G Cellular Network Protocol Analysis\n5G is the 5th generation cellular network protocol. It is the state-of-the-art global wireless standard that enables an advanced kind of network designed to connect virtually everyone and everything with increased speed and reduced latency. Therefore, its development, analysis, and security are critical. However, all approaches to the 5G protocol development and security analysis, e.g., property extraction, protocol summarization, and semantic analysis of the protocol specifications and implementations are completely manual. To reduce such manual effort, in this paper, we curate SPEC5G the first-ever public 5G dataset for NLP research. The dataset contains 3,547,586 sentences with 134M words, from 13094 cellular network specifications and 13 online websites. By leveraging large-scale pre-trained language models that have achieved state-of-the-art results on NLP tasks, we use this dataset for security-related text classification and summarization. Security-related text classification can be used to extract relevant security-related properties for protocol testing. On the other hand, summarization can help developers and practitioners understand the high level of the protocol, which is itself a daunting task. Our results show the value of our 5G-centric dataset in 5G protocol analysis automation. We believe that SPEC5G will enable a new research direction into automatic analyses for the 5G cellular network protocol and numerous related downstream tasks. Our data and code are publicly available."}
{"link":"http://arxiv.org/abs/2301.09169v1","created":"2023-01-22","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1349047683,"_task_hash":-1636818323,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674650427,"text":"Representing Interlingual Meaning in Lexical Databases\nIn today's multilingual lexical databases, the majority of the world's languages are under-represented. Beyond a mere issue of resource incompleteness, we show that existing lexical databases have structural limitations that result in a reduced expressivity on culturally-specific words and in mapping them across languages. In particular, the lexical meaning space of dominant languages, such as English, is represented more accurately while linguistically or culturally diverse languages are mapped in an approximate manner. Our paper assesses state-of-the-art multilingual lexical databases and evaluates their strengths and limitations with respect to their expressivity on lexical phenomena of linguistic diversity."}
{"link":"http://arxiv.org/abs/2301.08995v1","created":"2023-01-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1378921757,"_task_hash":1715900694,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674650442,"text":"REDAffectiveLM: Leveraging Affect Enriched Embedding and Transformer-based Neural Language Model for Readers' Emotion Detection\nTechnological advancements in web platforms allow people to express and share emotions towards textual write-ups written and shared by others. This brings about different interesting domains for analysis; emotion expressed by the writer and emotion elicited from the readers. In this paper, we propose a novel approach for Readers' Emotion Detection from short-text documents using a deep learning model called REDAffectiveLM. Within state-of-the-art NLP tasks, it is well understood that utilizing context-specific representations from transformer-based pre-trained language models helps achieve improved performance. Within this affective computing task, we explore how incorporating affective information can further enhance performance. Towards this, we leverage context-specific and affect enriched representations by using a transformer-based pre-trained language model in tandem with affect enriched Bi-LSTM+Attention. For empirical evaluation, we procure a new dataset REN-20k, besides using RENh-4k and SemEval-2007. We evaluate the performance of our REDAffectiveLM rigorously across these datasets, against a vast set of state-of-the-art baselines, where our model consistently outperforms baselines and obtains statistically significant results. Our results establish that utilizing affect enriched representation along with context-specific representation within a neural architecture can considerably enhance readers' emotion detection. Since the impact of affect enrichment specifically in readers' emotion detection isn't well explored, we conduct a detailed analysis over affect enriched Bi-LSTM+Attention using qualitative and quantitative model behavior evaluation techniques. We observe that compared to conventional semantic embedding, affect enriched embedding increases ability of the network to effectively identify and assign weightage to key terms responsible for readers' emotion detection."}
{"link":"http://arxiv.org/abs/2301.10180v1","created":"2023-01-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1389134537,"_task_hash":2036299283,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674650444,"text":"A Multi-Purpose Audio-Visual Corpus for Multi-Modal Persian Speech Recognition: the Arman-AV Dataset\nIn recent years, significant progress has been made in automatic lip reading. But these methods require large-scale datasets that do not exist for many low-resource languages. In this paper, we have presented a new multipurpose audio-visual dataset for Persian. This dataset consists of almost 220 hours of videos with 1760 corresponding speakers. In addition to lip reading, the dataset is suitable for automatic speech recognition, audio-visual speech recognition, and speaker recognition. Also, it is the first large-scale lip reading dataset in Persian. A baseline method was provided for each mentioned task. In addition, we have proposed a technique to detect visemes (a visual equivalent of a phoneme) in Persian. The visemes obtained by this method increase the accuracy of the lip reading task by 7% relatively compared to the previously proposed visemes, which can be applied to other languages as well."}
{"link":"http://arxiv.org/abs/2301.08880v1","created":"2023-01-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-399196349,"_task_hash":2115655710,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674650454,"text":"A Large-scale Film Style Dataset for Learning Multi-frequency Driven Film Enhancement\nFilm, a classic image style, is culturally significant to the whole photographic industry since it marks the birth of photography. However, film photography is time-consuming and expensive, necessitating a more efficient method for collecting film-style photographs. Numerous datasets that have emerged in the field of image enhancement so far are not film-specific. In order to facilitate film-based image stylization research, we construct FilmSet, a large-scale and high-quality film style dataset. Our dataset includes three different film types and more than 5000 in-the-wild high resolution images. Inspired by the features of FilmSet images, we propose a novel framework called FilmNet based on Laplacian Pyramid for stylizing images across frequency bands and achieving film style outcomes. Experiments reveal that the performance of our model is superior than state-of-the-art techniques. Our dataset and code will be made publicly available."}
{"link":"http://arxiv.org/abs/2301.08794v1","created":"2023-01-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":976221814,"_task_hash":231339584,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674650463,"text":"Robot Skill Learning Via Classical Robotics-Based Generated Datasets: Advantages, Disadvantages, and Future Improvement\nWhy do we not profit from our long-existing classical robotics knowledge and look for some alternative way for data collection? The situation ignoring all existing methods might be such a waste. This article argues that a dataset created using a classical robotics algorithm is a crucial part of future development. This developed classic algorithm has a perfect domain adaptation and generalization property, and most importantly, collecting datasets based on them is quite easy. It is well known that current robot skill-learning approaches perform exceptionally badly in the unseen domain, and their performance against adversarial attacks is quite limited as long as they do not have a very exclusive big dataset. Our experiment is the initial steps of using a dataset created by classical robotics codes. Our experiment investigated possible trajectory collection based on classical robotics. It addressed some advantages and disadvantages and pointed out other future development ideas."}
{"link":"http://arxiv.org/abs/2301.08784v1","created":"2023-01-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-910804476,"_task_hash":972667839,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674650465,"text":"Visual Semantic Relatedness Dataset for Image Captioning\nModern image captioning system relies heavily on extracting knowledge from images to capture the concept of a static story. In this paper, we propose a textual visual context dataset for captioning, in which the publicly available dataset COCO Captions (Lin et al., 2014) has been extended with information about the scene (such as objects in the image). Since this information has a textual form, it can be used to leverage any NLP task, such as text similarity or semantic relation methods, into captioning systems, either as an end-to-end training strategy or a post-processing based approach."}
{"link":"http://arxiv.org/abs/2301.08305v1","created":"2023-01-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1736673839,"_task_hash":2099083394,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674650468,"text":"Invasion of Ukraine Discourse on TikTok Dataset\nWe present a dataset of videos and comments from the social media platform TikTok, centred around the invasion of Ukraine in 2022, an event that launched TikTok into the geopolitical arena. The discourse around the invasion exposed myriad political behaviours and dynamics that are unexplored on this platform. To this end we provide a mass scale language and interaction dataset for further research into these processes. An initial investigation of language and social interaction dynamics are explored in this paper. The dataset and the library used to collect it are open sourced to the public."}
{"link":"http://arxiv.org/abs/2301.08147v1","created":"2023-01-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":881718716,"_task_hash":1191073474,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674650483,"text":"RGB-D-Based Categorical Object Pose and Shape Estimation: Methods, Datasets, and Evaluation\nRecently, various methods for 6D pose and shape estimation of objects at a per-category level have been proposed. This work provides an overview of the field in terms of methods, datasets, and evaluation protocols. First, an overview of existing works and their commonalities and differences is provided. Second, we take a critical look at the predominant evaluation protocol, including metrics and datasets. Based on the findings, we propose a new set of metrics, contribute new annotations for the Redwood dataset, and evaluate state-of-the-art methods in a fair comparison. The results indicate that existing methods do not generalize well to unconstrained orientations and are actually heavily biased towards objects being upright. We provide an easy-to-use evaluation toolbox with well-defined metrics, methods, and dataset interfaces, which allows evaluation and comparison with various state-of-the-art approaches (https://github.com/roym899/pose_and_shape_evaluation)."}
{"link":"http://arxiv.org/abs/2301.10161v1","created":"2023-01-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1788132752,"_task_hash":-992040862,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674650493,"text":"Dataset Bias in Human Activity Recognition\nWhen creating multi-channel time-series datasets for Human Activity Recognition (HAR), researchers are faced with the issue of subject selection criteria. It is unknown what physical characteristics and/or soft-biometrics, such as age, height, and weight, need to be taken into account to train a classifier to achieve robustness towards heterogeneous populations in the training and testing data. This contribution statistically curates the training data to assess to what degree the physical characteristics of humans influence HAR performance. We evaluate the performance of a state-of-the-art convolutional neural network on two HAR datasets that vary in the sensors, activities, and recording for time-series HAR. The training data is intentionally biased with respect to human characteristics to determine the features that impact motion behaviour. The evaluations brought forth the impact of the subjects' characteristics on HAR. Thus, providing insights regarding the robustness of the classifier with respect to heterogeneous populations. The study is a step forward in the direction of fair and trustworthy artificial intelligence by attempting to quantify representation bias in multi-channel time series HAR data."}
{"link":"http://arxiv.org/abs/2301.08008v1","created":"2023-01-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":87722204,"_task_hash":-943933233,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674650508,"text":"Improving Machine Translation with Phrase Pair Injection and Corpus Filtering\nIn this paper, we show that the combination of Phrase Pair Injection and Corpus Filtering boosts the performance of Neural Machine Translation (NMT) systems. We extract parallel phrases and sentences from the pseudo-parallel corpus and augment it with the parallel corpus to train the NMT models. With the proposed approach, we observe an improvement in the Machine Translation (MT) system for 3 low-resource language pairs, Hindi-Marathi, English-Marathi, and English-Pashto, and 6 translation directions by up to 2.7 BLEU points, on the FLORES test data. These BLEU score improvements are over the models trained using the whole pseudo-parallel corpus augmented with the parallel corpus."}
{"link":"http://arxiv.org/abs/2301.07525v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-2079904328,"_task_hash":-1550269727,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674650511,"text":"OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation\nRecent advances in modeling 3D objects mostly rely on synthetic datasets due to the lack of large-scale realscanned 3D databases. To facilitate the development of 3D perception, reconstruction, and generation in the real world, we propose OmniObject3D, a large vocabulary 3D object dataset with massive high-quality real-scanned 3D objects. OmniObject3D has several appealing properties: 1) Large Vocabulary: It comprises 6,000 scanned objects in 190 daily categories, sharing common classes with popular 2D datasets (e.g., ImageNet and LVIS), benefiting the pursuit of generalizable 3D representations. 2) Rich Annotations: Each 3D object is captured with both 2D and 3D sensors, providing textured meshes, point clouds, multiview rendered images, and multiple real-captured videos. 3) Realistic Scans: The professional scanners support highquality object scans with precise shapes and realistic appearances. With the vast exploration space offered by OmniObject3D, we carefully set up four evaluation tracks: a) robust 3D perception, b) novel-view synthesis, c) neural surface reconstruction, and d) 3D object generation. Extensive studies are performed on these four benchmarks, revealing new observations, challenges, and opportunities for future research in realistic 3D vision."}
{"link":"http://arxiv.org/abs/2301.07673v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":714352731,"_task_hash":-88572467,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674650516,"text":"OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models\nWe propose a new method for object pose estimation without CAD models. The previous feature-matching-based method OnePose has shown promising results under a one-shot setting which eliminates the need for CAD models or object-specific training. However, OnePose relies on detecting repeatable image keypoints and is thus prone to failure on low-textured objects. We propose a keypoint-free pose estimation pipeline to remove the need for repeatable keypoint detection. Built upon the detector-free feature matching method LoFTR, we devise a new keypoint-free SfM method to reconstruct a semi-dense point-cloud model for the object. Given a query image for object pose estimation, a 2D-3D matching network directly establishes 2D-3D correspondences between the query image and the reconstructed point-cloud model without first detecting keypoints in the image. Experiments show that the proposed pipeline outperforms existing one-shot CAD-model-free methods by a large margin and is comparable to CAD-model-based methods on LINEMOD even for low-textured objects. We also collect a new dataset composed of 80 sequences of 40 low-textured objects to facilitate future research on one-shot object pose estimation. The supplementary material, code and dataset are available on the project page: https://zju3dv.github.io/onepose_plus_plus/."}
{"link":"http://arxiv.org/abs/2301.07634v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":2050580039,"_task_hash":1272583169,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674650519,"text":"Training Semantic Segmentation on Heterogeneous Datasets\nWe explore semantic segmentation beyond the conventional, single-dataset homogeneous training and bring forward the problem of Heterogeneous Training of Semantic Segmentation (HTSS). HTSS involves simultaneous training on multiple heterogeneous datasets, i.e. datasets with conflicting label spaces and different (weak) annotation types from the perspective of semantic segmentation. The HTSS formulation exposes deep networks to a larger and previously unexplored aggregation of information that can potentially enhance semantic segmentation in three directions: i) performance: increased segmentation metrics on seen datasets, ii) generalization: improved segmentation metrics on unseen datasets, and iii) knowledgeability: increased number of recognizable semantic concepts. To research these benefits of HTSS, we propose a unified framework, that incorporates heterogeneous datasets in a single-network training pipeline following the established FCN standard. Our framework first curates heterogeneous datasets to bring them into a common format and then trains a single-backbone FCN on all of them simultaneously. To achieve this, it transforms weak annotations, which are incompatible with semantic segmentation, to per-pixel labels, and hierarchizes their label spaces into a universal taxonomy. The trained HTSS models demonstrate performance and generalization gains over a wide range of datasets and extend the inference label space entailing hundreds of semantic classes."}
{"link":"http://arxiv.org/abs/2301.07627v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-602966376,"_task_hash":-465618131,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674650530,"text":"A novel dataset and a two-stage mitosis nuclei detection method based on hybrid anchor branch\nMitosis detection is one of the challenging problems in computational pathology, and mitotic count is an important index of cancer grading for pathologists. However, current counts of mitotic nuclei rely on pathologists looking microscopically at the number of mitotic nuclei in hot spots, which is subjective and time-consuming. In this paper, we propose a two-stage cascaded network, named FoCasNet, for mitosis detection. In the first stage, a detection network named M_det is proposed to detect as many mitoses as possible. In the second stage, a classification network M_class is proposed to refine the results of the first stage. In addition, the attention mechanism, normalization method, and hybrid anchor branch classification subnet are introduced to improve the overall detection performance. Our method achieves the current highest F1-score of 0.888 on the public dataset ICPR 2012. We also evaluated our method on the GZMH dataset released by our research team for the first time and reached the highest F1-score of 0.563, which is also better than multiple classic detection networks widely used at present. It confirmed the effectiveness and generalization of our method. The code will be available at: https://github.com/antifen/mitosis-nuclei-detection."}
{"link":"http://arxiv.org/abs/2301.07597v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-906608590,"_task_hash":1522307976,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674650534,"text":"How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection\nThe introduction of ChatGPT has garnered widespread attention in both academic and industrial communities. ChatGPT is able to respond effectively to a wide range of human questions, providing fluent and comprehensive answers that significantly surpass previous public chatbots in terms of security and usefulness. On one hand, people are curious about how ChatGPT is able to achieve such strength and how far it is from human experts. On the other hand, people are starting to worry about the potential negative impacts that large language models (LLMs) like ChatGPT could have on society, such as fake news, plagiarism, and social security issues. In this work, we collected tens of thousands of comparison responses from both human experts and ChatGPT, with questions ranging from open-domain, financial, medical, legal, and psychological areas. We call the collected dataset the Human ChatGPT Comparison Corpus (HC3). Based on the HC3 dataset, we study the characteristics of ChatGPT's responses, the differences and gaps from human experts, and future directions for LLMs. We conducted comprehensive human evaluations and linguistic analyses of ChatGPT-generated content compared with that of humans, where many interesting results are revealed. After that, we conduct extensive experiments on how to effectively detect whether a certain text is generated by ChatGPT or humans. We build three different detection systems, explore several key factors that influence their effectiveness, and evaluate them in different scenarios. The dataset, code, and models are all publicly available at https://github.com/Hello-SimpleAI/chatgpt-comparison-detection."}
{"link":"http://arxiv.org/abs/2301.10673v1","created":"2023-01-25","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-747447984,"_task_hash":1593811056,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750236,"text":"An Overview on Cloud Distributed Databases for Business Environments\nCloud-based distributed databases are a popular choice for many current applications, especially those that run over the Internet. By incorporating distributed database systems within cloud environments, it has enabled businesses to scale operations to a global level, all while achieving desired standards of system reliability, availability, and responsiveness. Cloud providers offer infrastructure and management tools for distributed databases as Database-as-a-Service (DBaaS), re-purposing the investment by businesses towards database services. This paper reviews the functionality of these services, by highlighting Amazon Relational Data Service (RDS), suited for handling relational distributed databases."}
{"link":"http://arxiv.org/abs/2301.10649v1","created":"2023-01-25","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-843248447,"_task_hash":560972207,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750239,"text":"On Creating a Comprehensive Food Database\nStudies with the primary aim of addressing eating disorders focus on assessing the nutrient content of food items with an exclusive focus on caloric intake. There are two primary impediments that can be noted in these studies. The first of these relates to the fact that caloric intake of each food item is calculated from an existing database. The second concerns the scientific significance of caloric intake used as the single measure of nutrient content. By requiring an existing database, researchers are forced to find some source of a comprehensive set of food items as well as their respective nutrients. This search alone is a difficult task, and if completed often leads to the requirement of a paid API service. These services are expensive and non-customizable, taking away funding that could be aimed at other parts of the study only to give an unwieldy database that can not be modified or contributed to. In this work, we introduce a new rendition of the USDA's food database that includes both foods found in grocery stores and those found in restaurants or fast food places. At the moment, we have accumulated roughly 1.5 million food entries consisting of approximately 18,000 brands and 100 restaurants in the United States. These foods also have an abundance of nutrient data associated with them, from the caloric amount to saturated fat levels. The data is stored in MySQL format and is spread among five major tables. We have also procured images for theses foods entries when available, and have included all of our data and program scripts in an open source repository."}
{"link":"http://arxiv.org/abs/2301.10559v1","created":"2023-01-25","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1225557740,"_task_hash":-26413667,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750241,"text":"Tracking Different Ant Species: An Unsupervised Domain Adaptation Framework and a Dataset for Multi-object Tracking\nTracking individuals is a vital part of many experiments conducted to understand collective behaviour. Ants are the paradigmatic model system for such experiments but their lack of individually distinguishing visual features and their high colony densities make it extremely difficult to perform reliable tracking automatically. Additionally, the wide diversity of their species' appearances makes a generalized approach even harder. In this paper, we propose a data-driven multi-object tracker that, for the first time, employs domain adaptation to achieve the required generalisation. This approach is built upon a joint-detection-and-tracking framework that is extended by a set of domain discriminator modules integrating an adversarial training strategy in addition to the tracking loss. In addition to this novel domain-adaptive tracking framework, we present a new dataset and a benchmark for the ant tracking problem. The dataset contains 57 video sequences with full trajectory annotation, including 30k frames captured from two different ant species moving on different background patterns. It comprises 33 and 24 sequences for source and target domains, respectively. We compare our proposed framework against other domain-adaptive and non-domain-adaptive multi-object tracking baselines using this dataset and show that incorporating domain adaptation at multiple levels of the tracking pipeline yields significant improvements. The code and the dataset are available at https://github.com/chamathabeysinghe/da-tracker."}
{"link":"http://arxiv.org/abs/2301.10302v1","created":"2023-01-24","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1767506018,"_task_hash":1815692058,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750251,"text":"A database of basic numerical invariants of Hilbert modular surfaces\nWe describe algorithms for computing geometric invariants for Hilbert modular surfaces, and we report on their implementation."}
{"link":"http://arxiv.org/abs/2301.10545v1","created":"2023-01-25","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":-508550216,"_task_hash":-1002188722,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750257,"text":"Beware of the Unexpected: Bimodal Taint Analysis\nStatic analysis is a powerful tool for detecting security vulnerabilities and other programming problems. Global taint tracking, in particular, can spot vulnerabilities arising from complicated data flow across multiple functions. However, precisely identifying which flows are problematic is challenging, and sometimes depends on factors beyond the reach of pure program analysis, such as conventions and informal knowledge. For example, learning that a parameter \"name\" of an API function \"locale\" ends up in a file path is surprising and potentially problematic. In contrast, it would be completely unsurprising to find that a parameter \"command\" passed to an API function \"execaCommand\" is eventually interpreted as part of an operating-system command. This paper presents Fluffy, a bimodal taint analysis that combines static analysis, which reasons about data flow, with machine learning, which probabilistically determines which flows are potentially problematic. The key idea is to let machine learning models predict from natural language information involved in a taint flow, such as API names, whether the flow is expected or unexpected, and to inform developers only about the latter. We present a general framework and instantiate it with four learned models, which offer different trade-offs between the need to annotate training data and the accuracy of predictions. We implement Fluffy on top of the CodeQL analysis framework and apply it to 250K JavaScript projects. Evaluating on five common vulnerability types, we find that Fluffy achieves an F1 score of 0.85 or more on four of them across a variety of datasets."}
{"link":"http://arxiv.org/abs/2301.10400v1","created":"2023-01-25","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":-544046711,"_task_hash":1300285465,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750260,"text":"When to Trust Aggregated Gradients: Addressing Negative Client Sampling in Federated Learning\nFederated Learning has become a widely-used framework which allows learning a global model on decentralized local datasets under the condition of protecting local data privacy. However, federated learning faces severe optimization difficulty when training samples are not independently and identically distributed (non-i.i.d.). In this paper, we point out that the client sampling practice plays a decisive role in the aforementioned optimization difficulty. We find that the negative client sampling will cause the merged data distribution of currently sampled clients heavily inconsistent with that of all available clients, and further make the aggregated gradient unreliable. To address this issue, we propose a novel learning rate adaptation mechanism to adaptively adjust the server learning rate for the aggregated gradient in each round, according to the consistency between the merged data distribution of currently sampled clients and that of all available clients. Specifically, we make theoretical deductions to find a meaningful and robust indicator that is positively related to the optimal server learning rate and can effectively reflect the merged data distribution of sampled clients, and we utilize it for the server learning rate adaptation. Extensive experiments on multiple image and text classification tasks validate the great effectiveness of our method."}
{"link":"http://arxiv.org/abs/2301.10226v1","created":"2023-01-24","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":1922107343,"_task_hash":-1755727940,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750262,"text":"A Watermark for Large Language Models\nPotential harms of large language models can be mitigated by watermarking model output, i.e., embedding signals into generated text that are invisible to humans but algorithmically detectable from a short span of tokens. We propose a watermarking framework for proprietary language models. The watermark can be embedded with negligible impact on text quality, and can be detected using an efficient open-source algorithm without access to the language model API or parameters. The watermark works by selecting a randomized set of whitelist tokens before a word is generated, and then softly promoting use of whitelist tokens during sampling. We propose a statistical test for detecting the watermark with interpretable p-values, and derive an information-theoretic framework for analyzing the sensitivity of the watermark. We test the watermark using a multi-billion parameter model from the Open Pretrained Transformer (OPT) family, and discuss robustness and security."}
{"link":"http://arxiv.org/abs/2301.10053v1","created":"2023-01-24","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":1764927466,"_task_hash":-1674401390,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750265,"text":"A Linear Reconstruction Approach for Attribute Inference Attacks against Synthetic Data\nPersonal data collected at scale from surveys or digital devices offers important insights for statistical analysis and scientific research. Safely sharing such data while protecting privacy is however challenging. Anonymization allows data to be shared while minimizing privacy risks, but traditional anonymization techniques have been repeatedly shown to provide limited protection against re-identification attacks in practice. Among modern anonymization techniques, synthetic data generation (SDG) has emerged as a potential solution to find a good tradeoff between privacy and statistical utility. Synthetic data is typically generated using algorithms that learn the statistical distribution of the original records, to then generate \"artificial\" records that are structurally and statistically similar to the original ones. Yet, the fact that synthetic records are \"artificial\" does not, per se, guarantee that privacy is protected. In this work, we systematically evaluate the tradeoffs between protecting privacy and preserving statistical utility for a wide range of synthetic data generation algorithms. Modeling privacy as protection against attribute inference attacks (AIAs), we extend and adapt linear reconstruction attacks, which have not been previously studied in the context of synthetic data. While prior work suggests that AIAs may be effective only on few outlier records, we show they can be very effective even on randomly selected records. We evaluate attacks on synthetic datasets ranging from 10^3 to 10^6 records, showing that even for the same generative model, the attack effectiveness can drastically increase when a larger number of synthetic records is generated. Overall, our findings prove that synthetic data is subject to privacy-utility tradeoffs just like other anonymization techniques: when good utility is preserved, attribute inference can be a risk for many data subjects."}
{"link":"http://arxiv.org/abs/2301.09956v1","created":"2023-01-24","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":1408664665,"_task_hash":-206186508,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750267,"text":"Membership Inference of Diffusion Models\nRecent years have witnessed the tremendous success of diffusion models in data synthesis. However, when diffusion models are applied to sensitive data, they also give rise to severe privacy concerns. In this paper, we systematically present the first study about membership inference attacks against diffusion models, which aims to infer whether a sample was used to train the model. Two attack methods are proposed, namely loss-based and likelihood-based attacks. Our attack methods are evaluated on several state-of-the-art diffusion models, over different datasets in relation to privacy-sensitive data. Extensive experimental evaluations show that our attacks can achieve remarkable performance. Furthermore, we exhaustively investigate various factors which can affect attack performance. Finally, we also evaluate the performance of our attack methods on diffusion models trained with differential privacy."}
{"link":"http://arxiv.org/abs/2301.09806v1","created":"2023-01-24","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":628733106,"_task_hash":-119345528,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750281,"text":"Demystifying NFT Promotion and Phishing Scams\nThe popularity and hype around purchasing digital assets such as art, video, and music in the form of Non-fungible tokens (NFTs) has rapidly made them a lucrative investment opportunity, with NFT-based sales surpassing $25B in 2021 alone. However, the volatility and scarcity of NFTs, combined with the general lack of familiarity with the technical aspects of this ecosystem, encourage the spread of several scams. The success of an NFT is majorly impacted by its online virality. There have been sparse reports about scammers emulating this virality by either promoting their fraudulent NFT projects on social media or imitating other popular NFT projects. This paper presents a longitudinal analysis of 439 unique Twitter accounts that consistently promote fraudulent NFT collections through giveaway competitions and 1,028 NFT phishing attacks. Our findings indicate that most accounts interacting with these promotions are bots, which can rapidly increase the popularity of the fraudulent NFT collections by inflating their likes, followers, and retweet counts. This leads to significant engagement from real users, who then proceed to invest in the scams. On the other hand, we identify two novel attack vectors which are utilized by NFT phishing scams to steal funds and digital assets from the victim's wallet. We also identify several gaps in the prevalent anti-phishing ecosystem by evaluating the performance of popular anti-phishing blocklists and security tools against NFT phishing attacks. We utilize our findings to develop a machine learning classifier that can automatically detect NFT phishing scams at scale."}
{"link":"http://arxiv.org/abs/2301.09801v1","created":"2023-01-24","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":-2120378887,"_task_hash":-1524087068,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750285,"text":"Heterogeneous Domain Adaptation for IoT Intrusion Detection: A Geometric Graph Alignment Approach\nData scarcity hinders the usability of data-dependent algorithms when tackling IoT intrusion detection (IID). To address this, we utilise the data rich network intrusion detection (NID) domain to facilitate more accurate intrusion detection for IID domains. In this paper, a Geometric Graph Alignment (GGA) approach is leveraged to mask the geometric heterogeneities between domains for better intrusion knowledge transfer. Specifically, each intrusion domain is formulated as a graph where vertices and edges represent intrusion categories and category-wise interrelationships, respectively. The overall shape is preserved via a confused discriminator incapable to identify adjacency matrices between different intrusion domain graphs. A rotation avoidance mechanism and a centre point matching mechanism is used to avoid graph misalignment due to rotation and symmetry, respectively. Besides, category-wise semantic knowledge is transferred to act as vertex-level alignment. To exploit the target data, a pseudo-label election mechanism that jointly considers network prediction, geometric property and neighbourhood information is used to produce fine-grained pseudo-label assignment. Upon aligning the intrusion graphs geometrically from different granularities, the transferred intrusion knowledge can boost IID performance. Comprehensive experiments on several intrusion datasets demonstrate state-of-the-art performance of the GGA approach and validate the usefulness of GGA constituting components."}
{"link":"http://arxiv.org/abs/2301.09740v1","created":"2023-01-23","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":-803078848,"_task_hash":2041471862,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750287,"text":"DODEM: DOuble DEfense Mechanism Against Adversarial Attacks Towards Secure Industrial Internet of Things Analytics\nIndustrial Internet of Things (I-IoT) is a collaboration of devices, sensors, and networking equipment to monitor and collect data from industrial operations. Machine learning (ML) methods use this data to make high-level decisions with minimal human intervention. Data-driven predictive maintenance (PDM) is a crucial ML-based I-IoT application to find an optimal maintenance schedule for industrial assets. The performance of these ML methods can seriously be threatened by adversarial attacks where an adversary crafts perturbed data and sends it to the ML model to deteriorate its prediction performance. The models should be able to stay robust against these attacks where robustness is measured by how much perturbation in input data affects model performance. Hence, there is a need for effective defense mechanisms that can protect these models against adversarial attacks. In this work, we propose a double defense mechanism to detect and mitigate adversarial attacks in I-IoT environments. We first detect if there is an adversarial attack on a given sample using novelty detection algorithms. Then, based on the outcome of our algorithm, marking an instance as attack or normal, we select adversarial retraining or standard training to provide a secondary defense layer. If there is an attack, adversarial retraining provides a more robust model, while we apply standard training for regular samples. Since we may not know if an attack will take place, our adaptive mechanism allows us to consider irregular changes in data. The results show that our double defense strategy is highly efficient where we can improve model robustness by up to 64.6% and 52% compared to standard and adversarial retraining, respectively."}
{"link":"http://arxiv.org/abs/2301.09732v1","created":"2023-01-23","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":1859700591,"_task_hash":327798412,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750288,"text":"Backdoor Attacks in Peer-to-Peer Federated Learning\nWe study backdoor attacks in peer-to-peer federated learning systems on different graph topologies and datasets. We show that only 5% attacker nodes are sufficient to perform a backdoor attack with 42% attack success without decreasing the accuracy on clean data by more than 2%. We also demonstrate that the attack can be amplified by the attacker crashing a small number of nodes. We evaluate defenses proposed in the context of centralized federated learning and show they are ineffective in peer-to-peer settings. Finally, we propose a defense that mitigates the attacks by applying different clipping norms to the model updates received from peers and local model trained by a node."}
{"link":"http://arxiv.org/abs/2301.09604v1","created":"2023-01-23","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":1119888236,"_task_hash":1786454233,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750291,"text":"FedExP: Speeding up Federated Averaging Via Extrapolation\nFederated Averaging (FedAvg) remains the most popular algorithm for Federated Learning (FL) optimization due to its simple implementation, stateless nature, and privacy guarantees combined with secure aggregation. Recent work has sought to generalize the vanilla averaging in FedAvg to a generalized gradient descent step by treating client updates as pseudo-gradients and using a server step size. While the use of a server step size has been shown to provide performance improvement theoretically, the practical benefit of the server step size has not been seen in most existing works. In this work, we present FedExP, a method to adaptively determine the server step size in FL based on dynamically varying pseudo-gradients throughout the FL process. We begin by considering the overparameterized convex regime, where we reveal an interesting similarity between FedAvg and the Projection Onto Convex Sets (POCS) algorithm. We then show how FedExP can be motivated as a novel extension to the extrapolation mechanism that is used to speed up POCS. Our theoretical analysis later also discusses the implications of FedExP in underparameterized and non-convex settings. Experimental results show that FedExP consistently converges faster than FedAvg and competing baselines on a range of realistic FL datasets."}
{"link":"http://arxiv.org/abs/2301.09320v2","created":"2023-01-23","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":1094324745,"_task_hash":-545820852,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750294,"text":"A Framework for Evaluating the Impact of Food Security Scenarios\nThis study proposes an approach for predicting the impacts of scenarios on food security and demonstrates its application in a case study. The approach involves two main steps: (1) scenario definition, in which the end user specifies the assumptions and impacts of the scenario using a scenario template, and (2) scenario evaluation, in which a Vector Autoregression (VAR) model is used in combination with Monte Carlo simulation to generate predictions for the impacts of the scenario based on the defined assumptions and impacts. The case study is based on a proprietary time series food security database created using data from the Food and Agriculture Organization of the United Nations (FAOSTAT), the World Bank, and the United States Department of Agriculture (USDA). The database contains a wide range of data on various indicators of food security, such as production, trade, consumption, prices, availability, access, and nutritional value. The results show that the proposed approach can be used to predict the potential impacts of scenarios on food security and that the proprietary time series food security database can be used to support this approach. The study provides specific insights on how this approach can inform decision-making processes related to food security such as food prices and availability in the case study region."}
{"link":"http://arxiv.org/abs/2301.09305v1","created":"2023-01-23","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":-17206427,"_task_hash":245482626,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750300,"text":"Practical Adversarial Attacks Against AI-Driven Power Allocation in a Distributed MIMO Network\nIn distributed multiple-input multiple-output (D-MIMO) networks, power control is crucial to optimize the spectral efficiencies of users and max-min fairness (MMF) power control is a commonly used strategy as it satisfies uniform quality-of-service to all users. The optimal solution of MMF power control requires high complexity operations and hence deep neural network based artificial intelligence (AI) solutions are proposed to decrease the complexity. Although quite accurate models can be achieved by using AI, these models have some intrinsic vulnerabilities against adversarial attacks where carefully crafted perturbations are applied to the input of the AI model. In this work, we show that threats against the target AI model which might be originated from malicious users or radio units can substantially decrease the network performance by applying a successful adversarial sample, even in the most constrained circumstances. We also demonstrate that the risk associated with these kinds of adversarial attacks is higher than the conventional attack threats. Detailed simulations reveal the effectiveness of adversarial attacks and the necessity of smart defense techniques."}
{"link":"http://arxiv.org/abs/2301.09255v1","created":"2023-01-23","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":1654507276,"_task_hash":-294962442,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750315,"text":"Combined Use of Federated Learning and Image Encryption for Privacy-Preserving Image Classification with Vision Transformer\nIn recent years, privacy-preserving methods for deep learning have become an urgent problem. Accordingly, we propose the combined use of federated learning (FL) and encrypted images for privacy-preserving image classification under the use of the vision transformer (ViT). The proposed method allows us not only to train models over multiple participants without directly sharing their raw data but to also protect the privacy of test (query) images for the first time. In addition, it can also maintain the same accuracy as normally trained models. In an experiment, the proposed method was demonstrated to well work without any performance degradation on the CIFAR-10 and CIFAR-100 datasets."}
{"link":"http://arxiv.org/abs/2301.09254v1","created":"2023-01-23","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":141781759,"_task_hash":271324538,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750319,"text":"Learning to Linearize Deep Neural Networks for Secure and Efficient Private Inference\nThe large number of ReLU non-linearity operations in existing deep neural networks makes them ill-suited for latency-efficient private inference (PI). Existing techniques to reduce ReLU operations often involve manual effort and sacrifice significant accuracy. In this paper, we first present a novel measure of non-linearity layers' ReLU sensitivity, enabling mitigation of the time-consuming manual efforts in identifying the same. Based on this sensitivity, we then present SENet, a three-stage training method that for a given ReLU budget, automatically assigns per-layer ReLU counts, decides the ReLU locations for each layer's activation map, and trains a model with significantly fewer ReLUs to potentially yield latency and communication efficient PI. Experimental evaluations with multiple models on various datasets show SENet's superior performance both in terms of reduced ReLUs and improved classification accuracy compared to existing alternatives. In particular, SENet can yield models that require up to ~2x fewer ReLUs while yielding similar accuracy. For a similar ReLU budget SENet can yield models with ~2.32% improved classification accuracy, evaluated on CIFAR-100."}
{"link":"http://arxiv.org/abs/2301.09203v1","created":"2023-01-22","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":1478815832,"_task_hash":1498572529,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750322,"text":"Relaxed Models for Adversarial Streaming: The Advice Model and the Bounded Interruptions Model\nStreaming algorithms are typically analyzed in the oblivious setting, where we assume that the input stream is fixed in advance. Recently, there is a growing interest in designing adversarially robust streaming algorithms that must maintain utility even when the input stream is chosen adaptively and adversarially as the execution progresses. While several fascinating results are known for the adversarial setting, in general, it comes at a very high cost in terms of the required space. Motivated by this, in this work we set out to explore intermediate models that allow us to interpolate between the oblivious and the adversarial models. Specifically, we put forward the following two models:   (1) *The advice model*, in which the streaming algorithm may occasionally ask for one bit of advice.   (2) *The bounded interruptions model*, in which we assume that the adversary is only partially adaptive.   We present both positive and negative results for each of these two models. In particular, we present generic reductions from each of these models to the oblivious model. This allows us to design robust algorithms with significantly improved space complexity compared to what is known in the plain adversarial model."}
{"link":"http://arxiv.org/abs/2301.09201v1","created":"2023-01-22","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":-448376156,"_task_hash":-1784751369,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750330,"text":"SPEC5G: A Dataset for 5G Cellular Network Protocol Analysis\n5G is the 5th generation cellular network protocol. It is the state-of-the-art global wireless standard that enables an advanced kind of network designed to connect virtually everyone and everything with increased speed and reduced latency. Therefore, its development, analysis, and security are critical. However, all approaches to the 5G protocol development and security analysis, e.g., property extraction, protocol summarization, and semantic analysis of the protocol specifications and implementations are completely manual. To reduce such manual effort, in this paper, we curate SPEC5G the first-ever public 5G dataset for NLP research. The dataset contains 3,547,586 sentences with 134M words, from 13094 cellular network specifications and 13 online websites. By leveraging large-scale pre-trained language models that have achieved state-of-the-art results on NLP tasks, we use this dataset for security-related text classification and summarization. Security-related text classification can be used to extract relevant security-related properties for protocol testing. On the other hand, summarization can help developers and practitioners understand the high level of the protocol, which is itself a daunting task. Our results show the value of our 5G-centric dataset in 5G protocol analysis automation. We believe that SPEC5G will enable a new research direction into automatic analyses for the 5G cellular network protocol and numerous related downstream tasks. Our data and code are publicly available."}
{"link":"http://arxiv.org/abs/2301.08918v1","created":"2023-01-21","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":1350934583,"_task_hash":-1811022117,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750332,"text":"Is Signed Message Essential for Graph Neural Networks?\nMessage-passing Graph Neural Networks (GNNs), which collect information from adjacent nodes, achieve satisfying results on homophilic graphs. However, their performances are dismal in heterophilous graphs, and many researchers have proposed a plethora of schemes to solve this problem. Especially, flipping the sign of edges is rooted in a strong theoretical foundation, and attains significant performance enhancements. Nonetheless, previous analyses assume a binary class scenario and they may suffer from confined applicability. This paper extends the prior understandings to multi-class scenarios and points out two drawbacks: (1) the sign of multi-hop neighbors depends on the message propagation paths and may incur inconsistency, (2) it also increases the prediction uncertainty (e.g., conflict evidence) which can impede the stability of the algorithm. Based on the theoretical understanding, we introduce a novel strategy that is applicable to multi-class graphs. The proposed scheme combines confidence calibration to secure robustness while reducing uncertainty. We show the efficacy of our theorem through extensive experiments on six benchmark graph datasets."}
{"link":"http://arxiv.org/abs/2301.08824v1","created":"2023-01-20","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":-460572645,"_task_hash":-1818545265,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750336,"text":"An Automated Vulnerability Detection Framework for Smart Contracts\nWith the increase of the adoption of blockchain technology in providing decentralized solutions to various problems, smart contracts have become more popular to the point that billions of US Dollars are currently exchanged every day through such technology. Meanwhile, various vulnerabilities in smart contracts have been exploited by attackers to steal cryptocurrencies worth millions of dollars. The automatic detection of smart contract vulnerabilities therefore is an essential research problem. Existing solutions to this problem particularly rely on human experts to define features or different rules to detect vulnerabilities. However, this often causes many vulnerabilities to be ignored, and they are inefficient in detecting new vulnerabilities. In this study, to overcome such challenges, we propose a framework to automatically detect vulnerabilities in smart contracts on the blockchain. More specifically, first, we utilize novel feature vector generation techniques from bytecode of smart contract since the source code of smart contracts are rarely available in public. Next, the collected vectors are fed into our novel metric learning-based deep neural network(DNN) to get the detection result. We conduct comprehensive experiments on large-scale benchmarks, and the quantitative results demonstrate the effectiveness and efficiency of our approach."}
{"link":"http://arxiv.org/abs/2301.08778v1","created":"2023-01-20","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":1194804272,"_task_hash":761260368,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750340,"text":"Split Ways: Privacy-Preserving Training of Encrypted Data Using Split Learning\nSplit Learning (SL) is a new collaborative learning technique that allows participants, e.g. a client and a server, to train machine learning models without the client sharing raw data. In this setting, the client initially applies its part of the machine learning model on the raw data to generate activation maps and then sends them to the server to continue the training process. Previous works in the field demonstrated that reconstructing activation maps could result in privacy leakage of client data. In addition to that, existing mitigation techniques that overcome the privacy leakage of SL prove to be significantly worse in terms of accuracy. In this paper, we improve upon previous works by constructing a protocol based on U-shaped SL that can operate on homomorphically encrypted data. More precisely, in our approach, the client applies Homomorphic Encryption (HE) on the activation maps before sending them to the server, thus protecting user privacy. This is an important improvement that reduces privacy leakage in comparison to other SL-based works. Finally, our results show that, with the optimum set of parameters, training with HE data in the U-shaped SL setting only reduces accuracy by 2.65% compared to training on plaintext. In addition, raw training data privacy is preserved."}
{"link":"http://arxiv.org/abs/2301.08751v1","created":"2023-01-20","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":498240527,"_task_hash":-1462513053,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750342,"text":"Towards Understanding How Self-training Tolerates Data Backdoor Poisoning\nRecent studies on backdoor attacks in model training have shown that polluting a small portion of training data is sufficient to produce incorrect manipulated predictions on poisoned test-time data while maintaining high clean accuracy in downstream tasks. The stealthiness of backdoor attacks has imposed tremendous defense challenges in today's machine learning paradigm. In this paper, we explore the potential of self-training via additional unlabeled data for mitigating backdoor attacks. We begin by making a pilot study to show that vanilla self-training is not effective in backdoor mitigation. Spurred by that, we propose to defend the backdoor attacks by leveraging strong but proper data augmentations in the self-training pseudo-labeling stage. We find that the new self-training regime help in defending against backdoor attacks to a great extent. Its effectiveness is demonstrated through experiments for different backdoor triggers on CIFAR-10 and a combination of CIFAR-10 with an additional unlabeled 500K TinyImages dataset. Finally, we explore the direction of combining self-supervised representation learning with self-training for further improvement in backdoor defense."}
{"link":"http://arxiv.org/abs/2301.08427v1","created":"2023-01-20","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":-415864799,"_task_hash":726741599,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750346,"text":"Which Features are Learned by CodeBert: An Empirical Study of the BERT-based Source Code Representation Learning\nThe Bidirectional Encoder Representations from Transformers (BERT) were proposed in the natural language process (NLP) and shows promising results. Recently researchers applied the BERT to source-code representation learning and reported some good news on several downstream tasks. However, in this paper, we illustrated that current methods cannot effectively understand the logic of source codes. The representation of source code heavily relies on the programmer-defined variable and function names. We design and implement a set of experiments to demonstrate our conjecture and provide some insights for future works."}
{"link":"http://arxiv.org/abs/2301.08403v1","created":"2023-01-20","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":10037591,"_task_hash":795278772,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750349,"text":"Sequence Generation via Subsequence Similarity: Theory and Application to UAV Identification\nThe ability to generate synthetic sequences is crucial for a wide range of applications, and recent advances in deep learning architectures and generative frameworks have greatly facilitated this process. Particularly, unconditional one-shot generative models constitute an attractive line of research that focuses on capturing the internal information of a single image, video, etc. to generate samples with similar contents. Since many of those one-shot models are shifting toward efficient non-deep and non-adversarial approaches, we examine the versatility of a one-shot generative model for augmenting whole datasets. In this work, we focus on how similarity at the subsequence level affects similarity at the sequence level, and derive bounds on the optimal transport of real and generated sequences based on that of corresponding subsequences. We use a one-shot generative model to sample from the vicinity of individual sequences and generate subsequence-similar ones and demonstrate the improvement of this approach by applying it to the problem of Unmanned Aerial Vehicle (UAV) identification using limited radio-frequency (RF) signals. In the context of UAV identification, RF fingerprinting is an effective method for distinguishing legitimate devices from malicious ones, but heterogenous environments and channel impairments can impose data scarcity and affect the performance of classification models. By using subsequence similarity to augment sequences of RF data with a low ratio (5\\%-20\\%) of training dataset, we achieve significant improvements in performance metrics such as accuracy, precision, recall, and F1 score."}
{"link":"http://arxiv.org/abs/2301.08179v1","created":"2023-01-19","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"_input_hash":-1622794858,"_task_hash":1360754263,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750352,"text":"Machine Learning-Based Secret Key Generation for IRS-assisted Multi-antenna Systems\nPhysical-layer key generation (PKG) based on wireless channels is a lightweight technique to establish secure keys between legitimate communication nodes. Recently, intelligent reflecting surfaces (IRSs) have been leveraged to enhance the performance of PKG in terms of secret key rate (SKR), as it can reconfigure the wireless propagation environment and introduce more channel randomness. In this paper, we investigate an IRS-assisted PKG system, taking into account the channel spatial correlation at both the base station (BS) and the IRS. Based on the considered system model, the closed form expression of SKR is derived analytically. Aiming to maximize the SKR, a joint design problem of the BS precoding matrix and the IRS reflecting coefficient vector is formulated. To address this high-dimensional non-convex optimization problem, we propose a novel unsupervised deep neural network (DNN) based algorithm with a simple structure. Different from most previous works that adopt the iterative optimization to solve the problem, the proposed DNN based algorithm directly obtains the BS precoding and IRS phase shifts as the output of the DNN. Simulation results reveal that the proposed DNN-based algorithm outperforms the benchmark methods with regard to SKR."}
{"link":"http://arxiv.org/abs/2301.07551v2","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":104496682,"_task_hash":-611541966,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750531,"text":"A Synthetic Hyperspectral Array Video Database with Applications to Cross-Spectral Reconstruction and Hyperspectral Video Coding\nIn this paper, a synthetic hyperspectral video database is introduced. Since it is impossible to record ground truth hyperspectral videos, this database offers the possibility to leverage the evaluation of algorithms in diverse applications. For all scenes, depth maps are provided as well to yield the position of a pixel in all spatial dimensions as well as the reflectance in spectral dimension. Two novel algorithms for two different applications are proposed to prove the diversity of applications that can be addressed by this novel database. First, a cross-spectral image reconstruction algorithm is extended to exploit the temporal correlation between two consecutive frames. The evaluation using this hyperspectral database shows an increase in PSNR of up to 5.6 dB dependent on the scene. Second, a hyperspectral video coder is introduced which extends an existing hyperspectral image coder by exploiting temporal correlation. The evaluation shows rate savings of up to 10% depending on the scene. The novel hyperspectral video database and source code is available at https:// github.com/ FAU-LMS/ HyViD for use by the research community."}
{"link":"http://arxiv.org/abs/2301.07452v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1080925946,"_task_hash":-1673093340,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750537,"text":"SEN2DWATER: A Novel Multispectral and Multitemporal Dataset and Deep Learning Benchmark for Water Resources Analysis\nClimate change has caused disruption in certain weather patterns, leading to extreme weather events like flooding and drought in different parts of the world. In this paper, we propose machine learning methods for analyzing changes in water resources over a time period of six years, by focusing on lakes and rivers in Italy and Spain. Additionally, we release open-access code to enable the expansion of the study to any region of the world.   We create a novel multispectral and multitemporal dataset, SEN2DWATER, which is freely accessible on GitHub. We introduce suitable indices to monitor changes in water resources, and benchmark the new dataset on three different deep learning frameworks: Convolutional Long Short Term Memory (ConvLSTM), Bidirectional ConvLSTM, and Time Distributed Convolutional Neural Networks (TD-CNNs). Future work exploring the many potential applications of this research is also discussed."}
{"link":"http://arxiv.org/abs/2301.07369v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":277459624,"_task_hash":-2046160587,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750540,"text":"A semi-model-independent approach to describe a cosmological database\nA model-independent or non-parametric approach for modeling a database has been widely used in cosmology. In these scenarios, the data has been used directly to reconstruct an underlying function. In this work, we introduce a novel semi-model-independent method to do the task. The new approach not only removes some drawbacks of previous methods but also has some remarkable advantages. We combine the well-known Gaussian linear model with a neural network and introduce a procedure for the reconstruction of an arbitrary function. In the scenario, the neural network produces some arbitrary base functions which subsequently are fed to the Gaussian linear model. Given a prior distribution on the free parameters, the Gaussian linear model provides a close form for the posterior distribution as well as the Bayesian evidence. In addition, contrary to other methods, it is straightforward to compute the uncertainty."}
{"link":"http://arxiv.org/abs/2301.07315v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":539148723,"_task_hash":1107044308,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750554,"text":"Face Recognition in the age of CLIP & Billion image datasets\nCLIP (Contrastive Language-Image Pre-training) models developed by OpenAI have achieved outstanding results on various image recognition and retrieval tasks, displaying strong zero-shot performance. This means that they are able to perform effectively on tasks for which they have not been explicitly trained. Inspired by the success of OpenAI CLIP, a new publicly available dataset called LAION-5B was collected which resulted in the development of open ViT-H/14, ViT-G/14 models that outperform the OpenAI L/14 model. The LAION-5B dataset also released an approximate nearest neighbor index, with a web interface for search & subset creation.   In this paper, we evaluate the performance of various CLIP models as zero-shot face recognizers. Our findings show that CLIP models perform well on face recognition tasks, but increasing the size of the CLIP model does not necessarily lead to improved accuracy. Additionally, we investigate the robustness of CLIP models against data poisoning attacks by testing their performance on poisoned data. Through this analysis, we aim to understand the potential consequences and misuse of search engines built using CLIP models, which could potentially function as unintentional face recognition engines."}
{"link":"http://arxiv.org/abs/2301.07313v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1470339100,"_task_hash":-1396554860,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750559,"text":"Efficient Black-box Checking of Snapshot Isolation in Databases\nSnapshot isolation (SI) is a prevalent weak isolation level that avoids the performance penalty imposed by serializability and simultaneously prevents various undesired data anomalies. Nevertheless, SI anomalies have recently been found in production cloud databases that claim to provide the SI guarantee. Given the complex and often unavailable internals of such databases, a black-box SI checker is highly desirable.   In this paper we present PolySI, a novel black-box checker that efficiently checks SI and provides understandable counterexamples upon detecting violations. PolySI builds on a novel characterization of SI using generalized polygraphs (GPs), for which we establish its soundness and completeness. PolySI employs an SMT solver and also accelerates SMT solving by utilizing the compact constraint encoding of GPs and domain-specific optimizations for pruning constraints. As demonstrated by our extensive assessment, PolySI successfully reproduces all of 2477 known SI anomalies, detects novel SI violations in three production cloud databases, identifies their causes, outperforms the state-of-the-art black-box checkers under a wide range of workloads, and can scale up to large-sized workloads."}
{"link":"http://arxiv.org/abs/2301.07074v1","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":96874525,"_task_hash":-1304194528,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750565,"text":"SegViz: A Federated Learning Framework for Medical Image Segmentation from Distributed Datasets with Different and Incomplete Annotations\nSegmentation is one of the primary tasks in the application of deep learning in medical imaging, owing to its multiple downstream clinical applications. As a result, many large-scale segmentation datasets have been curated and released for the segmentation of different anatomical structures. However, these datasets focus on the segmentation of a subset of anatomical structures in the body, therefore, training a model for each dataset would potentially result in hundreds of models and thus limit their clinical translational utility. Furthermore, many of these datasets share the same field of view but have different subsets of annotations, thus making individual dataset annotations incomplete. To that end, we developed SegViz, a federated learning framework for aggregating knowledge from distributed medical image segmentation datasets with different and incomplete annotations into a `global` meta-model. The SegViz framework was trained to build a single model capable of segmenting both liver and spleen aggregating knowledge from both these nodes by aggregating the weights after every 10 epochs. The global SegViz model was tested on an external dataset, Beyond the Cranial Vault (BTCV), comprising both liver and spleen annotations using the dice similarity (DS) metric. The baseline individual segmentation models for spleen and liver trained on their respective datasets produced a DS score of 0.834 and 0.878 on the BTCV test set. In comparison, the SegViz model produced comparable mean DS scores of 0.829 and 0.899 for the segmentation of the spleen and liver respectively. Our results demonstrate SegViz as an essential first step towards training clinically translatable multi-task segmentation models from distributed datasets with disjoint incomplete annotations with excellent performance."}
{"link":"http://arxiv.org/abs/2301.07015v1","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1368897420,"_task_hash":359338116,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750568,"text":"Simplistic Collection and Labeling Practices Limit the Utility of Benchmark Datasets for Twitter Bot Detection\nAccurate bot detection is necessary for the safety and integrity of online platforms. It is also crucial for research on the influence of bots in elections, the spread of misinformation, and financial market manipulation. Platforms deploy infrastructure to flag or remove automated accounts, but their tools and data are not publicly available. Thus, the public must rely on third-party bot detection. These tools employ machine learning and often achieve near perfect performance for classification on existing datasets, suggesting bot detection is accurate, reliable and fit for use in downstream applications. We provide evidence that this is not the case and show that high performance is attributable to limitations in dataset collection and labeling rather than sophistication of the tools. Specifically, we show that simple decision rules -- shallow decision trees trained on a small number of features -- achieve near-state-of-the-art performance on most available datasets and that bot detection datasets, even when combined together, do not generalize well to out-of-sample datasets. Our findings reveal that predictions are highly dependent on each dataset's collection and labeling procedures rather than fundamental differences between bots and humans. These results have important implications for both transparency in sampling and labeling procedures and potential biases in research using existing bot detection tools for pre-processing."}
{"link":"http://arxiv.org/abs/2301.07014v2","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1941353964,"_task_hash":-331741038,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750575,"text":"Dataset Distillation: A Comprehensive Review\nRecent success of deep learning is largely attributed to the sheer amount of data used for training deep neural networks.Despite the unprecedented success, the massive data, unfortunately, significantly increases the burden on storage and transmission and further gives rise to a cumbersome model training process. Besides, relying on the raw data for training \\emph{per se} yields concerns about privacy and copyright. To alleviate these shortcomings, dataset distillation~(DD), also known as dataset condensation (DC), was introduced and has recently attracted much research attention in the community. Given an original dataset, DD aims to derive a much smaller dataset containing synthetic samples, based on which the trained models yield performance comparable with those trained on the original dataset. In this paper, we give a comprehensive review and summary of recent advances in DD and its application. We first introduce the task formally and propose an overall algorithmic framework followed by all existing DD methods. Next, we provide a systematic taxonomy of current methodologies in this area, and discuss their theoretical interconnections. We also present current challenges in DD through extensive experiments and envision possible directions for future works."}
{"link":"http://arxiv.org/abs/2301.06876v1","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1759265,"_task_hash":-43321189,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750586,"text":"CS-lol: a Dataset of Viewer Comment with Scene in E-sports Live-streaming\nBillions of live-streaming viewers share their opinions on scenes they are watching in real-time and interact with the event, commentators as well as other viewers via text comments. Thus, there is necessary to explore viewers' comments with scenes in E-sport live-streaming events. In this paper, we developed CS-lol, a new large-scale dataset containing comments from viewers paired with descriptions of game scenes in E-sports live-streaming. Moreover, we propose a task, namely viewer comment retrieval, to retrieve the viewer comments for the scene of the live-streaming event. Results on a series of baseline retrieval methods derived from typical IR evaluation methods show our task as a challenging task. Finally, we release CS-lol and baseline implementation to the research community as a resource."}
{"link":"http://arxiv.org/abs/2301.07107v1","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-288933215,"_task_hash":519650422,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750589,"text":"Mortality Prediction with Adaptive Feature Importance Recalibration for Peritoneal Dialysis Patients: a deep-learning-based study on a real-world longitudinal follow-up dataset\nObjective: Peritoneal Dialysis (PD) is one of the most widely used life-supporting therapies for patients with End-Stage Renal Disease (ESRD). Predicting mortality risk and identifying modifiable risk factors based on the Electronic Medical Records (EMR) collected along with the follow-up visits are of great importance for personalized medicine and early intervention. Here, our objective is to develop a deep learning model for a real-time, individualized, and interpretable mortality prediction model - AICare. Method and Materials: Our proposed model consists of a multi-channel feature extraction module and an adaptive feature importance recalibration module. AICare explicitly identifies the key features that strongly indicate the outcome prediction for each patient to build the health status embedding individually. This study has collected 13,091 clinical follow-up visits and demographic data of 656 PD patients. To verify the application universality, this study has also collected 4,789 visits of 1,363 hemodialysis dialysis (HD) as an additional experiment dataset to test the prediction performance, which will be discussed in the Appendix. Results: 1) Experiment results show that AICare achieves 81.6%/74.3% AUROC and 47.2%/32.5% AUPRC for the 1-year mortality prediction task on PD/HD dataset respectively, which outperforms the state-of-the-art comparative deep learning models. 2) This study first provides a comprehensive elucidation of the relationship between the causes of mortality in patients with PD and clinical features based on an end-to-end deep learning model. 3) This study first reveals the pattern of variation in the importance of each feature in the mortality prediction based on built-in interpretability. 4) We develop a practical AI-Doctor interaction system to visualize the trajectory of patients' health status and risk indicators."}
{"link":"http://arxiv.org/abs/2301.06796v1","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1945118862,"_task_hash":733245501,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750592,"text":"Database Matching Under Noisy Synchronization Errors\nThe re-identification or de-anonymization of users from anonymized data through matching with publicly-available correlated user data has raised privacy concerns, leading to the complementary measure of obfuscation in addition to anonymization. Recent research provides a fundamental understanding of the conditions under which privacy attacks, in the form of database matching, are successful in the presence of obfuscation. Motivated by synchronization errors stemming from the sampling of time-indexed databases, this paper presents a unified framework considering both obfuscation and synchronization errors and investigates the matching of databases under noisy entry repetitions. By investigating different structures for the repetition pattern, replica detection and seeded deletion detection algorithms are devised and sufficient and necessary conditions for successful matching are derived. Finally, the impacts of some variations of the underlying assumptions, such as adversarial deletion model, seedless database matching and zero-rate regime, on the results are discussed. Overall, our results provide insights into the privacy-preserving publication of anonymized and obfuscated time-indexed data as well as the closely-related problem of the capacity of synchronization channels."}
{"link":"http://arxiv.org/abs/2301.06782v1","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-948195794,"_task_hash":1153963665,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750606,"text":"A Large-Scale Outdoor Multi-modal Dataset and Benchmark for Novel View Synthesis and Implicit Scene Reconstruction\nNeural Radiance Fields (NeRF) has achieved impressive results in single object scene reconstruction and novel view synthesis, which have been demonstrated on many single modality and single object focused indoor scene datasets like DTU, BMVS, and NeRF Synthetic.However, the study of NeRF on large-scale outdoor scene reconstruction is still limited, as there is no unified outdoor scene dataset for large-scale NeRF evaluation due to expensive data acquisition and calibration costs. In this paper, we propose a large-scale outdoor multi-modal dataset, OMMO dataset, containing complex land objects and scenes with calibrated images, point clouds and prompt annotations. Meanwhile, a new benchmark for several outdoor NeRF-based tasks is established, such as novel view synthesis, surface reconstruction, and multi-modal NeRF. To create the dataset, we capture and collect a large number of real fly-view videos and select high-quality and high-resolution clips from them. Then we design a quality review module to refine images, remove low-quality frames and fail-to-calibrate scenes through a learning-based automatic evaluation plus manual review. Finally, a number of volunteers are employed to add the text descriptions for each scene and key-frame to meet the potential multi-modal requirements in the future. Compared with existing NeRF datasets, our dataset contains abundant real-world urban and natural scenes with various scales, camera trajectories, and lighting conditions. Experiments show that our dataset can benchmark most state-of-the-art NeRF methods on different tasks. We will release the dataset and model weights very soon."}
{"link":"http://arxiv.org/abs/2301.06683v1","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1676841447,"_task_hash":1017087920,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750609,"text":"Surgical Aggregation: A Federated Learning Framework for Harmonizing Distributed Datasets with Diverse Tasks\nAI-assisted characterization of chest x-rays (CXR) has the potential to provide substantial benefits across many clinical applications. Many large-scale public CXR datasets have been curated for detection of abnormalities using deep learning. However, each of these datasets focus on detecting a subset of disease labels that could be present in a CXR, thus limiting their clinical utility. Furthermore, the distributed nature of these datasets, along with data sharing regulations, make it difficult to share and create a complete representation of disease labels. We propose surgical aggregation, a federated learning framework for aggregating knowledge from distributed datasets with different disease labels into a 'global' deep learning model. We randomly divided the NIH Chest X-Ray 14 dataset into training (70%), validation (10%), and test (20%) splits with no patient overlap and conducted two experiments. In the first experiment, we pruned the disease labels to create two 'toy' datasets containing 11 and 8 labels respectively with 4 overlapping labels. For the second experiment, we pruned the disease labels to create two disjoint 'toy' datasets with 7 labels each. We observed that the surgically aggregated 'global' model resulted in excellent performance across both experiments when compared to a 'baseline' model trained on complete disease labels. The overlapping and disjoint experiments had an AUROC of 0.87 and 0.86 respectively, compared to the baseline AUROC of 0.87. We used surgical aggregation to harmonize the NIH Chest X-Ray 14 and CheXpert datasets into a 'global' model with an AUROC of 0.85 and 0.83 respectively. Our results show that surgical aggregation could be used to develop clinically useful deep learning models by aggregating knowledge from distributed datasets with diverse tasks, a step forward towards bridging the gap from bench to bedside."}
{"link":"http://arxiv.org/abs/2301.06660v1","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1762155471,"_task_hash":1077452365,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750631,"text":"VaxxHesitancy: A Dataset for Studying Hesitancy Towards COVID-19 Vaccination on Twitter\nVaccine hesitancy has been a common concern, probably since vaccines were created and, with the popularisation of social media, people started to express their concerns about vaccines online alongside those posting pro- and anti-vaccine content. Predictably, since the first mentions of a COVID-19 vaccine, social media users posted about their fears and concerns or about their support and belief into the effectiveness of these rapidly developing vaccines. Identifying and understanding the reasons behind public hesitancy towards COVID-19 vaccines is important for policy markers that need to develop actions to better inform the population with the aim of increasing vaccine take-up. In the case of COVID-19, where the fast development of the vaccines was mirrored closely by growth in anti-vaxx disinformation, automatic means of detecting citizen attitudes towards vaccination became necessary. This is an important computational social sciences task that requires data analysis in order to gain in-depth understanding of the phenomena at hand. Annotated data is also necessary for training data-driven models for more nuanced analysis of attitudes towards vaccination. To this end, we created a new collection of over 3,101 tweets annotated with users' attitudes towards COVID-19 vaccination (stance). Besides, we also develop a domain-specific language model (VaxxBERT) that achieves the best predictive performance (73.0 accuracy and 69.3 F1-score) as compared to a robust set of baselines. To the best of our knowledge, these are the first dataset and model that model vaccine hesitancy as a category distinct from pro- and anti-vaccine stance."}
{"link":"http://arxiv.org/abs/2301.06617v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1647543890,"_task_hash":552234962,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750634,"text":"ClassBases at CASE-2022 Multilingual Protest Event Detection Tasks: Multilingual Protest News Detection and Automatically Replicating Manually Created Event Datasets\nIn this report, we describe our ClassBases submissions to a shared task on multilingual protest event detection. For the multilingual protest news detection, we participated in subtask-1, subtask-2, and subtask-4, which are document classification, sentence classification, and token classification. In subtask-1, we compare XLM-RoBERTa-base, mLUKE-base, and XLM-RoBERTa-large on finetuning in a sequential classification setting. We always use a combination of the training data from every language provided to train our multilingual models. We found that larger models seem to work better and entity knowledge helps but at a non-negligible cost. For subtask-2, we only submitted an mLUKE-base system for sentence classification. For subtask-4, we only submitted an XLM-RoBERTa-base for token classification system for sequence labeling. For automatically replicating manually created event datasets, we participated in COVID-related protest events from the New York Times news corpus. We created a system to process the crawled data into a dataset of protest events."}
{"link":"http://arxiv.org/abs/2301.06601v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1655823501,"_task_hash":652451712,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750638,"text":"A Dataset of Coordinated Cryptocurrency-Related Social Media Campaigns\nThe rise in adoption of cryptoassets has brought many new and inexperienced investors in the cryptocurrency space. These investors can be disproportionally influenced by information they receive online, and particularly from social media. This paper presents a dataset of crypto-related bounty events and the users that participate in them. These events coordinate social media campaigns to create artificial \"hype\" around a crypto project in order to influence the price of its token. The dataset consists of information about 15.8K cross-media bounty events, 185K participants, 10M forum comments and 82M social media URLs collected from the Bounties(Altcoins) subforum of the BitcoinTalk online forum from May 2014 to December 2022. We describe the data collection and the data processing methods employed, we present a basic characterization of the dataset, and we describe potential research opportunities afforded by the dataset across many disciplines."}
{"link":"http://arxiv.org/abs/2301.06527v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1629866336,"_task_hash":-935945210,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750680,"text":"XNLI 2.0: Improving XNLI dataset and performance on Cross Lingual Understanding (XLU)\nNatural Language Processing systems are heavily dependent on the availability of annotated data to train practical models. Primarily, models are trained on English datasets. In recent times, significant advances have been made in multilingual understanding due to the steeply increasing necessity of working in different languages. One of the points that stands out is that since there are now so many pre-trained multilingual models, we can utilize them for cross-lingual understanding tasks. Using cross-lingual understanding and Natural Language Inference, it is possible to train models whose applications extend beyond the training language. We can leverage the power of machine translation to skip the tiresome part of translating datasets from one language to another. In this work, we focus on improving the original XNLI dataset by re-translating the MNLI dataset in all of the 14 different languages present in XNLI, including the test and dev sets of XNLI using Google Translate. We also perform experiments by training models in all 15 languages and analyzing their performance on the task of natural language inference. We then expand our boundary to investigate if we could improve performance in low-resource languages such as Swahili and Urdu by training models in languages other than English."}
{"link":"http://arxiv.org/abs/2301.06494v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1092773003,"_task_hash":1392142772,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750685,"text":"CRYPTEXT: Database and Interactive Toolkit of Human-Written Text Perturbations in the Wild\nUser-generated textual contents on the Internet are often noisy, erroneous, and not in correct forms in grammar. In fact, some online users choose to express their opinions online through carefully perturbed texts, especially in controversial topics (e.g., politics, vaccine mandate) or abusive contexts (e.g., cyberbullying, hate-speech). However, to the best of our knowledge, there is no framework that explores these online ``human-written\" perturbations (as opposed to algorithm-generated perturbations). Therefore, we introduce an interactive system called CRYPTEXT. CRYPTEXT is a data-intensive application that provides the users with a database and several tools to extract and interact with human-written perturbations. Specifically, CRYPTEXT helps look up, perturb, and normalize (i.e., de-perturb) texts. CRYPTEXT also provides an interactive interface to monitor and analyze text perturbations online. A short demo video is available at: https://youtu.be/8WT3G8xjIoI"}
{"link":"http://arxiv.org/abs/2301.06375v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-564951932,"_task_hash":143026657,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750689,"text":"OLKAVS: An Open Large-Scale Korean Audio-Visual Speech Dataset\nInspired by humans comprehending speech in a multi-modal manner, various audio-visual datasets have been constructed. However, most existing datasets focus on English, induce dependencies with various prediction models during dataset preparation, and have only a small number of multi-view videos. To mitigate the limitations, we recently developed the Open Large-scale Korean Audio-Visual Speech (OLKAVS) dataset, which is the largest among publicly available audio-visual speech datasets. The dataset contains 1,150 hours of transcribed audio from 1,107 Korean speakers in a studio setup with nine different viewpoints and various noise situations. We also provide the pre-trained baseline models for two tasks, audio-visual speech recognition and lip reading. We conducted experiments based on the models to verify the effectiveness of multi-modal and multi-view training over uni-modal and frontal-view-only training. We expect the OLKAVS dataset to facilitate multi-modal research in broader areas such as Korean speech recognition, speaker recognition, pronunciation level classification, and mouth motion analysis."}
{"link":"http://arxiv.org/abs/2301.06316v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1521091369,"_task_hash":-1068485969,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750691,"text":"A Twitter Dataset for Pakistani Political Discourse\nWe share the largest dataset for the Pakistani Twittersphere consisting of over 49 million tweets, collected during one of the most politically active periods in the country. We collect the data after the deposition of the government by a No Confidence Vote in April 2022. This large-scale dataset can be used for several downstream tasks such as political bias, bots detection, trolling behavior, (dis)misinformation, and censorship related to Pakistani Twitter users. In addition, this dataset provides a large collection of tweets in Urdu and Roman Urdu that can be used for optimizing language processing tasks."}
{"link":"http://arxiv.org/abs/2301.06304v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-922430463,"_task_hash":7038608,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750701,"text":"LYSTO: The Lymphocyte Assessment Hackathon and Benchmark Dataset\nWe introduce LYSTO, the Lymphocyte Assessment Hackathon, which was held in conjunction with the MICCAI 2019 Conference in Shenzen (China). The competition required participants to automatically assess the number of lymphocytes, in particular T-cells, in histopathological images of colon, breast, and prostate cancer stained with CD3 and CD8 immunohistochemistry. Differently from other challenges setup in medical image analysis, LYSTO participants were solely given a few hours to address this problem. In this paper, we describe the goal and the multi-phase organization of the hackathon; we describe the proposed methods and the on-site results. Additionally, we present post-competition results where we show how the presented methods perform on an independent set of lung cancer slides, which was not part of the initial competition, as well as a comparison on lymphocyte assessment between presented methods and a panel of pathologists. We show that some of the participants were capable to achieve pathologist-level performance at lymphocyte assessment. After the hackathon, LYSTO was left as a lightweight plug-and-play benchmark dataset on grand-challenge website, together with an automatic evaluation platform. LYSTO has supported a number of research in lymphocyte assessment in oncology. LYSTO will be a long-lasting educational challenge for deep learning and digital pathology, it is available at https://lysto.grand-challenge.org/."}
{"link":"http://arxiv.org/abs/2301.06270v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":123259706,"_task_hash":-652714141,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750710,"text":"Computational Assessment of Hyperpartisanship in News Titles\nWe first adopt a human-guided machine learning framework to develop a new dataset for hyperpartisan news title detection with 2,200 manually labeled and 1.8 million machine-labeled titles that were posted from 2014 to the present by nine representative media organizations across three media bias groups - Left, Central, and Right in an active learning manner. The fine-tuned transformer-based language model achieves an overall accuracy of 0.84 and an F1 score of 0.78 on an external validation set. Next, we conduct a computational analysis to quantify the extent and dynamics of partisanship in news titles. While some aspects are as expected, our study reveals new or nuanced differences between the three media groups. We find that overall the Right media tends to use proportionally more hyperpartisan titles. Roughly around the 2016 Presidential Election, the proportions of hyperpartisan titles increased in all media bias groups where the relative increase in the proportion of hyperpartisan titles of the Left media was the most. We identify three major topics including foreign issues, political systems, and societal issues that are suggestive of hyperpartisanship in news titles using logistic regression models and the Shapley values. Through an analysis of the topic distribution, we find that societal issues gradually receive more attention from all media groups. We further apply a lexicon-based language analysis tool to the titles of each topic and quantify the linguistic distance between any pairs of the three media groups. Three distinct patterns are discovered. The Left media is linguistically more different from Central and Right in terms of foreign issues. The linguistic distance between the three media groups becomes smaller over recent years. In addition, a seasonal pattern where linguistic difference is associated with elections is observed for societal issues."}
{"link":"http://arxiv.org/abs/2301.06262v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-536557881,"_task_hash":-799466743,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750715,"text":"Collaborative Perception in Autonomous Driving: Methods, Datasets and Challenges\nCollaborative perception is essential to address occlusion and sensor failure issues in autonomous driving. In recent years, deep learning on collaborative perception has become even thriving, with numerous methods have been proposed. Although some works have reviewed and analyzed the basic architecture and key components in this field, there is still a lack of reviews on systematical collaboration modules in perception networks and large-scale collaborative perception datasets. The primary goal of this work is to address the abovementioned issues and provide a comprehensive review of recent achievements in this field. First, we introduce fundamental technologies and collaboration schemes. Following that, we provide an overview of practical collaborative perception methods and systematically summarize the collaboration modules in networks to improve collaboration efficiency and performance while also ensuring collaboration robustness and safety. Then, we present large-scale public datasets and summarize quantitative results on these benchmarks. Finally, we discuss the remaining challenges and promising future research directions."}
{"link":"http://arxiv.org/abs/2301.06178v1","created":"2023-01-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1348684810,"_task_hash":-34555052,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750725,"text":"Bike Frames: Understanding the Implicit Portrayal of Cyclists in the News\nIncreasing the number of cyclists, whether for general transport or recreation, can provide health improvements and reduce the environmental impact of vehicular transportation. However, the public's perception of cycling may be driven by the ideologies and reporting standards of news agencies. For instance, people may identify cyclists on the road as \"dangerous\" if news agencies overly report cycling accidents, limiting the number of people that cycle for transportation. Moreover, if fewer people cycle, there may be less funding from the government to invest in safe infrastructure. In this paper, we explore the perceived perception of cyclists within news headlines. To accomplish this, we introduce a new dataset, \"Bike Frames\", that can help provide insight into how headlines portray cyclists and help detect accident-related headlines. Next, we introduce a multi-task (MT) regularization approach that increases the detection accuracy of accident-related posts, demonstrating improvements over traditional MT frameworks. Finally, we compare and contrast the perceptions of cyclists with motorcyclist-related headlines to ground the findings with another related activity for both male- and female-related posts. Our findings show that general news websites are more likely to report accidents about cyclists than other events. Moreover, cyclist-specific websites are more likely to report about accidents than motorcycling-specific websites, even though there is more potential danger for motorcyclists. Finally, we show substantial differences in the reporting about male vs. female-related persons, e.g., more male-related cyclists headlines are related to accidents, but more female-related motorcycling headlines about accidents. WARNING: This paper contains descriptions of accidents and death."}
{"link":"http://arxiv.org/abs/2301.06160v1","created":"2023-01-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":2062868030,"_task_hash":261321350,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750752,"text":"TextileNet: A Material Taxonomy-based Fashion Textile Dataset\nThe rise of Machine Learning (ML) is gradually digitalizing and reshaping the fashion industry. Recent years have witnessed a number of fashion AI applications, for example, virtual try-ons. Textile material identification and categorization play a crucial role in the fashion textile sector, including fashion design, retails, and recycling. At the same time, Net Zero is a global goal and the fashion industry is undergoing a significant change so that textile materials can be reused, repaired and recycled in a sustainable manner. There is still a challenge in identifying textile materials automatically for garments, as we lack a low-cost and effective technique for identifying them. In light of this, we build the first fashion textile dataset, TextileNet, based on textile material taxonomies - a fibre taxonomy and a fabric taxonomy generated in collaboration with material scientists. TextileNet can be used to train and evaluate the state-of-the-art Deep Learning models for textile materials. We hope to standardize textile related datasets through the use of taxonomies. TextileNet contains 33 fibres labels and 27 fabrics labels, and has in total 760,949 images. We use standard Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) to establish baselines for this dataset. Future applications for this dataset range from textile classification to optimization of the textile supply chain and interactive design for consumers. We envision that this can contribute to the development of a new AI-based fashion platform."}
{"link":"http://arxiv.org/abs/2301.06103v1","created":"2023-01-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":64030366,"_task_hash":1047972524,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750763,"text":"Learning Sparse Temporal Video Mapping for Action Quality Assessment in Floor Gymnastics\nAthlete performance measurement in sports videos requires modeling long sequences since the entire spatio-temporal progression contributes dominantly to the performance. It is crucial to comprehend local discriminative spatial dependencies and global semantics for accurate evaluation. However, existing benchmark datasets mainly incorporate sports where the performance lasts only a few seconds. Consequently, state-ofthe-art sports quality assessment methods specifically focus on spatial structure. Although they achieve high performance in short-term sports, they are unable to model prolonged video sequences and fail to achieve similar performance in long-term sports. To facilitate such analysis, we introduce a new dataset, coined AGF-Olympics, that incorporates artistic gymnastic floor routines. AFG-Olympics provides highly challenging scenarios with extensive background, viewpoint, and scale variations over an extended sample duration of up to 2 minutes. In addition, we propose a discriminative attention module to map the dense feature space into a sparse representation by disentangling complex associations. Extensive experiments indicate that our proposed module provides an effective way to embed long-range spatial and temporal correlation semantics."}
{"link":"http://arxiv.org/abs/2301.05948v1","created":"2023-01-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1237548805,"_task_hash":-1437008245,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750774,"text":"$\\texttt{tasksource}$: Structured Dataset Preprocessing Annotations for Frictionless Extreme Multi-Task Learning and Evaluation\nThe HuggingFace Datasets Hub hosts thousands of datasets. This provides exciting opportunities for language model training and evaluation. However, the datasets for a given type of task are stored with different schemas, and harmonization is harder than it seems (https://xkcd.com/927/). Multi-task training or evaluation requires manual work to fit data into task templates. Various initiatives independently address this problem by releasing the harmonized datasets or harmonization codes to preprocess datasets to the same format. We identify patterns across previous preprocessings, e.g. mapping of column names, and extraction of a specific sub-field from structured data in a column, and propose a structured annotation framework that makes our annotations fully exposed and not buried in unstructured code. We release a dataset annotation framework and dataset annotations for more than 400 English tasks (https://github.com/sileod/tasksource). These annotations provide metadata, like the name of the columns that should be used as input or labels for all datasets, and can save time for future dataset preprocessings, even if they do not use our framework. We fine-tune a multi-task text encoder on all tasksource tasks, outperforming every publicly available text encoder of comparable size on an external evaluation https://hf.co/sileod/deberta-v3-base-tasksource-nli."}
{"link":"http://arxiv.org/abs/2301.05892v2","created":"2023-01-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":905114540,"_task_hash":1975376809,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750777,"text":"Object Detection performance variation on compressed satellite image datasets with iquaflow\nA lot of work has been done to reach the best possible performance of predictive models on images. There are fewer studies about the resilience of these models when they are trained on image datasets that suffer modifications altering their original quality. Yet this is a common problem that is often encountered in the industry. A good example of that is with earth observation satellites that are capturing many images. The energy and time of connection to the earth of an orbiting satellite are limited and must be carefully used. An approach to mitigate that is to compress the images on board before downloading. The compression can be regulated depending on the intended usage of the image and the requirements of this application. We present a new software tool with the name iquaflow that is designed to study image quality and model performance variation given an alteration of the image dataset. Furthermore, we do a showcase study about oriented object detection models adoption on a public image dataset DOTA Xia_2018_CVPR given different compression levels. The optimal compression point is found and the usefulness of iquaflow becomes evident."}
{"link":"http://arxiv.org/abs/2301.05880v1","created":"2023-01-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1400260367,"_task_hash":-1426450361,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750786,"text":"TikTalk: A Multi-Modal Dialogue Dataset for Real-World Chitchat\nWe present a novel multi-modal chitchat dialogue dataset-TikTalk aimed at facilitating the research of intelligent chatbots. It consists of the videos and corresponding dialogues users generate on video social applications. In contrast to existing multi-modal dialogue datasets, we construct dialogue corpora based on video comment-reply pairs, which is more similar to chitchat in real-world dialogue scenarios. Our dialogue context includes three modalities: text, vision, and audio. Compared with previous image-based dialogue datasets, the richer sources of context in TikTalk lead to a greater diversity of conversations. TikTalk contains over 38K videos and 367K dialogues. Data analysis shows that responses in TikTalk are in correlation with various contexts and external knowledge. It poses a great challenge for the deep understanding of multi-modal information and the generation of responses. We evaluate several baselines on three types of automatic metrics and conduct case studies. Experimental results demonstrate that there is still a large room for future improvement on TikTalk. Our dataset is available at \\url{https://github.com/RUC-AIMind/TikTalk}."}
{"link":"http://arxiv.org/abs/2301.05776v1","created":"2023-01-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1126949278,"_task_hash":-298644891,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750791,"text":"Young Labeled Faces in the Wild (YLFW): A Dataset for Children Faces Recognition\nFace recognition has achieved outstanding performance in the last decade with the development of deep learning techniques.   Nowadays, the challenges in face recognition are related to specific scenarios, for instance, the performance under diverse image quality, the robustness for aging and edge cases of person age (children and elders), distinguishing of related identities.   In this set of problems, recognizing children's faces is one of the most sensitive and important. One of the reasons for this problem is the existing bias towards adults in existing face datasets.   In this work, we present a benchmark dataset for children's face recognition, which is compiled similarly to the famous face recognition benchmarks LFW, CALFW, CPLFW, XQLFW and AgeDB.   We also present a development dataset (separated into train and test parts) for adapting face recognition models for face images of children.   The proposed data is balanced for African, Asian, Caucasian, and Indian races. To the best of our knowledge, this is the first standartized data tool set for benchmarking and the largest collection for development for children's face recognition. Several face recognition experiments are presented to demonstrate the performance of the proposed data tool set."}
{"link":"http://arxiv.org/abs/2301.05768v1","created":"2023-01-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-665777298,"_task_hash":29335460,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750795,"text":"RxRx1: A Dataset for Evaluating Experimental Batch Correction Methods\nHigh-throughput screening techniques are commonly used to obtain large quantities of data in many fields of biology. It is well known that artifacts arising from variability in the technical execution of different experimental batches within such screens confound these observations and can lead to invalid biological conclusions. It is therefore necessary to account for these batch effects when analyzing outcomes. In this paper we describe RxRx1, a biological dataset designed specifically for the systematic study of batch effect correction methods. The dataset consists of 125,510 high-resolution fluorescence microscopy images of human cells under 1,138 genetic perturbations in 51 experimental batches across 4 cell types. Visual inspection of the images alone clearly demonstrates significant batch effects. We propose a classification task designed to evaluate the effectiveness of experimental batch correction methods on these images and examine the performance of a number of correction methods on this task. Our goal in releasing RxRx1 is to encourage the development of effective experimental batch correction methods that generalize well to unseen experimental batches. The dataset can be downloaded at https://rxrx.ai."}
{"link":"http://arxiv.org/abs/2301.05603v1","created":"2023-01-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-493261421,"_task_hash":1845741718,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750799,"text":"A Comprehensive Survey to Dataset Distillation\nDeep learning technology has unprecedentedly developed in the last decade and has become the primary choice in many application domains. This progress is mainly attributed to a systematic collaboration that rapidly growing computing resources encourage advanced algorithms to deal with massive data. However, it gradually becomes challenging to cope with the unlimited growth of data with limited computing power. To this end, diverse approaches are proposed to improve data processing efficiency. Dataset distillation, one of the dataset reduction methods, tackles the problem via synthesising a small typical dataset from giant data and has attracted a lot of attention from the deep learning community. Existing dataset distillation methods can be taxonomised into meta-learning and data match framework according to whether explicitly mimic target data. Albeit dataset distillation has shown a surprising performance in compressing datasets, it still possesses several limitations such as distilling high-resolution data. This paper provides a holistic understanding of dataset distillation from multiple aspects, including distillation frameworks and algorithms, disentangled dataset distillation, performance comparison, and applications. Finally, we discuss challenges and promising directions to further promote future studies about dataset distillation."}
{"link":"http://arxiv.org/abs/2301.05456v1","created":"2023-01-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1591723377,"_task_hash":-405294210,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750819,"text":"Data Quality for Software Vulnerability Datasets\nThe use of learning-based techniques to achieve automated software vulnerability detection has been of longstanding interest within the software security domain. These data-driven solutions are enabled by large software vulnerability datasets used for training and benchmarking. However, we observe that the quality of the data powering these solutions is currently ill-considered, hindering the reliability and value of produced outcomes. Whilst awareness of software vulnerability data preparation challenges is growing, there has been little investigation into the potential negative impacts of software vulnerability data quality. For instance, we lack confirmation that vulnerability labels are correct or consistent. Our study seeks to address such shortcomings by inspecting five inherent data quality attributes for four state-of-the-art software vulnerability datasets and the subsequent impacts that issues can have on software vulnerability prediction models. Surprisingly, we found that all the analyzed datasets exhibit some data quality problems. In particular, we found 20-71% of vulnerability labels to be inaccurate in real-world datasets, and 17-99% of data points were duplicated. We observed that these issues could cause significant impacts on downstream models, either preventing effective model training or inflating benchmark performance. We advocate for the need to overcome such challenges. Our findings will enable better consideration and assessment of software vulnerability data quality in the future."}
{"link":"http://arxiv.org/abs/2301.05417v1","created":"2023-01-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-656145718,"_task_hash":-586971319,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750834,"text":"Analysis of LGM Model for sEMG Signals related to Weight Training\nStatistical models of Surface electromyography (sEMG) signals have several applications such as better understanding of sEMG signal generation, improved pattern recognition based control of wearable exoskeletons and prostheses, improving training strategies in sports activities, and EMG simulation studies. Most of the existing studies analysed the statistical model of sEMG signals acquired under isometric contractions. However, there is no study that addresses the statistical model under isotonic contractions. In this work, a new dataset, electromyography analysis of human activities - database 2 (EMAHA-DB2) is developed. It consists of two experiments based on both isometric and isotonic activities during weight training. Previously, a novel Laplacian-Gaussian Mixture (LGM) model was demonstrated for a few benchmark datasets consisting of basic movements and gestures. In this work, the model suitability analysis is extended to the EMAHA-DB2 dataset. Further, the LGM model is compared with three existing statistical models including the recent scale-mixture model. According to qualitative and quantitative analyses, the LGM model has a better fit to the empirical pdf of the recorded sEMG signals compared with the scale mixture model and the other standard models. The variance and mixing weight of the Laplacian component of the signal are analyzed with respect to the type of muscle, type of muscle contraction, dumb-bell weight and training experience of the subjects. The sEMG variance (the Laplacian component) increases with respect to the weights, is greater for isotonic activity especially for the biceps. For isotonic activity, the signal variance increases with training experience. Importantly, the ratio of the variances from the two muscle sites is observed to be nearly independent of the lifted weight and consistently increases with the training experience."}
{"link":"http://arxiv.org/abs/2301.05119v1","created":"2023-01-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1024997981,"_task_hash":-420132748,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750841,"text":"ITA-ELECTION-2022: A multi-platform dataset of social media conversations around the 2022 Italian general election\nOnline social media play a major role in shaping public discourse and opinion, especially during political events. We present the first public multi-platform dataset of Italian-language political conversations, focused on the 2022 Italian general election taking place on September 25th. Leveraging public APIs and a keyword-based search, we collected millions of posts published by users, pages and groups on Facebook, Instagram and Twitter, along with metadata of TikTok and YouTube videos shared on these platforms, over a period of four months. We augmented the dataset with a collection of political ads sponsored on Meta platforms, and a list of social media handles associated with political representatives. Our data resource will allow researchers and academics to further our understanding of the role of social media in the democratic process."}
{"link":"http://arxiv.org/abs/2301.04962v1","created":"2023-01-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-160954192,"_task_hash":-686941638,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750843,"text":"A Dataset of Kurdish (Sorani) Named Entities -- An Amendment to Kurdish-BLARK Named Entities\nNamed Entity Recognition (NER) is one of the essential applications of Natural Language Processing (NLP). It is also an instrument that plays a significant role in many other NLP applications, such as Machine Translation (MT), Information Retrieval (IR), and Part of Speech Tagging (POST). Kurdish is an under-resourced language from the NLP perspective. Particularly, in all the categories, the lack of NER resources hinders other aspects of Kurdish processing. In this work, we present a data set that covers several categories of NEs in Kurdish (Sorani). The dataset is a significant amendment to a previously developed dataset in the Kurdish BLARK (Basic Language Resource Kit). It covers 11 categories and 33261 entries in total. The dataset is publicly available for non-commercial use under CC BY-NC-SA 4.0 license at https://kurdishblark.github.io/."}
{"link":"http://arxiv.org/abs/2301.04883v1","created":"2023-01-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-335322878,"_task_hash":1269444937,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674750847,"text":"SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images\nVisual question answering on document images that contain textual, visual, and layout information, called document VQA, has received much attention recently. Although many datasets have been proposed for developing document VQA systems, most of the existing datasets focus on understanding the content relationships within a single image and not across multiple images. In this study, we propose a new multi-image document VQA dataset, SlideVQA, containing 2.6k+ slide decks composed of 52k+ slide images and 14.5k questions about a slide deck. SlideVQA requires complex reasoning, including single-hop, multi-hop, and numerical reasoning, and also provides annotated arithmetic expressions of numerical answers for enhancing the ability of numerical reasoning. Moreover, we developed a new end-to-end document VQA model that treats evidence selection and question answering in a unified sequence-to-sequence format. Experiments on SlideVQA show that our model outperformed existing state-of-the-art QA models, but that it still has a large gap behind human performance. We believe that our dataset will facilitate research on document VQA."}
{"link":"http://arxiv.org/abs/2301.04802v1","created":"2023-01-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1072618955,"_task_hash":576980450,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750853,"text":"Diffusion-based Data Augmentation for Skin Disease Classification: Impact Across Original Medical Datasets to Fully Synthetic Images\nDespite continued advancement in recent years, deep neural networks still rely on large amounts of training data to avoid overfitting. However, labeled training data for real-world applications such as healthcare is limited and difficult to access given longstanding privacy, and strict data sharing policies. By manipulating image datasets in the pixel or feature space, existing data augmentation techniques represent one of the effective ways to improve the quantity and diversity of training data. Here, we look to advance augmentation techniques by building upon the emerging success of text-to-image diffusion probabilistic models in augmenting the training samples of our macroscopic skin disease dataset. We do so by enabling fine-grained control of the image generation process via input text prompts. We demonstrate that this generative data augmentation approach successfully maintains a similar classification accuracy of the visual classifier even when trained on a fully synthetic skin disease dataset. Similar to recent applications of generative models, our study suggests that diffusion models are indeed effective in generating high-quality skin images that do not sacrifice the classifier performance, and can improve the augmentation of training datasets after curation."}
{"link":"http://arxiv.org/abs/2301.05551v1","created":"2023-01-11","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1383485807,"_task_hash":909324612,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674750855,"text":"Dynamic Data Assimilation of MPAS-O and the Global Drifter Dataset\nIn this study, we propose a new method for combining in situ buoy measurements with Earth system models (ESMs) to improve the accuracy of temperature predictions in the ocean. The technique utilizes the dynamics and modes identified in ESMs to improve the accuracy of buoy measurements while still preserving features such as seasonality. Using this technique, errors in localized temperature predictions made by the MPAS-O model can be corrected. We demonstrate that our approach improves accuracy compared to other interpolation and data assimilation methods. We apply our method to assimilate the Model for Prediction Across Scales Ocean component (MPAS-O) with the Global Drifter Program's in-situ ocean buoy dataset."}
{"link":"http://arxiv.org/abs/2301.04644v1","created":"2023-01-11","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":152760537,"_task_hash":-833096514,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674751415,"text":"Does progress on ImageNet transfer to real-world datasets?\nDoes progress on ImageNet transfer to real-world datasets? We investigate this question by evaluating ImageNet pre-trained models with varying accuracy (57% - 83%) on six practical image classification datasets. In particular, we study datasets collected with the goal of solving real-world tasks (e.g., classifying images from camera traps or satellites), as opposed to web-scraped benchmarks collected for comparing models. On multiple datasets, models with higher ImageNet accuracy do not consistently yield performance improvements. For certain tasks, interventions such as data augmentation improve performance even when architectures do not. We hope that future benchmarks will include more diverse datasets to encourage a more comprehensive approach to improving learning algorithms."}
{"link":"http://arxiv.org/abs/2301.05028v1","created":"2023-01-11","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":313220792,"_task_hash":-1396161335,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674751420,"text":"MotorFactory: A Blender Add-on for Large Dataset Generation of Small Electric Motors\nTo enable automatic disassembly of different product types with uncertain conditions and degrees of wear in remanufacturing, agile production systems that can adapt dynamically to changing requirements are needed. Machine learning algorithms can be employed due to their generalization capabilities of learning from various types and variants of products. However, in reality, datasets with a diversity of samples that can be used to train models are difficult to obtain in the initial period. This may cause bad performances when the system tries to adapt to new unseen input data in the future. In order to generate large datasets for different learning purposes, in our project, we present a Blender add-on named MotorFactory to generate customized mesh models of various motor instances. MotorFactory allows to create mesh models which, complemented with additional add-ons, can be further used to create synthetic RGB images, depth images, normal images, segmentation ground truth masks, and 3D point cloud datasets with point-wise semantic labels. The created synthetic datasets may be used for various tasks including motor type classification, object detection for decentralized material transfer tasks, part segmentation for disassembly and handling tasks, or even reinforcement learning-based robotics control or view-planning."}
{"link":"http://arxiv.org/abs/2301.04423v1","created":"2023-01-11","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1237186885,"_task_hash":1319335802,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751446,"text":"Multi-Scanner Canine Cutaneous Squamous Cell Carcinoma Histopathology Dataset\nIn histopathology, scanner-induced domain shifts are known to impede the performance of trained neural networks when tested on unseen data. Multi-domain pre-training or dedicated domain-generalization techniques can help to develop domain-agnostic algorithms. For this, multi-scanner datasets with a high variety of slide scanning systems are highly desirable. We present a publicly available multi-scanner dataset of canine cutaneous squamous cell carcinoma histopathology images, composed of 44 samples digitized with five slide scanners. This dataset provides local correspondences between images and thereby isolates the scanner-induced domain shift from other inherent, e.g. morphology-induced domain shifts. To highlight scanner differences, we present a detailed evaluation of color distributions, sharpness, and contrast of the individual scanner subsets. Additionally, to quantify the inherent scanner-induced domain shift, we train a tumor segmentation network on each scanner subset and evaluate the performance both in- and cross-domain. We achieve a class-averaged in-domain intersection over union coefficient of up to 0.86 and observe a cross-domain performance decrease of up to 0.38, which confirms the inherent domain shift of the presented dataset and its negative impact on the performance of deep neural networks."}
{"link":"http://arxiv.org/abs/2301.03213v2","created":"2023-01-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1517487475,"_task_hash":-374994786,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751454,"text":"EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset\nVisual object tracking is a key component to many egocentric vision problems. However, the full spectrum of challenges of egocentric tracking faced by an embodied AI is underrepresented in many existing datasets; these tend to focus on relatively short, third-person videos. Egocentric video has several distinguishing characteristics from those commonly found in past datasets: frequent large camera motions and hand interactions with objects commonly lead to occlusions or objects exiting the frame, and object appearance can change rapidly due to widely different points of view, scale, or object states. Embodied tracking is also naturally long-term, and being able to consistently (re-)associate objects to their appearances and disappearances over as long as a lifetime is critical. Previous datasets under-emphasize this re-detection problem, and their \"framed\" nature has led to adoption of various spatiotemporal priors that we find do not necessarily generalize to egocentric video. We thus introduce EgoTracks, a new dataset for long-term egocentric visual object tracking. Sourced from the Ego4D dataset, this new dataset presents a significant challenge to recent state-of-the-art single-object tracking models, which we find score poorly on traditional tracking metrics for our new dataset, compared to popular benchmarks. We further show improvements that can be made to a STARK tracker to significantly increase its performance on egocentric data, resulting in a baseline model we call EgoSTARK. We publicly release our annotations and benchmark, hoping our dataset leads to further advancements in tracking."}
{"link":"http://arxiv.org/abs/2301.02560v1","created":"2023-01-05","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-296198292,"_task_hash":-1469779407,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751459,"text":"Beyond web-scraping: Crowd-sourcing a geographically diverse image dataset\nCurrent dataset collection methods typically scrape large amounts of data from the web. While this technique is extremely scalable, data collected in this way tends to reinforce stereotypical biases, can contain personally identifiable information, and typically originates from Europe and North America. In this work, we rethink the dataset collection paradigm and introduce GeoDE, a geographically diverse dataset with 61,940 images from 40 classes and 6 world regions, and no personally identifiable information, collected through crowd-sourcing. We analyse GeoDE to understand differences in images collected in this manner compared to web-scraping. Despite the smaller size of this dataset, we demonstrate its use as both an evaluation and training dataset, highlight shortcomings in current models, as well as show improved performances when even small amounts of GeoDE (1000 - 2000 images per region) are added to a training dataset. We release the full dataset and code at https://geodiverse-data-collection.cs.princeton.edu/"}
{"link":"http://arxiv.org/abs/2301.02200v1","created":"2023-01-05","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-2120789737,"_task_hash":-1067743168,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674751464,"text":"Impact, Attention, Influence: Early Assessment of Autonomous Driving Datasets\nAutonomous Driving (AD), the area of robotics with the greatest potential impact on society, has gained a lot of momentum in the last decade. As a result of this, the number of datasets in AD has increased rapidly. Creators and users of datasets can benefit from a better understanding of developments in the field. While scientometric analysis has been conducted in other fields, it rarely revolves around datasets. Thus, the impact, attention, and influence of datasets on autonomous driving remains a rarely investigated field. In this work, we provide a scientometric analysis for over 200 datasets in AD. We perform a rigorous evaluation of relations between available metadata and citation counts based on linear regression. Subsequently, we propose an Influence Score to assess a dataset already early on without the need for a track-record of citations, which is only available with a certain delay."}
{"link":"http://arxiv.org/abs/2301.02135v1","created":"2023-01-05","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":371590703,"_task_hash":-467016942,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751468,"text":"A Database of Modular Forms on Noncongruence Subgroups\nWe present a database of several hundred modular forms up to and including weight six on noncongruence subgroups of index $\\leq 17$. In addition, our database contains expressions for the Belyi map for genus zero subgroups and equations of the corresponding elliptic curves for genus one subgroups and numerical approximations of noncongruence Eisenstein series to 1500 digits precision."}
{"link":"http://arxiv.org/abs/2301.01820v2","created":"2023-01-04","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":466582103,"_task_hash":478297256,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751473,"text":"InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval\nRecently, InPars introduced a method to efficiently use large language models (LLMs) in information retrieval tasks: via few-shot examples, an LLM is induced to generate relevant queries for documents. These synthetic query-document pairs can then be used to train a retriever. However, InPars and, more recently, Promptagator, rely on proprietary LLMs such as GPT-3 and FLAN to generate such datasets. In this work we introduce InPars-v2, a dataset generator that uses open-source LLMs and existing powerful rerankers to select synthetic query-document pairs for training. A simple BM25 retrieval pipeline followed by a monoT5 reranker finetuned on InPars-v2 data achieves new state-of-the-art results on the BEIR benchmark. To allow researchers to further improve our method, we open source the code, synthetic data, and finetuned models: https://github.com/zetaalphavector/inPars/tree/master/tpu"}
{"link":"http://arxiv.org/abs/2301.00985v1","created":"2023-01-03","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1359439919,"_task_hash":-1582564905,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751483,"text":"More is Better: A Database for Spontaneous Micro-Expression with High Frame Rates\nAs one of the most important psychic stress reactions, micro-expressions (MEs), are spontaneous and transient facial expressions that can reveal the genuine emotions of human beings. Thus, recognizing MEs (MER) automatically is becoming increasingly crucial in the field of affective computing, and provides essential technical support in lie detection, psychological analysis and other areas. However, the lack of abundant ME data seriously restricts the development of cutting-edge data-driven MER models. Despite the recent efforts of several spontaneous ME datasets to alleviate this problem, it is still a tiny amount of work. To solve the problem of ME data hunger, we construct a dynamic spontaneous ME dataset with the largest current ME data scale, called DFME (Dynamic Facial Micro-expressions), which includes 7,526 well-labeled ME videos induced by 671 participants and annotated by more than 20 annotators throughout three years. Afterwards, we adopt four classical spatiotemporal feature learning models on DFME to perform MER experiments to objectively verify the validity of DFME dataset. In addition, we explore different solutions to the class imbalance and key-frame sequence sampling problems in dynamic MER respectively on DFME, so as to provide a valuable reference for future research. The comprehensive experimental results show that our DFME dataset can facilitate the research of automatic MER, and provide a new benchmark for MER. DFME will be published via https://mea-lab-421.github.io."}
{"link":"http://arxiv.org/abs/2301.00876v2","created":"2023-01-02","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":597999258,"_task_hash":-1817494142,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751486,"text":"MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement Understanding\nReading comprehension of legal text can be a particularly challenging task due to the length and complexity of legal clauses and a shortage of expert-annotated datasets. To address this challenge, we introduce the Merger Agreement Understanding Dataset (MAUD), an expert-annotated reading comprehension dataset based on the American Bar Association's 2021 Public Target Deal Points Study, with over 39,000 examples and over 47,000 total annotations. Our fine-tuned Transformer baselines show promising results, with models performing well above random on most questions. However, on a large subset of questions, there is still room for significant improvement. As the only expert-annotated merger agreement dataset, MAUD is valuable as a benchmark for both the legal profession and the NLP community."}
{"link":"http://arxiv.org/abs/2301.00689v2","created":"2023-01-02","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":924041900,"_task_hash":1964443103,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674751492,"text":"Comparative analysis of observations of the selected exoplanet transits obtained at the Kyiv Comet station with the database of the orbital telescopes TESS and Kepler\nWe present a comparative analysis of observations of the selected exoplanet transits obtained at the Kyiv Comet station with the database of the TESS (Transiting Exoplanet Survey Satellite) and Kepler space telescopes. The light curves obtained by the TESS and Kepler orbital telescopes were processed using a program based on the Python package Lightkurve 2.3v which is freely available in the MUST archive (Barbara A. Mikulski Archive for Space Telescopes). The ground-based observations were carried out with the 70-cm telescope AZT-8 (Lisnyky). Photometric processing of the ground-based observation was performed by using the Muniwin program. The light curves and parameters of the observed transits as well as the exoplanet orbital parameters obtained from ground-based observations were published in the ETD (Exoplanet Transit Database). Determined transit parameters were compared with the results of the TESS command, which are stored in the MUST archive. Here we present a comparison of the parameters of transit phenomena (period, depth, transit duration) and some orbital parameters were obtained from two independent sets of observations, terrestrial and orbital, performed in different epochs."}
{"link":"http://arxiv.org/abs/2301.00508v1","created":"2023-01-02","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1229873299,"_task_hash":814455909,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751495,"text":"EmoGator: A New Open Source Vocal Burst Dataset with Baseline Machine Learning Classification Methodologies\nVocal Bursts -- short, non-speech vocalizations that convey emotions, such as laughter, cries, sighs, moans, and groans -- are an often-overlooked aspect of speech emotion recognition, but an important aspect of human vocal communication. One barrier to study of these interesting vocalizations is a lack of large datasets. I am pleased to introduce the EmoGator dataset, which consists of 32,040 samples from 365 speakers, 16.91 hours of audio; each sample classified into one of 30 distinct emotion categories by the speaker. Several different approaches to construct classifiers to identify emotion categories will be discussed, and directions for future research will be suggested. Data set is available for download from https://github.com/fredbuhl/EmoGator."}
{"link":"http://arxiv.org/abs/2301.00395v1","created":"2023-01-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1020940319,"_task_hash":-1770045162,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751502,"text":"CORGI-PM: A Chinese Corpus For Gender Bias Probing and Mitigation\nAs natural language processing (NLP) for gender bias becomes a significant interdisciplinary topic, the prevalent data-driven techniques such as large-scale language models suffer from data inadequacy and biased corpus, especially for languages with insufficient resources such as Chinese. To this end, we propose a Chinese cOrpus foR Gender bIas Probing and Mitigation CORGI-PM, which contains 32.9k sentences with high-quality labels derived by following an annotation scheme specifically developed for gender bias in the Chinese context. Moreover, we address three challenges for automatic textual gender bias mitigation, which requires the models to detect, classify, and mitigate textual gender bias. We also conduct experiments with state-of-the-art language models to provide baselines. To our best knowledge, CORGI-PM is the first sentence-level Chinese corpus for gender bias probing and mitigation."}
{"link":"http://arxiv.org/abs/2301.00345v1","created":"2023-01-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-674054290,"_task_hash":-236003403,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751508,"text":"MTNeuro: A Benchmark for Evaluating Representations of Brain Structure Across Multiple Levels of Abstraction\nThere are multiple scales of abstraction from which we can describe the same image, depending on whether we are focusing on fine-grained details or a more global attribute of the image. In brain mapping, learning to automatically parse images to build representations of both small-scale features (e.g., the presence of cells or blood vessels) and global properties of an image (e.g., which brain region the image comes from) is a crucial and open challenge. However, most existing datasets and benchmarks for neuroanatomy consider only a single downstream task at a time. To bridge this gap, we introduce a new dataset, annotations, and multiple downstream tasks that provide diverse ways to readout information about brain structure and architecture from the same image. Our multi-task neuroimaging benchmark (MTNeuro) is built on volumetric, micrometer-resolution X-ray microtomography images spanning a large thalamocortical section of mouse brain, encompassing multiple cortical and subcortical regions. We generated a number of different prediction challenges and evaluated several supervised and self-supervised models for brain-region prediction and pixel-level semantic segmentation of microstructures. Our experiments not only highlight the rich heterogeneity of this dataset, but also provide insights into how self-supervised approaches can be used to learn representations that capture multiple attributes of a single image and perform well on a variety of downstream tasks. Datasets, code, and pre-trained baseline models are provided at: https://mtneuro.github.io/ ."}
{"link":"http://arxiv.org/abs/2212.14574v1","created":"2022-12-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-656382340,"_task_hash":186887152,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751513,"text":"X-MAS: Extremely Large-Scale Multi-Modal Sensor Dataset for Outdoor Surveillance in Real Environments\nIn robotics and computer vision communities, extensive studies have been widely conducted regarding surveillance tasks, including human detection, tracking, and motion recognition with a camera. Additionally, deep learning algorithms are widely utilized in the aforementioned tasks as in other computer vision tasks. Existing public datasets are insufficient to develop learning-based methods that handle various surveillance for outdoor and extreme situations such as harsh weather and low illuminance conditions. Therefore, we introduce a new large-scale outdoor surveillance dataset named eXtremely large-scale Multi-modAl Sensor dataset (X-MAS) containing more than 500,000 image pairs and the first-person view data annotated by well-trained annotators. Moreover, a single pair contains multi-modal data (e.g. an IR image, an RGB image, a thermal image, a depth image, and a LiDAR scan). This is the first large-scale first-person view outdoor multi-modal dataset focusing on surveillance tasks to the best of our knowledge. We present an overview of the proposed dataset with statistics and present methods of exploiting our dataset with deep learning-based algorithms. The latest information on the dataset and our study are available at https://github.com/lge-robot-navi, and the dataset will be available for download through a server."}
{"link":"http://arxiv.org/abs/2212.14092v1","created":"2022-12-28","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-236100459,"_task_hash":483031451,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751515,"text":"Assisted Living in the United States: an Open Dataset\nAn assisted living facility (ALF) is a place where someone can live, have access to social supports such as transportation, and receive assistance with the activities of daily living such as toileting and dressing. Despite the important role of ALFs, they are not required to be certified with Medicare and there is no public national database of these facilities. We present the first public dataset of assisted living facilities in the United States, covering all 50 states and DC with 44,638 facilities and over 1.2 million beds. This dataset can help provide answers to existing public health questions as well as help those in need find a facility. The dataset was validated by replicating the results of a nationwide study of ALFs that uses closed data [4], where the prevalence of ALFs is assessed with respect to county-level socioeconomic variables related to health disparity such as race, disability, and income. To showcase the value of this dataset, we also propose a novel metric to assess access to community-based care. We calculate the average distance an individual in need must travel in order to reach an ALF. The dataset and all relevant code are available at github.com/antonstengel/assisted-living-data."}
{"link":"http://arxiv.org/abs/2212.14746v1","created":"2022-12-27","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-500106791,"_task_hash":1562757498,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751518,"text":"MindBigData 2022 A Large Dataset of Brain Signals\nUnderstanding our brain is one of the most daunting tasks, one we cannot expect to complete without the use of technology. MindBigData aims to provide a comprehensive and updated dataset of brain signals related to a diverse set of human activities so it can inspire the use of machine learning algorithms as a benchmark of 'decoding' performance from raw brain activities into its corresponding (labels) mental (or physical) tasks. Using commercial of the self, EEG devices or custom ones built by us to explore the limits of the technology. We describe the data collection procedures for each of the sub datasets and with every headset used to capture them. Also, we report possible applications in the field of Brain Computer Interfaces or BCI that could impact the life of billions, in almost every sector like healthcare game changing use cases, industry or entertainment to name a few, at the end why not directly using our brains to 'disintermediate' senses, as the final HCI (Human-Computer Interaction) device? simply what we call the journey from Type to Touch to Talk to Think."}
{"link":"http://arxiv.org/abs/2301.04370v1","created":"2023-01-11","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-2057779839,"_task_hash":-1472791422,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674751662,"text":"Order-Preserving Database Encryption with Secret Sharing\nThe order-preserving encryption (OPE) problem was initially formulated by the database community in 2004 soon after the paradigm database-as-a-service (DaaS) was coined in 2002. Over the past two decades, OPE has drawn tremendous research interest from communities of databases, cryptography, and security; we have witnessed significant advances in OPE schemes both theoretically and systematically. All existing OPE schemes assume that the outsourced database is modeled as a single semi-honest adversary who should learn nothing more than the order information of plaintext messages up to a negligible probability. This paper addresses the OPE problem from a new perspective: instead of modeling the outsourced database as a single semi-honest adversary, we assume the outsourced database \\textit{service} compromises a cluster of non-colluding servers, which is a practical assumption as all major cloud vendors support multiple database instances deployed to exclusive sub-networks or even to distinct data centers. This assumption allows us to design a new stateless OPE protocol, namely order-preserving database encryption with secret sharing (ODES), by employing secret-sharing schemes among those presumably non-colluding servers. We will demonstrate that ODES guarantees the latest security level, namely IND-FAOCPA, and outperforms the state-of-the-art scheme by orders of magnitude."}
{"link":"http://arxiv.org/abs/2301.04253v1","created":"2023-01-11","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":904795436,"_task_hash":548546016,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751669,"text":"ClimaBench: A Benchmark Dataset For Climate Change Text Understanding in English\nThe topic of Climate Change (CC) has received limited attention in NLP despite its real world urgency. Activists and policy-makers need NLP tools in order to effectively process the vast and rapidly growing textual data produced on CC. Their utility, however, primarily depends on whether the current state-of-the-art models can generalize across various tasks in the CC domain. In order to address this gap, we introduce Climate Change Benchmark (ClimaBench), a benchmark collection of existing disparate datasets for evaluating model performance across a diverse set of CC NLU tasks systematically. Further, we enhance the benchmark by releasing two large-scale labelled text classification and question-answering datasets curated from publicly available environmental disclosures. Lastly, we provide an analysis of several generic and CC-oriented models answering whether fine-tuning on domain text offers any improvements across these tasks. We hope this work provides a standard assessment tool for research on CC text data."}
{"link":"http://arxiv.org/abs/2301.10174v1","created":"2023-01-10","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1962732728,"_task_hash":-1219797169,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1674751673,"text":"Analysis of Arrhythmia Classification on ECG Dataset\nThe heart is one of the most vital organs in the human body. It supplies blood and nutrients in other parts of the body. Therefore, maintaining a healthy heart is essential. As a heart disorder, arrhythmia is a condition in which the heart's pumping mechanism becomes aberrant. The Electrocardiogram is used to analyze the arrhythmia problem from the ECG signals because of its fewer difficulties and cheapness. The heart peaks shown in the ECG graph are used to detect heart diseases, and the R peak is used to analyze arrhythmia disease. Arrhythmia is grouped into two groups - Tachycardia and Bradycardia for detection. In this paper, we discussed many different techniques such as Deep CNNs, LSTM, SVM, NN classifier, Wavelet, TQWT, etc., that have been used for detecting arrhythmia using various datasets throughout the previous decade. This work shows the analysis of some arrhythmia classification on the ECG dataset. Here, Data preprocessing, feature extraction, classification processes were applied on most research work and achieved better performance for classifying ECG signals to detect arrhythmia. Automatic arrhythmia detection can help cardiologists make the right decisions immediately to save human life. In addition, this research presents various previous research limitations with some challenges in detecting arrhythmia that will help in future research."}
{"link":"http://arxiv.org/abs/2301.04471v1","created":"2023-01-10","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-875219827,"_task_hash":-47154562,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751679,"text":"Dataset of Fluorescence Spectra and Chemical Parameters of Olive Oils\nThis dataset encompasses fluorescence spectra and chemical parameters of 24 olive oil samples from the 2019-2020 harvest provided by the producer Conde de Benalua, Granada, Spain. The oils are characterized by different qualities: 10 extra virgin olive oil (EVOO), 8 virgin olive oil (VOO), and 6 lampante olive oil (LOO) samples. For each sample, the dataset includes fluorescence spectra obtained with two excitation wavelengths, oil quality, and five chemical parameters necessary for the quality assessment of olive oil. The fluorescence spectra were obtained by exciting the samples at 365 nm and 395 nm under identical conditions. The dataset includes the values of the following chemical parameters for each olive oil sample: acidity, peroxide value, K270, K232, ethyl esters, and the quality of the samples (EVOO, VOO, or LOO). The dataset offers a unique possibility for researchers in food technology to develop machine learning models based on fluorescence data for the quality assessment of olive oil due to the availability of both spectroscopic and chemical data. The dataset can be used, for example, to predict one or multiple chemical parameters or to classify samples based on their quality from fluorescence spectra."}
{"link":"http://arxiv.org/abs/2301.03829v1","created":"2023-01-10","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1033247951,"_task_hash":2069133904,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1674751691,"text":"A Dietary Nutrition-aided Healthcare Platform via Effective Food Recognition on a Localized Singaporean Food Dataset\nLocalized food datasets have profound meaning in revealing a country's special cuisines to explore people's dietary behaviors, which will shed light on their health conditions and disease development. In this paper, revolving around the demand for accurate food recognition in Singapore, we develop the FoodSG platform to incubate diverse healthcare-oriented applications as a service in Singapore, taking into account their shared requirements. We release a localized Singaporean food dataset FoodSG-233 with a systematic cleaning and curation pipeline for promoting future data management research in food computing. To overcome the hurdle in recognition performance brought by Singaporean multifarious food dishes, we propose to integrate supervised contrastive learning into our food recognition model FoodSG-SCL for the intrinsic capability to mine hard positive/negative samples and therefore boost the accuracy. Through a comprehensive evaluation, we share the insightful experience with practitioners in the data management community regarding food-related data-intensive healthcare applications.   The FoodSG-233 dataset can be accessed via: https://foodlg.comp.nus.edu.sg/."}
{"link":"http://arxiv.org/abs/2303.04805v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":409228535,"_task_hash":-545880798,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678458290,"text":"X-Avatar: Expressive Human Avatars\nWe present X-Avatar, a novel avatar model that captures the full expressiveness of digital humans to bring about life-like experiences in telepresence, AR/VR and beyond. Our method models bodies, hands, facial expressions and appearance in a holistic fashion and can be learned from either full 3D scans or RGB-D data. To achieve this, we propose a part-aware learned forward skinning module that can be driven by the parameter space of SMPL-X, allowing for expressive animation of X-Avatars. To efficiently learn the neural shape and deformation fields, we propose novel part-aware sampling and initialization strategies. This leads to higher fidelity results, especially for smaller body parts while maintaining efficient training despite increased number of articulated bones. To capture the appearance of the avatar with high-frequency details, we extend the geometry and deformation fields with a texture network that is conditioned on pose, facial expression, geometry and the normals of the deformed surface. We show experimentally that our method outperforms strong baselines in both data domains both quantitatively and qualitatively on the animation task. To facilitate future research on expressive avatars we contribute a new dataset, called X-Humans, containing 233 sequences of high-quality textured scans from 20 participants, totalling 35,500 data frames."}
{"link":"http://arxiv.org/abs/2303.04738v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-145970368,"_task_hash":-2037542484,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678458297,"text":"Defectors: A Large, Diverse Python Dataset for Defect Prediction\nDefect prediction has been a popular research topic where machine learning (ML) and deep learning (DL) have found numerous applications. However, these ML/DL-based defect prediction models are often limited by the quality and size of their datasets. In this paper, we present Defectors, a large dataset for just-in-time and line-level defect prediction. Defectors consists of $\\approx$ 213K source code files ($\\approx$ 93K defective and $\\approx$ 120K defect-free) that span across 24 popular Python projects. These projects come from 18 different domains, including machine learning, automation, and internet-of-things. Such a scale and diversity make Defectors a suitable dataset for training ML/DL models, especially transformer models that require large and diverse datasets. We also foresee several application areas of our dataset including defect prediction and defect explanation.   Dataset link: https://doi.org/10.5281/zenodo.7708984"}
{"link":"http://arxiv.org/abs/2303.04720v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":387007879,"_task_hash":2054043591,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678458367,"text":"Medical Waste Sorting: a computer vision approach for assisted primary sorting\nMedical waste, i.e. waste produced during medical activities in hospitals, clinics and laboratories, represents hazardous waste whose management involves special care and high costs. However, this kind of waste contains a significant fraction of highly valued materials that can enter a circular economy process. To this end, in this paper, we propose a computer vision approach for assisting in the primary sorting of medical waste. The feasibility of our approach is demonstrated on a representative dataset we collected and made available to the community, with which we have trained a model that achieves 100\\% accuracy, and a new dataset on which the trained model exhibits good generalization."}
{"link":"http://arxiv.org/abs/2303.04707v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":358158813,"_task_hash":-1838943568,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678458373,"text":"DiM: Distilling Dataset into Generative Model\nDataset distillation reduces the network training cost by synthesizing small and informative datasets from large-scale ones. Despite the success of the recent dataset distillation algorithms, three drawbacks still limit their wider application: i). the synthetic images perform poorly on large architectures; ii). they need to be re-optimized when the distillation ratio changes; iii). the limited diversity restricts the performance when the distillation ratio is large. In this paper, we propose a novel distillation scheme to \\textbf{D}istill information of large train sets \\textbf{i}nto generative \\textbf{M}odels, named DiM. Specifically, DiM learns to use a generative model to store the information of the target dataset. During the distillation phase, we minimize the differences in logits predicted by a models pool between real and generated images. At the deployment stage, the generative model synthesizes various training samples from random noises on the fly. Due to the simple yet effective designs, the trained DiM can be directly applied to different distillation ratios and large architectures without extra cost. We validate the proposed DiM across 4 datasets and achieve state-of-the-art results on all of them. To the best of our knowledge, we are the first to achieve higher accuracy on complex architectures than simple ones, such as 75.1\\% with ResNet-18 and 72.6\\% with ConvNet-3 on ten images per class of CIFAR-10. Besides, DiM outperforms previous methods with 10\\% $\\sim$ 22\\% when images per class are 1 and 10 on the SVHN dataset."}
{"link":"http://arxiv.org/abs/2303.04486v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1378512431,"_task_hash":4713256,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678458380,"text":"Better Together: Using Multi-task Learning to Improve Feature Selection within Structural Datasets\nThere have been recent efforts to move to population-based structural health monitoring (PBSHM) systems. One area of PBSHM which has been recognised for potential development is the use of multi-task learning (MTL); algorithms which differ from traditional independent learning algorithms. Presented here is the use of the MTL, ''Joint Feature Selection with LASSO'', to provide automatic feature selection for a structural dataset. The classification task is to differentiate between the port and starboard side of a tailplane, for samples from two aircraft of the same model. The independent learner produced perfect F1 scores but had poor engineering insight; whereas the MTL results were interpretable, highlighting structural differences as opposed to differences in experimental set-up."}
{"link":"http://arxiv.org/abs/2303.04449v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1857244664,"_task_hash":1025676168,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678458382,"text":"Loss-Curvature Matching for Dataset Selection and Condensation\nTraining neural networks on a large dataset requires substantial computational costs. Dataset reduction selects or synthesizes data instances based on the large dataset, while minimizing the degradation in generalization performance from the full dataset. Existing methods utilize the neural network during the dataset reduction procedure, so the model parameter becomes important factor in preserving the performance after reduction. By depending upon the importance of parameters, this paper introduces a new reduction objective, coined LCMat, which Matches the Loss Curvatures of the original dataset and reduced dataset over the model parameter space, more than the parameter point. This new objective induces a better adaptation of the reduced dataset on the perturbed parameter region than the exact point matching. Particularly, we identify the worst case of the loss curvature gap from the local parameter region, and we derive the implementable upper bound of such worst-case with theoretical analyses. Our experiments on both coreset selection and condensation benchmarks illustrate that LCMat shows better generalization performances than existing baselines."}
{"link":"http://arxiv.org/abs/2303.04302v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-703906295,"_task_hash":1912714288,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678458383,"text":"Camera-Radar Perception for Autonomous Vehicles and ADAS: Concepts, Datasets and Metrics\nOne of the main paths towards the reduction of traffic accidents is the increase in vehicle safety through driver assistance systems or even systems with a complete level of autonomy. In these types of systems, tasks such as obstacle detection and segmentation, especially the Deep Learning-based ones, play a fundamental role in scene understanding for correct and safe navigation. Besides that, the wide variety of sensors in vehicles nowadays provides a rich set of alternatives for improvement in the robustness of perception in challenging situations, such as navigation under lighting and weather adverse conditions. Despite the current focus given to the subject, the literature lacks studies on radar-based and radar-camera fusion-based perception. Hence, this work aims to carry out a study on the current scenario of camera and radar-based perception for ADAS and autonomous vehicles. Concepts and characteristics related to both sensors, as well as to their fusion, are presented. Additionally, we give an overview of the Deep Learning-based detection and segmentation tasks, and the main datasets, metrics, challenges, and open questions in vehicle perception."}
{"link":"http://arxiv.org/abs/2302.01005v1","created":"2023-02-02","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1222198948,"_task_hash":-1324858170,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678458401,"text":"Predefined domain specific embeddings of food concepts and recipes: A case study on heterogeneous recipe datasets\nAlthough recipe data are very easy to come by nowadays, it is really hard to find a complete recipe dataset - with a list of ingredients, nutrient values per ingredient, and per recipe, allergens, etc. Recipe datasets are usually collected from social media websites where users post and publish recipes. Usually written with little to no structure, using both standardized and non-standardized units of measurement. We collect six different recipe datasets, publicly available, in different formats, and some including data in different languages. Bringing all of these datasets to the needed format for applying a machine learning (ML) pipeline for nutrient prediction [1], [2], includes data normalization using dictionary-based named entity recognition (NER), rule-based NER, as well as conversions using external domain-specific resources. From the list of ingredients, domain-specific embeddings are created using the same embedding space for all recipes - one ingredient dataset is generated. The result from this normalization process is two corpora - one with predefined ingredient embeddings and one with predefined recipe embeddings. On all six recipe datasets, the ML pipeline is evaluated. The results from this use case also confirm that the embeddings merged using the domain heuristic yield better results than the baselines."}
{"link":"http://arxiv.org/abs/2302.00785v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":915503391,"_task_hash":1571393321,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678458404,"text":"SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis\nFor the deployment of artificial intelligence (AI) in high-risk settings, such as healthcare, methods that provide interpretability/explainability or allow fine-grained error analysis are critical. Many recent methods for interpretability/explainability and fine-grained error analysis use concepts, which are meta-labels that are semantically meaningful to humans. However, there are only a few datasets that include concept-level meta-labels and most of these meta-labels are relevant for natural images that do not require domain expertise. Densely annotated datasets in medicine focused on meta-labels that are relevant to a single disease such as melanoma. In dermatology, skin disease is described using an established clinical lexicon that allows clinicians to describe physical exam findings to one another. To provide a medical dataset densely annotated by domain experts with annotations useful across multiple disease processes, we developed SkinCon: a skin disease dataset densely annotated by dermatologists. SkinCon includes 3230 images from the Fitzpatrick 17k dataset densely annotated with 48 clinical concepts, 22 of which have at least 50 images representing the concept. The concepts used were chosen by two dermatologists considering the clinical descriptor terms used to describe skin lesions. Examples include \"plaque\", \"scale\", and \"erosion\". The same concepts were also used to label 656 skin disease images from the Diverse Dermatology Images dataset, providing an additional external dataset with diverse skin tone representations. We review the potential applications for the SkinCon dataset, such as probing models, concept-based explanations, and concept bottlenecks. Furthermore, we use SkinCon to demonstrate two of these use cases: debugging mistakes of an existing dermatology AI model with concepts and developing interpretable models with post-hoc concept bottleneck models."}
{"link":"http://arxiv.org/abs/2302.00765v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1596723916,"_task_hash":152679589,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678458414,"text":"Visually Grounded Keyword Detection and Localisation for Low-Resource Languages\nThis study investigates the use of Visually Grounded Speech (VGS) models for keyword localisation in speech. The study focusses on two main research questions: (1) Is keyword localisation possible with VGS models and (2) Can keyword localisation be done cross-lingually in a real low-resource setting? Four methods for localisation are proposed and evaluated on an English dataset, with the best-performing method achieving an accuracy of 57%. A new dataset containing spoken captions in Yoruba language is also collected and released for cross-lingual keyword localisation. The cross-lingual model obtains a precision of 16% in actual keyword localisation and this performance can be improved by initialising from a model pretrained on English data. The study presents a detailed analysis of the model's success and failure modes and highlights the challenges of using VGS models for keyword localisation in low-resource settings."}
{"link":"http://arxiv.org/abs/2302.00734v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-152879801,"_task_hash":910398124,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678458419,"text":"Revisiting Query Performance in GPU Database Systems\nGPUs offer massive compute parallelism and high-bandwidth memory accesses. GPU database systems seek to exploit those capabilities to accelerate data analytics. Although modern GPUs have more resources (e.g., higher DRAM bandwidth) than ever before, judicious choices for query processing that avoid wasteful resource allocations are still advantageous. Database systems can save GPU runtime costs through just-enough resource allocation or improve query throughput with concurrent query processing by leveraging new GPU capabilities, such as Multi-Instance GPU (MIG).   In this paper we do a cross-stack performance and resource utilization analysis of five GPU database systems. We study both database-level and micro-architectural aspects, and offer recommendations to database developers. We also demonstrate how to use and extend the traditional roofline model to identify GPU resource bottlenecks. This enables users to conduct what-if analysis to forecast performance impact for different resource allocation or the degree of concurrency. Our methodology addresses a key user pain point in selecting optimal configurations by removing the need to do exhaustive testing for a multitude of resource configurations."}
{"link":"http://arxiv.org/abs/2302.00646v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-816110712,"_task_hash":1697964661,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678458421,"text":"Epic-Sounds: A Large-scale Dataset of Actions That Sound\nWe introduce EPIC-SOUNDS, a large-scale dataset of audio annotations capturing temporal extents and class labels within the audio stream of the egocentric videos. We propose an annotation pipeline where annotators temporally label distinguishable audio segments and describe the action that could have caused this sound. We identify actions that can be discriminated purely from audio, through grouping these free-form descriptions of audio into classes. For actions that involve objects colliding, we collect human annotations of the materials of these objects (e.g. a glass object being placed on a wooden surface), which we verify from visual labels, discarding ambiguities. Overall, EPIC-SOUNDS includes 78.4k categorised segments of audible events and actions, distributed across 44 classes as well as 39.2k non-categorised segments. We train and evaluate two state-of-the-art audio recognition models on our dataset, highlighting the importance of audio-only labels and the limitations of current models to recognise actions that sound."}
{"link":"http://arxiv.org/abs/2302.00606v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1974882764,"_task_hash":-1398622054,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678458428,"text":"The RW3D: A multi-modal panel dataset to understand the psychological impact of the pandemic\nBesides far-reaching public health consequences, the COVID-19 pandemic had a significant psychological impact on people around the world. To gain further insight into this matter, we introduce the Real World Worry Waves Dataset (RW3D). The dataset combines rich open-ended free-text responses with survey data on emotions, significant life events, and psychological stressors in a repeated-measures design in the UK over three years (2020: n=2441, 2021: n=1716 and 2022: n=1152). This paper provides background information on the data collection procedure, the recorded variables, participants' demographics, and higher-order psychological and text-based derived variables that emerged from the data. The RW3D is a unique primary data resource that could inspire new research questions on the psychological impact of the pandemic, especially those that connect modalities (here: text data, psychological survey variables and demographics) over time."}
{"link":"http://arxiv.org/abs/2302.00521v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-119130111,"_task_hash":1900628088,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678458445,"text":"Off-the-Grid MARL: a Framework for Dataset Generation with Baselines for Cooperative Offline Multi-Agent Reinforcement Learning\nBeing able to harness the power of large, static datasets for developing autonomous multi-agent systems could unlock enormous value for real-world applications. Many important industrial systems are multi-agent in nature and are difficult to model using bespoke simulators. However, in industry, distributed system processes can often be recorded during operation, and large quantities of demonstrative data can be stored. Offline multi-agent reinforcement learning (MARL) provides a promising paradigm for building effective online controllers from static datasets. However, offline MARL is still in its infancy, and, therefore, lacks standardised benchmarks, baselines and evaluation protocols typically found in more mature subfields of RL. This deficiency makes it difficult for the community to sensibly measure progress. In this work, we aim to fill this gap by releasing \\emph{off-the-grid MARL (OG-MARL)}: a framework for generating offline MARL datasets and algorithms. We release an initial set of datasets and baselines for cooperative offline MARL, created using the framework, along with a standardised evaluation protocol. Our datasets provide settings that are characteristic of real-world systems, including complex dynamics, non-stationarity, partial observability, suboptimality and sparse rewards, and are generated from popular online MARL benchmarks. We hope that OG-MARL will serve the community and help steer progress in offline MARL, while also providing an easy entry point for researchers new to the field."}
{"link":"http://arxiv.org/abs/2302.00455v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1207544641,"_task_hash":-1147215469,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678458447,"text":"HunSum-1: an Abstractive Summarization Dataset for Hungarian\nWe introduce HunSum-1: a dataset for Hungarian abstractive summarization, consisting of 1.14M news articles. The dataset is built by collecting, cleaning and deduplicating data from 9 major Hungarian news sites through CommonCrawl. Using this dataset, we build abstractive summarizer models based on huBERT and mT5. We demonstrate the value of the created dataset by performing a quantitative and qualitative analysis on the models' results. The HunSum-1 dataset, all models used in our experiments and our code are available open source."}
{"link":"http://arxiv.org/abs/2302.00431v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":964912505,"_task_hash":-301392347,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678458463,"text":"Do I Have Your Attention: A Large Scale Engagement Prediction Dataset and Baselines\nThe degree of concentration, enthusiasm, optimism, and passion displayed by individual(s) while interacting with a machine is referred to as `user engagement'. Engagement comprises of behavioural, cognitive, and affect related cues. To create engagement predictions systems, which can work in real-world conditions it is quintessential to learn from rich diverse datasets. To this end, a large scale multi-faceted engagement in the wild dataset is proposed. 31 hours duration data of 127 participants representing different illumination conditions is recorded. Thorough experiments are performed exploring applicability of different features action units, eye gaze and head pose and transformers. To further validate the rich nature of the dataset, evaluation is also performed on the EngageWild dataset. The experiments show the usefulness of the proposed dataset. The code, models and dataset will be made publicly available."}
{"link":"http://arxiv.org/abs/2302.00321v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1876572267,"_task_hash":-1936030013,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678458480,"text":"An Evaluation of Persian-English Machine Translation Datasets with Transformers\nNowadays, many researchers are focusing their attention on the subject of machine translation (MT). However, Persian machine translation has remained unexplored despite a vast amount of research being conducted in languages with high resources, such as English. Moreover, while a substantial amount of research has been undertaken in statistical machine translation for some datasets in Persian, there is currently no standard baseline for transformer-based text2text models on each corpus. This study collected and analysed the most popular and valuable parallel corpora, which were used for Persian-English translation. Furthermore, we fine-tuned and evaluated two state-of-the-art attention-based seq2seq models on each dataset separately (48 results). We hope this paper will assist researchers in comparing their Persian to English and vice versa machine translation results to a standard baseline."}
{"link":"http://arxiv.org/abs/2301.13095v1","created":"2023-01-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-352752282,"_task_hash":246427011,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678458483,"text":"Explaining Dataset Changes for Semantic Data Versioning with Explain-Da-V (Technical Report)\nIn multi-user environments in which data science and analysis is collaborative, multiple versions of the same datasets are generated. While managing and storing data versions has received some attention in the research literature, the semantic nature of such changes has remained under-explored. In this work, we introduce \\texttt{Explain-Da-V}, a framework aiming to explain changes between two given dataset versions. \\texttt{Explain-Da-V} generates \\emph{explanations} that use \\emph{data transformations} to explain changes. We further introduce a set of measures that evaluate the validity, generalizability, and explainability of these explanations. We empirically show, using an adapted existing benchmark and a newly created benchmark, that \\texttt{Explain-Da-V} generates better explanations than existing data transformation synthesis methods."}
{"link":"http://arxiv.org/abs/2301.13057v1","created":"2023-01-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-159395158,"_task_hash":1470785409,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678458485,"text":"MYRiAD: A Multi-Array Room Acoustic Database\nIn the development of acoustic signal processing algorithms, their evaluation in various acoustic environments is of utmost importance. In order to advance evaluation in realistic and reproducible scenarios, several high-quality acoustic databases have been developed over the years. In this paper, we present another complementary database of acoustic recordings, referred to as the Multi-arraY Room Acoustic Database (MYRiAD). The MYRiAD database is unique in its diversity of microphone configurations suiting a wide range of enhancement and reproduction applications (such as assistive hearing, teleconferencing, or sound zoning), the acoustics of the two recording spaces, and the variety of contained signals including 1214 room impulse responses (RIRs), reproduced speech, music, and stationary noise, as well as recordings of live cocktail parties held in both rooms. The microphone configurations comprise a dummy head (DH) with in-ear omnidirectional microphones, two behind-the-ear (BTE) pieces equipped with 2 omnidirectional microphones each, 5 external omnidirectional microphones (XMs), and two concentric circular microphone arrays (CMAs) consisting of 12 omnidirectional microphones in total. The two recording spaces, namely the SONORA Audio Laboratory (SAL) and the Alamire Interactive Laboratory (AIL), have reverberation times of 2.1s and 0.5s, respectively. Audio signals were reproduced using 10 movable loudspeakers in the SAL and a built-in array of 24 loudspeakers in the AIL. MATLAB and Python scripts are included for accessing the signals as well as microphone and loudspeaker coordinates. The database is publicly available at [1]."}
{"link":"http://arxiv.org/abs/2301.12800v1","created":"2023-01-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":996664525,"_task_hash":-1176788,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678458491,"text":"Behavioural Reports of Multi-Stage Malware\nThe extensive damage caused by malware requires anti-malware systems to be constantly improved to prevent new threats. The current trend in malware detection is to employ machine learning models to aid in the classification process. We propose a new dataset with the objective of improving current anti-malware systems. The focus of this dataset is to improve host based intrusion detection systems by providing API call sequences for thousands of malware samples executed in Windows 10 virtual machines. A tutorial on how to create and expand this dataset is provided along with a benchmark demonstrating how to use this dataset to classify malware. The data contains long sequences of API calls for each sample, and in order to create models that can be deployed in resource constrained devices, three feature selection methods were tested. The principal innovation, however, lies in the multi-label classification system in which one sequence of APIs can be tagged with multiple labels describing its malicious behaviours."}
{"link":"http://arxiv.org/abs/2301.11932v1","created":"2023-01-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":513549799,"_task_hash":187916684,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678458497,"text":"RGB Arabic Alphabets Sign Language Dataset\nThis paper introduces the RGB Arabic Alphabet Sign Language (AASL) dataset. AASL comprises 7,856 raw and fully labelled RGB images of the Arabic sign language alphabets, which to our best knowledge is the first publicly available RGB dataset. The dataset is aimed to help those interested in developing real-life Arabic sign language classification models. AASL was collected from more than 200 participants and with different settings such as lighting, background, image orientation, image size, and image resolution. Experts in the field supervised, validated and filtered the collected images to ensure a high-quality dataset. AASL is made available to the public on Kaggle."}
{"link":"http://arxiv.org/abs/2301.12700v1","created":"2023-01-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-2077107932,"_task_hash":-672143111,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476406,"text":"CSDR-BERT: a pre-trained scientific dataset match model for Chinese Scientific Dataset Retrieval\nAs the number of open and shared scientific datasets on the Internet increases under the open science movement, efficiently retrieving these datasets is a crucial task in information retrieval (IR) research. In recent years, the development of large models, particularly the pre-training and fine-tuning paradigm, which involves pre-training on large models and fine-tuning on downstream tasks, has provided new solutions for IR match tasks. In this study, we use the original BERT token in the embedding layer, improve the Sentence-BERT model structure in the model layer by introducing the SimCSE and K-Nearest Neighbors method, and use the cosent loss function in the optimization phase to optimize the target output. Our experimental results show that our model outperforms other competing models on both public and self-built datasets through comparative experiments and ablation implementations. This study explores and validates the feasibility and efficiency of pre-training techniques for semantic retrieval of Chinese scientific datasets."}
{"link":"http://arxiv.org/abs/2301.12561v1","created":"2023-01-29","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1484471230,"_task_hash":1393902572,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476409,"text":"Benchmarking Specialized Databases for High-frequency Data\nThis paper presents a benchmarking suite designed for the evaluation and comparison of time series databases for high-frequency data, with a focus on financial applications. The proposed suite comprises of four specialized databases: ClickHouse, InfluxDB, kdb+ and TimescaleDB. The results from the suite demonstrate that kdb+ has the highest performance amongst the tested databases, while also highlighting the strengths and weaknesses of each of the databases. The benchmarking suite was designed to provide an objective measure of the performance of these databases as well as to compare their capabilities for different types of data. This provides valuable insights into the suitability of different time series databases for different use cases and provides benchmarks that can be used to inform system design decisions."}
{"link":"http://arxiv.org/abs/2303.04962v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1838408323,"_task_hash":-392049621,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476487,"text":"Contributing to Accessibility Datasets: Reflections on Sharing Study Data by Blind People\nTo ensure that AI-infused systems work for disabled people, we need to bring accessibility datasets sourced from this community in the development lifecycle. However, there are many ethical and privacy concerns limiting greater data inclusion, making such datasets not readily available. We present a pair of studies where 13 blind participants engage in data capturing activities and reflect with and without probing on various factors that influence their decision to share their data via an AI dataset. We see how different factors influence blind participants' willingness to share study data as they assess risk-benefit tradeoffs. The majority support sharing of their data to improve technology but also express concerns over commercial use, associated metadata, and the lack of transparency about the impact of their data. These insights have implications for the development of responsible practices for stewarding accessibility datasets, and can contribute to broader discussions in this area."}
{"link":"http://arxiv.org/abs/2212.13401v1","created":"2022-12-27","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1870726540,"_task_hash":-1623283740,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476491,"text":"A Novel Dataset and a Deep Learning Method for Mitosis Nuclei Segmentation and Classification\nMitosis nuclei count is one of the important indicators for the pathological diagnosis of breast cancer. The manual annotation needs experienced pathologists, which is very time-consuming and inefficient. With the development of deep learning methods, some models with good performance have emerged, but the generalization ability should be further strengthened. In this paper, we propose a two-stage mitosis segmentation and classification method, named SCMitosis. Firstly, the segmentation performance with a high recall rate is achieved by the proposed depthwise separable convolution residual block and channel-spatial attention gate. Then, a classification network is cascaded to further improve the detection performance of mitosis nuclei. The proposed model is verified on the ICPR 2012 dataset, and the highest F-score value of 0.8687 is obtained compared with the current state-of-the-art algorithms. In addition, the model also achieves good performance on GZMH dataset, which is prepared by our group and will be firstly released with the publication of this paper. The code will be available at: https://github.com/antifen/mitosis-nuclei-segmentation."}
{"link":"http://arxiv.org/abs/2212.10515v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1522927386,"_task_hash":-415935791,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476510,"text":"CausalDialogue: Modeling Utterance-level Causality in Conversations\nDespite their widespread adoption, neural conversation models have yet to exhibit natural chat capabilities with humans. In this research, we examine user utterances as causes and generated responses as effects, recognizing that changes in a cause should produce a different effect. To further explore this concept, we have compiled and expanded upon a new dataset called CausalDialogue through crowd-sourcing. This dataset includes multiple cause-effect pairs within a directed acyclic graph (DAG) structure. Our analysis reveals that traditional loss functions can struggle to effectively incorporate the DAG structure, leading us to propose a causality-enhanced method called Exponential Maximum Average Treatment Effect (ExMATE) to enhance the impact of causality at the utterance level in training neural conversation models. To evaluate the effectiveness of this approach, we have built a comprehensive benchmark using the CausalDialogue dataset leveraging large-scale pre-trained language models, and have assessed the results through both human and automatic evaluation metrics for coherence, diversity, and agility. Our findings show that current techniques are still unable to effectively address conversational DAGs, and that the ExMATE method can improve the diversity and agility of conventional loss functions while maintaining coherence."}
{"link":"http://arxiv.org/abs/2212.10770v1","created":"2022-12-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1420056498,"_task_hash":-339480863,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476513,"text":"ImPaKT: A Dataset for Open-Schema Knowledge Base Construction\nLarge language models have ushered in a golden age of semantic parsing. The seq2seq paradigm allows for open-schema and abstractive attribute and relation extraction given only small amounts of finetuning data. Language model pretraining has simultaneously enabled great strides in natural language inference, reasoning about entailment and implication in free text. These advances motivate us to construct ImPaKT, a dataset for open-schema information extraction, consisting of around 2500 text snippets from the C4 corpus, in the shopping domain (product buying guides), professionally annotated with extracted attributes, types, attribute summaries (attribute schema discovery from idiosyncratic text), many-to-one relations between compound and atomic attributes, and implication relations. We release this data in hope that it will be useful in fine tuning semantic parsers for information extraction and knowledge base construction across a variety of domains. We evaluate the power of this approach by fine-tuning the open source UL2 language model on a subset of the dataset, extracting a set of implication relations from a corpus of product buying guides, and conducting human evaluations of the resulting predictions."}
{"link":"http://arxiv.org/abs/2212.06071v2","created":"2022-12-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1028674078,"_task_hash":64870169,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476516,"text":"3DSC - A New Dataset of Superconductors Including Crystal Structures\nData-driven methods, in particular machine learning, can help to speed up the discovery of new materials by finding hidden patterns in existing data and using them to identify promising candidate materials. In the case of superconductors, which are a highly interesting but also a complex class of materials with many relevant applications, the use of data science tools is to date slowed down by a lack of accessible data. In this work, we present a new and publicly available superconductivity dataset ('3DSC'), featuring the critical temperature $T_\\mathrm{c}$ of superconducting materials additionally to tested non-superconductors. In contrast to existing databases such as the SuperCon database which contains information on the chemical composition, the 3DSC is augmented by the approximate three-dimensional crystal structure of each material. We perform a statistical analysis and machine learning experiments to show that access to this structural information improves the prediction of the critical temperature $T_\\mathrm{c}$ of materials. Furthermore, we see the 3DSC not as a finished dataset, but we provide ideas and directions for further research to improve the 3DSC in multiple ways. We are confident that this database will be useful in applying state-of-the-art machine learning methods to eventually find new superconductors."}
{"link":"http://arxiv.org/abs/2301.05639v1","created":"2023-01-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1082724160,"_task_hash":1597793998,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476526,"text":"Predictions of photophysical properties of phosphorescent platinum(II) complexes based on ensemble machine learning approach\nPhosphorescent metal complexes have been under intense investigations as emissive dopants for energy efficient organic light emitting diodes (OLEDs). Among them, cyclometalated Pt(II) complexes are widespread triplet emitters with color-tunable emissions. To render their practical applications as OLED emitters, it is in great need to develop Pt(II) complexes with high radiative decay rate constant ($k_r$) and photoluminescence (PL) quantum yield. Thus, an efficient and accurate prediction tool is highly desirable. Here, we develop a general protocol for accurate predictions of emission wavelength, radiative decay rate constant, and PL quantum yield for phosphorescent Pt(II) emitters based on the combination of first-principles quantum mechanical method, machine learning (ML) and experimental calibration. A new dataset concerning phosphorescent Pt(II) emitters is constructed, with more than two hundred samples collected from the literature. Features containing pertinent electronic properties of the complexes are chosen. Our results demonstrate that ensemble learning models combined with stacking-based approaches exhibit the best performance, where the values of squared correlation coefficients ($R^2$), mean absolute error (MAE), and root mean square error (RMSE) are 0.96, 7.21 nm and 13.00 nm for emission wavelength prediction, and 0.81, 0.11 and 0.15 for PL quantum yield prediction. For radiative decay rate constant ($k_r$), the obtained value of $R^2$ is 0.67 while MAE and RMSE are 0.21 and 0.25 (both in log scale), respectively. The accuracy of the protocol is further confirmed using 24 recently reported Pt(II) complexes, which demonstrates its reliability for a broad palette of Pt(II) emitters.We expect this protocol will become a valuable tool, accelerating the rational design of novel OLED materials with desired properties."}
{"link":"http://arxiv.org/abs/2212.08639v1","created":"2022-12-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1476339545,"_task_hash":-837648352,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476537,"text":"An annotated instance segmentation XXL-CT dataset from a historic airplane\nThe Me 163 was a Second World War fighter airplane and a result of the German air force secret developments. One of these airplanes is currently owned and displayed in the historic aircraft exhibition of the Deutsches Museum in Munich, Germany. To gain insights with respect to its history, design and state of preservation, a complete CT scan was obtained using an industrial XXL-computer tomography scanner.   Using the CT data from the Me 163, all its details can visually be examined at various levels, ranging from the complete hull down to single sprockets and rivets. However, while a trained human observer can identify and interpret the volumetric data with all its parts and connections, a virtual dissection of the airplane and all its different parts would be quite desirable. Nevertheless, this means, that an instance segmentation of all components and objects of interest into disjoint entities from the CT data is necessary.   As of currently, no adequate computer-assisted tools for automated or semi-automated segmentation of such XXL-airplane data are available, in a first step, an interactive data annotation and object labeling process has been established. So far, seven 512 x 512 x 512 voxel sub-volumes from the Me 163 airplane have been annotated and labeled, whose results can potentially be used for various new applications in the field of digital heritage, non-destructive testing, or machine-learning.   This work describes the data acquisition process of the airplane using an industrial XXL-CT scanner, outlines the interactive segmentation and labeling scheme to annotate sub-volumes of the airplane's CT data, describes and discusses various challenges with respect to interpreting and handling the annotated and labeled data."}
{"link":"http://arxiv.org/abs/2212.06701v1","created":"2022-12-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1441658294,"_task_hash":-238425351,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476546,"text":"A Novel Approach For Generating Customizable Light Field Datasets for Machine Learning\nTo train deep learning models, which often outperform traditional approaches, large datasets of a specified medium, e.g., images, are used in numerous areas. However, for light field-specific machine learning tasks, there is a lack of such available datasets. Therefore, we create our own light field datasets, which have great potential for a variety of applications due to the abundance of information in light fields compared to singular images. Using the Unity and C# frameworks, we develop a novel approach for generating large, scalable, and reproducible light field datasets based on customizable hardware configurations to accelerate light field deep learning research."}
{"link":"http://arxiv.org/abs/2212.07917v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1140368794,"_task_hash":2130646075,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476549,"text":"An Analysis of Variance of the Pantheon+ Dataset: Systematics in the Covariance Matrix?\nWe investigate the statistics of the available Pantheon+ dataset. Noticing that the $\\chi^2$ value for the best-fit $\\Lambda$CDM model to the real data is small, we quantify how significant its smallness is by calculating the distribution of $\\chi^2$ values for the best-fit $\\Lambda$CDM model fit to mock Pantheon+-like datasets, using the provided covariance matrix. We further investigate the distribution of the residuals of the Pantheon+ dataset, with respect to the best-fit $\\Lambda$CDM model, and notice they scatter smaller than would be expected from the covariance matrix but find no significant amount of kurtosis. These results point to the conclusion that the Pantheon+ covariance matrix is over-estimated. One simple interpretation of these results is a $\\sim$5\\% overestimation of errors on SN distances in Pantheon+ data. When the covariance matrix is reduced by subtracting an intrinsic scatter term from the diagonal terms of the covariance matrix, the best-fit $\\chi^2$ for the $\\Lambda$CDM model achieves a normal value of 1580 and no deviation from $\\Lambda$CDM is detected. We further quantify how consistent the $\\Lambda$CDM model is with respect to the modified data with the subtracted covariance matrix using model independent reconstruction techniques such as the iterative smoothing method and we find that the standard model is consistent with the data."}
{"link":"http://arxiv.org/abs/2212.13296v1","created":"2022-12-26","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":170323057,"_task_hash":-1585296830,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476552,"text":"VQA and Visual Reasoning: An Overview of Recent Datasets, Methods and Challenges\nArtificial Intelligence (AI) and its applications have sparked extraordinary interest in recent years. This achievement can be ascribed in part to advances in AI subfields including Machine Learning (ML), Computer Vision (CV), and Natural Language Processing (NLP). Deep learning, a sub-field of machine learning that employs artificial neural network concepts, has enabled the most rapid growth in these domains. The integration of vision and language has sparked a lot of attention as a result of this. The tasks have been created in such a way that they properly exemplify the concepts of deep learning. In this review paper, we provide a thorough and an extensive review of the state of the arts approaches, key models design principles and discuss existing datasets, methods, their problem formulation and evaluation measures for VQA and Visual reasoning tasks to understand vision and language representation learning. We also present some potential future paths in this field of research, with the hope that our study may generate new ideas and novel approaches to handle existing difficulties and develop new applications."}
{"link":"http://arxiv.org/abs/2212.08550v1","created":"2022-12-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":636947097,"_task_hash":-1477229558,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476554,"text":"Fine-grained Czech News Article Dataset: An Interdisciplinary Approach to Trustworthiness Analysis\nWe present the Verifee Dataset: a novel dataset of news articles with fine-grained trustworthiness annotations. We develop a detailed methodology that assesses the texts based on their parameters encompassing editorial transparency, journalist conventions, and objective reporting while penalizing manipulative techniques. We bring aboard a diverse set of researchers from social, media, and computer sciences to overcome barriers and limited framing of this interdisciplinary problem. We collect over $10,000$ unique articles from almost $60$ Czech online news sources. These are categorized into one of the $4$ classes across the credibility spectrum we propose, raging from entirely trustworthy articles all the way to the manipulative ones. We produce detailed statistics and study trends emerging throughout the set. Lastly, we fine-tune multiple popular sequence-to-sequence language models using our dataset on the trustworthiness classification task and report the best testing F-1 score of $0.52$. We open-source the dataset, annotation methodology, and annotators' instructions in full length at https://verifee.ai/research to enable easy build-up work. We believe similar methods can help prevent disinformation and educate in the realm of media literacy."}
{"link":"http://arxiv.org/abs/2212.07914v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1549743736,"_task_hash":1802727582,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476575,"text":"The Effects of In-domain Corpus Size on pre-training BERT\nMany prior language modeling efforts have shown that pre-training on an in-domain corpus can significantly improve performance on downstream domain-specific NLP tasks. However, the difficulties associated with collecting enough in-domain data might discourage researchers from approaching this pre-training task. In this paper, we conducted a series of experiments by pre-training Bidirectional Encoder Representations from Transformers (BERT) with different sizes of biomedical corpora. The results demonstrate that pre-training on a relatively small amount of in-domain data (4GB) with limited training steps, can lead to better performance on downstream domain-specific NLP tasks compared with fine-tuning models pre-trained on general corpora."}
{"link":"http://arxiv.org/abs/2212.06130v1","created":"2022-12-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1992195042,"_task_hash":1319054709,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476585,"text":"Siamese Neural Networks for Skin Cancer Classification and New Class Detection using Clinical and Dermoscopic Image Datasets\nSkin cancer is the most common malignancy in the world. Automated skin cancer detection would significantly improve early detection rates and prevent deaths. To help with this aim, a number of datasets have been released which can be used to train Deep Learning systems - these have produced impressive results for classification. However, this only works for the classes they are trained on whilst they are incapable of identifying skin lesions from previously unseen classes, making them unconducive for clinical use. We could look to massively increase the datasets by including all possible skin lesions, though this would always leave out some classes. Instead, we evaluate Siamese Neural Networks (SNNs), which not only allows us to classify images of skin lesions, but also allow us to identify those images which are different from the trained classes - allowing us to determine that an image is not an example of our training classes. We evaluate SNNs on both dermoscopic and clinical images of skin lesions. We obtain top-1 classification accuracy levels of 74.33% and 85.61% on clinical and dermoscopic datasets, respectively. Although this is slightly lower than the state-of-the-art results, the SNN approach has the advantage that it can detect out-of-class examples. Our results highlight the potential of an SNN approach as well as pathways towards future clinical deployment."}
{"link":"http://arxiv.org/abs/2212.06981v1","created":"2022-12-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-472862453,"_task_hash":-1410234782,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476588,"text":"Automatic Classification of Galaxy Morphology: a rotationally invariant supervised machine learning method based on the UML-dataset\nClassification of galaxy morphology is a challenging but meaningful task for the enormous amount of data produced by the next-generation telescope. By introducing the adaptive polar coordinate transformation, we develop a rotationally invariant supervised machine learning (SML) method that ensures consistent classifications when rotating galaxy images, which is always required to be satisfied physically but difficult to achieve algorithmically. The adaptive polar coordinate transformation, compared with the conventional method of data augmentation by including additional rotated images in the training set, is proved to be an effective and efficient method in improving the robustness of the SML methods. In the previous work, we generated a catalog of galaxies with well-classified morphologies via our developed unsupervised machine learning (UML) method. By using this UML-dataset as the training set, we apply the new method to classify galaxies into five categories (unclassifiable, irregulars, late-type disks, early-type disks, and spheroids). In general, the result of our morphological classifications following the sequence from irregulars to spheroids agrees well with the expected trends of other galaxy properties, including S\\'{e}rsic indices, effective radii, nonparametric statistics, and colors. Thus, we demonstrate that the rotationally invariant SML method, together with the previously developed UML method, completes the entire task of automatic classification of galaxy morphology."}
{"link":"http://arxiv.org/abs/2301.03567v1","created":"2023-01-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":237999486,"_task_hash":-1778252951,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476605,"text":"Safer Together: Machine Learning Models Trained on Shared Accident Datasets Predict Construction Injuries Better than Company-Specific Models\nIn this study, we capitalized on a collective dataset repository of 57k accidents from 9 companies belonging to 3 domains and tested whether models trained on multiple datasets (generic models) predicted safety outcomes better than the company-specific models. We experimented with full generic models (trained on all data), per-domain generic models (construction, electric T&D, oil & gas), and with ensembles of generic and specific models. Results are very positive, with generic models outperforming the company-specific models in most cases while also generating finer-grained, hence more useful, forecasts. Successful generic models remove the needs for training company-specific models, saving a lot of time and resources, and give small companies, whose accident datasets are too limited to train their own models, access to safety outcome predictions. It may still however be advantageous to train specific models to get an extra boost in performance through ensembling with the generic models. Overall, by learning lessons from a pool of datasets whose accumulated experience far exceeds that of any single company, and making these lessons easily accessible in the form of simple forecasts, generic models tackle the holy grail of safety cross-organizational learning and dissemination in the construction industry."}
{"link":"http://arxiv.org/abs/2212.10579v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":918575336,"_task_hash":-1557932570,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476622,"text":"Resonant Anomaly Detection with Multiple Reference Datasets\nAn important class of techniques for resonant anomaly detection in high energy physics builds models that can distinguish between reference and target datasets, where only the latter has appreciable signal. Such techniques, including Classification Without Labels (CWoLa) and Simulation Assisted Likelihood-free Anomaly Detection (SALAD) rely on a single reference dataset. They cannot take advantage of commonly-available multiple datasets and thus cannot fully exploit available information. In this work, we propose generalizations of CWoLa and SALAD for settings where multiple reference datasets are available, building on weak supervision techniques. We demonstrate improved performance in a number of settings with realistic and synthetic data. As an added benefit, our generalizations enable us to provide finite-sample guarantees, improving on existing asymptotic analyses."}
{"link":"http://arxiv.org/abs/2212.09911v1","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1567918856,"_task_hash":1506459578,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476638,"text":"A Physically-Consistent Chemical Dataset for the Simulation of N$_2$-CH$_4$ Shocked Flows Up to T=100,000K\nIn the previous work carried out in the scope of the \\emph{Validation of Aerothermochemistry Models for Re-Entry Applications}, it was verified that the G\\\"{o}k\\c{c}en chemical dataset provided increasingly diverging results from experiments, as one considered shock speeds in excess of 5\\kilo\\metre\\per\\second. Namely, for shock velocities between 7 and 9\\kilo\\metre\\per\\second, more than one temporal peak in CN Violet radiation were predicted by models considering this kinetic dataset, in contradiction with experiments. This hinted at several of the rates from the dataset not being directly applicable in the temperature range of interest for such applications, often in excess of 10,000\\kelvin. Indeed, it has been found that several macroscopic rates from the G\\\"{o}k\\c{c}en chemical dataset reached unphysical values at very high temperatures. Furthermore, many of the ionization rates have been found to be inadequate for the simulation of high-temperature N$_{2}$--CH$_{4}$ shocked flows. Here, we have carried an extensive update of the G\\\"{o}k\\c{c}en chemical dataset, with the aim of at least reaching physically consistent rates for the whole T=100-100,000\\kelvin\\ temperature range. While it cannot really be claimed that such improved dataset is validated in such an extended temperature range (due to the scarcely available experimental data for such high temperature ranges), it is capable of providing more accurate simulations of high-speed shocked flows for this mixture, when compared to the G\\\"{o}k\\c{c}en chemical dataset."}
{"link":"http://arxiv.org/abs/2212.08167v1","created":"2022-12-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1577466060,"_task_hash":-2049480388,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476645,"text":"Evaluation of Synthetic Datasets for Conversational Recommender Systems\nFor researchers leveraging Large-Language Models (LLMs) in the generation of training datasets, especially for conversational recommender systems - the absence of robust evaluation frameworks has been a long-standing problem. The efficiency brought about by LLMs in the data generation phase is impeded during the process of evaluation of the generated data, since it generally requires human-raters to ensure that the data generated is of high quality and has sufficient diversity. Since the quality of training data is critical for downstream applications, it is important to develop metrics that evaluate the quality holistically and identify biases. In this paper, we present a framework that takes a multi-faceted approach towards evaluating datasets produced by generative models and discuss the advantages and limitations of various evaluation methods."}
{"link":"http://arxiv.org/abs/2212.10722v1","created":"2022-12-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1574820008,"_task_hash":1539914856,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476651,"text":"Tracing and Removing Data Errors in Natural Language Generation Datasets\nRecent work has identified noisy and misannotated data as a core cause of hallucinations and unfaithful outputs in Natural Language Generation (NLG) tasks. Consequently, identifying and removing these examples is a key open challenge in creating reliable NLG systems. In this work, we introduce a framework to identify and remove low-quality training instances that lead to undesirable outputs, such as faithfulness errors in text summarization. We show that existing approaches for error tracing, such as gradient-based influence measures, do not perform reliably for detecting faithfulness errors in summarization. We overcome the drawbacks of existing error tracing methods through a new, contrast-based estimate that compares undesired generations to human-corrected outputs. Our proposed method can achieve a mean average precision of 0.91 across synthetic tasks with known ground truth and can achieve a two-fold reduction in hallucinations on a real entity hallucination evaluation on the NYT dataset."}
{"link":"http://arxiv.org/abs/2212.10750v1","created":"2022-12-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1022516162,"_task_hash":1903073980,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476653,"text":"PropSegmEnt: A Large-Scale Corpus for Proposition-Level Segmentation and Entailment Recognition\nThe widely studied task of Natural Language Inference (NLI) requires a system to recognize whether one piece of text is textually entailed by another, i.e. whether the entirety of its meaning can be inferred from the other. In current NLI datasets and models, textual entailment relations are typically defined on the sentence- or paragraph-level. However, even a simple sentence often contains multiple propositions, i.e. distinct units of meaning conveyed by the sentence. As these propositions can carry different truth values in the context of a given premise, we argue for the need to recognize the textual entailment relation of each proposition in a sentence individually.   We propose PropSegmEnt, a corpus of over 35K propositions annotated by expert human raters. Our dataset structure resembles the tasks of (1) segmenting sentences within a document to the set of propositions, and (2) classifying the entailment relation of each proposition with respect to a different yet topically-aligned document, i.e. documents describing the same event or entity. We establish strong baselines for the segmentation and entailment tasks. Through case studies on summary hallucination detection and document-level NLI, we demonstrate that our conceptual framework is potentially useful for understanding and explaining the compositionality of NLI labels."}
{"link":"http://arxiv.org/abs/2212.12204v1","created":"2022-12-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1517079822,"_task_hash":1748502266,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476709,"text":"EndoBoost: a plug-and-play module for false positive suppression during computer-aided polyp detection in real-world colonoscopy (with dataset)\nThe advance of computer-aided detection systems using deep learning opened a new scope in endoscopic image analysis. However, the learning-based models developed on closed datasets are susceptible to unknown anomalies in complex clinical environments. In particular, the high false positive rate of polyp detection remains a major challenge in clinical practice. In this work, we release the FPPD-13 dataset, which provides a taxonomy and real-world cases of typical false positives during computer-aided polyp detection in real-world colonoscopy. We further propose a post-hoc module EndoBoost, which can be plugged into generic polyp detection models to filter out false positive predictions. This is realized by generative learning of the polyp manifold with normalizing flows and rejecting false positives through density estimation. Compared to supervised classification, this anomaly detection paradigm achieves better data efficiency and robustness in open-world settings. Extensive experiments demonstrate a promising false positive suppression in both retrospective and prospective validation. In addition, the released dataset can be used to perform 'stress' tests on established detection systems and encourages further research toward robust and reliable computer-aided endoscopic image analysis. The dataset and code will be publicly available at http://endoboost.miccai.cloud."}
{"link":"http://arxiv.org/abs/2212.12213v1","created":"2022-12-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1711667464,"_task_hash":-1384342674,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476755,"text":"Finetuning for Sarcasm Detection with a Pruned Dataset\nSarcasm is a form of irony that involves saying or writing something that is opposite or opposite to what one really means, often in a humorous or mocking way. It is often used to mock or mock someone or something, or to be humorous or amusing. Sarcasm is usually conveyed through tone of voice, facial expressions, or other forms of nonverbal communication, but it can also be indicated by the use of certain words or phrases that are typically associated with irony or humor. Sarcasm detection is difficult because it relies on context and non-verbal cues. It can also be culturally specific, subjective and ambiguous. In this work, we fine-tune the RoBERTa based sarcasm detection model presented in Abaskohi et al. [2022] to get to within 0.02 F1 of the state-of-the-art (Hercog et al. [2022]) on the iSarcasm dataset (Oprea and Magdy [2019]). This performance is achieved by augmenting iSarcasm with a pruned version of the Self Annotated Reddit Corpus (SARC) (Khodak et al. [2017]). Our pruned version is 100 times smaller than the subset of SARC used to train the state-of-the-art model."}
{"link":"http://arxiv.org/abs/2212.06933v1","created":"2022-12-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1225912380,"_task_hash":-922829492,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476772,"text":"Paraphrase Identification with Deep Learning: A Review of Datasets and Methods\nThe rapid advancement of AI technology has made text generation tools like GPT-3 and ChatGPT increasingly accessible, scalable, and effective. This can pose serious threat to the credibility of various forms of media if these technologies are used for plagiarism, including scientific literature and news sources. Despite the development of automated methods for paraphrase identification, detecting this type of plagiarism remains a challenge due to the disparate nature of the datasets on which these methods are trained. In this study, we review traditional and current approaches to paraphrase identification and propose a refined typology of paraphrases. We also investigate how this typology is represented in popular datasets and how under-representation of certain types of paraphrases impacts detection capabilities. Finally, we outline new directions for future research and datasets in the pursuit of more effective paraphrase detection using AI."}
{"link":"http://arxiv.org/abs/2212.06511v1","created":"2022-12-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1959656899,"_task_hash":1793168694,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476801,"text":"A Comprehensive Dataset of Grains for Granular Jamming in Soft Robotics: Grip Strength and Shock Absorption\nWe test grip strength and shock absorption properties of various granular material in granular jamming robotic components. The granular material comprises a range of natural, manufactured, and 3D printed material encompassing a wide range of shapes, sizes, and Shore hardness. Two main experiments are considered, both representing compelling use cases for granular jamming in soft robotics. The first experiment measures grip strength (retention force measured in Newtons) when we fill a latex balloon with the chosen grain type and use it as a granular jamming gripper to pick up a range of test objects. The second experiment measures shock absorption properties recorded by an Inertial Measurement Unit which is suspended in an envelope of granular material and dropped from a set height. Our results highlight a range of shape, size and softness effects, including that grain deformability is a key determinant of grip strength, and interestingly, that larger grain sizes in 3D printed grains create better shock absorbing materials."}
{"link":"http://arxiv.org/abs/2303.05264v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":885268710,"_task_hash":1483389392,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476807,"text":"Belnap-Dunn logic and query answering in inconsistent databases with null values\nThis paper concerns an expansion of first-order Belnap-Dunn logic, named $\\mathrm{BD}^{\\supset,\\mathsf{F}}$, and an application of this logic in the area of relational database theory. The notion of a relational database, the notion of a query applicable to a relational database, and several notions of an answer to a query with respect to a relational database are considered from the perspective of this logic, taking into account that a database may be an inconsistent database or a database with null values. The chosen perspective enables among other things the definition of a notion of a consistent answer to a query with respect to a possibly inconsistent database without resort to database repairs. For each of the notions of an answer considered, being an answer to a query with respect to a database of the kind considered is decidable."}
{"link":"http://arxiv.org/abs/2212.09258v1","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-546610000,"_task_hash":111169687,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476811,"text":"CHAD: Charlotte Anomaly Dataset\nIn recent years, we have seen a significant interest in data-driven deep learning approaches for video anomaly detection, where an algorithm must determine if specific frames of a video contain abnormal behaviors. However, video anomaly detection is particularly context-specific, and the availability of representative datasets heavily limits real-world accuracy. Additionally, the metrics currently reported by most state-of-the-art methods often do not reflect how well the model will perform in real-world scenarios. In this article, we present the Charlotte Anomaly Dataset (CHAD). CHAD is a high-resolution, multi-camera anomaly dataset in a commercial parking lot setting. In addition to frame-level anomaly labels, CHAD is the first anomaly dataset to include bounding box, identity, and pose annotations for each actor. This is especially beneficial for skeleton-based anomaly detection, which is useful for its lower computational demand in real-world settings. CHAD is also the first anomaly dataset to contain multiple views of the same scene. With four camera views and over 1.15 million frames, CHAD is the largest fully annotated anomaly detection dataset including person annotations, collected from continuous video streams from stationary cameras for smart video surveillance applications. To demonstrate the efficacy of CHAD for training and evaluation, we benchmark two state-of-the-art skeleton-based anomaly detection algorithms on CHAD and provide comprehensive analysis, including both quantitative results and qualitative examination."}
{"link":"http://arxiv.org/abs/2301.01134v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1106218507,"_task_hash":-1350136803,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476819,"text":"Ring That Bell: A Corpus and Method for Multimodal Metaphor Detection in Videos\nWe present the first openly available multimodal metaphor annotated corpus. The corpus consists of videos including audio and subtitles that have been annotated by experts. Furthermore, we present a method for detecting metaphors in the new dataset based on the textual content of the videos. The method achieves a high F1-score (62\\%) for metaphorical labels. We also experiment with other modalities and multimodal methods; however, these methods did not out-perform the text-based model. In our error analysis, we do identify that there are cases where video could help in disambiguating metaphors, however, the visual cues are too subtle for our model to capture. The data is available on Zenodo."}
{"link":"http://arxiv.org/abs/2212.14350v1","created":"2022-12-29","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1583764744,"_task_hash":628912432,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476823,"text":"Synthetic dataset generation methodology for Recommender Systems using statistical sampling methods, a Multinomial Logit model, and a Fuzzy Inference System\nIt is said that we live in the age of data, and that data is ubiquitous and readily available if one has the tools to harness it. That may well be true, but so is the opposite. It is ever more common to try to start a data science project only to find oneself without quality data. Be it due to just not having collected the needed features, or due to insufficient data, or even legality issues, the list goes on. When this happens, either the project is prematurely abandoned, or similar datasets are searched for and used. However, finding a dataset that answers your needs in terms of features, type of ratings, etc., may not be an easy task, this is particularly the case for recommender systems. In this work, a methodology for the generation of synthetic datasets for recommender systems is presented, thus allowing to overcome the obstacle of not having quality data in sufficient amount readily available. With this methodology, one can generate a synthetic dataset for recommendation composed by numerical/ordinal and nominal features. The dataset is built with Gaussian copulas, Dirichlet and Gaussian distributions, a Multinomial Logit model and a Fuzzy Logic Inference System that generates the ratings according to different user behavioural profiles and perceived item quality."}
{"link":"http://arxiv.org/abs/2212.14099v1","created":"2022-12-28","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1318693067,"_task_hash":269043717,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476831,"text":"Curator: Creating Large-Scale Curated Labelled Datasets using Self-Supervised Learning\nApplying Machine learning to domains like Earth Sciences is impeded by the lack of labeled data, despite a large corpus of raw data available in such domains. For instance, training a wildfire classifier on satellite imagery requires curating a massive and diverse dataset, which is an expensive and time-consuming process that can span from weeks to months. Searching for relevant examples in over 40 petabytes of unlabelled data requires researchers to manually hunt for such images, much like finding a needle in a haystack. We present a no-code end-to-end pipeline, Curator, which dramatically minimizes the time taken to curate an exhaustive labeled dataset. Curator is able to search massive amounts of unlabelled data by combining self-supervision, scalable nearest neighbor search, and active learning to learn and differentiate image representations. The pipeline can also be readily applied to solve problems across different domains. Overall, the pipeline makes it practical for researchers to go from just one reference image to a comprehensive dataset in a diminutive span of time."}
{"link":"http://arxiv.org/abs/2301.03325v1","created":"2023-01-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1842144295,"_task_hash":279884475,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476837,"text":"EMAHA-DB1: A New Upper Limb sEMG Dataset for Classification of Activities of Daily Living\nIn this paper, we present electromyography analysis of human activity - database 1 (EMAHA-DB1), a novel dataset of multi-channel surface electromyography (sEMG) signals to evaluate the activities of daily living (ADL). The dataset is acquired from 25 able-bodied subjects while performing 22 activities categorised according to functional arm activity behavioral system (FAABOS) (3 - full hand gestures, 6 - open/close office draw, 8 - grasping and holding of small office objects, 2 - flexion and extension of finger movements, 2 - writing and 1 - rest). The sEMG data is measured by a set of five Noraxon Ultium wireless sEMG sensors with Ag/Agcl electrodes placed on a human hand. The dataset is analyzed for hand activity recognition classification performance. The classification is performed using four state-ofthe-art machine learning classifiers, including Random Forest (RF), Fine K-Nearest Neighbour (KNN), Ensemble KNN (sKNN) and Support Vector Machine (SVM) with seven combinations of time domain and frequency domain feature sets. The state-of-theart classification accuracy on five FAABOS categories is 83:21% by using the SVM classifier with the third order polynomial kernel using energy feature and auto regressive feature set ensemble. The classification accuracy on 22 class hand activities is 75:39% by the same SVM classifier with the log moments in frequency domain (LMF) feature, modified LMF, time domain statistical (TDS) feature, spectral band powers (SBP), channel cross correlation and local binary patterns (LBP) set ensemble. The analysis depicts the technical challenges addressed by the dataset. The developed dataset can be used as a benchmark for various classification methods as well as for sEMG signal analysis corresponding to ADL and for the development of prosthetics and other wearable robotics."}
{"link":"http://arxiv.org/abs/2212.06501v1","created":"2022-12-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1523901619,"_task_hash":1085623469,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476842,"text":"Subjective Sleepiness Dynamics Dataset (SSDD) Presentation: the Study of Two Scales Consistency\nWhile the first references to the system of sleepiness assessment are associated with medical re-search and the study of the effects of drugs on sleep, currently subjective sleepiness assessment is widely used across fundamental and practically oriented studies. The Stanford Sleepiness Scale (SSS) and the Karolinska Sleepiness Scale (KSS) are often used as ground truth in sleepiness re-search. Only a few studies applied both scales and practically none aimed at studying their con-sistency and specific features. The present study is devoted to analyzing the dynamics and con-sistency of subjective sleepiness as measured by the KSS and the SSS in the adult population. A particular task of the paper is to present the Subjective Sleepiness Dynamics Dataset (SSDD) with the evening and morning dynamics of situational subjective sleepiness. A total of 208 adults took part in the experiment. The results of the study revealed that sleepiness generally increased from evening till night and was maximal at early morning. The SSS score appeared to be more sensitive to some factors (e.g., the presence of sleep problems). The SSS and KSS scores were strongly consistent with each other. The KSS showed a generally more even distribution than the SSS. SSDD continues to be collected, we are going to equalize the sample by sex, we are actively adding older people. We plan to collect a sample of 1,000 people. Currently SSDD contains a lot of in-formation that can be used for scientific research."}
{"link":"http://arxiv.org/abs/2212.06200v1","created":"2022-12-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":547112206,"_task_hash":-601165054,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476844,"text":"Breaking the \"Object\" in Video Object Segmentation\nThe appearance of an object can be fleeting when it transforms. As eggs are broken or paper is torn, their color, shape and texture can change dramatically, preserving virtually nothing of the original except for the identity itself. Yet, this important phenomenon is largely absent from existing video object segmentation (VOS) benchmarks. In this work, we close the gap by collecting a new dataset for Video Object Segmentation under Transformations (VOST). It consists of more than 700 high-resolution videos, captured in diverse environments, which are 20 seconds long on average and densely labeled with instance masks. A careful, multi-step approach is adopted to ensure that these videos focus on complex object transformations, capturing their full temporal extent. We then extensively evaluate state-of-the-art VOS methods and make a number of important discoveries. In particular, we show that existing methods struggle when applied to this novel task and that their main limitation lies in over-reliance on static appearance cues. This motivates us to propose a few modifications for the top-performing baseline that improve its capabilities by better modeling spatio-temporal information. But more broadly, the hope is to stimulate discussion on learning more robust video object representations."}
{"link":"http://arxiv.org/abs/2212.14474v1","created":"2022-12-29","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1691869644,"_task_hash":-976983144,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476848,"text":"Learning 3D Human Pose Estimation from Dozens of Datasets using a Geometry-Aware Autoencoder to Bridge Between Skeleton Formats\nDeep learning-based 3D human pose estimation performs best when trained on large amounts of labeled data, making combined learning from many datasets an important research direction. One obstacle to this endeavor are the different skeleton formats provided by different datasets, i.e., they do not label the same set of anatomical landmarks. There is little prior research on how to best supervise one model with such discrepant labels. We show that simply using separate output heads for different skeletons results in inconsistent depth estimates and insufficient information sharing across skeletons. As a remedy, we propose a novel affine-combining autoencoder (ACAE) method to perform dimensionality reduction on the number of landmarks. The discovered latent 3D points capture the redundancy among skeletons, enabling enhanced information sharing when used for consistency regularization. Our approach scales to an extreme multi-dataset regime, where we use 28 3D human pose datasets to supervise one model, which outperforms prior work on a range of benchmarks, including the challenging 3D Poses in the Wild (3DPW) dataset. Our code and models are available for research purposes."}
{"link":"http://arxiv.org/abs/2212.13892v1","created":"2022-12-22","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1913602119,"_task_hash":-608933990,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476850,"text":"Cross-Dataset Propensity Estimation for Debiasing Recommender Systems\nDatasets for training recommender systems are often subject to distribution shift induced by users' and recommenders' selection biases. In this paper, we study the impact of selection bias on datasets with different quantization. We then leverage two differently quantized datasets from different source distributions to mitigate distribution shift by applying the inverse probability scoring method from causal inference. Empirically, our approach gains significant performance improvement over single-dataset methods and alternative ways of combining two datasets."}
{"link":"http://arxiv.org/abs/2212.09272v1","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":752680824,"_task_hash":1206292119,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476859,"text":"Statistical Dataset Evaluation: Reliability, Difficulty, and Validity\nDatasets serve as crucial training resources and model performance trackers. However, existing datasets have exposed a plethora of problems, inducing biased models and unreliable evaluation results. In this paper, we propose a model-agnostic dataset evaluation framework for automatic dataset quality evaluation. We seek the statistical properties of the datasets and address three fundamental dimensions: reliability, difficulty, and validity, following a classical testing theory. Taking the Named Entity Recognition (NER) datasets as a case study, we introduce $9$ statistical metrics for a statistical dataset evaluation framework. Experimental results and human evaluation validate that our evaluation framework effectively assesses various aspects of the dataset quality. Furthermore, we study how the dataset scores on our statistical metrics affect the model performance, and appeal for dataset quality evaluation or targeted dataset improvement before training or testing models."}
{"link":"http://arxiv.org/abs/2212.07162v1","created":"2022-12-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":481875369,"_task_hash":1407035370,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476882,"text":"Building and Evaluating Universal Named-Entity Recognition English corpus\nThis article presents the application of the Universal Named Entity framework to generate automatically annotated corpora. By using a workflow that extracts Wikipedia data and meta-data and DBpedia information, we generated an English dataset which is described and evaluated. Furthermore, we conducted a set of experiments to improve the annotations in terms of precision, recall, and F1-measure. The final dataset is available and the established workflow can be applied to any language with existing Wikipedia and DBpedia. As part of future research, we intend to continue improving the annotation process and extend it to other languages."}
{"link":"http://arxiv.org/abs/2212.07738v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-2009488486,"_task_hash":-1044052929,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476894,"text":"A large-scale and PCR-referenced vocal audio dataset for COVID-19\nThe UK COVID-19 Vocal Audio Dataset is designed for the training and evaluation of machine learning models that classify SARS-CoV-2 infection status or associated respiratory symptoms using vocal audio. The UK Health Security Agency recruited voluntary participants through the national Test and Trace programme and the REACT-1 survey in England from March 2021 to March 2022, during dominant transmission of the Alpha and Delta SARS-CoV-2 variants and some Omicron variant sublineages. Audio recordings of volitional coughs, exhalations, and speech were collected in the 'Speak up to help beat coronavirus' digital survey alongside demographic, self-reported symptom and respiratory condition data, and linked to SARS-CoV-2 test results. The UK COVID-19 Vocal Audio Dataset represents the largest collection of SARS-CoV-2 PCR-referenced audio recordings to date. PCR results were linked to 70,794 of 72,999 participants and 24,155 of 25,776 positive cases. Respiratory symptoms were reported by 45.62% of participants. This dataset has additional potential uses for bioacoustics research, with 11.30% participants reporting asthma, and 27.20% with linked influenza PCR test results."}
{"link":"http://arxiv.org/abs/2212.13442v1","created":"2022-12-27","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1679225066,"_task_hash":1092727729,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476897,"text":"Audiovisual Database with 360 Video and Higher-Order Ambisonics Audio for Perception, Cognition, Behavior, and QoE Evaluation Research\nResearch into multi-modal perception, human cognition, behavior, and attention can benefit from high-fidelity content that may recreate real-life-like scenes when rendered on head-mounted displays. Moreover, aspects of audiovisual perception, cognitive processes, and behavior may complement questionnaire-based Quality of Experience (QoE) evaluation of interactive virtual environments. Currently, there is a lack of high-quality open-source audiovisual databases that can be used to evaluate such aspects or systems capable of reproducing high-quality content. With this paper, we provide a publicly available audiovisual database consisting of twelve scenes capturing real-life nature and urban environments with a video resolution of 7680x3840 at 60 frames-per-second and with 4th-order Ambisonics audio. These 360 video sequences, with an average duration of 60 seconds, represent real-life settings for systematically evaluating various dimensions of uni-/multi-modal perception, cognition, behavior, and QoE. The paper provides details of the scene requirements, recording approach, and scene descriptions. The database provides high-quality reference material with a balanced focus on auditory and visual sensory information. The database will be continuously updated with additional scenes and further metadata such as human ratings and saliency information."}
{"link":"http://arxiv.org/abs/2212.13059v1","created":"2022-12-26","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1733805799,"_task_hash":-649726892,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476912,"text":"OMSN and FAROS: OCTA Microstructure Segmentation Network and Fully Annotated Retinal OCTA Segmentation Dataset\nThe lack of efficient segmentation methods and fully-labeled datasets limits the comprehensive assessment of optical coherence tomography angiography (OCTA) microstructures like retinal vessel network (RVN) and foveal avascular zone (FAZ), which are of great value in ophthalmic and systematic diseases evaluation. Here, we introduce an innovative OCTA microstructure segmentation network (OMSN) by combining an encoder-decoder-based architecture with multi-scale skip connections and the split-attention-based residual network ResNeSt, paying specific attention to OCTA microstructural features while facilitating better model convergence and feature representations. The proposed OMSN achieves excellent single/multi-task performances for RVN or/and FAZ segmentation. Especially, the evaluation metrics on multi-task models outperform single-task models on the same dataset. On this basis, a fully annotated retinal OCTA segmentation (FAROS) dataset is constructed semi-automatically, filling the vacancy of a pixel-level fully-labeled OCTA dataset. OMSN multi-task segmentation model retrained with FAROS further certifies its outstanding accuracy for simultaneous RVN and FAZ segmentation."}
{"link":"http://arxiv.org/abs/2212.09981v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1191663334,"_task_hash":-316151319,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476929,"text":"Benchmarking person re-identification datasets and approaches for practical real-world implementations\nRecently, Person Re-Identification (Re-ID) has received a lot of attention. Large datasets containing labeled images of various individuals have been released, allowing researchers to develop and test many successful approaches. However, when such Re-ID models are deployed in new cities or environments, the task of searching for people within a network of security cameras is likely to face an important domain shift, thus resulting in decreased performance. Indeed, while most public datasets were collected in a limited geographic area, images from a new city present different features (e.g., people's ethnicity and clothing style, weather, architecture, etc.). In addition, the whole frames of the video streams must be converted into cropped images of people using pedestrian detection models, which behave differently from the human annotators who created the dataset used for training. To better understand the extent of this issue, this paper introduces a complete methodology to evaluate Re-ID approaches and training datasets with respect to their suitability for unsupervised deployment for live operations. This method is used to benchmark four Re-ID approaches on three datasets, providing insight and guidelines that can help to design better Re-ID pipelines in the future."}
{"link":"http://arxiv.org/abs/2301.00891v1","created":"2023-01-02","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-74006928,"_task_hash":-1751599007,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476941,"text":"Understanding Political Polarisation using Language Models: A dataset and method\nOur paper aims to analyze political polarization in US political system using Language Models, and thereby help candidates make an informed decision. The availability of this information will help voters understand their candidates views on the economy, healthcare, education and other social issues. Our main contributions are a dataset extracted from Wikipedia that spans the past 120 years and a Language model based method that helps analyze how polarized a candidate is. Our data is divided into 2 parts, background information and political information about a candidate, since our hypothesis is that the political views of a candidate should be based on reason and be independent of factors such as birthplace, alma mater, etc. We further split this data into 4 phases chronologically, to help understand if and how the polarization amongst candidates changes. This data has been cleaned to remove biases. To understand the polarization we begin by showing results from some classical language models in Word2Vec and Doc2Vec. And then use more powerful techniques like the Longformer, a transformer based encoder, to assimilate more information and find the nearest neighbors of each candidate based on their political view and their background."}
{"link":"http://arxiv.org/abs/2301.01197v1","created":"2023-01-03","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":614470110,"_task_hash":-933824876,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476955,"text":"Backdoor Attacks Against Dataset Distillation\nDataset distillation has emerged as a prominent technique to improve data efficiency when training machine learning models. It encapsulates the knowledge from a large dataset into a smaller synthetic dataset. A model trained on this smaller distilled dataset can attain comparable performance to a model trained on the original training dataset. However, the existing dataset distillation techniques mainly aim at achieving the best trade-off between resource usage efficiency and model utility. The security risks stemming from them have not been explored. This study performs the first backdoor attack against the models trained on the data distilled by dataset distillation models in the image domain. Concretely, we inject triggers into the synthetic data during the distillation procedure rather than during the model training stage, where all previous attacks are performed. We propose two types of backdoor attacks, namely NAIVEATTACK and DOORPING. NAIVEATTACK simply adds triggers to the raw data at the initial distillation phase, while DOORPING iteratively updates the triggers during the entire distillation procedure. We conduct extensive evaluations on multiple datasets, architectures, and dataset distillation techniques. Empirical evaluation shows that NAIVEATTACK achieves decent attack success rate (ASR) scores in some cases, while DOORPING reaches higher ASR scores (close to 1.0) in all cases. Furthermore, we conduct a comprehensive ablation study to analyze the factors that may affect the attack performance. Finally, we evaluate multiple defense mechanisms against our backdoor attacks and show that our attacks can practically circumvent these defense mechanisms."}
{"link":"http://arxiv.org/abs/2212.12478v1","created":"2022-12-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":544621877,"_task_hash":161706213,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476960,"text":"Image Classification with Small Datasets: Overview and Benchmark\nImage classification with small datasets has been an active research area in the recent past. However, as research in this scope is still in its infancy, two key ingredients are missing for ensuring reliable and truthful progress: a systematic and extensive overview of the state of the art, and a common benchmark to allow for objective comparisons between published methods. This article addresses both issues. First, we systematically organize and connect past studies to consolidate a community that is currently fragmented and scattered. Second, we propose a common benchmark that allows for an objective comparison of approaches. It consists of five datasets spanning various domains (e.g., natural images, medical imagery, satellite data) and data types (RGB, grayscale, multispectral). We use this benchmark to re-evaluate the standard cross-entropy baseline and ten existing methods published between 2017 and 2021 at renowned venues. Surprisingly, we find that thorough hyper-parameter tuning on held-out validation data results in a highly competitive baseline and highlights a stunted growth of performance over the years. Indeed, only a single specialized method dating back to 2019 clearly wins our benchmark and outperforms the baseline classifier."}
{"link":"http://arxiv.org/abs/2212.12061v1","created":"2022-12-22","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1580026760,"_task_hash":1762688300,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476967,"text":"MN-DS: A Multilabeled News Dataset for News Articles Hierarchical Classification\nThis article presents a dataset of 10,917 news articles with hierarchical news categories collected between January 1st 2019, and December 31st 2019. We manually labelled the articles based on a hierarchical taxonomy with 17 first-level and 109 second-level categories. This dataset can be used to train machine learning models for automatically classifying news articles by topic. This dataset can be helpful for researchers working on news structuring, classification, and predicting future events based on released news."}
{"link":"http://arxiv.org/abs/2212.12645v1","created":"2022-12-24","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":143537972,"_task_hash":-399335008,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678476980,"text":"HandsOff: Labeled Dataset Generation With No Additional Human Annotations\nRecent work leverages the expressive power of generative adversarial networks (GANs) to generate labeled synthetic datasets. These dataset generation methods often require new annotations of synthetic images, which forces practitioners to seek out annotators, curate a set of synthetic images, and ensure the quality of generated labels. We introduce the HandsOff framework, a technique capable of producing an unlimited number of synthetic images and corresponding labels after being trained on less than 50 pre-existing labeled images. Our framework avoids the practical drawbacks of prior work by unifying the field of GAN inversion with dataset generation. We generate datasets with rich pixel-wise labels in multiple challenging domains such as faces, cars, full-body human poses, and urban driving scenes. Our method achieves state-of-the-art performance in semantic segmentation, keypoint detection, and depth estimation compared to prior dataset generation approaches and transfer learning baselines. We additionally showcase its ability to address broad challenges in model development which stem from fixed, hand-annotated datasets, such as the long-tail problem in semantic segmentation."}
{"link":"http://arxiv.org/abs/2212.10428v2","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1624291315,"_task_hash":846124050,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476987,"text":"HouseCat6D -- A Large-Scale Multi-Modal Category Level 6D Object Pose Dataset with Household Objects in Realistic Scenarios\nEstimating the 6D pose of objects is one of the major fields in 3D computer vision. Since the promising outcomes from instance-level pose estimation, the research trends are heading towards category-level pose estimation for more practical application scenarios. However, unlike well-established instance-level pose datasets, available category-level datasets lack annotation quality and provided pose quantity. We propose the new category level 6D pose dataset HouseCat6D featuring 1) Multi-modality of Polarimetric RGB+P and Depth, 2) Highly diverse 194 objects of 10 household object categories including 2 photometrically challenging categories, 3) High-quality pose annotation with an error range of only 1.35 mm to 1.74 mm, 4) 41 large scale scenes with extensive viewpoint coverage, 5) Checkerboard-free environment throughout the entire scene. We also provide benchmark results of state-of-the-art category-level pose estimation networks."}
{"link":"http://arxiv.org/abs/2301.12515v1","created":"2023-01-29","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":2092538671,"_task_hash":445698791,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678476998,"text":"LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D Object Detection\nLiDAR devices are widely used in autonomous driving scenarios and researches on 3D point cloud achieve remarkable progress over the past years. However, deep learning-based methods heavily rely on the annotation data and often face the domain generalization problem. Unlike 2D images whose domains are usually related to the texture information, the feature extracted from the 3D point cloud is affected by the distribution of the points. Due to the lack of a 3D domain adaptation benchmark, the common practice is to train the model on one benchmark (e.g, Waymo) and evaluate it on another dataset (e.g. KITTI). However, in this setting, there are two types of domain gaps, the scenarios domain, and sensors domain, making the evaluation and analysis complicated and difficult. To handle this situation, we propose LiDAR Dataset with Cross-Sensors (LiDAR-CS Dataset), which contains large-scale annotated LiDAR point cloud under 6 groups of different sensors but with same corresponding scenarios, captured from hybrid realistic LiDAR simulator. As far as we know, LiDAR-CS Dataset is the first dataset focused on the sensor (e.g., the points distribution) domain gaps for 3D object detection in real traffic. Furthermore, we evaluate and analyze the performance with several baseline detectors on the LiDAR-CS benchmark and show its applications."}
{"link":"http://arxiv.org/abs/2303.05345v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":646876553,"_task_hash":-486477113,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477003,"text":"TGDataset: a Collection of Over One Hundred Thousand Telegram Channels\nTelegram is one of the most popular instant messaging apps in today's digital age. In addition to providing a private messaging service, Telegram, with its channels, represents a valid medium for rapidly broadcasting content to a large audience (COVID-19 announcements), but, unfortunately, also for disseminating radical ideologies and coordinating attacks (Capitol Hill riot). This paper presents the TGDataset, a new dataset that includes 120,979 Telegram channels and over 400 million messages, making it the largest collection of Telegram channels to the best of our knowledge. After a brief introduction to the data collection process, we analyze the languages spoken within our dataset and the topic covered by English channels. Finally, we discuss some use cases in which our dataset can be extremely useful to understand better the Telegram ecosystem, as well as to study the diffusion of questionable news. In addition to the raw dataset, we released the scripts we used to analyze the dataset and the list of channels belonging to the network of a new conspiracy theory called Sabmyk."}
{"link":"http://arxiv.org/abs/2212.09306v1","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1747964955,"_task_hash":1918165373,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477006,"text":"E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text\nIdentifying named entities such as a person, location or organization, in documents can highlight key information to readers. Training Named Entity Recognition (NER) models requires an annotated data set, which can be a time-consuming labour-intensive task. Nevertheless, there are publicly available NER data sets for general English. Recently there has been interest in developing NER for legal text. However, prior work and experimental results reported here indicate that there is a significant degradation in performance when NER methods trained on a general English data set are applied to legal text. We describe a publicly available legal NER data set, called E-NER, based on legal company filings available from the US Securities and Exchange Commission's EDGAR data set. Training a number of different NER algorithms on the general English CoNLL-2003 corpus but testing on our test collection confirmed significant degradations in accuracy, as measured by the F1-score, of between 29.4\\% and 60.4\\%, compared to training and testing on the E-NER collection."}
{"link":"http://arxiv.org/abs/2212.14732v1","created":"2022-12-27","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1003667252,"_task_hash":-1672156450,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477659,"text":"Lab-scale Vibration Analysis Dataset and Baseline Methods for Machinery Fault Diagnosis with Machine Learning\nThe monitoring of machine conditions in a plant is crucial for production in manufacturing. A sudden failure of a machine can stop production and cause a loss of revenue. The vibration signal of a machine is a good indicator of its condition. This paper presents a dataset of vibration signals from a lab-scale machine. The dataset contains four different types of machine conditions: normal, unbalance, misalignment, and bearing fault. Three machine learning methods (SVM, KNN, and GNB) evaluated the dataset, and a perfect result was obtained by one of the methods on a 1-fold test. The performance of the algorithms is evaluated using weighted accuracy (WA) since the data is balanced. The results show that the best-performing algorithm is the SVM with a WA of 99.75\\% on the 5-fold cross-validations. The dataset is provided in the form of CSV files in an open and free repository at https://zenodo.org/record/7006575."}
{"link":"http://arxiv.org/abs/2212.13929v1","created":"2022-12-28","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":758541834,"_task_hash":-1918683441,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477669,"text":"Evaluating Generalizability of Deep Learning Models Using Indian-COVID-19 CT Dataset\nComputer tomography (CT) have been routinely used for the diagnosis of lung diseases and recently, during the pandemic, for detecting the infectivity and severity of COVID-19 disease. One of the major concerns in using ma-chine learning (ML) approaches for automatic processing of CT scan images in clinical setting is that these methods are trained on limited and biased sub-sets of publicly available COVID-19 data. This has raised concerns regarding the generalizability of these models on external datasets, not seen by the model during training. To address some of these issues, in this work CT scan images from confirmed COVID-19 data obtained from one of the largest public repositories, COVIDx CT 2A were used for training and internal vali-dation of machine learning models. For the external validation we generated Indian-COVID-19 CT dataset, an open-source repository containing 3D CT volumes and 12096 chest CT images from 288 COVID-19 patients from In-dia. Comparative performance evaluation of four state-of-the-art machine learning models, viz., a lightweight convolutional neural network (CNN), and three other CNN based deep learning (DL) models such as VGG-16, ResNet-50 and Inception-v3 in classifying CT images into three classes, viz., normal, non-covid pneumonia, and COVID-19 is carried out on these two datasets. Our analysis showed that the performance of all the models is comparable on the hold-out COVIDx CT 2A test set with 90% - 99% accuracies (96% for CNN), while on the external Indian-COVID-19 CT dataset a drop in the performance is observed for all the models (8% - 19%). The traditional ma-chine learning model, CNN performed the best on the external dataset (accu-racy 88%) in comparison to the deep learning models, indicating that a light-weight CNN is better generalizable on unseen data. The data and code are made available at https://github.com/aleesuss/c19."}
{"link":"http://arxiv.org/abs/2301.03591v1","created":"2023-01-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1531159190,"_task_hash":697985282,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477672,"text":"PatentsView-Evaluation: Evaluation Datasets and Tools to Advance Research on Inventor Name Disambiguation\nWe present PatentsView-Evaluation, a Python package that enables researchers to evaluate the performance of inventor name disambiguation systems such as PatentsView.org. The package includes benchmark datasets and evaluation tools, and aims to advance research on inventor name disambiguation by providing access to high-quality evaluation data and improving evaluation standards."}
{"link":"http://arxiv.org/abs/2301.02773v1","created":"2023-01-07","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-988991870,"_task_hash":-737727005,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477677,"text":"Building a Parallel Corpus and Training Translation Models Between Luganda and English\nNeural machine translation (NMT) has achieved great successes with large datasets, so NMT is more premised on high-resource languages. This continuously underpins the low resource languages such as Luganda due to the lack of high-quality parallel corpora, so even 'Google translate' does not serve Luganda at the time of this writing. In this paper, we build a parallel corpus with 41,070 pairwise sentences for Luganda and English which is based on three different open-sourced corpora. Then, we train NMT models with hyper-parameter search on the dataset. Experiments gave us a BLEU score of 21.28 from Luganda to English and 17.47 from English to Luganda. Some translation examples show high quality of the translation. We believe that our model is the first Luganda-English NMT model. The bilingual dataset we built will be available to the public."}
{"link":"http://arxiv.org/abs/2212.07564v2","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":2118754020,"_task_hash":877197045,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477682,"text":"AirfRANS: High Fidelity Computational Fluid Dynamics Dataset for Approximating Reynolds-Averaged Navier-Stokes Solutions\nSurrogate models are necessary to optimize meaningful quantities in physical dynamics as their recursive numerical resolutions are often prohibitively expensive. It is mainly the case for fluid dynamics and the resolution of Navier-Stokes equations. However, despite the fast-growing field of data-driven models for physical systems, reference datasets representing real-world phenomena are lacking. In this work, we develop AirfRANS, a dataset for studying the two-dimensional incompressible steady-state Reynolds-Averaged Navier-Stokes equations over airfoils at a subsonic regime and for different angles of attacks. We also introduce metrics on the stress forces at the surface of geometries and visualization of boundary layers to assess the capabilities of models to accurately predict the meaningful information of the problem. Finally, we propose deep learning baselines on four machine learning tasks to study AirfRANS under different constraints for generalization considerations: big and scarce data regime, Reynolds number, and angle of attack extrapolation."}
{"link":"http://arxiv.org/abs/2301.12500v1","created":"2023-01-29","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-366177452,"_task_hash":-856296808,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477693,"text":"BERT-based Authorship Attribution on the Romanian Dataset called ROST\nBeing around for decades, the problem of Authorship Attribution is still very much in focus currently. Some of the more recent instruments used are the pre-trained language models, the most prevalent being BERT. Here we used such a model to detect the authorship of texts written in the Romanian language. The dataset used is highly unbalanced, i.e., significant differences in the number of texts per author, the sources from which the texts were collected, the time period in which the authors lived and wrote these texts, the medium intended to be read (i.e., paper or online), and the type of writing (i.e., stories, short stories, fairy tales, novels, literary articles, and sketches). The results are better than expected, sometimes exceeding 87\\% macro-accuracy."}
{"link":"http://arxiv.org/abs/2212.10108v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":106154423,"_task_hash":398977010,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477697,"text":"Efficient aggregation of face embeddings for decentralized face recognition deployments (extended version)\nBiometrics are one of the most privacy-sensitive data. Ubiquitous authentication systems with a focus on privacy favor decentralized approaches as they reduce potential attack vectors, both on a technical and organizational level. The gold standard is to let the user be in control of where their own data is stored, which consequently leads to a high variety of devices used. Moreover, in comparison with a centralized system, designs with higher end-user freedom often incur additional network overhead. Therefore, when using face recognition for biometric authentication, an efficient way to compare faces is important in practical deployments, because it reduces both network and hardware requirements that are essential to encourage device diversity. This paper proposes an efficient way to aggregate embeddings used for face recognition based on an extensive analysis on different datasets and the use of different aggregation strategies. As part of this analysis, a new dataset has been collected, which is available for research purposes. Our proposed method supports the construction of massively scalable, decentralized face recognition systems with a focus on both privacy and long-term usability."}
{"link":"http://arxiv.org/abs/2301.03404v1","created":"2023-01-05","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-432457008,"_task_hash":-1253255190,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477704,"text":"CSRCZ: A Dataset About Corporate Social Responsibility in Czech Republic\nAs stakeholders' pressure on corporates for disclosing their corporate social responsibility operations grows, it is crucial to understand how efficient corporate disclosure systems are in bridging the gap between corporate social responsibility reports and their actual practice. Meanwhile, research on corporate social responsibility is still not aligned with the recent data-driven strategies, and little public data are available. This paper aims to describe CSRCZ, a newly created dataset based on disclosure reports from the websites of 1000 companies that operate in Czech Republic. Each company was analyzed based on three main parameters: company size, company industry, and company initiatives. We describe the content of the dataset as well as its potential use for future research. We believe that CSRCZ has implications for further research, since it is the first publicly available dataset of its kind."}
{"link":"http://arxiv.org/abs/2212.10273v1","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1825144801,"_task_hash":-951456033,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477740,"text":"Managing Large Dataset Gaps in Urban Air Quality Prediction: DCU-Insight-AQ at MediaEval 2022\nCalculating an Air Quality Index (AQI) typically uses data streams from air quality sensors deployed at fixed locations and the calculation is a real time process. If one or a number of sensors are broken or offline, then the real time AQI value cannot be computed. Estimating AQI values for some point in the future is a predictive process and uses historical AQI values to train and build models. In this work we focus on gap filling in air quality data where the task is to predict the AQI at 1, 5 and 7 days into the future. The scenario is where one or a number of air, weather and traffic sensors are offline and explores prediction accuracy under such situations. The work is part of the MediaEval'2022 Urban Air: Urban Life and Air Pollution task submitted by the DCU-Insight-AQ team and uses multimodal and crossmodal data consisting of AQI, weather and CCTV traffic images for air pollution prediction."}
{"link":"http://arxiv.org/abs/2212.13805v2","created":"2022-12-28","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-474427912,"_task_hash":2124641074,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477743,"text":"Swin MAE: Masked Autoencoders for Small Datasets\nThe development of deep learning models in medical image analysis is majorly limited by the lack of large-sized and well-annotated datasets. Unsupervised learning does not require labels and is more suitable for solving medical image analysis problems. However, most of the current unsupervised learning methods need to be applied to large datasets. To make unsupervised learning applicable to small datasets, we proposed Swin MAE, which is a masked autoencoder with Swin Transformer as its backbone. Even on a dataset of only a few thousand medical images and without using any pre-trained models, Swin MAE is still able to learn useful semantic features purely from images. It can equal or even slightly outperform the supervised model obtained by Swin Transformer trained on ImageNet in terms of the transfer learning results of downstream tasks. The code is publicly available at https://github.com/Zian-Xu/Swin-MAE."}
{"link":"http://arxiv.org/abs/2212.10735v1","created":"2022-12-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-195132232,"_task_hash":1462764942,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477772,"text":"NADBenchmarks -- a compilation of Benchmark Datasets for Machine Learning Tasks related to Natural Disasters\nClimate change has increased the intensity, frequency, and duration of extreme weather events and natural disasters across the world. While the increased data on natural disasters improves the scope of machine learning (ML) in this field, progress is relatively slow. One bottleneck is the lack of benchmark datasets that would allow ML researchers to quantify their progress against a standard metric. The objective of this short paper is to explore the state of benchmark datasets for ML tasks related to natural disasters, categorizing them according to the disaster management cycle. We compile a list of existing benchmark datasets introduced in the past five years. We propose a web platform - NADBenchmarks - where researchers can search for benchmark datasets for natural disasters, and we develop a preliminary version of such a platform using our compiled list. This paper is intended to aid researchers in finding benchmark datasets to train their ML models on, and provide general directions for topics where they can contribute new benchmark datasets."}
{"link":"http://arxiv.org/abs/2302.07901v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":441159331,"_task_hash":-1028253248,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477775,"text":"Search for scalar induced gravitational waves in the International Pulsar Timing Array Data Release 2 and NANOgrav 12.5 years dataset\nWe perform a Bayesian search in the latest Pulsar Timing Array (PTA) datasets for a stochastic gravitational wave (GW) background sourced by curvature perturbations at scales $10^5~\\text{Mpc}^{-1}\\lesssim k\\lesssim 10^8~\\text{Mpc}^{-1}$. These re-enter the Hubble horizon at temperatures around and below the QCD crossover phase transition in the early Universe. We include a stochastic background of astrophysical origin in our search and properly account for constraints on the curvature power spectrum from the overproduction of primordial black holes (PBHs). We find that the International PTA Data Release 2 significantly favors the astrophysical model for its reported common-spectrum process, over the curvature-induced background. On the other hand, the two interpretations fit the NANOgrav 12.5 years dataset equally well. We then set new upper limits on the amplitude of the curvature power spectrum at small scales. These are independent from, and competitive with, indirect astrophysical bounds from the abundance of PBH dark matter. Upcoming PTA data releases will provide the strongest probe of the curvature power spectrum around the QCD epoch."}
{"link":"http://arxiv.org/abs/2212.10080v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1102354536,"_task_hash":-669118809,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477779,"text":"Rumour detection using graph neural network and oversampling in benchmark Twitter dataset\nRecently, online social media has become a primary source for new information and misinformation or rumours. In the absence of an automatic rumour detection system the propagation of rumours has increased manifold leading to serious societal damages. In this work, we propose a novel method for building automatic rumour detection system by focusing on oversampling to alleviating the fundamental challenges of class imbalance in rumour detection task. Our oversampling method relies on contextualised data augmentation to generate synthetic samples for underrepresented classes in the dataset. The key idea exploits selection of tweets in a thread for augmentation which can be achieved by introducing a non-random selection criteria to focus the augmentation process on relevant tweets. Furthermore, we propose two graph neural networks(GNN) to model non-linear conversations on a thread. To enhance the tweet representations in our method we employed a custom feature selection technique based on state-of-the-art BERTweet model. Experiments of three publicly available datasets confirm that 1) our GNN models outperform the the current state-of-the-art classifiers by more than 20%(F1-score); 2) our oversampling technique increases the model performance by more than 9%;(F1-score) 3) focusing on relevant tweets for data augmentation via non-random selection criteria can further improve the results; and 4) our method has superior capabilities to detect rumours at very early stage."}
{"link":"http://arxiv.org/abs/2302.07797v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-877399781,"_task_hash":1703925360,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477782,"text":"'Aariz: A Benchmark Dataset for Automatic Cephalometric Landmark Detection and CVM Stage Classification\nThe accurate identification and precise localization of cephalometric landmarks enable the classification and quantification of anatomical abnormalities. The traditional way of marking cephalometric landmarks on lateral cephalograms is a monotonous and time-consuming job. Endeavours to develop automated landmark detection systems have persistently been made, however, they are inadequate for orthodontic applications due to unavailability of a reliable dataset. We proposed a new state-of-the-art dataset to facilitate the development of robust AI solutions for quantitative morphometric analysis. The dataset includes 1000 lateral cephalometric radiographs (LCRs) obtained from 7 different radiographic imaging devices with varying resolutions, making it the most diverse and comprehensive cephalometric dataset to date. The clinical experts of our team meticulously annotated each radiograph with 29 cephalometric landmarks, including the most significant soft tissue landmarks ever marked in any publicly available dataset. Additionally, our experts also labelled the cervical vertebral maturation (CVM) stage of the patient in a radiograph, making this dataset the first standard resource for CVM classification. We believe that this dataset will be instrumental in the development of reliable automated landmark detection frameworks for use in orthodontics and beyond."}
{"link":"http://arxiv.org/abs/2212.10152v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1336574577,"_task_hash":1870498866,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477821,"text":"Quirk or Palmer: A Comparative Study of Modal Verb Frameworks with Annotated Datasets\nModal verbs, such as \"can\", \"may\", and \"must\", are commonly used in daily communication to convey the speaker's perspective related to the likelihood and/or mode of the proposition. They can differ greatly in meaning depending on how they're used and the context of a sentence (e.g. \"They 'must' help each other out.\" vs. \"They 'must' have helped each other out.\") Despite their practical importance in natural language understanding, linguists have yet to agree on a single, prominent framework for the categorization of modal verb senses. This lack of agreement stems from high degrees of flexibility and polysemy from the modal verbs, making it more difficult for researchers to incorporate insights from this family of words into their work. This work presents Moverb dataset, which consists of 27,240 annotations of modal verb senses over 4,540 utterances containing one or more sentences from social conversations. Each utterance is annotated by three annotators using two different theoretical frameworks (i.e., Quirk and Palmer) of modal verb senses. We observe that both frameworks have similar inter-annotator agreements, despite having different numbers of sense types (8 for Quirk and 3 for Palmer). With the RoBERTa-based classifiers fine-tuned on \\dataset, we achieve F1 scores of 82.2 and 78.3 on Quirk and Palmer, respectively, showing that modal verb sense disambiguation is not a trivial task. Our dataset will be publicly available with our final version."}
{"link":"http://arxiv.org/abs/2212.07090v1","created":"2022-12-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-240388143,"_task_hash":-301532627,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477829,"text":"Database Matching Under Adversarial Column Deletions\nThe de-anonymization of users from anonymized microdata through matching or aligning with publicly-available correlated databases has been of scientific interest recently. While most of the rigorous analyses of database matching have focused on random-distortion models, the adversarial-distortion models have been wanting in the relevant literature. In this work, motivated by synchronization errors in the sampling of time-indexed microdata, matching (alignment) of random databases under adversarial column deletions is investigated. It is assumed that a constrained adversary, which observes the anonymized database, can delete up to a $\\delta$ fraction of the columns (attributes) to hinder matching and preserve privacy. Column histograms of the two databases are utilized as permutation-invariant features to detect the column deletion pattern chosen by the adversary. The detection of the column deletion pattern is then followed by an exact row (user) matching scheme. The worst-case analysis of this two-phase scheme yields a sufficient condition for the successful matching of the two databases, under the near-perfect recovery condition. A more detailed investigation of the error probability leads to a tight necessary condition on the database growth rate, and in turn, to a single-letter characterization of the adversarial matching capacity. This adversarial matching capacity is shown to be significantly lower than the \\say{random} matching capacity, where the column deletions occur randomly. Overall, our results analytically demonstrate the privacy-wise advantages of adversarial mechanisms over random ones during the publication of anonymized time-indexed data."}
{"link":"http://arxiv.org/abs/2212.11468v1","created":"2022-12-22","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-890429812,"_task_hash":369512410,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477835,"text":"IPProtect: protecting the intellectual property of visual datasets during data valuation\nData trading is essential to accelerate the development of data-driven machine learning pipelines. The central problem in data trading is to estimate the utility of a seller's dataset with respect to a given buyer's machine learning task, also known as data valuation. Typically, data valuation requires one or more participants to share their raw dataset with others, leading to potential risks of intellectual property (IP) violations. In this paper, we tackle the novel task of preemptively protecting the IP of datasets that need to be shared during data valuation. First, we identify and formalize two kinds of novel IP risks in visual datasets: data-item (image) IP and statistical (dataset) IP. Then, we propose a novel algorithm to convert the raw dataset into a sanitized version, that provides resistance to IP violations, while at the same time allowing accurate data valuation. The key idea is to limit the transfer of information from the raw dataset to the sanitized dataset, thereby protecting against potential intellectual property violations. Next, we analyze our method for the likely existence of a solution and immunity against reconstruction attacks. Finally, we conduct extensive experiments on three computer vision datasets demonstrating the advantages of our method in comparison to other baselines."}
{"link":"http://arxiv.org/abs/2301.00493v1","created":"2023-01-02","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":120438181,"_task_hash":-786968162,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477840,"text":"Argoverse 2: Next Generation Datasets for Self-Driving Perception and Forecasting\nWe introduce Argoverse 2 (AV2) - a collection of three datasets for perception and forecasting research in the self-driving domain. The annotated Sensor Dataset contains 1,000 sequences of multimodal data, encompassing high-resolution imagery from seven ring cameras, and two stereo cameras in addition to lidar point clouds, and 6-DOF map-aligned pose. Sequences contain 3D cuboid annotations for 26 object categories, all of which are sufficiently-sampled to support training and evaluation of 3D perception models. The Lidar Dataset contains 20,000 sequences of unlabeled lidar point clouds and map-aligned pose. This dataset is the largest ever collection of lidar sensor data and supports self-supervised learning and the emerging task of point cloud forecasting. Finally, the Motion Forecasting Dataset contains 250,000 scenarios mined for interesting and challenging interactions between the autonomous vehicle and other actors in each local scene. Models are tasked with the prediction of future motion for \"scored actors\" in each scenario and are provided with track histories that capture object location, heading, velocity, and category. In all three datasets, each scenario contains its own HD Map with 3D lane and crosswalk geometry - sourced from data captured in six distinct cities. We believe these datasets will support new and existing machine learning research problems in ways that existing datasets do not. All datasets are released under the CC BY-NC-SA 4.0 license."}
{"link":"http://arxiv.org/abs/2212.10207v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-723837059,"_task_hash":-1960892721,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477846,"text":"Graph Neural Networks in Computer Vision -- Architectures, Datasets and Common Approaches\nGraph Neural Networks (GNNs) are a family of graph networks inspired by mechanisms existing between nodes on a graph. In recent years there has been an increased interest in GNN and their derivatives, i.e., Graph Attention Networks (GAT), Graph Convolutional Networks (GCN), and Graph Recurrent Networks (GRN). An increase in their usability in computer vision is also observed. The number of GNN applications in this field continues to expand; it includes video analysis and understanding, action and behavior recognition, computational photography, image and video synthesis from zero or few shots, and many more. This contribution aims to collect papers published about GNN-based approaches towards computer vision. They are described and summarized from three perspectives. Firstly, we investigate the architectures of Graph Neural Networks and their derivatives used in this area to provide accurate and explainable recommendations for the ensuing investigations. As for the other aspect, we also present datasets used in these works. Finally, using graph analysis, we also examine relations between GNN-based studies in computer vision and potential sources of inspiration identified outside of this field."}
{"link":"http://arxiv.org/abs/2301.04008v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":254914068,"_task_hash":682593631,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477853,"text":"Balanced Datasets for IoT IDS\nAs the Internet of Things (IoT) continues to grow, cyberattacks are becoming increasingly common. The security of IoT networks relies heavily on intrusion detection systems (IDSs). The development of an IDS that is accurate and efficient is a challenging task. As a result, this challenge is made more challenging by the absence of balanced datasets for training and testing the proposed IDS. In this study, four commonly used datasets are visualized and analyzed visually. Moreover, it proposes a sampling algorithm that generates a sample that represents the original dataset. In addition, it proposes an algorithm to generate a balanced dataset. Researchers can use this paper as a starting point when investigating cybersecurity and machine learning. The proposed sampling algorithms showed reliability in generating well-representing and balanced samples from NSL-KDD, UNSW-NB15, BotNetIoT-01, and BoTIoT datasets."}
{"link":"http://arxiv.org/abs/2212.10455v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1792980348,"_task_hash":-809099055,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477859,"text":"MULTI3NLU++: A Multilingual, Multi-Intent, Multi-Domain Dataset for Natural Language Understanding in Task-Oriented Dialogue\nTask-oriented dialogue (TOD) systems have been applied in a range of domains to support human users to achieve specific goals. Systems are typically constructed for a single domain or language and do not generalise well beyond this. Their extension to other languages in particular is restricted by the lack of available training data for many of the world's languages. To support work on Natural Language Understanding (NLU) in TOD across multiple languages and domains simultaneously, we constructed MULTI3NLU++, a multilingual, multi-intent, multi-domain dataset. MULTI3NLU++ extends the English-only NLU++ dataset to include manual translations into a range of high, medium and low resource languages (Spanish, Marathi, Turkish and Amharic), in two domains (banking and hotels). MULTI3NLU++ inherits the multi-intent property of NLU++, where an utterance may be labelled with multiple intents, providing a more realistic representation of a user's goals and aligning with the more complex tasks that commercial systems aim to model. We use MULTI3NLU++ to benchmark state-of-the-art multilingual language models as well as Machine Translation and Question Answering systems for the NLU task of intent detection for TOD systems in the multilingual setting. The results demonstrate the challenging nature of the dataset, particularly in the low-resource language setting."}
{"link":"http://arxiv.org/abs/2301.01095v1","created":"2023-01-03","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":296351523,"_task_hash":-653523412,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477863,"text":"Database management system performance comparisons: A systematic survey\nEfficiency has been a pivotal aspect of the software industry since its inception, as a system that serves the end-user fast, and the service provider cost-efficiently benefits all parties. A database management system (DBMS) is an integral part of effectively all software systems, and therefore it is logical that different studies have compared the performance of different DBMSs in hopes of finding the most efficient one. This survey systematically synthesizes the results and approaches of studies that compare DBMS performance and provides recommendations for industry and research. The results show that performance is usually tested in a way that does not reflect real-world use cases, and that tests are typically reported in insufficient detail for replication or for drawing conclusions from the stated results."}
{"link":"http://arxiv.org/abs/2301.00595v1","created":"2023-01-02","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1582430487,"_task_hash":-1222367870,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477866,"text":"Chains of Autoreplicative Random Forests for missing value imputation in high-dimensional datasets\nMissing values are a common problem in data science and machine learning. Removing instances with missing values can adversely affect the quality of further data analysis. This is exacerbated when there are relatively many more features than instances, and thus the proportion of affected instances is high. Such a scenario is common in many important domains, for example, single nucleotide polymorphism (SNP) datasets provide a large number of features over a genome for a relatively small number of individuals. To preserve as much information as possible prior to modeling, a rigorous imputation scheme is acutely needed. While Denoising Autoencoders is a state-of-the-art method for imputation in high-dimensional data, they still require enough complete cases to be trained on which is often not available in real-world problems. In this paper, we consider missing value imputation as a multi-label classification problem and propose Chains of Autoreplicative Random Forests. Using multi-label Random Forests instead of neural networks works well for low-sampled data as there are fewer parameters to optimize. Experiments on several SNP datasets show that our algorithm effectively imputes missing values based only on information from the dataset and exhibits better performance than standard algorithms that do not require any additional information. In this paper, the algorithm is implemented specifically for SNP data, but it can easily be adapted for other cases of missing value imputation."}
{"link":"http://arxiv.org/abs/2301.03092v1","created":"2023-01-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-594138049,"_task_hash":-1293842264,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477868,"text":"Deep Injective Prior for Inverse Scattering\nIn electromagnetic inverse scattering, we aim to reconstruct object permittivity from scattered waves. Deep learning is a promising alternative to traditional iterative solvers, but it has been used mostly in a supervised framework to regress the permittivity patterns from scattered fields or back-projections. While such methods are fast at test-time and achieve good results for specific data distributions, they are sensitive to the distribution drift of the scattered fields, common in practice. If the distribution of the scattered fields changes due to changes in frequency, the number of transmitters and receivers, or any other real-world factor, an end-to-end neural network must be re-trained or fine-tuned on a new dataset. In this paper, we propose a new data-driven framework for inverse scattering based on deep generative models. We model the target permittivities by a low-dimensional manifold which acts as a regularizer and learned from data. Unlike supervised methods which require both scattered fields and target signals, we only need the target permittivities for training; it can then be used with any experimental setup. We show that the proposed framework significantly outperforms the traditional iterative methods especially for strong scatterers while having comparable reconstruction quality to state-of-the-art deep learning methods like U-Net."}
{"link":"http://arxiv.org/abs/2212.09937v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1574766765,"_task_hash":-1520768144,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678477874,"text":"AI applications in forest monitoring need remote sensing benchmark datasets\nWith the rise in high resolution remote sensing technologies there has been an explosion in the amount of data available for forest monitoring, and an accompanying growth in artificial intelligence applications to automatically derive forest properties of interest from these datasets. Many studies use their own data at small spatio-temporal scales, and demonstrate an application of an existing or adapted data science method for a particular task. This approach often involves intensive and time-consuming data collection and processing, but generates results restricted to specific ecosystems and sensor types. There is a lack of widespread acknowledgement of how the types and structures of data used affects performance and accuracy of analysis algorithms. To accelerate progress in the field more efficiently, benchmarking datasets upon which methods can be tested and compared are sorely needed.   Here, we discuss how lack of standardisation impacts confidence in estimation of key forest properties, and how considerations of data collection need to be accounted for in assessing method performance. We present pragmatic requirements and considerations for the creation of rigorous, useful benchmarking datasets for forest monitoring applications, and discuss how tools from modern data science can improve use of existing data. We list a set of example large-scale datasets that could contribute to benchmarking, and present a vision for how community-driven, representative benchmarking initiatives could benefit the field."}
{"link":"http://arxiv.org/abs/2212.14569v1","created":"2022-12-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":221426287,"_task_hash":1846027059,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678477876,"text":"A Fine-Grained Vehicle Detection (FGVD) Dataset for Unconstrained Roads\nThe previous fine-grained datasets mainly focus on classification and are often captured in a controlled setup, with the camera focusing on the objects. We introduce the first Fine-Grained Vehicle Detection (FGVD) dataset in the wild, captured from a moving camera mounted on a car. It contains 5502 scene images with 210 unique fine-grained labels of multiple vehicle types organized in a three-level hierarchy. While previous classification datasets also include makes for different kinds of cars, the FGVD dataset introduces new class labels for categorizing two-wheelers, autorickshaws, and trucks. The FGVD dataset is challenging as it has vehicles in complex traffic scenarios with intra-class and inter-class variations in types, scale, pose, occlusion, and lighting conditions. The current object detectors like yolov5 and faster RCNN perform poorly on our dataset due to a lack of hierarchical modeling. Along with providing baseline results for existing object detectors on FGVD Dataset, we also present the results of a combination of an existing detector and the recent Hierarchical Residual Network (HRN) classifier for the FGVD task. Finally, we show that FGVD vehicle images are the most challenging to classify among the fine-grained datasets."}
{"link":"http://arxiv.org/abs/2301.02726v1","created":"2023-01-06","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":680722571,"_task_hash":1178755511,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678478018,"text":"Augmenting Ego-Vehicle for Traffic Near-Miss and Accident Classification Dataset using Manipulating Conditional Style Translation\nTo develop the advanced self-driving systems, many researchers are focusing to alert all possible traffic risk cases from closed-circuit television (CCTV) and dashboard-mounted cameras. Most of these methods focused on identifying frame-by-frame in which an anomaly has occurred, but they are unrealized, which road traffic participant can cause ego-vehicle leading into collision because of available annotation dataset only to detect anomaly on traffic video. Near-miss is one type of accident and can be defined as a narrowly avoided accident. However, there is no difference between accident and near-miss at the time before the accident happened, so our contribution is to redefine the accident definition and re-annotate the accident inconsistency on DADA-2000 dataset together with near-miss. By extending the start and end time of accident duration, our annotation can precisely cover all ego-motions during an incident and consistently classify all possible traffic risk accidents including near-miss to give more critical information for real-world driving assistance systems. The proposed method integrates two different components: conditional style translation (CST) and separable 3-dimensional convolutional neural network (S3D). CST architecture is derived by unsupervised image-to-image translation networks (UNIT) used for augmenting the re-annotation DADA-2000 dataset to increase the number of traffic risk accident videos and to generalize the performance of video classification model on different types of conditions while S3D is useful for video classification to prove dataset re-annotation consistency. In evaluation, the proposed method achieved a significant improvement result by 10.25% positive margin from the baseline model for accuracy on cross-validation analysis."}
{"link":"http://arxiv.org/abs/2212.07612v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1881281381,"_task_hash":-2115355779,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678478021,"text":"TED: Towards Discovering Top-k Edge-Diversified Patterns in a Graph Database\nWith an exponentially growing number of graphs from disparate repositories, there is a strong need to analyze a graph database containing an extensive collection of small- or medium-sized data graphs (e.g., chemical compounds). Although subgraph enumeration and subgraph mining have been proposed to bring insights into a graph database by a set of subgraph structures, they often end up with similar or homogenous topologies, which is undesirable in many graph applications. To address this limitation, we propose the Top-k Edge-Diversified Patterns Discovery problem to retrieve a set of subgraphs that cover the maximum number of edges in a database. To efficiently process such query, we present a generic and extensible framework called Ted which achieves a guaranteed approximation ratio to the optimal result. Two optimization strategies are further developed to improve the performance. Experimental studies on real-world datasets demonstrate the superiority of Ted to traditional techniques."}
{"link":"http://arxiv.org/abs/2302.08121v1","created":"2023-02-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-632696702,"_task_hash":-1165487781,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678478024,"text":"Practically Efficient Secure Computation of Rank-based Statistics Over Distributed Datasets\nIn this paper, we propose a practically efficient model for securely computing rank-based statistics, e.g., median, percentiles and quartiles, over distributed datasets in the malicious setting without leaking individual data privacy. Based on the binary search technique of Aggarwal et al. (EUROCRYPT \\textquotesingle 04), we respectively present an interactive protocol and a non-interactive protocol, involving at most $\\log ||R||$ rounds, where $||R||$ is the range size of the dataset elements. Besides, we introduce a series of optimisation techniques to reduce the round complexity. Our computing model is modular and can be instantiated with either homomorphic encryption or secret-sharing schemes. Compared to the state-of-the-art solutions, it provides stronger security and privacy while maintaining high efficiency and accuracy. Unlike differential-privacy-based solutions, it does not suffer a trade-off between accuracy and privacy. On the other hand, it only involves $O(N \\log ||R||)$ time complexity, which is far more efficient than those bitwise-comparison-based solutions with $O(N^2\\log ||R||)$ time complexity, where $N$ is the dataset size. Finally, we provide a UC-secure instantiation with the threshold Paillier cryptosystem and $\\Sigma$-protocol zero-knowledge proofs of knowledge."}
{"link":"http://arxiv.org/abs/2302.08292v1","created":"2023-02-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1538311929,"_task_hash":201072885,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678478030,"text":"Navya3DSeg -- Navya 3D Semantic Segmentation Dataset & split generation for autonomous vehicles\nAutonomous driving (AD) perception today relies heavily on deep learning based architectures requiring large scale annotated datasets with their associated costs for curation and annotation. The 3D semantic data are useful for core perception tasks such as obstacle detection and ego-vehicle localization. We propose a new dataset, Navya 3D Segmentation (Navya3DSeg), with a diverse label space corresponding to a large scale production grade operational domain, including rural, urban, industrial sites and universities from 13 countries. It contains 23 labeled sequences and 25 supplementary sequences without labels, designed to explore self-supervised and semi-supervised semantic segmentation benchmarks on point clouds. We also propose a novel method for sequential dataset split generation based on iterative multi-label stratification, and demonstrated to achieve a +1.2% mIoU improvement over the original split proposed by SemanticKITTI dataset. A complete benchmark for semantic segmentation task was performed, with state of the art methods. Finally, we demonstrate an active learning (AL) based dataset distillation framework. We introduce a novel heuristic-free sampling method called distance sampling in the context of AL. A detailed presentation on the dataset is available at https://www.youtube.com/watch?v=5m6ALIs-s20 ."}
{"link":"http://arxiv.org/abs/2212.07083v1","created":"2022-12-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-561847247,"_task_hash":-1241960290,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678478038,"text":"Decoding Multi-class Motor-related Intentions with User-optimized and Robust BCI System Based on Multimodal Dataset\nA brain-computer interface (BCI) based on electroencephalography (EEG) can be useful for rehabilitation and the control of external devices. Five grasping tasks were decoded for motor execution (ME) and motor imagery (MI). During this experiment, eight healthy subjects were asked to imagine and grasp five objects. Analysis of EEG signals was performed after detecting muscle signals on electromyograms (EMG) with a time interval selection technique on data taken from these ME and MI experiments. By refining only data corresponding to the exact time when the users performed the motor intention, the proposed method can train the decoding model using only the EEG data generated by various motor intentions with strong correlation with a specific class. There was an accuracy of 70.73% for ME and 47.95% for MI for the five offline tasks. This method may be applied to future applications, such as controlling robot hands with BCIs."}
{"link":"http://arxiv.org/abs/2303.05110v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1006486636,"_task_hash":-1287049846,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678478042,"text":"Retinal Image Segmentation with Small Datasets\nMany eye diseases like Diabetic Macular Edema (DME), Age-related Macular Degeneration (AMD), and Glaucoma manifest in the retina, can cause irreversible blindness or severely impair the central version. The Optical Coherence Tomography (OCT), a 3D scan of the retina with high qualitative information about the retinal morphology, can be used to diagnose and monitor changes in the retinal anatomy. Many Deep Learning (DL) methods have shared the success of developing an automated tool to monitor pathological changes in the retina. However, the success of these methods depend mainly on large datasets. To address the challenge from very small and limited datasets, we proposed a DL architecture termed CoNet (Coherent Network) for joint segmentation of layers and fluids in retinal OCT images on very small datasets (less than a hundred training samples). The proposed model was evaluated on the publicly available Duke DME dataset consisting of 110 B-Scans from 10 patients suffering from DME. Experimental results show that the proposed model outperformed both the human experts' annotation and the current state-of-the-art architectures by a clear margin with a mean Dice Score of 88% when trained on 55 images without any data augmentation."}
{"link":"http://arxiv.org/abs/2212.10180v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1906529332,"_task_hash":1527087246,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678478051,"text":"IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for Indian Languages\nThe rapid growth of machine translation (MT) systems has necessitated comprehensive studies to meta-evaluate evaluation metrics being used, which enables a better selection of metrics that best reflect MT quality. Unfortunately, most of the research focuses on high-resource languages, mainly English, the observations for which may not always apply to other languages. Indian languages, having over a billion speakers, are linguistically different from English, and to date, there has not been a systematic study of evaluating MT systems from English into Indian languages. In this paper, we fill this gap by creating an MQM dataset consisting of 7000 fine-grained annotations, spanning 5 Indian languages and 7 MT systems, and use it to establish correlations between annotator scores and scores obtained using existing automatic metrics. Our results show that pre-trained metrics, such as COMET, have the highest correlations with annotator scores. Additionally, we find that the metrics do not adequately capture fluency-based errors in Indian languages, and there is a need to develop metrics focused on Indian languages. We hope that our dataset and analysis will help promote further research in this area."}
{"link":"http://arxiv.org/abs/2302.07951v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":862052905,"_task_hash":1203627723,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678478055,"text":"Analyzing the Engagement of Social Relationships During Life Event Shocks in Social Media\nIndividuals experiencing unexpected distressing events, shocks, often rely on their social network for support. While prior work has shown how social networks respond to shocks, these studies usually treat all ties equally, despite differences in the support provided by different social relationships. Here, we conduct a computational analysis on Twitter that examines how responses to online shocks differ by the relationship type of a user dyad. We introduce a new dataset of over 13K instances of individuals' self-reporting shock events on Twitter and construct networks of relationship-labeled dyadic interactions around these events. By examining behaviors across 110K replies to shocked users in a pseudo-causal analysis, we demonstrate relationship-specific patterns in response levels and topic shifts. We also show that while well-established social dimensions of closeness such as tie strength and structural embeddedness contribute to shock responsiveness, the degree of impact is highly dependent on relationship and shock types. Our findings indicate that social relationships contain highly distinctive characteristics in network interactions and that relationship-specific behaviors in online shock responses are unique from those of offline settings."}
{"link":"http://arxiv.org/abs/2212.09052v1","created":"2022-12-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-986411318,"_task_hash":328791613,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678478069,"text":"A Better Choice: Entire-space Datasets for Aspect Sentiment Triplet Extraction\nAspect sentiment triplet extraction (ASTE) aims to extract aspect term, sentiment and opinion term triplets from sentences. Since the initial datasets used to evaluate models on ASTE had flaws, several studies later corrected the initial datasets and released new versions of the datasets independently. As a result, different studies select different versions of datasets to evaluate their methods, which makes ASTE-related works hard to follow. In this paper, we analyze the relation between different versions of datasets and suggest that the entire-space version should be used for ASTE. Besides the sentences containing triplets and the triplets in the sentences, the entire-space version additionally includes the sentences without triplets and the aspect terms which do not belong to any triplets. Hence, the entire-space version is consistent with real-world scenarios and evaluating models on the entire-space version can better reflect the models' performance in real-world scenarios. In addition, experimental results show that evaluating models on non-entire-space datasets inflates the performance of existing models and models trained on the entire-space version can obtain better performance."}
{"link":"http://arxiv.org/abs/2212.07669v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-760269662,"_task_hash":-16807555,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678478070,"text":"Using Two Losses and Two Datasets Simultaneously to Improve TempoWiC Accuracy\nWSD (Word Sense Disambiguation) is the task of identifying which sense of a word is meant in a sentence or other segment of text. Researchers have worked on this task (e.g. Pustejovsky, 2002) for years but it's still a challenging one even for SOTA (state-of-the-art) LMs (language models). The new dataset, TempoWiC introduced by Loureiro et al. (2022b) focuses on the fact that words change over time. Their best baseline achieves 70.33% macro-F1. In this work, we use two different losses simultaneously to train RoBERTa-based classification models. We also improve our model by using another similar dataset to generalize better. Our best configuration beats their best baseline by 4.23% and reaches 74.56% macroF1."}
{"link":"http://arxiv.org/abs/2212.13015v1","created":"2022-12-26","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1160530248,"_task_hash":-912374833,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678478076,"text":"Skit-S2I: An Indian Accented Speech to Intent dataset\nConventional conversation assistants extract text transcripts from the speech signal using automatic speech recognition (ASR) and then predict intent from the transcriptions. Using end-to-end spoken language understanding (SLU), the intents of the speaker are predicted directly from the speech signal without requiring intermediate text transcripts. As a result, the model can optimize directly for intent classification and avoid cascading errors from ASR. The end-to-end SLU system also helps in reducing the latency of the intent prediction model. Although many datasets are available publicly for text-to-intent tasks, the availability of labeled speech-to-intent datasets is limited, and there are no datasets available in the Indian accent. In this paper, we release the Skit-S2I dataset, the first publicly available Indian-accented SLU dataset in the banking domain in a conversational tonality. We experiment with multiple baselines, compare different pretrained speech encoder's representations, and find that SSL pretrained representations perform slightly better than ASR pretrained representations lacking prosodic features for speech-to-intent classification. The dataset and baseline code is available at \\url{https://github.com/skit-ai/speech-to-intent-dataset}"}
{"link":"http://arxiv.org/abs/2301.02390v1","created":"2023-01-06","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":430063773,"_task_hash":-1588410732,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678478079,"text":"Deep-learning models in medical image analysis: Detection of esophagitis from the Kvasir Dataset\nEarly detection of esophagitis is important because this condition can progress to cancer if left untreated. However, the accuracies of different deep learning models in detecting esophagitis have yet to be compared. Thus, this study aimed to compare the accuracies of convolutional neural network models (GoogLeNet, ResNet-50, MobileNet V2, and MobileNet V3) in detecting esophagitis from the open Kvasir dataset of endoscopic images. Results showed that among the models, GoogLeNet achieved the highest F1-scores. Based on the average of true positive rate, MobileNet V3 predicted esophagitis more confidently than the other models. The results obtained using the models were also compared with those obtained using SHapley Additive exPlanations and Gradient-weighted Class Activation Mapping."}
{"link":"http://arxiv.org/abs/2302.07676v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1519652237,"_task_hash":1958569073,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678478090,"text":"DIVOTrack: A Novel Dataset and Baseline Method for Cross-View Multi-Object Tracking in DIVerse Open Scenes\nCross-view multi-object tracking aims to link objects between frames and camera views with substantial overlaps. Although cross-view multi-object tracking has received increased attention in recent years, existing datasets still have several issues, including 1) missing real-world scenarios, 2) lacking diverse scenes, 3) owning a limited number of tracks, 4) comprising only static cameras, and 5) lacking standard benchmarks, which hinder the investigation and comparison of cross-view tracking methods. To solve the aforementioned issues, we introduce DIVOTrack: a new cross-view multi-object tracking dataset for DIVerse Open scenes with dense tracking pedestrians in realistic and non-experimental environments. Our DIVOTrack has ten distinct scenarios and 550 cross-view tracks, surpassing all cross-view multi-object tracking datasets currently available. Furthermore, we provide a novel baseline cross-view tracking method with a unified joint detection and cross-view tracking framework named CrossMOT, which learns object detection, single-view association, and cross-view matching with an all-in-one embedding model. Finally, we present a summary of current methodologies and a set of standard benchmarks with our DIVOTrack to provide a fair comparison and conduct a comprehensive analysis of current approaches and our proposed CrossMOT. The dataset and code are available at https://github.com/shengyuhao/DIVOTrack."}
{"link":"http://arxiv.org/abs/2212.12104v1","created":"2022-12-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1934033390,"_task_hash":-943171142,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678478095,"text":"The Consistency of Probabilistic Databases with Independent Cells\nA probabilistic database with attribute-level uncertainty consists of relations where cells of some attributes may hold probability distributions rather than deterministic content. Such databases arise, implicitly or explicitly, in the context of noisy operations such as missing data imputation, where we automatically fill in missing values, column prediction, where we predict unknown attributes, and database cleaning (and repairing), where we replace the original values due to detected errors or violation of integrity constraints. We study the computational complexity of problems that regard the selection of cell values in the presence of integrity constraints. More precisely, we focus on functional dependencies and study three problems: (1) deciding whether the constraints can be satisfied by any choice of values, (2) finding a most probable such choice, and (3) calculating the probability of satisfying the constraints. The data complexity of these problems is determined by the combination of the set of functional dependencies and the collection of uncertain attributes. We give full classifications into tractable and intractable complexities for several classes of constraints, including a single dependency, matching constraints, and unary functional dependencies."}
{"link":"http://arxiv.org/abs/2303.05265v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1761300808,"_task_hash":1165014687,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678478102,"text":"Dataset CYLinCF-01 creation pipeline: Circular cylinder in a cross flow, Mach Number 0.03 and Reynolds Number 200\nThis article presents an aeroacoustic workflow (pipeline) to generate a flow and acoustic dataset for studying flow-induced sound in the context of a cylinder in cross flow. The numerical simulations are performed using OpenFOAM for the flow and openCFS for acoustics using the perturbed convective wave equation (PCWE). The workflow involves several steps, including the flow simulation, the acoustic simulation, and post-processing of the results. The simulation workflow is presented in all its details. The analysis focuses on the acoustic characteristics of the flow, including sound pressure levels, frequency spectra, and directivity patterns. The results show good agreement with the literature. The article concludes by discussing applications of the workflow for different cases that involve flow-induced sound generation."}
{"link":"http://arxiv.org/abs/2212.09885v1","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1662005183,"_task_hash":112834966,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678524537,"text":"Asking Clarification Questions for Code Generation in General-Purpose Programming Language\nCode generation from text requires understanding the user's intent from a natural language description (NLD) and generating an executable program code snippet that satisfies this intent. While recent pretrained language models (PLMs) demonstrate remarkable performance for this task, these models fail when the given NLD is ambiguous due to the lack of enough specifications for generating a high-quality code snippet. In this work, we introduce a novel and more realistic setup for this task. We hypothesize that ambiguities in the specifications of an NLD are resolved by asking clarification questions (CQs). Therefore, we collect and introduce a new dataset named CodeClarQA containing NLD-Code pairs with created CQAs. We evaluate the performance of PLMs for code generation on our dataset. The empirical results support our hypothesis that clarifications result in more precise generated code, as shown by an improvement of 17.52 in BLEU, 12.72 in CodeBLEU, and 7.7\\% in the exact match. Alongside this, our task and dataset introduce new challenges to the community, including when and what CQs should be asked."}
{"link":"http://arxiv.org/abs/2303.05325v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-545464728,"_task_hash":1767970146,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678524543,"text":"BaDLAD: A Large Multi-Domain Bengali Document Layout Analysis Dataset\nWhile strides have been made in deep learning based Bengali Optical Character Recognition (OCR) in the past decade, the absence of large Document Layout Analysis (DLA) datasets has hindered the application of OCR in document transcription, e.g., transcribing historical documents and newspapers. Moreover, rule-based DLA systems that are currently being employed in practice are not robust to domain variations and out-of-distribution layouts. To this end, we present the first multidomain large Bengali Document Layout Analysis Dataset: BaDLAD. This dataset contains 33,695 human annotated document samples from six domains - i) books and magazines, ii) public domain govt. documents, iii) liberation war documents, iv) newspapers, v) historical newspapers, and vi) property deeds, with 710K polygon annotations for four unit types: text-box, paragraph, image, and table. Through preliminary experiments benchmarking the performance of existing state-of-the-art deep learning architectures for English DLA, we demonstrate the efficacy of our dataset in training deep learning based Bengali document digitization models."}
{"link":"http://arxiv.org/abs/2303.04970v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1520593783,"_task_hash":1134657664,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678524548,"text":"LMR: A Large-Scale Multi-Reference Dataset for Reference-based Super-Resolution\nIt is widely agreed that reference-based super-resolution (RefSR) achieves superior results by referring to similar high quality images, compared to single image super-resolution (SISR). Intuitively, the more references, the better performance. However, previous RefSR methods have all focused on single-reference image training, while multiple reference images are often available in testing or practical applications. The root cause of such training-testing mismatch is the absence of publicly available multi-reference SR training datasets, which greatly hinders research efforts on multi-reference super-resolution. To this end, we construct a large-scale, multi-reference super-resolution dataset, named LMR. It contains 112,142 groups of 300x300 training images, which is 10x of the existing largest RefSR dataset. The image size is also much larger. More importantly, each group is equipped with 5 reference images with different similarity levels. Furthermore, we propose a new baseline method for multi-reference super-resolution: MRefSR, including a Multi-Reference Attention Module (MAM) for feature fusion of an arbitrary number of reference images, and a Spatial Aware Filtering Module (SAFM) for the fused feature selection. The proposed MRefSR achieves significant improvements over state-of-the-art approaches on both quantitative and qualitative evaluations. Our code and data would be made available soon."}
{"link":"http://arxiv.org/abs/2302.07692v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-81305162,"_task_hash":1595135971,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678524553,"text":"Predicting distributional profiles of physical activity in the NHANES database using a Partially Linear Single-Index Fr\u00e9chet Regression model\nObject-oriented data analysis is a fascinating and developing field in modern statistical science with the potential to make significant and valuable contributions to biomedical applications. This statistical framework allows for the formalization of new methods to analyze complex data objects that capture more information than traditional clinical biomarkers. The paper applies the object-oriented framework to analyzing and predicting physical activity measured by accelerometers. As opposed to traditional summary metrics, we utilize a recently proposed representation of physical activity data as a distributional object, providing a more sophisticated and complete profile of individual energetic expenditure in all ranges of monitoring intensity. For the purpose of predicting these distributional objects, we propose a novel hybrid Frechet regression model and apply it to US population accelerometer data from NHANES 2011-2014. The semi-parametric character of the new model allows us to introduce non-linear effects for essential variables, such as age, that are known from a biological point of view to have nuanced effects on physical activity. At the same time, the inclusion of a global for linear term retains the advantage of interpretability for other variables, particularly categorical covariates such as ethnicity and sex. The results obtained in our analysis are helpful from a public health perspective and may lead to new strategies for optimizing physical activity interventions in specific American subpopulations."}
{"link":"http://arxiv.org/abs/2212.10381v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1871212296,"_task_hash":-372616611,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678524566,"text":"To Adapt or to Annotate: Challenges and Interventions for Domain Adaptation in Open-Domain Question Answering\nRecent advances in open-domain question answering (ODQA) have demonstrated impressive accuracy on standard Wikipedia style benchmarks. However, it is less clear how robust these models are and how well they perform when applied to real-world applications in drastically different domains. While there has been some work investigating how well ODQA models perform when tested for out-of-domain (OOD) generalization, these studies have been conducted only under conservative shifts in data distribution and typically focus on a single component (ie. retrieval) rather than an end-to-end system. In response, we propose a more realistic and challenging domain shift evaluation setting and, through extensive experiments, study end-to-end model performance. We find that not only do models fail to generalize, but high retrieval scores often still yield poor answer prediction accuracy. We then categorize different types of shifts and propose techniques that, when presented with a new dataset, predict if intervention methods are likely to be successful. Finally, using insights from this analysis, we propose and evaluate several intervention methods which improve end-to-end answer F1 score by up to 24 points."}
{"link":"http://arxiv.org/abs/2212.08279v1","created":"2022-12-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1392609057,"_task_hash":2104400710,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678524578,"text":"Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion Behaviors in Social Deduction Games\nPersuasion modeling is a key building block for conversational agents. Existing works in this direction are limited to analyzing textual dialogue corpus. We argue that visual signals also play an important role in understanding human persuasive behaviors. In this paper, we introduce the first multimodal dataset for modeling persuasion behaviors. Our dataset includes 199 dialogue transcriptions and videos captured in a multi-player social deduction game setting, 26,647 utterance level annotations of persuasion strategy, and game level annotations of deduction game outcomes. We provide extensive experiments to show how dialogue context and visual signals benefit persuasion strategy prediction. We also explore the generalization ability of language models for persuasion modeling and the role of persuasion strategies in predicting social deduction game outcomes. Our dataset, code, and models can be found at https://persuasion-deductiongame.socialai-data.org."}
{"link":"http://arxiv.org/abs/2212.09268v1","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":480623478,"_task_hash":953006184,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678524673,"text":"UAVCAN Dataset Description\nWe collected attack data from unmanned vehicles using the UAVCAN protocol, and public and described technical documents. A testbed was built with a drone using PX4, and a total of three attacks, Flooding, Fuzzy, and Replay, were performed. The attack was carried out in a total of 10 scenarios. We expect that the attack data will help develop technologies such as anomaly detection to solve the security threat problem of drones."}
{"link":"http://arxiv.org/abs/2303.05102v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":4625778,"_task_hash":-2146501182,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678524675,"text":"StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent Disentangled Space\nOne major challenge in machine learning applications is coping with mismatches between the datasets used in the development and those obtained in real-world applications. These mismatches may lead to inaccurate predictions and errors, resulting in poor product quality and unreliable systems. In this study, we propose StyleDiff to inform developers of the differences between the two datasets for the steady development of machine learning systems. Using disentangled image spaces obtained from recently proposed generative models, StyleDiff compares the two datasets by focusing on attributes in the images and provides an easy-to-understand analysis of the differences between the datasets. The proposed StyleDiff performs in $O (d N\\log N)$, where $N$ is the size of the datasets and $d$ is the number of attributes, enabling the application to large datasets. We demonstrate that StyleDiff accurately detects differences between datasets and presents them in an understandable format using, for example, driving scenes datasets."}
{"link":"http://arxiv.org/abs/2301.00153v1","created":"2022-12-31","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-362006942,"_task_hash":1192902964,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678524677,"text":"Knowledge-Based Dataset for Training PE Malware Detection Models\nOntologies are a standard for semantic schemata in many knowledge-intensive domains of human interest. They are now becoming increasingly important also in areas until very recently dominated by subsymbolic representations and machine-learning-based data processing. One such area is information security, and more specifically malware detection. We propose PE Malware Ontology that offers a reusable semantic schema for Portable Executable (PE, Windows binary format) malware files. The ontology was inspired by the structure of the data in the EMBER dataset and it currently covers the data intended for static malware analysis. With this proposal, we hope to achieve: a) a unified semantic representation for PE malware datasets that are available or will be published in the future; (b) applicability of symbolic, neural-symbolic, or otherwise explainable approaches in the PE Malware domain that may lead to improved interpretability of results which may now be characterized by the terms defined in the ontology; and (c)by joint publishing of semantically treated EMBER data, including fractional datasets, also improved reproducibility of experiments."}
{"link":"http://arxiv.org/abs/2212.06218v1","created":"2022-12-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1015453728,"_task_hash":1328356503,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678524684,"text":"Comparison Of Deep Object Detectors On A New Vulnerable Pedestrian Dataset\nPedestrian safety is one primary concern in autonomous driving. The under-representation of vulnerable groups in today's pedestrian datasets points to an urgent need for a dataset of vulnerable road users. In this paper, we first introduce a new vulnerable pedestrian detection dataset, BG Vulnerable Pedestrian (BGVP) dataset to help train well-rounded models and thus induce research to increase the efficacy of vulnerable pedestrian detection. The dataset includes four classes, i.e., Children Without Disability, Elderly without Disability, With Disability, and Non-Vulnerable. This dataset consists of images collected from the public domain and manually-annotated bounding boxes. In addition, on the proposed dataset, we have trained and tested five state-of-the-art object detection models, i.e., YOLOv4, YOLOv5, YOLOX, Faster R-CNN, and EfficientDet. Our results indicate that YOLOX and YOLOv4 perform the best on our dataset, YOLOv4 scoring 0.7999 and YOLOX scoring 0.7779 on the mAP 0.5 metric, while YOLOX outperforms YOLOv4 by 3.8 percent on the mAP 0.5:0.95 metric. Generally speaking, all five detectors do well predicting the With Disability class and perform poorly in the Elderly Without Disability class. YOLOX consistently outperforms all other detectors on the mAP (0.5:0.95) per class metric, obtaining 0.5644, 0.5242, 0.4781, and 0.6796 for Children Without Disability, Elderly Without Disability, Non-vulnerable, and With Disability, respectively. Our dataset and codes are available at https://github.com/devvansh1997/BGVP."}
{"link":"http://arxiv.org/abs/2212.13994v2","created":"2022-12-26","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1121201417,"_task_hash":-1675009583,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678524756,"text":"Investigation and rectification of NIDS datasets and standardized feature set derivation for network attack detection with graph neural networks\nNetwork Intrusion and Detection Systems (NIDS) are essential for malicious traffic and cyberattack detection in modern networks. Artificial intelligence-based NIDS are powerful tools that can learn complex data correlations for accurate attack prediction. Graph Neural Networks (GNNs) provide an opportunity to analyze network topology along with flow features which makes them particularly suitable for NIDS applications. However, successful application of such tool requires large amounts of carefully collected and labeled data for training and testing. In this paper we inspect different versions of ToN-IoT dataset and point out inconsistencies in some versions. We filter the full version of ToN-IoT and present a new version labeled ToN-IoT-R. To ensure generalization we propose a new standardized and compact set of flow features which are derived solely from NetFlowv5-compatible data. We separate numeric data and flags into different categories and propose a new dataset-agnostic normalization approach for numeric features. This allows us to preserve meaning of flow flags and we propose to conduct targeted analysis based on, for instance, network protocols. For flow classification we use E-GraphSage algorithm with modified node initialization technique that allows us to add node degree to node features. We achieve high classification accuracy on ToN-IoT-R and compare it with previously published results for ToN-IoT, NF-ToN-IoT, and NF-ToN-IoT-v2. We highlight the importance of careful data collection and labeling and appropriate data preprocessing choice and conclude that the proposed set of features is more applicable for real NIDS due to being less demanding to traffic monitoring equipment while preserving high flow classification accuracy."}
{"link":"http://arxiv.org/abs/2212.09368v1","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1044488200,"_task_hash":274297716,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678524765,"text":"TAS-NIR: A VIS+NIR Dataset for Fine-grained Semantic Segmentation in Unstructured Outdoor Environments\nVegetation Indices based on paired images of the visible color spectrum (VIS) and near infrared spectrum (NIR) have been widely used in remote sensing applications. These vegetation indices are extended for their application in autonomous driving in unstructured outdoor environments. In this domain we can combine traditional vegetation indices like the Normalized Difference Vegetation Index (NDVI) and Enhanced Vegetation Index (EVI) with Convolutional Neural Networks (CNNs) pre-trained on available VIS datasets. By laying a focus on learning calibrated CNN outputs, we can provide an approach to fuse known hand-crafted image features with CNN predictions for different domains as well. The method is evaluated on a VIS+NIR dataset of semantically annotated images in unstructured outdoor environments. The dataset is available at mucar3.de/iros2022-ppniv-tas-nir."}
{"link":"http://arxiv.org/abs/2212.07703v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1423868017,"_task_hash":1696642276,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678524790,"text":"The negligible impact of experimental inconsistencies in the NNPDF4.0 global dataset\nAs both predictions and measurements of high-energy physics observables become more precise, controlling all sources of uncertainties in determinations of parton distribution functions (PDFs) becomes increasingly important. One source of PDF uncertainty is the result of data not being consistent under a chosen theoretical framework. In these proceedings we investigate the impact these inconsistencies present in the global NNPDF4.0 dataset. We show that, when accounting for missing higher order uncertainties, the missing contribution to the PDF uncertainty due to data inconsistencies are at the level of statistical fluctuations."}
{"link":"http://arxiv.org/abs/2302.07865v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":992635189,"_task_hash":632667630,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678532441,"text":"Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation\nDistribution shifts are a major source of failure of deployed machine learning models. However, evaluating a model's reliability under distribution shifts can be challenging, especially since it may be difficult to acquire counterfactual examples that exhibit a specified shift. In this work, we introduce dataset interfaces: a framework which allows users to scalably synthesize such counterfactual examples from a given dataset. Specifically, we represent each class from the input dataset as a custom token within the text space of a text-to-image diffusion model. By incorporating these tokens into natural language prompts, we can then generate instantiations of objects in that dataset under desired distribution shifts. We demonstrate how applying our framework to the ImageNet dataset enables us to study model behavior across a diverse array of shifts, including variations in background, lighting, and attributes of the objects themselves. Code available at https://github.com/MadryLab/dataset-interfaces."}
{"link":"http://arxiv.org/abs/2212.14293v1","created":"2022-12-29","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1573642715,"_task_hash":367250560,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678532449,"text":"Error syntax aware augmentation of feedback comment generation dataset\nThis paper presents a solution to the GenChal 2022 shared task dedicated to feedback comment generation for writing learning. In terms of this task given a text with an error and a span of the error, a system generates an explanatory note that helps the writer (language learner) to improve their writing skills. Our solution is based on fine-tuning the T5 model on the initial dataset augmented according to syntactical dependencies of the words located within indicated error span. The solution of our team \"nigula\" obtained second place according to manual evaluation by the organizers."}
{"link":"http://arxiv.org/abs/2212.11541v2","created":"2022-12-22","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":201129219,"_task_hash":422795412,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678532466,"text":"Generative Colorization of Structured Mobile Web Pages\nColor is a critical design factor for web pages, affecting important factors such as viewer emotions and the overall trust and satisfaction of a website. Effective coloring requires design knowledge and expertise, but if this process could be automated through data-driven modeling, efficient exploration and alternative workflows would be possible. However, this direction remains underexplored due to the lack of a formalization of the web page colorization problem, datasets, and evaluation protocols. In this work, we propose a new dataset consisting of e-commerce mobile web pages in a tractable format, which are created by simplifying the pages and extracting canonical color styles with a common web browser. The web page colorization problem is then formalized as a task of estimating plausible color styles for a given web page content with a given hierarchical structure of the elements. We present several Transformer-based methods that are adapted to this task by prepending structural message passing to capture hierarchical relationships between elements. Experimental results, including a quantitative evaluation designed for this task, demonstrate the advantages of our methods over statistical and image colorization methods. The code is available at https://github.com/CyberAgentAILab/webcolor."}
{"link":"http://arxiv.org/abs/2212.07707v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1346009393,"_task_hash":-1421789354,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678532480,"text":"FreCDo: A Large Corpus for French Cross-Domain Dialect Identification\nWe present a novel corpus for French dialect identification comprising 413,522 French text samples collected from public news websites in Belgium, Canada, France and Switzerland. To ensure an accurate estimation of the dialect identification performance of models, we designed the corpus to eliminate potential biases related to topic, writing style, and publication source. More precisely, the training, validation and test splits are collected from different news websites, while searching for different keywords (topics). This leads to a French cross-domain (FreCDo) dialect identification task. We conduct experiments with four competitive baselines, a fine-tuned CamemBERT model, an XGBoost based on fine-tuned CamemBERT features, a Support Vector Machines (SVM) classifier based on fine-tuned CamemBERT features, and an SVM based on word n-grams. Aside from presenting quantitative results, we also make an analysis of the most discriminative features learned by CamemBERT. Our corpus is available at https://github.com/MihaelaGaman/FreCDo."}
{"link":"http://arxiv.org/abs/2212.13965v1","created":"2022-12-28","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1056382417,"_task_hash":987217194,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678532661,"text":"Exploration of latent space of LOD2 GML dataset to identify similar buildings\nExplainable numerical representations of otherwise complex datasets are vital as they extract relevant information, which is more convenient to analyze and study. These latent representations help identify clusters and outliers and assess the similarity between data points. The 3-D model of buildings is one dataset that possesses inherent complexity given the variety in footprint shape, distinct roof types, walls, height, and volume. Traditionally, comparing building shapes requires matching their known properties and shape metrics with each other. However, this requires obtaining a plethora of such properties to calculate similarity. In contrast, this study utilizes an autoencoder-based method to compute the shape information in a fixed-size vector form that can be compared and grouped with the help of distance metrics. This study uses \"FoldingNet,\" a 3D autoencoder, to generate the latent representation of each building from the obtained LOD2 GML dataset of German cities and villages. The Cosine distance is calculated for each latent vector to determine the locations of similar buildings in the city. Further, a set of geospatial tools is utilized to iteratively find the geographical clusters of buildings with similar forms. The state of Brandenburg in Germany is taken as an example to test the methodology. The study introduces a novel approach to finding similar buildings and their geographical location, which can define the neighborhood's character, history, and social setting. Further, the process can be scaled to include multiple settlements where more regional insights can be made."}
{"link":"http://arxiv.org/abs/2212.09219v3","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-122051772,"_task_hash":1867708699,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678532671,"text":"Modeling and Performance Analysis of Single-Server Database Over Quasi-static Rayleigh Fading Channel\nCloud database is the key technology in cloud computing. The effective and efficient service quality of the cloud database is inseparable from communication technology, just as improving communication quality will reduce the concurrency phenomenon in the ticketing system. In order to visually observe the impact of communication on the cloud database, we propose a Communication-Database (C-D) Model with a single-server database over the quasi-static Rayleigh fading channel, which consists of three parts: CLIENTS SOURCE, COMMUNICATION SYSTEM and DATABASE SYSTEM. This paper uses the queuing model, M/G/1//K, to model the whole system. The C-D Model is analyzed in two cases: nonlinearity and linearity, which correspond to some instances of SISO and MIMO. The simulation results of average staying time, average number of transactions and other performance characteristics are basically consistent with the theoretical results, which verifies the validity of the C-D Model. The comparison of these experimental results also proves that poor communication quality does lead to the reduction in the quality of service."}
{"link":"http://arxiv.org/abs/2302.07784v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1224437570,"_task_hash":-915174710,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678532676,"text":"A Case Study on Record Matching of Individuals in Historical Archives of Indigenous Databases\nDigitization of historical records has produced a significant amount of data for analysis and interpretation. A critical challenge is the ability to relate historical information across different archives to allow for the data to be framed in the appropriate historical context. This paper presents a real-world case study on historical information integration and record matching with the goal to improve the historical value of archives containing data in the period 1800 to 1920. The archives contain unique information about M\\'etis and Indigenous people in Canada and interactions with European settlers. The archives contain thousands of records that have increased relevance when relationships and interconnections are discovered. The contribution is a record linking approach suitable for historical archives and an evaluation of its effectiveness. Experimental results demonstrate potential for discovering historical linkage with high precision enabling new historical discoveries."}
{"link":"http://arxiv.org/abs/2212.10190v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":380513492,"_task_hash":867798199,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678532689,"text":"Pay Attention to Your Tone: Introducing a New Dataset for Polite Language Rewrite\nWe introduce \\textsc{PoliteRewrite} -- a dataset for polite language rewrite which is a novel sentence rewrite task. Compared with previous text style transfer tasks that can be mostly addressed by slight token- or phrase-level edits, polite language rewrite requires deep understanding and extensive sentence-level edits over an offensive and impolite sentence to deliver the same message euphemistically and politely, which is more challenging -- not only for NLP models but also for human annotators to rewrite with effort. To alleviate the human effort for efficient annotation, we first propose a novel annotation paradigm by a collaboration of human annotators and GPT-3.5 to annotate \\textsc{PoliteRewrite}. The released dataset has 10K polite sentence rewrites annotated collaboratively by GPT-3.5 and human, which can be used as gold standard for training, validation and test; and 100K high-quality polite sentence rewrites by GPT-3.5 without human review. We wish this work (The dataset (10K+100K) will be released soon) could contribute to the research on more challenging sentence rewrite, and provoke more thought in future on resource annotation paradigm with the help of the large-scaled pretrained models."}
{"link":"http://arxiv.org/abs/2302.07541v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1536293320,"_task_hash":-1227946146,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678532695,"text":"Activity Cliff Prediction: Dataset and Benchmark\nActivity cliffs (ACs), which are generally defined as pairs of structurally similar molecules that are active against the same bio-target but significantly different in the binding potency, are of great importance to drug discovery. Up to date, the AC prediction problem, i.e., to predict whether a pair of molecules exhibit the AC relationship, has not yet been fully explored. In this paper, we first introduce ACNet, a large-scale dataset for AC prediction. ACNet curates over 400K Matched Molecular Pairs (MMPs) against 190 targets, including over 20K MMP-cliffs and 380K non-AC MMPs, and provides five subsets for model development and evaluation. Then, we propose a baseline framework to benchmark the predictive performance of molecular representations encoded by deep neural networks for AC prediction, and 16 models are evaluated in experiments. Our experimental results show that deep learning models can achieve good performance when the models are trained on tasks with adequate amount of data, while the imbalanced, low-data and out-of-distribution features of the ACNet dataset still make it challenging for deep neural networks to cope with. In addition, the traditional ECFP method shows a natural advantage on MMP-cliff prediction, and outperforms other deep learning models on most of the data subsets. To the best of our knowledge, our work constructs the first large-scale dataset for AC prediction, which may stimulate the study of AC prediction models and prompt further breakthroughs in AI-aided drug discovery. The codes and dataset can be accessed by https://drugai.github.io/ACNet/."}
{"link":"http://arxiv.org/abs/2212.09132v1","created":"2022-12-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1299270676,"_task_hash":2043183671,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678532701,"text":"JEMMA: An Extensible Java Dataset for ML4Code Applications\nMachine Learning for Source Code (ML4Code) is an active research field in which extensive experimentation is needed to discover how to best use source code's richly structured information. With this in mind, we introduce JEMMA, an Extensible Java Dataset for ML4Code Applications, which is a large-scale, diverse, and high-quality dataset targeted at ML4Code. Our goal with JEMMA is to lower the barrier to entry in ML4Code by providing the building blocks to experiment with source code models and tasks. JEMMA comes with a considerable amount of pre-processed information such as metadata, representations (e.g., code tokens, ASTs, graphs), and several properties (e.g., metrics, static analysis results) for 50,000 Java projects from the 50KC dataset, with over 1.2 million classes and over 8 million methods. JEMMA is also extensible allowing users to add new properties and representations to the dataset, and evaluate tasks on them. Thus, JEMMA becomes a workbench that researchers can use to experiment with novel representations and tasks operating on source code. To demonstrate the utility of the dataset, we also report results from two empirical studies on our data, ultimately showing that significant work lies ahead in the design of context-aware source code models that can reason over a broader network of source code entities in a software project, the very task that JEMMA is designed to help with."}
{"link":"http://arxiv.org/abs/2212.10935v1","created":"2022-12-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1643126740,"_task_hash":2046386971,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678532713,"text":"Esports Data-to-commentary Generation on Large-scale Data-to-text Dataset\nEsports, a sports competition using video games, has become one of the most important sporting events in recent years. Although the amount of esports data is increasing than ever, only a small fraction of those data accompanies text commentaries for the audience to retrieve and understand the plays. Therefore, in this study, we introduce a task of generating game commentaries from structured data records to address the problem. We first build a large-scale esports data-to-text dataset using structured data and commentaries from a popular esports game, League of Legends. On this dataset, we devise several data preprocessing methods including linearization and data splitting to augment its quality. We then introduce several baseline encoder-decoder models and propose a hierarchical model to generate game commentaries. Considering the characteristics of esports commentaries, we design evaluation metrics including three aspects of the output: correctness, fluency, and strategic depth. Experimental results on our large-scale esports dataset confirmed the advantage of the hierarchical model, and the results revealed several challenges of this novel task."}
{"link":"http://arxiv.org/abs/2301.03364v2","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":2093402412,"_task_hash":-272357311,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678532830,"text":"Towards an AI-enabled Connected Industry: AGV Communication and Sensor Measurement Datasets\nThis paper presents two wireless measurement campaigns in industrial testbeds: industrial Vehicle-to-vehicle (iV2V) and industrial Vehicle-to-infrastructure plus Sensor (iV2I+). Detailed information about the two captured datasets is provided as well. iV2V covers sidelink communication scenarios between Automated Guided Vehicles (AGVs), while iV2I+ is conducted at an industrial setting where an autonomous cleaning robot is connected to a private cellular network. The combination of different communication technologies, together with a common measurement methodology, provides insights that can be exploited by Machine Learning (ML) for tasks such as fingerprinting, line-of-sight detection, prediction of quality of service or link selection. Moreover, the datasets are labelled and pre-filtered for fast on-boarding and applicability. The corresponding testbeds and measurements are also presented in detail for both datasets."}
{"link":"http://arxiv.org/abs/2303.05123v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-2098087196,"_task_hash":476906205,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678532834,"text":"Dominating Set Database Selection for Visual Place Recognition\nThis paper presents an approach for creating a visual place recognition (VPR) database for localization in indoor environments from RGBD scanning sequences. The proposed approach is formulated as a minimization problem in terms of dominating set algorithm for graph, constructed from spatial information, and referred as DominatingSet. Our algorithm shows better scene coverage in comparison to other methodologies that are used for database creation. Also, we demonstrate that using DominatingSet, a database size could be up to 250-1400 times smaller than the original scanning sequence while maintaining a recall rate of more than 80% on testing sequences. We evaluated our algorithm on 7-scenes and BundleFusion datasets and an additionally recorded sequence in a highly repetitive office setting. In addition, the database selection can produce weakly-supervised labels for fine-tuning neural place recognition algorithms to particular settings, improving even more their accuracy. The paper also presents a fully automated pipeline for VPR database creation from RGBD scanning sequences, as well as a set of metrics for VPR database evaluation. The code and released data are available on our web-page~ -- https://prime-slam.github.io/place-recognition-db/"}
{"link":"http://arxiv.org/abs/2212.13595v1","created":"2022-12-27","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-600545123,"_task_hash":497400423,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678532836,"text":"Datasets on materials research of hard ferromagnet in TM-Fe-Si (TM=Ti, Zr, Hf, V, Nb, and Ta) ternary systems\nThe datasets presented in this article are related to materials research on hard ferromagnet in TM-Fe-Si (TM=Ti, Zr, Hf, V, Nb, and Ta) ternary systems. The motivation for data collection is based on the research paper entitled \"Novel hard magnetic phase with Zr$_{11.5}$Fe$_{53}$Si$_{35.5}$ composition\". The datasets are composed of scanning electron microscope images, X-ray diffraction (XRD) patterns, and magnetization data for TM$_{7}$Fe$_{52}$Si$_{41}$ annealed at 1050 $^{\\circ}$C. The chemical compositions of constituent phases were determined by an energy dispersive X-ray spectrometer (EDS). The phase analysis was performed using XRD and EDS results. The Curie temperature of each sample was obtained using magnetization data, and the coercive field was determined for hard ferromagnet samples Zr$_{7}$Fe$_{52}$Si$_{41}$ and Hf$_{7}$Fe$_{52}$Si$_{41}$. The datasets would be useful for developing an Fe-based rare-earth-free permanent magnet, which is one of the central issues of materials science."}
{"link":"http://arxiv.org/abs/2302.07560v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1479718640,"_task_hash":1645438632,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678532884,"text":"Unsupervised classification to improve the quality of a bird song recording dataset\nOpen audio databases such as Xeno-Canto are widely used to build datasets to explore bird song repertoire or to train models for automatic bird sound classification by deep learning algorithms. However, such databases suffer from the fact that bird sounds are weakly labelled: a species name is attributed to each audio recording without timestamps that provide the temporal localization of the bird song of interest. Manual annotations can solve this issue, but they are time consuming, expert-dependent, and cannot run on large datasets. Another solution consists in using a labelling function that automatically segments audio recordings before assigning a label to each segmented audio sample. Although labelling functions were introduced to expedite strong label assignment, their classification performance remains mostly unknown. To address this issue and reduce label noise (wrong label assignment) in large bird song datasets, we introduce a data-centric novel labelling function composed of three successive steps: 1) time-frequency sound unit segmentation, 2) feature computation for each sound unit, and 3) classification of each sound unit as bird song or noise with either an unsupervised DBSCAN algorithm or the supervised BirdNET neural network. The labelling function was optimized, validated, and tested on the songs of 44 West-Palearctic common bird species. We first showed that the segmentation of bird songs alone aggregated from 10% to 83% of label noise depending on the species. We also demonstrated that our labelling function was able to significantly reduce the initial label noise present in the dataset by up to a factor of three. Finally, we discuss different opportunities to design suitable labelling functions to build high-quality animal vocalizations with minimum expert annotation effort."}
{"link":"http://arxiv.org/abs/2301.02429v1","created":"2023-01-06","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-2114026364,"_task_hash":-962810531,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678532891,"text":"Reconstruction of the Sunspot Number Source Database and the 1947 Zurich Discontinuity\nThe recalibration of the sunspot number series, the primary long-term record of the solar cycle, requires the recovery of the entire collection of raw sunspot counts collected by the Zurich Observatory for the production of this index between 1849 and 1980. Here, we report about the major progresses accomplished recently in the construction of this global digital sunspot number database, and we derive global statistics of all the individual observers and professional observatories who provided sunspot data over more than 130 years. First, we can announce the full recovery of long-lost source-data tables covering the last 34 years between 1945 and 1979, and we describe the unique information available in those tables. We then also retrace the evolution of the core observing team in Zurich and of the auxiliary stations. In 1947, we find a major disruption in the composition of both the Zurich team and the international network of auxiliary stations. This sharp transition is unique in the history of the Zurich Observatory and coincides with the main scale-jump found in the original Zurich sunspot number series, the so-called \"Waldmeier\" jump. This adds key historical evidence explaining why methodological changes introduced progressively in the early $20^{th}$ century could play a role precisely at that time. We conclude on the remaining steps needed to fully complete this new sunspot data resource."}
{"link":"http://arxiv.org/abs/2212.11919v2","created":"2022-12-22","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":558437012,"_task_hash":-1753013183,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678532897,"text":"Populations of the Kreutz Sungrazer System in a SOHO Database\nDiscovery of nine populations in a set of 193 select SOHO Kreutz sungrazers (Sekanina 2021) is confirmed for the first time via a histogram of the true longitudes of the ascending node, constructed for a revised set of 220 select sungrazers imaged exclusively by the SOHO's C2 coronagraph. Marsden's orbits are approximately corrected for effects of the out-of-plane nongravitational force. Population I displays two peaks in the histogram, one presumably belonging to a side branch alike to Population Pe, but with no related naked-eye sungrazer known. Swarms/clusters of objects are commonplace, providing evidence on cascading fragmentation proceeding throughout the orbit. Augmentation to all C2-only SOHO Kreutz comets, aimed at removing deliberate bias against Populations I and Pe, reduces the appearance of Populations Ia and Pre-I to bulges along the slope of the histogram because of the swollen wings of Populations I and Pe, respectively. Populations II through IV change very little or not at all. The high Population I-to-II abundance ratio, of 14:1, may be a product of temporal limitations in fragment release. A drop in the number of fragments toward the ends of the nodal-longitude distribution, especially from Population II to IV, is in line with the contact-binary model."}
{"link":"http://arxiv.org/abs/2301.01079v1","created":"2023-01-03","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-77683493,"_task_hash":657016606,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678533005,"text":"Fine-Grained Hard Negative Mining: Generalizing Mitosis Detection with a Fifth of the MIDOG 2022 Dataset\nMaking histopathology image classifiers robust to a wide range of real-world variability is a challenging task. Here, we describe a candidate deep learning solution for the Mitosis Domain Generalization Challenge 2022 (MIDOG) to address the problem of generalization for mitosis detection in images of hematoxylin-eosin-stained histology slides under high variability (scanner, tissue type and species variability). Our approach consists in training a rotation-invariant deep learning model using aggressive data augmentation with a training set enriched with hard negative examples and automatically selected negative examples from the unlabeled part of the challenge dataset. To optimize the performance of our models, we investigated a hard negative mining regime search procedure that lead us to train our best model using a subset of image patches representing 19.6% of our training partition of the challenge dataset. Our candidate model ensemble achieved a F1-score of .697 on the final test set after automated evaluation on the challenge platform, achieving the third best overall score in the MIDOG 2022 Challenge."}
{"link":"http://arxiv.org/abs/2301.00847v1","created":"2023-01-02","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1035023042,"_task_hash":-521885437,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678533008,"text":"Popularity Ranking of Database Management Systems\nDatabases are considered to be integral part of modern information systems. Almost every web or mobile application uses some kind of database. Database management systems are considered to be a crucial element from both business and technological standpoint. This paper divides different types of database management systems into two main categories (relational and non-relational) and several sub categories. Ranking of various sub categories for the month of July, 2021 are presented in the form of popularity score calculated and managed by DB-Engines. Popularity trend for each category is also presented to look at the change in popularity since 2013. Complete ranking and trend of top 20 systems has shown that relational models are still most popular systems with Oracle and MySQL being two most popular systems. However, recent trends have shown DBMSs like Time Series and Document Store getting more and more popular with their wide use in IOT technology and BigData, respectively."}
{"link":"http://arxiv.org/abs/2212.10343v2","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-663312181,"_task_hash":43830043,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678533016,"text":"Berlin V2X: A Machine Learning Dataset from Multiple Vehicles and Radio Access Technologies\nThe evolution of wireless communications into 6G and beyond is expected to rely on new machine learning (ML)-based capabilities. These can enable proactive decisions and actions from wireless-network components to sustain quality-of-service (QoS) and user experience. Moreover, new use cases in the area of vehicular and industrial communications will emerge. Specifically in the area of vehicle communication, vehicle-to-everything (V2X) schemes will benefit strongly from such advances. With this in mind, we have conducted a detailed measurement campaign with the purpose of enabling a plethora of diverse ML-based studies. The resulting datasets offer GPS-located wireless measurements across diverse urban environments for both cellular (with two different operators) and sidelink radio access technologies, thus enabling a variety of different studies towards V2X. The datasets are labeled and sampled with a high time resolution. Furthermore, we make the data publicly available with all the necessary information to support the on-boarding of new researchers. We provide an initial analysis of the data showing some of the challenges that ML needs to overcome and the features that ML can leverage, as well as some hints at potential research studies."}
{"link":"http://arxiv.org/abs/2212.12301v1","created":"2022-12-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":261492383,"_task_hash":-1713647166,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678533024,"text":"NoSQL Database Tuning through Machine Learning\nNoSQL databases have become an important component of many big data and real-time web applications. Their distributed nature and scalability make them an ideal data storage repository for a variety of use cases. While NoSQL databases are delivered with a default ''off-the-shelf'' configuration, they offer configuration settings to adjust a database's behavior and performance to a specific use case and environment. The abundance and oftentimes imperceptible inter-dependencies of configuration settings make it difficult to optimize and performance-tune a NoSQL system. There is no one-size-fits-all configuration and therefore the workload, the physical design, and available resources need to be taken into account when optimizing the configuration of a NoSQL database. This work explores Machine Learning as a means to automatically tune a NoSQL database for optimal performance. Using Random Forest and Gradient Boosting Decision Tree Machine Learning algorithms, multiple Machine Learning models were fitted with a training dataset that incorporates properties of the NoSQL physical configuration (replication and sharding). The best models were then employed as surrogate models to optimize the Database Management System's configuration settings for throughput and latency using a Black-box Optimization algorithm. Using an Apache Cassandra database, multiple experiments were carried out to demonstrate the feasibility of this approach, even across varying physical configurations. The tuned DBMS configurations yielded throughput improvements of up to 4%, read latency reductions of up to 43%, and write latency reductions of up to 39% when compared to the default configuration settings."}
{"link":"http://arxiv.org/abs/2212.06152v1","created":"2022-12-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1437703302,"_task_hash":-1511355423,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678533191,"text":"Accelerating Dataset Distillation via Model Augmentation\nDataset Distillation (DD), a newly emerging field, aims at generating much smaller and high-quality synthetic datasets from large ones. Existing DD methods based on gradient matching achieve leading performance; however, they are extremely computationally intensive as they require continuously optimizing a dataset among thousands of randomly initialized models. In this paper, we assume that training the synthetic data with diverse models leads to better generalization performance. Thus we propose two \\textbf{model augmentation} techniques, ~\\ie using \\textbf{early-stage models} and \\textbf{weight perturbation} to learn an informative synthetic set with significantly reduced training cost. Extensive experiments demonstrate that our method achieves up to 20$\\times$ speedup and comparable performance on par with state-of-the-art baseline methods."}
{"link":"http://arxiv.org/abs/2301.01187v1","created":"2023-01-03","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":2137229438,"_task_hash":-1533411168,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678533194,"text":"A double-hybrid density functional based on good local physics with outstanding performance on the GMTKN55 database\nIn two recent papers [A. D. Becke, J. Chem. Phys. 156, 214101 (2022) and 157, 234102 (2022)] we compared two Kohn-Sham density functionals based on physical modelling and theory with the best density-functional power-series fits in the literature. The best error statistics reported to date for a hybrid functional on the GMTKN55 chemical database of Goerigk, Grimme, and coworkers [Phys. Chem. Chem. Phys. 19, 32184 (2017)] were obtained. In the present work, additional second-order perturbation-theory terms are considered. The result is a 12-parameter double-hybrid (DH) density functional with the lowest GMTKN55 \"WTMAD2\" error yet seen for a DH functional. We call it \"DH23\"."}
{"link":"http://arxiv.org/abs/2212.08987v1","created":"2022-12-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1584901275,"_task_hash":1723706077,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678533208,"text":"A Robust Semantic Frame Parsing Pipeline on a New Complex Twitter Dataset\nMost recent semantic frame parsing systems for spoken language understanding (SLU) are designed based on recurrent neural networks. These systems display decent performance on benchmark SLU datasets such as ATIS or SNIPS, which contain short utterances with relatively simple patterns. However, the current semantic frame parsing models lack a mechanism to handle out-of-distribution (\\emph{OOD}) patterns and out-of-vocabulary (\\emph{OOV}) tokens. In this paper, we introduce a robust semantic frame parsing pipeline that can handle both \\emph{OOD} patterns and \\emph{OOV} tokens in conjunction with a new complex Twitter dataset that contains long tweets with more \\emph{OOD} patterns and \\emph{OOV} tokens. The new pipeline demonstrates much better results in comparison to state-of-the-art baseline SLU models on both the SNIPS dataset and the new Twitter dataset (Our new Twitter dataset can be downloaded from https://1drv.ms/u/s!AroHb-W6_OAlavK4begsDsMALfE?e=c8f2XX ). Finally, we also build an E2E application to demo the feasibility of our algorithm and show why it is useful in real application."}
{"link":"http://arxiv.org/abs/2212.14674v1","created":"2022-12-27","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":517675687,"_task_hash":457749725,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678533216,"text":"A Comprehensive Gold Standard and Benchmark for Comics Text Detection and Recognition\nThis study focuses on improving the optical character recognition (OCR) data for panels in the COMICS dataset, the largest dataset containing text and images from comic books. To do this, we developed a pipeline for OCR processing and labeling of comic books and created the first text detection and recognition datasets for western comics, called \"COMICS Text+: Detection\" and \"COMICS Text+: Recognition\". We evaluated the performance of state-of-the-art text detection and recognition models on these datasets and found significant improvement in word accuracy and normalized edit distance compared to the text in COMICS. We also created a new dataset called \"COMICS Text+\", which contains the extracted text from the textboxes in the COMICS dataset. Using the improved text data of COMICS Text+ in the comics processing model from resulted in state-of-the-art performance on cloze-style tasks without changing the model architecture. The COMICS Text+ dataset can be a valuable resource for researchers working on tasks including text detection, recognition, and high-level processing of comics, such as narrative understanding, character relations, and story generation. All the data and inference instructions can be accessed in https://github.com/gsoykan/comics_text_plus."}
{"link":"http://arxiv.org/abs/2212.13876v2","created":"2022-12-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1920711169,"_task_hash":1693391668,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678534078,"text":"xFBD: Focused Building Damage Dataset and Analysis\nThe xView2 competition and xBD dataset spurred significant advancements in overhead building damage detection, but the competition's pixel level scoring can lead to reduced solution performance in areas with tight clusters of buildings or uninformative context. We seek to advance automatic building damage assessment for disaster relief by proposing an auxiliary challenge to the original xView2 competition. This new challenge involves a new dataset and metrics indicating solution performance when damage is more local and limited than in xBD. Our challenge measures a network's ability to identify individual buildings and their damage level without excessive reliance on the buildings' surroundings. Methods that succeed on this challenge will provide more fine-grained, precise damage information than original xView2 solutions. The best-performing xView2 networks' performances dropped noticeably in our new limited/local damage detection task. The common causes of failure observed are that (1) building objects and their classifications are not separated well, and (2) when they are, the classification is strongly biased by surrounding buildings and other damage context. Thus, we release our augmented version of the dataset with additional object-level scoring metrics https://gitlab.kitware.com/dennis.melamed/xfbd to test independence and separability of building objects, alongside the pixel-level performance metrics of the original competition. We also experiment with new baseline models which improve independence and separability of building damage predictions. Our results indicate that building damage detection is not a fully-solved problem, and we invite others to use and build on our dataset augmentations and metrics."}
{"link":"http://arxiv.org/abs/2212.12266v1","created":"2022-12-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1035530181,"_task_hash":-373916654,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678534083,"text":"Large Raw Emotional Dataset with Aggregation Mechanism\nWe present a new data set for speech emotion recognition (SER) tasks called Dusha. The corpus contains approximately 350 hours of data, more than 300 000 audio recordings with Russian speech and their transcripts. Therefore it is the biggest open bi-modal data collection for SER task nowadays. It is annotated using a crowd-sourcing platform and includes two subsets: acted and real-life. Acted subset has a more balanced class distribution than the unbalanced real-life part consisting of audio podcasts. So the first one is suitable for model pre-training, and the second is elaborated for fine-tuning purposes, model approbation, and validation. This paper describes pre-processing routine, annotation, and experiment with a baseline model to demonstrate some actual metrics which could be obtained with the Dusha data set."}
{"link":"http://arxiv.org/abs/2212.11116v1","created":"2022-12-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1082012075,"_task_hash":2095001368,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678534091,"text":"Balanced Split: A new train-test data splitting strategy for imbalanced datasets\nClassification data sets with skewed class proportions are called imbalanced. Class imbalance is a problem since most machine learning classification algorithms are built with an assumption of equal representation of all classes in the training dataset. Therefore to counter the class imbalance problem, many algorithm-level and data-level approaches have been developed. These mainly include ensemble learning and data augmentation techniques. This paper shows a new way to counter the class imbalance problem through a new data-splitting strategy called balanced split. Data splitting can play an important role in correctly classifying imbalanced datasets. We show that the commonly used data-splitting strategies have some disadvantages, and our proposed balanced split has solved those problems."}
{"link":"http://arxiv.org/abs/2301.01348v1","created":"2023-01-03","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1927205307,"_task_hash":-461614636,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678534106,"text":"DADAgger: Disagreement-Augmented Dataset Aggregation\nDAgger is an imitation algorithm that aggregates its original datasets by querying the expert on all samples encountered during training. In order to reduce the number of samples queried, we propose a modification to DAgger, known as DADAgger, which only queries the expert for state-action pairs that are out of distribution (OOD). OOD states are identified by measuring the variance of the action predictions of an ensemble of models on each state, which we simulate using dropout. Testing on the Car Racing and Half Cheetah environments achieves comparable performance to DAgger but with reduced expert queries, and better performance than a random sampling baseline. We also show that our algorithm may be used to build efficient, well-balanced training datasets by running with no initial data and only querying the expert to resolve uncertainty."}
{"link":"http://arxiv.org/abs/2212.12734v2","created":"2022-12-24","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-581820171,"_task_hash":-1149279679,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678534125,"text":"DDH-QA: A Dynamic Digital Humans Quality Assessment Database\nIn recent years, large amounts of effort have been put into pushing forward the real-world application of dynamic digital human (DDH). However, most current quality assessment research focuses on evaluating static 3D models and usually ignores motion distortions. Therefore, in this paper, we construct a large-scale dynamic digital human quality assessment (DDH-QA) database with diverse motion content as well as multiple distortions to comprehensively study the perceptual quality of DDHs. Both model-based distortion (noise, compression) and motion-based distortion (binding error, motion unnaturalness) are taken into consideration. Ten types of common motion are employed to drive the DDHs and a total of 800 DDHs are generated in the end. Afterward, we render the video sequences of the distorted DDHs as the evaluation media and carry out a well-controlled subjective experiment. Then a benchmark experiment is conducted with the state-of-the-art video quality assessment (VQA) methods and the experimental results show that existing VQA methods are limited in assessing the perceptual loss of DDHs."}
{"link":"http://arxiv.org/abs/2212.07835v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":1549088490,"_task_hash":1790518211,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678534130,"text":"You were saying? -- Spoken Language in the V3C Dataset\nThis paper presents an analysis of the distribution of spoken language in the V3C video retrieval benchmark dataset based on automatically generated transcripts. It finds that a large portion of the dataset is covered by spoken language. Since language transcripts can be quickly and accurately described, this has implications for retrieval tasks such as known-item search."}
{"link":"http://arxiv.org/abs/2212.08662v1","created":"2022-12-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":609160849,"_task_hash":1397019686,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678534137,"text":"Wide-scale Monitoring of Satellite Lifetimes: Pitfalls and a Benchmark Dataset\nAn important task within the broader goal of Space Situational Awareness (SSA) is to observe changes in the orbits of satellites, where the data spans thousands of objects over long time scales (decades). The Two-Line Element (TLE) data provided by the North American Aerospace Defense Command is the most comprehensive and widely-available dataset cataloguing the orbits of satellites. This makes it a highly-attractive data source on which to perform this observation. However, when attempting to infer changes in satellite behaviour from TLE data, there are a number of potential pitfalls. These mostly relate to specific features of the TLE data which are not always clearly documented in the data sources or popular software packages for manipulating them. These quirks produce a particularly hazardous data type for researchers from adjacent disciplines (such as anomaly detection or machine learning). We highlight these features of TLE data and the resulting pitfalls in order to save future researchers from being trapped. A seperate, significant, issue is that existing contributions to manoeuvre detection from TLE data evaluate their algorithms on different satellites, making comparison between these methods difficult. Moreover, the ground-truth in these datasets is often poor quality, sometimes being based on subjective human assessment. We therefore release and describe in-depth an open, curated, benchmark dataset containing TLE data for 15 satellites alongside high-quality ground-truth manoeuvre timestamps."}
{"link":"http://arxiv.org/abs/2212.12436v1","created":"2022-12-22","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":251901085,"_task_hash":517125948,"label":"dataset","_view_id":"classification","answer":"accept","_timestamp":1678534145,"text":"SceNDD: A Scenario-based Naturalistic Driving Dataset\nIn this paper, we propose SceNDD: a scenario-based naturalistic driving dataset that is built upon data collected from an instrumented vehicle in downtown Indianapolis. The data collection was completed in 68 driving sessions with different drivers, where each session lasted about 20--40 minutes. The main goal of creating this dataset is to provide the research community with real driving scenarios that have diverse trajectories and driving behaviors. The dataset contains ego-vehicle's waypoints, velocity, yaw angle, as well as non-ego actor's waypoints, velocity, yaw angle, entry-time, and exit-time. Certain flexibility is provided to users so that actors, sensors, lanes, roads, and obstacles can be added to the existing scenarios. We used a Joint Probabilistic Data Association (JPDA) tracker to detect non-ego vehicles on the road. We present some preliminary results of the proposed dataset and a few applications associated with it. The complete dataset is expected to be released by early 2023."}
{"link":"http://arxiv.org/abs/2301.02554v1","created":"2023-01-04","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-2128998234,"_task_hash":-1593612127,"label":"dataset","_view_id":"classification","answer":"reject","_timestamp":1678534150,"text":"MSCDA: Multi-level Semantic-guided Contrast Improves Unsupervised Domain Adaptation for Breast MRI Segmentation in Small Datasets\nDeep learning (DL) applied to breast tissue segmentation in magnetic resonance imaging (MRI) has received increased attention in the last decade, however, the domain shift which arises from different vendors, acquisition protocols, and biological heterogeneity, remains an important but challenging obstacle on the path towards clinical implementation. Recently, unsupervised domain adaptation (UDA) methods have attempted to mitigate this problem by incorporating self-training with contrastive learning. To better exploit the underlying semantic information of the image at different levels, we propose a Multi-level Semantic-guided Contrastive Domain Adaptation (MSCDA) framework to align the feature representation between domains. In particular, we extend the contrastive loss by incorporating pixel-to-pixel, pixel-to-centroid, and centroid-to-centroid contrasts to integrate semantic information of images. We utilize a category-wise cross-domain sampling strategy to sample anchors from target images and build a hybrid memory bank to store samples from source images. Two breast MRI datasets were retrospectively collected: The source dataset contains non-contrast MRI examinations from 11 healthy volunteers and the target dataset contains contrast-enhanced MRI examinations of 134 invasive breast cancer patients. We set up experiments from source T2W image to target dynamic contrast-enhanced (DCE)-T1W image (T2W-to-T1W) and from source T1W image to target T2W image (T1W-to-T2W). The proposed method achieved Dice similarity coefficient (DSC) of 89.2\\% and 84.0\\% in T2W-to-T1W and T1W-to-T2W, respectively, outperforming state-of-the-art methods. Notably, good performance is still achieved with a smaller source dataset, proving that our framework is label-efficient."}
{"link":"http://arxiv.org/abs/2303.05321v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"_input_hash":-1096642059,"_task_hash":328310204,"label":"dataset","_view_id":"classification","answer":"ignore","_timestamp":1678534591,"text":"WASD: A Wilder Active Speaker Detection Dataset\nCurrent Active Speaker Detection (ASD) models achieve great results on AVA-ActiveSpeaker (AVA), using only sound and facial features. Although this approach is applicable in movie setups (AVA), it is not suited for less constrained conditions. To demonstrate this limitation, we propose a Wilder Active Speaker Detection (WASD) dataset, with increased difficulty by targeting the two key components of current ASD: audio and face. Grouped into 5 categories, ranging from optimal conditions to surveillance settings, WASD contains incremental challenges for ASD with tactical impairment of audio and face data. We select state-of-the-art models and assess their performance in two groups of WASD: Easy (cooperative settings) and Hard (audio and/or face are specifically degraded). The results show that: 1) AVA trained models maintain a state-of-the-art performance in WASD Easy group, while underperforming in the Hard one, showing the 2) similarity between AVA and Easy data; and 3) training in WASD does not improve models performance to AVA levels, particularly for audio impairment and surveillance settings. This shows that AVA does not prepare models for wild ASD and current approaches are subpar to deal with such conditions. The proposed dataset also contains body data annotations to provide a new source for ASD, and is available at https://github.com/Tiago-Roxo/WASD."}
