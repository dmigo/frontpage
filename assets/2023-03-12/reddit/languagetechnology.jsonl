{"title":"Best approach for sarcasm subcategory classification?","description":" Hi All,\n\nI  am currently working on my thesis which is attempting to build on  existing research in the field of sarcasm detection within NLP and  sentiment analysis. The task outlined is to basically build a model  which can identify subcategories of sarcasm (e.g. irony, overstatement,  rhetorical questions etc.). The dataset includes values for whether a  phrase is sarcastic or not, and which subcategories the phrase fits into  (there can be overlap between categories). I have fine-tuned BERT for  sarcasm detection and this works fine but that isn't really the task. My  questions are twofold essentially:\n\n\\-  Is the solely transformer-based approach useful in this instance, given  that it could build on existing research where previous scores obtained  in this task were fairly low. If so, does anyone have any resources on  how to build a multi-subclass classification model, or would it be  better to build separate models for each task?\n\n\\-  Would attempting to use a rule-based approach be more valuable e.g.  using vector semantics and embeddings to attempt to identify the  subcategories using this approach, and if so are there any particular  resources I should have a look at to understand how to implement this in  code? I am currently reading Jurafsky &amp; Martin's 3rd draft of  Speech and Language Processing, but I am unclear on how I could use this  to categorise the subcategories which are difficult to define by  linguistic experts as it is?\n\nI'm  sorry if this is a bit rambling and all over the place, I'm feeling  pretty lost and stressed, but happy to answer any questions and try to  clarify anything :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11ok7ug/best_approach_for_sarcasm_subcategory/","created":"2023-03-11","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":4}}
{"title":"Identify custom labels as well as existing labels with Spacy v3","description":"Hi all,\n\nI want to train a model with custom labels, and use it in combination with a pretrained model in Spacy v3.\n\nFor example for this code:\n\n    import spacy\n    import random\n    import json\n    \n    # Load the spaCy NLP model\n    nlp = spacy.load('en_core_web_lg')\n    \n    # Define the training data\n    train_data = [\n        ('These tomatoes are red and tasty.', {'entities': [(6, 14, 'VEGETABLE')]}),\n        ('I like red tomatoes.', {'entities': [(11, 19, 'VEGETABLE')]}),\n       \n        ('These bananas are very green.', {'entities': [(6, 13, 'FRUIT')]}),\n        ('Where are my bananas?', {'entities': [(13, 20, 'FRUIT')]}),\n        ('Are there any bananas near?', {'entities': [(14, 21, 'FRUIT')]}),    \n    ]\n    \n    # Define the new entity labels\n    new_labels = [\"FRUIT\", \"VEGETABLE\"]\n    \n    # Add the new labels to the existing entity recognizer\n    ner = nlp.get_pipe(\"ner\")\n    for label in new_labels:\n        ner.add_label(label)\n    \n    # Set up the optimizer\n    #optimizer = nlp.begin_training()\n    optimizer = nlp.initialize()\n    \n    # Iterate over the training data and update the model\n    for i in range(10):\n        random.shuffle(train_data)\n        for text, annotations in train_data:\n            doc = nlp.make_doc(text)\n            example = spacy.training.Example.from_dict(doc, annotations)\n            nlp.update([example], sgd=optimizer)\n    \n    # Test the model\n    text = \"\"\"What kind of color have bananas &amp; tomatoes in London?\"\"\"\n    doc = nlp(text)\n    for ent in doc.ents:\n        print(ent.text, ent.label_)\n\nThe output is:\n\n    bananas FRUIT\n    tomatoes VEGETABLE\n\nThe custom labels are recognized, but why is \"London\" not recognized as \"GPE\"? How can I achieve it?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11nr3r2/identify_custom_labels_as_well_as_existing_labels/","created":"2023-03-10","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"How to interpret actions","description":"Hey guys, I would like to be able to extract actions along with their objects. For example, in the sentence \"Paint all the walls red and hide all the doors and windows.\", I would like to extract the verbs \"paint\" and \"hide\", the objects \"walls, doors, windows\", the relationships \"paint-&gt;walls\", \"hide-&gt;doors, windows\", and the adverb relationship \"paint-&gt;red\".\n\nWhat tools/techniques would you suggest? Is deep learning the way to go?\n\n[Spacy](https://spacy.io/usage/rule-based-matching#dependencymatcher) and [Stanza](https://stanfordnlp.github.io/stanza/available\\_models.html) look promising, but I am not sure.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11nozbv/how_to_interpret_actions/","created":"2023-03-10","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":4}}
{"title":"Training Transformer Networks in Scikit-Learn?!","description":"Have you ever wanted to use handy scikit-learn functionalities with your neural networks, but couldn\u2019t because TensorFlow models are not compatible with the scikit-learn API?\n\nI\u2019m excited to introduce one-line wrappers for TensorFlow/Keras models that enable you to use TensorFlow models within scikit-learn workflows with features like Pipeline, GridSearch, and more.\n\nTransformers are extremely popular for modeling text nowadays with GPT3, ChatGPT, Bard, PaLM, FLAN excelling for conversational AI and other Transformers like T5 &amp; BERT excelling for text classification. Scikit-learn offers a broadly useful suite of features for classifier models, but these are hard to use with Transformers. However not if you use these wrappers we developed, which only require changing one line of code to make your existing Tensorflow/Keras model compatible with scikit-learn\u2019s rich ecosystem!\n\nAll you have to do is swap `keras.Model` \u2192 `KerasWrapperModel`, or `keras.Sequential` \u2192 `KerasSequentialWrapper`. The wrapper objects have all the same methods as their keras counterparts, plus you can use them with tons of awesome scikit-learn methods.\n\nYou can find a demo jupyter notebook and read more about the wrappers here: [https://cleanlab.ai/blog/transformer-sklearn/](https://cleanlab.ai/blog/transformer-sklearn/)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11mzctf/training_transformer_networks_in_scikitlearn/","created":"2023-03-09","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"Can NLP be used to categorize individuals based on responses?","description":"Hi all,\n\nNew to the field of machine learning and have a dataset with survey responses. I was wondering if NLP can be utilized to categorize individuals based on their responses (approximately 2-3 categories), or is this something better for another domain of machine learning?\n\nIt seems like NLP is more for language generation and interaction. I haven't found much with a couple of quick Google searches around categorization, which makes me think it likely isn't role but just want to check.\n\nThank you!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11n56np/can_nlp_be_used_to_categorize_individuals_based/","created":"2023-03-09","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":11}}
{"title":"Computational Linguist looking to expand","description":"Hello,\n\nI\u2019m in between jobs right now and looking to expand my career. I\u2019ve held about 4-5 jobs as a computational linguist. It remains my strong suit but I\u2019m also realizing that there are very few jobs for compling. Last role I interviewed for was for an nlp engineer and I realized I\u2019m falling short for anything after building a prototype. I\u2019m looking to get back into \u201cstudying\u201d and considering MLOps or Data Science or MBA as I have held two roles as a product manager too (of language technologies) so may be time to explore that area too. My preference is definitely engineering over product management but I wanted to hear people\u2019s opinion on what/ how to stay relevant to the language technology domain.\n\nThanks for reading!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11mvjhs/computational_linguist_looking_to_expand/","created":"2023-03-09","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":2}}
{"title":"Wanna Get Training Datasets For Social media spam classifier","description":"I am planning to build social media's spam classifier with Multinomial Naive Bayes model with python, using \\`sklearn\\` and \\`spacy\\` library. And the text feature extraction technique I will use is tf-idf vectorizer.\n\nHowever, I am having problem to find social media datasets with labelled data as SPAM or NOT SPAM. Another criteria with the datasets is that I need the datasets to be balanced (with roughly equal number of SPAM and NOT SPAM data).\n\nDo suggest me some links or source that I could get the data from?\n\nHope for help. Thanks in advance.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11muxkl/wanna_get_training_datasets_for_social_media_spam/","created":"2023-03-09","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
