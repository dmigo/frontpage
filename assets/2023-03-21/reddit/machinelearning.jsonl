{"title":"[D] Is ML doomed to end up closed-source?","description":"So basically, OpenAI is keeping its models a secret, Hugging Face added a new gated feature, and LLaMA is using a non-commercial license. It looks like companies are all moving towards closed-source and monopolizing ML. \n\nI've always loved Hugging Face, but now they are doing the opposite of what they preach with this new gated feature thing, this is just not open-source and shouldn't be encouraged in the first place.\n\nOpen AI [clearly stated](https://openai.com/policies/terms-of-use#:~:text=use%20output%20from%20the%20Services%20to%20develop%20models%20that%20compete%20with%20OpenAI) that you can't \"use output from the Services to develop models that compete with OpenAI\"\n\nGoogle shared its paper Attention Is All You Need transparently which was a breakthrough in NLP and got utilized by OpenAI (with many other papers) to build GPT-4 which is adopted by Bing and now posing risk to Google's business. As a consequence, could companies start to avoid sharing research openly and rather monopolize their work for the sake of their own business safety?\n\nAlso, assuming we will witness more of these closed-source models. is it safe to just trust them without understanding what data they got exactly trained on? This doesn't seem to make sense, not sure how this would end up.","link":"https://www.reddit.com/r/MachineLearning/comments/11wxabh/d_is_ml_doomed_to_end_up_closedsource/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":55}}
{"title":"[Project] Alpaca-30B: Facebook's 30b parameter LLaMa fine-tuned on the Alpaca dataset","description":"How to fine-tune Facebooks 30 billion parameter LLaMa on the Alpaca data set.\n\nBlog post: [https://abuqader.substack.com/p/releasing-alpaca-30b](https://abuqader.substack.com/p/releasing-alpaca-30b)\n\nWeights: [https://huggingface.co/baseten/alpaca-30b](https://huggingface.co/baseten/alpaca-30b)","link":"https://www.reddit.com/r/MachineLearning/comments/11wqmga/project_alpaca30b_facebooks_30b_parameter_llama/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":53}}
{"title":"[P] OpenAssistant is now live on reddit (Open Source ChatGPT alternative)","description":"OpenAssistant bot is live on /r/ask_open_assistant. There are some limitations to the reddit bot; you can also try on the model in chat mode at https://huggingface.co/spaces/olivierdehaene/chat-llm-streaming. Model is available for free download at https://huggingface.co/OpenAssistant/oasst-sft-1-pythia-12b.\n\n\nPrompt it by creating a new text post (responds to text body of post), starting a comment with !OpenAssistant, or by replying directly to it. \n\nI have recently enabled memory for the bot so it should do a (pretty mediocre) job of continuing a conversation with you.","link":"https://www.reddit.com/r/MachineLearning/comments/11wt2fl/p_openassistant_is_now_live_on_reddit_open_source/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":21}}
{"title":"[R] CodeAlpaca - Instruction following model to generate code","description":"Finetuned Stanford Alpaca on code generation instructions.  \nDemo - [https://code-alpaca-demo.vercel.app/](https://code-alpaca-demo.vercel.app/)  \n\n\nWorking on open sourcing the code and data.","link":"https://www.reddit.com/r/MachineLearning/comments/11wm83d/r_codealpaca_instruction_following_model_to/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":37}}
{"title":"[R] \ud83e\udd16\ud83c\udf1f Unlock the Power of Personal AI: Introducing ChatLLaMA, Your Custom Personal Assistant! \ud83d\ude80\ud83d\udcac","description":"\ud83d\ude80 Introducing ChatLLaMA: Your Personal AI Assistant Powered by LoRA! \ud83e\udd16\n\n&amp;#x200B;\n\nHey AI enthusiasts! \ud83c\udf1f We're excited to announce that you can now create custom personal assistants that run directly on your GPUs!\n\n&amp;#x200B;\n\nChatLLaMA utilizes LoRA, trained on Anthropic's HH dataset, to model seamless conversations between an AI assistant and users.\n\n&amp;#x200B;\n\nPlus, the RLHF version of LoRA is coming soon! \ud83d\udd25\n\n&amp;#x200B;\n\n\ud83d\udc49 Get it here: [https://cxn.to/@serpai/lora-weights](https://cxn.to/@serpai/lora-weights)\n\n&amp;#x200B;\n\n\ud83d\udcda Know any high-quality dialogue-style datasets? Share them with us, and we'll train ChatLLaMA on them!\n\n&amp;#x200B;\n\n\ud83c\udf10 ChatLLaMA is currently available for 30B and 13B models, and the 7B version.\n\n&amp;#x200B;\n\n\ud83d\udd14 Want to stay in the loop for new ChatLLaMA updates? Grab the FREE \\[gumroad link\\]([https://cxn.to/@serpai/lora-weights](https://cxn.to/@serpai/lora-weights)) to sign up and access a collection of links, tutorials, and guides on running the model, merging weights, and more.  (Guides on running and training the model coming soon)\n\n&amp;#x200B;\n\n\ud83e\udd14 Have questions or need help setting up ChatLLaMA? Drop a comment or DM us, and we'll be more than happy to help you out! \ud83d\udcac\n\n&amp;#x200B;\n\nLet's revolutionize AI-assisted conversations together! \ud83c\udf1f\n\n&amp;#x200B;\n\n\\*Disclaimer: trained for research, no foundation model weights, and the post was ran through gpt4 to make it more coherent.\n\n&amp;#x200B;\n\n\ud83d\udc49 Get it here: [https://cxn.to/@serpai/lora-weights](https://cxn.to/@serpai/lora-weights)\n\n&amp;#x200B;\n\n\\*Edit: [https://github.com/serp-ai/LLaMA-8bit-LoRA](https://github.com/serp-ai/LLaMA-8bit-LoRA) &lt;- training repo/instructions (If anything is unclear just let us know and we will try to help/fix the issue!)  (Sorry for spamming the link, don't really know how else to remind people lol)","link":"https://www.reddit.com/r/MachineLearning/comments/11w03sy/r_unlock_the_power_of_personal_ai_introducing/","created":"2023-03-19","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":227}}
{"title":"[D] Machine learning for credit risk scoring for SME","description":"Hey fellas,\n\nI'm looking to get an idea on how machine learning can be used to develop credit risk scorecards or credit assessment methodologies using machine learning, for small business loans.\n\nDoes anyone have experience with this? \n\nI'm also wondering, I have an interview for a fintech company where I will have to build out the credit risk team - but I'm looking to steer away from 'pure' finance and more into the data science space and am concerned this role won't have a lot of innovation scope. Does anyone have experience doing this type of role and whether there's much machine learning involved? \n\nCheers","link":"https://www.reddit.com/r/MachineLearning/comments/11xbewd/d_machine_learning_for_credit_risk_scoring_for_sme/","created":"2023-03-21","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":1}}
{"title":"ICML rebuttals still not visible to reviewers? [D]","description":"The rebuttals for ICML submissions were supposed to become visible to reviewers at 3pm ET on Sunday, with the author-reviewer discussion period beginning today at 10am ET, but OpenReview says my rebuttals are not visible to the reviewers yet. Is anyone else having this problem? Am worried I somehow made them only visible to the chairs","link":"https://www.reddit.com/r/MachineLearning/comments/11wkacx/icml_rebuttals_still_not_visible_to_reviewers_d/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":10}}
{"title":"[P] Make AI Robust and Trustworthy with CAPSA!","description":"Modern AI models show great potential across various applications, but their deployment in everyday life is limited due to a lack of trustworthiness. While accuracy is crucial, AI models must also recognize when they can and cannot be trusted to make decisions, especially in safety-critical systems. To bridge this gap, it\u2019s essential to develop AI models with built-in trust mechanisms for reliable decision-making in real-world scenarios.\n\nTrustworthiness in AI models can be improved by addressing three risk sources: Representation Bias, Epistemic Uncertainty, and Aleatoric Uncertainty.\n\n&amp;#x200B;\n\n* Representation Bias refers to the potential for the model to favor certain groups or types of data over others, leading to inaccuracies in its predictions with under-represented data.\n* Epistemic Uncertainty, also known as Model Uncertainty, describes the uncertainty associated with the model\u2019s ability to make accurate predictions based on the data it has been trained on. Epistemic uncertainty can be improved by training the model longer, or picking a model architecture with higher predictive capacity.\n* Aleatoric Uncertainty, also known as Data Uncertainty, refers to the inherent noise or unpredictability in the data itself. This type of uncertainty can arise due to factors such as measurement errors, labeling errors, or natural variations in the data. This can only be improved by improving the data source, or manually fixing the inherent issues that lie within the dataset.\n\n&amp;#x200B;\n\nTo address this issue of AI trust and gain knowledge of the risk metrics mentioned above, we are open-sourcing CAPSA -- a tool that automates the creation of robust and trustworthy neural networks! It is a Python library that utilizes wrappers to make tensorflow/keras models risk-aware. These wrappers work by augmenting a given model to support the risk metric the wrapper provides. The wrapped model gains risk awareness capabilities, outputting risk metrics mentioned above alongside its predictions. Since these wrapped models are simply augmented models, they can be further trained with Keras API.\n\n[How Representation Bias, Epistemic Uncertainty, and Aleatoric Uncertainty looks in regression and classification tasks with 2d and 1d datasets. CAPSA wraps your Keras models to output these risk metrics alongside of your model's prediction.](https://preview.redd.it/qi94awk1qxoa1.png?width=2756&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=cc1f05011ae7e54e653f06d4d544f315d6c17cbc)\n\nCheckout [CAPSA on Github](https://github.com/themis-ai/capsa) and STAR our repo if you find it cool or helpful for your projects!\n\nWe also have a [paper published](https://themisai.io/papers/capsa.pdf) if you'd like to learn more about the details of how some of our wrappers work.\n\nLet us know what other features you would like CAPSA to support and we'll work on adding them as well!","link":"https://www.reddit.com/r/MachineLearning/comments/11wqh9u/p_make_ai_robust_and_trustworthy_with_capsa/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0}}
{"title":"[D] Hyperparameter robustness of RL algorithms","description":"\n\nI've gone through a lot of RL algorithms recently and a lot of them seem to be very sensitive to hyperparameters with performances varying by degrees of +/-10 in some cases in a scale of  100. Do reviewers consider them as limitations when evaluating these algorithms and yet they still get published, what's the way forward in the field of RL to reduce this?","link":"https://www.reddit.com/r/MachineLearning/comments/11wrqw2/d_hyperparameter_robustness_of_rl_algorithms/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":1}}
{"title":"[D] Im looking for an ai that can put together parts of an image that are loss, due to bad image quality?","description":"Im trying to reconstruct a scene, now i can turn the video into images then reconstruct each frame, or if there is a video version then i can go with that.  So the scene i am trying to reconstruct is a black trouser leg leading to the shoe, and another trouser leg that is also black.","link":"https://www.reddit.com/r/MachineLearning/comments/11x4meq/d_im_looking_for_an_ai_that_can_put_together/","created":"2023-03-21","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":7}}
{"title":"[P] Action Recognition in Computer Vision","description":"Action recognition is a difficult task. Mainly because of its vagueness. Type of actions, duration, ontology, etc. I made a complete overview of the problem relevant today. Here is a collection of approaches, networks, and problem statements. It will help you clarify the task the next time you meet it.    https://medium.com/@zlodeibaal/action-recognition-in-the-wild-9eb7f12b4d12","link":"https://www.reddit.com/r/MachineLearning/comments/11wjk9x/p_action_recognition_in_computer_vision/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0}}
{"title":"[R][D] Papers on Transductive Learning","description":"Hi all,\n\nI'm trying to find some good papers on transductive learning. I'm looking for newly published ones in general however papers which aren't that recent but had a good impact would also be nice to read. I've been searching for some papers however I do not want to miss out on the really good ones. So could anyone suggest papers on transductive learning which you think that I should not miss out?\n\nAlso I'm not sure if this is the right subreddit for this but, there is something which I'm struggling with recently. I have to conduct my literature review but it's too difficult really. And it takes too long to understand an article. Do you guys also have some suggestions on how I could read an article more efficiently so that I could read multiple articles in a single day?","link":"https://www.reddit.com/r/MachineLearning/comments/11wvv5t/rd_papers_on_transductive_learning/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0}}
{"title":"[D] Determining quality of training images with some metrics","description":"Hello ML sub,\n\nHow does one evaluate the quality of training images before actually training a model ? Training a model is surely expensive. What if one had a way of sort of ascertaining that the image quality of a training set for a particular task (say object detection or semantic segmentation etc) ? It doesn't have to be perfect but some kind of hint...\n\nCould you please point me to some papers or studies or discussions on this ?\n\nThere are some objective metrics like PSNR or SSIM but they need a reference image","link":"https://www.reddit.com/r/MachineLearning/comments/11wreix/d_determining_quality_of_training_images_with/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":4}}
{"title":"IJCAI 2023 Reviews discussion [D]","description":"This is my first time submitting to IJCAI. Any comments on how to respond to the reviews are welcome. Any help is appreciated.","link":"https://www.reddit.com/r/MachineLearning/comments/11wopqb/ijcai_2023_reviews_discussion_d/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0}}
{"title":"[D]The Ethical Implications of AI","description":"Greetings, AI enthusiasts! As someone who's deeply engaged with the world of artificial intelligence, I know firsthand how exciting and powerful this technology can be. However, it's important to remember that with great power comes great responsibility. That's why I'm here to talk about the importance of ethical AI.\n\nAs Tim Cook, CEO of Apple, once said, \"Technology should be infused with humanity. It's not something that comes off an assembly line.\" That sentiment is particularly important when it comes to AI, which has the potential to impact so many aspects of our lives. We need to ensure that we're using this technology in a responsible and ethical way, so that we can maximize its benefits while minimizing its potential risks.\n\nSome of the key ethical considerations for using AI include privacy, transparency, inclusivity, safety, and impact. For example, it's essential that AI systems be designed with privacy in mind, and that they be transparent about how they collect and use personal data. It's also important to ensure that AI systems are accessible and beneficial for everyone, regardless of their background or abilities.\n\nAs Joy Buolamwini, founder of the Algorithmic Justice League, has said, \"AI can't be neutral, it reflects the values of those who make it.\" That's why it's important to be vigilant in detecting and addressing bias in AI systems, and ensure that the data used to train them is diverse and representative. We also need to consider the potential impact of AI on society, including the risk of job displacement and the widening of economic inequality.\n\nTo use AI in an ethical and responsible way, we need to stay informed and up-to-date on the latest developments and best practices in the field. There are many resources available to help us learn more about AI ethics, such as academic papers, reports, and online courses. By educating ourselves and staying informed, we can create a culture of ethical AI that benefits everyone.\n\nSo, what can we do to promote ethical AI? Let's start by having an open and honest conversation about the ethical considerations of using this technology. Let's also make sure that we're holding ourselves and others accountable for creating and using AI in an ethical and responsible way. By working together, we can create a brighter future with AI that is ethical, responsible, and beneficial for all.","link":"https://www.reddit.com/r/MachineLearning/comments/11x837e/dthe_ethical_implications_of_ai/","created":"2023-03-21","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0}}
{"title":"[D]: Vanishing Gradients and Resnets","description":"I am working with Resnets consisting of feedforward networks. Additionally, I am using Kaiming-He weight initialisation and ReLU as an activation function. Extending the network to more than 10 layers leads to vanishing gradients. I cannot use batch normalization because that would violate assumptions of a gradient penalty. What should I do? Should I form residual connections over longer steps?\nShould I implement artificial derivatives? What's the common remedy here?","link":"https://www.reddit.com/r/MachineLearning/comments/11wmpoj/d_vanishing_gradients_and_resnets/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":3}}
{"title":"[D] IJCAI 2023 Rebuttal Discussion","description":"Title","link":"https://www.reddit.com/r/MachineLearning/comments/11w8x8d/d_ijcai_2023_rebuttal_discussion/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":23}}
{"title":"[D] Best ChatBot that can be run locally?","description":"What do you guys think is currently the best ChatBot that you can download and run offline? After hearing that Alpaca has results similar to GPT-3, I was curious if anything else competes.","link":"https://www.reddit.com/r/MachineLearning/comments/11w8lp2/d_best_chatbot_that_can_be_run_locally/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":8}}
{"title":"Smarty-GPT: wrapper of prompts/contexts [P]","description":"This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers in a **TRANSPARENT** way to end users.\n\n[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)","link":"https://www.reddit.com/r/MachineLearning/comments/11whc0s/smartygpt_wrapper_of_promptscontexts_p/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":2}}
{"title":"[R] What are the current must-read papers representing the state of the art in machine learning research?","description":"Recently, John Carmack [suggested](https://twitter.com/ID_AA_Carmack/status/1622673143469858816) the creation of a \"canonical list of references from a leading figure,\" referring to a never-released reading list given to him by Ilya Sutskever.\n\nWhile there may be an undue interest in that specific list, MLR is such a big field that it's difficult to know where to start. What are the major papers that are relevant to state of the art work being done in 2023? Perhaps we may crowd-source a list here?","link":"https://www.reddit.com/r/MachineLearning/comments/11vs3oe/r_what_are_the_current_mustread_papers/","created":"2023-03-19","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":16}}
{"title":"[D] For those who have worked 5+ years in the field, what are you up to now?","description":"Hey,I've  been working in ML for the last 5-10 years, almost since deep learning  came up, mostly startups with various successes, sometimes doing more research sometimes doing more engineering tasks.\n\nThis year I was excited to manage a team focused on ML but plans have just changed in my company and this isn't going to happen anytime soon. I am interviewing for another company for a \"senior\"  role but they still ask me to do this basic ML assignment that takes a  few hours to complete. I have just realised how boring it became to me  to the point I don't even want to do it as I literally have done this  for the last 5+ years.\n\nFor those  who have been in the field for at least 5+ years, what are you up to now? Are you still doing ML? Have you moved into management? Have you started your own company? Moved to a different subfield perhaps?\n\nPS: I  have a PhD, in addition to those years of experience i mention. I am  aware this isn't related to ML purely but more like mid-career crisis,  but would be interested to know how people in the field have dealt with  it.","link":"https://www.reddit.com/r/MachineLearning/comments/11vygjb/d_for_those_who_have_worked_5_years_in_the_field/","created":"2023-03-19","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":7}}
