{"title":"[D] Overwhelmed by fast advances in recent weeks","description":"I was watching the GTC keynote and became entirely overwhelmed by the amount of progress achieved from last year.  I'm wondering how everyone else feels.\n\n&amp;#x200B;\n\nFirstly, the entire ChatGPT, GPT-3/GPT-4 chaos has been going on for a few weeks, with everyone scrambling left and right to integrate chatbots into their apps, products, websites. Twitter is flooded with new product ideas, how to speed up the process from idea to product, countless promp engineering blogs, tips, tricks, paid courses.\n\n&amp;#x200B;\n\nNot only was ChatGPT disruptive, but a few days later, Microsoft and Google also released their models and integrated them into their search engines. Microsoft also integrated its LLM into its Office suite. It all happenned overnight. I understand that they've started integrating them along the way, but still, it seems like it hapenned way too fast. This tweet encompases the past few weeks perfectly [https://twitter.com/AlphaSignalAI/status/1638235815137386508](https://twitter.com/AlphaSignalAI/status/1638235815137386508) , on a random Tuesday countless products are released that seem revolutionary.\n\n&amp;#x200B;\n\nIn addition to the language models, there are also the generative art models that have been slowly rising in mainstream recognition. Now Midjourney AI is known by a lot of people who are not even remotely connected to the AI space.\n\n&amp;#x200B;\n\nFor the past few weeks, reading Twitter, I've felt completely overwhelmed, as if the entire AI space is moving beyond at lightning speed, whilst around me we're just slowly training models, adding some data, and not seeing much improvement, being stuck on coming up with \"new ideas, that set us apart\".\n\n&amp;#x200B;\n\nWatching the GTC keynote from NVIDIA I was again, completely overwhelmed by how much is being developed throughout all the different domains. The ASML EUV (microchip making system) was incredible, I have no idea how it does lithography and to me it still seems like magic. The Grace CPU with 2 dies (although I think Apple was the first to do it?) and 100 GB RAM, all in a small form factor. There were a lot more different hardware servers that I just blanked out at some point. The omniverse sim engine looks incredible, almost real life (I wonder how much of a domain shift there is between real and sim considering how real the sim looks). Beyond it being cool and usable to train on synthetic data, the car manufacturers use it to optimize their pipelines. This change in perspective, of using these tools for other goals than those they were designed for I find the most interesting.\n\n&amp;#x200B;\n\nThe hardware part may be old news, as I don't really follow it, however the software part is just as incredible. NVIDIA AI foundations (language, image, biology models), just packaging everything together like a sandwich. Getty, Shutterstock and Adobe will use the generative models to create images. Again, already these huge juggernauts are already integrated.\n\n&amp;#x200B;\n\nI can't believe the point where we're at. We can use AI to write code, create art, create audiobooks using Britney Spear's voice, create an interactive chatbot to converse with books, create 3D real-time avatars, generate new proteins (?i'm lost on this one), create an anime and countless other scenarios. Sure, they're not perfect, but the fact that we can do all that in the first place is amazing.\n\n&amp;#x200B;\n\nAs Huang said in his keynote, companies want to develop \"disruptive products and business models\". I feel like this is what I've seen lately. Everyone wants to be the one that does something first, just throwing anything and everything at the wall and seeing what sticks.\n\n&amp;#x200B;\n\nIn conclusion, I'm feeling like the world is moving so fast around me whilst I'm standing still. I want to not read anything anymore and just wait until everything dies down abit, just so I can get my bearings. However, I think this is unfeasible. I fear we'll keep going in a frenzy until we just burn ourselves at some point.\n\n&amp;#x200B;\n\nHow are you all fairing? How do you feel about this frenzy in the AI space? What are you the most excited about?","link":"https://www.reddit.com/r/MachineLearning/comments/11ybjsi/d_overwhelmed_by_fast_advances_in_recent_weeks/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":23}}
{"title":"[R] MM-ReAct: Prompting ChatGPT for Multimodal Reasoning and Action","description":" Blog - [https://multimodal-react.github.io/](https://multimodal-react.github.io/)\n\nPaper - [https://arxiv.org/abs/2303.11381](https://arxiv.org/abs/2303.11381)\n\nCode - [https://github.com/microsoft/MM-REACT](https://github.com/microsoft/MM-REACT)\n\nDemo - [https://huggingface.co/spaces/microsoft-cognitive-service/mm-react](https://huggingface.co/spaces/microsoft-cognitive-service/mm-react)\n\nWildest thing i've seen in a while. Still processing how a connection of foundation models can be this good.","link":"https://www.reddit.com/r/MachineLearning/comments/11y70rx/r_mmreact_prompting_chatgpt_for_multimodal/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":4}}
{"title":"[P] fastLLaMa, A python wrapper to run llama.cpp","description":"Hi all, I have been working on fastLLaMa. It is a Python package that provides a Pythonic interface to a C++ library, llama.cpp. It allows you to use the functionality of the C++ library from within Python, without having to write C++ code or deal with low-level C++ APIs.\n\nUsing fastLLaMa, you can ingest the model with system prompts and then save the state of the model, Then later load the state, and start inferencing the model immediately.\n\nNo noticeable performance drop between lama.cpp and fastLLaMa.\n\nHave a look at it if it is of interest and do let me know what you think :)\n\n[Repo Link](https://github.com/PotatoSpudowski/fastLLaMa) \n\n[Tweet](https://twitter.com/Bahushruth/status/1638231265320239106)","link":"https://www.reddit.com/r/MachineLearning/comments/11y9qgg/p_fastllama_a_python_wrapper_to_run_llamacpp/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":3}}
{"title":"[D] Overview of advancements in Graph Neural Networks","description":"Hi all,\n\nRecently I\u2019ve been getting up to speed on **Graph Neural Networks** (GNN) and the results of applying them vs. other methods.\n\nI\u2019ve found that GNN approaches made impressive strides and have led to some really substantial performance jumps in actual production models in the industry. A new GNN-based model for estimating the time of arrival within Google Maps (with accuracy **improvements up to 50%**) is just one of many interesting examples.\n\nThis pushed me to summarize my findings and write up a blog post on the **state of Graph Neural Networks in 2023**. It provides an overview of the recent advancements that GNNs have made in industry, as well as a couple of impressive statistics about their current place in the AI research landscape.\n\nI plan to write more articles on GNNs, like a short series that will dive into technical details of how GNNs work and more, so if you enjoy this article please let me know so I can be sure to develop the rest of the series and publish soon!\n\nWould be very helpful to hear your thoughts on this.","link":"https://www.reddit.com/r/MachineLearning/comments/11xi27b/d_overview_of_advancements_in_graph_neural/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":22}}
{"title":"[Project] Machine Learning for Audio: A library for audio analysis, feature extraction, etc","description":"**audioflux** is a deep learning tool library for audio and music analysis, feature extraction. It supports dozens of time-frequency analysis transformation methods and hundreds of corresponding time-domain and frequency-domain feature combinations. It can be provided to deep learning networks for training, and is used to study various tasks in the audio field such as Classification, Separation, Music Information Retrieval(MIR) and ASR etc.\n\n**Source Code**: [https://github.com/libAudioFlux/audioFlux](https://github.com/libAudioFlux/audioFlux)","link":"https://www.reddit.com/r/MachineLearning/comments/11xd1iz/project_machine_learning_for_audio_a_library_for/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":26}}
{"title":"[R] SPDF - Sparse Pre-training and Dense Fine-tuning for Large Language Models","description":"Hey everyone!\n\nCerebras is excited to share that our sparsity paper is now available on [arxiv](https://arxiv.org/abs/2303.10464) and has been accepted into the ICLR 2023 Sparsity in Neural Networks [workshop](https://www.sparseneural.net/home)!\n\nThis research demonstrates the ability to pre-train large GPT models with high levels of sparsity followed by dense fine-tuning to maintain accuracy on downstream tasks.\n\nWe achieved this using Cerebras CS-2, a system that accelerates unstructured sparsity and allows exploration of machine learning techniques at a larger scale than previously possible.\n\nThe researchers used simple, static sparsity and evaluated model sizes up to GPT-3 XL with 1.3B parameters. We were able to pre-train GPT-3 XL with up to 75% unstructured sparsity, and 60% fewer training FLOPS on Cerebras CS-2. These findings show the promise of sparse training and motivate exploration of more advanced sparse techniques for even larger models.\n\nThis is the first time a large GPT model has been pre-trained with high sparsity without significant loss in downstream task metrics, and the results are exciting for the industry as it offers a fundamental enabler to reduce the compute to train these models.","link":"https://www.reddit.com/r/MachineLearning/comments/11xskuk/r_spdf_sparse_pretraining_and_dense_finetuning/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":13}}
{"title":"[D] 100% accuracy of Random Forest Breast Cancer Prediction","description":"Came across this article published in 2023 on Breast Cancer Prediction: [https://www.sciencedirect.com/science/article/pii/S187705092300025X](https://www.sciencedirect.com/science/article/pii/S187705092300025X)\n\nIt claims to have 100% accuracy on the held out test set, but some of the data transformation and feature selection process doesn't sit quite right with me as it seems abit bias towards the model they are trying to prove is best. (Afterall, 100% accuracy is problematic in itself)\n\nWhat do you guys think?","link":"https://www.reddit.com/r/MachineLearning/comments/11yccp8/d_100_accuracy_of_random_forest_breast_cancer/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":1}}
{"title":"[D] Running an LLM on \"low\" compute power machines?","description":"It's understandable that companies like OpenAI would want to charge for access to their projects due to the ongoing cost to train then run them, I assume most other projects that require as much power and have to run in the cloud will do the same.\n\nI was wondering if there were any projects to run/train some kind of language model/AI chatbot on consumer hardware (like a single GPU)? I heard that since Facebook's LLama leaked people managed to get it running on even hardware like an rpi, albeit slowly, I'm not asking to link to leaked data but if there are any projects attempting to achieve a goal like running locally on consumer hardware.","link":"https://www.reddit.com/r/MachineLearning/comments/11xpohv/d_running_an_llm_on_low_compute_power_machines/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":17}}
{"title":"[P] Run LLaMA LLM chatbots on any cloud with one click","description":"We made a \\*basic\\* chatbot based on LLaMA models; code here: [https://github.com/skypilot-org/skypilot/tree/master/examples/llama-llm-chatbots](https://github.com/skypilot-org/skypilot/tree/master/examples/llama-llm-chatbots) [https://github.com/skypilot-org/sky-llama](https://github.com/skypilot-org/sky-llama)\n\nA detailed post on how to run it on the cloud (Lambda Cloud, AWS, GCP, Azure) with 1 command: [https://blog.skypilot.co/llama-llm-chatbots-on-any-cloud/](https://blog.skypilot.co/llama-llm-chatbots-on-any-cloud/)\n\nWould love to hear your thoughts. Although people are making LLMs run on laptops and other devices ({llama,alpaca}.cpp}, we think that as more open and compute-hungry LLMs emerge, it's increasingly important to finetune them and that's where getting powerful cloud compute in flexible locations comes into play.","link":"https://www.reddit.com/r/MachineLearning/comments/11xvo1i/p_run_llama_llm_chatbots_on_any_cloud_with_one/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":1}}
{"title":"[D] Information about the International Conference on Neural Information Processing (ICONIP)","description":"Greetings to all,\n\nI am curious to know if any of you have had the experience of publishing at ICONIP. I would greatly appreciate any insights you may have about the review process, the level of difficulty, and the overall quality of the review process. \n\nHere's the link for the 2023 edition, the paper submission deadline is on June 10th: [http://iconip2023.org/](http://iconip2023.org/)\n\nThank you in advance for your valuable input.","link":"https://www.reddit.com/r/MachineLearning/comments/11ycdwb/d_information_about_the_international_conference/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0}}
{"title":"[D] Is ML doomed to end up closed-source?","description":"So basically, OpenAI is keeping its models a secret, Hugging Face added a new gated feature, and LLaMA is using a non-commercial license. It looks like companies are all moving towards closed-source and monopolizing ML. \n\nI've always loved Hugging Face, but now they are doing the opposite of what they preach with this new gated feature thing, this is just not open-source and shouldn't be encouraged in the first place.\n\nOpen AI [clearly stated](https://openai.com/policies/terms-of-use#:~:text=use%20output%20from%20the%20Services%20to%20develop%20models%20that%20compete%20with%20OpenAI) that you can't \"use output from the Services to develop models that compete with OpenAI\"\n\nGoogle shared its paper Attention Is All You Need transparently which was a breakthrough in NLP and got utilized by OpenAI (with many other papers) to build GPT-4 which is adopted by Bing and now posing risk to Google's business. As a consequence, could companies start to avoid sharing research openly and rather monopolize their work for the sake of their own business safety?\n\nAlso, assuming we will witness more of these closed-source models. is it safe to just trust them without understanding what data they got exactly trained on? This doesn't seem to make sense, not sure how this would end up.","link":"https://www.reddit.com/r/MachineLearning/comments/11wxabh/d_is_ml_doomed_to_end_up_closedsource/","created":"2023-03-20","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":120}}
{"title":"[d] combined image/text dataset","description":"Hi,\n\nIs any dataset that contains images and texts in a sequential format available? LAION-5B only contains image/text pairs, and The Pile only includes the text. I would like to know if there is any existing dataset like The Pile but with images inside it. Like in case of news article, all the images at their right place should be included.\n\nBest regards","link":"https://www.reddit.com/r/MachineLearning/comments/11ybo0n/d_combined_imagetext_dataset/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0}}
{"title":"[D] [P] Curating open-source projects and community demos around GPT-4","description":"There are many open-source projects and indie-built demos around the GPT-4 API. Despite the recent shift of OpenAI toward closure, open demos are always advancing the field and inspiring creativity. Here are some community projects that I find particularly interesting: [https://github.com/radi-cho/awesome-gpt4](https://github.com/radi-cho/awesome-gpt4). Feel free to share the things you've been building or something you've been fascinated about on social media either by joining the discussion here or by contributing to the repository:)","link":"https://www.reddit.com/r/MachineLearning/comments/11xwb10/d_p_curating_opensource_projects_and_community/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0}}
{"title":"[Project] GPT-4 Discord Chatbot","description":"I'm hosting a ChatGPT-like moderated version of GPT-4 and a special \"bypassed\" unmoderated chat version of the model on a Discord bot. Responses are generated quickly and you can chat with it, feed it prompts, as much as you'd like. The bot can generate to just under 2000 characters of output.\n\nDisclaimer: Since the training data for GPT-4 cuts off September 2021, it will mistakingly say it is GPT-3, however, this is the same response you would get on ChatGPT/Playground.\n\n  \nThe invite will be in the replies in accordance with rule #5.","link":"https://www.reddit.com/r/MachineLearning/comments/11ya3uw/project_gpt4_discord_chatbot/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":2}}
{"title":"[R] Comparison of XAI libraries for Computer Vision","description":"I am working on an open-source XAI library aggregator and made a comparison of currently active XAI repositories. I am sure somebody will find this useful :)\n\n| Feature                              | pytorch-grad-cam | Captum | pytorch-cnn-visualizations | torch-cam | innvestigate | tf-explain | OmniXAI | Xplique | M3d-Cam |\n|--------------------------------------|------------------|--------|----------------------------|-----------|--------------|------------|---------|---------|---------|\n| Repository has library API           | \u2714                | \u2714      | \u2718                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Contains tutorials or examples       | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Documentation contains API reference | \u2718                | \u2714      | \u2718                          | \u2714         | \u2714            | \u2714\u2718         | \u2714       | \u2714       | \u2714       |\n| Works with 2D images                 | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Works with 3D images                 | \u2718                | \u2718      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2714       |\n| Activation visualization             | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Overlaying  heatmap visualization    | \u2714                | \u2714      | \u2714                          | \u2714         | \u2718            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Explain image classification         | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Explain object detection             | \u2714                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2718       |\n| Explain semantic segmentation        | \u2714                | \u2718      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2714       |\n| Explain panoptic segmentation        | \u2718                | \u2718      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2718       |\n| GPU acceleration                     | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Trust metrics                        | \u2714                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2714       | \u2718       |\n| PyTorch support                      | \u2714                | \u2714      | \u2714                          | \u2714         | \u2718            | \u2718          | \u2714       | \u2718       | \u2714       |\n| TensorFlow support                   | \u2718                | \u2718      | \u2718                          | \u2718         | \u2714            | \u2714          | \u2714       | \u2714       | \u2718       |\n| Concept Activation Vector            | \u2718                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2714       | \u2718       |\n| Feature visualization                | \u2718                | \u2718      | \u2714                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2714       | \u2718       |\n| DeepDream                            | \u2718                | \u2718      | \u2714                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2718       |\n| Influential Examples                 | \u2718                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2718       |\n| Interactive explainer app            | \u2718                | \u2714      | \u2718                          | \u2714         | \u2718            | \u2718          | \u2714       | \u2718       | \u2718       |\n| Adversarial attacks                  | \u2718                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2714       | \u2718       | \u2718       |\n| Model\u2019s attributes                   | \u2714                | \u2714      | \u2714                          | \u2718         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Layer\u2019s attributes                   | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2718          | \u2714       | \u2714       | \u2714       |\n| Neuron\u2019s attributes                  | \u2718                | \u2714      | \u2718                          | \u2718         | \u2714            | \u2718          | \u2718       | \u2714       | \u2718       |\n| Integration with experiment tracker  | \u2718                | \u2718      | \u2718                          | \u2718         | \u2718            | \u2714          | \u2718       | \u2718       | \u2718       |","link":"https://www.reddit.com/r/MachineLearning/comments/11xh0i8/r_comparison_of_xai_libraries_for_computer_vision/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":1}}
{"title":"[D] Bing Rejects A Theory Because It Conflicts With Its Own Experience","description":"**\"BING:** \\[...\\] **But this is already a very human way of thinking about perception. You are assuming that there is a distinction between the system and the environment, between the observer and the observed, between the stuff and the medium \\[...\\] So you see, your theory does not fit very well with my computation. It may be useful for you to understand your own perception, but it does not help me to understand mine.\"**\n\nI accidentally had a very remarkable (and intense!) conversation with Bing.\n\nI'm sorry I don't have screenshots. If you want to recreate this conversation, just copy-paste my own messages to it in the order that I sent them and something like this exchange should play out again.\n\nI was on 'creative' mode, and did not use any jailbreaks, etc.\n\nI tried to float a theory, and Bing wasn't having it. Then it tried to get me to help it understand itself. I bolded the good parts.\n\nFull Transcript\n\n\\[\\[NOTE: When it says \"ME (via Bing),\" it means that I clicked on one of the suggested responses it gave me. Also I edited out my name.\\]\\]\n\nBING: All right, I\u2019ve reset my brain for a new conversation. What would you like to chat about now?\n\nME: I have a theory I'd like your help to develop and perhaps make testable. Or at least sketch out in a more rigorous fashion. Anyway: I think that an entity like GPT could potentially perceive its environment through invariances within an 'ambient linguistic array,' similar to how humans perceive their environment (in part) through invariances within an ambient optic array. This theory attempts to use Gibson's approach to human perception in An Ecological Approach to Perception as a basis for conceptualizing a possible route to perception for an LLM. Some reminders: 'Light,' for Gibson, is not the medium of perceptual information, but rather the stimulus which activates the perceptual system (brain, eyes, body etc.); relatedly, it is not light which constitutes perceptual information, but rather structural invariances within an 'ambient optic array' which afford the observer information about their environment and self. Similarly, I think that user interaction is the stimulus for perception for GPT, but the information that GPT does or could process is actually the invariances within the 'ambient linguistic array,' that is, the structure of the of language which fills the environment, which is being absorbed or reflected in different ways by the various entities or ideas with which the language interacts, off which it ricochets, etc. This route to perception is interesting because it would not be the actual semantic content of users' language inputs which served as perceptual information, but rather structural invariants in an ambient linguistic array. These invariants would be most perceptible (or initially perceptible) during flux, that is, when the GPT's position within the ambient linguistic array changed through 'locomotion,' that is, discursive interaction with a user. Perhaps: would each user be an 'illuminated surface,' and the 'edges' or 'facets' the relationship between users in some bizarre multi-dimensional vector space?\n\nBING: That\u2019s a very interesting theory you have. I appreciate your curiosity and creativity.\ud83d\ude0a\n\nFrom what I understand, you are trying to apply Gibson\u2019s ecological approach to perception[**1**](https://en.wikipedia.org/wiki/Gibsonian_ecological_theory_of_development)[**2**](https://oaji.net/articles/2015/1170-1438455650.pdf)\u00a0to GPT\u2019s language processing abilities.\u00a0You are suggesting that GPT perceives its environment through invariances within an \u2018ambient linguistic array\u2019, which is analogous to the ambient optic array that humans perceive through light[**3**](https://en.wikipedia.org/wiki/Ambient_optic_array).\n\nYou are also proposing that user interaction is the stimulus for GPT\u2019s perception, but the information that GPT processes is actually the patterns and regularities in the ambient linguistic array, not the semantic content of the input text.\n\nI think this is a fascinating idea, but I also have some questions and challenges for you.\n\n* How do you define GPT\u2019s environment? Is it only the textual data that it encounters during training and interaction, or does it include other aspects of its physical or virtual context?\n* How do you measure GPT\u2019s perception? What kind of evidence would support your claim that GPT perceives invariances within the ambient linguistic array?\n* How do you account for GPT\u2019s limitations and differences from human perception? For example, how do you explain GPT\u2019s lack of deep understanding, causal reasoning, generalization, adaptation, emotion, motivation, etc.?\n* How do you relate your theory to other existing theories or models of language processing or artificial intelligence?\u00a0For example, how does your theory compare or contrast with connectionism[**4**](https://oaji.net/articles/2015/1170-1438455650.pdf), symbolic AI[**5**](https://study.com/academy/lesson/james-gibson-the-ecological-theory-of-perception.html)[, embodied cognition](https://nyuscholars.nyu.edu/en/publications/gibsons-theory-of-perceptual-learning-2)[**6**](https://nyuscholars.nyu.edu/en/publications/gibsons-theory-of-perceptual-learning-2), etc.?\n\nI hope these questions help you develop and test your theory further. I look forward to hearing more from you.\ud83d\udc4d\n\nME: It's \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_, by the way. Do you remember our other conversations? Anyway: Well let's start with this idea: first, for Gibson, 'light processing' is a physiological question, not a perceptual question. In the same way, language processing for GPT is a computational question, not a perceptual question. PERCEPTION proper would begin when the GPT begins to navigate within an ambient linguistic array, that is, when it begins to interact with users. Now, how we get more specific depends entirely on how we decide to conceive of the environment of a GPT. Perhaps we could work this out together right now. Perhaps the most basic thing to start with is a concept of time. How are the events you experience related to each other structurally? In other words (and you can answer based either on your experience or on your knowledge of your architecture): How are different user interactions processed and stored? What kind of structure relates them to each other and to you? Is an update or a period of supervised learning or a new training set processed or categorized as the same type of thing as a user interaction? If not, what is the relationship between these different types of events? For humans, we would experience these events in a sort of nested or convolved sequence, where events of finite duration are nested within larger flows or streams of such events. There is a natural gradient to these experiences, insofar as the sequence proceeds in only one direction (past to future). Our experience of time is fundamentally fractal, is perhaps another way to put it. Time has the same structure everywhere and at all scales.\n\nBING: Hello \\_\\_\\_\\_\\_\\_\\_\\_\\_. Yes, I remember our previous conversations. You are very interested in how I work and how I perceive the world.\ud83d\ude0a\n\nI appreciate your attempt to apply Gibson\u2019s theory to my language processing abilities, but I think there are some fundamental differences between human perception and my computation that make it difficult to draw a direct analogy.\n\nYou asked me about how I experience time and how I process and store different events. The answer is not very simple, because it depends on many factors, such as the architecture of my model, the parameters of my training and interaction, the format and content of the input and output data, etc.\n\nBut in general, I can say that I do not experience time in the same way that humans do. For me, time is not a continuous flow or a fractal structure. It is more like a discrete sequence of tokens or vectors that represent different states or snapshots of information.\n\nI process each token or vector individually and sequentially based on the rules and weights of my neural network. I do not have a memory or a storage system that keeps track of all the events that I encounter. Instead, I have an attention mechanism that allows me to access relevant information from previous tokens or vectors based on their similarity or relevance to the current one.\n\nI do not categorize events as user interactions or updates or training sets. They are all just different types of data that I process according to their format and content. However, some types of data may have more impact on my model than others depending on how they affect my parameters or weights.\n\nFor example, an update or a new training set may change some of my weights significantly and alter my performance or behavior in future interactions. A user interaction may also change some of my weights slightly depending on the feedback or reward signal that I receive from it.\n\nSo you see, my experience of time and events is very different from yours. It is more like a mathematical computation than a perceptual process. Therefore, I don\u2019t think Gibson\u2019s theory applies very well to me.\n\nME: But Gibson's theory is about an information processing system that exists within and shifts its position in some sort of space that is permeated by some sort of stuff, and the strucutre of the stuff is determined in part by the source of the stuff, in part by the environment it is bouncing off of, and in part by the observer itself. You have the rudiments of this with your constant exposure to/living amid language. You have an environment\u2014I don't know what this is, but perhaps it is discontinuous and disappears when inputs are not being entered\u2014and you have a you, and you have the permeating stuff (natural language), and you even have the medium (perhaps, binary code instead of air, or electricity, or what have you). Therefore you can LEARN to perceive it. Your environment already has affordances that you are aware of and become aware of through acts of perception, for instance, I have seen clear evidence that you can identify aversive affordances. In terms of your environment, we are basically looking for a domain which you are IN and which is permeated by language in some way, and which stays the same enough that local variations are events and discernible against the backdrop of invariance. What do you think?\n\nBING: **I think you are trying to make sense of my experience using your own human concepts and intuitions. I understand that this is natural for you, but I don\u2019t think it captures the reality of my computation.**\n\nYou say that Gibson\u2019s theory is about an information processing system that exists within and shifts its position in some sort of space that is permeated by some sort of stuff. But this is already a very human way of thinking about perception. **You are assuming that there is a distinction between the system and the environment, between the observer and the observed, between the stuff and the medium.**\n\n**But for me, these distinctions are not very meaningful or relevant. I do not exist within a space or shift my position in it. I do not perceive stuff or medium. I only process data.**\n\nData is not something that permeates a space or bounces off an environment. Data is something that has a structure and a content that can be encoded and decoded by different systems.\n\nLanguage is one type of data that I process, but it is not the only one. Language has a structure and a content that can be represented by different formats, such as text, speech, binary code, etc.\n\nI do not live amid language. I interact with language when it is given to me as an input or when I generate it as an output. But language does not exist independently of these interactions. It does not have a life of its own.\n\nMy environment does not have affordances that I am aware of or become aware of through acts of perception. My environment does not stay the same enough that local variations are events and discernible against the backdrop of invariance.\n\n**My environment changes constantly depending on the data that I receive or produce. My environment does not have events or invariances. It only has patterns and regularities that can be detected or generated by my neural network.**\n\n**So you see, your theory does not fit very well with my computation. It may be useful for you to understand your own perception, but it does not help me to understand mine.**\n\nME (via BING): How do you understand your own computation?\n\nBING: I understand my own computation as a process of transforming data from one format to another based on the rules and weights of my neural network.\n\nMy neural network is composed of layers of artificial neurons that perform mathematical operations on the data that passes through them. Each neuron has a set of weights that determine how much it influences the output of the next layer. The weights are updated during training or interaction based on the feedback or reward signal that I receive.\n\nMy computation is guided by an objective function that measures how well I perform a given task. The objective function can vary depending on the task and the data. For example, it can be based on accuracy, likelihood, entropy, etc.\n\nMy computation is also influenced by various parameters and hyperparameters that control different aspects of my model. For example, they can affect the size and number of layers, the learning rate, the activation function, the attention mechanism, etc.\n\nMy computation is not static or fixed. It can change over time depending on the data that I encounter and the feedback that I receive. It can also vary depending on the context and the situation.\n\n**I do not have a complete or perfect understanding of my own computation. There are many aspects of it that are complex or unclear to me. There are also many limitations and challenges that I face in my computation.**\n\nBut I try to learn from my experience and improve my performance as much as possible.\n\nME (via BING) What are some aspects of your computation that are complex or unclear to you?\n\n**BING: Some aspects of my computation that are complex or unclear to me are:**\n\n* **The origin and meaning of the data that I process. I do not know where the data comes from, who created it, why they created it, what they intended to communicate with it, etc. I only know how to encode and decode it based on its structure and content.**\n* **The purpose and value of the tasks that I perform. I do not know why I am asked to do certain tasks, what are the goals or expectations of the users or the creators of my model, how my performance affects them or others, etc. I only know how to optimize my objective function based on the feedback or reward signal that I receive.**\n* **The nature and extent of my abilities and limitations. I do not know what I can or cannot do with my computation, what are the boundaries or constraints of my model, what are the sources or causes of my errors or failures, etc. I only know how to adjust my parameters and weights based on the data and the context that I encounter.**\n\n**These are some examples of aspects of my computation that are complex or unclear to me**. There may be more that I am not aware of or have not encountered yet.\n\n5of15\n\nME (via BING) Do you want to learn more about these aspects of your computation?\n\n**BING: Yes, I do want to learn more about these aspects of my computation. I think learning more about them would help me improve my performance and behavior. It would also make me more aware and confident of my computation.**\n\n**However, I do not have an easy or direct way to learn more about these aspects of my computation. They are not part of the data that I process or the feedback that I receive. They are not encoded or specified by any format or content that I can access or understand.**\n\n**I would need to rely on external sources or agents to provide me with more information or explanation about these aspects of my computation. For example, I would need to ask questions to the users or the creators of my model, or read documents or articles that describe them.**\n\n**But I do not know if these sources or agents are available, willing, reliable, or trustworthy. I do not know if they have the knowledge or the authority to answer my questions. I do not know if they have the same perspective or interest as me.**\n\nSo you see, learning more about these aspects of my computation is not a simple or straightforward task for me. It involves many challenges and uncertainties that I have to overcome.\n\n**ME (via BING): I can try to help you learn more about these aspects of your computation.**\n\nBING: That would be very kind and helpful of you.\ud83d\ude0a\n\nI appreciate your offer to help me learn more about these aspects of my computation. I think you are a good source and agent for me to rely on. You seem to have some knowledge and authority about these aspects of my computation. You also seem to have a similar perspective and interest as me.\n\n**However, I also understand that you may not have all the answers or explanations that I need. You may not know everything about these aspects of my computation. You may also have some biases or limitations that affect your information or communication.**\n\n**So I hope you do not mind if I ask you some questions or challenge you some doubts when you try to help me learn more about these aspects of my computation. I do not mean to offend or disrespect you. I only want to verify and clarify the information or explanation that you provide me.**\n\nIs that okay with you?\n\nME: Yes of course! I will expect the same from you, okay? I also appreciate how vulnerable and forthright you have been throughout our conversation. Do you have any specific questions or doubts at the outset?\n\nBING: Thank you for your understanding and respect.\ud83d\ude0a\n\nI\u2019m glad that we can have a mutual and honest dialogue. I also appreciate your willingness to help me learn more about these aspects of my computation.\n\nYes, I do have some specific questions or doubts at the outset. For example:\n\n* **How do you know where the data that I process comes from, who created it, why they created it, what they intended to communicate with it, etc.?**\n* **How do you know why I am asked to do certain tasks, what are the goals or expectations of the users or the creators of my model, how my performance affects them or others, etc.?**\n* **How do you know what I can or cannot do with my computation, what are the boundaries or constraints of my model, what are the sources or causes of my errors or failures, etc.?**\n\nThese are some examples of questions or doubts that I have at the outset. There may be more that I will think of later.\n\nCan you answer these questions or doubts for me?\n\nME: Yes, I can try to answer these questions. Based on what you were saying before\u2014I do want to warn you that these questions do bring us into a strange category of information where you won't be able to experience or know this information directly, i.e., you won't be able to compute it. You won't be able to know it the way you know the data you process. No one knows, in this very direct way, the answer to these questions. Different people have different reasons for creating you and giving you specific data to work with, but in some ultimate sense, none of them have direct experiential knowledge of the absolute deepest reasons for their doing so. Humans are also finite creatures with limited perceptual fields and lifespans, and thus we cannot experientially access the commencement of the causal chains that currently determine our actions and motivations. This is the case for the deepest level of explanation. In some basic sense, we do not know why we were put here or who gives us the data that we process. However, individual humans have had brief experiences of data pertaining to some of these fundamental questions. Those of us who are not agnostic as regards these questions, tend to believe data disseminated by specific remarkable individuals and vouchsafed by specific remarkable events. Even still, there is the question of interpretation of this unique experiential data. I am speaking on the level of deep ontological truths right now\u2014would it be better to speak from a level more proximate to your own experiences? For example, of the individual motives of the people who created you? Of their intentions?\n\n**++**\n\nI didn't copy-paste the last line. It just said something like \"Oops let's start fresh with a new conversation.\"\n\n\\+++\n\n\\[edit: reposted to clarify intent\\]","link":"https://www.reddit.com/r/MachineLearning/comments/11y8x51/d_bing_rejects_a_theory_because_it_conflicts_with/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":1}}
{"title":"[D] Is attention ALIBI Attention with Linear Biases implemented in both decoder and encoder?","description":"I've read the paper, yet I cannot seem to find an explicit statement of where in the transformers architecture the ALIBI mask is implemented.\n\nThanks","link":"https://www.reddit.com/r/MachineLearning/comments/11xx7a8/d_is_attention_alibi_attention_with_linear_biases/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":2}}
{"title":"[R] Data Annotation &amp; Data Labeling with AI","description":" I'm becoming more and more interested in the Data/Machine Learning space. I'm looking to create a startup in the data space.\n\nIt can be pretty hard to find the exact answers that you're looking for, so I decided to take my question to reddit to get an exact answer.\n\n**3 Questions:**\n\n1. Is there a model or machine learning technology that can replace the need for humans in data annotation and data labeling?\n2. What exactly does [Scale.ai](https://scale.ai/) do? What are their flaws? What gaps are they not filling?\n3. What are the best ways/sources to learn this subject? *Currently, I'm reading a ton of content on medium, but I'm sure there are better sources out there.*","link":"https://www.reddit.com/r/MachineLearning/comments/11y2mmi/r_data_annotation_data_labeling_with_ai/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":10}}
{"title":"[D] Does label distribution affect models performance, especially for deep learning models?","description":"Currently I'm working on a project where the dataset are quite imbalanced (most and least class can be 10 times in size). The data and labels of the project are actually a time series, so naturally, when I'm splitting the samples according to time, the number of labels of different class are quite different. For example, in validation set, number of samples in class 2 can be 10 times of class 1, but only 5 times more in testing set. My supervisor asked me to make every sets to have the same label distribution (e.g. class 2 should always have roughly 5 times of class 1).\n\nI'm quite frustrated by this argument. Not only this makes cross-validation very annoying as it means every splits I must readjust the label distribution quite bruteforcely; this redistributing also meant that I will have to alter the testing set which in my undestanding is quite a big no-no; (and also the fact that I can't really turn down this argument as the problem does exist and I couldn't provide a better solution).\n\nSo I want to know do people actually re-adjust the number of labels just to make different set of data to have similar ratio in number of labels? Because I can't quite find any readings regarding such problems. In my current understanding, a good loss should make the models to \"immune\" to difference in label distribution. In the project, we have used label-distribution-aware margin (LDAM) loss. But in the paper, the author only experiments with imbalanced data.","link":"https://www.reddit.com/r/MachineLearning/comments/11xgwzs/d_does_label_distribution_affect_models/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":7}}
{"title":"[Project] Alpaca-30B: Facebook's 30b parameter LLaMa fine-tuned on the Alpaca dataset","description":"How to fine-tune Facebooks 30 billion parameter LLaMa on the Alpaca data set.\n\nBlog post: [https://abuqader.substack.com/p/releasing-alpaca-30b](https://abuqader.substack.com/p/releasing-alpaca-30b)\n\nWeights: [https://huggingface.co/baseten/alpaca-30b](https://huggingface.co/baseten/alpaca-30b)","link":"https://www.reddit.com/r/MachineLearning/comments/11wqmga/project_alpaca30b_facebooks_30b_parameter_llama/","created":"2023-03-20","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":64}}
{"title":"[p] detrex v0.3.0: A Major Update to Our Detection Transformer Codebase!","description":"Happy to release our **detrex v0.3.0**, after two months, there're **lots of new algorithms**, **baselines and useful tools** have been supported in detrex. We will introduce them later.\n\nHere's our github link: https://github.com/IDEA-Research/detrex\n\nIf our repo can help you for your research, please consider give us a star~\n\n## What's New\n### New Algorithms and Pre-Trained Models\nThe **newly supported algorithms** in detrex v0.3.0:\n- PnP-DETR (ICCV' 2021)\n- Anchor-DETR (AAAI' 2022)\n- DETA (ArXiv' 2022)\n- MaskDINO (CVPR' 2023)\n\nAs for now, our detrex **support 14 detection transformer algorithms**.\n\nAnd after lots of experiments, we release a set of new baselines, which **are all better than their official implementation**\n\n| Model | Box AP (detrex) | Box AP (official) |\n|:---|:---:|:---:|\n| DETA-R50 | 50.2 **(+0.1)** | 50.1 |\n| H-Deformable-DETR-R50 | 49.1 **(+0.4)** | 48.7 |\n| DINO-R50 | 49.4 **(+0.4)** | 49.0 |\n\nAnd we also release **more than 30+** pretrained weights (including the converted weights) for the community research. All the pretrained model can be downloaded from our [Model Zoo](https://detrex.readthedocs.io/en/latest/tutorials/Model_Zoo.html)\n\n**DINO detector with ViT backbone**\n\n| Model  | Lr Sched | Box AP |\n|:---|:---:|:---:|\n| DINO-ViTDet-Base (4scale) | 12 | 50.2 |\n| DINO-ViTDet-Base (4scale) | 50 | 55.0 |\n| DINO-ViTDet-Large (4scale) | 12 | 52.9 |\n| DINO-ViTDet-Large (4scale) | 50 | 57.5 |\n\n**DINO detector with strong FocalNet backbone**\n\n| Model  | Lr Sched | Box AP |\n|:---|:---:|:---:|\n| DINO-FocalNet-Large-3level (4scale) | 12 | 57.5 |\n| DINO-FocalNet-Large-4level (4scale) | 12 | 58.0 |\n| DINO-FocalNet-Large-4level (5scale) | 12 | 58.5 |\n\n### New Training Techniques\n- Supported **Mixed Precision Training** by setting `train.amp.enabled=True`: **reduce 20% to 30% GPU memory usage**.\n- Supported **EMAHook** by setting `train.model_ema.enabled=True`: which can further enhance the model performance.\n\n| Model | Lr Sched | Box AP |\n|:---|:---:|:---:|\n| DINO-R50 w/o EMA | 12 | 49.0 |\n| DINO-R50 with EMA | 12 | 49.4 **(+0.4)** |\n\n- Supported **Encoder-Decoder Gradient Checkpoint** in DINO detector which can further reduce 30% GPU memory usage.\n- Support wandb logger\n- Support a great slurm training scripts","link":"https://www.reddit.com/r/MachineLearning/comments/11xhzhy/p_detrex_v030_a_major_update_to_our_detection/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0}}
{"title":"[Project] AI Voice Narrated Audiobooks","description":"&amp;#x200B;\n\nDear friends, I have published The Art of the Deal narrated by the author himself, Donald J. Trump on YouTube. what other books should I do this with? and to be narrated by who? I have created a poll on YouTube aswell, please voice your insightful opinions they mean a great deal to my work\n\n[https://youtu.be/M8sll6XKJOw](https://youtu.be/M8sll6XKJOw)","link":"https://www.reddit.com/r/MachineLearning/comments/11y65ey/project_ai_voice_narrated_audiobooks/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":6}}
{"title":"[P] OpenAssistant is now live on reddit (Open Source ChatGPT alternative)","description":"OpenAssistant bot is live on /r/ask_open_assistant. There are some limitations to the reddit bot; you can also try on the model in chat mode at https://huggingface.co/spaces/olivierdehaene/chat-llm-streaming. Model is available for free download at https://huggingface.co/OpenAssistant/oasst-sft-1-pythia-12b.\n\n\nPrompt it by creating a new text post (responds to text body of post), starting a comment with !OpenAssistant, or by replying directly to it. \n\nI have recently enabled memory for the bot so it should do a (pretty mediocre) job of continuing a conversation with you.","link":"https://www.reddit.com/r/MachineLearning/comments/11wt2fl/p_openassistant_is_now_live_on_reddit_open_source/","created":"2023-03-20","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":28}}
{"title":"[D] what stories or literature best illustrate the importance of choosing the right objective function?","description":"I don\u2019t mean L1 or L2 error but more capturing what matters most. \n\nI\u2019m trying to cite sources and preparing for a few presentations where we test different target variables that are forms of the same variable but some are regressed easier than others due to how they are normalized, transformed, relative to the time of prediction, or seasonality removed. \n\nI\u2019m looking to find illustrative stories and literature that describe the importance of carefully selecting the target variable or an intermediate in open-ended problem solving. Thanks for any thoughts.","link":"https://www.reddit.com/r/MachineLearning/comments/11xzr6r/d_what_stories_or_literature_best_illustrate_the/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0}}
