{"title":"Using CharBERT for text similarity","description":"Hi all!\n\nI'm looking into [CharBERT](https://arxiv.org/abs/2011.01513) for an university project, and I noticed that it was finetuned on many tasks like sentiment analysis, NER, and so on. I tried to use it to do text similarity by using only the pretrained version the authors give + a cosine similarity algorithm between word embeddings: is this the way to go? Should I treat the embeddings the model gives in some way before calculating the cosine distance?","link":"https://www.reddit.com/r/deeplearning/comments/11ycciy/using_charbert_for_text_similarity/","created":"2023-03-22","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":1}}
{"title":"Training on distributed system/ own cluster","description":"Hi Reddit,\nIs there a way to increase training speed of a own model by putting it on several consumer computers / laptops?\nOr in other words can i set up an own sort of cluster for LLM training/finetuning?\nAnyone give me some hints?","link":"https://www.reddit.com/r/deeplearning/comments/11ybkl6/training_on_distributed_system_own_cluster/","created":"2023-03-22","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0}}
{"title":"Minimizing model training stability","description":"Hello good people of reddit,  \n\n\ni've been developing a neural net for some time and im currently reaching sufficiently low RMSE in some cases. What im having an issue is the deviation of rmse during multiple training runs. This is showing to be very problematic since in some cases i get three times the desirable RMSE.  I applied most of the techniques i can imagine could help with this but non of it really works. I normalize the input data, use dropout, batch normalization as well as decaying learning rate and weight initializers.  \n\n\nIs there any other technique that im missing that could help with it ?","link":"https://www.reddit.com/r/deeplearning/comments/11ye16q/minimizing_model_training_stability/","created":"2023-03-22","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0}}
{"title":"Reduced Memory Usage with Burn: A Deep Learning Framework written in Rust","description":"I announced last year on the Rust subreddit Burn, the deep learning framework I'm building in Rust.\n\nWhile building machine learning tools in a language other than Python goes against the trend, I humbly believe it is a promising avenue. There has been a lot of work since the last release, and now we're starting to see some benefits. Burn uses less memory, especially on the CPU during both inference and training than PyTorch with a similar computational graph. I wrote a technical blog post about it, describing how Burn allows for the reuse of tensor-allocated memory ([**https://burn-rs.github.io/blog/burn-rusty-approach-to-tensor-handling**](https://burn-rs.github.io/blog/burn-rusty-approach-to-tensor-handling)).\n\nThere is still a lot more work to be done before being really competitive with other frameworks, notably properly supporting operation fusion. But Burn is still usable today, and you can even run inference in the browser using WebAssembly ([**https://burn-rs.github.io/demo**](https://burn-rs.github.io/demo)).  \n\n\nIf you have any questions regarding the blog, Rust, or Burn, I'm happy to answer them below.","link":"https://www.reddit.com/r/deeplearning/comments/11xtmnf/reduced_memory_usage_with_burn_a_deep_learning/","created":"2023-03-21","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0}}
{"title":"Alpaca Turbo : A chat interface to interact with alpaca models with history and context","description":"So I made this chat UI that will help you use alpaca models to have coherent conversations with history and the bot will remember your previous questions  \n\n\nHere is the demo  \n\n\nyou can get the interface from [https://github.com/ViperX7/Alpaca-Turbo](https://github.com/ViperX7/Alpaca-Turbo)  \n \n\nhttps://reddit.com/link/11xdx3w/video/o7jpmysvt2pa1/player","link":"https://www.reddit.com/r/deeplearning/comments/11xdx3w/alpaca_turbo_a_chat_interface_to_interact_with/","created":"2023-03-21","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":17}}
{"title":"It would be cool if there was a machine learning Nes Emulator, that the ai could learn to play automatically and you just run it on your pc till it finds the optimum root.","description":"","link":"https://www.reddit.com/r/deeplearning/comments/11xx3r6/it_would_be_cool_if_there_was_a_machine_learning/","created":"2023-03-21","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":3}}
{"title":"Anyone knows what is the minimum requirement to run the dalai alpaca 7B? Does the CPU matter or GPU?","description":"Can I run it using a machine i7 from 2014 with 16gb ram?","link":"https://www.reddit.com/r/deeplearning/comments/11xpyrh/anyone_knows_what_is_the_minimum_requirement_to/","created":"2023-03-21","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":2}}
{"title":"Adding Number of Sequence into dataset","description":" \n\nI will adding the number of sequence to original data. each array will be adding number of sequence based on iteration.\n\noriginal data :\n\n \n\n    a = np.array([     [-0.939,3838,393],     [7.937,7373,283],     [8.293,2222,838] ])\n    \n    after adding seqeunce number, the data look like above:\n    \n    a = np.array([\n        [1,-0.939,3838,393],\n        [2,7.937,7373,283],\n        [1,8.293,2222,838]\n    ])\n    \n    what is the technique above? is it the part of data preprocessing such as feature engineering or data augmentation or not","link":"https://www.reddit.com/r/deeplearning/comments/11xid8v/adding_number_of_sequence_into_dataset/","created":"2023-03-21","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0}}
{"title":"CoDev- A GPT 4.0 Virtual Developer To Generate Apps","description":"&amp;#x200B;\n\n&amp;#x200B;\n\nCoDev is a GPT 4.0 virtual developer prompt to help you create and refine boilerplates/apps. You can get the prompt from my GitHub link below, paste it in a new Chat session, and issue the commands (see How To Use CoDev). In this article, we will use CoDev to create a React/Typescript/MUI dashboard boiler plate\n\n[https://medium.com/@etherlegend/codev-a-gpt-4-0-virtual-developer-to-build-app-boilerplates-34a431e779c7](https://medium.com/@etherlegend/codev-a-gpt-4-0-virtual-developer-to-build-app-boilerplates-34a431e779c7)","link":"https://www.reddit.com/r/deeplearning/comments/11x3p2u/codev_a_gpt_40_virtual_developer_to_generate_apps/","created":"2023-03-21","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":5}}
{"title":"Searching for an AI script/program","description":"Is there any AI program that works like first-order-model / wav2lip but it is combination of those two?I mean creating your reference video and transfer lips and face movement onto the destination video?\n\nIf not, I have an Idea on how to do this but I'm lack of abilities with programming to do this on my own. It could export every frame of our destination video and use it as a single photo to animate, but instead of recreating our whole reference motion on individual frame from the destination video it could recreate 1 frame from source video to 1 frame in destination video and after that compile changed frames into a whole video.\n\nI know we can animate photo with reference video, but I couldn't find animating face in videos. Wav2Lip is not that dynamic, and first-order-model only stick to animating photos.\n\nI think we can modify those two scripts and automate the process to stick with frame by frame changes.\n\nCan someone help with this idea? What are your thoughts? Or maybe there is someone who already done that?","link":"https://www.reddit.com/r/deeplearning/comments/11xd4lz/searching_for_an_ai_scriptprogram/","created":"2023-03-21","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0}}
{"title":"Implementing new dataset on CV arch.","description":"I want to implement the \\[PIE dataset\\]\\[1\\] in the \\[AgentFormer arch\\]\\[2\\]. \n\nAgentFormer uses ETH and nuScene datasets. I successfully run these datasets on this arch. However, I couldn't take a good way with the PIE dataset. I am not sure how I could write a new data loader for it. Which steps should I take? \n\nI normally have experience in implementing articles without looking at similar GitHub codes, but this time I stuck. \n\n&amp;#x200B;\n\nThank you for any help. \n\n&amp;#x200B;\n\n&amp;#x200B;\n\n  \\[1\\]: [https://github.com/aras62/PIE](https://github.com/aras62/PIE)\n\n  \\[2\\]: [https://github.com/Khrylx/AgentFormer](https://github.com/Khrylx/AgentFormer)","link":"https://www.reddit.com/r/deeplearning/comments/11x3p1d/implementing_new_dataset_on_cv_arch/","created":"2023-03-21","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0}}
{"title":"Alpaca-7B and Dalai, how can I get coherent results?","description":"Recently, I installed dalai on my Macbook Pro (late 2019, i7 processor and 16GB of RAM) and I also installed Alpaca-7B model. Now when I ask it to write a tweet, it writes a wikipedia article and it does the same pretty much every time \ud83d\ude02\n\nFirst, should I fine-tune it?\n\nSecond, is there any \"prompt magic\" going on here?\n\nP.S: using [this one](https://github.com/tloen/alpaca-lora),  I got much better results. What's the difference between the two?","link":"https://www.reddit.com/r/deeplearning/comments/11wdi8m/alpaca7b_and_dalai_how_can_i_get_coherent_results/","created":"2023-03-20","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":11}}
{"title":"How to get the clossest word from a vector, fasttext embeding","description":"using ft.get_word_vector(string) you get the vector embedding of that string, is there a way to get the word if a given vector?\nsomthing like this: ft.get_word_of_vector(vector)?\nthis is using fasttext","link":"https://www.reddit.com/r/deeplearning/comments/11wo1zi/how_to_get_the_clossest_word_from_a_vector/","created":"2023-03-20","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":1}}
{"title":"Error while training yolov5","description":"Just after starting the traing this error shows up . Please help ! \n\nYOLOv5  v7.0-120-g3e55763 Python-3.8.16 torch-2.0.0 CPU \n\nSetup complete  (8 CPUs, 16.0 GB RAM, 183.8 / 460.4 GB disk)  \n[/AppleInternal/Library/BuildRoots/c651a45f-806e-11ed-a221-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:82](https://file+.vscode-resource.vscode-cdn.net/AppleInternal/Library/BuildRoots/c651a45f-806e-11ed-a221-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:82): failed assertion \\`\\[MPSNDArrayDescriptor sliceDimension:withSubrange:\\] error: subRange.start (3) is not less than length of dimension\\[1\\] (3)'","link":"https://www.reddit.com/r/deeplearning/comments/11wr7fz/error_while_training_yolov5/","created":"2023-03-20","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0}}
{"title":"3 interviews with exceptional NVIDIA people to launch my new podcast, \"What's AI by Louis Bouchard\"!","description":"In this short series, we learn a lot about the Data Science world at NVIDIA (more on what are a data scientist and a solution architect), Kaggle, scaling large models, the NVIDIA interview process (and improving at them), how it is to work at such a big company, and more.\n\nThere are many valuable insights from Chris Deotte, Meriem Bendris, and Adam Grzywaczewski.  \nIt is also in partnership with NVIDIA GTC running all week, where they provided me with an RTX 4080 to giveaway to help promote this new project.\n\nIf you want to learn more about AI and inspiring personas in the field, have a look at the new podcast (available on Spotify, Apple podcasts, and YouTube): [https://podcasters.spotify.com/pod/show/louis-bouchard](https://podcasters.spotify.com/pod/show/louis-bouchard)\n\nPlease let me know what you think of these interviews and if you know anyone (including you) that would like to be interviewed! :)\n\nIf you want to learn more from the interviewees, have a look at GTC this week: [https://nvda.ws/3XQRtkl](https://nvda.ws/3XQRtkl)","link":"https://www.reddit.com/r/deeplearning/comments/11wkzz3/3_interviews_with_exceptional_nvidia_people_to/","created":"2023-03-20","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0}}
