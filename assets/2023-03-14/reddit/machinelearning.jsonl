{"title":"[D] Simple Questions Thread","description":"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!","link":"https://www.reddit.com/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/","created":"2023-03-12","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":22}}
{"title":"[R] Stanford-Alpaca 7B model (an instruction tuned version of LLaMA) performs as well as text-davinci-003","description":"According to the authors, the model performs on par with text-davinci-003 in a small scale human study (the five authors of the paper rated model outputs), despite the Alpaca 7B model being much smaller than text-davinci-003. Read the blog post for details.\n\nBlog post: https://crfm.stanford.edu/2023/03/13/alpaca.html\nDemo: https://crfm.stanford.edu/alpaca/\nCode: https://github.com/tatsu-lab/stanford_alpaca","link":"https://www.reddit.com/r/MachineLearning/comments/11qfcwb/r_stanfordalpaca_7b_model_an_instruction_tuned/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":97}}
{"title":"[P] ControlNetInpaint: No extra training and you can use \ud83d\udcddtext +\ud83c\udf0cimage + \ud83d\ude37mask to generate new images.","description":"Hi! Here's an **open-source implementation** I released today for masked ControlNet synthesis, where you can specify the region that will be synthesised using a mask. The content of the synthesised region is controlled via textual and visual guidance as shown in the README.\n\n[https://github.com/mikonvergence/ControlNetInpaint](https://github.com/mikonvergence/ControlNetInpaint)\n\nHere's an example with a prompt of ***\"a red panda sitting on a bench\"*****:**\n\nhttps://preview.redd.it/4vxsg9sc0lna1.png?width=1860&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9776369a86043f9420ec8771dd6f9d22308e521c","link":"https://www.reddit.com/r/MachineLearning/comments/11qnv4c/p_controlnetinpaint_no_extra_training_and_you_can/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":1}}
{"title":"[D] ICML 2023 Paper Reviews","description":"ICML 2023 paper reviews are supposed to be released soon. According to the [website](https://icml.cc/Conferences/2023/Dates), they should be released on March 13 (anywhere on earth). I thought to create a discussion thread for us to discuss any issue/complain/celebration or anything else.\n\nThere is so much noise in the reviews every year. Some good work that the authors are proud of might get a low score because of the noisy system, given that ICML is growing so large these years. We should keep in mind that the work is still valuable no matter what the score is.\n\nAccording to the Program Chair's [tweet](https://twitter.com/kchonyc/status/1635126401807585280), it seems that only \\~91% of the reviews are submitted. Hopefully it will not delay the release of the reviews and the start of the rebuttal.","link":"https://www.reddit.com/r/MachineLearning/comments/11q9pqj/d_icml_2023_paper_reviews/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":30}}
{"title":"[R] Training Small Diffusion Model","description":"Does anyone have experience training a small diffusion model conditioned on text captions from scratch on 64x64 images or possibly even smaller? \n\nI would like to run it only on images of text to see if it is able to render text. How long would this potentially take if I ran it on 1-2 GPUs? Is this something that\u2019s even possible?","link":"https://www.reddit.com/r/MachineLearning/comments/11qynbp/r_training_small_diffusion_model/","created":"2023-03-14","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":3}}
{"title":"[D] ChatGPT without text limits.","description":"One of the biggest limitations of large language models is the text limit. This limits their use cases and prohibits more ambitious prompts.\n\nThis was recently resolved by researchers at Google Brain in Alberta, Canada. In their recent paper they describe a new method of using associative memory which removes the text limit and they also prove that some large language models are universal Turing machines.\n\nThis will pave the way for entire novels being shared with large language models, personal genomes, etc.\n\nThe paper talks about the use of \"associative memory\" which is also known as content-addressable memory (CAM). This type of memory allows the system to retrieve data based on its content rather than its location. Unlike traditional memory systems that use specific memory addresses to access data, associative memory uses CAM to find data based on a pattern or keyword.\n\nPresumably, this will open up a new market for associative memory since I would happily pay some extra money for content to be permanently stored in associative memory and to remove the text limit. This will also drive down the price of associative memory if millions of people are willing to pay a monthly fee for storage and the removal of prompt text limits.\n\nThe paper does point that there are still problems with conditional statements that confuse the large language models. However, I believe this can be resolved with semantic graphs. This would involve collecting data from various sources and using natural language processing techniques to extract entities and relationships from the text. Once the graph is constructed, it could be integrated into the language model in a variety of ways. One approach is to use the graph as an external memory, similar to the approach taken in the paper. The graph can be encoded as a set of key-value pairs and used to augment the model's attention mechanism during inference. The attention mechanism can then focus on relevant nodes in the graph when generating outputs.\n\nAnother potential approach is to incorporate the graph into the model's architecture itself. For example, the graph can be used to inform the initialization of the model's parameters or to guide the attention mechanism during training. This could help the model learn to reason about complex concepts and relationships more effectively, potentially leading to better performance on tasks that require this kind of reasoning.\n\nThe use of knowledge graphs can also help ground truth large language models and reduce hallucinations.\n\nI'm curious to read your thoughts.","link":"https://www.reddit.com/r/MachineLearning/comments/11qgxs8/d_chatgpt_without_text_limits/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":11}}
{"title":"[R] MathPrompter: Mathematical Reasoning using Large Language Models. New State of the Art on MultiArith ( 78.7% to 92.5%) with Text-Davinci 002","description":"Paper - [https://arxiv.org/abs/2303.05398](https://arxiv.org/abs/2303.05398)","link":"https://www.reddit.com/r/MachineLearning/comments/11q8w62/r_mathprompter_mathematical_reasoning_using_large/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":16}}
{"title":"[D] Comparing models implemented in PyTorch and Tensorflow","description":"\nHola!\n\nI am working on comparing some models, few of which have been implemented in PyTorch and the rest of them in Tensorflow (some in 1.x and others in 2.x versions). I know if they are implemented well, one should be able to simply compare their graphs/performances regardless of the platform. But often there might be some subtle differences in the implementations (within the platforms themselves and the way model code utilizes it) that can make it painful to trust the training. Some models are from official sources so I'd rather not verify much of their code before using them. Of course, I don't want to implement all of them into a single platform unless I must.\n\nIf you have come across such a problem, how have you dealt with it? Are there certain tests you would conduct to ensure the loss curves can be compared? How would you go about this issue other than finding someone else's implementation of say, a TF model in PyTorch, and verifying it?\n\nSincerely,\nA man in crisis.","link":"https://www.reddit.com/r/MachineLearning/comments/11qwzb6/d_comparing_models_implemented_in_pytorch_and/","created":"2023-03-14","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":3}}
{"title":"[P] Build a Question Answer system/chat bot trained on documentation.","description":"Hi everyone! I'm working on a side project for my company where the goal is to train an ML model on the company's documentation. We should then be able to ask it any question based on the docs and it should generate a concise response( something like what chatgpt does). How can I achieve this? \nThanks you in advance :)","link":"https://www.reddit.com/r/MachineLearning/comments/11qxys6/p_build_a_question_answer_systemchat_bot_trained/","created":"2023-03-14","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":2}}
{"title":"\"[D]\" ,\"[R]\" Applications of Deep belief Networks","description":"What will be the future of deep belief networks, RBM in the current ML research?   \n\n\nWhat are the advantage of these compared to existing models ?  \n\n\nAre there any practical applications of these methods?","link":"https://www.reddit.com/r/MachineLearning/comments/11r157c/d_r_applications_of_deep_belief_networks/","created":"2023-03-14","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0}}
{"title":"[D] NLP - Merging token embeddings for smaller input sizes","description":"We all know that one of the main problems with current LLMs is their limited input size. \n\nHowever, for certain applications like code modeling, joining common tokens into a single one can make sense and reduce the vocabulary drastically. Example: if you are modeling Python code, probably you can consider \\`import\\` as a single token, instead of having two tokens like \\`im\\` + \\`port\\`.   \n\n\nDoes this work in practice? Are there any resources on this? Maybe averaging the tokens into a single embedding and adding that to the vocabulary and tokenizer is enough?   \nI've seen some [work on token merging for images](https://openreview.net/pdf?id=JroZRaRw7Eu), but not for text.\n\nThank you in advance!","link":"https://www.reddit.com/r/MachineLearning/comments/11r10yz/d_nlp_merging_token_embeddings_for_smaller_input/","created":"2023-03-14","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0}}
{"title":"[R] New grand challenge on generative models for medical imaging","description":"Want to advance generative AI for medical imaging? \ud83e\udd16\n\nJoin us in the [2023 AAPM Grand Challenge on Deep Generative Modeling for Learning Medical Image Statistics!](https://www.aapm.org/GrandChallenge/DGM-Image/default.asp) This year, we're calling all the GAN gurus, VAE virtuosos, and diffusion dreamers to showcase their generative genius in developing a model that can accurately learn medical imaging statistics apart from creating beautiful synthetic images with low FID.\n\nWe all know that generative AI produce unpredictable hallucinations, which is why our goal is to create an evaluation benchmark based on domain-specific statistics meaningful to medical imaging. Register now to become a part of this challenge!\n\nhttps://preview.redd.it/gf4a5d2g4jna1.png?width=1024&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2849f1d227c0613b2bc1329ef2b1369aa4bac6c2","link":"https://www.reddit.com/r/MachineLearning/comments/11qdji0/r_new_grand_challenge_on_generative_models_for/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":1}}
{"title":"Productionize training pipeline vs model artifact? [D]","description":"Let's say you have ETL,  training, and inference pipelines. Is it best practices to promote all pipelines to production (you will have one model artifact in dev env and one model artifact in prod env) or keep the training pipeline in dev and only promote the resulting model artifact + ETL/inference pipelines? Why?","link":"https://www.reddit.com/r/MachineLearning/comments/11qu3qc/productionize_training_pipeline_vs_model_artifact/","created":"2023-03-14","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":1}}
{"title":"[D] Importance of square root in denominator for AdaGrad","description":"I have seen in a lot of places that without the square root operation, the algorithm performs much worse, such as [https://www.ruder.io/optimizing-gradient-descent/](https://www.ruder.io/optimizing-gradient-descent/).\n\nSo I tried to set up a small experiment with the exponent of the denominator of the learning rate as a hyperparameter. The problem setup is house price prediction, and I am performing stochastic gradient descent with AdaGrad on the California Housing Dataset. Here is what I got.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/8o55320fjjna1.png?width=2783&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d1fa7175f6f7585bf66ce08bc32cb39929ec0d8c\n\nNow the square root, i.e. 0.5 performs pretty well, but there is no predictable pattern for the others. Has anyone analyzed why the square-root is important, and what advantages it has? 0.8 exponent has a better convergence as it achieves optimum value from the start itself.","link":"https://www.reddit.com/r/MachineLearning/comments/11qfpbf/d_importance_of_square_root_in_denominator_for/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":2}}
{"title":"[Research] NeRFshop: Interactive Editing of Neural Radiance Fields, I3D 2023","description":"Twitter link: [https://twitter.com/clementjbn/status/1635200991523139584](https://twitter.com/clementjbn/status/1635200991523139584)  \n\n\nTLDR: instant-ngp based interface for editing of NeRF objects. Format exportable to instant-ngp app.","link":"https://www.reddit.com/r/MachineLearning/comments/11q6gco/research_nerfshop_interactive_editing_of_neural/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0}}
{"title":"[D] Are modern generative AI models on a path to significantly improved truthfulness?","description":"I just posted this on r/ChatGPT but thought there might be some great thoughts here, too.\n\nChatGPT generates believable output but, as many have noted, not trustworthy output. A lot of the use cases I see for future generative AI models seem to crucially depend on making believable AND truthful responses. But given that it's probably easier to make believable but non-truth responses (since more of them exist), I imagine that this is a very hard prospect. Is it even possible with current methods?\n\nFrom my read, modern generative AI models can only increase correctness of output in 2 ways. Using more correct data, and using human labellers for fine-tuning. Having more correct data either requires much smaller datasets (even academic journals can't be considered correct since science evolves over time) or human expertise in correcting the data. So it seems like human expertise remains vital.\n\nNow I know that human labellers were necessary to reduce the toxicity of GPT-3 responses. I read that something like dozens were used over a period of months, though I don't know if this is publicly shared by OpenAI. But how important is human training in driving up \"truthfulness\" of these models?\n\nI briefly reviewed this paper and it talks about InstructGPT being better than GPT-3 at truthfulness, even with 1/100th of the parameters (1.3B parameters vs 175B of GPT-3). But I also understand that larger models tend to lie more, so that could be part of it. And even though it is \"more truthful\", the metric used to compare seems suspect to me, especially since \"InstructGPT still makes simple mistakes\", including making up facts.\n\nIt seems here like little improvement in truthfulness.\n\nWithout a clear path to increasing this vital metric, I struggle to see how modern generative AI models can be used for any important tasks that are sensitive to correctness. That's still a lot of cool things, but we seem far from even a good search engine, from assisting researchers, or even from coding support. (I have used ChatGPT for this latter purpose, and sometimes it helps me more quickly, but sometimes it makes it slower because it's flat-out false. Stackoverflow is generally much more trustworthy and useful for me so far.) And certainly we are really far from anything remotely \"AGI\".","link":"https://www.reddit.com/r/MachineLearning/comments/11qgasm/d_are_modern_generative_ai_models_on_a_path_to/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":18}}
{"title":"[D]: Generalisation ability of autoencoders","description":"What is the current state-of-the-art when it comes to the generalisation ability of autoencoders?\nI have been working with text autoencoders for some time and, although they work well on the training data, they generalise very poorly to unseen sentences (as, for example, noted here: \nhttps://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=there+and+back+again+autoencoder&amp;btnG=#d=gs_qabs&amp;t=1678725350369&amp;u=%23p%3DksKOTTf1c1IJ). How do image autoencoders do with unseen images? What research efforts are underway to improve generalisation ability?","link":"https://www.reddit.com/r/MachineLearning/comments/11qejcz/d_generalisation_ability_of_autoencoders/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":9}}
{"title":"[P] Introducing \ud83c\udf00 Ciclo: A functional training loops library for JAX","description":"# \ud83c\udf00 Ciclo\n\n*A functional training loops library for JAX*\n\n`ciclo` provides a set of utilities and abstractions to build complex training loops with any JAX framework. `ciclo` defines a set of building blocks that naturally compose together and scale up to build higher-level abstractions, ranging from low-level custom training loops to Keras-like training APIs.\n\n**Features**\n\n\u2714\ufe0f Training utilities \n\n\u2714\ufe0f Loop language \n\n\u2714\ufe0f Predefined Loops \n\n\ud83e\uddea Managed API (simplified training + parallelism support)\n\n\ud83e\uddea Framework support (predifined states)   \n\n\nRepo: [https://github.com/cgarciae/ciclo](https://github.com/cgarciae/ciclo)\n\nAnnouncement tweet: [https://twitter.com/cgarciae88/status/1635016202925010944](https://twitter.com/cgarciae88/status/1635016202925010944)\n\n  \n**Show case**  \n\ud83c\udf00 Ciclo's core API is the `loop` mini-language that lets you express arbitrary training loops by composing schedules and callbacks.\n\nhttps://preview.redd.it/0twnp80osina1.jpg?width=1938&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=2c3d78e99057e228ac7fce4d857aa33c69594572\n\nCiclo also provides a set of predefined loops (train\\_loop, test\\_loop, predict\\_loop) for common patterns, these are super-sets of \\`loop\\` that additionally provide \"named schedules\":\n\nhttps://preview.redd.it/whqyxfaxsina1.jpg?width=1938&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=ad473ba0d468a21e47a75356dba2a2bd3c914be7\n\nFinally, Ciclo also aims to provide framework support for simple supervised-like tasks via custom states that come with predefined methods (e.g. train\\_step), giving a simplified Keras-like experience.  \n\n\nhttps://preview.redd.it/2lubzkqjtina1.jpg?width=2230&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0251fffaf7de5de87524145698107b5fff11bd92\n\nMore info: [https://cgarciae.github.io/ciclo/](https://cgarciae.github.io/ciclo/)","link":"https://www.reddit.com/r/MachineLearning/comments/11qc3nz/p_introducing_ciclo_a_functional_training_loops/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0}}
{"title":"[Discussion] Searching for end-to-end MLOps training solution","description":"I am working in a small research group and we recently found a problem with our resource utilization. We have 11 servers with 4 gpus in each and I am looking for an automatic execution manager with a queue. Currently we don't have anything in place and just write in a table which GPU is occupied by who, which, as you can imagine, is not ideal, our current utilization is around 50-60%. So we came up with the following two requirements:\n\n* Queue for training/inference tasks with dynamic GPU allocation (ex. you can launch 4 tasks on one machine that require 1 GPU each, or 2 tasks with 2 GPU, etc.)\n* Ability to reserve GPUs so that you can connect to the host and work directly (for example you want to launch 3rd party repository with complex environment setup)\n\nThe only solution I found so far is ClearML with clearml agent, but there are two problems with it, the first one is dynamic GPU allocation is available only in enterprise edition, which means that we need to reserve some hosts to run 2 GPU tasks and some that run 1 GPU tasks, which is not ideal. The second is that you can't directly tell clearml to not use some gpu for the time, so we used a crutch - launch an task with infinite loop in it that does nothing, which is once again is not ideal.\n\nHave some of you encountered a similar problems? How did you solve it? Maybe there is a solution that we missed, any help is appreciated.","link":"https://www.reddit.com/r/MachineLearning/comments/11q53pp/discussion_searching_for_endtoend_mlops_training/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":8}}
{"title":"Sagemaker studio notebooks vs Colab Pro+ [D]","description":" \n\nHi there, has anyone had experiences with both?\n\nI've  been using colab for quite a while, and it's a bit intransparent with  it's new model of computing units, also sometimes you don't get access  to gpus anymore despite (or because of see github, colab sub) the  subscription.\n\nI think the pricing  seems very fair, though I wasn't able to find signle GPU instances with  &gt; 16 GB of memory and that I get for free already with kaggle,  studiolab or colab (if I don't subscribe, lol).\n\nMany thanks for sharing your insights and experiences.","link":"https://www.reddit.com/r/MachineLearning/comments/11q7jlo/sagemaker_studio_notebooks_vs_colab_pro_d/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0}}
{"title":"[R] Optimal Data Acquisition Strategy","description":"tl;dr: Looking for state of the art methods on how to select which additional training data to acquire to improve image classification performance (key words, authors, etc. wanted)\n\nHi all,\n\nI am training an image classification algorithm and want to improve the performance. For this I have the option to acquire new training data. \n\nI was wondering: Is there a specific method on how to select which examples likely will boost overall performance? Something like an \u201eoptimal data acquisition strategy\u201c?\n\nOfc, the naive way is to rebalance classes, add more examples of low performing clusters etc. However, I could not find the specific field of machine learning research dealing with these questions. Do you have any keywords for me to search for?","link":"https://www.reddit.com/r/MachineLearning/comments/11qg55j/r_optimal_data_acquisition_strategy/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":1}}
