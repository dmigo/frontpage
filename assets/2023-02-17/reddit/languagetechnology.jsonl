{"title":"How can I generate sentences by using different phrases.","description":"so I have multiple list of phrases and want to put them together to form a grammatically correct sentence (for now I want the sentences to be grammatically correct but if I could find a way to make it semantically correct as well then it will be a bonus), so how can go about doing that?  \nfor example,\n\nlist1=\\[\"Accounts\", \"department\"\\]  \nlist2=\\[\"company\"\\]  \nlist3=\\[\"7\",\"employee\"\\]  \n\n\ngiven the list of phrases, I should get sentence like   \nsentence=the company has accounts department in that there are 7 employee working.\n\nI know the sentence I made here is semantically correct but i don't mind the program making weird sentences, also if I specify the order of the list (ie. the list2 should be taken first and then join it with list1 and so on) will it make my sentences less weird.  \n\n\nalso to make my sentences more semantically correct should i train a model on a text corpus where there are sentences formed by similar phrases, if yes then how do i go about doing that? (I already have access to the text corpus)","link":"https://www.reddit.com/r/LanguageTechnology/comments/114dgou/how_can_i_generate_sentences_by_using_different/","created":"2023-02-17","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"Cerebras launches fine-tuning of large language models in the cloud","description":"\\[Note: I work for Cerebras Systems\\]\n\nCerebras just made [fine-tuning](https://www.cerebras.net/blog/cerebras-announces-fine-tuning-on-the-cerebras-ai-model-studio) for large language models available via the [Cerebras AI Model Studio](https://www.cerebras.net/product-cloud/). Users can fine-tune models including GPT-J (6B), GPT-NeoX (20B), and CodeGen (350M to 16B), with more models and checkpoints coming soon. This comes as an addition to the training-from-scratch capabilities we made available in our previous launch.\n\nUsers can fine-tune these models on a dedicated cloud-based cluster powered by Cerebras CS-2 systems with the following advantages:\n\n* Fast - Fine-tune GPT-J 6B in 17 hours\n* Cheap - Priced competitively with OpenAI\n* Easy -  Enjoy cluster performance with no code change\n* Ownership - Your trained weights are yours to keep!\n\nCurious how we enabled cluster performance with no distributed coding? [read this blog](https://www.cerebras.net/blog/what-is-appliance-mode)\n\nCurious how we can train multi-billion parameter models on a single device? [read this blog](https://www.cerebras.net/blog/linear-scaling-made-possible-with-weight-streaming)\n\nInterested? We are offering a [free trial](https://www.cerebras.net/product-cloud/#free) for users interested in fine-tuning or training from scratch.","link":"https://www.reddit.com/r/LanguageTechnology/comments/113zxmr/cerebras_launches_finetuning_of_large_language/","created":"2023-02-16","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"New AI Tool To Help Improve Language Skills!","description":"Hey everyone!\n\nI wanted to share a new, free AI tool called GPTionary ([https://gptionary.com/](https://gptionary.com/)), an AI tool that can help you find the best words/phrases you are looking for.\n\nFeel free to give it a try and hopefully this tool can help a lot of the members on this subreddit!","link":"https://www.reddit.com/r/LanguageTechnology/comments/114ambo/new_ai_tool_to_help_improve_language_skills/","created":"2023-02-17","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"Model for text summarization","description":"I have a dataset in which I have two columns, the first one is the target and the second one consist of a description of the target. I what my approach could be and what models I could use to perform my objective.\n\nMy objective is to take input from user and process it to output the most suited target result based on the provided input.\n\nFor example if the input is \"King of the jungle, male species have manes\" then it gives me the output \"Lion\", here I will have a both the description and the target available in the dataset.","link":"https://www.reddit.com/r/LanguageTechnology/comments/1145e3s/model_for_text_summarization/","created":"2023-02-17","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1}}
{"title":"Utilizing Language Models to Expand Vision-Based Commonsense Knowledge Graphs","description":"If you are interested in using large language models, such as GPT-3, to do research on KGs and expand them: [https://www.mdpi.com/2073-8994/14/8/1715](https://www.mdpi.com/2073-8994/14/8/1715)","link":"https://www.reddit.com/r/LanguageTechnology/comments/113wczh/utilizing_language_models_to_expand_visionbased/","created":"2023-02-16","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"Advice on MA/ Uni Stuttgart","description":"Hello everyone! I am looking into pursuing a master\u2019s degree in CL, coming from a linguistic background. So I figured I\u2019d ask if anyone can recommend me a MA in Europe, I was looking specifically at the one at Stuttgart University but I\u2019m open to anything. Is there anyone who could share their experience or some recommendations? Thanks a lot! :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/113rjwo/advice_on_ma_uni_stuttgart/","created":"2023-02-16","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1}}
{"title":"Struggling with thesis idea and implementation","description":"Basically due to my supervisor\u2019s research field it would make sense for me to do something linguistics/nlp related (Master in Data Science).\nHowever, I\u2019m really struggling to find a good publicly available dataset on which there\u2019s still an edge for novelty to work on. \n\nMy initial idea was to explore reddit data, like from addiction recovery communities that have been growing exponentially, and explore how the sentiment of the posts changes in function of the time of abstinence (self reported), however all my data will be unlabeled and unsupervised learning is not recommended.\n\nHowever, everything I find online (as dataset) is either unlabeled or too \u201chot\u201d already for me to outperform what is being done already.\n\n\nI\u2019m in need of guidance, as the deadlines are approaching and I\u2019m panicking.","link":"https://www.reddit.com/r/LanguageTechnology/comments/113lr7u/struggling_with_thesis_idea_and_implementation/","created":"2023-02-16","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":13}}
{"title":"Hugging Face\u2019s Experts Teach Transformers for Enterprise Use Cases","description":"Hey folks - I wanted to put this live course from Hugging Face\u2019s top experts ([Rajiv Shah](https://www.linkedin.com/in/rajistics/), [Nicholas Broad](https://www.linkedin.com/in/nicholas-m-broad/), [Eno Reyes](https://www.linkedin.com/in/enoreyes/), [Derek Thomas](https://www.linkedin.com/in/dthomas/) and [Florent Gbelidji](https://www.linkedin.com/in/florentgbelidji/)) on your radar!\n\nThe course looks at how to utilize transformers to build reliable and scalable services. The course draws on the instructors and Hugging Face\u2019s expertise in implementing transformers in industry along with case studies, applied exercises and frameworks that you can share with your team and apply at work!\n\nIt kicks off on March 20 and you can use your learning stipend to cover - more info here:\n\n[https://www.getsphere.com/cohorts/transformers-for-enterprise-use-cases?source=Sphere-Com-r-lt](https://www.getsphere.com/cohorts/transformers-for-enterprise-use-cases?source=Sphere-Comm-)","link":"https://www.reddit.com/r/LanguageTechnology/comments/113a2dq/hugging_faces_experts_teach_transformers_for/","created":"2023-02-15","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":2}}
{"title":"Question answering based embeddings retrieval models question.","description":"I am looking for a high performance model that will take queries that are in the form of questions and embed the query in a suitable way to search a local embeddings index and return passages that are relevant to the question.  I've experimented with keybert to preprocess the query to pass on to vanilla Roberta but I think a question answering model might be better.  The best answer I could come up with is Facebook DPR in conjuction with FAISS.  Though I sort of want to stick with Roberta if there's an appropriate variant for this use but I'm open to all better alternatives.","link":"https://www.reddit.com/r/LanguageTechnology/comments/113c2lu/question_answering_based_embeddings_retrieval/","created":"2023-02-16","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1}}
{"title":"We made a map showing what each US state \"loves\" with our text-to-location machine learning models","description":"For Valentine's, we wanted to see what people love. We created a map of what word comes after \"love \\_\\_\\_\" for people posting to social media\n\nThe full, interactive map is here: [https://1712n.github.io/yachay-public/maps/14feb/](https://1712n.github.io/yachay-public/maps/14feb/)","link":"https://www.reddit.com/r/LanguageTechnology/comments/113dopl/we_made_a_map_showing_what_each_us_state_loves/","created":"2023-02-16","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"Longest Common Subsequence for Words (python)","description":"Guys I basically have to files and what I need to do extract the longest common subsequence with indexes. \nThe task is to basically find the longest match and return the indexes of the longest match.\nIs there any library available that does that? \n\n\nSmall_text= \u2018a scientist who works at a lab\u2019\nLong_text = \u2018I am a computer scientist who works at a research lab. The lab I work at is located in the university.\u2019 \n\n\n\nOutput= \u2018a scientist who works at a lab\u2019\nIndexes_in_long_text=[3, 5, 6, 7, 8, 9, 11]\n\nI already tried Pylcs does not work on words it only works on characters. \nAny help would be greatly appreciated.","link":"https://www.reddit.com/r/LanguageTechnology/comments/112zpjw/longest_common_subsequence_for_words_python/","created":"2023-02-15","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":3}}
{"title":"How do you keep track of conference/talks/events in NLP?","description":"I'm currently trying to find professors to build connections with and work as an unaffiliated researcher with, as I'm trying to find a detour path into a Computational Linguistics PhD.\n\nI've recently been following Diyi Yang and her SALT group, because she covers computational social sciences which is such a niche field that I'd really like to work with (I had a paper written in this field before I even knew it existed).\n\nHowever, it turns out, based on their twitter, AAAI 2023 just had a talk literally yesterday that featured her group and I missed it.\n\nI thought I was paying close attention, but maybe not close enough.\n\n\nHow do you guys stay organized with all of the dates?\n\nHow do you find ways to network with top researchers in the field?","link":"https://www.reddit.com/r/LanguageTechnology/comments/1126s7l/how_do_you_keep_track_of_conferencetalksevents_in/","created":"2023-02-14","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":7}}
{"title":"A Comprehensive Guide &amp; Hand-Curated Resource List for Prompt Engineering and LLMs on Github","description":"Greetings,\n\nExcited to share with all those interested in Prompt Engineering and Large Language Models (LLMs)!\n\nWe've hand-curated a comprehensive, Free &amp; Open Source resource list on Github that includes everything related to Prompt Engineering, LLMs, and all related topics. We've covered most things, from papers and articles to tools and code!\n\nHere you will find:\n\n* \ud83d\udcc4 Papers in different categories such as Prompt Engineering Techniques, Text to Image Generation, Text Music/Sound Generation, Text Video Generation etc.\n* \ud83d\udd27 Tools &amp; code to build different GPT-based applications\n* \ud83d\udcbb Open-Source &amp; Paid APIs\n* \ud83d\udcbe Datasets\n* \ud83e\udde0 Prompt-Based Models\n* \ud83d\udcda Tutorials from Beginner to Advanced level\n* \ud83c\udfa5 Videos\n* \ud83e\udd1d Prompt-Engineering Communities and Groups for discussion\n\n**Resource list**: [https://github.com/promptslab/Awesome-Prompt-Engineering](https://github.com/promptslab/Awesome-Prompt-Engineering)\n\nWe hope it will help you to get started &amp; learn more about Prompt-Engineering. If you have questions, Join our discord for Prompt-Engineering, LLMs and other latest research discussions\n\n[https://discord.com/invite/m88xfYMbK6](https://discord.com/invite/m88xfYMbK6)\n\nThank you :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/1128bu9/a_comprehensive_guide_handcurated_resource_list/","created":"2023-02-14","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"A Comprehensive Guide &amp; Hand-Curated Resource List for Prompt Engineering and LLMs on Github","description":"Greetings,\n\nExcited to share with all those interested in Prompt Engineering and Large Language Models (LLMs)!\n\nWe've hand-curated a comprehensive, Free &amp; Open Source resource list on Github that includes everything related to Prompt Engineering, LLMs, and all related topics. We've covered most things, from papers and articles to tools and code!  \n\n\nPlease take a look at the first comment for more details!","link":"https://www.reddit.com/r/LanguageTechnology/comments/112au84/a_comprehensive_guide_handcurated_resource_list/","created":"2023-02-14","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":4}}
{"title":"Website name","description":"A few months ago, I was introduced to a website that worked in the following way: you should provide a scientific paper to it and then a model would interpret each section of the paper, explaining them. I am trying to find this website again, but with no success. Does anyone know?","link":"https://www.reddit.com/r/LanguageTechnology/comments/1126wia/website_name/","created":"2023-02-14","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":4}}
