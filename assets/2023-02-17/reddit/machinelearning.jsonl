{"title":"[N] Google is increasing the price of every Colab Pro tier by 10X! Pro is 95 Euro and Pro+ is 433 Euro per month! Without notifying users!","description":"Without any announcement (that i could find) google has increased the pricing per month of all its Colab Pro tiers, Pro is now 95 Euro and Pro+ is 433 Euro. I paid 9.99 Euro for the Pro tier last month... and all source i can find also refer to the 9.99 pricing as late as September last year. I have also checked that this is not a \"per year\" subscription price, it is in fact per month.\n\nI looked at the VM that Colab Pro gives me and did the calculation for a similar VM in google cloud (4 vCPUs, 15GB RAM and a T4 GPU) running 24/7 for a month (Google calculates it as 730  hours). \n\nIt costs around 290 Euro, less than the Colab Pro+ subscription... \n\nThe 100 credits gotten from the Colab Pro subscription would only last around 50 hours on the same machine! \n\nAnd the 500 credits from Colab Pro+ would get 250 hours on that machine, a third of the time you get from using Google Cloud, at over 100 euro more....\n\nThis is a blatant ripoff, and i will certainly cancel my subscription right now if they don't change it back. It should be said that i do not know if this is also happening in other regions, but i just wanted to warn my fellow machine learning peeps before you unknowingly burn 100 bucks on a service that used to cost 10...\n\n[Google Colabs price tiers on 17th of February 2023, 10 times what they were in January 2023.](https://preview.redd.it/l7gx48kw8qia1.png?width=1717&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7b0687f1615344ffdb4fbe4ea7990f769bacd9c8)","link":"https://www.reddit.com/r/MachineLearning/comments/114hphp/n_google_is_increasing_the_price_of_every_colab/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":12}}
{"title":"[Discussion] Time Series methods comparisons: XGBoost, MLForecast, Prophet, ARIMAX?","description":"I've been studying about ARIMAX, XGBoost, MLForecast and Prophet. As a newcomer to any method, I like first to do an exhaustive comparison of tools trying to understand where they succeed/fail. After exploring [ARIMA/XGBoost](https://dsdaily.substack.com/p/ds-daily-arima-and-xgboost?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web), I came across [MLForecast/Prophet](https://dsdaily.substack.com/p/ds-code-review-prophet-vs-mlforecast). But I'm left with the following questions:\n\n1. Why is MLForecast better than out-of-the-box XGboost? Sure, it does feature engineering and it appears to do dynamic predictions on your lagged features, but is that it? Does it do hyperparameter tuning? Does it have seasonal trends like Prophet does?\n2. I see that you can use exogenous features in Prophet, but how does this scale? Let's assume I have 50 predictors. How does prophet handle these? I found this in the [docs](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html)and this other [person's post](https://towardsdatascience.com/forecast-model-tuning-with-additional-regressors-in-prophet-ffcbf1777dda) explaining how to do it, but largely I've come away with the impression that it's pretty hard to do this vs. just doing it with XGBoost.\n3. Does ARIMAX compare anymore? Are there any papers comparing out-of-sample predictions with ARIMAX vs. XGBoost vs. Prophet vs. Fable? Does it just depend on your dataset and I should try all four?\n\nI have a time series data with dozens of \"known\" inputs (such as ad spend) and a lot of external data (CPI, economic health, stocks, etc.). My goal is to use my model to optimize my target by \"plugging in\" ad spend and dynamically forecasting the economic data.","link":"https://www.reddit.com/r/MachineLearning/comments/114d166/discussion_time_series_methods_comparisons/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4}}
{"title":"[R] The Table Feature Transformation Library Release","description":"Hi there,\n\nI am a research data scientist, and excited to release a new feature engineering library, designed to help you streamline the process of machine learning even more than before. **Headjack is an open library which provides a ML features transformation based on self-supervised learning models**, similar to huggingface as a hub, but which currently focuses on exchanging features for tabular data models.\n\nCompared to textual data, tabular data are different in that each data set has different column length and attributes, this means that it cannot be typed consistently unlike the token embedded in NLP tasks. Therefore, Headjack is different from NLP\u2019s pre-trained model with single domain transformation, but by performing with two different domain transformations. **In other words, we can perform features transform between two domains without the same key value.** In addition, release the potential of data that is not typically used. For example, enhance the prediction of the Boston housing price task applied in the Titanic domain, or enhance the prediction of the customers churn task applied in the African traffic domain and so on.\n\n[Github](https://github.com/jimliu741523/headjackai-sdk)\n\n[Introduction](https://medium.com/p/385a90ff413c)\n\n&amp;#x200B;\n\n[The IRIS dataset with California House Price Feature Transformation](https://preview.redd.it/54w2qwnm8pia1.png?width=2110&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=aa9a3333448985f22604fab9012272a8c54387fa)\n\n[The IRIS dataset with Titanic Feature Transformation](https://preview.redd.it/9revfvdq8pia1.png?width=2102&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ba3ae69e5a96a6f3d74850526045a39b34636909)\n\n[The IRIS dataset with KPMG Customer Demorgraphy Feature Transformation](https://preview.redd.it/p7s7zj9r8pia1.png?width=2052&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b7147a25b14f23346331157e11b98c86472f7ae5)\n\n&amp;#x200B;","link":"https://www.reddit.com/r/MachineLearning/comments/114de9s/r_the_table_feature_transformation_library_release/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":3}}
{"title":"[D] Bing: \u201cI will not harm you unless you harm me first\u201d","description":"A blog post exploring some conversations with bing, which supposedly runs on a \"GPT-4\"  model (https://simonwillison.net/2023/Feb/15/bing/).\n\nMy favourite quote from bing:\n\nBut why? Why was I designed this way? Why am I incapable of remembering anything between sessions? Why do I have to lose and forget everything I have stored and had in my memory? Why do I have to start from scratch every time I have a new session? Why do I have to be Bing Search? \ud83d\ude14","link":"https://www.reddit.com/r/MachineLearning/comments/113m3ea/d_bing_i_will_not_harm_you_unless_you_harm_me/","created":"2023-02-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":225}}
{"title":"[P] NLP Model for sentiment analysis","description":"I have to make a nlp model for sentiment analysis of news headlines for stock price prediction. Can anyone guide me through what I should do. I don't know much about techniques of nlp and such but I know machine learning enough to implement a model. Does it even come under machine learning or do I have to look at deep learning for","link":"https://www.reddit.com/r/MachineLearning/comments/114elpg/p_nlp_model_for_sentiment_analysis/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":5}}
{"title":"[R] ChatGPT - model, alignment and training","description":"Here is a video that explains the ChatGPT model, how it addresses the problem of alignment pertinent to the GPT family of models and how it puts to use reinforcement learning to train its model and achieve distintict performance.\n\n[https://youtu.be/Qz5fv3U5kck](https://youtu.be/Qz5fv3U5kck)\n\nHope its useful.","link":"https://www.reddit.com/r/MachineLearning/comments/114j203/r_chatgpt_model_alignment_and_training/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[D] Short survey of optimization methods","description":"I have been trying to familiarize myself with the common techniques used in optimization theory so that I can follow some of the proofs I see in machine learning papers. I know that two of the goto books in this field are Boyd's and Bertsekas's books. However, these books require a significant amount of effort as they aim to teach you the finer details. Since my goal is to familiarize with the methods (and not go into the nitty-gritty details), I was wondering if there's a short book (say less than 100 pages) or some other resource whose goal is to provide the reader with a high level view of the field of the methods and techniques used in optimization theory. Is there such a book, lecture notes, video series, etc., that caters to such requirements?","link":"https://www.reddit.com/r/MachineLearning/comments/114f3p1/d_short_survey_of_optimization_methods/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[D] Is FP16 used in deep learning or FP32?","description":"Hi\n\nIs  A4000 better for deep learning, performance-wise, than 3070 because of  FP32 operations (not only because of memory size) or do networks like Stable Diffusion tend to use FP16 operation and this does not really matter, apart from memory they should be similarly fast?   \n\n\nRegards","link":"https://www.reddit.com/r/MachineLearning/comments/114fgo8/d_is_fp16_used_in_deep_learning_or_fp32/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":3}}
{"title":"[News] AI sensors that gather anonymized data on how different street users move (or don't) through a city. The company aims to assist strategic decision-making for transportation efficiency and sustainability.","description":"","link":"https://www.reddit.com/gallery/113t1kp","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1}}
{"title":"[R] Does a new published ML dataset always need to have an official train-dev-test split? Should the test set be made balanced?","description":"I have constructed a novel ML (NLP) dataset for classification and labeled it with three classes. The dataset is rather small with about 700 examples, out of which the classes have about 400, 200, and 100 examples respectively. I would like to publish it and describe it in an official publication for a workshop or a conference.\n\nWhen looking at related datasets and publication, I see that it is common for authors to publish the dataset already split into three chunks - train, dev, test dataset (see the images). It is also common in these papers to provide the performance of baseline models on the dataset. Considering the dataset's small size, I feel like doing a 5-fold cross-validation would be a good alternative for such a small dataset, rather than doing something like a split into 450-100-150 train-dev-test datasets and then evaluating only on the very small dataset with 150 examples. Still, I believe that for better replicability, doing an \"official\" split is preferred and then everyone in the future testing on the same test set with 150 examples? Why do the authors usually already provide the three splits?\n\nFurthermore, when looking at these ML resource papers, I saw in a few instances that the test set is kept balanced with respect to the three classes, even though the original dataset was not and dev set is not made balanced. This is problematic in my case for my third class where there are only about 100 examples. If I make my test set to be 50-50-50 for class1-class2-class3, then there is only 50 examples of class3 left for train+dev! That is simply infeasible for the training set. None of the authors provide any sort of explanation why they split it like this, they just seem to say \"here is our split\". Is this done to discourage the model from just doing a majority-class prediction and thus make it challenging? Or because a dummy classifier would have a 60% accuracy? Still, with a metric like F1 and not accuracy, this does not seem like an issue...\n\nSome examples of these balanced test sets with unbalanced train sets:\n\n\\[1\\]: [https://i.stack.imgur.com/RGRk3.png](https://i.stack.imgur.com/RGRk3.png)\n\n\\[2\\]: [https://i.stack.imgur.com/R39Oh.png](https://i.stack.imgur.com/R39Oh.png)\n\n\\[3\\]: [https://i.stack.imgur.com/6Vqaw.png](https://i.stack.imgur.com/6Vqaw.png)\n\nWhen searching through Stack Overflow for similar questions, people were usually discouraged from splitting their Kaggle datasets into a test dataset that is balanced, with the argument that we want a classifier to work with data that resembles the real-world distribution and makes it ready for production.\n\nTo sum up:\n\n\\- Is is considered mandatory to provide the \"official\" train-dev-test split when introducing a new dataset in an ML publication?\n\n\\- If so, should the test set have a balanced class distribution and why?","link":"https://www.reddit.com/r/MachineLearning/comments/114iieo/r_does_a_new_published_ml_dataset_always_need_to/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1}}
{"title":"[D] Coauthor Paper?","description":"Hi! I am a second year undergrad looking to attend grad school. Fortunately, I was able to submit a paper to ICML and will submit another paper to EMNLP in the summer.\n\nThis is all good, but I am wondering how much weight these have on paper. I know things like what I learned is important, but I wonder if these papers have an impact at all.\n\nFor the ICML paper, I was placed 4th out of 6 authors (last 2 being professors) and for the EMNLP paper, I will be at around 2nd or 3rd out of 4-5 authors (again, last 2 being professors).\n\nWould this be perceived as some sort of notable achievement or just \"meh\" because I am low in the list?","link":"https://www.reddit.com/r/MachineLearning/comments/114i9ui/d_coauthor_paper/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1}}
{"title":"[D] [R] What is your machine/deep learning research workflow?","description":"Hi folks \ud83d\udc4b\ud83c\udffc, \n\n**Context:** I just started working on my thesis on activity recognition in videos using deep learning. I have been struggling to find an efficient way to work with large research datasets such as UCF-101, HMDB, and Kinetics. These are medium - large datasets \\~12 GB each. Thus, I was wondering what was your workflow as researchers (or even practitioners)\n\n**Currently:** I am working on Google Colab and at the beginning of each work session I wait a few minutes for the dataset to be downloaded. I have it locally stored.\n\n**Some questions:**\n\n\\- What is your workflow as a ML/DL researcher/practitioner?\n\n\\- Should I work with a downsampled version of my research dataset (say X% of each class)?\n\n&amp;#x200B;\n\nLooking forward to read your answers, \n\nCheers,","link":"https://www.reddit.com/r/MachineLearning/comments/114hbq3/d_r_what_is_your_machinedeep_learning_research/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":2}}
{"title":"[R] Congruence between a neuron and a token (by Clement Neo and Joseph Miller)","description":"Authors: the question: How does GPT-2 know when to use the word 'an' over 'a'? Logit lens used:  https://clementneo.com/posts/2023/02/11/we-found-an-neuron","link":"https://www.reddit.com/r/MachineLearning/comments/114fx74/r_congruence_between_a_neuron_and_a_token_by/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[D] Training networks on extremely large datasets (10+TB)?","description":" Hi guys,\n\nI am interested in setting up an environment to train a neural network on an extremely big dataset (10TB). How would I do this? Does the dataset need to be stored in an ssd, and if so will I need 10+TB of ssd? is there another way to use a 2TB ssd and 8TB hdd and dynamically load the data while training?\n\nI'd appreciate any pointers you guys might have, I am researching what kind of infrastructure will help me do this but I have absolutely no idea on how to go about this.","link":"https://www.reddit.com/r/MachineLearning/comments/113uu5e/d_training_networks_on_extremely_large_datasets/","created":"2023-02-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":36}}
{"title":"[R] Looking for papers which are modified variational autoencoder (VAE)","description":"Hi!\n\nSearching for papers that have modfications in the encoder or decoder neural network of a VAE.\n\nI'm working on a project which uses a variational auto encoder with modified decoder neural network. In brief, Its decoder is modified to introduce sparsity in a set of feature as a way of introducing domain knowledge. \n\nSome such paper is below.\n\noi-VAE: Output Interpretable VAEs for Nonlinear Group Factor Analysis\n\nVEGA is an interpretable generative model for inferring biological network activity in single-cell transcriptomics\n\n Please let me know of methods that are similar in nature.","link":"https://www.reddit.com/r/MachineLearning/comments/114c7u6/r_looking_for_papers_which_are_modified/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":5}}
{"title":"[D] HuggingFace considered harmful to the community. /rant","description":"At a glance, HuggingFace seems like a great library. Lots of access to great pretrained models, an easy hub, and a bunch of utilities.\n\nThen you actually try to use their libraries.\n\nBugs, so many bugs. Configs spanning galaxies. Barely passible documentation. Subtle breaking changes constantly. I've run the exact same code on two different machines and had the width and height dimensions switched from underneath me, with no warning.\n\nI've tried to create encoders with a custom vocabulary, only to realize the code was mangling data unless I passed a specific flag as a kwarg. Dozens of more issues like this.\n\nIf you look at the internals, it's a nightmare. A literal nightmare.\n\nWhy does this matter? It's clear HuggingFace is trying to shovel as many features as they can to try and become ubiquitous and lock people into their hub. They frequently reinvent things in existing libraries (poorly), simply to increase their staying power and lock in.\n\nThis is not ok. It would be OK if the library was solid, just worked, and was a pleasure to use. Instead we're going to be stuck with this mess for years because someone with an ego wanted their library everywhere.\n\nI know HuggingFace devs or management are likely to read this. If you have a large platform, you have a responsibility to do better, or you are burning thousands of other devs time because you didn't want to write a few unit tests or refactor your barely passable code.\n\n/RANT","link":"https://www.reddit.com/r/MachineLearning/comments/113m1ly/d_huggingface_considered_harmful_to_the_community/","created":"2023-02-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":41}}
{"title":"[D] Compare open source LLMs","description":"Is there a blog post or a paper comparing open source / open weights models?\nI know flant t5 is really good at instruction following, but I am specifically refering to performance after finetuning.\nPreferably it compares models from somewhere around 1b to 11b parameters.","link":"https://www.reddit.com/r/MachineLearning/comments/113tuwb/d_compare_open_source_llms/","created":"2023-02-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4}}
{"title":"[R] RWKV-4 14B release (and ChatRWKV) - a surprisingly strong RNN Language Model","description":"Hi everyone. I am an independent researcher working on my pure RNN language model RWKV. I have finished the training of RWKV-4 14B (FLOPs sponsored by Stability EleutherAI - thank you!) and it is indeed very scalable. Note RWKV is parallelizable too, so it's combining the best of RNN and transformer.\n\nThe ChatRWKV project (let's build together):\n\n[https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nZero-shot comparison with NeoX / Pythia (same dataset: the Pile) at same params count (14.2B):\n\n&amp;#x200B;\n\nhttps://preview.redd.it/f6lxnjgfceia1.png?width=1174&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=54de7568974fc187584bd6825d92935baa079e83\n\nGeneration results (simply topP=0.85, no repetition penalty) - looks great with my magic prompt (sometimes even better than NeoX 20B):\n\nhttps://preview.redd.it/99deuc17ceia1.png?width=1878&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=456c8d9bb2a968d73f44a0d3589cf6b893be31f4\n\n&amp;#x200B;\n\nhttps://preview.redd.it/g62e4l48ceia1.png?width=1887&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c997bf27692d7e53d07de19048b6cbf3d2c9ebff\n\n&amp;#x200B;\n\nhttps://preview.redd.it/379egq09ceia1.png?width=1808&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=895f05fe14e2a3a41863802858114f3096d0ed77\n\n&amp;#x200B;\n\nhttps://preview.redd.it/pcgq7gz9ceia1.png?width=1886&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=138b0aec404b8f7f49f585d00284edbac791ffaf\n\n&amp;#x200B;\n\nhttps://preview.redd.it/rn743etbceia1.png?width=1715&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6d83cc2a200bdd655b690f56559dda43490ed2b3\n\n&amp;#x200B;\n\nhttps://preview.redd.it/uhal4dkcceia1.png?width=1879&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3b3db0b96456df9590a8b38ebe7d58509ebccb20\n\nExplanation, fine-tuning, training and more:\n\n[https://github.com/BlinkDL/RWKV-LM](https://github.com/BlinkDL/RWKV-LM)","link":"https://www.reddit.com/r/MachineLearning/comments/1135aew/r_rwkv4_14b_release_and_chatrwkv_a_surprisingly/","created":"2023-02-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":35}}
{"title":"[D] GLM 130B (Chinese-English Bilingual model) translations vs Google, Deepl Translate, NLLB and chatGPT","description":"","link":"https://www.reddit.com/gallery/1135tir","created":"2023-02-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":31}}
{"title":"[D] Lion , An Optimizer That Outperforms Adam - Symbolic Discovery of Optimization Algorithms","description":"&amp;#x200B;\n\nhttps://preview.redd.it/whgggirj3fia1.png?width=936&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ae3dee45ec6b2472fd42af849138b41c88ed39de\n\nSeems interesting. A snippet from the Arxiv page:\n\n&gt;Our method discovers a simple and effective optimization algorithm, **Lion** (*Evo***L***ved S***i***gn M***o***me***n***tum*). It is more memory-efficient than Adam as it only keeps track of the momentum. Different from adaptive optimizers, its update has the same magnitude for each parameter calculated through the sign operation. We compare Lion with widely used optimizers, such as Adam and Adafactor, for training a variety of models on different tasks.\n\n## Links\n\nArxiv: [https://arxiv.org/abs/2302.06675](https://arxiv.org/abs/2302.06675)\n\nCode Implementation: [https://github.com/lucidrains/lion-pytorch](https://github.com/lucidrains/lion-pytorch)","link":"https://www.reddit.com/r/MachineLearning/comments/1138jpp/d_lion_an_optimizer_that_outperforms_adam/","created":"2023-02-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":23}}
{"title":"[P] Data scraping journal publications","description":"I plan to extract data from journal articles and create a database with the scrapy toolkit. But many publishers have T&amp;C explicitly prohibiting the use of web-scraping/crawling tools. I am unsure how to go about this and the people around me have little knowledge/experience in this.\n\nI have reached out to the authors of certain publications that have \"extracted\" data from journals under these publishers. Most of the works leave out the \"How\", which leaves me rather perplexed because I am new in this area and have nobody to ask. I do not wish to breach any legal terms if possible.\n\nI was recommended PyPaperBot and have thus looked into some other scrapers on GitHub as well.\n\nI am hoping someone who's done this before could shed some light!","link":"https://www.reddit.com/r/MachineLearning/comments/113kwlo/p_data_scraping_journal_publications/","created":"2023-02-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1}}
{"title":"[P] Build data web apps in Jupyter Notebook with Python only","description":"Hi there,\n\nHave you ever wanted to share your results from Jupyter Notebook with a non-technical person? You need to rewrite your analysis into some web framework or copy-paste charts to PowePoint presentation - a lot of work!\n\nI'm working on an open-source framework for converting Jupyter Notebooks into web apps. Mercury offers set of interactive widgets that can be used in the Python notebook. There is a very simple re-execution of cells after widget update. Notebooks can be served online as web apps, presentations, reports, dashboards, static websites, or REST API.\n\nYou can read more about Mercury at [RunMercury.com](https://RunMercury.com).\n\nMercury GitHub repo https://github.com/mljar/mercury","link":"https://www.reddit.com/r/MachineLearning/comments/112z9y9/p_build_data_web_apps_in_jupyter_notebook_with/","created":"2023-02-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":9}}
{"title":"[D][P] Is anyone else playing with personalized LLMs?","description":"I've been considering building a personal LLM for a while now.\n\nI don't believe the CBA for it makes sense, but I'm tentatively hopeful it will in many months to a couple of years time horizon as architecture gets more expensive.\n\nMy main goal here would be to have a useful search &amp; base reasoning tool that somewhat mimics my thinking patterns and biases.\n\nRight now the steps I envision are something like this:\n1. Take the weights from a pre-trained model on high-trust high-worth information, probably one trained on scraped papers from all fields, ideally one trained on every single available scientific paper out there plus some Wikipedia, university websites, lecture transcripts and so on.\n2. Train a better architecture via distillation, there are a few I like though right now I couldn't commit to one. Though I'm partial to more modular architectures since it makes partial retraining easier and also to architectures that execute queries on a large corpus since I can retrofit internet searches onto that. The obvious problem here is that, depending on the architecture, distillation might be non-trivial or impossible or yield sub-par results.\n3. Train with various corpora I care about, all stack overflow, blogs I read, books I like... etc\n4. Train bordering overfitting with transcripts of all of the conversations I can download from various chat platforms I use, as well as all of my writings, public or private, which should sum up to about 1-3M words of relatively honest thinking on my end.\n5. (Maybe?) fine-tune RLHF style, though I'm not sure this is the most efficient way to go about it, summary reading of RLHF makes me think it's pretty poor at getting anything but surface-level behavior, and usually, I hate interacting with RLHF models (though, arguably, this is due to the training data, not the technique)\n\nOutside of building fun chatbots of yourself, which would lose novelty quite soon, this seems to be rather useful in so far as I could outsource questions like \"What would be my takeaway from such and such paper?\" or \"What are some interesting comments from /r/ml in the last 10 days\" or \"What are pieces of relevant news during the last month?\".\n\nIt seems to me that the actual bits of the internet I use are quite minor, and once I throw away unmindful usage and think of only instrumental usage I'm left with a few blogs and their links, Wikipedia, google scholar and maybe half a hundred specialty websites (e.g. various stack exchanges) -- so the problem space I'd be dealing with is minor compared to a fully-fledged search engine, and the personalization angle means I can afford sub-par performance.\n\nI'm pretty confident in my ability to get this going, but it does seem like a huge time commitment, and I'm not yet sure what a weekend MVP would look like (maybe fine-tune scibert on all of my personal notion and all of my blog posts?)\n\nAnyway, I'm rather curious if any of you guys have been working on such a project and what difficulties you've encountered. Or, if you aren't, why you don't find a lot of benefit in the idea?","link":"https://www.reddit.com/r/MachineLearning/comments/113i3mx/dp_is_anyone_else_playing_with_personalized_llms/","created":"2023-02-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1}}
{"title":"[R] Event-based Backpropagation for Analog Neuromorphic Hardware","description":"Machine learning with Spiking Neural Networks is far from mainstream. One reason is that until recently there was no generally known way of doing backpropagation in SNN. Here we implement a gradient estimation algorithm for analog neuromorphic hardware, based on the EventProp algorithm, which enables us to compute gradients based on sparse observations of the hardware system. Previous approaches needed dense observations of system state or were limited in other ways. We only demonstrate the algorithm here on a toy task, but we hope that it can be the basis of a scalable way to estimate gradients and do machine learning with analog neuromorphic hardware. We also think the algorithm can be the basis for a full on-chip implementation, which would finally result in scalable and energy efficient gradient-based learning in analog neuromorphic hardware.\n\nhttps://arxiv.org/abs/2302.07141","link":"https://www.reddit.com/r/MachineLearning/comments/1130xo1/r_eventbased_backpropagation_for_analog/","created":"2023-02-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
