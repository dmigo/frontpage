{"title":"Extracting large spans of text without a clear pattern","description":"I'm working on a project where I want to automatically detect and extract trauma narratives from a corpus of text (I will label it myself). I'm thinking of using NLP techniques to classify text as either containing a trauma narrative or not, and then extracting those narratives from the classified text to analyze them. I'm lost as to how to extract the narratives once they have been classified. The data is quiet noisy since there is lots of contextual information. Which tools could be used to approach this problem?","link":"https://www.reddit.com/r/LanguageTechnology/comments/122alia/extracting_large_spans_of_text_without_a_clear/","created":"2023-03-26","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1}}
{"title":"[Beginner advice] Plaintext layout segmentation","description":"Hey, hey! I'm hoping to do some layout segmentation for legal text, with no experience in NLP (I'd dare say I'm fairly confident working with ML methods generally). A big problem in my dataset is that whilst the text is often somewhat structured, it varies A LOT between different documents.\n\nHere's an example:\n\n&gt;     Neutral Citation Number: [2023] EWCA Crim 316 Case No: 202200988 B1 IN THE COURT OF APPEAL (CRIMINAL DIVISION)\n&gt; \n&gt;     ON APPEAL FROM THE CROWN COURT AT CANTERBURY\n&gt; \n&gt;     HIS HONOUR JUDGE JAMES\n&gt; \n&gt;     T20117349\n&gt; \n&gt;     Royal Courts of Justice\n&gt; \n&gt;     Strand, London, WC2A 2LL Date: 24 March 2023\n&gt; \n&gt;     Before:\n&gt; \n&gt;     LORD JUSTICE STUART-SMITH\n&gt; \n&gt;     MRS JUSTICE LAMBERT and\n&gt; \n&gt;     SIR NIGEL DAVIS\n&gt; \n&gt;     Between:\n&gt; \n&gt;     REX\n&gt; \n&gt;     Respondent\n&gt; \n&gt;     and\n&gt; \n&gt;     PHILIP ROE\n&gt; \n&gt;     Applicant\n&gt; \n&gt;     Mark Summers KC and Rachel Darby (instructed by Lound Mulrenan Jefferies Solicitors) for the Applicant\n&gt; \n&gt;     Edmund Burge KC (instructed by CPS Appeals and Review Unit) for the Respondent\n&gt; \n&gt;     Hearing date: 21 February 2023\n&gt; \n&gt;     Approved Judgment\n&gt; \n&gt;     This judgment was handed down remotely at 10.30am on 24 March 2023 by circulation to the parties or their representatives by e-mail and by release to the National Archives.\n&gt; \n&gt;     .............................\n&gt; \n&gt;     Lord Justice Stuart-Smith:\n&gt; \n&gt;     Introduction\n&gt; \n&gt;     1.\n&gt; \n&gt;     On 11 December 2013 in the Crown Court at Canterbury the Applicant was convicted after a re-trial on an indictment containing six counts of the offences we detail below. On 12 December 2013 he was sentenced by the trial judge, His Honour Judge James, as follows:\n&gt; \n&gt;     i)\n&gt; \n&gt;     On Counts 1 and 2, which were offences of being knowingly concerned in a fraudulent evasion of the prohibition on the importation of goods (namely class A drugs) contrary to Section 170(2)(b) of the Customs and Excise Management Act 1979, he was sentenced to 13 years imprisonment concurrent;\n&gt; \n&gt;     ii)\n&gt; \n&gt;     On Counts 3 and 4, which were offences of being knowingly concerned in a fraudulent evasion of the prohibition on the importation of goods (namely class B drugs) contrary to Section 170(2)(b) of the Customs and Excise Management Act 1979, he was sentenced to 3 years (count 3) and 4 years (count 4) imprisonment concurrent;\n&gt; \n&gt;     iii)\n&gt; \n&gt;     On Count 5, which was an offence of possessing a prohibited firearm contrary to section 5(1)(aba) of the Firearms Act 1968, he was sentenced to 5 years imprisonment consecutive; and\n&gt; \n&gt;     iv)\n&gt; \n&gt;     On Count 6, which was an offence of possessing ammunition without a firearm authority contrary to section 1(1)(b) of the Firearms Act 1968, he was sentenced to 1 year imprisonment, concurrent.\n&gt; \n&gt;     The total sentence was therefore one of 18 years imprisonment.\n&gt; \n&gt;     2. The Applicant now applies for permission to appeal against his conviction some 3003 days out of time. His application was referred to the full Court by the Single Judge.\n&gt; \n&gt;     [...]\n&gt; \nI want to segment out the header (i.e. the text until \"Lord Justice Stuart-Smith / Introduction\"), any section titles, the individual paragraphs (potentially including subparagraphs), and any eventual footnotes. Unfortunately, all of these things are too variable between documents for regex approaches to work well. I have about 4000 documents I need to segment.\n\nI could generate a sample dataset for training on these classes relatively easily, but I am an NLP beginner, and know quite little about what the best methodologies / networks / pre-trained nets for this type of problem would be! I've tried looking around, but most available tools seem to be image (e.g. PDF) focused, and not tailored for this kind of document (one such example is layoutlmv3).\n\nCould someone please point me in the right direction regarding state-of-the-art methods and reasonable approaches to this type of problem?","link":"https://www.reddit.com/r/LanguageTechnology/comments/1220le7/beginner_advice_plaintext_layout_segmentation/","created":"2023-03-25","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":2}}
{"title":"Should I specialize in NLP considering the advent of Large Language Models?","description":"I am feeling that most of cutting edge research work is being done in a handful of companies. In that case, how does the future look like  say 5 years down the line for somebody specialising in research in NLP? Seems like models like ChatGPT can do many of NLP tasks and are so ahead of the curve that it will ne difficult to beat them. How do job prospects look like in NLP?","link":"https://www.reddit.com/r/LanguageTechnology/comments/121gv4c/should_i_specialize_in_nlp_considering_the_advent/","created":"2023-03-25","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":9}}
{"title":"Starting a career in Speech AI","description":"I will soon graduate from a master\u2019s in compling and I was very lucky to find a job in a good company that is relatively new to language technology. In such a position, I don\u2019t really have any senior people to ask for advice when it comes to tackling problems, and this leaves me very lost in my day to day work. \n\nIs this common when starting a career in the field? How can I find mentors and guidance outside of my immediate environment?","link":"https://www.reddit.com/r/LanguageTechnology/comments/1221oc9/starting_a_career_in_speech_ai/","created":"2023-03-25","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"Spacy dependency parsing visualizer","description":"When using Spacy I noticed that it was quite difficult sometimes to know what the various POS tags, dependency labels, and morphological features actually *mean*. Especially difficult since the different models (e.g. en\\_core\\_web\\_sm) often use different labelling schema.\n\nI built this to help people get a feel for Spacy dependency parsing. Each POS tag, dependency label and morphological feature links to the relevant documentation to find out more about their meanings.\n\nIt features a fully parsed version of George Orwell's \"Politics and the English Language\", with parallel texts in both English and Spanish.\n\n&amp;#x200B;\n\nLink: [https://www.getcorrecto.com/nlp/en/0/0](https://www.getcorrecto.com/nlp/en/0/0)","link":"https://www.reddit.com/r/LanguageTechnology/comments/121lavk/spacy_dependency_parsing_visualizer/","created":"2023-03-25","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":3}}
{"title":"What algo to use to check if student answer is correct?","description":"Hi there,\n\nQuestions for the experts here: I'm trying to programmatically grade open-text questions from Google Form quizes. For example: the question is \"Which country in Africa is the largest by area\". As a teacher, I have the answer: \"Algeria is the largest country in Africa by area\".\n\nI want to compare my student's answers to the correct answer in order to know whether they are right or wrong. **Which algo should I use?**\n\nI was playing a bit with string similarity, but I got ridiculous results, because \"***Egypt*** is the largest country in Africa\" is pretty close the the right answer, except that it's completely wrong. \n\nWhat do you think?","link":"https://www.reddit.com/r/LanguageTechnology/comments/121zjrv/what_algo_to_use_to_check_if_student_answer_is/","created":"2023-03-25","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":4}}
{"title":"Deploy a huggingface classification model","description":"I want to classify around 50k tweets with a BERT classification model which I found on huggingface. What is the fastest way to do this? I am pretty sure the hugging face API is rate limited. Do I need to pay for an Interference endpoint? Is this worth it?","link":"https://www.reddit.com/r/LanguageTechnology/comments/121lrt2/deploy_a_huggingface_classification_model/","created":"2023-03-25","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"Can I train Stanford Alpaca on style + tone?","description":"I've been learning about the breakthrough with [Stanford Alpaca](https://www.youtube.com/watch?v=xslW5sQOkC8) and understand we can create our own models for less than $600. What I am trying to better understand is how specifically can we train these models? How important are the training datasets and if the training datasets were, for example, very much in a style (the style of Vladimir Nabokov, or Youtube comment style) would those stylistic touches be reflected in the model?","link":"https://www.reddit.com/r/LanguageTechnology/comments/1215q2q/can_i_train_stanford_alpaca_on_style_tone/","created":"2023-03-25","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1}}
{"title":"Positive and Negative Sampling Strategies for Representation Learning in Semantic Search","description":"I have been looking into strategies for effectively training a dual encoder (the \"two tower\" model) to learn representations. I came across a set of papers that described various sampling methods (supervised/self-supervised/unsupervised) to create positive and negative pairs to be fed to the model for training.\n\n&amp;#x200B;\n\nTL;DR on what I learned:\n\n\u2022 Using in-batch negatives and/or cross-batch negatives helps in reducing the training and inference discrepancies in retrieval and ranking applications.  \n\u2022 For training, using both easy negative and hard negative examples, and using more easy examples than hard ones could lead to the best results. \n\n&amp;#x200B;\n\nI compiled the references and summarized them here: [https://blog.reachsumit.com/posts/2023/03/pairing-for-representation/](https://blog.reachsumit.com/posts/2023/03/pairing-for-representation/)","link":"https://www.reddit.com/r/LanguageTechnology/comments/1214nrb/positive_and_negative_sampling_strategies_for/","created":"2023-03-25","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":2}}
{"title":"(Soon) NLP graduate and feel completely inferior on the job market","description":"I am a master student in NLP/Computational linguistics and currently looking for jobs after graduation. Prepare for long panicked post, hope this is the right place to ask/vent..\n\nBoth my bachelor and master were a specialized NLP degree. Especially the bachelor was pretty general: I took all the same intro to linguistics (syntax, phonetics, morphology etc.) classes as the theoretical linguistics. I had a lot of \u201etraditional\u201c NLP methods such as parsing based on formal languages, automata theory, search algorithms. Basic maths, statistics, linear algebra. Specialized seminars on coreference, sentiment analysis etc but those were mostly in the style of reading-papers-and-discussing-them. My master offered more technical and applied courses, but I did not feel well prepared since I never learned how to program neural networks myself except for a very basic numpy and pandas based classifier, but suddenly everyone was talking about transformer models. I had theoretical ML classes, but somehow we were just expected to know how to implement them into our projects too? I am now doing my thesis where I am using an existing system (pytorch-based) and adapting and tuning it for a slightly different task. While I (thought I) know how to program and the basic of how machine learning, the reality is I feel soooo out of place. I have a hard time even understanding the pytorch documentation, and I feel like there are a million things to consider. Shapes don\u2019t match, cuda out of memory, suddenly i need to do gradient clipping which I feel I was taught about in 30min 2 years ago maybe. I usually make it work somehow after 5 nervous breakdows, but I constantly feel like I am half-assing everything, just trying to get it to run at least. If I were to build such a system, even a way simple one, from scratch, I would die.\n\nNow looking at jobs, most of those that advertise with NLP require \u201epractical machine learning experience with frameworks such as TensorFlow, PyTorch\u2026\u201c, and nearly every job is also equally directed at graduates from EITHER data science, mathematics, computer science, NLP \u2026 How can I keep up with data scientists in this aspect? Did I mess up by not practicing how to actually code and understand complex systems during my degree? I know a few other students who expressed similar concerns, at least from my school. I definitely see potential for me in areas with highly specialized use cases/messy/non-standard data, but wonder if this really needed &gt;3 years of linguistic basics. Will employers actually care about my linguistic background compared to a data scientist with some NLP experience? Currently I feel like I would have done better doing a data science degree and then taking a few classes on linguistics later on to specialize\u2026. I guess I will find a job one way or another but I am already scared of interviews because of these inadequacies.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zvsnj/soon_nlp_graduate_and_feel_completely_inferior_on/","created":"2023-03-23","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":14}}
{"title":"SUMMARY OF LANGUAGE LEARNING APPS USING GPT","description":" Notion, Bing and Microsoft Office have integrated GPT. Now it's time for Duolingo and other language learning apps to catch up with this trend, providing a native communication training environment and helping you practice 24/7! \n\nIn order for us not to be behind with this trend, I have summarized some language learning applications with GPT integration: Duolingo Max, Speak and eJOY EPIC.\n\n**1. DUOLINGO:**\n\na. Features of GPT - Duolingo Max integration:\n\n\\- Roleplay: Voice chat with AI for multiple communication contexts: order drinks at the cafe, plan outings, go shopping\u2026 with Duolingo characters\n\n\\- Explain My Answer: give examples and explanations for your answers in the lesson whether you choose right or wrong\n\nb. Advantage:\n\n\\- User-friendly interface, easy to use\n\n\\- Automatically show suggestions for better communication next time after each dialogue\n\n\\- Automatically analyze answers\n\n\\- Roleplay option gives +40 XP, much higher than normal lessons (+10 XP)\n\nc. Defect:\n\n\\- Currently Duolingo Max is only available in the U.S., Great Britain, Ireland, Canada, Australia, and New Zealand\n\n\\- The only courses that can utilize these new features are Spanish and French for English speakers on iOS\n\n\\- Charges quite high: $29.99/month or $167.99/year\n\n*Link to download Duolingo on iOS:* [*https://apps.apple.com/us/app/duolingo-language-lessons/id570060128*](https://apps.apple.com/us/app/duolingo-language-lessons/id570060128) \n\n*Link to download Duolingo on Android:* [*https://play.google.com/store/apps/details?id=com.duolingo&amp;hl=en&amp;gl=US*](https://play.google.com/store/apps/details?id=com.duolingo&amp;hl=en&amp;gl=US) \n\n\u2014--\u2014--\u2014--\u2014--\u2014--\n\n**2. SPEAK:**\n\na. GPT integration features:\n\n\\- Role-playing: Chat, voice chat with AI in many communication contexts and goals\n\nb. Advantage:\n\n\\- Friendly interface, easy to use, smooth experience\n\n\\- Classification of communication contexts according to learning level\n\n\\- In each context, there will be examples of sentences and communication goals\n\n\\- There is grading based on intonation and communication goals. The speech recognition of this app is accurate!\n\n\\- Show hints if you don\u2019t know what to say next\n\nc. Defect:\n\n\\- Do not automatically interpret the answer\n\n\\- Only displayed in Japanese and Korean for English learners. Fortunately, I know a few Korean words, but I'm tired of translating the words from Korean\n\n\\- Charge quite high but cheaper than Duolingo: $26.52/month or $117.7/year\n\n*Link to download Speak on iOS:* [*https://apps.apple.com/vn/app/speak-learn-english/id1286609883*](https://apps.apple.com/vn/app/speak-learn-english/id1286609883) \n\n*Link to download Speak on Android:* [*https://play.google.com/store/apps/details?id=com.selabs.speak&amp;hl=en*](https://play.google.com/store/apps/details?id=com.selabs.speak&amp;hl=en) \n\n\u2014--\u2014--\u2014--\u2014--\u2014--\n\n**3. eJOY EPIC:**\n\na. GPT Integration Features\n\n\\- Role playing talking with commands and context available\n\n\\- Voice chat with GPT\n\n\\- Look up and save words right in sentences, play games to remember words\n\nb. Advantage:\n\n\\- It's Vietnamese. I'm a bit biased towards Vietnamese products since I\u2019m also one of them \ud83d\ude00\n\n\\- Look up words right in the sentence, save the time to open the dictionary\n\n\\- ChatGPT feature is free to use, but the main features like the course are paid. Free ChatGPT only. But this course is very interesting. I will share more below\n\nc. Defect:\n\n\\- GPT is not integrated into the course section - which is the part I like the most of Epic. Epic's learning concept is also very different from other applications, like having a teacher show you any special vocabulary or grammar in this video, then give exercises for those phrases. Learning experience is quite enjoyable for beginners\n\n\\- Do not automatically interpret the answer\n\n\\- Only suggest prompt for the first question, you have to come up with the content to say and maintain the conversation after that\n\n*Link to download eJOY EPIC on iOS:* [*https://apps.apple.com/vn/app/ejoy-epic-english-courses/id1622797145*](https://apps.apple.com/vn/app/ejoy-epic-english-courses/id1622797145) \n\n*Link to download eJOY EPIC on Android:* [*https://play.google.com/store/apps/details?id=com.ejoy.epic&amp;hl=en*](https://play.google.com/store/apps/details?id=com.ejoy.epic&amp;hl=en)","link":"https://www.reddit.com/r/LanguageTechnology/comments/120fvgu/summary_of_language_learning_apps_using_gpt/","created":"2023-03-24","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"How to make a homemade ChatGPT model","description":"Obviously, the creation of such big and complex models like ChatGPT is not a trivial task, but it is possible to create a model which can solve 1 task like ChatGPT. We are glad to announce our opensource [dataset](https://www.kaggle.com/datasets/vladimirvorobevv/chatgpt-paraphrases) of 420k paraphrases generated by ChatGPT and a [model](https://huggingface.co/humarin/chatgpt_paraphraser_on_T5_base) pretrained on it. We have trained the model just for 2 epochs and the model shows not the best results, but it is already makes more variative paraphrases than the most popular paraphraser on huggingface. Feel free to try the dataset and the model and give a feedback to improve their quality","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zuzco/how_to_make_a_homemade_chatgpt_model/","created":"2023-03-23","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"[D] What's the technology behind Bing's chat: summarization with citations.","description":"Cross-posting from r/MachineLearning for the audience.\n\nWould love to learn from you folks on thoughts and inputs how Bing generates links/citations as in the attached image.  [https://imgur.com/a/SL3OFbL](https://imgur.com/a/SL3OFbL) \n\nA few possibilities how these citations are generated\n\n\\- prompt engineering: it might work to some extent, however, i feel it is unlikely the production solution.\n\n\\- A mixture of extractive / abstractive summary\n\n\\- Additional models to check for text entailment/relevance: e.g, for each statement in the summary, identify the best support from each source, this seems too expensive.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zm0n5/d_whats_the_technology_behind_bings_chat/","created":"2023-03-23","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":4}}
{"title":"Guidance on courses to understand language?","description":"I do research with several touchpoints with the social sciences (Psych / Sociology / Management) . I work a lot with Language Models (Word Embeddings / Topic Models), but I would like to obtain a deeper understanding of language itself. The problem is, I don't know where to start. The questions I have for you are then: what are course contents you consider basic to understand language in culture and cognition? Do you know of any online courses I could take to obtain such knowledge? I will also try to audit courses at the linguistics faculty of my home university, but I would like to know what to look for...  \n\n\nEdit: This is of course something I will pursue during my free time, so I would like to balance depth with relevance to my work. ","link":"https://www.reddit.com/r/LanguageTechnology/comments/1204c7v/guidance_on_courses_to_understand_language/","created":"2023-03-24","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0}}
{"title":"Model Selection for Fine-Tuning","description":"I am working on a project that involves text-generation. I have completed my data collection and preprocessing, and would like to fine tune a model to generate text similar to my dataset. This means that I need a decoder model such as gpt-x, llama, etc.\n\nTo save costs on testing the idea out, I would like to train a model locally before I experiment with fine-tuning apis/training on the cloud. Here are my current specs:\n\nCPU: Ryzen 5 5600\n\nRAM: 16 GB (willing to upgrade)\n\nGPU: RTX 3060 12GB\n\nWhat is the largest model that is reasonable to be fine-tuned on my computer? How would someone go about determining that?\n\nI am also familiar with fine-tuning using 8-bit mode or something like LORA. Using one of these methods, what is the largest model I could fine-tune?\n\nIf it helps, my dataset is \\~400MB of text. The text is structured, and I need the model to also learn that structure properly.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zp1f3/model_selection_for_finetuning/","created":"2023-03-23","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":15}}
{"title":"Looking for a recommendation on cloud STT, NLP services","description":"I'm looking for an STT/NLP service with specific requirements: Intent and Entity extraction from the real-time audio stream with minimum latency, adding custom vocabulary to recognize (like sending a list with usernames and it will be able to extract them).\n\nI've already checked:\n\nDialogflow - speech recognition quality is bad compared to the Whisper, even though it has almost everything I need.\n\nNLPcloud - no real-time speech recognition, as far as I've seen.\n\nAssemblyAi - it looks like something that I would like to use, but I'm unable to find whether it can support its features in real-time stream audio.\n\nThanks in advance.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zo3m9/looking_for_a_recommendation_on_cloud_stt_nlp/","created":"2023-03-23","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1}}
{"title":"Document to keep list of acceptable words/phrases for an NLP?","description":"I am creating a document to save all the words variations I'd accept when a NLP transcribes. Is this a common practice? Is their an official name for this document or this practice?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zngbm/document_to_keep_list_of_acceptable_wordsphrases/","created":"2023-03-23","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":6}}
