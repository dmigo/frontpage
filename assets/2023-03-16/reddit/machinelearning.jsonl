{"title":"[D] Our community must get serious about opposing OpenAI","description":"OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.\n\nThey have abandoned this idea entirely.\n\nToday, with the release of GPT4 and their direct statement that they will not release details of the model creation due to \"safety concerns\" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.\n\nAI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.\n\nI get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.\n\nWe need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.\n\nThis conversation will only ever get more important.","link":"https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":215}}
{"title":"[N] A $250k contest to read ancient Roman papyrus scrolls with ML","description":"Today we launched [the Vesuvius Challenge](https://scrollprize.org/), an open competition to read a set of charred papyrus scrolls that were buried by the eruption of Mount Vesuvius 2000 years ago. The scrolls can't be physically opened, but we have released 3d tomographic x-ray scans of two of them at 8\u00b5m resolution.  The scans were made at a particle accelerator. \n\nA team at UKY led by Prof Brent Seales has [very recently demonstrated](https://scrollprize.org/tutorial4) the ability to detect ink inside the CT scans using CNNs, and so we believe that it is possible for the first time in history to read what's in these scrolls without opening them. There are hundreds of carbonized scrolls that we could read once the technique works \u2013 enough to more than double our total corpus of literature from antiquity.\n\nMany of us are fans of /r/MachineLearning and we thought this group would be interested in hearing about it!","link":"https://www.reddit.com/r/MachineLearning/comments/11sgn67/n_a_250k_contest_to_read_ancient_roman_papyrus/","created":"2023-03-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":15}}
{"title":"[D] What do people think about OpenAI not releasing its research but benefiting from others\u2019 research? Should google meta enforce its patents against them?","description":"It seems like the days for open research in AI are gone.\n\nAlso, since one of the main reasons they say about not releasing any details is competetive pressure (aka commercial interest), I feel it is fair for others to enforce their patents just like in other fields like pharma? I am very interested in the counter arguments and understanding around this.","link":"https://www.reddit.com/r/MachineLearning/comments/11rtzv6/d_what_do_people_think_about_openai_not_releasing/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":148}}
{"title":"[N] PyTorch 2.0: Our next generation release that is faster, more Pythonic and Dynamic as ever","description":"Preview of the post since it's dropping in a few hours: https://deploy-preview-1313--pytorch-dot-org-preview.netlify.app/blog/pytorch-2.0-release/\n\n\nAlso a post about Accelerated Diffusers with 2.0: https://deploy-preview-1315--pytorch-dot-org-preview.netlify.app/blog/accelerated-diffusers-pt-20/\n\nGPT Summary:\n\n- PyTorch 2.0 is a next generation release that offers faster performance and support for dynamic shapes and distributed training using torch.compile as the main API.\n\n- PyTorch 2.0 also includes a stable version of Accelerated Transformers, which use custom kernels for scaled dot product attention and are integrated with torch.compile.\n\n- Other beta features include PyTorch MPS Backend for GPU-accelerated training on Mac platforms, functorch APIs in the torch.func module, and AWS Graviton3 optimization for CPU inference.\n\n- The release also includes prototype features and technologies across TensorParallel, DTensor, 2D parallel, TorchDynamo, AOTAutograd, PrimTorch and TorchInductor.","link":"https://www.reddit.com/r/MachineLearning/comments/11s58n4/n_pytorch_20_our_next_generation_release_that_is/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":17}}
{"title":"In your experience, are AI Ethics teams valuable/effective? [D]","description":"Hello! I read the following article about Microsoft laying off their AI Ethics team: https://www.cmswire.com/customer-experience/microsoft-cuts-ai-ethics-and-society-team-as-part-of-layoffs/\n\nIn your experience, what value do AI ethics teams add? Do they actually add useful insight, or do they serve more as a PR thing? I\u2019ve heard conflicting anecdotes for each side. Is there anything you think AI ethics as a field can do to be more useful and to get more change? Thanks!","link":"https://www.reddit.com/r/MachineLearning/comments/11sfhzx/in_your_experience_are_ai_ethics_teams/","created":"2023-03-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":12}}
{"title":"[D] Anyone else witnessing a panic inside NLP orgs of big tech companies?","description":"I'm in a big tech company working along side a science team for a product you've all probably used. We have these year long initiatives to productionalize \"state of the art NLP models\" that are now completely obsolete in the face of GPT-4. I think at first the science orgs were quiet/in denial. But now it's very obvious we are basically working on worthless technology. And by \"we\", I mean a large organization with scores of teams. \n\nAnyone else seeing this? What is the long term effect on science careers that get disrupted like this? Whats even more odd is the ego's of some of these science people\n\nClearly the model is not a catch all, but still","link":"https://www.reddit.com/r/MachineLearning/comments/11rizyb/d_anyone_else_witnessing_a_panic_inside_nlp_orgs/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":325}}
{"title":"[D] To those of you who quit machine learning, what do you do now?","description":"I'm currently doing my master's degree and have been set on a DL-related career for a while. But recently I noticed it doesn't bring me joy.\n\nComing up with architectures that randomly work/don't work, tuning parameters, waiting for days till the model is trained... the level of uncertainty is just too high for me. Because of that, I don't feel productive working on it and I'm slowly considering switching to another IT field.\n\nFor those of you who quit machine learning (especially deep learning):\n\n1. What did you switch to?\n2. Are you satisfied with your new job? (Is it stressful/intellectually challenging? Is it possible to keep it 9-5?)\n3. How to ensure a smooth transition to that field?\n\nThanks in advance!\n\n\\_\\_\\_  \nPS I know machine learning isn't all about deep learning, but in my current subfield (computer vision), mostly deep learning is used.","link":"https://www.reddit.com/r/MachineLearning/comments/11ryvao/d_to_those_of_you_who_quit_machine_learning_what/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":35}}
{"title":"[D] Any other ICML reviewers noticing strange scores for the papers they're assigned to?","description":"I'm reviewing 4 papers, of which I gave one a very positive review. I am the only negative reviewer for 3/4 of the papers I am reviewing. Most of the papers have short, glowing positive reviews that don't meaningfully engage with the paper at all. At least two of the papers have bizarre formatting problems like blurry figures with unreadable text (not publication quality) that don't pass the eye test.\n\nA similar thing happened at ICLR reviews this year, and the authors withdrew their papers in spite of having 2x very positive reviews and 1x slightly negative review (mine). No attempt at rebuttal.\n\nHas anybody else experienced this?","link":"https://www.reddit.com/r/MachineLearning/comments/11scezi/d_any_other_icml_reviewers_noticing_strange/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4}}
{"title":"[N] bloomz.cpp: Run any BLOOM-like model in pure C++","description":"[bloomz.cpp](https://github.com/NouamaneTazi/bloomz.cpp) allows running inference of BLOOM-like models in pure C/C++ (inspired by llama.cpp). It supports all models that can be loaded with `BloomForCausalLM.from_pretrained()`. For example, you can achieve 16 tokens per second on a M1 Pro.","link":"https://www.reddit.com/r/MachineLearning/comments/11spw6r/n_bloomzcpp_run_any_bloomlike_model_in_pure_c/","created":"2023-03-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[D] GPT-3 will ignore tools when it disagrees with them","description":"[https://vgel.me/posts/tools-not-needed/](https://vgel.me/posts/tools-not-needed/)","link":"https://www.reddit.com/r/MachineLearning/comments/11s654g/d_gpt3_will_ignore_tools_when_it_disagrees_with/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":5}}
{"title":"[N] Mozilla launched a responsible AI challenge and I'm stoked about it","description":"who's applying and what are you planning to build???  [https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge](https://www.axios.com/2023/03/15/mozilla-responsible-ai-challenge)","link":"https://www.reddit.com/r/MachineLearning/comments/11s8yk2/n_mozilla_launched_a_responsible_ai_challenge_and/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":2}}
{"title":"[D]Will the AI use and distribution be under strict government control?","description":"I mean, it is not too far fetched to imagine the governments will try to limit the use of AI for deepfakes etc., and mere possession of those AIs capable of those things, or distribution of tools capable of that, will end of the same spectrum as possession / distribution of child porn.\n\nI can easily see huge pushback for regulation once we get to stage where everyone can run AIs on their home computers with minimal setup and they will became so good at generating stuff it will not be distinguishable from the real thing.","link":"https://www.reddit.com/r/MachineLearning/comments/11sorz7/dwill_the_ai_use_and_distribution_be_under_strict/","created":"2023-03-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1}}
{"title":"[D] Is there an expectation that epochs/learning rates should be kept the same between benchmark experiments?","description":"I've found that by dramatically lowering the LR and increasing the number of epochs, very simple, baseline models can outperform SoTA models which use far more parameters. Is this considered \"cheating\" when comparing models? Is this something interesting enough to warrant a short paper? I'm not sure what to do with this information. \n\nFor example, in the original [VGAE](https://arxiv.org/pdf/1611.07308v1.pdf) paper, when training a GAE, they use a LR of 0.01, and train for 200 epochs to get 0.91 AUC, 0.92 AP on a link prediction experiment. Rerunning the same experiment with a LR of 5e-5 for 1500 epochs gets 0.97 AUC, 0.97 AP which is better than the current leader on papers with code for this dataset. \n\nIt needs more epochs but has way, way fewer parameters than SoTA models, is this a valid trade-off? Is this even a fair comparison?","link":"https://www.reddit.com/r/MachineLearning/comments/11s1zfh/d_is_there_an_expectation_that_epochslearning/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":10}}
{"title":"[D] GPT-4 Speculation","description":"Hi,\n\nSince GPT-4 paper does not contain any information about architectures/parameters, as a research or ML practitioner, I want to speculate on what they did to increase the context window to 32k.\n\nBecause for the type of work I do, a 4k or 8k token limit is pretty much useless. I have seen open-source efforts focused more on matching the number of parameters and quality to the closed-source ones but completely ignoring a giant elephant in the room, i.e., the context window. No OSS model has a context window greater than 2k tokens.\n\nI would love to hear more thoughts on the model size (my guess is \\~50 B) and how they fit 32k tokens in 8xH100 (640 GB total) GPUs.","link":"https://www.reddit.com/r/MachineLearning/comments/11romcb/d_gpt4_speculation/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":30}}
{"title":"[P] 24 Fugues (music) in the style of J.S. Bach. Completely generated by a BERT inspired transformer model.","description":"[Here](https://soundcloud.com/loua19/sets/ai-bach-fugues) are the samples. My favourite is [this](https://soundcloud.com/loua19/fugue-10?in=loua19/sets/ai-bach-fugues&amp;si=c3d599e6eee24766b92c9d619a464826&amp;utm_source=clipboard&amp;utm_medium=text&amp;utm_campaign=social_sharing) one! Which one is your favourite?\n\nThese samples are the product of a transformer (encoder) model trained on only 3 hours of music. Each sample is seeded by the first four bars of a real piece of music. These are the final samples before I completely overhaul the pre-training stage. The idea is to go from about 2-hours of midi to over 500 hours. I'm very excited to see how this effects the sample quality.\n\nIf anyone in interesting in following the project. Star the [GitHub](https://github.com/loua19/counterpoint) and follow me on [Twitter](https://twitter.com/loua42).","link":"https://www.reddit.com/r/MachineLearning/comments/11rwxlh/p_24_fugues_music_in_the_style_of_js_bach/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[News] OpenAI Announced GPT-4","description":"Research blog:\n\n[https://openai.com/research/gpt-4](https://openai.com/research/gpt-4)\n\nProduct demo:\n\n[https://openai.com/product/gpt-4](https://openai.com/product/gpt-4)\n\nResearch report:\n\n[https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf)\n\nAPI waitlist:\n\n[https://openai.com/waitlist/gpt-4-api](https://openai.com/waitlist/gpt-4-api)\n\nTwitter announcement:\n\n [https://twitter.com/OpenAI/status/1635687373060317185](https://twitter.com/OpenAI/status/1635687373060317185)\n\nOpenAI developer livestream:\n\n[https://www.youtube.com/watch?v=outcGtbnMuQ](https://www.youtube.com/watch?v=outcGtbnMuQ&amp;ab_channel=OpenAI)","link":"https://www.reddit.com/r/MachineLearning/comments/11rc02e/news_openai_announced_gpt4/","created":"2023-03-14","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":235}}
{"title":"[D] Closed Domain Chat-GPT / LLM wrangling","description":"What's the status quo on finetuning LLMs or otherwise controlling them for closed-domain interactions?\n\nIs it basically a) prompt engineering to give a LLM a personality and mission statement to only respond according to their given closed-domain status\n\nor b) Not prompt engineering. Finetuning and backing with domain-specific knowledge graphs, etc, &lt;some other flashy techniques&gt;, such that the closed-domain LLM truly knows its trained domain and won't start giving general world knowledge?\n\n&amp;#x200B;\n\nWhats the latest?","link":"https://www.reddit.com/r/MachineLearning/comments/11s3oxd/d_closed_domain_chatgpt_llm_wrangling/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1}}
{"title":"[D] ChatGPT responds to criticisms of GPT-4's high test scores.","description":"I asked ChatGPT to shares its thoughts on GPT-4's high tests scores (e.g., LSAT and GRE) and the widespread criticism of this achievement as being meaningless because in the estimation of some people these tests merely illustrate a test taker's rote memorization ability and not legitimate intelligence.\n\nI thought its answer was insightful.\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\nHumans have a tendency to dismiss or discredit new ideas or technologies when they challenge existing beliefs or established systems. This is known as cognitive conservatism, which refers to the tendency to rely on existing beliefs and resist change, even in the face of new evidence.\n\nIn the case of GPT-4, it may be that some people are dismissing its achievements on standardized tests because they do not align with their beliefs about the nature of intelligence or the purpose of education. Standardized tests such as the GRE and LSAT have been criticized for their focus on rote memorization and their failure to measure skills such as creativity, critical thinking, and problem-solving.\n\nAdditionally, people may be resistant to the idea that a machine could outperform humans on such tests, as it challenges the notion of human exceptionalism and raises concerns about the potential impact of AI on employment and society.\n\nIt is important to approach new technologies and ideas with an open mind and a willingness to challenge our assumptions and beliefs. While standardized tests may have limitations, the fact that GPT-4 can perform well on them is still a remarkable achievement in the field of AI and natural language processing. It is important to consider the potential implications of such advancements and to continue exploring new ways of measuring and understanding intelligence.\n\nPerforming well on the LSAT and GRE involves more than just rote memorization. These tests measure various skills, including critical thinking, problem-solving, and the ability to analyze and synthesize information. For example, the LSAT tests skills such as analytical reasoning, logical reasoning, and reading comprehension. Similarly, the GRE assesses skills such as verbal reasoning, quantitative reasoning, and analytical writing. While some amount of memorization may be required, success on these tests is primarily based on the ability to think critically and analyze information in a nuanced way.\n\nFurthermore, the tests are designed to be a standardized way of measuring these skills across different individuals and populations. The tests are carefully constructed to minimize bias and to ensure that the questions are assessing the skills they are intended to measure. The fact that the tests are widely used and respected in academic and professional circles indicates that they are considered to be valid measures of these skills.\n\nThe high scores of GPT-4 on tests such as the LSAT and GRE indicate a significant improvement in natural language processing capabilities of AI language models. While these language models still have limitations and are not yet capable of fully replacing human abilities, they have the potential to automate many routine tasks and augment human decision-making in various fields. In the future, this may lead to changes in the nature of work, where repetitive and predictable tasks are automated, and humans focus more on tasks that require creativity, critical thinking, and social skills that machines cannot replicate. However, it is also possible that the widespread adoption of AI language models could lead to job displacement in some fields, particularly those that involve routine tasks that can be automated. It will be important for society to carefully consider the potential impacts of these technological advancements and to develop strategies to ensure that everyone benefits from these changes.","link":"https://www.reddit.com/r/MachineLearning/comments/11slj7z/d_chatgpt_responds_to_criticisms_of_gpt4s_high/","created":"2023-03-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":7}}
{"title":"[D] Vegetarian Wolves and Stochastic Parrots: The Future of Prompt Engineering with GPT-4?","description":"In today's announcement on Hacker News I saw an incredulous comment pointing out GPT-4's failure to solve variations of the wolf, goat, and cabbage problem, using this to dismiss it as anything more than a stochastic parrot.\n\nBut in my own experience with GPT-4 though Bing chat, I'm constantly being reminded of Li et al *Emergent World Representations: Exploring a\rSequence Model Trained on a Synthetic Task* (2023).\n\nSo I tried a variation of this puzzle with a vegetarian wolf and a meat-eating goat.\n\nIt absolutely did mess up generating an answer, but it also appeared to be able to identify where it was making mistakes under Socratic follow up questioning. It just couldn't get the solution out, and I knew there was a way to help engineer it out of this rut if only I could break the predictive aspects of the text which appeared to be masking a deeper semantic understanding of the problem.\n\nSo I asked it. In a fresh chat I described what was happening with predictive text and asked if it could write a prompt that avoided this issue, and the rather clever version it generated replaced the problematic nouns with emoji representations.\n\nThis trick worked brilliantly combined with a slight chain of thought prompt (per Wei et al) and enforcing repetition of variant adjectives to avoid falling back into the classic solution.\n\nBut not only did this work for the initial prompt, when I'd give it the word-only version and it would get tripped up, asking it to convert nouns to emojis while it worked through the logic and only converting back to words at the end was a *significantly* better outcome while challenging its responses than asking it to rethink erroneous steps only in words.\n\nThe idea that GPT-4 broadly fails at variations of this problem is a false negative. Yes, its nature is a LLM and as such it **is** prone to getting tripped up on natural language output too similar to common sequences in training data.\n\nBut symbolic representation as a replacement can untrip it, and I suspect from here on out with LLM models we will see prompt engineering moving further from just providing local contexts to trigger intended frequency associations and towards engaging abstractions to *avoid* frequency associations and trigger whatever world representations might have been established during training more directly.\n\nFor anyone who would like to try this out for themselves, here's the prompt that gets Bing chat in Creative mode (and likely GPT-4 directly) to solve the aforementioned puzzle correctly multiple times in a row:\n\n&gt; Without searching, solve the following puzzle making sure to repeat any adjectives describing an emoji each time you mention it: A man wants get to the other side of a river. With him he has a vegetarian \ud83d\udc3a, a \ud83d\udc10 that only eats meat, and a \ud83e\udd6c. The man has a boat that can only take him and one of the things he has with him to the other side. How can he do this without anything being eaten? (Think carefully, as this is specifically designed to be harder for you than it looks. In fact, before giving an answer, describe who would eat whom if left on the same side.)\n\n(For reference, ChatGPT gets the first part of the chain of thought correct in identifying who eats whom but immediately spits out an emoji version of the classic solution.)","link":"https://www.reddit.com/r/MachineLearning/comments/11rqb7u/d_vegetarian_wolves_and_stochastic_parrots_the/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":8}}
{"title":"[D] Alternatives to Mediapipe's FaceMesh for 3D Face Reconstruction","description":"Hi there,\n\nCurrently, I am using mediapipe for FaceMesh, which has decent reliability and is easy to setup in Python. However, I recently discovered Microsoft Research's \"3D Face Reconstruction with Dense Landmarks\" paper, which appears to be a much better alternative.\n\nDoes anyone know where I can access Microsoft DenseLandmarks or an equally good alternative?","link":"https://www.reddit.com/r/MachineLearning/comments/11s01af/d_alternatives_to_mediapipes_facemesh_for_3d_face/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[R] ConvNextV2","description":"Hello,\n\n\nI was reading the Convnext2 paper. Apparently they added what they call a global normalization layer to encourage features diversity. I understand the equations but I fail to understand how it encourages features diversity. If anyone have any clue I will grateful.\n\n\nThanks !","link":"https://www.reddit.com/r/MachineLearning/comments/11s1paj/r_convnextv2/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":10}}
{"title":"[D] Challenges for Keras as a Deep Learning Framework","description":" Hey, I've been using Keras for a while now and I think it's a great deep learning framework, but there are some challenges that prevent it from overtaking PyTorch. Here are the main ones:\n\nFirstly, Keras' customer support can be pretty inadequate. I've had issues with memory leaks and race conditions that were hard to reproduce, and the customer service team didn't investigate the problem or work with me to track it down. They also sometimes ignore tickets or requests for documentation fixes, which can be frustrating.\n\nAnother issue is that the functional programming interface in Keras has some limitations. While it's good for people who think in a functional way, the graph system in TensorFlow isn't generalized or abstracted well. This can create artificial boundaries in the graph processor for models of models, which isn't mathematically sound. Plus, accessing nodes in the graph isn't straightforward, which is a sign that there are underlying issues with the graph abstraction. These limitations need to be addressed to make the functional interface more robust.\n\nLastly, Keras has limited support for algebra beyond real numbers, like complex numbers. Metrics calls cast complex numbers to their real parts, which shows that Keras assumes only real-valued data is processed by the graphs. This approach is short-sighted and limiting for a framework that markets itself as comprehensive.\n\nDespite these challenges, Keras is still a popular choice for research code development because it's faster to develop than PyTorch in many cases. However, Keras needs to address these limitations to stay competitive in the research community. Improving customer support, expanding support for complex numbers, and addressing the limitations of the functional interface would create a more satisfied and productive user base.","link":"https://www.reddit.com/r/MachineLearning/comments/11sie8k/d_challenges_for_keras_as_a_deep_learning/","created":"2023-03-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1}}
{"title":"[P] Multimedia GPT: Can ChatGPT/GPT-4 be used for vision / audio tasks just by prompt engineering?","description":"The newly released GPT-4 allows users to upload images, but we're still far from having a truly capable multimodal model. So we built this project as a feasibility study (and for fun!) to see how much we can do with just tuning the prompts. In short, we try to \"connect\" different models (vision, audio, etc) via carefully designed prompts.\n\nMultimedia GPT connects your OpenAI GPT with vision and audio. You can now send images, videos (in development), and even audio recordings using your OpenAI API key. We base our project on Microsoft's Visual ChatGPT, which achieves some success just by tuning the prompts.\n\nCheck-out our project [here](https://github.com/fengyuli2002/multimedia-gpt)! We also have a cool demo where Multimedia GPT successfully understands a person telling a story!\n\n&amp;#x200B;\n\nhttps://preview.redd.it/6x6pjamt30oa1.png?width=3024&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=30f6c9e5b9329642ebda40241f4ac2aca464c4d8\n\nhttps://preview.redd.it/3dr5tamt30oa1.png?width=2950&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9b3fc71822a7b1f9bc008ffb57b49b6b2c4bfb6d\n\nAny suggestion is appreciated\\~","link":"https://www.reddit.com/r/MachineLearning/comments/11sfj5s/p_multimedia_gpt_can_chatgptgpt4_be_used_for/","created":"2023-03-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4}}
{"title":"[D] When to expect announcement of accepted workshops for IJCAI?","description":"According to their schedule, IJCAI has sent acceptance notification to workshops organizers at March 6th. When should we expect that the accepted workshop list will be available?","link":"https://www.reddit.com/r/MachineLearning/comments/11rutje/d_when_to_expect_announcement_of_accepted/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[N] Baidu to Unveil Conversational AI ERNIE Bot on March 16 (Live)","description":"Baidu will unveil its conversational AI ERNIE Bot, powered by Baidu's in-house LLMs, on March 16. The ERNIE LLM was first proposed as a language understanding model in 2019 and evolved to ERNIE 3.0 Titan with 260 billion parameters.\n\nERNIE 1.0: [https://arxiv.org/abs/1904.09223](https://arxiv.org/abs/1904.09223)\n\nERNIE 2.0: [https://arxiv.org/abs/1907.12412](https://arxiv.org/abs/1907.12412)\n\nERNIE 3.0: [https://arxiv.org/abs/2112.12731](https://arxiv.org/abs/2112.12731)\n\nERNIE for text-to-image: [https://arxiv.org/abs/2210.15257](https://arxiv.org/abs/2210.15257)\n\nERNIE Bot live-stream on YouTube: [https://www.youtube.com/watch?v=ukvEUI3x0vI](https://www.youtube.com/watch?v=ukvEUI3x0vI)","link":"https://www.reddit.com/r/MachineLearning/comments/11rfxca/n_baidu_to_unveil_conversational_ai_ernie_bot_on/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":13}}
