{"title":"Transformer models: if token embeddings are trainable params, why doesn't training cause every token to be mapped to the same vector?","description":"Wouldn't the model have incredibly low loss if every token was the same? What stops this from happening?","link":"https://www.reddit.com/r/deeplearning/comments/11rqtpm/transformer_models_if_token_embeddings_are/","created":"2023-03-15","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":1}}
{"title":"How does Donut extract precise text without OCR?","description":"I've stumbled upon [this paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136880493.pdf) and a couple of others that basically discuss an alternative approach (Donut) for Visual Document Understanding (VDU).\n\nThe conventional and common approach (like what's done by LayoutLM) is to first perform OCR on the input image (with potential text block recognition beforehand), then post-process the output text. Donut's premise is to basically cut out the OCR step and process end-to-end in one pass.\n\nMy question is simply how does the text extraction happen in that case? how can text be extracted with such precision without OCR or some other form of optical text recognition?\n\nI went through the paper and a handful of articles explaining it, but the concept as a whole is still quite baffling to me and it all sounds like \"you can see without your eyes\" at this point x)","link":"https://www.reddit.com/r/deeplearning/comments/11rc2oh/how_does_donut_extract_precise_text_without_ocr/","created":"2023-03-14","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0}}
{"title":"Hilarious mistake by a friend","description":"I thought this conversation may spread some laughs. A friend is just starting to learn about CNNs in a course and comes to me for help sometimes. Hilarity ensued this morning when he tried to add some new functionality to his CNN on the Caltech dataset and mistook weight decay for learning rate decay.\n\nhttps://preview.redd.it/5hvcc817gqna1.png?width=455&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=30eaba5feea732dd60b5f426b1dcd1cae9efd6d8\n\nhttps://preview.redd.it/xej27laagqna1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ce46be4bef86e6ed7e56c49a46db396d67ca5755\n\n&amp;#x200B;\n\nhttps://preview.redd.it/nv4m4hqagqna1.png?width=449&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=da8f9d0981c6a1d07fad04db40d81516cfa6bd21\n\nhttps://preview.redd.it/ouphexgbgqna1.png?width=445&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c4f1e2d71e19420f9b10b5c4f9df22323c885bdd","link":"https://www.reddit.com/r/deeplearning/comments/11rb5eo/hilarious_mistake_by_a_friend/","created":"2023-03-14","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":2}}
{"title":"Research opportunity","description":"Hey all, I came across Fatima Fellowship on LinkedIn (not sure if links are allowed here so I won't post it but you can just google it up). They provide research opportunities for Machine Learning and I guess related areas. It says that it's free and works as a non-profit. Thought I would share here incase anyone is looking for research chances.","link":"https://www.reddit.com/r/deeplearning/comments/11rfapy/research_opportunity/","created":"2023-03-14","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0}}
{"title":"Question on study options","description":"I started my career as a quant then programmer, then data scientist and now work for Bloomberg.\n\nI've been using ML for years but have not really worked with NLP and with the recent advances in LLMs the penny dropped that our working world is about to start changing very quickly.\n\nAre there any AI MSc degrees that are aligned to this space that are open to part time study?\n\nOr, should I just dive into the books as the MSc would not be specific enough.\n\nI did an MSc in quant mathematics a few years ago after a break of 20 years from my Physics BSc and found it pretty broad and tbh not all that useful.\n\nAnyway. Just seeing what people's thoughts are \n\nCheers","link":"https://www.reddit.com/r/deeplearning/comments/11r0l52/question_on_study_options/","created":"2023-03-14","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":3}}
{"title":"What are some ways to teach myself new skills?","description":"","link":"https://www.reddit.com/r/deeplearning/comments/11r65oj/what_are_some_ways_to_teach_myself_new_skills/","created":"2023-03-14","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":4}}
{"title":"Calculating the gradient of the marginal log-likelihood function","description":"In the article [The theory behind Latent Variable Models: formulating a Variational Autoencoder](https://theaisummer.com/latent-variable-models/#variational-autoencoders)  , to model the desired probability distribution, estimating the parameters of a probability distribution so that the distribution fits the observed data is presented as an optimization problem of: \n\n&amp;#x200B;\n\nhttps://preview.redd.it/sgfz5txkjnna1.png?width=374&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=73b1ebc471187004419e8f7e1402b1d030a43e00\n\nThe gradient of the marginal log-likelihood function is then calculated using simple calculus and the Bayes rule:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/kwgde2twjnna1.png?width=427&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9f5071bcc63ed8e8c2c31c23a46ee3e51075a9bf\n\nwhere can one find the proof/maths behind this gradient calculation?","link":"https://www.reddit.com/r/deeplearning/comments/11qz5ze/calculating_the_gradient_of_the_marginal/","created":"2023-03-14","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":4}}
{"title":"How To Scale Transformers\u2019 Memory up to 262K Tokens With a Minor Change?","description":"I just published my latest medium article. \n\nThis article is a fabulous attempt to leverage language models in memorizing information by transformers with the least required effort by inserting only an external memory near the last layer of the transformer.\n\nWe can use this to retrieve information that the transformer is trained with which helps the reliability of predictions.\n\nFeel free to share this and/or contact me directly.\n\nhttps://medium.com/towards-artificial-intelligence/extending-transformers-by-memorizing-up-to-262k-tokens-f9e066108777","link":"https://www.reddit.com/r/deeplearning/comments/11qfl2o/how_to_scale_transformers_memory_up_to_262k/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":5}}
{"title":"Using GANs to generate defective data","description":"Hey guys,\n\nI'm working on implementing a model to detect defects on the  labels of bottles.\n\nThe model should be able to spot bubbles, folds, and  miss-labels.\n\nBut I'm short on actual defective data, so I'm thinking  about making some artificial data using GANs.\n\nI gave it a shot with  simple image processing, but the model couldn't generalize well.\n\nGot any ideas  or suggestions on how I could make this work?\n\nWould really appreciate  some help.\n\n&amp;#x200B;\n\n[Bubble example](https://preview.redd.it/d9xnpmm1kina1.jpg?width=500&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8de5ec7bcfecfc765bef680f756bf67d629e26c8)","link":"https://www.reddit.com/r/deeplearning/comments/11qanvr/using_gans_to_generate_defective_data/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":17}}
{"title":"Learning logical relationships with neural networks with differential ILP","description":"Since last week\u2019s post on my lab\u2019s software package [PyReason](https://neurosymoblic.asu.edu/pyreason/), I got a lot of questions on if it would be possible for a neural network to learn logical relationships from data. After all, ChatGPT seems to be able to generate Python code, and Meta released a NeurIPS paper to show you can learn math equations from data using a transformer-based model, so why not logic? In this article, we will one line of research in this area \u2013 differential ILP.\n\nThe research in this area really kicked off with a 2018 [paper from DeepMind](https://www.reddit.com/r/deeplearning/jair.org/index.php/jair/article/view/11172) where Richard Evans and Edward Grefenstette showed that you could adapt techniques from \u201cinductive logic programming\u201d to use gradient descent, and learn logical rules from data. Previous (non-neural) work on inductive logic programming was generally not designed to work with noisy data and instead fit the historical examples in a precise manner. Evans and Grefenstette utilized a neural architecture and a loss function \u2013 and they showed they could handle noisy data and even do some level of integration with CNN\u2019s. Their neural architecture mimicked a set of candidate logical rules \u2013 and the rules assigned higher weights by gradient descent would be thought to best fit the data. However, a downside to this approach is that the neural network was [quintic in the size of the input](https://www.youtube.com/watch?v=SOnAE0EyX8c&amp;list=PLpqh-PUKX-i7URwnkTqpAkSchJHvbxZHB&amp;index=5). This is why they only applied their approach on very small problems \u2013 it did not see very wide adoption.\n\nThat said, in the last two years, there have been some notable follow-ons to this work. Researchers out of Kyoto University and NTT introduced a manner to learn rules that are more expressive in a different manner by allowing function symbols in the logical language ([Shindo et al., AAAI 2021](https://ojs.aaai.org/index.php/AAAI/article/view/16637/16444)). They leverage a clause search and refinement process to limit the number of candidate rules \u2013 hence limiting the size of the neural network. A student team from ASU created a presentation on their work for our recent seminar course on neuro symbolic AI. We released a three part video series from their talk:\n\n[Part 1: Review of differentiable inductive logic programming](https://www.youtube.com/watch?v=JIS78a40q8U&amp;t=270s)\n\n[Part 2: Clause search and refinement In our recent video series](https://www.youtube.com/watch?v=nzfbxlHUwuE&amp;t=345s)\n\n[Part 3: Experiments](https://www.youtube.com/watch?v=-fKWNtHUIN0&amp;t=27s)\n\n[Slides](https://labs.engineering.asu.edu/labv2/wp-content/uploads/sites/82/2022/10/Shindo_dILP.pdf)\n\nSome think that the ability to learn such relationships will represent a significant advancement in ML, specifically addressing shortcomings in areas such as knowledge graph completion and reasoning about scene graphs. However, the gap still remains wide, and ILP techniques, including differentiable ILP still have a ways to go. Really interested in what your thoughts are, feel free to comment below.","link":"https://www.reddit.com/r/deeplearning/comments/11q8tir/learning_logical_relationships_with_neural/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":3}}
{"title":"Which topic in deep learning do you think will become relevant or popular in the future?","description":"I recently saw Continual Learning (CL) growing, with several papers published recently that have considerable potential to impact real-world applications. Which topic (such as CV, RL, NLP, CL..) will be very relevant to research or be focused on a lot? And which topic do you think still needs a breakthrough and will have a significant impact in real-world applications, such as in the case of these LLM models in recent times? Feel free to mention your current topic of work and why you chose to do it \ud83d\ude0a","link":"https://www.reddit.com/r/deeplearning/comments/11pyvb3/which_topic_in_deep_learning_do_you_think_will/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":14}}
{"title":"Multiple objects - Multivariate LSTM","description":"Hello there, I'm new to deeplearning but I'm very fascinated by it.\n\nI'm actually working with multivariate time series (TS) forecasting. I already saw many approaches but none of them appear to be similar to my problem:\n\nI have ~150k objects, for each objects I have 4 independent TS (A B C D) and 1 dependent TS (let's call it Z).\n\nEach TS is about 45-50 observations depending on the studied year.\nI need to train a NN on the TS from the previous years to be used on the TS for this year and the next ones.\n\nI have 2 objectives: \n-predict the next 2-4 observations of TS Z using no more than the last 6 observations of ABCD;\n-predict all TS Z based on all the previous observations from ABCD. Obviously the predictions in the nearest future will be more precise that the ones in the long future. So with gradually increasing obs after each time step.\n\nCan you suggest me the best structure to achieve those 2 objs?","link":"https://www.reddit.com/r/deeplearning/comments/11q9hj3/multiple_objects_multivariate_lstm/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0}}
{"title":"Display model like tensorspace","description":"Hi guys, quick question.\n\nDo you know any JavaScript module that could be used to display your model layers like in tensorspace playground? \n\nI was trying to use their angular example but I think it\u2019s outdated and doesn\u2019t have the best docs. Thanks!","link":"https://www.reddit.com/r/deeplearning/comments/11qdorq/display_model_like_tensorspace/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0}}
{"title":"Image reconstruction","description":"I have a use-case where (say) N RGB input images are used to reconstruct a single RGB output image, using either an Autoencoder, or a U-Net architecture. More concretely, if N = 18, 18 RGB input images are used as input to a CNN which should then predict one target RGB output image.\n\nIf the spatial width and height are 90, then *one input sample* might be (18, 3, 90, 90) **which is not batch-size = 18!** AFAIK, (18, 3, 90, 90) as input to a CNN will reproduce (18, 3, 90, 90) as output, whereas, I want (3, 90, 90) as the desired output.\n\nAny idea how to achieve this?","link":"https://www.reddit.com/r/deeplearning/comments/11qazip/image_reconstruction/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":6}}
{"title":"Recommendations sources for Understanding Advanced Mathematical Concepts in Research Papers?","description":"Hey everyone,\n\nI'm struggling with understanding mathematical proofs in research papers. I have a good grasp of basic concepts such as calculus (single variable calculus and basic knowledge of multi-variable calculus), linear algebra, and basic probability.\n\nI was wondering if any of you could recommend some sources (preferably videos or lecture series) to help me become more familiar with advanced mathematical concepts found in research papers.\n\nFor example:([source](https://www.biorxiv.org/content/10.1101/2021.03.21.436284v1.full.pdf))\n\nhttps://preview.redd.it/m19pwqkwkdna1.png?width=1104&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5cb83feec7e92d4e7f991f7c22cda8483c39c377\n\nIn papers, I have frequently encountered concepts like, **KL divergence**, **mathematics in higher-dimensional space**, **hessian**, **topology, Random projections** and many more;What are the subject/module names I need to study  to confidently read and understand proofs in papers?\n\n&amp;#x200B;\n\nThanks in advance!","link":"https://www.reddit.com/r/deeplearning/comments/11pq968/recommendations_sources_for_understanding/","created":"2023-03-12","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":9}}
{"title":"YOLO equation","description":"Hi,Can any one explain this equation?Pr(Classi|Object) \u2217 Pr(Object) \u2217 IOU = Pr(Classi) \u2217 IOUIt is from the You Look Only Once article, but it seems mathematically wrong. Shouldnt be like this  Pr(Classi|Object) \u2217 Pr(Object) \u2217 IOU = Pr(Classi\\^Object) \u2217 IOU ?","link":"https://www.reddit.com/r/deeplearning/comments/11q0c2t/yolo_equation/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":5}}
{"title":"Does anyone here have a job in industry using deep learning for genomics/bioinformatic work?","description":"If so, how common would you describe these jobs to be? Asking as a grad student who might spend a considerable amount of time doing deep learning projects and who hopes to get a job in industry. I have asked similar questions on the bioinfornatic sub.","link":"https://www.reddit.com/r/deeplearning/comments/11pr44f/does_anyone_here_have_a_job_in_industry_using/","created":"2023-03-12","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0}}
