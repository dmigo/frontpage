{"title":"(Soon) NLP graduate and feel completely inferior on the job market","description":"I am a master student in NLP/Computational linguistics and currently looking for jobs after graduation. Prepare for long panicked post, hope this is the right place to ask/vent..\n\nBoth my bachelor and master were a specialized NLP degree. Especially the bachelor was pretty general: I took all the same intro to linguistics (syntax, phonetics, morphology etc.) classes as the theoretical linguistics. I had a lot of \u201etraditional\u201c NLP methods such as parsing based on formal languages, automata theory, search algorithms. Basic maths, statistics, linear algebra. Specialized seminars on coreference, sentiment analysis etc but those were mostly in the style of reading-papers-and-discussing-them. My master offered more technical and applied courses, but I did not feel well prepared since I never learned how to program neural networks myself except for a very basic numpy and pandas based classifier, but suddenly everyone was talking about transformer models. I had theoretical ML classes, but somehow we were just expected to know how to implement them into our projects too? I am now doing my thesis where I am using an existing system (pytorch-based) and adapting and tuning it for a slightly different task. While I (thought I) know how to program and the basic of how machine learning, the reality is I feel soooo out of place. I have a hard time even understanding the pytorch documentation, and I feel like there are a million things to consider. Shapes don\u2019t match, cuda out of memory, suddenly i need to do gradient clipping which I feel I was taught about in 30min 2 years ago maybe. I usually make it work somehow after 5 nervous breakdows, but I constantly feel like I am half-assing everything, just trying to get it to run at least. If I were to build such a system, even a way simple one, from scratch, I would die.\n\nNow looking at jobs, most of those that advertise with NLP require \u201epractical machine learning experience with frameworks such as TensorFlow, PyTorch\u2026\u201c, and nearly every job is also equally directed at graduates from EITHER data science, mathematics, computer science, NLP \u2026 How can I keep up with data scientists in this aspect? Did I mess up by not practicing how to actually code and understand complex systems during my degree? I know a few other students who expressed similar concerns, at least from my school. I definitely see potential for me in areas with highly specialized use cases/messy/non-standard data, but wonder if this really needed &gt;3 years of linguistic basics. Will employers actually care about my linguistic background compared to a data scientist with some NLP experience? Currently I feel like I would have done better doing a data science degree and then taking a few classes on linguistics later on to specialize\u2026. I guess I will find a job one way or another but I am already scared of interviews because of these inadequacies.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zvsnj/soon_nlp_graduate_and_feel_completely_inferior_on/","created":"2023-03-23","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":13}}
{"title":"SUMMARY OF LANGUAGE LEARNING APPS USING GPT","description":" Notion, Bing and Microsoft Office have integrated GPT. Now it's time for Duolingo and other language learning apps to catch up with this trend, providing a native communication training environment and helping you practice 24/7! \n\nIn order for us not to be behind with this trend, I have summarized some language learning applications with GPT integration: Duolingo Max, Speak and eJOY EPIC.\n\n**1. DUOLINGO:**\n\na. Features of GPT - Duolingo Max integration:\n\n\\- Roleplay: Voice chat with AI for multiple communication contexts: order drinks at the cafe, plan outings, go shopping\u2026 with Duolingo characters\n\n\\- Explain My Answer: give examples and explanations for your answers in the lesson whether you choose right or wrong\n\nb. Advantage:\n\n\\- User-friendly interface, easy to use\n\n\\- Automatically show suggestions for better communication next time after each dialogue\n\n\\- Automatically analyze answers\n\n\\- Roleplay option gives +40 XP, much higher than normal lessons (+10 XP)\n\nc. Defect:\n\n\\- Currently Duolingo Max is only available in the U.S., Great Britain, Ireland, Canada, Australia, and New Zealand\n\n\\- The only courses that can utilize these new features are Spanish and French for English speakers on iOS\n\n\\- Charges quite high: $29.99/month or $167.99/year\n\n*Link to download Duolingo on iOS:* [*https://apps.apple.com/us/app/duolingo-language-lessons/id570060128*](https://apps.apple.com/us/app/duolingo-language-lessons/id570060128) \n\n*Link to download Duolingo on Android:* [*https://play.google.com/store/apps/details?id=com.duolingo&amp;hl=en&amp;gl=US*](https://play.google.com/store/apps/details?id=com.duolingo&amp;hl=en&amp;gl=US) \n\n\u2014--\u2014--\u2014--\u2014--\u2014--\n\n**2. SPEAK:**\n\na. GPT integration features:\n\n\\- Role-playing: Chat, voice chat with AI in many communication contexts and goals\n\nb. Advantage:\n\n\\- Friendly interface, easy to use, smooth experience\n\n\\- Classification of communication contexts according to learning level\n\n\\- In each context, there will be examples of sentences and communication goals\n\n\\- There is grading based on intonation and communication goals. The speech recognition of this app is accurate!\n\n\\- Show hints if you don\u2019t know what to say next\n\nc. Defect:\n\n\\- Do not automatically interpret the answer\n\n\\- Only displayed in Japanese and Korean for English learners. Fortunately, I know a few Korean words, but I'm tired of translating the words from Korean\n\n\\- Charge quite high but cheaper than Duolingo: $26.52/month or $117.7/year\n\n*Link to download Speak on iOS:* [*https://apps.apple.com/vn/app/speak-learn-english/id1286609883*](https://apps.apple.com/vn/app/speak-learn-english/id1286609883) \n\n*Link to download Speak on Android:* [*https://play.google.com/store/apps/details?id=com.selabs.speak&amp;hl=en*](https://play.google.com/store/apps/details?id=com.selabs.speak&amp;hl=en) \n\n\u2014--\u2014--\u2014--\u2014--\u2014--\n\n**3. eJOY EPIC:**\n\na. GPT Integration Features\n\n\\- Role playing talking with commands and context available\n\n\\- Voice chat with GPT\n\n\\- Look up and save words right in sentences, play games to remember words\n\nb. Advantage:\n\n\\- It's Vietnamese. I'm a bit biased towards Vietnamese products since I\u2019m also one of them \ud83d\ude00\n\n\\- Look up words right in the sentence, save the time to open the dictionary\n\n\\- ChatGPT feature is free to use, but the main features like the course are paid. Free ChatGPT only. But this course is very interesting. I will share more below\n\nc. Defect:\n\n\\- GPT is not integrated into the course section - which is the part I like the most of Epic. Epic's learning concept is also very different from other applications, like having a teacher show you any special vocabulary or grammar in this video, then give exercises for those phrases. Learning experience is quite enjoyable for beginners\n\n\\- Do not automatically interpret the answer\n\n\\- Only suggest prompt for the first question, you have to come up with the content to say and maintain the conversation after that\n\n*Link to download eJOY EPIC on iOS:* [*https://apps.apple.com/vn/app/ejoy-epic-english-courses/id1622797145*](https://apps.apple.com/vn/app/ejoy-epic-english-courses/id1622797145) \n\n*Link to download eJOY EPIC on Android:* [*https://play.google.com/store/apps/details?id=com.ejoy.epic&amp;hl=en*](https://play.google.com/store/apps/details?id=com.ejoy.epic&amp;hl=en)","link":"https://www.reddit.com/r/LanguageTechnology/comments/120fvgu/summary_of_language_learning_apps_using_gpt/","created":"2023-03-24","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":0}}
{"title":"[D] What's the technology behind Bing's chat: summarization with citations.","description":"Cross-posting from r/MachineLearning for the audience.\n\nWould love to learn from you folks on thoughts and inputs how Bing generates links/citations as in the attached image.  [https://imgur.com/a/SL3OFbL](https://imgur.com/a/SL3OFbL) \n\nA few possibilities how these citations are generated\n\n\\- prompt engineering: it might work to some extent, however, i feel it is unlikely the production solution.\n\n\\- A mixture of extractive / abstractive summary\n\n\\- Additional models to check for text entailment/relevance: e.g, for each statement in the summary, identify the best support from each source, this seems too expensive.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zm0n5/d_whats_the_technology_behind_bings_chat/","created":"2023-03-23","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":3}}
{"title":"How to make a homemade ChatGPT model","description":"Obviously, the creation of such big and complex models like ChatGPT is not a trivial task, but it is possible to create a model which can solve 1 task like ChatGPT. We are glad to announce our opensource [dataset](https://www.kaggle.com/datasets/vladimirvorobevv/chatgpt-paraphrases) of 420k paraphrases generated by ChatGPT and a [model](https://huggingface.co/humarin/chatgpt_paraphraser_on_T5_base) pretrained on it. We have trained the model just for 2 epochs and the model shows not the best results, but it is already makes more variative paraphrases than the most popular paraphraser on huggingface. Feel free to try the dataset and the model and give a feedback to improve their quality","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zuzco/how_to_make_a_homemade_chatgpt_model/","created":"2023-03-23","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":0}}
{"title":"Guidance on courses to understand language?","description":"I do research with several touchpoints with the social sciences (Psych / Sociology / Management) . I work a lot with Language Models (Word Embeddings / Topic Models), but I would like to obtain a deeper understanding of language itself. The problem is, I don't know where to start. The questions I have for you are then: what are course contents you consider basic to understand language in culture and cognition? Do you know of any online courses I could take to obtain such knowledge? I will also try to audit courses at the linguistics faculty of my home university, but I would like to know what to look for...  \n\n\nEdit: This is of course something I will pursue during my free time, so I would like to balance depth with relevance to my work. ","link":"https://www.reddit.com/r/LanguageTechnology/comments/1204c7v/guidance_on_courses_to_understand_language/","created":"2023-03-24","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":0}}
{"title":"Model Selection for Fine-Tuning","description":"I am working on a project that involves text-generation. I have completed my data collection and preprocessing, and would like to fine tune a model to generate text similar to my dataset. This means that I need a decoder model such as gpt-x, llama, etc.\n\nTo save costs on testing the idea out, I would like to train a model locally before I experiment with fine-tuning apis/training on the cloud. Here are my current specs:\n\nCPU: Ryzen 5 5600\n\nRAM: 16 GB (willing to upgrade)\n\nGPU: RTX 3060 12GB\n\nWhat is the largest model that is reasonable to be fine-tuned on my computer? How would someone go about determining that?\n\nI am also familiar with fine-tuning using 8-bit mode or something like LORA. Using one of these methods, what is the largest model I could fine-tune?\n\nIf it helps, my dataset is \\~400MB of text. The text is structured, and I need the model to also learn that structure properly.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zp1f3/model_selection_for_finetuning/","created":"2023-03-23","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":10}}
{"title":"Looking for a recommendation on cloud STT, NLP services","description":"I'm looking for an STT/NLP service with specific requirements: Intent and Entity extraction from the real-time audio stream with minimum latency, adding custom vocabulary to recognize (like sending a list with usernames and it will be able to extract them).\n\nI've already checked:\n\nDialogflow - speech recognition quality is bad compared to the Whisper, even though it has almost everything I need.\n\nNLPcloud - no real-time speech recognition, as far as I've seen.\n\nAssemblyAi - it looks like something that I would like to use, but I'm unable to find whether it can support its features in real-time stream audio.\n\nThanks in advance.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zo3m9/looking_for_a_recommendation_on_cloud_stt_nlp/","created":"2023-03-23","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":0}}
{"title":"Document to keep list of acceptable words/phrases for an NLP?","description":"I am creating a document to save all the words variations I'd accept when a NLP transcribes. Is this a common practice? Is their an official name for this document or this practice?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zngbm/document_to_keep_list_of_acceptable_wordsphrases/","created":"2023-03-23","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":6}}
{"title":"I need guidance on the feasibility or scoping of a project","description":"Hello everyone, for my work I'm assigned to make a system, which, for a given job ad will produce the necessary skills and responsibilities needed to do the job.  \nFor example, let's say, I'm giving the content of a  job ad to chatGPT and ask \" what skills are needed to do this job? \". And it replied:\n\n1. Good understanding of Oracle/Sybase/MSSQL database architecture\n2. Hands-on experience in database administration, including backup and recovery using RMAN\n3. Experience with Oracle GRID Control, ASM, Recovery Manager, Import / Export, Datapump, SQL Server administration, and clustering management\n4. Working knowledge of Control\\_M jobs\n5. Good understanding of High Availability (HA) concepts such as Always On and Clustering.  \n\n\n.... The list contains a couple more instances.  \n\n\n  \nNow, I want to phrase it as a QA system to make just this. To train it, I will have jobs\\_ad... and the fixed\\_question \"What are the skills/responsibilities to do this job\" and the context answer will be manually labeled. I'm thinking of fine-tuning \"distilbert-base-cased-distilled-squad\" with randomly sampled 5000 labeled instances.  \n\n\nI need suggestions on the feasibility of this. Has anyone built this kind of system? Any suggestion on phrasing the solution differently? Any feedback is really appreciated.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11zblqp/i_need_guidance_on_the_feasibility_or_scoping_of/","created":"2023-03-23","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":1}}
{"title":"Rare/unusual words extraction","description":"I want to get a list of the rare words (probably these that are not encountered on a normal basis, speaking in language-acquisition terms, words that are known for C2 speakers of the language or native speakers) from some text.\n\nWhat i thought about so far is just going through some frequency lists (like this one [http://corpus.leeds.ac.uk/serge/kelly/](http://corpus.leeds.ac.uk/serge/kelly/) or wikipedia frequency lists, or even everything combined), but this sounds like brute-forcing and something that would not entirely accurate. Are there any good pre-trained models classifying the rarity of words?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11z0hyk/rareunusual_words_extraction/","created":"2023-03-22","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":2}}
{"title":"best way to do Topic modeling for short texts?","description":"Hello, \n\nwhat's the best topic modeling technique to identify topics in short texts? I have a data set where textes are composed of around 10 to 60 words ! I tried LDA, TopicBERT and GDSMM. the results were all bad. My texts are in french by the way.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11ykwu1/best_way_to_do_topic_modeling_for_short_texts/","created":"2023-03-22","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":3}}
{"title":"How do we find Values in Attention, or do we need them at all?","description":"Hi everyone, I'm a bit confused about value(v) parameter in attention. At some posts after calculating attention scores they don't introduce any value(v) parameter. Sometimes they just copy and use the same values as key parameter.\n\n&amp;#x200B;\n\nI'm watching the lecture: [https://www.youtube.com/watch?v=0PPzD4mxpuM&amp;list=PL8PYTP1V4I8D0UkqW2fEhgLrnlDW9QK7z&amp;index=7](https://www.youtube.com/watch?v=0PPzD4mxpuM&amp;list=PL8PYTP1V4I8D0UkqW2fEhgLrnlDW9QK7z&amp;index=7)\n\n&amp;#x200B;\n\n1st part: We calculate attention scores. For this Seq2Seq model we take each encoder state as query vector. We take each decoder state as key vector. We choose a attention score function and calculate attention.\n\n[https://imgur.com/a/HcameRc](https://imgur.com/a/HcameRc)\n\n&amp;#x200B;\n\n2nd part: Point I get confused. We treat the value vectors same as key vectors and we do a multiplication with the attention scores if I understood correctly.\n\n[https://imgur.com/a/S7lYDGl](https://imgur.com/a/S7lYDGl)\n\n&amp;#x200B;\n\nI understand different attention papers implement differently. **But if we're going to use the value vectors same as key vectors why do we need it in the first place?** \n\nI've been trying to understand this key, query, value triplet. Read papers, posts, implementations. The database analogies but I couldn't get the intuition behind. I would be appreciated to any insights.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11ybmdd/how_do_we_find_values_in_attention_or_do_we_need/","created":"2023-03-22","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":2}}
{"title":"Txtai RuntimeError: failed to import","description":"I made a semantic search engine using txtai and it has stopped working. So I\u2019m wondering if it is to do with package versions. Any advice would be brilliant\n\n[error and line where it failed](https://imgur.com/a/1ulj2KS)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11yf8be/txtai_runtimeerror_failed_to_import/","created":"2023-03-22","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":5}}
{"title":"Is there any value in continuing research on LSTM behavior?","description":"I've been doing research on the generalization capacity of LSTMs (e.g. stratifying training data based on different factors and seeing effects on performance) and although I've observed some interesting results, I can't help but just feel defeated at this point since now Transformers Are All We Need. My advisor has said that there is still value in LSTM research that might be of interest to the cognitive science community if we treat LSTMs as a cognitive model of language learning, but honestly the remarkable capacity of LLMs for humanlike language generation has me doubting even that. I want to believe there are reasons to keep going but it's been difficult to make a case for it, and it's hard for me to transfer the work I've been doing to transformers because with a large enough model we don't even observe these kinds of effects at all, or they just pattern with human behavior.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11xwk4p/is_there_any_value_in_continuing_research_on_lstm/","created":"2023-03-21","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":6}}
{"title":"CU Boulder or Brandeis for compling MS?","description":"I was admitted to both CU Boulder and Brandeis for their computational linguistics masters programs. I\u2019m leaning quite heavily toward CU for a few reasons, but just from an academic and professional standpoint, does anyone have any insight of which of those might be a more solid choice and program if all else were equal?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11y0wqq/cu_boulder_or_brandeis_for_compling_ms/","created":"2023-03-22","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":2}}
{"title":"Whisper Open AI: How to not include silences in the timestamps returned?","description":"Hello\n\n&amp;#x200B;\n\nI'm using Whisper, the timestamps includes the silence.\n\nWhen having a video with a speaker starting his speech at sec 10, I'm getting the first timestamp to be at sec 1. instead of sec 10.\n\nHere is my config:\n\nPOST/ v1/audio/transcriptions\n\nConfig\n\n\\`\\`\\`\n\n{\n\nmodel:\"whisper-1\"\n\nfile:\"...mp3\"\n\nresponse\\_format:\"srt\",\n\nprompt:\"Hello, welcome to my lecture\"\n\n}\n\n&amp;#x200B;\n\n\\`\\`\\`\n\n&amp;#x200B;\n\nOutput:\n\n\\`\\`\\`\n\n1\n\n00:00:01,000 --&gt; 00:00:14,000\n\nWhy are there both successful and struggling entrepreneurs?\n\n&amp;#x200B;\n\n2\n\n00:00:15,000 --&gt; 00:00:23,000\n\nMany customers prefer to watch videos to enjoy online content.\n\n&amp;#x200B;\n\n3\n\n00:00:24,000 --&gt; 00:00:32,000\n\nan other sentences.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n\\`\\`\\`\n\n&amp;#x200B;\n\n\\* I believe  \\`1\\` it should be \\`00:00:10,000 --&gt; 00:00:14,000\\`, since there is no one talking at all for 10 sec.\n\n\\* Also, the \\`3\\`, the speakers starts again talking at sec 28, but I'm getting the timestamp to be at sec 24. The silence is simply included in the timestamp with Whisper\n\n&amp;#x200B;\n\nAny idea how I could fix that, maybe using a prompt?\n\n&amp;#x200B;\n\nThanks!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11xdnvd/whisper_open_ai_how_to_not_include_silences_in/","created":"2023-03-21","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":3}}
{"title":"Is there any literature or courses on how to build datasets from scratch to train language models?","description":"Hi, everyone! I'm looking to get better at creating datasets to train/fine-tune different language models (mostly Transformers) for very specific tasks. I'm currently putting together a dataset from different social media sources and tagging it manually, and throughout the process my team and I had to make a lot of choices that were more guided by instinct than by theory.\n\nTherefore, I would be interested in any book/course that covers one or more of the following (or other relevant) topics for dataset creation:\n\n&amp;#x200B;\n\n\\- How to determine which data sources to use.\n\n\\- How to access the data I need (and automation if possible).\n\n\\- How to check for biases.\n\n\\- How to balance the dataset for different tasks.\n\n\\- Tagging techniques/tools.\n\n\\- Good practices/industry standards.\n\n\\- Any other topic you consider important or key for this task.\n\n&amp;#x200B;\n\nThanks in advance to all! Looking forward to reading from all of you.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11xhzq8/is_there_any_literature_or_courses_on_how_to/","created":"2023-03-21","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":0}}
{"title":"Are there any pretrained sentiment analysis models that grade sentiment along a gradient?","description":"I'm not sure if I've phrased my title correctly, but what I mean is, the majority of the models I've found tend towards the extremes. For example,\n\n&gt;You're an asshole\n\nmight be a -0.99 and\n\n&gt;Fuck you, I hope you fucking die you piece of shit\n\nis a -1, despite there being a significant difference in the intensity of the negative sentiment. Are there any pretrained models where the score that the model outputs doesn't just show the sentiment, but also the intensity of the sentiment?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11xlnrq/are_there_any_pretrained_sentiment_analysis/","created":"2023-03-21","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":3}}
