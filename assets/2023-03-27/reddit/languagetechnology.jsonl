{"title":"what are the best Arabic sources to learn NLP frrom the scrach ?","description":"","link":"https://www.reddit.com/r/LanguageTechnology/comments/123d8rv/what_are_the_best_arabic_sources_to_learn_nlp/","created":"2023-03-27","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":0}}
{"title":"Pre-trained Electra consistently producing Precision and Accuracy metrics of 0, does anyone have any suggestions on how to resolve?","description":"Hi all I'm back with more questions :)\n\nI  am currently doing my dissertation which is a binary multi-label  classification task for sarcasm subcategory detection. I have  implemented Electra as I want to assess the efficacy of this model for  this particular task. There is a set dataset provided for the task of  \\~4000 samples of training data and \\~1400 samples of testing data. F1  score is outlined as the prerequisite evaluation metric, so I have  implemented Precision and Accuracy as the metrics when fitting the  model. Each time I have trained the model, these metrics start at 0 and  do not increase, meaning that when I am trying to predict on the test  data, all predictions end up being 0 and thus my F1 score is  consistently 0.0.\n\nDoes anyone have any suggestions on how to resolve this?\n\nN.B.  - I am aware that the model is likely underfitting, and am looking into  data augmentation techniques or potentially fine tuning the model on a  general sarcasm detection dataset, then fine tuning it again for this  subtask, however the issue with the 6 labels in the dataset is that I  don't know how I would augment data whilst maintaining some semblance of  the dataset already outlined.\n\nN.B.  2 - I have attached a [photo](https://imgur.com/a/iq9h12i)of my existing model architecture, but am  unsure whether this is correct, as it doesn't seem like the input is  being fed to the actual Electra model or the architecture itself may be  too simple for the task.\n\nHappy to answer any questions to clarify anything that doesn't make sense :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/122jvu9/pretrained_electra_consistently_producing/","created":"2023-03-26","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":1}}
{"title":"Extracting large spans of text without a clear pattern","description":"I'm working on a project where I want to automatically detect and extract trauma narratives from a corpus of text (I will label it myself). I'm thinking of using NLP techniques to classify text as either containing a trauma narrative or not, and then extracting those narratives from the classified text to analyze them. I'm lost as to how to extract the narratives once they have been classified. The data is quiet noisy since there is lots of contextual information. Which tools could be used to approach this problem?","link":"https://www.reddit.com/r/LanguageTechnology/comments/122alia/extracting_large_spans_of_text_without_a_clear/","created":"2023-03-26","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":2}}
{"title":"[Beginner advice] Plaintext layout segmentation","description":"Hey, hey! I'm hoping to do some layout segmentation for legal text, with no experience in NLP (I'd dare say I'm fairly confident working with ML methods generally). A big problem in my dataset is that whilst the text is often somewhat structured, it varies A LOT between different documents.\n\nHere's an example:\n\n&gt;     Neutral Citation Number: [2023] EWCA Crim 316 Case No: 202200988 B1 IN THE COURT OF APPEAL (CRIMINAL DIVISION)\n&gt; \n&gt;     ON APPEAL FROM THE CROWN COURT AT CANTERBURY\n&gt; \n&gt;     HIS HONOUR JUDGE JAMES\n&gt; \n&gt;     T20117349\n&gt; \n&gt;     Royal Courts of Justice\n&gt; \n&gt;     Strand, London, WC2A 2LL Date: 24 March 2023\n&gt; \n&gt;     Before:\n&gt; \n&gt;     LORD JUSTICE STUART-SMITH\n&gt; \n&gt;     MRS JUSTICE LAMBERT and\n&gt; \n&gt;     SIR NIGEL DAVIS\n&gt; \n&gt;     Between:\n&gt; \n&gt;     REX\n&gt; \n&gt;     Respondent\n&gt; \n&gt;     and\n&gt; \n&gt;     PHILIP ROE\n&gt; \n&gt;     Applicant\n&gt; \n&gt;     Mark Summers KC and Rachel Darby (instructed by Lound Mulrenan Jefferies Solicitors) for the Applicant\n&gt; \n&gt;     Edmund Burge KC (instructed by CPS Appeals and Review Unit) for the Respondent\n&gt; \n&gt;     Hearing date: 21 February 2023\n&gt; \n&gt;     Approved Judgment\n&gt; \n&gt;     This judgment was handed down remotely at 10.30am on 24 March 2023 by circulation to the parties or their representatives by e-mail and by release to the National Archives.\n&gt; \n&gt;     .............................\n&gt; \n&gt;     Lord Justice Stuart-Smith:\n&gt; \n&gt;     Introduction\n&gt; \n&gt;     1.\n&gt; \n&gt;     On 11 December 2013 in the Crown Court at Canterbury the Applicant was convicted after a re-trial on an indictment containing six counts of the offences we detail below. On 12 December 2013 he was sentenced by the trial judge, His Honour Judge James, as follows:\n&gt; \n&gt;     i)\n&gt; \n&gt;     On Counts 1 and 2, which were offences of being knowingly concerned in a fraudulent evasion of the prohibition on the importation of goods (namely class A drugs) contrary to Section 170(2)(b) of the Customs and Excise Management Act 1979, he was sentenced to 13 years imprisonment concurrent;\n&gt; \n&gt;     ii)\n&gt; \n&gt;     On Counts 3 and 4, which were offences of being knowingly concerned in a fraudulent evasion of the prohibition on the importation of goods (namely class B drugs) contrary to Section 170(2)(b) of the Customs and Excise Management Act 1979, he was sentenced to 3 years (count 3) and 4 years (count 4) imprisonment concurrent;\n&gt; \n&gt;     iii)\n&gt; \n&gt;     On Count 5, which was an offence of possessing a prohibited firearm contrary to section 5(1)(aba) of the Firearms Act 1968, he was sentenced to 5 years imprisonment consecutive; and\n&gt; \n&gt;     iv)\n&gt; \n&gt;     On Count 6, which was an offence of possessing ammunition without a firearm authority contrary to section 1(1)(b) of the Firearms Act 1968, he was sentenced to 1 year imprisonment, concurrent.\n&gt; \n&gt;     The total sentence was therefore one of 18 years imprisonment.\n&gt; \n&gt;     2. The Applicant now applies for permission to appeal against his conviction some 3003 days out of time. His application was referred to the full Court by the Single Judge.\n&gt; \n&gt;     [...]\n&gt; \nI want to segment out the header (i.e. the text until \"Lord Justice Stuart-Smith / Introduction\"), any section titles, the individual paragraphs (potentially including subparagraphs), and any eventual footnotes. Unfortunately, all of these things are too variable between documents for regex approaches to work well. I have about 4000 documents I need to segment.\n\nI could generate a sample dataset for training on these classes relatively easily, but I am an NLP beginner, and know quite little about what the best methodologies / networks / pre-trained nets for this type of problem would be! I've tried looking around, but most available tools seem to be image (e.g. PDF) focused, and not tailored for this kind of document (one such example is layoutlmv3).\n\nCould someone please point me in the right direction regarding state-of-the-art methods and reasonable approaches to this type of problem?","link":"https://www.reddit.com/r/LanguageTechnology/comments/1220le7/beginner_advice_plaintext_layout_segmentation/","created":"2023-03-25","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":2}}
{"title":"Should I specialize in NLP considering the advent of Large Language Models?","description":"I am feeling that most of cutting edge research work is being done in a handful of companies. In that case, how does the future look like  say 5 years down the line for somebody specialising in research in NLP? Seems like models like ChatGPT can do many of NLP tasks and are so ahead of the curve that it will ne difficult to beat them. How do job prospects look like in NLP?","link":"https://www.reddit.com/r/LanguageTechnology/comments/121gv4c/should_i_specialize_in_nlp_considering_the_advent/","created":"2023-03-25","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":9}}
{"title":"What algo to use to check if student answer is correct?","description":"Hi there,\n\nQuestions for the experts here: I'm trying to programmatically grade open-text questions from Google Form quizes. For example: the question is \"Which country in Africa is the largest by area\". As a teacher, I have the answer: \"Algeria is the largest country in Africa by area\".\n\nI want to compare my student's answers to the correct answer in order to know whether they are right or wrong. **Which algo should I use?**\n\nI was playing a bit with string similarity, but I got ridiculous results, because \"***Egypt*** is the largest country in Africa\" is pretty close the the right answer, except that it's completely wrong. \n\nWhat do you think?","link":"https://www.reddit.com/r/LanguageTechnology/comments/121zjrv/what_algo_to_use_to_check_if_student_answer_is/","created":"2023-03-25","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":5}}
{"title":"Spacy dependency parsing visualizer","description":"When using Spacy I noticed that it was quite difficult sometimes to know what the various POS tags, dependency labels, and morphological features actually *mean*. Especially difficult since the different models (e.g. en\\_core\\_web\\_sm) often use different labelling schema.\n\nI built this to help people get a feel for Spacy dependency parsing. Each POS tag, dependency label and morphological feature links to the relevant documentation to find out more about their meanings.\n\nIt features a fully parsed version of George Orwell's \"Politics and the English Language\", with parallel texts in both English and Spanish.\n\n&amp;#x200B;\n\nLink: [https://www.getcorrecto.com/nlp/en/0/0](https://www.getcorrecto.com/nlp/en/0/0)","link":"https://www.reddit.com/r/LanguageTechnology/comments/121lavk/spacy_dependency_parsing_visualizer/","created":"2023-03-25","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":9}}
{"title":"Starting a career in Speech AI","description":"I will soon graduate from a master\u2019s in compling and I was very lucky to find a job in a good company that is relatively new to language technology. In such a position, I don\u2019t really have any senior people to ask for advice when it comes to tackling problems, and this leaves me very lost in my day to day work. \n\nIs this common when starting a career in the field? How can I find mentors and guidance outside of my immediate environment?","link":"https://www.reddit.com/r/LanguageTechnology/comments/1221oc9/starting_a_career_in_speech_ai/","created":"2023-03-25","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":0}}
{"title":"Deploy a huggingface classification model","description":"I want to classify around 50k tweets with a BERT classification model which I found on huggingface. What is the fastest way to do this? I am pretty sure the hugging face API is rate limited. Do I need to pay for an Interference endpoint? Is this worth it?","link":"https://www.reddit.com/r/LanguageTechnology/comments/121lrt2/deploy_a_huggingface_classification_model/","created":"2023-03-25","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":0}}
{"title":"Can I train Stanford Alpaca on style + tone?","description":"I've been learning about the breakthrough with [Stanford Alpaca](https://www.youtube.com/watch?v=xslW5sQOkC8) and understand we can create our own models for less than $600. What I am trying to better understand is how specifically can we train these models? How important are the training datasets and if the training datasets were, for example, very much in a style (the style of Vladimir Nabokov, or Youtube comment style) would those stylistic touches be reflected in the model?","link":"https://www.reddit.com/r/LanguageTechnology/comments/1215q2q/can_i_train_stanford_alpaca_on_style_tone/","created":"2023-03-25","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":2}}
{"title":"Positive and Negative Sampling Strategies for Representation Learning in Semantic Search","description":"I have been looking into strategies for effectively training a dual encoder (the \"two tower\" model) to learn representations. I came across a set of papers that described various sampling methods (supervised/self-supervised/unsupervised) to create positive and negative pairs to be fed to the model for training.\n\n&amp;#x200B;\n\nTL;DR on what I learned:\n\n\u2022 Using in-batch negatives and/or cross-batch negatives helps in reducing the training and inference discrepancies in retrieval and ranking applications.  \n\u2022 For training, using both easy negative and hard negative examples, and using more easy examples than hard ones could lead to the best results. \n\n&amp;#x200B;\n\nI compiled the references and summarized them here: [https://blog.reachsumit.com/posts/2023/03/pairing-for-representation/](https://blog.reachsumit.com/posts/2023/03/pairing-for-representation/)","link":"https://www.reddit.com/r/LanguageTechnology/comments/1214nrb/positive_and_negative_sampling_strategies_for/","created":"2023-03-25","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":2}}
