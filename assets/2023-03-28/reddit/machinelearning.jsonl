{"title":"[D] Simple Questions Thread","description":"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!","link":"https://www.reddit.com/r/MachineLearning/comments/122oxap/d_simple_questions_thread/","created":"2023-03-26","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":31}}
{"title":"[N] OpenAI may have benchmarked GPT-4\u2019s coding ability on it\u2019s own training data","description":"[GPT-4 and professional benchmarks: the wrong answer to the wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks)\n\n*OpenAI may have tested on the training data. Besides, human benchmarks are meaningless for bots.*\n\n **Problem 1: training data contamination**\n\nTo benchmark GPT-4\u2019s coding ability, OpenAI evaluated it on problems from Codeforces, a website that hosts coding competitions. Surprisingly, Horace He pointed out that GPT-4 solved 10/10 pre-2021 problems and 0/10 recent problems in the easy category. The training data cutoff for GPT-4 is September 2021. This strongly suggests that the model is able to memorize solutions from its training set \u2014 or at least partly memorize them, enough that it can fill in what it can\u2019t recall.\n\nAs further evidence for this hypothesis, we tested it on Codeforces problems from different times in 2021. We found that it could regularly solve problems in the easy category before September 5, but none of the problems after September 12.\n\nIn fact, we can definitively show that it has memorized problems in its training set: when prompted with the title of a Codeforces problem, GPT-4 includes a link to the exact contest where the problem appears (and the round number is almost correct: it is off by one). Note that GPT-4 cannot access the Internet, so memorization is the only explanation.","link":"https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/","created":"2023-03-28","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":22}}
{"title":"[D] FOMO on the rapid pace of LLMs","description":"Hi all, \n\nI recently read [this reddit post](https://www.reddit.com/r/blender/comments/121lhfq/i_lost_everything_that_made_me_love_my_job/) about a 2D modeler experiencing an existential crisis about their job being disrupted by midjourney ([HN discussion here](https://news.ycombinator.com/item?id=35319861)). I can't help but feel the same as someone who has been working in the applied ML space for the past few years. \n\nDespite my background in \"classical\" ML, I'm feeling some anxiety about the rapid pace of LLM development and face a fear of missing out / being left behind.\n\nI'd love to get involved again in ML research apart from my day job, but one of the biggest obstacles is the fact that training most of foundational LLM research requires huge compute more than anything else \\[1\\]. I understand that there are some directions in distributing compute ([https://petals.ml](https://petals.ml/)), or distilling existing models  ([https://arxiv.org/abs/2106.09685](https://arxiv.org/abs/2106.09685)). \n\nI thought I might not be the only one being humbled by the recent advances in ChatGPT, etc. and wanted to hear how other people feel / are getting involved. \n\n\\--\n\n\\[1\\] I can't help but be reminded of Sutton's description of the [\"bitter lesson\" of modern AI research](https://www.incompleteideas.net/IncIdeas/BitterLesson.html): \"breakthrough progress eventually arrives by an opposing approach based on scaling computation... eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach.\"","link":"https://www.reddit.com/r/MachineLearning/comments/1244q71/d_fomo_on_the_rapid_pace_of_llms/","created":"2023-03-27","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":56}}
{"title":"[P] two copies of gpt-3.5 (one playing as the oracle, and another as the guesser) performs poorly on the game of 20 Questions (68/1823).","description":"I put two copies of gpt-3.5 as partners, one plays the role of the oracle that answers yes/no questions, the other as the role of a guesser that asks yes/no questions. I want to see if gpt-3.5 would perform well on this \"dynamic\" task -- i.e. rather than a fixed test set with 1 good answer, 20 questions can be played into many paths, depending on the questions being asked.\n\nthe result is poor 68 / 1823\n\n&amp;#x200B;\n\n&gt;20 Questions forces the guesser to be cohesive in a long chain of yes / no predicates. You want an ***actually*** **difficult and consistent world model**? This is a good one that is combinatorially complex.  \n...  \n20 Questions (and other interactive, self-play tasks) is worth looking at in evaluating LLMs.\n\nfor more details see blog post: [https://evanthebouncy.medium.com/llm-self-play-on-20-questions-dee7a8c63377](https://evanthebouncy.medium.com/llm-self-play-on-20-questions-dee7a8c63377) \n\n&amp;#x200B;\n\nI'd be happy to answer some questions here as well\n\n\\--evan","link":"https://www.reddit.com/r/MachineLearning/comments/12435uq/p_two_copies_of_gpt35_one_playing_as_the_oracle/","created":"2023-03-27","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":13}}
{"title":"[P] Consistency: Diffusion in a Single Forward Pass \ud83d\ude80","description":"Hey all!\n\nRecently, researchers from OpenAI proposed  [consistency models](https://arxiv.org/abs/2303.01469), a new family of generative models. It allows us to generate high quality images in a *single forward pass*, just like good-old GANs and VAEs.\n\nI have been working on it and found it definetly works!\n\n&amp;#x200B;\n\n[training progress on cifar10](https://i.redd.it/6iimqzj4bgqa1.gif)\n\n&amp;#x200B;\n\nYou can try it with `diffusers`.\n\n    import diffusers\n    \n    from diffusers import DiffusionPipeline\n    \n    pipeline = DiffusionPipeline.from_pretrained(\n        \"consistency/cifar10-32-demo\",\n        custom_pipeline=\"consistency/pipeline\",\n    )\n    \n    pipeline(steps=1).images[0]  # Super Fast Generation! \ud83e\udd2f\n    pipeline(steps=5).images[0]  # Trade-off compute for sample quality \n\n&amp;#x200B;\n\nI think it would be really interesting if we could train this models on other datasets and share our checkpoints! \ud83e\udd17 So, I've made a simple library called `consistency` that makes it easy for you to train your own consistency models. You can check it out here:\n\n[https://github.com/junhsss/consistency-models](https://github.com/junhsss/consistency-models)\n\nI believe it can be more powerful if integrated with the whole 'latent diffusion' scheme. Really excited about this new direction!","link":"https://www.reddit.com/r/MachineLearning/comments/124jfoa/p_consistency_diffusion_in_a_single_forward_pass/","created":"2023-03-28","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"Approaches to add logical reasoning into LLMs [D]","description":"The more I play with GPT-4 the more I am struck by how completely illogical it is. \n \nThe easiest way to show this is to ask it to come up with a novel riddle and then solve it. Because you asked it to be novel, it's now out of it's training distribution and almost every time it's solution is completely wrong and full of basic logical errors.\n\nI am curious, is anyone working on fixing this at a fundamental level? Hooking it into Wolfram alpha is a useful step but surely it still needs to be intrinsically logical in order to use this tool effectively.","link":"https://www.reddit.com/r/MachineLearning/comments/123nczy/approaches_to_add_logical_reasoning_into_llms_d/","created":"2023-03-27","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":73}}
{"title":"[P] ChatGPT Survey: Performance on NLP datasets","description":"I've done a survey of how well ChatGPT performs on various NLP tasks as reported in arXiv papers. I have found 19 papers where they compared ChatGPT with fine-tuned models, but they are being published practically daily now. It seems that for the most of the classical NLP tasks, ChatGPT is not actually that strong and smaller fine-tuned models are often much better. According to the API page, GPT-4 is not expected to be much stronger on tasks like these. I think it is an interesting perspective that shows that for many of the tasks we need to solve, GPT models are actually not the right tool.\n\nThe full survey is in my blog post: [http://opensamizdat.com/posts/chatgpt\\_survey/](http://opensamizdat.com/posts/chatgpt_survey/)\n\nAny feedback is welcomed.","link":"https://www.reddit.com/r/MachineLearning/comments/124frc3/p_chatgpt_survey_performance_on_nlp_datasets/","created":"2023-03-28","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":2}}
{"title":"[D] Small language model suitable for personal-scale pre-training research?","description":"SOTA LLMs are getting too big, and not even available.  For individual researchers who want to try different pre-training strategies/architecture and potentially publish meaningful research, what would be the best way to proceed?  Any smaller model suitable for this? (and yet that people would take the result seriously.)","link":"https://www.reddit.com/r/MachineLearning/comments/124er9o/d_small_language_model_suitable_for_personalscale/","created":"2023-03-28","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4}}
{"title":"Future of AI/ML Skills/Methodologies and Applications [D]","description":"What does everyone think will be some of the most sought after applications of Al/ML and skills in the future?\n\nSkills like Natural Language Processing, Deep Learning, Reinforcement Learning, Neural Nets, etc.?\n\nApplications like Healthcare, Large Language Models, Generative Al, Al for Cybersecutiry, Computer Vision?\n\nDiscuss.","link":"https://www.reddit.com/r/MachineLearning/comments/124hxal/future_of_aiml_skillsmethodologies_and/","created":"2023-03-28","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[P] \ud83c\udf89 Announcing Auto-Analyst: An open-source AI tool for data analytics! \ud83c\udf89","description":"  \n\n\nAuto-Analyst leverages power of cutting-edge Large Language Models (LLMs) to revolutionize data analytics. This powerful UI tool simplifies the data analysis process, eliminating the need for complex coding.  \n\n\n\ud83d\udd0e Key Features of Auto-Analyst:  \n\n\n1. Streamlined data analysis process utilizing advanced AI technology and LLMs  \n2. Enhanced productivity and efficiency through intuitive language-based commands  \n3. Increased accessibility to data analysis for professionals across industries  \n\n\n\ud83d\udd17 Want to explore and contribute to the project? Head over to the GitHub repo: [https://github.com/aadityaubhat/auto-analyst](https://github.com/aadityaubhat/auto-analyst)","link":"https://www.reddit.com/r/MachineLearning/comments/123w6sv/p_announcing_autoanalyst_an_opensource_ai_tool/","created":"2023-03-27","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":8}}
{"title":"[PROJECT] Built a new tool using NER to extract data from ANY documents","description":"Hey guys, I have been working on a tool (for over a couple of months now) that will help extract ANY data you want from ANY documents. Like for example, You want to extract financial data from receipts or medical info from medical docs.\n\nWe use the CRF algorithm and NER techniques.\n\nThe tool also makes labeling your documents soo much more easier because the model does most of the labeling for you (Check out the video).\n\nLet me know if you would like to discuss more. It's free to use as well.\n\nDemo Video - [https://youtu.be/uzANQZL2bA0](https://youtu.be/uzANQZL2bA0)\n\nhttps://preview.redd.it/3v35cwo6vfqa1.png?width=1912&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f23db8bd5cb456e2b7e1afa92e9f564d1239a3c1","link":"https://www.reddit.com/r/MachineLearning/comments/124hlea/project_built_a_new_tool_using_ner_to_extract/","created":"2023-03-28","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[D] Instruct Datasets for Commercial Use","description":"I love seeing all this great progress with LLMs being made more accessible to all, but all of the new efficient models (Dolly, Alpaca, etc.) depend on the Alpaca dataset, which was generated from a GPT3 davinci model, and is subject to non-commercial use. Are there efforts in the community to replicate this dataset for commercial use? This seems to me to be the \u201csecret sauce\u201d: a good quality instruction dataset you can use to \u201cunlock\u201d potential of smaller models.","link":"https://www.reddit.com/r/MachineLearning/comments/123oovw/d_instruct_datasets_for_commercial_use/","created":"2023-03-27","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":24}}
{"title":"[D] ICML2023 Review Experience Thread","description":"Now that the author-reviewer discussion period for ICML 2023 has ended, it seems like it is up to the meta reviewers to decide.\n\nLet us discuss our experiences with the revised process. The general consensus I have seen online is that there were more low quality / absent reviewers than usual, but it is unknown how common it was. \n\nFor authors, how were your reviews, and how was the author-reviewer period? Did your scores change? Was anything off about your review?\n\nI\u2019ll start: \n\nI got one terrible score and one borderline score. The terrible score reviewer made basic factual errors in their criticism. No follow up after rebuttal. Also note we were unable to get a third reviewer.","link":"https://www.reddit.com/r/MachineLearning/comments/123wjtv/d_icml2023_review_experience_thread/","created":"2023-03-27","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":10}}
{"title":"[R] Feature Clustering: A Simple Solution to Many Machine Learning Problems","description":"This sounds like an interesting alternative to PCA for dimensionality reduction.\n\nhttps://mltechniques.com/2023/03/12/feature-clustering-a-simple-solution-to-many-machine-learning-problems/","link":"https://www.reddit.com/r/MachineLearning/comments/124fjts/r_feature_clustering_a_simple_solution_to_many/","created":"2023-03-28","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[R] What is the state of the art for Logos Image Retrieval?","description":"I have a directories with a lot of different logos for each brand... given a query logo I would like to Retrieval the most similars, in order to correct classify the brand. What is the state of the art?","link":"https://www.reddit.com/r/MachineLearning/comments/124jq9i/r_what_is_the_state_of_the_art_for_logos_image/","created":"2023-03-28","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[N] Predicting Finger Movement and Pressure with Machine Learning and Open Hardware Bracelet","description":" We are excited to share our latest findings in predicting finger movement and pressure using machine learning. The results show that our model is capable of predicting the finger movement within a Mean Absolute Error (MAE) of 25, which is a sufficient level of accuracy for detecting both the finger movement and the pressure applied.   \n\n\n[Predicted vs Actual](https://preview.redd.it/1i4t6dhkzaqa1.png?width=1018&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d035bb410f88e39ab017b73d89147c569e744588)\n\nThe system is comprised of a bracelet and label system that captures the data to feed into an artificial neural network.\n\n&amp;#x200B;\n\n[Bracelet in the background with the LASK label system in the foreground.](https://preview.redd.it/halqon9qzaqa1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=785855adc7e7ad79c7f554376a8aa994ea0e85b9)\n\n \n\nThese screenshots showcase a portion of the data file available for download, which contains the actual and predicted finger movement and pressure values. Our model not only indicates that a finger is moving but also estimates the amount of pressure being applied, providing valuable insights into the intricacies of finger movements.\n\nThis achievement opens up new possibilities for applications that require precise finger movement and pressure detection, such as in rehabilitation therapy, robotics, and gesture-based user interfaces.\n\nWe invite you to download the full data file and explore the results in more detail. As we continue to refine our model and improve its accuracy, we look forward to discovering new ways to utilize this technology for the betterment of various fields and industries.\n\n&amp;#x200B;\n\n All data to train the model and code available on our Github: [https://github.com/turfptax/openmuscle](https://github.com/turfptax/openmuscle)   \n\n\n[https://www.youtube.com/watch?v=ZC1migPdiRk](https://www.youtube.com/watch?v=ZC1migPdiRk)  \n\n\n&amp;#x200B;\n\n[Open Muscle Bracelet.](https://preview.redd.it/p9kitphzzaqa1.jpg?width=4032&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=7e5008302643199e814e1288865e9cd3aa49ade8)","link":"https://www.reddit.com/r/MachineLearning/comments/123r591/n_predicting_finger_movement_and_pressure_with/","created":"2023-03-27","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":3}}
{"title":"[P] Clustering face embeddings (512d) using GCN's (not knowing the amount of needed clusters)","description":"Hi, I have used the InsightFace model to detect a bunch of faces in images. It returns face embeddings of 512d. I don't have reference data for the persons on these images, neither do I know how many different identities appear on them. I would love to cluster the face embeddings as good as possible. So far I have tried dbscan and hierarchical clustering, both showing decent results when I manually evaluate the clusters (after playing around with the hyperparams).\n\n&amp;#x200B;\n\nNow I have been reading about how using GCN's (graph convolutional networks) could lead to better clustering results. Problem is I don't know how to do this. I learned that the nodes in the graph would represent the face embeddings, and that an edge between 2 nodes would imply that 2 embeddings correspond to the face of the same identity. I also learned (by searching online and asking ChatGPT) that you would first need to feed the GCN a thresholded similarity matrix (adjacency matrix), build the GCN model and train it, and eventually cluster the resulting node embeddings using dbscan or spectral clustering or some other clustering algorithm. I don't know to which extent this information is correct.\n\n&amp;#x200B;\n\nCould somebody with knowledge about GCN's give me some tips on how to work out the code necessary to achieve this?","link":"https://www.reddit.com/r/MachineLearning/comments/124iv13/p_clustering_face_embeddings_512d_using_gcns_not/","created":"2023-03-28","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[R] Looking for a book","description":"I would really appreciate it, if anyone could send me the pdf version of this book: Deep Learning, by Aaron Courville, Ian Goodfellow, and Yoshua Bengio","link":"https://www.reddit.com/r/MachineLearning/comments/124g0xw/r_looking_for_a_book/","created":"2023-03-28","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":2}}
{"title":"[D] Can DeepL learn from edits to the translations it produces immediately?","description":"I made an amendment to text and it appeared to modify the next text I entered in precisely the same way.\n\nFor example,\n\nTranslation 1\nSpanish text: Ley sobre el uso de sombreros rosas, 1986 \n\nDeepL\u2019s initial translation: The Law on wearing Pink Hats, 1986\n\nMy edit: The Spanish Law on wearing Pink Hats, 1986\n\nTranslation 2 \n\nSpanish text: La Ley sobre el uso de pantalones cortos amarillos, 1987\n\nDeepL\u2019s initial translation: The Spanish Law on wearing yellow shorts, 1987\n\nThere was no need for me to make any edit.\n\n\ud83d\ude33\n\nDid it learn my preferences from my edit \u2026immediately ?","link":"https://www.reddit.com/r/MachineLearning/comments/1248fka/d_can_deepl_learn_from_edits_to_the_translations/","created":"2023-03-28","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4}}
{"title":"Creating Dynamically Contextualized Modular AGI Environments in Lower-Dimensional Space [P], [R]","description":"**This white paper is still being edited. I came up with this back on 3/19, and then the bombshell GPT-4 paper hit, and basically blew me out of the water. I still think I have some improvements and specificity that they didnt cover, in regards to the creation of Identity and benefits of multi-model friction to create better performanc. I will also be releasing my notes on something I call \u201cModal-ID\u2019s\u201d which were basically plugins until OpenAI released plugins immediately after I came up with this! Haha. Hope you enjoy!**\n\n**Recombinant AI:**\n\nCreating Dynamically Contextualized Modular AGI Environments in Lower-Dimensional Space\n\n## Abstract\n\nIn this paper, I introduce Recombinant AI. By leveraging pre-trained language models, such as GPT-4, a recombinant contextual learning loop, and efficient indexing techniques like Hierarchical Navigable Small World (HNSW) Graphs, we are able to generate AI modules that when sufficiently robust, will inherently (with human input and direction) begin to function as distinct entities with their own knowledge, conversational history, and personality guidelines.\n\nThe proposed framework allows for the creation of powerful and interactive AI applications, with the potential to enhance user experiences across various domains, including, but not limited to:\n\n* Interactive storytelling\n* customer support\n* personalized AI assistants.\n* Instantly customizable solutions\n\nIn this context, I discuss the underlying principles, implementation details, and potential applications of Recombinant AI, drawing comparisons to existing methodologies, and highlighting unique solutions, challenges, and opportunities. Additionally, I will explore the impact of real-time adaptation and indexing, combined with a recombination flow, allowing AI modules to learn immediately from user interactions and commit these lessons to improve their performance over time. By integrating state-of-the-art language models with advanced indexing and retrieval techniques, Recombinant AI represents a promising new direction in the pursuit of dynamic and versatile AGI systems.It\u2019s important for me to note that this methodology is not meant to supplant fine-tuning of an LLM. In fact, I believe this framework not only augments current fine-tuning strategies, but is itself strengthened by the utilization of fine-tuned external LLMs. However, I do believe that this presents the potential for a more flexible, dynamic, and accessible approach to model customization and improvement by an order of magnitude.\n\nMy approach to this involves 3 main components.\n\n1. Introduction\n\nRecombinant AI builds upon existing systems, but aims to revolutionize the development of artificial general intelligence (AGI) systems by harnessing the power of pre-trained language models and lower dimensional indexing techniques. With the advent of increasingly sophisticated language models like GPT-4, the potential to create dynamic and modular AGI environments has never been more promising. In this section, we provide an overview of the key ideas behind Recombinant AI, illustrating its unique features, advantages, and potential applications.\n\nThe primary goal of Recombinant AI is to create distinct AI modules, each with its own knowledge base, conversational history, and personality guidelines. These modules can be seen as AGI \"game cartridges\" that can be loaded and interacted with on-demand, allowing users to engage with highly customizable AI applications that cater to specific needs and preferences.\n\nTo achieve this, Recombinant AI relies on two main components: pre-trained language models and efficient lower dimensional indexing techniques, such as Hierarchical Navigable Small World (HNSW). By combining these components, we can create highly scalable and adaptable AI modules that learn and evolve through user interactions.\n\n\\[CONTENT HERE: An illustration demonstrating the interaction between pre-trained language models, lower dimensional indexing, and AI modules in the Recombinant AI framework.\\]\n\nIn the following sections, we delve deeper into the methodology, implementation details, and potential applications of Recombinant AI, exploring the unique challenges and opportunities it presents. We also discuss how the framework can adapt in real-time, allowing AI modules to learn from user inputs and improve their performance over time.\n\nThrough its innovative approach to AGI development, Recombinant AI has the potential to transform a wide range of industries, from interactive storytelling and customer support to personalized AI assistants and AI-driven gaming. By offering dynamic, modular, and scalable solutions, Recombinant AI paves the way for a new era of interactive and versatile AI applications.\n\n1. Methodology and Implementation\n\nIn this section, we delve into the methodology and implementation details of Recombinant AI, providing an in-depth explanation of the key components, processes, and techniques involved in creating dynamic and modular AGI environments. We will discuss the role of pre-trained language models, lower dimensional indexing techniques, and prompt chaining strategies, as well as provide code examples and tables to illustrate the practical application of the framework.\n\n2.1 Pre-trained Language Models\n\nRecombinant AI leverages the power of pre-trained language models like GPT-4 to generate context-aware embeddings and responses. These models have been trained on vast amounts of text data, making them capable of generating coherent and contextually relevant text based on user inputs.\n\n\\[CONTENT HERE: A table comparing different pre-trained language models, such as GPT-4, BERT, and RoBERTa, highlighting their key features, performance metrics, and suitability for various applications.\\]\n\n2.2 Lower Dimensional Indexing Techniques\n\nEfficient lower dimensional indexing techniques, such as Hierarchical Navigable Small World (HNSW) Graphs, Sparse Priming, and Clustering, play a crucial role in Recombinant AI. These techniques enable the framework to efficiently store, retrieve, and update AI module knowledge bases, conversational histories, and personality guidelines.\n\nHNSW is a graph-based indexing technique that allows for fast and accurate nearest neighbor searches in high-dimensional spaces. It is particularly well-suited for Recombinant AI due to its scalability and adaptability.\n\nAdd definitions\n\n\\[CONTENT HERE: A diagram illustrating the structure and search process of an HNSW index, showing the hierarchical organization of nodes and the process of traversing the graph to find the nearest neighbors.\\]\n\n2.3 Prompt Chaining Strategies\n\nPrompt engineering and chaining enables the framework to systematically and consistently process simple input prompts into complex, reasoned outputs. The process involves crafting a programmatic data flow through inputs, catalyst indices or code, into desired outcomes that guide the language model through a specific line of reasoning or inquiry, resulting in a coherent and context-aware response.\n\n\\[CONTENT HERE: An example of a prompt chain for a Dungeon Master AI module, illustrating the process of guiding the language model through a series of prompts to generate a coherent and contextually relevant response.\n\n* Backend system prompt from the initial user message spins up the Dungeon Master RAI.\n* Base index of the user\u2019s conversational history, as well as the appropriate system role index are analyzed by the LLM\u2026.\n\n2.4 Code Examples and Implementation Details\n\nTo better illustrate the practical application of Recombinant AI, we provide code examples that demonstrate the process of creating and interacting with AI modules.\n\n\\[CONTENT HERE: A code snippet showing the implementation of an HNSW index, embedding generation using GPT-4, and the process of querying the index based on user input.\\]\n\n\\[CONTENT HERE: A code snippet demonstrating the implementation of prompt chaining strategies to generate contextually relevant responses from the language model based on user input and module context.\\]\n\nBy combining these components and techniques, Recombinant AI creates a dynamic, modular, and scalable framework for AGI development, enabling the creation of highly customizable AI applications that adapt and learn through user interactions. In the next section, we explore the potential applications and use cases of Recombinant AI, as well as discuss the challenges and opportunities it presents.","link":"https://www.reddit.com/r/MachineLearning/comments/123slpu/creating_dynamically_contextualized_modular_agi/","created":"2023-03-27","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[D] Can we train a decompiler?","description":"Looking at how GPT can work with source code mixed with language, I am thinking that similar techniques could perhaps be used to construct a decent decomplier. Consider a language like C. There are plenty of open sources which could be compiled. Then you can use the dataset consisting of (source code, compiled code) pairs to train a generative model to learn the inverse operation from data. Ofc, the model would need to fill in the information lost during compilation (variable names etc) in a human-understandable way, but looking at the recent language models and how they work with source codes, this now seems rather doable. Is anyone working on this already? I would consider such an application to be extremely beneficial.","link":"https://www.reddit.com/r/MachineLearning/comments/123asbg/d_can_we_train_a_decompiler/","created":"2023-03-27","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":32}}
{"title":"[D] 3d model generation","description":"[D] Hello, everyone. I watched an explanation on the use of diffusion models for creation of 2d images.\n\nI just wonder, I think we are somewhat far away from 3d model generation. First, I think it would be much more computationally expensive. Second, I am not sure whether we have such a large set of training data. And third, the input and output that we have in 3d graphics is somewhat different from pixels, i.e. we are working with triangles in 3d graphics (maybe this is not as hard, as we can always start with vertices and then estimate triangles.\n\nWhat's your take on that?","link":"https://www.reddit.com/r/MachineLearning/comments/123xa6r/d_3d_model_generation/","created":"2023-03-27","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4}}
{"title":"[P] Graph mining/exploration for subpath identification based on edge values","description":"**Problem statement:** I have a sparse directed graph (about 6000-10000 nodes) with no node attributes, and numerical edge values. (The edge values are calculated by the same program based on data regarding the nodes, based on a statistical formula, if it's important)\n\n**Goal:** I want to find paths within the graph that have significantly higher edge values than the rest of the paths' edges (edge values are relative).\n\nI thought about graph clustering and partitioning but don't care about how highly connected a particular node is, and from my (elementary) understanding, these methods are not really well-suited for paths.\n\nI thought about doing a variation of iterative deepening search that starts on every node that has 0 incoming edges (and terminates when the last explored node has a small number of outgoing edges with small edge values), but these first edges that the search encounters may have smaller values than edges further down the paths, so if I use a traditional search algorithm, it would have to recursively update the start node for some iterations to reach the goal state, which is a path with all edges having edge values larger than other paths in the graph. As an extension, perhaps node characteristics (such as number of outgoing edges and their edge values) could be used as a heuristic?  Also, the whole graph needs to be explored, and edge values are relative to each other so the comparison between different paths has to be relative. Is anyone aware of a search method like this, or another method that may be suitable?","link":"https://www.reddit.com/r/MachineLearning/comments/123sq7w/p_graph_miningexploration_for_subpath/","created":"2023-03-27","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":5}}
{"title":"[D] Debugging mean collapse/suboptimal learning in deep regression models","description":"I don't know if r/learnmachinelearning is a better fit for this, but I thought I'd raise a discussion here as well. \n\nI'm doing some research on depth images, and my models keep collapsing to a suboptimal value. Shallower networks converge to a model that predicts a nearly constant prediction (not necessarily the mean) regardless of the input data. Deeper networks will overfit after reaching this stage. No matter what architecture I use, my validation performance never gets better than the constant prediction. \n\nOn the data - my inputs are (x,y,z) coordinates of 17 points sampled from a depth image from two different perspectives. I am attempting to predict 45 values from these coordinates (each normalized be bounded from 0 to 1).  I'm effectively using Openpose to downsample an image and predict some parameters from it. My dataset is 3000 samples and I'm using the regular 80-20 train-test split. \n\nThis data is synthetically generated and takes a long time to create (\\~24 hrs for 3k samples), so I want to make sure I don't have any fundamental issues before committing more time to generate more samples. \n\nThings I've tried that haven't worked - network depth (deeper networks can at least overfit but can't generalize), reducing the output dimensions (no change in loss), normalizing the inputs to standardize the coordinates (no change in loss).\n\nAny recommendations/advice? I've been stuck on this for some time and I suspect a fundamental issue is present, or I'm missing something critical/obvious. I've checked the data and the training inputs/targets are fine as well.  Thanks!","link":"https://www.reddit.com/r/MachineLearning/comments/123pu4o/d_debugging_mean_collapsesuboptimal_learning_in/","created":"2023-03-27","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":7}}
