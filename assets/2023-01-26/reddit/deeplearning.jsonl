{"title":"Why add bias instead of subtracting bias?","description":"Pretty much the title, why do we add the bias instead of subtracting?  \nAlso when i watched 3blue1browns video about neural networks nad he said that you subtract the with the bias, but other sources tell me or explain that you simply add the bias in the dot product instead of subtracting.\n\n//Newbie","link":"https://www.reddit.com/r/deeplearning/comments/10lsw4c/why_add_bias_instead_of_subtracting_bias/","created":"2023-01-26","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":5}}
{"title":"Which is your go to framework for deep learning, in python","description":"Just trying to see people's opinions. Both are good frameworks and I find both have their own pros and cons.\n\nEven though ultimately it's about the concepts/architecture/methodologies of the model that's key, what's your preferred implementation tool ?\n\n[View Poll](https://www.reddit.com/poll/10ludw6)","link":"https://www.reddit.com/r/deeplearning/comments/10ludw6/which_is_your_go_to_framework_for_deep_learning/","created":"2023-01-26","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0}}
{"title":"What's the best AI YouTube video summarizer?","description":"Just found out that these GPT tools exist. But there are so many out there. Which ones are the better/best ones out there?","link":"https://www.reddit.com/r/deeplearning/comments/10lu3d1/whats_the_best_ai_youtube_video_summarizer/","created":"2023-01-26","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0}}
{"title":"ImageNet Advise","description":"I've gotten to the point in my PhD career to where I have some really good CNN model variants, on CIFAR10, CIFAR100, and some other datasets (Flowers,Cars, Caltech). We wish to apply to NeurIPS this Spring, deadline around May 13. However, it seems that to have a chance at getting accepted at top conferences, NeurIPS, ICCV, etc, reviewers are looking at results on ImageNet2012.\n\nThe problem being, my university does not have a lot of resources available. Granted, we have 2 40GB A100 GPUs available, but these are shared within the entire university. From my estimate, using both A100 GPUs will allow us to use a batch size around 256 when testing our final model, containing 22 million parameters, at a max image size of 300. I do not know how long this will take to train, but I expect it to take about 4 days for 300 epochs at a total of 105,000 steps. Unfortunately, we have about 6 of these models (variants) to test (no way to cut it down). Equating to roughly 24 full days worth of computation on 2 A100 GPUS (which has about a 50/50% chance of finishing by May, given wait times in queue). We definitely don't have the computation to run each one 3 times to obtain a mean, so our results will be based off one training session.\n\nI know there are ImageNet derivative datasets, such as TinyImageNet (which scales all images to 64x64) or  ImageNet100 (which only contains 100 classes). I believe I can definitely obtain results for either of these datasets within the given time frame.\n\n&amp;#x200B;\n\nQuestion: For top conferences focused on CNNs and deep learning, are ImageNet results that influential? Are these smaller ImageNet derivative datasets even worth training upon rather than testing upon standard ImageNet (Note: these smaller datasets still take a long time to train)?","link":"https://www.reddit.com/r/deeplearning/comments/10lkgwp/imagenet_advise/","created":"2023-01-26","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":4}}
{"title":"best deep learning reference","description":"Hi! I am an aspiring deep learning engineer and I'm looking for best/highly recommended courses/reference in studying deep learning from basic to advanced topics.","link":"https://www.reddit.com/r/deeplearning/comments/10lh60i/best_deep_learning_reference/","created":"2023-01-26","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":8}}
{"title":"best deep learning reference","description":"Hi! I am an aspiring deep learning engineer and I'm looking for best/highly recommended courses/reference in studying deep learning from basic to advanced topics.","link":"https://www.reddit.com/r/deeplearning/comments/10lh5yr/best_deep_learning_reference/","created":"2023-01-26","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0}}
{"title":"3D-to-text methods","description":"Like Clip Interrogator for images that does 2D-to-text [https://huggingface.co/spaces/pharma/CLIP-Interrogator](https://huggingface.co/spaces/pharma/CLIP-Interrogator), do you know any 3D-to-text methods?\n\nI would like to have DreamFusion-like methods work backwards to describe a 3D object [https://dreamfusion3d.github.io/](https://dreamfusion3d.github.io/)","link":"https://www.reddit.com/r/deeplearning/comments/10kwb64/3dtotext_methods/","created":"2023-01-25","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0}}
{"title":"Classify dataset with only 100 images?","description":"Hello Guys,\n\ni am writing a thesis in a company about Image Classification with Convolutional neural networks. The Images Contain a part of a microship, where a crack is visible or if the microchip is okay, then not. How can i build a CNN with such a small dataset? Is that even possible? I thought about maybe using datasets with cracks from the internet, add a image threshold and train my network with them. But i also read about pre-trained neural networks.. Are they maybe a option too?","link":"https://www.reddit.com/r/deeplearning/comments/10l06xg/classify_dataset_with_only_100_images/","created":"2023-01-25","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":10}}
{"title":"Efficient way to tune a network by changing hyperparameters?","description":"Hello all!\n\nAbsolute noob here. I'm trying to optimize an image classifier using transfer learning from InceptionV3 (last layer being 'Mixed 7') and fine-tuned with a small convolutional network on top. So far, I find that changing hyperparameters yields modest (if any) changes in performance and each attempt takes a prohibitive amount of time. I was thus wondering if there were any way to systematically test out multiple changes in hyperparameters without just manually changing one at a time in incremental fashion.","link":"https://www.reddit.com/r/deeplearning/comments/10kecyc/efficient_way_to_tune_a_network_by_changing/","created":"2023-01-24","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":14}}
{"title":"Best cloud to train models with 100-200 GB of data?","description":"So I've been wondering for a while if maybe I should get a 4090, or if I should just use AWS or something.\n\nFor context: I work at a tech company and we use tensorflow/pytorch so I have a decent experience with that. I have used mostly AWS  to train and test things. The problem is, in my experience, moving data from S3 to Sagemaker is a pain in the ass, and I have only used like 1-2 GB of data, mostly tabular data.\n\nNow I want to test a few things myself, train some image models. I've been playing with some models and I got 100 GB of data that I want to fit a model with. I have tried with Colab and the data in google drive, but drive gets confused with multiple files so it's really annoying.\n\nAny suggestions on how to do this in the cloud? I also have some experience with GCP and Azure, but AWS is the provider I have the most experience with. Can I do this without suffering too much when handling data around or should I just buy a 4090 and train stuff locally?","link":"https://www.reddit.com/r/deeplearning/comments/10khmxo/best_cloud_to_train_models_with_100200_gb_of_data/","created":"2023-01-24","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":11}}
{"title":"OpenAi's breakthrough","description":"[https://twitter.com/make\\_mhe/status/1618255363580755968](https://twitter.com/make_mhe/status/1618255363580755968)","link":"https://www.reddit.com/r/deeplearning/comments/10lb7k3/openais_breakthrough/","created":"2023-01-25","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":2}}
{"title":"What are the best ways to learn about deep learning?","description":"Starting a group project in college about \"Brain tumor segmentation using deep learning\" and searching for a summer internship in the subject. I usually approach a new area by looking at youtube videos, looking at some slides from teachers, and perhaps testing simpler code examples. We were now told to research the field for two weeks prior to starting and hence I'm searching for recommendations to effectively learn to be able to contribute to the project. \n\nLooking for any tips like websites (just found Kaggle for an example), threads, code, channels, methods, topics to focus/prioritize, frameworks to prefer/avoid,  articles, books etc.\n\n**Skills:** Intermediate Python/c++, 3rd year MSc, little-to-no knowledge about machine learning.\n\n**Resources:** Slides, An \"expert\" (PhD from college), eight group members, RTX 3060 Ti (and Azure hours later).","link":"https://www.reddit.com/r/deeplearning/comments/10k2cnt/what_are_the_best_ways_to_learn_about_deep/","created":"2023-01-24","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":13}}
{"title":"Trying to build an RNN to predict NBA player performance based on college stats","description":"Hi all,\n\nI'm looking for some help with a model I'm attempting to build. I'm creating a simple RNN that is meant to predict how an NBA player performs over his career based on his college stats. Simply put, the model consists of an LSTM that takes a sequence of college stats and outputs 5 classes. The classes are the NBA player's maximum Player Efficiency Rating (PER) over his or her career.\n\nThe model is relatively simple, but I'm not able to improve accuracy beyond \\~20%. I suspect I'm doing something incorrect? I did a dummy-check of testing on a single training instance and it overfitted, as expected.\n\nWould someone mind looking over my codebase and seeing if I'm doing something glaringly incorrect? Or is my thought process/approach completely off?\n\nHere is a link to my colab notebook: [https://colab.research.google.com/drive/1zEqmgdbRk5-en1LtDPSWynWuBlOTTdBi?usp=sharing](https://colab.research.google.com/drive/1zEqmgdbRk5-en1LtDPSWynWuBlOTTdBi?usp=sharing)\n\n&amp;#x200B;\n\nThanks in advance :)","link":"https://www.reddit.com/r/deeplearning/comments/10jwfpn/trying_to_build_an_rnn_to_predict_nba_player/","created":"2023-01-24","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":5}}
{"title":"Neural Rendering: Tumwater, WA Reconstructed By a Beta Tester!","description":"Video shows 3D reconstruction and a neural render created by a beta tester who captured the city of Tumwater, WA.\n\nLearn more and apply for beta: [https://www.citysynth.ai/](https://www.citysynth.ai/)\n\nhttps://reddit.com/link/10jnz34/video/jwcfbu0p1vda1/player","link":"https://www.reddit.com/r/deeplearning/comments/10jnz34/neural_rendering_tumwater_wa_reconstructed_by_a/","created":"2023-01-23","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0}}
{"title":"Deeplearning Framework Rap","description":"Yo, it's Snoop Dogg, and I'm here to spit 'Bout deep learnin' frameworks, so listen up a bit\n\nFirst up, we got TensorFlow, developed by Google Flexible and scalable, it's a real cool dude\n\nPyTorch, by Facebook, is next on the list Dynamic graphs make it a model designer's twist\n\nCaffe, from Berkeley, is known for its speed In computer vision, it's the ultimate breed\n\nKeras, a library, easy to use and understand For beginners, it's a great tool in hand\n\nTheano, from Montreal, memory usage is key Low-level control, it's the real MVP\n\nNo matter which one you choose, they all get the job done Deep learnin' frameworks, they're second to none\n\nPeace out, and remember, stay in school, and don't be a fool.","link":"https://www.reddit.com/r/deeplearning/comments/10k54f8/deeplearning_framework_rap/","created":"2023-01-24","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0}}
{"title":"What is the difference between Causal LM and Text Generation?","description":"Hi,\n\nI am new to DL. I see on Hugging Face that it separates text generation and causal LM. But it seems both are similar in that they accept a prompt that starts you off and finishes it for you depending on how many more tokens you would like. \n\nIs the difference purely an issue of one being more creative than the other? What does that mean for training?\n\nAlso, do the dataset structure for something like GPT-J typically differ between the two and say, question-answering models?","link":"https://www.reddit.com/r/deeplearning/comments/10jkz9k/what_is_the_difference_between_causal_lm_and_text/","created":"2023-01-23","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0}}
