{"title":"[D] Simple Questions Thread","description":"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!","link":"https://www.reddit.com/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/","created":"2023-01-29","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":14}}
{"title":"[P] I launched \u201cCatchGPT\u201d, a supervised model trained with millions of text examples, to detect GPT created content","description":"I\u2019m an ML Engineer at Hive AI and I\u2019ve been working on a ChatGPT Detector.\n\nHere is a free demo we have up: [https://hivemoderation.com/ai-generated-content-detection](https://hivemoderation.com/ai-generated-content-detection)\n\nFrom our benchmarks it\u2019s significantly better than similar solutions like GPTZero and OpenAI\u2019s GPT2 Output Detector. On our internal datasets, we\u2019re seeing balanced accuracies of &gt;99% for our own model compared to around 60% for GPTZero and 84% for OpenAI\u2019s GPT2 Detector.\n\nFeel free to try it out and let us know if you have any feedback!","link":"https://www.reddit.com/r/MachineLearning/comments/10pb1y3/p_i_launched_catchgpt_a_supervised_model_trained/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":173}}
{"title":"[D] Have researchers given up on traditional machine learning methods?","description":"This may be a silly question for those familiar with the field, but don't machine learning researchers expect any more prospects for traditional methods (I mean, \"traditional\" is other than deep learning)? I feel that most of the time when people talk about machine learning in the world today, they are referring to deep learning, but is this the same in the academic world? Have people who have been studying traditional methods switched to neural networks? I know that many researchers are excited about deep learning, but I am wondering what they think about other methods.","link":"https://www.reddit.com/r/MachineLearning/comments/10pu9eh/d_have_researchers_given_up_on_traditional/","created":"2023-01-31","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":9}}
{"title":"[R] Parsel: A (De-)compositional Framework for Algorithmic Reasoning with Language Models - Stanford University Eric Zelikman et al - Beats prior code generation sota by over 75%!","description":"Paper: [https://arxiv.org/abs/2212.10561](https://arxiv.org/abs/2212.10561) \n\nGithub: [https://github.com/ezelikman/parsel](https://github.com/ezelikman/parsel) \n\nTwitter: [https://twitter.com/ericzelikman/status/1618426056163356675?s=20](https://twitter.com/ericzelikman/status/1618426056163356675?s=20) \n\nWebsite: [https://zelikman.me/parselpaper/](https://zelikman.me/parselpaper/) \n\nCode Generation on APPS Leaderboard: [https://paperswithcode.com/sota/code-generation-on-apps](https://paperswithcode.com/sota/code-generation-on-apps) \n\nAbstract:\n\n&gt;Despite recent success in large language model (LLM) reasoning, **LLMs struggle with hierarchical multi-step reasoning tasks like generating complex programs.** For these tasks, **humans often start with a high-level algorithmic design and implement each part gradually.** We introduce Parsel, a framework enabling automatic implementation and validation of complex algorithms with code LLMs, taking hierarchical function descriptions in natural language as input. We show that **Parsel can be used across domains requiring hierarchical reasoning, including program synthesis, robotic planning, and theorem proving.** We show that LLMs generating Parsel solve more competition-level problems in the APPS dataset, resulting in **pass rates that are over 75% higher than prior results from directly sampling AlphaCode and Codex**, while often using a smaller sample budget. We also find that LLM-generated **robotic plans using Parsel as an intermediate language are more than twice as likely to be considered accurate than directly generated plans.** Lastly, we explore how Parsel addresses LLM limitations and discuss how Parsel may be useful for human programmers. \n\nhttps://preview.redd.it/66zehsdps6fa1.jpg?width=811&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=96db4cb832def624ad10f7383cde56c1444dcbcc\n\nhttps://preview.redd.it/is4pzwdps6fa1.jpg?width=1638&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5e6c3137b982c91c658b58d286e5036a46a7d55d\n\nhttps://preview.redd.it/szkbb0eps6fa1.jpg?width=711&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6eacbd0cdfc8ecc2c21ad1a46d87d8f367d9bbb5\n\nhttps://preview.redd.it/6lk1wzdps6fa1.jpg?width=1468&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5a37d08a5677d927c1b017d711558a6d859e8f3c\n\nhttps://preview.redd.it/8h7p8vdps6fa1.jpg?width=1177&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3e9926040e6af04ec8945fcfe81e51b5c94d5913","link":"https://www.reddit.com/r/MachineLearning/comments/10p3afl/r_parsel_a_decompositional_framework_for/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":7}}
{"title":"[N] Monitor OpenAI API Latency, Tokens, Rate Limits, and More with Graphsignal","description":"Relying on hosted inference with LLMs in productions, such as via OpenAI API, has some challenges. The use of APIs should be designed around unstable latency, rate limits, token counts, costs, etc. To make it observable we've built tracing and monitoring specifically for AI apps. For example, the OpenAI Python library is monitored automatically, no need to do anything. We'll be adding support for more libraries.\n\nHere is a blog post with more info and screenshots: [Monitor OpenAI API Latency, Tokens, Rate Limits, and More](https://graphsignal.com/blog/monitor-open-ai-api-latency-tokens-rate-limits-and-more/). And the [GitHub repo](https://github.com/graphsignal/graphsignal).","link":"https://www.reddit.com/r/MachineLearning/comments/10pzktw/n_monitor_openai_api_latency_tokens_rate_limits/","created":"2023-01-31","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":0}}
{"title":"[D] Towards A Token-Free Future In NLP","description":"[https://peltarion.com/blog/data-science/towards-a-token-free-future-in-nlp](https://peltarion.com/blog/data-science/towards-a-token-free-future-in-nlp)","link":"https://www.reddit.com/r/MachineLearning/comments/10pb982/d_towards_a_tokenfree_future_in_nlp/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":2}}
{"title":"[P] Fine Tuning Whisper in another language","description":"Hi all, I'm trying to fine-tune Whisper AI to transcribe albanian speech to text but I have a problem in that I don't know how the dataset for training whisper model should look like. \n\nI already have voice audios and the transcript for that audio file but I need to know how to reformat it into a valid dataset for training Whisper.\n\nThanks in advance!","link":"https://www.reddit.com/r/MachineLearning/comments/10px4n6/p_fine_tuning_whisper_in_another_language/","created":"2023-01-31","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":2}}
{"title":"[D] What's stopping you from working on speech and voice?","description":"I've been working in the speech and voice space for a while now and am now building out some tooling in the space to make it easier for researchers/engineers/developers to build speech processing systems and features; I'd love to hear what people in ML struggle with when you're trying to build or work with speech processing for your projects/products (beyond speech-to-text APIs)","link":"https://www.reddit.com/r/MachineLearning/comments/10p66zc/d_whats_stopping_you_from_working_on_speech_and/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":37}}
{"title":"[D] deepmind's ai vision","description":"hey i've been looking at this paper from deepmind [https://arxiv.org/pdf/1807.01281.pdf](https://arxiv.org/pdf/1807.01281.pdf) where they train agents to play capture the flag based off of only visual input. what i'm curious about is are there any tricks going on here? Is the ai looking at a \"screen\" the same way a human would and then encodes it's observations after? or is it just looking at a grid of numbers?","link":"https://www.reddit.com/r/MachineLearning/comments/10ptxdt/d_deepminds_ai_vision/","created":"2023-01-31","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":1}}
{"title":"[R] Train CIFAR10 in under 10 seconds on an A100 (new world record!)","description":"[https://github.com/tysam-code/hlb-CIFAR10](https://github.com/tysam-code/hlb-CIFAR10)","link":"https://www.reddit.com/r/MachineLearning/comments/10op6va/r_train_cifar10_in_under_10_seconds_on_an_a100/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":28}}
{"title":"[D] Are there neural net plugins to assist audio editing of Youtube screencasts?","description":"In order to improve my talking skills, I am doing a [little series](https://www.youtube.com/playlist?list=PL04PGV4cTuIVGO5ImYTk9wPVmbgdYbe7J) on how to setup Stable Diffusion on Paperspace, and I am astounded how much time it takes to do the audio editing. Well, part of the reason is that I've only been doing this for 3 days and my process is very inefficient, but it feels that in the current time, neural nets should be able to do things like remove uhms, lip smacking and breath intakes.\n\nI've looked around, and [this post](https://www.reddit.com/r/audioengineering/comments/1xtm1r/comment/cfej9oa/?utm_source=share&amp;utm_medium=web2x&amp;context=3) from 9 years ago says the only choice is to edit it by hand. Is that still true?","link":"https://www.reddit.com/r/MachineLearning/comments/10p7hup/d_are_there_neural_net_plugins_to_assist_audio/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":2}}
{"title":"[Discussion] ChatGPT and language understanding benchmarks","description":"The general consensus seems to be that large language models, and ChatGPT in particular, have a problem with accuracy and hallucination. As compared to what, is often unclear, but let's say as compared to other NLP methods of question answering, language understanding or as compared to Google Search.\n\nI haven't really been able to find any reliable sources documenting this accuracy problem, though.\n\nThe SuperGLUE benchmark has GPT-3 ranked #24, not terrible, but outperformed by old models like T5, which seems odd. GLUE nothing. SQUAD nothing.\n\nSo, I'm curious:\n\n1. Is there any benchmark or metric reflecting the seeming step-function made by ChatGPT that's got everyone so excited? I definitely feel like there's a difference between gpt-3 and chatGPT, but is it measurable or is it just vibes?\n2. Is there any metric showing ChatGPT's problem with fact hallucination and accuracy?\n3. Am I off the mark here looking at question-answering benchmarks as an assessment of LLMs?\n\nThanks","link":"https://www.reddit.com/r/MachineLearning/comments/10oyllu/discussion_chatgpt_and_language_understanding/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":15}}
{"title":"[D] Is the YoloR paper worth looking into?","description":"Doing a survey of object detection papers with plausible application to pose-estimation tasks. Came across the paper \"You Only Learn One Representation\" and, while the theory seems interesting, I want to hear people's opinions before doing a deep dive into the theory.","link":"https://www.reddit.com/r/MachineLearning/comments/10pducv/d_is_the_yolor_paper_worth_looking_into/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":1}}
{"title":"[D] I want to understand the broad steps for building something like Adept.AI","description":"From the given [link!](https://www.adept.ai/act), I gather that it is a large-scale Transformer trained to use digital tools like a web browser. Right now, it\u2019s hooked up to a Chrome extension which allows it to observe what\u2019s happening in the browser and take certain actions, like clicking, typing, and scrolling, etc.\n\nI am interested in knowing the broad steps involved in building something like this.","link":"https://www.reddit.com/r/MachineLearning/comments/10p0iir/d_i_want_to_understand_the_broad_steps_for/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":2}}
{"title":"[D]Are There Studies on text-davinci-003's Zero/Few-shot Performance on Various Academic Benchmarks?","description":"Has anyone come across studies on GPT3 text-davinci-003's zero/few-shot performance over various NLP benchmarks and how they compare to current SoTA? E.g GLUE, SuperGLUE and over more classic ones like CoNLL 2003 NER.\n\nI thought it would be pretty interesting to see how far zero/few-shot learning with LLM has progressed with RLHF and instruction tuning. Am surprised that nobody has done such a benchmark yet.","link":"https://www.reddit.com/r/MachineLearning/comments/10oyi6a/dare_there_studies_on_textdavinci003s_zerofewshot/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":0}}
{"title":"[P] Keras model production deployment","description":" Hi guys.\n\nIt's been some time since I started developing my Keras models, but now is the first time I am trying to push it to production.\n\nMy Keras model looks like this:\n\n`model = Sequential()`\n\n`model.add(Bidirectional(LSTM(256, return_sequences=True)))`\n\n`model.add(Bidirectional(LSTM(256, return_sequences=True)))`\n\n`model.add(TimeDistributed(Dense(1, activation='sigmoid')))`\n\n`model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])`\n\nMy problem is I need to run through about 25 of these for every written sentence. There is going to be an online editor, where users can paste text for my analysis. That means up to about 300 words or about 20 sentences at once. With the current time to run each network (about 0.2s), that means 25 \\* 0,2 \\* 20 or about 100s per user input. I am going for 30 seconds at most with potentially dozens of users at once. Ideally on a Raspberry Pi 4.\n\nThe internet is surely gonna back me up I thought to myself and started googling. If only I know what kind of a rabbit hole I was about to fall into.\n\nFirst I converted my Keras model into a TensorFlow frozen graph model. 10x time improvement on CPU, but still at 0.2s on average.\n\nAnother thing I think may boost the performance is retraining the models for variable input shape (currently I always feed in 50 values). With the average sentence size of 16 words this may, from what I understand, lead to a 3 times boost?\n\nMy question is: now what? What can I do to make it faster? Is it even possible to run it on a Raspberry Pi 4 and get reasonable response times? If not, what is my best option on a tight budget?","link":"https://www.reddit.com/r/MachineLearning/comments/10p1cwu/p_keras_model_production_deployment/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":7}}
{"title":"[D] DL university research PC suggestions?","description":"I am a researcher at a US university and have a budget of 25k to build a PC for training various ML algorithms (e.g. DRL, neuromorphic computing, VAE, etc). I'm trying to decide between going for prebuilds (like [https://lambdalabs.com/gpu-workstations/vector](https://lambdalabs.com/gpu-workstations/vector)) or building with consumer cards like 4090s.   \n\n\nAny advice on which is the most bang for the price? Im not sure how much Im giving up by going for consumer 24g cards vs a6000, 6000 ada but prebuild prices go up quick. Warrantee vs building it myself isn't an issue","link":"https://www.reddit.com/r/MachineLearning/comments/10p4lhq/d_dl_university_research_pc_suggestions/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":5}}
{"title":"[P] Automating a Youtube Shorts channel with Huggingface Transformers and After Effects","description":"I\u2019ll try to get into detail about the implementation and difficulties in case it is useful for anyone else trying to do something similar with an applied ML project, so there\u2019s a TLDR at the end if you\u2019d like the short version/result.\n\nAt the end of last year I convinced myself to start 2023 by creating a side-project that I'd actually finish and deploy and perhaps earn some \u201cpassive\u201d income (spoiler, not so passive after all :P), and after some brainstorming I settled on making an automated Youtube channel about finance news since I had just gotten into investing. Shorts seemed to be more manageable and monetization is changing in February so I went with that.\n\nMy rough initial idea was to get online articles, summarize them, make a basic compilation with some combination of pymovie, opencv and stock photos and done. I was pretty worried about the summarization, since in my ML day job I mainly work with vision or sensor data in manufacturing not NLP. Also, I quickly realized pymovie with still images and some overlayed text was not very attractive for viewers (starting with myself).\n\nFast-forward a few days, and after some research online I came across two things, Huggingface transformers (yep, I know I\u2019ve been living under a rock :P) and After Effects scripting.  From here, it became mainly about figuring out exactly which ML models I needed to fine-tune for finance / social media and for what, then putting it all together.\n\nThe entire workflow looks something like this: the bot fetches online daily news about a topic (stocks or crypto), then sentiment analysis is performed on the title and the full text is summarized into a single sentence. I fine-tuned SBERT on \\~1.5M posts from /r/worldnews publicly available in Google Cloud BigQuery so that it could predict a \u201csocial engagement\u201d score that could be used to rank and filter the news that would make it into the video.\n\nFinally, all of this is combined into a single JSON object written into a .js file that can be used by another \u201ccontent creator\u201d script to render the video from a template using aerender in Python. The content of this template is generated dynamically based on the contents of the .js file via AE Expressions. This module also uses the TTS lib to generate voice-overs for the text, and is also responsible for generating the title (using NLTK to identify the main subjects of each title) and the video\u2019s description. Pexel stock videos are used for the background.\n\nIn principle automating the upload to Youtube could also be done, but at this stage I\u2019m handling this manually as the JSON generation is not as robust as I\u2019d like, so the output file often needs to be tweaked and fixed before the video can be finalized and uploaded. An examples is the summary being too short or vague when taken out of the context of the original article. If you increase the max\\_length of the summarizer to compensate, it can easily become too long to for the overlay to fit the pre-defined dimensions, or the total audio length can be too long for the max duration of a youtube short.\n\nWith some more work I\u2019m confident the whole process can be automated further. For those interested, feel free to check the result here:\n\n[Byte Size Bot channel](https://www.youtube.com/@bytesizebot)\n\nIf you have any questions or suggestions I\u2019d be happy to hear them.\n\nTLDR: Coded an automated (not 100% yet, but will get there) Youtube Shorts channel about finance news to create a passive income stream. Ended up being way harder, more fun and not so \u201cpassive\u201d than my initial expectations.","link":"https://www.reddit.com/r/MachineLearning/comments/10oauj5/p_automating_a_youtube_shorts_channel_with/","created":"2023-01-29","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":14}}
{"title":"[D] Sparse Ridge Regression","description":"Hi all!\n\nGiven X \u2208 \u211d ^(Nx), Y \u2208 \u211d ^(Ny), \u03b2 \u2208 \u211d^(+), so\n\nW = YX^(T)(XX^(T)\\+\u03b2I)^(-1)   (with the Moore\u2013Penrose pseudoinverse)\n\nwhere A = YX^(T) and B = XX^(T)\\+\u03b2I.\n\nIf we consider an arbitrary number of indices/units &lt; Nx, and so we consider only some columns of matrix A and some columns and rows (crosses) of B. The rest of A and B are zeros.\n\nThe approach above of sparsify A and B will break the ridge regression solution when W=AB^(-1)? If yes, there are ways to avoid it?\n\nMany thanks!","link":"https://www.reddit.com/r/MachineLearning/comments/10oxy9j/d_sparse_ridge_regression/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":5}}
{"title":"[D] AI Theory - Signal Processing?","description":"On [This](https://ai.facebook.com/research/theory/) page of Meta AI research where they mention AI theory as a topic, they mention that they use techniques from Signal Processing. As someone with an Electrical Engineering background, and interests in Mathematics and AI, I found this very intriguing. Can someone tell me some of the ways signal processing has been used in AI theory? Some papers or some work done?","link":"https://www.reddit.com/r/MachineLearning/comments/10ocalm/d_ai_theory_signal_processing/","created":"2023-01-29","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":26}}
{"title":"[N][R] Compiling and running GLM-130B on a local machine (4x 3090s, int4 quantization) - Author: Alex J. Champandard","description":"Twitter link to his post: [https://twitter.com/alexjc/status/1617152800571416577?s=46&amp;t=CMQT9rK4F1Lt7g7aX2vTJA](https://twitter.com/alexjc/status/1617152800571416577?s=46&amp;t=CMQT9rK4F1Lt7g7aX2vTJA) \n\nalso important in that regard:\n\n**The case for 4-bit precision: k-bit Inference Scaling Laws - Tim Dettmers**\n\nPaper: [https://arxiv.org/abs/2212.09720](https://arxiv.org/abs/2212.09720) \n\nhttps://preview.redd.it/7nn0pfhn81fa1.jpg?width=585&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8aecd5774fabae48a453cc09bba8b4c2c5e5a16e\n\nhttps://preview.redd.it/0084vhhn81fa1.jpg?width=598&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=61f1c325541d6deec62eba3d7d803a37c073151b","link":"https://www.reddit.com/r/MachineLearning/comments/10ofybj/nr_compiling_and_running_glm130b_on_a_local/","created":"2023-01-29","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":4}}
{"title":"[R] A Robust Hypothesis Test for Tree Ensemble Pruning","description":"I'm looking for help/feedback with this paper. Please let me know if the method is interesting and if there's ways to improve it!\n\n[https://arxiv.org/abs/2301.10115](https://arxiv.org/abs/2301.10115)\n\nAbstract:\n\nGradient boosted decision trees are some of the most popular algorithms in applied machine learning. They are a flexible and powerful tool that can robustly fit to any tabular dataset in a scalable and computationally efficient way. One of the most critical parameters to tune when fitting these models are the various penalty terms used to distinguish signal from noise in the current model. These penalties are effective in practice, but are lacking in robust theoretical justifications. In this paper we develop and present a novel theoretically justified hypothesis test of split quality for gradient boosted tree ensembles and demonstrate that using this method instead of the common penalty terms leads to a significant reduction in out of sample loss. Additionally, this method provides a theoretically well-justified stopping condition for the tree growing algorithm. We also present several innovative extensions to the method, opening the door for a wide variety of novel tree pruning algorithms.","link":"https://www.reddit.com/r/MachineLearning/comments/10otrnf/r_a_robust_hypothesis_test_for_tree_ensemble/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":0}}
{"title":"[D] Remote PhD","description":"Hi all,\n\nDuring the pandemic many software companies transitioned their workforce to \"fully-remote\" or \"partially-remote\"; therefore, I was wondering if any reputable institutions offer a remote CS PhD?\n\nFor context, I know of several individuals who have sorted out remote work with their PIs on a per-person basis (typically after the first 1-2 years of study), but I am not aware of any labs or programs that advertise remote study.\n\nThank you in advance for the responses.\n\nCheers,\n\nMatt","link":"https://www.reddit.com/r/MachineLearning/comments/10ohc3f/d_remote_phd/","created":"2023-01-29","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":18}}
