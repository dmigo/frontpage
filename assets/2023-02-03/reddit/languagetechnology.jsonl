{"title":"Fine tuning mt5","description":"How do I fine-tune an MT5 model for generating Bengali paraphrases? I have enough datasets but I can't find a working script to fine-tune an MT5  model.","link":"https://www.reddit.com/r/LanguageTechnology/comments/10rvura/fine_tuning_mt5/","created":"2023-02-02","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":1}}
{"title":"[ADVISE NEEDED] Extracting clauses from contracts","description":"Hi everyone!\n\nI am currently trying to extract specific clauses from employment contracts that describe something the employee needs to ask approval for from the employer (e.g., requesting time off or requesting a waiver for a non-compete) while ignoring other clauses that do not contain asking-for-approval actions for something (e.g., statement about working days and hours, the position description, or the salary components). And I would like your advice or recommendations on doing this.\n\nThe scenario: the employment contracts are in English and PDF format. I have a manually labeled data set of example clauses that I want (containing asking-for-approval actions). The data describes exactly where the clauses are located in the contract (coordinates and page number). This data set is created from multiple employment contract PDFs. Basically, annotations with the full text from the PDF and also the starting and ending coordinates on where it is located on the page of the contract.\n\nWhat approach would you suggest or recommend for me to tackle this challenge?\n\n&amp;#x200B;\n\nThank you very much!","link":"https://www.reddit.com/r/LanguageTechnology/comments/10seo2i/advise_needed_extracting_clauses_from_contracts/","created":"2023-02-03","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":1}}
{"title":"1-click deploy for your GPT-3 App","description":"Link - [https://github.com/ClerkieAI/berri\\_ai](https://github.com/ClerkieAI/berri_ai)\n\nWe  made a package that makes it easy for you to quickly deploy your LLM Agent from Google Colab to production (Web App and API   Endpoint).\n\n**How it works?**\n\nJust install the package, import the function, and run deploy.\n\nAt the end of the deploy (\\~10-15mins), you will get:\n\n1. A web app to interact with your agent \ud83d\udc49  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/)\n2. An endpoint you can query \ud83d\udc49  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/langchain_agent?query=%22who) is obama?\"\n\nWant a more detailed walkthrough? Check out our loom - [https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43](https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43)\n\nWe\u2019re still early so would love your feedback and opinions. Feel free to try     us out for free \u2013 and if you need help building an agent / want a specific integration, just let us know!","link":"https://www.reddit.com/r/LanguageTechnology/comments/10rzror/1click_deploy_for_your_gpt3_app/","created":"2023-02-02","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0}}
{"title":"merging two vectors in word2vec","description":"lets say X is a vector that contains the traits of person 1\n\nand Y is a vector that contains the traits of a person 2 \n\nhow to merge X and Y into a vector that describes both","link":"https://www.reddit.com/r/LanguageTechnology/comments/10rufby/merging_two_vectors_in_word2vec/","created":"2023-02-02","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":3}}
{"title":"Ordered Keyword Extraction","description":"I'm interested in finding a way to order important terms, phrases and keywords extracted from a text so that they may be passed to a generative language model in an attempt to create a condensed summary of the original text.\n\nConsider a document that contains the following terms in descending order of importance: solar, rooftop, cheap, advanced, panels, photovoltaics, manufacture, etc. These terms won't necessarily have appeared in this order in the document they're extracted from, so I would like to first extract the important terms (as above) and then place them in order so they still make syntactic sense.\n\nFor example, we may have something like: advanced, manufacture, photovoltaics, rooftop, solar, panels, cheap. This ordering seems to suggest that advanced manufacturing of photovoltaics has helped make rooftop solar panels very cheap. I expect that ordering the terms will help provide context for the generative language model and help make the abstractive summary more accurate.\n\nObviously, in this simple toy example, I could just extract the keywords and place them in the sequential order in which they appear in the original text. Not all applications will be this simple, so is there a way to order the keywords so that they most closely resemble the context of the original text? I think that a graph-based approach like TextRank may be the way to proceed, but I would be very grateful for any thoughts or guidance.","link":"https://www.reddit.com/r/LanguageTechnology/comments/10rf68m/ordered_keyword_extraction/","created":"2023-02-02","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":1}}
{"title":"EMNLP video interviews, workshops, and posters","description":"I learned a lot at EMNLP in December and captured some of what I learned in this video.\n\n**Interviews**\n\nI asked five NLP researchers these questions:\n\n1- What is the most exciting development in NLP in 2022\n\n2- What are you looking forward to in 2023?\n\n3- What is an underrated idea that the field should pay more attention to?\n\nTheir answers start at [01:22](https://www.youtube.com/watch?v=plCvF_7qrmY&amp;t=82s).\n\n**Workshops**\n\nI got to spend time at these workshops:\n\n* [Generation, Evaluation &amp; Metrics (GEM)](https://gem-benchmark.com/workshop)\n* [Massively Multilingual NLU](https://mmnlu-22.github.io/)\n* [Blackbox NLP](https://blackboxnlp.github.io/2022/)\n\nMy main takeaways are at [09:25](https://www.youtube.com/watch?v=plCvF_7qrmY&amp;t=565s).\n\n**Posters**\n\nIf you've been to a conference you'd know there's an overwhelming number of posters. I recorded four of the ones I came across and thought were interesting (covering retrieval-augmented text generation, human evaluation, the BLOOM multimodal dataset, and a multimodal method to name music playlists).\n\nPoster presentations start at [14:38](https://www.youtube.com/watch?v=plCvF_7qrmY&amp;t=878s)\n\nFull video: [https://www.youtube.com/watch?v=plCvF\\_7qrmY](https://www.youtube.com/watch?v=plCvF_7qrmY)\n\nWhat's your answer to these questions?\n\n&gt;1- What is the most exciting development in NLP in 2022  \n2- What are you looking forward to in 2023?  \n3- What is an underrated idea that the field should pay more attention to?","link":"https://www.reddit.com/r/LanguageTechnology/comments/10qxm0l/emnlp_video_interviews_workshops_and_posters/","created":"2023-02-01","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0}}
{"title":"Can NLP identify interesting quotes?","description":"**I don't have any knowledge of NLP or machine learning in general.**\n\nI have a small product that gathers users' highlights from their books (like ReadWise, but free). I'd like to find a way to separate the 'interesting' highlights (i.e. those you learn something from, although I know it's subjective), from the meaningless ones.\n\nExample of 'interesting' highlight:\n\n*\"As you consider building your own minimum viable product, let this simple rule suffice: remove any feature, process, or effort that does not contribute directly to the learning you seek.\"*\n\n&amp;#x200B;\n\nExample of 'not-interesting' highlight:\n\n*\"My voice is nothing special, but when your mother tells you something about yourself, even if you\u2019ve coaxed it out of her, it\u2019s hard not to always believe it.\"*\n\nIt's probably a dumb question, but I'm running in circles on how to automate this selection. I thought  NLP could maybe help, so any insight is appreciated!","link":"https://www.reddit.com/r/LanguageTechnology/comments/10r4stt/can_nlp_identify_interesting_quotes/","created":"2023-02-01","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":1}}
{"title":"Dirty labelling solution","description":"I\u2019m looking to some aggregation on academic research and news articles to see what insights I get from it. I\u2019m using textrazor to do named entity recognition on the documents, but getting a lot of dirty labels that have slightly different wording. For example, Tesla, Tesla ltd, Tesla Ltd. As a result, my aggregations have a lot of duplicate results.\n\nThe dataset consists of about 4M labels so the solution has to be efficient to be viable. I was thinking of putting the labels through word2vec and then clustering them based on the word embedding distances? But then the problem arises of how many clusters to use?\n\nI\u2019ve also tried simple regex preprocessing to get rid of the company abbreviations but there are other examples that cannot be solved that easily.","link":"https://www.reddit.com/r/LanguageTechnology/comments/10qnv70/dirty_labelling_solution/","created":"2023-02-01","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":2}}
{"title":"Reducing mistakes by as much as 50% with Recitation aided models: How can you acquire good questions/solutions for samples?","description":"Recently this paper showed how reciting a similar, known truthful question and answer could significantly boost the performance of question/answers, as shown here:\n\n[https://openreview.net/pdf?id=-cqvvvb-NkI](https://openreview.net/pdf?id=-cqvvvb-NkI)\n\nThe paper followed advancements and earlier work such as the notable benefits of few-shots examples with unfinetuned, non-instruct base GPT models, and the \"Ask my anything\" paper which showed how simply formulating questions as ... question and answer pairs... in prompts has similar benefits for retrieval as \"Let's think step by step\" had for factual, logical and consistent answers.\n\n&amp;#x200B;\n\n**What's next? Can we reach almost 100% recall one day for Retrieval augmented tasks and finally overcome hallucination?**\n\nLiterally today the REPLUG paper came out, which clarifies how altering the retriever model can be yet more effective (and in particular by having a retrainable retriever, with echos to the first paper)\n\n[https://arxiv.org/pdf/2301.12652.pdf](https://arxiv.org/pdf/2301.12652.pdf)\n\n&amp;#x200B;\n\n**What's in common between these two?**\n\nIt's the context around the model generation that matters - not finetuning the model  - not for knowledge retrieval tasks anyway (different story for classification, ideation, RTE tasks etc). And excitingly, even small models can reach top level recall with enough context. Sometimes building the context out, and correctly embedding it (/few shot examples), increases your performance on recall at a rate 10x that work on larger models does... this excites me, because it gives power back to the user of the system who equips it with the data, and reduces the power / potential innovation monopoly of those who innovate the cutting edge of LLMs alone...\n\nI am working on retrieval (actually something useful for in context Knowledge retrieveal) and I'd love to know:\n\n**What do you think of the recent trend in better, sourced knowledge retrieval?** If the rate of knowledge retrieval recall continues to skyrocket, will we one day see LLMs equipped with entire companies documents trusted as more factual than any one persons thoughts? Able to identify areas of cognitive dissonance situations, and cite almost every sentence?","link":"https://www.reddit.com/r/LanguageTechnology/comments/10qxh3h/reducing_mistakes_by_as_much_as_50_with/","created":"2023-02-01","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0}}
{"title":"Deltas and Delta-Deltas Features Explained","description":"Hi guys,\n\nI have made a video on YouTube [here](https://youtu.be/zxEnuPolylY) where I explain how deltas and delta-deltas speech features are computed.\n\nI hope it may be of use to some of you out there. As always, feedback is more than welcomed! :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/10qorre/deltas_and_deltadeltas_features_explained/","created":"2023-02-01","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0}}
{"title":"Is there is any rule of thumb for number of data points to finetune bert models?","description":"Finetuning bert models for various downstream tasks is common method to improve performance given  small datasets. I would be grateful if there is any study or any rule of thumb about number of data points that are needed or considered appropriate.","link":"https://www.reddit.com/r/LanguageTechnology/comments/10qc3ua/is_there_is_any_rule_of_thumb_for_number_of_data/","created":"2023-01-31","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":6}}
{"title":"Problems with Doccano","description":"I\u2019ve e been experiencing a weird problem with Doccano. When I download the json file I\u2019ve noticed some of the tags I can see in the GUI are not in the json file, which translates in many errors during the model training results. Has anyone experienced this same issues? How did you fix it?","link":"https://www.reddit.com/r/LanguageTechnology/comments/10qai9p/problems_with_doccano/","created":"2023-01-31","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0}}
{"title":"help me find the paper","description":"hey there was a paper on arxiv similar to this deep mind one   \n[https://the-decoder.com/deepminds-dramatron-can-write-film-and-theater-scripts/](https://the-decoder.com/deepminds-dramatron-can-write-film-and-theater-scripts/)\n\nwhere the team proposed a technique to write a 10 000 token novel using gpt3 \n\nI searched all my history and bookmarks and still can not find it, please help me :(","link":"https://www.reddit.com/r/LanguageTechnology/comments/10qb2vs/help_me_find_the_paper/","created":"2023-01-31","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0}}
{"title":"Conversion of parametric data describing the product to an understandable product description","description":"Hi, I'm wondering what would you say is the best model to create a solution for converting parametric data about a product into an understandable description of the product. Thank you for your suggestions","link":"https://www.reddit.com/r/LanguageTechnology/comments/10q5vhl/conversion_of_parametric_data_describing_the/","created":"2023-01-31","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":3}}
