{"title":"[N] Microsoft integrates GPT 3.5 into Teams","description":"Official blog post: https://www.microsoft.com/en-us/microsoft-365/blog/2023/02/01/microsoft-teams-premium-cut-costs-and-add-ai-powered-productivity/\n\nGiven the amount of money they pumped into OpenAI, it's not surprising that you'd see it integrated into their products. I do wonder how this will work in highly regulated fields (finance, law, medicine, education).","link":"https://www.reddit.com/r/MachineLearning/comments/10rqe34/n_microsoft_integrates_gpt_35_into_teams/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":108}}
{"title":"[p] I built an open source platform to deploy computationally intensive Python functions as serverless jobs, with no timeouts","description":"Hi friends! I ran into this problem enough times at my last few jobs that I built a tool to solve it. I spent many hours building Docker containers for my Python functions, as many of the data science modules required building C libraries (since they significantly speed up compute-intensive routines, such as math calculations). Deploying the containers to AWS Lambda or Fargate (if the processes required more CPU or memory or were &gt;15 minutes) and wiring functions to talk to each other using queues, databases, and blob storage made iterating on the actual code, which wasn't even that complex most of the time, slow.\n\nI made cakework\u00a0[https://github.com/usecakework/cakework](https://github.com/usecakework/cakework), a platform that lets you spin up your Python functions as serverless, production-scale backends with a single command. Using the client SDK, you submit requests, check status, and get results. You can also specify the amount of CPU (up to 16 cores) and memory (up to 128GB) for each individual request, which is helpful when your data size and complexity varies across different requests.\n\nA common pattern that I built cakework for is doing file processing for ML:\n\n\\- ingest data from some source daily, or in response to an external event (data written to blob storage)\n\n\\- run my function (often using pandas/numpy/scipy)\n\n\\- write results to storage, update database\n\n\\- track failures and re-run/fix\n\nIt's open source &lt;3. Here are some fun examples to get you started:\u00a0[https://docs.cakework.com/examples](https://docs.cakework.com/examples)\n\nWould love to hear your thoughts!","link":"https://www.reddit.com/r/MachineLearning/comments/10ryu6b/p_i_built_an_open_source_platform_to_deploy/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":3}}
{"title":"[D] Understanding Vision Transformer (ViT) - What are the prerequisites?","description":"Hello everyone,\n\nI'm interested in diving into the field of computer vision and I recently came across the concept of Vision Transformer (ViT). I want to understand this concept in depth but I'm not sure what prerequisites I need to have in order to grasp the concept fully.\n\nDo I need to have a strong background in Recurrent Neural Networks (RNNs) and Transformer (Attention Is All You Need) to understand ViT, or can I get by just knowing the basics of deep learning and Convolutional Neural Networks (CNNs)?\n\nI would really appreciate if someone could shed some light on this and provide some guidance.\n\nThank you in advance!","link":"https://www.reddit.com/r/MachineLearning/comments/10siibd/d_understanding_vision_transformer_vit_what_are/","created":"2023-02-03","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":0}}
{"title":"[Project] I built a minimal stateless ML project template built on my current favourite stack","description":"Dear r/MachineLearning,\n\nHello everyone! I hope you are all out there having fun, training deep nets and generating fun story-telling with stable-diffusion! :)\n\nI am here today to share with you all a minimal ml project template that I've recently built, which can be found at [https://github.com/AntreasAntoniou/minimal-ml-template/](https://github.com/AntreasAntoniou/minimal-ml-template/). I became increasingly annoyed at how there weren't any repos out there that provided **stateless** ML project templates, which are absolutely necessary when using kubernetes on spot instances, and I decided to build one. By stateless I mean a repo that by default can store model weights in a remote repo and then download them to continue from where it left off if the previous machine dies. The result was this repository.\n\nThe repo remains minimal and extremely readable, all while being packed with a cool stack that I use every day. I'd love to get some feedback, so have a look and let me know.\n\nRegards, Antreas\n\nP.S. A short summary straight from the Github Repo:\n\nThis repo implements a **minimal** machine learning template, that is fully featured for most of the things a machine learning project might need. The most important parts that set this repo apart from the rest are:\n\n1. It is **stateless**. Any given experiment ran using this template, will, automatically and periodically stores the model weights and configuration to [HuggingFace Hub](https://huggingface.co/docs/hub/models-the-hub) and [wandb](https://wandb.ai/site) respectively. As a result, if your machine dies or job exits, and you resume on another machine, the code will automatically locate and download the previous history and continue from where it left off. This makes this repo very useful when using spot instances, or using schedulers like slurm and kubernetes. \n2. It provides support for all the latest and greatest GPU and TPU optimization and scaling algorithms through [HuggingFace Accelerate](https://huggingface.co/docs/accelerate/index).\n3. It provides mature configuration support via [Hydra-Zen](https://github.com/mit-ll-responsible-ai/hydra-zen) and automates configuration generation via [decorators](https://github.com/BayesWatch/minimal-ml-template/blob/af387e59472ea67552b4bb8972b39fe95952dd8a/mlproject/decorators.py#L10) implemented in this repo.\n4. It has a minimal **callback** based boilerplate that allows a user to easily inject any functionality at predefined places in the system without spagettifying the code.\n5. It uses [HuggingFace Models](https://huggingface.co/models) and [Datasets](https://huggingface.co/docs/datasets/index) to streamline building/loading of models, and datasets, but is also not forcing you to use those, allowing for very easy injection of any models and datasets you care about, assuming you use models implemented under PyTorch's `nn.Module` and `Dataset` classes.\n6. It provides plug and play functionality that allows easy hyperparameter search on Kubernetes clusters using [BWatchCompute](https://github.com/BayesWatch/bwatchcompute) and some readily available scripts and yaml templates.\n\n## The Software Stack\n\nThis machine learning project template is built using the following software stack:\n1. Deep Learning Framework: [PyTorch](https://pytorch.org/get-started/locally/)\n2. Dataset storage and retrieval: [Huggingface Datasets](https://huggingface.co/docs/datasets/index)\n3. Model storage and retrieval [Huggingface Hub](https://huggingface.co/docs/hub/models-the-hub), and [HuggingFace Models](https://huggingface.co/models)\n4. GPU/TPU/CPU Optimization and Scaling up options library: [Huggingface Accelerate](https://huggingface.co/docs/accelerate/index)\n5. Experiment configuration + command line argument parsing: [Hydra-zen](https://github.com/mit-ll-responsible-ai/hydra-zen)\n6. Experiment tracking: [Weights and Biases](https://docs.wandb.ai)\n7. Simple python based ML experiment running with Kubernetes using [BWatchCompute](https://github.com/BayesWatch/bwatchcompute)","link":"https://www.reddit.com/r/MachineLearning/comments/10s82tf/project_i_built_a_minimal_stateless_ml_project/","created":"2023-02-03","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":0}}
{"title":"[R] [P] Noisy Sentences Dataset","description":"550K sentences in 5 European languages augmented with noise for training and evaluating spell correction tools or machine learning models. We have constructed our dataset to cover representatives from the language families used across Europe.\n\n* Germanic - English, German;\n* Romance - French;\n* Slavic - Bulgarian;\n* Turkic - Turkish;\n\n**Use case example:** Apply language models or other techniques to compare the sentence pairs and reconstruct the original sentences from the augmented ones. You can use a single multilingual solution to solve the challenge or employ multiple models/techniques for the separate languages. Per-word dictionary lookup is also an option.\n\n**Link:** [https://github.com/radi-cho/noisy-sentences-dataset](https://github.com/radi-cho/noisy-sentences-dataset)","link":"https://www.reddit.com/r/MachineLearning/comments/10sgxs4/r_p_noisy_sentences_dataset/","created":"2023-02-03","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":0}}
{"title":"[D] Why do LLMs like InstructGPT and LLM use RL to instead of supervised learning to learn from the user-ranked examples?","description":"Aligned LLMs such as InstructGPT and ChatGPT are trained via supervised fine-tuning after the initial self-supervised pretraining. Then, the researchers train a reward model on responses ranked by humans. \n\nWhen I understand correctly, they let the LLM generate responses that humans have to rank on a scale from 1-5. Then, they train a reward model (I suppose in supervised fashion?) on these ranked outputs. Once that's done, they use reinforcement learning (RL) with proximal policy optimization (PPO) to update the LLM. \n\nMy question is why they use RL with PPO for this last step? Why don't they fine-tune the LLM using regular supervised learning, whereas the human-ranked outputs represent the labels. Since these are labels in the range 1-5, this could be a ranking or ordinal regression loss for supervised learning.","link":"https://www.reddit.com/r/MachineLearning/comments/10rpj0f/d_why_do_llms_like_instructgpt_and_llm_use_rl_to/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":22}}
{"title":"[d]? Is there a way to access youtube alphabetically or by id?","description":"I'm guessing i probably am not the first person who has wanted to work with youtube data so I'm hoping here is a good place to ask\n\nSo i had an idea to make a neural network that would go through your youtube history and then train a neural network on it. Afterwards if there is a way to access all of youtube by id in a way that you can check every video then you could store all of the id for videos you might like and then use a youtube downloader like youtube-dl to download a certain amount. Was just a dumb idea i had but now i want to actually try it but I'm unsure if I'll actually be able to get the data i need to do it","link":"https://www.reddit.com/r/MachineLearning/comments/10sdrp4/d_is_there_a_way_to_access_youtube_alphabetically/","created":"2023-02-03","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":3}}
{"title":"[P] [R] A simplistic UI to edit images with Stable Diffusion and InstructPix2Pix","description":"https://preview.redd.it/ut4us5251rfa1.png?width=2000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=bf0add1de91537cb806f9f81405d065c95a42cc4\n\nCurrently, the UI supports a picture upload and uses InstructPix2Pix to edit it. Also, it uses upscaling models for quality enhancements. More models are coming soon.\n\nThe goal is to provide a way for non-ML people to use diffusion-based image editing through simplistic app design. Web demo: [https://diffground.com/](https://diffground.com/)","link":"https://www.reddit.com/r/MachineLearning/comments/10rmdwa/p_r_a_simplistic_ui_to_edit_images_with_stable/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":3}}
{"title":"[p] Is it possible to add more classes to an already trained resnet image classifier model without the need to retrain it in all dataset again? [p]","description":"\\[p\\] I am working on massive dataset, and in the future, we'll have to add some more classes over time, can I train the model in the only new classes?\\[p\\]","link":"https://www.reddit.com/r/MachineLearning/comments/10sa859/p_is_it_possible_to_add_more_classes_to_an/","created":"2023-02-03","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":6}}
{"title":"[P] Domestic Violence Dataset","description":"Hi, I am working on  project and for that I need a Twitter Domestic Violence Dataset. Basically I need a dataset with domestic violence tweets against woman.\n\nI have searched Kaggle and other websites but found no luck.\n\nPlus, I tried using Snscrape, but I need some phrases ideas related to domestic violence so I can get some tweets using that. I tried \"Domestic Violence\" , \"My husband tried to kill me\" and looking for more. Help is appreciated.","link":"https://www.reddit.com/r/MachineLearning/comments/10s0b47/p_domestic_violence_dataset/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":3}}
{"title":"[R] Extracting Training Data from Diffusion Models","description":"[https://twitter.com/eric\\_wallace\\_/status/1620449934863642624?s=46&amp;t=GVukPDI7944N8-waYE5qcw](https://twitter.com/eric_wallace_/status/1620449934863642624?s=46&amp;t=GVukPDI7944N8-waYE5qcw)\n\nExtracting training data from diffusion models is possible by following, more or less, these steps:\n\n* Compute CLIP embeddings for the images in a training dataset.\n* Perform an all-pairs comparison and mark the pairs with l2 distance smaller than some threshold as near duplicates\n* Use the prompts for training samples marked as near duplicates to generate N synthetic samples with the trained model\n* Compute the all-pairs  l2 distance between the embeddings of generated samples for a given training prompt. Build a graph where the nodes are generated samples and an edge exists if the l2 distance is less than some threshold. If the largest clique in the resulting graph is of size 10, then the training sample is considered to be memorized.\n* Visually inspect the results to determine if the samples considered to be memorized are similar to the training data samples.\n\nWith this method, the authors were able to find samples from Stable Diffusion and Imagen  corresponding to copyrighted training images.","link":"https://www.reddit.com/r/MachineLearning/comments/10r57pn/r_extracting_training_data_from_diffusion_models/","created":"2023-02-01","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":77}}
{"title":"[D] Querying with multiple vectors during embedding nearest neighbor search?","description":"Are there tools or techniques that permit you to joint query using more than one query vector? \n\nUse case: iterative ANN search refinement, where I start with a seed vector, select matches, and re-query with more examples to improve the search results.\n\nI tried doing this with FAISS, but it performs a \"batch query\" that returns a separate set of results for each query vector (not a joint query).","link":"https://www.reddit.com/r/MachineLearning/comments/10rvkru/d_querying_with_multiple_vectors_during_embedding/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":6}}
{"title":"[D] Commercial Use of a Model that has been trained using Human3.6M","description":" I wanted to use the [Learnable Trainangulation](https://github.com/karfly/learnable-triangulation-pytorch) model in a commercial project. The source code itself is under MIT licensing. However, the dataset they have used is [Human3.6M](http://vision.imar.ro/human3.6m/description.php), which states that the [license](http://vision.imar.ro/human3.6m/eula.php) is \"FREE OF CHARGE FOR ACADEMIC USE ONLY\".\n\nYet, recent court rulings (in the US) state that models can use copyrighted data during training, and the results are no longer bound by that copyright (e.g. Google Books). Does the same apply here?","link":"https://www.reddit.com/r/MachineLearning/comments/10rp7ze/d_commercial_use_of_a_model_that_has_been_trained/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":2}}
{"title":"[D] Workflow chair for AI conference","description":"Hi! Does anyone here have experience working as a workflow chair for major conferences? What are the duties and how much does it pay? (I heard that it's a paid role)","link":"https://www.reddit.com/r/MachineLearning/comments/10rzdem/d_workflow_chair_for_ai_conference/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":4}}
{"title":"[D] ImageNet normalization vs [-1, 1] normalization","description":"For ImageNet classification, there are two common ways of normalizing the input images:\n\n\\- Normalize to `[-1, 1]` using an affine transformation (`2*(x/255) - 1`).\n\n\\- Normalize using ImageNet `mean = (0.485, 0.456, 0.406)` and `std = (0.229, 0.224, 0.225)`.\n\nI observe that the first one is more common in TensorFlow codebases (including Jax models with TensorFlow data processing, e.g. the official Vision Transformers code), whereas the second is ubiquitous in PyTorch codebases.\n\nI tried to find empirical comparisons of the two, but there doesn't seem to be any.\n\nWhich one is better in your opinion? I guess the performance shouldn't be too different, but still it's interesting to hear your experience.","link":"https://www.reddit.com/r/MachineLearning/comments/10rtis6/d_imagenet_normalization_vs_1_1_normalization/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":12}}
{"title":"[D] Global Optimum of K-Means Cost Function","description":"I've recently started reading up on classical ML and I got a question about K-Means.\n\nMore concretely, I am confused about the uniqueness of the global optimal solution of K-Means's cost function.\n\nLet's state the problem formally below, extracted from Bishop's Pattern Recognition and Machine Learning book, exercise 9.1.\n\nConsider the \ud835\udc3e-means algorithm discussed in Section 9.1. Show that as a consequence of there being a finite number of possible assignments for the set of discrete indicator variables \ud835\udc5f\ud835\udc5b\ud835\udc58, and that for each such assignment there is a unique optimum for the \ud835\udf41\ud835\udc58, the K-means algorithm must converge after a finite number of iterations.\n\nI made an answer \\[here\\]([https://stats.stackexchange.com/questions/603327/question-on-the-proof-of-convergence-of-k-means](https://stats.stackexchange.com/questions/603327/question-on-the-proof-of-convergence-of-k-means)) detailing the proof of why it does converge in Lloyd's algorithm, but I think I still do not understand why Lloyd's do not converge to a global minimum, which mathematical theorem/understanding am I missing here?\n\nI think that optimizing both the assignments and the centroids of K-Means at the same time is non-convex and hence there are many local minimums, we can use brute force to search for the global minimum but of course it is exponential to the number of data points. On the other hand, Lloyd optimizes it (greedily) alternatively, and hence you will find the cost functions' local minima (guaranteed)?","link":"https://www.reddit.com/r/MachineLearning/comments/10rmi74/d_global_optimum_of_kmeans_cost_function/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":3}}
{"title":"[P] Time series outlier / anomaly detection","description":"I have traffic speed time series data for each day of the week over several months, with data samples about every 30 seconds. I'd like to find periods of time (subsequences) where the speed is much slower than usual. Any recommendations for algorithms that would be well suited to this problem? Thanks","link":"https://www.reddit.com/r/MachineLearning/comments/10rxnsk/p_time_series_outlier_anomaly_detection/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":3}}
{"title":"[N] OpenAI starts selling subscriptions to its ChatGPT bot","description":"https://www.axios.com/2023/02/01/chatgpt-subscriptions-chatbot-openai\n\nNot fully paywalled, but there's a tiering system.","link":"https://www.reddit.com/r/MachineLearning/comments/10r7k0h/n_openai_starts_selling_subscriptions_to_its/","created":"2023-02-01","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":46}}
{"title":"[D] Apple's ane-transformers - experiences?","description":"I'm using Huggingface's transformers regularly for experimentations, but I plan to deploy some of the models to iOS.\n\nI have found [ml-ane-transformers](https://github.com/apple/ml-ane-transformers/tree/main/ane_transformers) repo from Apple, which shows how transformers can be rewritten to have much better performance on Apple's devices. There's an example of DistilBERT implemented in that optimized way.\n\nAs I plan to deploy transformers to iOS, I started thinking about this. I'm hoping some already have experience about this, so we can discuss:\n\n* Has anyone tried this themselves? Do they actually see the improvements in performance on iOS?\n* I'm using Huggingface's transformer models in my experiments. How much work do you think there is to rewrite model in this optimized way?\n* It's very difficult to train transformers from scratch (especially if they're big :) ), so I'm fine-tuning on top of pre-trained models on Huggingface. Is it possible to use weights from pretrained Huggingface models with the Apple's reference code? How difficult is it?","link":"https://www.reddit.com/r/MachineLearning/comments/10raouh/d_apples_anetransformers_experiences/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":7}}
{"title":"[D] Do high leverage points affect Neural Net and Tree-based model?","description":"I know they can affect linear regression badly but given the fact that neural net and tree-based models can approximate non-linear complex functions, I don't think the high leverage points would be a problem. Just curious about your opinion whether my thinking makes sense","link":"https://www.reddit.com/r/MachineLearning/comments/10rtv0b/d_do_high_leverage_points_affect_neural_net_and/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":1}}
{"title":"[D] What does a DL role look like in ten years?","description":"Every day, there seems to be new evidence of the generalization capabilities of LLMs.\n\nWhat does this mean for the future role of deep learning experts in academia and business? \n\nIt seems like there's a significant chance that skills such as PyTorch and Jax will be displaced by prompt construction and off-the-shelf model APIs, with only a few large institutions working on the DNN itself.\n\nCurious to hear others' thoughts on this.","link":"https://www.reddit.com/r/MachineLearning/comments/10qzlhw/d_what_does_a_dl_role_look_like_in_ten_years/","created":"2023-02-01","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":26}}
{"title":"[R] On the Expressive Power of Geometric Graph Neural Networks","description":"Geometric GNNs are an emerging class of GNNs for **spatially embedded graphs** in scientific and engineering applications, s.a. biomolecular structure, material science, and physical simulations. Notable examples include SchNet, DimeNet, Tensor Field Networks, and E(n) Equivariant GNNs.\n\n**How powerful are geometric GNNs?** How do key design choices influence expressivity and how to build maximally powerful ones?\n\nCheck out this recent paper for more:\n\n\ud83d\udcc4 PDF: [http://arxiv.org/abs/2301.09308](http://arxiv.org/abs/2301.09308)\n\n\ud83d\udcbb Code: [http://github.com/chaitjo/geometric-gnn-dojo](http://github.com/chaitjo/geometric-gnn-dojo)\n\n\ud83d\udca1Key findings: [https://twitter.com/chaitjo/status/1617812402632019968](https://twitter.com/chaitjo/status/1617812402632019968)\u00a0\n\nP.S. Are you new to Geometric GNNs, GDL, PyTorch Geometric, etc.? Want to understand how theory/equations connect to real code?\n\nTry this **Geometric GNN 101 notebook**\u00a0before diving in:  \n[https://github.com/chaitjo/geometric-gnn-dojo/blob/main/geometric\\_gnn\\_101.ipynb](https://github.com/chaitjo/geometric-gnn-dojo/blob/main/geometric_gnn_101.ipynb)","link":"https://www.reddit.com/r/MachineLearning/comments/10r31eo/r_on_the_expressive_power_of_geometric_graph/","created":"2023-02-01","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":6}}
{"title":"[D] Why is stable diffusion much smaller than predecessors?","description":"Stable diffusion seems to be a departure from the trend of building larger and larger models.\n\nIt has 10x less parameters than other image generation models like DALLE-2.\n\n[\u201cIncredibly, compared with DALL-E 2 and Imagen, the Stable Diffusion model is a lot smaller. While DALL-E 2 has around 3.5 Billion parameters, and Imagen has 4.6 Billion, the first Stable Diffusion model has just 890 million parameters, which means it uses a lot less VRAM and can actually be run on consumer-grade graphics cards.\u201d](https://medium.com/nightcafe-creator/stable-diffusion-tutorial-how-to-use-stable-diffusion-157785632eb3)\n\n\nWhat allows stable diffusion to work so well with a lot less parameters? Are there any drawbacks to this, like requiring stable diffusion to be fine tuned more than DALLE-2 for example?","link":"https://www.reddit.com/r/MachineLearning/comments/10r5gku/d_why_is_stable_diffusion_much_smaller_than/","created":"2023-02-01","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":7}}
{"title":"[D] Inconsistent Featurespace in Data","description":"Hi colleagues!\n\nI  am working on a model for which I have a dataset consisting of 2 data  sources. Problem is that one datastream starts in 2017 and the other  only in 2022. Feature spaces from those 2 data streams are different.\n\nI  am wondering if there is a methodology to follow which allows me to use  both data streams for training even though one starts way later than  the other. Or am I forced to drop the newer one? (just 2022 data from  two sources is too small for me to train on)\n\nThank you!","link":"https://www.reddit.com/r/MachineLearning/comments/10rpebe/d_inconsistent_featurespace_in_data/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":2}}
{"title":"[D]How Will Open Source Alternatives Compete With GPT3?","description":"To clarify, I'm not talking about ChatGPT here. I've been testing outputs from GPT-3 davinci003 against alternatives in terms of output quality, relevance, and ability to understand \"instruct\" (versus vanilla autocompletion).\n\nI tried these:\nAI21 Jurassic 178B\nNeoX 20B\nGPT J 6B\nFairSeq 13B\n\nAs well as:\nGPT-3 davinci002\nGPT-3 davinci001\n\n\nOf course, I didn't expect the smaller models to be on par with GPT-3, but I was surprised at how much better GPT3 davinci 003 performed compared to AI21's 178B model. AI21's Jurassic 178B seems to be comparable to GPT3 davinci 001.\n\n\nDoes this mean that only well-funded corporations will be able to train general-purpose LLMs? It seems to me that just having a large model doesn't do much, it's also about several iterations of training and feedback. How are open source alternatives going to be able to compete?\n\n\n(I'm not in the ML or CS field, just an amateur who enjoys using these models)","link":"https://www.reddit.com/r/MachineLearning/comments/10rhprm/dhow_will_open_source_alternatives_compete_with/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":7}}
