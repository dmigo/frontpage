{"title":"[N] GPT-4 is coming next week \u2013 and it will be multimodal, says Microsoft Germany - heise online","description":"[https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html](https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html)\n\n&gt;**GPT-4 is coming next week**: at an approximately one-hour hybrid information event entitled \"**AI in Focus - Digital Kickoff\" on 9 March 2023**, four Microsoft Germany employees presented Large Language Models (LLM) like GPT series as a disruptive force for companies and their Azure-OpenAI offering in detail. The kickoff event took place in the German language, news outlet Heise was present. **Rather casually, Andreas Braun, CTO Microsoft Germany** and Lead Data &amp; AI STU, **mentioned** what he said was **the imminent release of GPT-4.** The fact that **Microsoft is fine-tuning multimodality with OpenAI should no longer have been a secret since the release of Kosmos-1 at the beginning of March.**\n\n[ Dr. Andreas Braun, CTO Microsoft Germany and Lead Data  &amp; AI STU at the Microsoft Digital Kickoff: \\\\\"KI im Fokus\\\\\" \\(AI in  Focus, Screenshot\\) \\(Bild:\u00a0Microsoft\\) ](https://preview.redd.it/rnst03avarma1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c398017ac69b7dda4c95f0d0ee28aa3a37893b90)","link":"https://www.reddit.com/r/MachineLearning/comments/11mzqxu/n_gpt4_is_coming_next_week_and_it_will_be/","created":"2023-03-09","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":50}}
{"title":"[P] Implementing Vision Transformer (ViT) from Scratch using PyTorch","description":"I recently delved into the world of transformers and their application to vision tasks.\n\nAs part of my learning process, I implemented the Vision Transformer (ViT) from scratch using PyTorch. I am sharing my implementation and a step-by-step guide to implementing the model in this post.\n\nI hope you find it helpful.\n\nGithub: [https://github.com/tintn/vision-transformer-from-scratch](https://github.com/tintn/vision-transformer-from-scratch)\n\nPost: [https://medium.com/towards-data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0](https://medium.com/towards-data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0)","link":"https://www.reddit.com/r/MachineLearning/comments/11nj58o/p_implementing_vision_transformer_vit_from/","created":"2023-03-10","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[R] Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models","description":"","link":"https://www.reddit.com/gallery/11mlwty","created":"2023-03-09","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":29}}
{"title":"[D] Is ML a big boys game now?","description":"As much as I enjoy ML as a whole, I am a bit skeptical of the future for individuals. With OpenAI trying to monopolize the market along with Microsoft, which part remains for the small time researchers/developers?\n\nIt seems everything now is just a ChatGPT wrapper, and with GPT-4 around the corner I assume itll be even more prominent.\n\nWhat are your thoughts?","link":"https://www.reddit.com/r/MachineLearning/comments/11njpb9/d_is_ml_a_big_boys_game_now/","created":"2023-03-10","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":3}}
{"title":"[R] RODIN: A Generative Model for Sculpting 3D Digital Avatars Using Diffusion","description":"We, the team from Microsoft Research, propose a diffusion-based generative model to automatically produces highly detailed 3D digital avatars. The generated avatars can be freely viewed in 360 degrees with unprecedented quality. The model significantly accelerates the traditionally sophisticated 3D modeling process and opens new opportunities for 3D artists. The work has been accepted to CVPR 2022.\n\nProject page: [https://3d-avatar-diffusion.microsoft.com/](https://3d-avatar-diffusion.microsoft.com/)\n\nArxiv paper link: [https://arxiv.org/abs/2212.06135](https://arxiv.org/abs/2212.06135)\n\n[360-degree renderable avatar](https://reddit.com/link/11njhnz/video/3bhbf5x7evma1/player)\n\nOne can use a user-given image or natural language prompt to produce a personalized avatar.\n\n[Text-conditioned avatar generation.](https://preview.redd.it/yp32l7u6fvma1.png?width=2778&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e8699c81e0750084209c2d2f6b94a7df117fcf78)\n\nWhile this work is validated on 3D avatar generation, as a broader impact, we hope this work paves the way toward building a 3D generative foundation model for general 3D objects.","link":"https://www.reddit.com/r/MachineLearning/comments/11njhnz/r_rodin_a_generative_model_for_sculpting_3d/","created":"2023-03-10","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1}}
{"title":"[D] Neuron Modeling","description":"Disclaimer : I am just a SWE who only knows some basic concepts of NN and ML, so I might be talking total garbage here.\n\nRecently, I read the news that the organoid made from brain cells can now play a simple game. Since it was made from the real neurons, it was way more efficient in learning.\n\nIf we think about it, our brain is very small and consumes comparably lower power, but still we are pretty smarter than the most of ai models powered by 1000s of gpus.\n\nI was wondering if there are any interesting research papers that actually try to model a human neuron. Btw I am not talking about a neural network itself. I feel like we are over simplifying a neuron as just a number while it can be an object that contains interesting features of our real neurons.\n\nI would really appreciate it if anyone could recommend any related research papers to read!","link":"https://www.reddit.com/r/MachineLearning/comments/11ned6g/d_neuron_modeling/","created":"2023-03-10","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":5}}
{"title":"[D] JAX vs PyTorch in 2023","description":"I've recently started my Ph.D. in Multi-Agent RL, and want to learn JAX/Flax and use that for my research, the reason being that DeepMind/Google use it, and I want to land an internship/job there at some point.\n\nI have been using PyTorch for 2.5 years, and in the past few days, I've been struggling to make the switch to JAX/Flax. Although the ideas behind JAX are cool, I feel like they make it unnecessarily complicated, and I would just be better off if I simply kept using PyTorch since I'm very familiar with it.\n\nI had tried to learn JAX 1-2 years ago already, and I came to the same conclusion back then, which makes me think that the usability of JAX hasn't improved much.\n\nDo you think it's worth it to make a serious effort this time to learn JAX, so that I will be able to use it for the rest of my Ph.D., or is there just no point in doing so and I should keep using PyTorch?","link":"https://www.reddit.com/r/MachineLearning/comments/11myoug/d_jax_vs_pytorch_in_2023/","created":"2023-03-09","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":24}}
{"title":"Recent advances in multimodal models: What are your thoughts on chain of thoughts models? [D]","description":"Hi everyone,\n\nI'm interested in learning more about recent advances in multimodal models, particularly chain of thoughts models. I'm curious to know what people working in this field are most excited about and what ideas and papers have inspired them.\n\nSpecifically, I'm interested in learning about:\n\n- The latest research on multimodal models, especially chain of thoughts models\n- The challenges that researchers are currently facing when developing these models\n- How researchers are addressing these challenges\n- What researchers are most excited about when it comes to the potential applications of these models\n\nIf you work on multimodal models, I'd love to hear your thoughts and insights. What papers have been particularly inspiring or influential? What challenges are you currently facing, and how are you addressing them? What are you most excited about when it comes to the future of multimodal models?\n\nThank you in advance for your responses :)","link":"https://www.reddit.com/r/MachineLearning/comments/11nl766/recent_advances_in_multimodal_models_what_are/","created":"2023-03-10","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[D] Is it possible to train LLaMa?","description":"Most AI is impossible to train(like chat GPT)\n\nDose LLaMa can be trained? \n\nAlthough the dataset is very hard to get, It would be nice if LLaMa can be trained.\n\nWhen searching for reddit, this topic cannot be searched, so I hope it becomes a discuss about HW or availability.  \nThank you.","link":"https://www.reddit.com/r/MachineLearning/comments/11nhl03/d_is_it_possible_to_train_llama/","created":"2023-03-10","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":6}}
{"title":"[R] Survey on Visual Analytics for Explainable Deep Learning","description":"Hi, we are happy to share our recently published survey, \"State of the Art of Visual Analytics for Explainable Deep Learning\". Any feedback is welcome!\n\nThe survey provides a ptaxonomical analysis of visual analytics (VA) solutions that employ explanation methods to aid the user in understanding deep learning models. The paper analyzes them by their explanation methods, the visualization techniques used, the degree of analytics support toward human-based analysis, the types of evaluation activities applied, and how this field is evolving, among others.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/whhhkt4l7rma1.png?width=803&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=7c20c1045289bc58fcc8a5830994f042438a3749\n\nWe wrote the paper intending to make it readable by researchers working in visual analytics, AI, or XAI. It aims at bridging their communities and providing a common reasoning ground for them to foster new joint research contributions.\n\nIn the last part of the paper, we argue for more research on[ ](https://mobile.twitter.com/hashtag/VisualAnalytics?src=hashtag_click)VA systems supporting the end-users in confirmatory and what-if analysis, in addition to exploratory analysis at the model and input levels. We invite researchers of the three communities to tighter collaboration to fix issues and challenges identified in the literature, such as using a limited set of explanation methods, the trustworthiness of the systems, and the lack of standard interfaces for cross-contamination.\n\nPaper: [https://onlinelibrary.wiley.com/doi/10.1111/cgf.14733](https://onlinelibrary.wiley.com/doi/10.1111/cgf.14733)\n\nInteractive explorable survey: [https://aware-diag-sapienza.github.io/VA4XDL/survis/](https://aware-diag-sapienza.github.io/VA4XDL/survis/)\n\nTweet: [https://mobile.twitter.com/Lynos79/status/1623995496804089860](https://mobile.twitter.com/Lynos79/status/1623995496804089860)\n\nAbstract:\n\n&gt;The use and creation of machine-learning-based solutions to solve problems or reduce their computational costs are becoming increasingly widespread in many domains. Deep Learning plays a large part in this growth. However, it has drawbacks such as a lack of explainability and behaving as a black-box model. During the last few years, Visual Analytics has provided several proposals to cope with these drawbacks, supporting the emerging eXplainable Deep Learning field. This survey aims to (i) systematically report the contributions of Visual Analytics for eXplainable Deep Learning; (ii) spot gaps and challenges; (iii) serve as an anthology of visual analytical solutions ready to be exploited and put into operation by the Deep Learning community (architects, trainers and end users) and (iv) prove the degree of maturity, ease of integration and results for specific domains. The survey concludes by identifying future research challenges and bridging activities that are helpful to strengthen the role of Visual Analytics as effective support for eXplainable Deep Learning and to foster the adoption of Visual Analytics solutions in the eXplainable Deep Learning community. An interactive explorable version of this survey is available online at [https://aware-diag-sapienza.github.io/VA4XDL](https://aware-diag-sapienza.github.io/VA4XDL).","link":"https://www.reddit.com/r/MachineLearning/comments/11mz7mj/r_survey_on_visual_analytics_for_explainable_deep/","created":"2023-03-09","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[Research] Feature Extraction for Geospatial Vector Data","description":"I am exploring a binary classification problem about classifying road intersections into\u00a0roundabouts\u00a0or\u00a0not roundabouts. The available input data consists of the GPS latitude / longitude points contained inside the intersection polygons. So each sample contains a list of GPS points that we know that are contained in the intersection.\n\nAs such, I am interested in Machine Learning / Deep Learning techniques for\u00a0classifying geospatial vector data\u00a0specifically (as opposed to raster data). I've searched the web quite a bit and it seems to me that most of the ML research on geospatial data focuses on raster data, but rasterization is not an option for me. The only paper researching learning techniques applied on geospatial vector data I found is this:\u00a0https://arxiv.org/abs/1806.03857, which refers to Polygon data, not Points. I was considering taking the (projected and scaled) point coordinates as features, but since each intersection contains a different number of points, the feature vectors will have variable-length.\n\nI suspect that simply taking the point coordinates and zero-padding until the feature vectors have a fixed length, isn't going to work, due to the dimensionality curse, especially given that I only have ~800 intersection samples.\nOther data I could derive from the points include speed, curvature and curvature change. How do I go about feature engineering / extraction in this case?","link":"https://www.reddit.com/r/MachineLearning/comments/11mtctv/research_feature_extraction_for_geospatial_vector/","created":"2023-03-09","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":6}}
{"title":"[D] What is the best way to fine tune a LLM with your own data and build a custom text classifier?","description":" I am new to LLM. What is the best way to build a custom text classifier leveraging your own data? The data is not labeled. Also what is the best starting LLM for this purpose- smaller model like Roberta or larger ones like GPT?","link":"https://www.reddit.com/r/MachineLearning/comments/11mw2xy/d_what_is_the_best_way_to_fine_tune_a_llm_with/","created":"2023-03-09","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":2}}
{"title":"[P] Introducing the GitHub profile summarizer","description":"Hi guys, I built a website that summarizes a GitHub user using GPT.\n\nWhat is it?You type a GitHub profile URL, then it gives you a summary of the user.\n\nHow does it work?It finds the most important work by heuristics, then summarizes it using GPT.\n\nGive it a try and let me know what you think. :)\n\n[sample summary](https://preview.redd.it/c5o8tccc2jma1.png?width=1238&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9a5c6bc7ba5661020f75b22e3d76aa4441483ff4)\n\n[http://devmarizer.firebaseapp.com/](http://devmarizer.firebaseapp.com/)","link":"https://www.reddit.com/r/MachineLearning/comments/11ly4d9/p_introducing_the_github_profile_summarizer/","created":"2023-03-08","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":33}}
{"title":"[N] CFP: IJCAI 2023 Workshop on Knowledge-Based Compositional Generalization (KBCG)","description":"\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* KBCG @ IJCAI 2023 Call for papers \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nThe 1st International Workshop on Knowledge-Based Compositional Generalization (KBCG)\n\nHeld  in conjunction with the 32nd International Joint Conference on  Artificial Intelligence (IJCAI 2023), August 19th 2023, Cape Town, South  Africa\n\n* Website: [https://KnowledgeAI.github.io/](https://knowledgeai.github.io/)\n* Submission deadline: April 26th, 2023 (11:59 pm AOE)\n* Submission link: [https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG](https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG)\n* IJCAI format, 7-page paper (+2-page references) for proceeding articles\n* IJCAI format, 2-page abstract for posters/demonstrations\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nDear Colleagues,\n\nWe  are excited to announce the First International Workshop on  Knowledge-Based Compositional Generalization (KBCG), which will be held  in conjunction with IJCAI 2023 this August in Cape Town, South Africa.  Our workshop aims to bring together researchers from academia and  industry to discuss the latest advances and challenges in the area of  knowledge representation and compositional generalization in AI.\n\nWebsite: [https://knowledgeai.github.io/](https://knowledgeai.github.io/)\n\nWe  invite researchers in AI, machine learning, statistics, cognitive  sciences, psychology and neuroscience to submit their latest work on  knowledge-based compositional generalization. The goal of this workshop  is to provide a platform for researchers to present their latest work  and to foster discussions on the challenges and opportunities in this  area.  \nThe submission deadline is April 26th, 2023 (11:59 pm AOE), and  the acceptance notification will be on June 1st, 2022. Accepted papers  will be presented at the workshop and included in a workshop proceeding.\n\nWe  invite researchers in AI, machine learning, statistics, cognitive  sciences and neuroscience to submit their papers, posters, and  demonstrations on any topic related to knowledge representation and  compositional generalization, including but not limited to:\n\n* Representation learning for compositional generalization\n* Meta-learning for compositional generalization\n* Transfer learning for compositional generalization\n* Reasoning for compositional generalization\n* Applications of knowledge-based compositional generalization\n* Learning compositional representations\n* Combining knowledge from multiple sources\n* Transfer learning and domain adaptation\n* Compositional generalization in natural language understanding\n* Compositional generalization in reinforcement learning\n* Compositional generalization in knowledge representation and reasoning\n* Relational machine Learning\n* Using external knowledge for efficient machine learning\n* Symbol grounding and Abstractions\n* Benchmarks for compositional generalization\n\nSubmissions  should be in the form of a 7-page paper (+2-page references) for  proceeding articles or a 2-page abstract for posters/demonstrations,  formatted according to the conference's guidelines ([https://www.ijcai.org/authors\\_kit](https://www.ijcai.org/authors_kit)). The submission website is on OpenReview: [https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG](https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG)\n\nKey Dates:\n\n* Submission deadline: April 26th, 2023 (11:59 pm AOE)\n* Acceptance notification: June 1st, 2022\n* Camera ready for accepted submissions: June 15th, 2022\n\nOrganizing Committee:\n\n* Baihan Lin, Columbia University\n* Djallel Bouneffouf, IBM Research\n* Asim Munawar, IBM Research\n* Irina Rish, Mila - Quebec AI Institute\n\nWe  look forward to your submissions and to seeing you at the workshop. If  you have any questions, please feel free to contact the organizing  committee at [kbcg.workshop@gmail.com](mailto:kbcg.workshop@gmail.com).","link":"https://www.reddit.com/r/MachineLearning/comments/11msqu6/n_cfp_ijcai_2023_workshop_on_knowledgebased/","created":"2023-03-09","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[D] Why are so many tokens needed to train large language models?","description":"Hey everyone!\n\nA quick fermi estimate shows that if a person were to encounter 50,000 tokens a day (extremely high estimate, this is a novel per day assuming 1 token = 1 word) then by the time they are 20 they would have encountered 365 million tokens.\n\nObviously this person would be VERY well read. However, if we feed a transformer language model with the same number of tokens then according to scaling laws it would be worse than gpt-2 (which was trained with a dataset about an order of magnitude larger).\n\nSo the question is, why do language models need so many tokens? Does anyone know of any review papers/blog posts discussing this observation?\n\nMy theory is that we haven't yet found the most efficient architecture for language yet, and that transformers' ability to excell at many different tasks means that you need to give it a lot of data to force it to come up with the right neural circuits for the job.\n\nTLDR: Humans need substantially fewer tokens than transformer language models. What's the current understanding for why this is?","link":"https://www.reddit.com/r/MachineLearning/comments/11misax/d_why_are_so_many_tokens_needed_to_train_large/","created":"2023-03-09","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":16}}
{"title":"[D] Is a diverse dataset necessary for accuracy if the conditions in which inference will be used are narrow?","description":"Let's say hypothetically that I want to train an object detection model to recognize dogs in the video output of my home security camera. I know for a fact that I will only use my model on this one camera and that the position and rotation of my camera will never change. Normally when building a dataset, especially for computer vision models, you want to include diverse data to ensure that objects can be detected regardless of their surroundings. However in this case one can make the assumption that the surroundings will largely be static other than some minor variations. For this example does it make more sense to train a model on images collected from the perspective of the camera itself, or should a variety of dog pictures in various environments still be used? My thought process is that if we know enough about the conditions the model will be deployed in it would make more sense to provide training data that reflects this real world usage, but pretty much all the sources I've found online always say your dataset should be diverse. I'm curious to hear what reddit's thoughts on this approach are, or if there's any research that's been done into this topic that I've missed.","link":"https://www.reddit.com/r/MachineLearning/comments/11mvjtu/d_is_a_diverse_dataset_necessary_for_accuracy_if/","created":"2023-03-09","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":3}}
{"title":"[D] Machine/Deep learning jupyter notebooks for computer vision, NLP, and recommender systems","description":"Hi, I work at Intel as an academic outreach coordinator.  I'm sharing about Intel's open source OpenVINO toolkit for optimizing and deploy AI inference on CPUs, discrete and integrated GPUs, and other accelerators like Movidius VPUs and Intel FPGA.  The [github](https://github.com/openvinotoolkit/openvino_notebooks) has over 60 jupyter notebooks that can work on Intel PCs/laptop using Windows &amp; Linux, or on Macs on MacOS including M1 processors.\n\nTry out the stable diffusion Jupyter Notebook [\\#225](https://github.com/openvinotoolkit/openvino_notebooks/tree/main/notebooks/225-stable-diffusion-text-to-image),  or try out the vehicle recognition and detection Jupyter Notebook [\\#218](https://github.com/openvinotoolkit/openvino_notebooks/tree/main/notebooks/218-vehicle-detection-and-recognition)\n\nIts easy to install in 9 simple steps on Windows with pip install, 8 steps on MacOS, and 7 steps on Linux.","link":"https://www.reddit.com/r/MachineLearning/comments/11mbikv/d_machinedeep_learning_jupyter_notebooks_for/","created":"2023-03-08","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[D] Text embedding model for financial documents","description":"I'm currently working on a project where I'm analyzing financial documents such as 10Ks and 10Qs. I'm looking for a pretrained text embedding model that has been fine-tuned on such documents to generate accurate embeddings. While there are models like FinBERT that are tuned for sentiment analysis, I'm interested in a model that can generate more accurate embeddings in general, without focusing solely on sentiment.\n\n&amp;#x200B;\n\nThanks!","link":"https://www.reddit.com/r/MachineLearning/comments/11m99js/d_text_embedding_model_for_financial_documents/","created":"2023-03-08","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":10}}
{"title":"[R] Internet Explorer: Targeted Representation Learning on the Open Web - Carnegie Mellon University Alexander C. Li et al 2023 - Trained on a single GPU for 40 hours and outperforms CLIP ResNet-50 that was trained on 4000 GPU hours!","description":"Paper: [https://arxiv.org/abs/2302.14051](https://arxiv.org/abs/2302.14051) \n\nYoutube: [https://youtu.be/1hYtGZ0CUSA](https://youtu.be/1hYtGZ0CUSA) \n\nBlog: [https://internet-explorer-ssl.github.io/](https://internet-explorer-ssl.github.io/) \n\nCode coming soon! : [https://github.com/internet-explorer-ssl/internet-explorer](https://github.com/internet-explorer-ssl/internet-explorer) \n\nAbstract:\n\n&gt;Modern vision models typically rely on fine-tuning general-purpose models pre-trained on large, static datasets. These general-purpose models only capture the knowledge within their pre-training datasets, which are tiny, out-of-date snapshots of the Internet -- where billions of images are uploaded each day. We suggest an alternate approach: rather than hoping our static datasets transfer to our desired tasks after large-scale pre-training, we propose dynamically utilizing the Internet to quickly train a small-scale model that does extremely well on the task at hand. Our approach, called **Internet Explorer,** **explores the web in a self-supervised manner to progressively find relevant examples that improve performance on a desired target dataset.** It cycles between searching for images on the Internet with text queries, self-supervised training on downloaded images, determining which images were useful, and prioritizing what to search for next. We evaluate Internet Explorer across several datasets and show that it **outperforms or matches CLIP oracle performance by using just a single GPU desktop to actively query the Internet for 30--40 hours.** \n\nhttps://preview.redd.it/zjcqpn4qrjma1.jpg?width=804&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=d2d53c37527aee160847551371d7159432869212\n\nhttps://preview.redd.it/7v97tp4qrjma1.jpg?width=580&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3c9a765589f9710de46e0bb4e40c858c3fc35433\n\nhttps://preview.redd.it/j4bp7s4qrjma1.jpg?width=1646&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e63626dce48a8504ddf5c0bec294b9202c8eece0\n\nhttps://preview.redd.it/q2uibu4qrjma1.jpg?width=1466&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a256020a48f39af67786a19e4528b12ba6f1a28b\n\nhttps://preview.redd.it/j4z0gr4qrjma1.jpg?width=1457&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6729bdb52838304710e6962a9f7102fcd8ecfbb9","link":"https://www.reddit.com/r/MachineLearning/comments/11m1ux4/r_internet_explorer_targeted_representation/","created":"2023-03-08","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":3}}
{"title":"[P] Feste, an open-source framework to optimize and parallelize NLP tasks","description":"Hi, just sharing a new open-source framework called Feste.\n\nDocumentation: https://feste.readthedocs.io\n\nGithub: https://github.com/perone/feste\n\nFeste is a tool for LLMs task composition that does automatic parallelization of backend API calls, tools, and *automatic batching* using graph optimization. Contributions are welcome!","link":"https://www.reddit.com/r/MachineLearning/comments/11m4l8y/p_feste_an_opensource_framework_to_optimize_and/","created":"2023-03-08","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0}}
{"title":"[R] Analysis of 200+ ML competitions in 2022","description":"I run mlcontests.com, a website that aggregates ML competitions across Kaggle and other platforms.\n\nI've just finished a detailed analysis of **200+ competitions** in 2022, and what winners did (we found winning solutions for 67 competitions).\n\nSome highlights:\n\n* **Kaggle still dominant** with the most prize money, most competitions, and most entries per competition...\n* ... but there are **10+ other platforms** with interesting competitions and decent prize money, and dozens of single-competition sites\n* **Almost all competition winners used Python**, 1 used C++, 1 used R, 1 used Java\n* **96% (!) of Deep Learning solutions used PyTorch** (up from 77% last year)\n* **All winning NLP solutions we found used Transformers**\n* **Most computer vision solutions used CNNs**, though some used Transformer-based models\n* **Tabular data competitions were mostly won by GBDTs** (mostly LightGBM), though ensembles with PyTorch are common\n* **Some winners spent hundreds of dollars on cloud compute** for a single training run, **others managed to win just using Colab**'s free tier\n* Winners have largely converged on a common toolkit - PyData stack for the basics, PyTorch for deep learning, LightGBM/XGBoost/CatBoost for GBDTs, Optuna for hyperparam optimisation.\n* Half of competition winners are first-time winners; a third have won multiple comps before; half are solo winners. Some *serial winners* won 2-3 competitions just in 2022!\n\nWay more details as well as methodology here in the full report: [https://mlcontests.com/state-of-competitive-machine-learning-2022?ref=mlc\\_reddit](https://mlcontests.com/state-of-competitive-machine-learning-2022?ref=mlc_reddit)\n\n[Most common Python Packages used by winners](https://preview.redd.it/kwqmozh9lbma1.png?width=1600&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1096de087592eb4cc2fbe85c8068617cb4f73d8f)\n\nWhen I published something similar here [last year](https://www.reddit.com/r/MachineLearning/comments/tdd889/news_analysis_of_83_ml_competitions_in_2021/), I got a lot of questions about tabular data, so I did a [deep dive](https://mlcontests.com/state-of-competitive-machine-learning-2022/#tabular-data?ref=mlc_reddit) into that this year.People also asked about [leaderboard shakeups](https://mlcontests.com/state-of-competitive-machine-learning-2022/#cross-validation?ref=mlc_reddit) and [compute cost trends](https://mlcontests.com/state-of-competitive-machine-learning-2022/#compute-and-hardware?ref=mlc_reddit), so those are included too. I'd love to hear your suggestions for next year.\n\nI managed to spend way more time on this analysis than last year thanks to the report sponsors (**G-Research**, a top quant firm, and **Genesis Cloud**, a renewable-energy cloud compute firm) - if you want to support this research, please check them out. I won't spam you with links here, there's more detail on them at the bottom of the report.","link":"https://www.reddit.com/r/MachineLearning/comments/11kzkla/r_analysis_of_200_ml_competitions_in_2022/","created":"2023-03-07","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":27}}
{"title":"[D] Why isn't everyone using RWKV if it's so much better than transformers?","description":"The machine learning (ML) community is progressing at a remarkable pace and is embracing new techniques very quickly. Based on my comprehension of this model, it appears to offer a distinct set of advantages relative to transformers, while lacking any real drawbacks. Despite these benefits, it remains unclear why adopting this approach is not more widespread among individuals and organizations in the field.\n\nWhy is this the case? I really can't wrap my head around it. The [RWKV](https://github.com/BlinkDL/RWKV-LM) principle has existed for more than a year now and has more than 2k stars on GitHub! I feel like we should have seen wider adoption.\n\nAny thoughts?\n\n------------------\n\nJust to sum things up:\n\n/u/LetterRip explains this by saying that the larger organizations basically just haven't noticed/understood it's potential yet.\n\nMy explaination is that it's actually something problematic with the RWKV architecture. Still wondering what it is though.","link":"https://www.reddit.com/r/MachineLearning/comments/11lq5j4/d_why_isnt_everyone_using_rwkv_if_its_so_much/","created":"2023-03-08","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":19}}
{"title":"[D] The Emergent Abilities of Large Language Models","description":"Hey everyone!  \n\n\nLarge Language Models have been shown to gain new abilities (like translation and arithmetic) as they are scaled. Some of these abilities have been recently observed to be **emergent**, meaning that there is an apparent discontinuity in their appearance with scale.  \n\n\nThis article on [**the emergent abilities of large language models**](https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models/) examines this phenomenon, providing necessary background and information on the concept of emergence as a whole.  \n\n\nI'm interested to hear what folks here think about this phenomenon and observation, especially regarding potential explanations as well as real-world implications. Let me know what you think!\n\n&amp;#x200B;\n\nhttps://preview.redd.it/hrh3zuztgcma1.png?width=1316&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ad511d6d8875cf2765d5f80672d32e49abe28f55","link":"https://www.reddit.com/r/MachineLearning/comments/11l49y5/d_the_emergent_abilities_of_large_language_models/","created":"2023-03-07","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":20}}
{"title":"[R] Prismer: An Open Source Vision-Language Model with An Ensemble of Experts.","description":"Paper here -  [https://arxiv.org/abs/2303.02506](https://arxiv.org/abs/2303.02506)\n\nCode and Models -  [https://github.com/NVlabs/prismer](https://github.com/NVlabs/prismer)","link":"https://www.reddit.com/r/MachineLearning/comments/11lcspc/r_prismer_an_open_source_visionlanguage_model/","created":"2023-03-07","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":5}}
