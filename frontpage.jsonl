{"title":"Defectors: A Large, Diverse Python Dataset for Defect Prediction","description":"Defect prediction has been a popular research topic where machine learning (ML) and deep learning (DL) have found numerous applications. However, these ML/DL-based defect prediction models are often limited by the quality and size of their datasets. In this paper, we present Defectors, a large dataset for just-in-time and line-level defect prediction. Defectors consists of $\\approx$ 213K source code files ($\\approx$ 93K defective and $\\approx$ 120K defect-free) that span across 24 popular Python projects. These projects come from 18 different domains, including machine learning, automation, and internet-of-things. Such a scale and diversity make Defectors a suitable dataset for training ML/DL models, especially transformer models that require large and diverse datasets. We also foresee several application areas of our dataset including defect prediction and defect explanation.   Dataset link: https://doi.org/10.5281/zenodo.7708984","link":"http://arxiv.org/abs/2303.04738v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Defectors: A Large, Diverse Python Dataset for Defect Prediction Defect prediction has been a popular research topic where machine learning (ML) and deep learning (DL) have found numerous applications. However, these ML/DL-based defect prediction models are often limited by the quality and size of their datasets. In this paper, we present Defectors, a large dataset for just-in-time and line-level defect prediction. Defectors consists of $\\approx$ 213K source code files ($\\approx$ 93K defective and $\\approx$ 120K defect-free) that span across 24 popular Python projects. These projects come from 18 different domains, including machine learning, automation, and internet-of-things. Such a scale and diversity make Defectors a suitable dataset for training ML/DL models, especially transformer models that require large and diverse datasets. We also foresee several application areas of our dataset including defect prediction and defect explanation.   Dataset link: https://doi.org/10.5281/zenodo.7708984","classes":{"dataset":0.9792076945}}
{"title":"DiM: Distilling Dataset into Generative Model","description":"Dataset distillation reduces the network training cost by synthesizing small and informative datasets from large-scale ones. Despite the success of the recent dataset distillation algorithms, three drawbacks still limit their wider application: i). the synthetic images perform poorly on large architectures; ii). they need to be re-optimized when the distillation ratio changes; iii). the limited diversity restricts the performance when the distillation ratio is large. In this paper, we propose a novel distillation scheme to \\textbf{D}istill information of large train sets \\textbf{i}nto generative \\textbf{M}odels, named DiM. Specifically, DiM learns to use a generative model to store the information of the target dataset. During the distillation phase, we minimize the differences in logits predicted by a models pool between real and generated images. At the deployment stage, the generative model synthesizes various training samples from random noises on the fly. Due to the simple yet effective designs, the trained DiM can be directly applied to different distillation ratios and large architectures without extra cost. We validate the proposed DiM across 4 datasets and achieve state-of-the-art results on all of them. To the best of our knowledge, we are the first to achieve higher accuracy on complex architectures than simple ones, such as 75.1\\% with ResNet-18 and 72.6\\% with ConvNet-3 on ten images per class of CIFAR-10. Besides, DiM outperforms previous methods with 10\\% $\\sim$ 22\\% when images per class are 1 and 10 on the SVHN dataset.","link":"http://arxiv.org/abs/2303.04707v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"DiM: Distilling Dataset into Generative Model Dataset distillation reduces the network training cost by synthesizing small and informative datasets from large-scale ones. Despite the success of the recent dataset distillation algorithms, three drawbacks still limit their wider application: i). the synthetic images perform poorly on large architectures; ii). they need to be re-optimized when the distillation ratio changes; iii). the limited diversity restricts the performance when the distillation ratio is large. In this paper, we propose a novel distillation scheme to \\textbf{D}istill information of large train sets \\textbf{i}nto generative \\textbf{M}odels, named DiM. Specifically, DiM learns to use a generative model to store the information of the target dataset. During the distillation phase, we minimize the differences in logits predicted by a models pool between real and generated images. At the deployment stage, the generative model synthesizes various training samples from random noises on the fly. Due to the simple yet effective designs, the trained DiM can be directly applied to different distillation ratios and large architectures without extra cost. We validate the proposed DiM across 4 datasets and achieve state-of-the-art results on all of them. To the best of our knowledge, we are the first to achieve higher accuracy on complex architectures than simple ones, such as 75.1\\% with ResNet-18 and 72.6\\% with ConvNet-3 on ten images per class of CIFAR-10. Besides, DiM outperforms previous methods with 10\\% $\\sim$ 22\\% when images per class are 1 and 10 on the SVHN dataset.","classes":{"dataset":0.0761332214}}
{"title":"Loss-Curvature Matching for Dataset Selection and Condensation","description":"Training neural networks on a large dataset requires substantial computational costs. Dataset reduction selects or synthesizes data instances based on the large dataset, while minimizing the degradation in generalization performance from the full dataset. Existing methods utilize the neural network during the dataset reduction procedure, so the model parameter becomes important factor in preserving the performance after reduction. By depending upon the importance of parameters, this paper introduces a new reduction objective, coined LCMat, which Matches the Loss Curvatures of the original dataset and reduced dataset over the model parameter space, more than the parameter point. This new objective induces a better adaptation of the reduced dataset on the perturbed parameter region than the exact point matching. Particularly, we identify the worst case of the loss curvature gap from the local parameter region, and we derive the implementable upper bound of such worst-case with theoretical analyses. Our experiments on both coreset selection and condensation benchmarks illustrate that LCMat shows better generalization performances than existing baselines.","link":"http://arxiv.org/abs/2303.04449v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Loss-Curvature Matching for Dataset Selection and Condensation Training neural networks on a large dataset requires substantial computational costs. Dataset reduction selects or synthesizes data instances based on the large dataset, while minimizing the degradation in generalization performance from the full dataset. Existing methods utilize the neural network during the dataset reduction procedure, so the model parameter becomes important factor in preserving the performance after reduction. By depending upon the importance of parameters, this paper introduces a new reduction objective, coined LCMat, which Matches the Loss Curvatures of the original dataset and reduced dataset over the model parameter space, more than the parameter point. This new objective induces a better adaptation of the reduced dataset on the perturbed parameter region than the exact point matching. Particularly, we identify the worst case of the loss curvature gap from the local parameter region, and we derive the implementable upper bound of such worst-case with theoretical analyses. Our experiments on both coreset selection and condensation benchmarks illustrate that LCMat shows better generalization performances than existing baselines.","classes":{"dataset":0.0446737297}}
{"title":"On the Risks of Stealing the Decoding Algorithms of Language Models","description":"A key component of generating text from modern language models (LM) is the selection and tuning of decoding algorithms. These algorithms determine how to generate text from the internal probability distribution generated by the LM. The process of choosing a decoding algorithm and tuning its hyperparameters takes significant time, manual effort, and computation, and it also requires extensive human evaluation. Therefore, the identity and hyperparameters of such decoding algorithms are considered to be extremely valuable to their owners. In this work, we show, for the first time, that an adversary with typical API access to an LM can steal the type and hyperparameters of its decoding algorithms at very low monetary costs. Our attack is effective against popular LMs used in text generation APIs, including GPT-2 and GPT-3. We demonstrate the feasibility of stealing such information with only a few dollars, e.g., $\\$0.8$, $\\$1$, $\\$4$, and $\\$40$ for the four versions of GPT-3.","link":"http://arxiv.org/abs/2303.04729v1","created":"2023-03-08","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"On the Risks of Stealing the Decoding Algorithms of Language Models A key component of generating text from modern language models (LM) is the selection and tuning of decoding algorithms. These algorithms determine how to generate text from the internal probability distribution generated by the LM. The process of choosing a decoding algorithm and tuning its hyperparameters takes significant time, manual effort, and computation, and it also requires extensive human evaluation. Therefore, the identity and hyperparameters of such decoding algorithms are considered to be extremely valuable to their owners. In this work, we show, for the first time, that an adversary with typical API access to an LM can steal the type and hyperparameters of its decoding algorithms at very low monetary costs. Our attack is effective against popular LMs used in text generation APIs, including GPT-2 and GPT-3. We demonstrate the feasibility of stealing such information with only a few dollars, e.g., $\\$0.8$, $\\$1$, $\\$4$, and $\\$40$ for the four versions of GPT-3.","classes":{"dataset":0.2638296485}}
{"title":"Differential Privacy Meets Neural Network Pruning","description":"A major challenge in applying differential privacy to training deep neural network models is scalability.The widely-used training algorithm, differentially private stochastic gradient descent (DP-SGD), struggles with training moderately-sized neural network models for a value of epsilon corresponding to a high level of privacy protection. In this paper, we explore the idea of dimensionality reduction inspired by neural network pruning to improve the scalability of DP-SGD. We study the interplay between neural network pruning and differential privacy, through the two modes of parameter updates. We call the first mode, parameter freezing, where we pre-prune the network and only update the remaining parameters using DP-SGD. We call the second mode, parameter selection, where we select which parameters to update at each step of training and update only those selected using DP-SGD. In these modes, we use public data for freezing or selecting parameters to avoid privacy loss incurring in these steps. Naturally, the closeness between the private and public data plays an important role in the success of this paradigm. Our experimental results demonstrate how decreasing the parameter space improves differentially private training. Moreover, by studying two popular forms of pruning which do not rely on gradients and do not incur an additional privacy loss, we show that random selection performs on par with magnitude-based selection when it comes to DP-SGD training.","link":"http://arxiv.org/abs/2303.04612v1","created":"2023-03-08","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Differential Privacy Meets Neural Network Pruning A major challenge in applying differential privacy to training deep neural network models is scalability.The widely-used training algorithm, differentially private stochastic gradient descent (DP-SGD), struggles with training moderately-sized neural network models for a value of epsilon corresponding to a high level of privacy protection. In this paper, we explore the idea of dimensionality reduction inspired by neural network pruning to improve the scalability of DP-SGD. We study the interplay between neural network pruning and differential privacy, through the two modes of parameter updates. We call the first mode, parameter freezing, where we pre-prune the network and only update the remaining parameters using DP-SGD. We call the second mode, parameter selection, where we select which parameters to update at each step of training and update only those selected using DP-SGD. In these modes, we use public data for freezing or selecting parameters to avoid privacy loss incurring in these steps. Naturally, the closeness between the private and public data plays an important role in the success of this paradigm. Our experimental results demonstrate how decreasing the parameter space improves differentially private training. Moreover, by studying two popular forms of pruning which do not rely on gradients and do not incur an additional privacy loss, we show that random selection performs on par with magnitude-based selection when it comes to DP-SGD training.","classes":{"dataset":0.2091470361}}
{"title":"Graph Neural Networks Enhanced Smart Contract Vulnerability Detection of Educational Blockchain","description":"With the development of blockchain technology, more and more attention has been paid to the intersection of blockchain and education, and various educational evaluation systems and E-learning systems are developed based on blockchain technology. Among them, Ethereum smart contract is favored by developers for its ``event-triggered\" mechanism for building education intelligent trading systems and intelligent learning platforms. However, due to the immutability of blockchain, published smart contracts cannot be modified, so problematic contracts cannot be fixed by modifying the code in the educational blockchain. In recent years, security incidents due to smart contract vulnerabilities have caused huge property losses, so the detection of smart contract vulnerabilities in educational blockchain has become a great challenge. To solve this problem, this paper proposes a graph neural network (GNN) based vulnerability detection for smart contracts in educational blockchains. Firstly, the bytecodes are decompiled to get the opcode. Secondly, the basic blocks are divided, and the edges between the basic blocks according to the opcode execution logic are added. Then, the control flow graphs (CFG) are built. Finally, we designed a GNN-based model for vulnerability detection. The experimental results show that the proposed method is effective for the vulnerability detection of smart contracts. Compared with the traditional approaches, it can get good results with fewer layers of the GCN model, which shows that the contract bytecode and GCN model are efficient in vulnerability detection.","link":"http://arxiv.org/abs/2303.04477v1","created":"2023-03-08","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Graph Neural Networks Enhanced Smart Contract Vulnerability Detection of Educational Blockchain With the development of blockchain technology, more and more attention has been paid to the intersection of blockchain and education, and various educational evaluation systems and E-learning systems are developed based on blockchain technology. Among them, Ethereum smart contract is favored by developers for its ``event-triggered\" mechanism for building education intelligent trading systems and intelligent learning platforms. However, due to the immutability of blockchain, published smart contracts cannot be modified, so problematic contracts cannot be fixed by modifying the code in the educational blockchain. In recent years, security incidents due to smart contract vulnerabilities have caused huge property losses, so the detection of smart contract vulnerabilities in educational blockchain has become a great challenge. To solve this problem, this paper proposes a graph neural network (GNN) based vulnerability detection for smart contracts in educational blockchains. Firstly, the bytecodes are decompiled to get the opcode. Secondly, the basic blocks are divided, and the edges between the basic blocks according to the opcode execution logic are added. Then, the control flow graphs (CFG) are built. Finally, we designed a GNN-based model for vulnerability detection. The experimental results show that the proposed method is effective for the vulnerability detection of smart contracts. Compared with the traditional approaches, it can get good results with fewer layers of the GCN model, which shows that the contract bytecode and GCN model are efficient in vulnerability detection.","classes":{"dataset":0.0491004027}}
{"title":"Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models","description":"ChatGPT is attracting a cross-field interest as it provides a language interface with remarkable conversational competency and reasoning capabilities across many domains. However, since ChatGPT is trained with languages, it is currently not capable of processing or generating images from the visual world. At the same time, Visual Foundation Models, such as Visual Transformers or Stable Diffusion, although showing great visual understanding and generation capabilities, they are only experts on specific tasks with one-round fixed inputs and outputs. To this end, We build a system called \\textbf{Visual ChatGPT}, incorporating different Visual Foundation Models, to enable the user to interact with ChatGPT by 1) sending and receiving not only languages but also images 2) providing complex visual questions or visual editing instructions that require the collaboration of multiple AI models with multi-steps. 3) providing feedback and asking for corrected results. We design a series of prompts to inject the visual model information into ChatGPT, considering models of multiple inputs/outputs and models that require visual feedback. Experiments show that Visual ChatGPT opens the door to investigating the visual roles of ChatGPT with the help of Visual Foundation Models. Our system is publicly available at \\url{https://github.com/microsoft/visual-chatgpt}.","link":"http://arxiv.org/abs/2303.04671v1","created":"2023-03-08","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models ChatGPT is attracting a cross-field interest as it provides a language interface with remarkable conversational competency and reasoning capabilities across many domains. However, since ChatGPT is trained with languages, it is currently not capable of processing or generating images from the visual world. At the same time, Visual Foundation Models, such as Visual Transformers or Stable Diffusion, although showing great visual understanding and generation capabilities, they are only experts on specific tasks with one-round fixed inputs and outputs. To this end, We build a system called \\textbf{Visual ChatGPT}, incorporating different Visual Foundation Models, to enable the user to interact with ChatGPT by 1) sending and receiving not only languages but also images 2) providing complex visual questions or visual editing instructions that require the collaboration of multiple AI models with multi-steps. 3) providing feedback and asking for corrected results. We design a series of prompts to inject the visual model information into ChatGPT, considering models of multiple inputs/outputs and models that require visual feedback. Experiments show that Visual ChatGPT opens the door to investigating the visual roles of ChatGPT with the help of Visual Foundation Models. Our system is publicly available at \\url{https://github.com/microsoft/visual-chatgpt}.","classes":{"dataset":0.5618650317}}
{"title":"A Prompt Log Analysis of Text-to-Image Generation Systems","description":"Recent developments in diffusion models have unleashed the astonishing capabilities of text-to-image generation systems to synthesize high-quality images that are faithful to a given reference text, known as a \"prompt.\" These systems, once released to the public, have immediately received tons of attention from researchers, creators, and common users. Despite the plenty of efforts to improve the underneath generative models, there is limited work on understanding the information needs of the real users of these systems, e.g., by investigating the prompts the users input at scale. In this paper, we take the initiative to conduct a comprehensive analysis of large-scale prompt logs collected from multiple text-to-image generation systems. Our work is analogous to analyzing the query log of Web search engines, a line of work that has made critical contributions to the glory of the Web search industry and research. We analyze over two million user-input prompts submitted to three popular text-to-image systems at scale. Compared to Web search queries, text-to-image prompts are significantly longer, often organized into unique structures, and present different categories of information needs. Users tend to make more edits within creation sessions, showing remarkable exploratory patterns. Our findings provide concrete implications on how to improve text-to-image generation systems for creation purposes.","link":"http://arxiv.org/abs/2303.04587v1","created":"2023-03-08","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"A Prompt Log Analysis of Text-to-Image Generation Systems Recent developments in diffusion models have unleashed the astonishing capabilities of text-to-image generation systems to synthesize high-quality images that are faithful to a given reference text, known as a \"prompt.\" These systems, once released to the public, have immediately received tons of attention from researchers, creators, and common users. Despite the plenty of efforts to improve the underneath generative models, there is limited work on understanding the information needs of the real users of these systems, e.g., by investigating the prompts the users input at scale. In this paper, we take the initiative to conduct a comprehensive analysis of large-scale prompt logs collected from multiple text-to-image generation systems. Our work is analogous to analyzing the query log of Web search engines, a line of work that has made critical contributions to the glory of the Web search industry and research. We analyze over two million user-input prompts submitted to three popular text-to-image systems at scale. Compared to Web search queries, text-to-image prompts are significantly longer, often organized into unique structures, and present different categories of information needs. Users tend to make more edits within creation sessions, showing remarkable exploratory patterns. Our findings provide concrete implications on how to improve text-to-image generation systems for creation purposes.","classes":{"dataset":0.1057908684}}
{"title":"Towards Trust of Explainable AI in Thyroid Nodule Diagnosis","description":"The ability to explain the prediction of deep learning models to end-users is an important feature to leverage the power of artificial intelligence (AI) for the medical decision-making process, which is usually considered non-transparent and challenging to comprehend. In this paper, we apply state-of-the-art eXplainable artificial intelligence (XAI) methods to explain the prediction of the black-box AI models in the thyroid nodule diagnosis application. We propose new statistic-based XAI methods, namely Kernel Density Estimation and Density map, to explain the case of no nodule detected. XAI methods' performances are considered under a qualitative and quantitative comparison as feedback to improve the data quality and the model performance. Finally, we survey to assess doctors' and patients' trust in XAI explanations of the model's decisions on thyroid nodule images.","link":"http://arxiv.org/abs/2303.04731v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Towards Trust of Explainable AI in Thyroid Nodule Diagnosis The ability to explain the prediction of deep learning models to end-users is an important feature to leverage the power of artificial intelligence (AI) for the medical decision-making process, which is usually considered non-transparent and challenging to comprehend. In this paper, we apply state-of-the-art eXplainable artificial intelligence (XAI) methods to explain the prediction of the black-box AI models in the thyroid nodule diagnosis application. We propose new statistic-based XAI methods, namely Kernel Density Estimation and Density map, to explain the case of no nodule detected. XAI methods' performances are considered under a qualitative and quantitative comparison as feedback to improve the data quality and the model performance. Finally, we survey to assess doctors' and patients' trust in XAI explanations of the model's decisions on thyroid nodule images.","classes":{"dataset":0.9792076945}}
{"title":"Diffusing Gaussian Mixtures for Generating Categorical Data","description":"Learning a categorical distribution comes with its own set of challenges. A successful approach taken by state-of-the-art works is to cast the problem in a continuous domain to take advantage of the impressive performance of the generative models for continuous data. Amongst them are the recently emerging diffusion probabilistic models, which have the observed advantage of generating high-quality samples. Recent advances for categorical generative models have focused on log likelihood improvements. In this work, we propose a generative model for categorical data based on diffusion models with a focus on high-quality sample generation, and propose sampled-based evaluation methods. The efficacy of our method stems from performing diffusion in the continuous domain while having its parameterization informed by the structure of the categorical nature of the target distribution. Our method of evaluation highlights the capabilities and limitations of different generative models for generating categorical data, and includes experiments on synthetic and real-world protein datasets.","link":"http://arxiv.org/abs/2303.04635v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Diffusing Gaussian Mixtures for Generating Categorical Data Learning a categorical distribution comes with its own set of challenges. A successful approach taken by state-of-the-art works is to cast the problem in a continuous domain to take advantage of the impressive performance of the generative models for continuous data. Amongst them are the recently emerging diffusion probabilistic models, which have the observed advantage of generating high-quality samples. Recent advances for categorical generative models have focused on log likelihood improvements. In this work, we propose a generative model for categorical data based on diffusion models with a focus on high-quality sample generation, and propose sampled-based evaluation methods. The efficacy of our method stems from performing diffusion in the continuous domain while having its parameterization informed by the structure of the categorical nature of the target distribution. Our method of evaluation highlights the capabilities and limitations of different generative models for generating categorical data, and includes experiments on synthetic and real-world protein datasets.","classes":{"dataset":0.5620317459}}
{"title":"Learning Enhancement From Degradation: A Diffusion Model For Fundus Image Enhancement","description":"The quality of a fundus image can be compromised by numerous factors, many of which are challenging to be appropriately and mathematically modeled. In this paper, we introduce a novel diffusion model based framework, named Learning Enhancement from Degradation (LED), for enhancing fundus images. Specifically, we first adopt a data-driven degradation framework to learn degradation mappings from unpaired high-quality to low-quality images. We then apply a conditional diffusion model to learn the inverse enhancement process in a paired manner. The proposed LED is able to output enhancement results that maintain clinically important features with better clarity. Moreover, in the inference phase, LED can be easily and effectively integrated with any existing fundus image enhancement framework. We evaluate the proposed LED on several downstream tasks with respect to various clinically-relevant metrics, successfully demonstrating its superiority over existing state-of-the-art methods both quantitatively and qualitatively. The source code is available at https://github.com/QtacierP/LED.","link":"http://arxiv.org/abs/2303.04603v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Learning Enhancement From Degradation: A Diffusion Model For Fundus Image Enhancement The quality of a fundus image can be compromised by numerous factors, many of which are challenging to be appropriately and mathematically modeled. In this paper, we introduce a novel diffusion model based framework, named Learning Enhancement from Degradation (LED), for enhancing fundus images. Specifically, we first adopt a data-driven degradation framework to learn degradation mappings from unpaired high-quality to low-quality images. We then apply a conditional diffusion model to learn the inverse enhancement process in a paired manner. The proposed LED is able to output enhancement results that maintain clinically important features with better clarity. Moreover, in the inference phase, LED can be easily and effectively integrated with any existing fundus image enhancement framework. We evaluate the proposed LED on several downstream tasks with respect to various clinically-relevant metrics, successfully demonstrating its superiority over existing state-of-the-art methods both quantitatively and qualitatively. The source code is available at https://github.com/QtacierP/LED.","classes":{"dataset":0.1940930337}}
{"title":"Estimation of the qualification and behavior of a contributor and aggregation of his answers in a crowdsourcing context","description":"Crowdsourcing is the outsourcing of tasks to a crowd of contributors on a dedicated platform. The crowd on these platforms is very diversified and includes various profiles of contributors which generates data of uneven quality. However, majority voting, which is the aggregating method commonly used in platforms, gives equal weight to each contribution. To overcome this problem, we propose a method, MONITOR, which estimates the contributor's profile and aggregates the collected data by taking into account their possible imperfections thanks to the theory of belief functions. To do so, MONITOR starts by estimating the profile of the contributor through his qualification for the task and his behavior.Crowdsourcing campaigns have been carried out to collect the necessary data to test MONITOR on real data in order to compare it to existing approaches. The results of the experiments show that thanks to the use of the MONITOR method, we obtain a better rate of correct answer after aggregation of the contributions compared to the majority voting. Our contributions in this article are for the first time the proposal of a model that takes into account both the qualification of the contributor and his behavior in the estimation of his profile. For the second one, the weakening and the aggregation of the answers according to the estimated profiles.","link":"http://arxiv.org/abs/2303.04548v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Estimation of the qualification and behavior of a contributor and aggregation of his answers in a crowdsourcing context Crowdsourcing is the outsourcing of tasks to a crowd of contributors on a dedicated platform. The crowd on these platforms is very diversified and includes various profiles of contributors which generates data of uneven quality. However, majority voting, which is the aggregating method commonly used in platforms, gives equal weight to each contribution. To overcome this problem, we propose a method, MONITOR, which estimates the contributor's profile and aggregates the collected data by taking into account their possible imperfections thanks to the theory of belief functions. To do so, MONITOR starts by estimating the profile of the contributor through his qualification for the task and his behavior.Crowdsourcing campaigns have been carried out to collect the necessary data to test MONITOR on real data in order to compare it to existing approaches. The results of the experiments show that thanks to the use of the MONITOR method, we obtain a better rate of correct answer after aggregation of the contributions compared to the majority voting. Our contributions in this article are for the first time the proposal of a model that takes into account both the qualification of the contributor and his behavior in the estimation of his profile. For the second one, the weakening and the aggregation of the answers according to the estimated profiles.","classes":{"dataset":0.4847727716}}
{"title":"FUSQA: Fetal Ultrasound Segmentation Quality Assessment","description":"Deep learning models have been effective for various fetal ultrasound segmentation tasks. However, generalization to new unseen data has raised questions about their effectiveness for clinical adoption. Normally, a transition to new unseen data requires time-consuming and costly quality assurance processes to validate the segmentation performance post-transition. Segmentation quality assessment efforts have focused on natural images, where the problem has been typically formulated as a dice score regression task. In this paper, we propose a simplified Fetal Ultrasound Segmentation Quality Assessment (FUSQA) model to tackle the segmentation quality assessment when no masks exist to compare with. We formulate the segmentation quality assessment process as an automated classification task to distinguish between good and poor-quality segmentation masks for more accurate gestational age estimation. We validate the performance of our proposed approach on two datasets we collect from two hospitals using different ultrasound machines. We compare different architectures, with our best-performing architecture achieving over 90% classification accuracy on distinguishing between good and poor-quality segmentation masks from an unseen dataset. Additionally, there was only a 1.45-day difference between the gestational age reported by doctors and estimated based on CRL measurements using well-segmented masks. On the other hand, this difference increased and reached up to 7.73 days when we calculated CRL from the poorly segmented masks. As a result, AI-based approaches can potentially aid fetal ultrasound segmentation quality assessment and might detect poor segmentation in real-time screening in the future.","link":"http://arxiv.org/abs/2303.04418v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"FUSQA: Fetal Ultrasound Segmentation Quality Assessment Deep learning models have been effective for various fetal ultrasound segmentation tasks. However, generalization to new unseen data has raised questions about their effectiveness for clinical adoption. Normally, a transition to new unseen data requires time-consuming and costly quality assurance processes to validate the segmentation performance post-transition. Segmentation quality assessment efforts have focused on natural images, where the problem has been typically formulated as a dice score regression task. In this paper, we propose a simplified Fetal Ultrasound Segmentation Quality Assessment (FUSQA) model to tackle the segmentation quality assessment when no masks exist to compare with. We formulate the segmentation quality assessment process as an automated classification task to distinguish between good and poor-quality segmentation masks for more accurate gestational age estimation. We validate the performance of our proposed approach on two datasets we collect from two hospitals using different ultrasound machines. We compare different architectures, with our best-performing architecture achieving over 90% classification accuracy on distinguishing between good and poor-quality segmentation masks from an unseen dataset. Additionally, there was only a 1.45-day difference between the gestational age reported by doctors and estimated based on CRL measurements using well-segmented masks. On the other hand, this difference increased and reached up to 7.73 days when we calculated CRL from the poorly segmented masks. As a result, AI-based approaches can potentially aid fetal ultrasound segmentation quality assessment and might detect poor segmentation in real-time screening in the future.","classes":{"dataset":0.2447209358}}
{"title":"Does Synthetic Data Generation of LLMs Help Clinical Text Mining?","description":"Recent advancements in large language models (LLMs) have led to the development of highly potent models like OpenAI's ChatGPT. These models have exhibited exceptional performance in a variety of tasks, such as question answering, essay composition, and code generation. However, their effectiveness in the healthcare sector remains uncertain. In this study, we seek to investigate the potential of ChatGPT to aid in clinical text mining by examining its ability to extract structured information from unstructured healthcare texts, with a focus on biological named entity recognition and relation extraction. However, our preliminary results indicate that employing ChatGPT directly for these tasks resulted in poor performance and raised privacy concerns associated with uploading patients' information to the ChatGPT API. To overcome these limitations, we propose a new training paradigm that involves generating a vast quantity of high-quality synthetic data with labels utilizing ChatGPT and fine-tuning a local model for the downstream task. Our method has resulted in significant improvements in the performance of downstream tasks, improving the F1-score from 23.37% to 63.99% for the named entity recognition task and from 75.86% to 83.59% for the relation extraction task. Furthermore, generating data using ChatGPT can significantly reduce the time and effort required for data collection and labeling, as well as mitigate data privacy concerns. In summary, the proposed framework presents a promising solution to enhance the applicability of LLM models to clinical text mining.","link":"http://arxiv.org/abs/2303.04360v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Does Synthetic Data Generation of LLMs Help Clinical Text Mining? Recent advancements in large language models (LLMs) have led to the development of highly potent models like OpenAI's ChatGPT. These models have exhibited exceptional performance in a variety of tasks, such as question answering, essay composition, and code generation. However, their effectiveness in the healthcare sector remains uncertain. In this study, we seek to investigate the potential of ChatGPT to aid in clinical text mining by examining its ability to extract structured information from unstructured healthcare texts, with a focus on biological named entity recognition and relation extraction. However, our preliminary results indicate that employing ChatGPT directly for these tasks resulted in poor performance and raised privacy concerns associated with uploading patients' information to the ChatGPT API. To overcome these limitations, we propose a new training paradigm that involves generating a vast quantity of high-quality synthetic data with labels utilizing ChatGPT and fine-tuning a local model for the downstream task. Our method has resulted in significant improvements in the performance of downstream tasks, improving the F1-score from 23.37% to 63.99% for the named entity recognition task and from 75.86% to 83.59% for the relation extraction task. Furthermore, generating data using ChatGPT can significantly reduce the time and effort required for data collection and labeling, as well as mitigate data privacy concerns. In summary, the proposed framework presents a promising solution to enhance the applicability of LLM models to clinical text mining.","classes":{"dataset":0.0962061062}}
{"title":"Privacy-preserving and Uncertainty-aware Federated Trajectory Prediction for Connected Autonomous Vehicles","description":"Deep learning is the method of choice for trajectory prediction for autonomous vehicles. Unfortunately, its data-hungry nature implicitly requires the availability of sufficiently rich and high-quality centralized datasets, which easily leads to privacy leakage. Besides, uncertainty-awareness becomes increasingly important for safety-crucial cyber physical systems whose prediction module heavily relies on machine learning tools. In this paper, we relax the data collection requirement and enhance uncertainty-awareness by using Federated Learning on Connected Autonomous Vehicles with an uncertainty-aware global objective. We name our algorithm as FLTP. We further introduce ALFLTP which boosts FLTP via using active learning techniques in adaptatively selecting participating clients. We consider both negative log-likelihood (NLL) and aleatoric uncertainty (AU) as client selection metrics. Experiments on Argoverse dataset show that FLTP significantly outperforms the model trained on local data. In addition, ALFLTP-AU converges faster in training regression loss and performs better in terms of NLL, minADE and MR than FLTP in most rounds, and has more stable round-wise performance than ALFLTP-NLL.","link":"http://arxiv.org/abs/2303.04340v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Privacy-preserving and Uncertainty-aware Federated Trajectory Prediction for Connected Autonomous Vehicles Deep learning is the method of choice for trajectory prediction for autonomous vehicles. Unfortunately, its data-hungry nature implicitly requires the availability of sufficiently rich and high-quality centralized datasets, which easily leads to privacy leakage. Besides, uncertainty-awareness becomes increasingly important for safety-crucial cyber physical systems whose prediction module heavily relies on machine learning tools. In this paper, we relax the data collection requirement and enhance uncertainty-awareness by using Federated Learning on Connected Autonomous Vehicles with an uncertainty-aware global objective. We name our algorithm as FLTP. We further introduce ALFLTP which boosts FLTP via using active learning techniques in adaptatively selecting participating clients. We consider both negative log-likelihood (NLL) and aleatoric uncertainty (AU) as client selection metrics. Experiments on Argoverse dataset show that FLTP significantly outperforms the model trained on local data. In addition, ALFLTP-AU converges faster in training regression loss and performs better in terms of NLL, minADE and MR than FLTP in most rounds, and has more stable round-wise performance than ALFLTP-NLL.","classes":{"dataset":0.074622497}}
{"title":"X-Avatar: Expressive Human Avatars","description":"We present X-Avatar, a novel avatar model that captures the full expressiveness of digital humans to bring about life-like experiences in telepresence, AR/VR and beyond. Our method models bodies, hands, facial expressions and appearance in a holistic fashion and can be learned from either full 3D scans or RGB-D data. To achieve this, we propose a part-aware learned forward skinning module that can be driven by the parameter space of SMPL-X, allowing for expressive animation of X-Avatars. To efficiently learn the neural shape and deformation fields, we propose novel part-aware sampling and initialization strategies. This leads to higher fidelity results, especially for smaller body parts while maintaining efficient training despite increased number of articulated bones. To capture the appearance of the avatar with high-frequency details, we extend the geometry and deformation fields with a texture network that is conditioned on pose, facial expression, geometry and the normals of the deformed surface. We show experimentally that our method outperforms strong baselines in both data domains both quantitatively and qualitatively on the animation task. To facilitate future research on expressive avatars we contribute a new dataset, called X-Humans, containing 233 sequences of high-quality textured scans from 20 participants, totalling 35,500 data frames.","link":"http://arxiv.org/abs/2303.04805v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"X-Avatar: Expressive Human Avatars We present X-Avatar, a novel avatar model that captures the full expressiveness of digital humans to bring about life-like experiences in telepresence, AR/VR and beyond. Our method models bodies, hands, facial expressions and appearance in a holistic fashion and can be learned from either full 3D scans or RGB-D data. To achieve this, we propose a part-aware learned forward skinning module that can be driven by the parameter space of SMPL-X, allowing for expressive animation of X-Avatars. To efficiently learn the neural shape and deformation fields, we propose novel part-aware sampling and initialization strategies. This leads to higher fidelity results, especially for smaller body parts while maintaining efficient training despite increased number of articulated bones. To capture the appearance of the avatar with high-frequency details, we extend the geometry and deformation fields with a texture network that is conditioned on pose, facial expression, geometry and the normals of the deformed surface. We show experimentally that our method outperforms strong baselines in both data domains both quantitatively and qualitatively on the animation task. To facilitate future research on expressive avatars we contribute a new dataset, called X-Humans, containing 233 sequences of high-quality textured scans from 20 participants, totalling 35,500 data frames.","classes":{"dataset":0.210879907}}
{"title":"Medical Waste Sorting: a computer vision approach for assisted primary sorting","description":"Medical waste, i.e. waste produced during medical activities in hospitals, clinics and laboratories, represents hazardous waste whose management involves special care and high costs. However, this kind of waste contains a significant fraction of highly valued materials that can enter a circular economy process. To this end, in this paper, we propose a computer vision approach for assisting in the primary sorting of medical waste. The feasibility of our approach is demonstrated on a representative dataset we collected and made available to the community, with which we have trained a model that achieves 100\\% accuracy, and a new dataset on which the trained model exhibits good generalization.","link":"http://arxiv.org/abs/2303.04720v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Medical Waste Sorting: a computer vision approach for assisted primary sorting Medical waste, i.e. waste produced during medical activities in hospitals, clinics and laboratories, represents hazardous waste whose management involves special care and high costs. However, this kind of waste contains a significant fraction of highly valued materials that can enter a circular economy process. To this end, in this paper, we propose a computer vision approach for assisting in the primary sorting of medical waste. The feasibility of our approach is demonstrated on a representative dataset we collected and made available to the community, with which we have trained a model that achieves 100\\% accuracy, and a new dataset on which the trained model exhibits good generalization.","classes":{"dataset":0.9490346313}}
{"title":"Better Together: Using Multi-task Learning to Improve Feature Selection within Structural Datasets","description":"There have been recent efforts to move to population-based structural health monitoring (PBSHM) systems. One area of PBSHM which has been recognised for potential development is the use of multi-task learning (MTL); algorithms which differ from traditional independent learning algorithms. Presented here is the use of the MTL, ''Joint Feature Selection with LASSO'', to provide automatic feature selection for a structural dataset. The classification task is to differentiate between the port and starboard side of a tailplane, for samples from two aircraft of the same model. The independent learner produced perfect F1 scores but had poor engineering insight; whereas the MTL results were interpretable, highlighting structural differences as opposed to differences in experimental set-up.","link":"http://arxiv.org/abs/2303.04486v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Better Together: Using Multi-task Learning to Improve Feature Selection within Structural Datasets There have been recent efforts to move to population-based structural health monitoring (PBSHM) systems. One area of PBSHM which has been recognised for potential development is the use of multi-task learning (MTL); algorithms which differ from traditional independent learning algorithms. Presented here is the use of the MTL, ''Joint Feature Selection with LASSO'', to provide automatic feature selection for a structural dataset. The classification task is to differentiate between the port and starboard side of a tailplane, for samples from two aircraft of the same model. The independent learner produced perfect F1 scores but had poor engineering insight; whereas the MTL results were interpretable, highlighting structural differences as opposed to differences in experimental set-up.","classes":{"dataset":0.1109075844}}
{"title":"Camera-Radar Perception for Autonomous Vehicles and ADAS: Concepts, Datasets and Metrics","description":"One of the main paths towards the reduction of traffic accidents is the increase in vehicle safety through driver assistance systems or even systems with a complete level of autonomy. In these types of systems, tasks such as obstacle detection and segmentation, especially the Deep Learning-based ones, play a fundamental role in scene understanding for correct and safe navigation. Besides that, the wide variety of sensors in vehicles nowadays provides a rich set of alternatives for improvement in the robustness of perception in challenging situations, such as navigation under lighting and weather adverse conditions. Despite the current focus given to the subject, the literature lacks studies on radar-based and radar-camera fusion-based perception. Hence, this work aims to carry out a study on the current scenario of camera and radar-based perception for ADAS and autonomous vehicles. Concepts and characteristics related to both sensors, as well as to their fusion, are presented. Additionally, we give an overview of the Deep Learning-based detection and segmentation tasks, and the main datasets, metrics, challenges, and open questions in vehicle perception.","link":"http://arxiv.org/abs/2303.04302v1","created":"2023-03-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Camera-Radar Perception for Autonomous Vehicles and ADAS: Concepts, Datasets and Metrics One of the main paths towards the reduction of traffic accidents is the increase in vehicle safety through driver assistance systems or even systems with a complete level of autonomy. In these types of systems, tasks such as obstacle detection and segmentation, especially the Deep Learning-based ones, play a fundamental role in scene understanding for correct and safe navigation. Besides that, the wide variety of sensors in vehicles nowadays provides a rich set of alternatives for improvement in the robustness of perception in challenging situations, such as navigation under lighting and weather adverse conditions. Despite the current focus given to the subject, the literature lacks studies on radar-based and radar-camera fusion-based perception. Hence, this work aims to carry out a study on the current scenario of camera and radar-based perception for ADAS and autonomous vehicles. Concepts and characteristics related to both sensors, as well as to their fusion, are presented. Additionally, we give an overview of the Deep Learning-based detection and segmentation tasks, and the main datasets, metrics, challenges, and open questions in vehicle perception.","classes":{"dataset":0.0412661321}}
{"title":"Considerations on the Theory of Training Models with Differential Privacy","description":"In federated learning collaborative learning takes place by a set of clients who each want to remain in control of how their local training data is used, in particular, how can each client's local training data remain private? Differential privacy is one method to limit privacy leakage. We provide a general overview of its framework and provable properties, adopt the more recent hypothesis based definition called Gaussian DP or $f$-DP, and discuss Differentially Private Stochastic Gradient Descent (DP-SGD). We stay at a meta level and attempt intuitive explanations and insights \\textit{in this book chapter}.","link":"http://arxiv.org/abs/2303.04676v1","created":"2023-03-08","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Considerations on the Theory of Training Models with Differential Privacy In federated learning collaborative learning takes place by a set of clients who each want to remain in control of how their local training data is used, in particular, how can each client's local training data remain private? Differential privacy is one method to limit privacy leakage. We provide a general overview of its framework and provable properties, adopt the more recent hypothesis based definition called Gaussian DP or $f$-DP, and discuss Differentially Private Stochastic Gradient Descent (DP-SGD). We stay at a meta level and attempt intuitive explanations and insights \\textit{in this book chapter}.","classes":{"dataset":0.3336561918}}
{"title":"Distributed and Deep Vertical Federated Learning with Big Data","description":"In recent years, data are typically distributed in multiple organizations while the data security is becoming increasingly important. Federated Learning (FL), which enables multiple parties to collaboratively train a model without exchanging the raw data, has attracted more and more attention. Based on the distribution of data, FL can be realized in three scenarios, i.e., horizontal, vertical, and hybrid. In this paper, we propose to combine distributed machine learning techniques with Vertical FL and propose a Distributed Vertical Federated Learning (DVFL) approach. The DVFL approach exploits a fully distributed architecture within each party in order to accelerate the training process. In addition, we exploit Homomorphic Encryption (HE) to protect the data against honest-but-curious participants. We conduct extensive experimentation in a large-scale cluster environment and a cloud environment in order to show the efficiency and scalability of our proposed approach. The experiments demonstrate the good scalability of our approach and the significant efficiency advantage (up to 6.8 times with a single server and 15.1 times with multiple servers in terms of the training time) compared with baseline frameworks.","link":"http://arxiv.org/abs/2303.04574v1","created":"2023-03-08","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Distributed and Deep Vertical Federated Learning with Big Data In recent years, data are typically distributed in multiple organizations while the data security is becoming increasingly important. Federated Learning (FL), which enables multiple parties to collaboratively train a model without exchanging the raw data, has attracted more and more attention. Based on the distribution of data, FL can be realized in three scenarios, i.e., horizontal, vertical, and hybrid. In this paper, we propose to combine distributed machine learning techniques with Vertical FL and propose a Distributed Vertical Federated Learning (DVFL) approach. The DVFL approach exploits a fully distributed architecture within each party in order to accelerate the training process. In addition, we exploit Homomorphic Encryption (HE) to protect the data against honest-but-curious participants. We conduct extensive experimentation in a large-scale cluster environment and a cloud environment in order to show the efficiency and scalability of our proposed approach. The experiments demonstrate the good scalability of our approach and the significant efficiency advantage (up to 6.8 times with a single server and 15.1 times with multiple servers in terms of the training time) compared with baseline frameworks.","classes":{"dataset":0.0349671356}}
{"title":"QuickSRNet: Plain Single-Image Super-Resolution Architecture for Faster Inference on Mobile Platforms","description":"In this work, we present QuickSRNet, an efficient super-resolution architecture for real-time applications on mobile platforms. Super-resolution clarifies, sharpens, and upscales an image to higher resolution. Applications such as gaming and video playback along with the ever-improving display capabilities of TVs, smartphones, and VR headsets are driving the need for efficient upscaling solutions. While existing deep learning-based super-resolution approaches achieve impressive results in terms of visual quality, enabling real-time DL-based super-resolution on mobile devices with compute, thermal, and power constraints is challenging. To address these challenges, we propose QuickSRNet, a simple yet effective architecture that provides better accuracy-to-latency trade-offs than existing neural architectures for single-image super resolution. We present training tricks to speed up existing residual-based super-resolution architectures while maintaining robustness to quantization. Our proposed architecture produces 1080p outputs via 2x upscaling in 2.2 ms on a modern smartphone, making it ideal for high-fps real-time applications.","link":"http://arxiv.org/abs/2303.04336v1","created":"2023-03-08","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"QuickSRNet: Plain Single-Image Super-Resolution Architecture for Faster Inference on Mobile Platforms In this work, we present QuickSRNet, an efficient super-resolution architecture for real-time applications on mobile platforms. Super-resolution clarifies, sharpens, and upscales an image to higher resolution. Applications such as gaming and video playback along with the ever-improving display capabilities of TVs, smartphones, and VR headsets are driving the need for efficient upscaling solutions. While existing deep learning-based super-resolution approaches achieve impressive results in terms of visual quality, enabling real-time DL-based super-resolution on mobile devices with compute, thermal, and power constraints is challenging. To address these challenges, we propose QuickSRNet, a simple yet effective architecture that provides better accuracy-to-latency trade-offs than existing neural architectures for single-image super resolution. We present training tricks to speed up existing residual-based super-resolution architectures while maintaining robustness to quantization. Our proposed architecture produces 1080p outputs via 2x upscaling in 2.2 ms on a modern smartphone, making it ideal for high-fps real-time applications.","classes":{"dataset":0.010346246}}
{"title":"Does Synthetic Data Generation of LLMs Help Clinical Text Mining?","description":"Recent advancements in large language models (LLMs) have led to the development of highly potent models like OpenAI's ChatGPT. These models have exhibited exceptional performance in a variety of tasks, such as question answering, essay composition, and code generation. However, their effectiveness in the healthcare sector remains uncertain. In this study, we seek to investigate the potential of ChatGPT to aid in clinical text mining by examining its ability to extract structured information from unstructured healthcare texts, with a focus on biological named entity recognition and relation extraction. However, our preliminary results indicate that employing ChatGPT directly for these tasks resulted in poor performance and raised privacy concerns associated with uploading patients' information to the ChatGPT API. To overcome these limitations, we propose a new training paradigm that involves generating a vast quantity of high-quality synthetic data with labels utilizing ChatGPT and fine-tuning a local model for the downstream task. Our method has resulted in significant improvements in the performance of downstream tasks, improving the F1-score from 23.37% to 63.99% for the named entity recognition task and from 75.86% to 83.59% for the relation extraction task. Furthermore, generating data using ChatGPT can significantly reduce the time and effort required for data collection and labeling, as well as mitigate data privacy concerns. In summary, the proposed framework presents a promising solution to enhance the applicability of LLM models to clinical text mining.","link":"http://arxiv.org/abs/2303.04360v1","created":"2023-03-08","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Does Synthetic Data Generation of LLMs Help Clinical Text Mining? Recent advancements in large language models (LLMs) have led to the development of highly potent models like OpenAI's ChatGPT. These models have exhibited exceptional performance in a variety of tasks, such as question answering, essay composition, and code generation. However, their effectiveness in the healthcare sector remains uncertain. In this study, we seek to investigate the potential of ChatGPT to aid in clinical text mining by examining its ability to extract structured information from unstructured healthcare texts, with a focus on biological named entity recognition and relation extraction. However, our preliminary results indicate that employing ChatGPT directly for these tasks resulted in poor performance and raised privacy concerns associated with uploading patients' information to the ChatGPT API. To overcome these limitations, we propose a new training paradigm that involves generating a vast quantity of high-quality synthetic data with labels utilizing ChatGPT and fine-tuning a local model for the downstream task. Our method has resulted in significant improvements in the performance of downstream tasks, improving the F1-score from 23.37% to 63.99% for the named entity recognition task and from 75.86% to 83.59% for the relation extraction task. Furthermore, generating data using ChatGPT can significantly reduce the time and effort required for data collection and labeling, as well as mitigate data privacy concerns. In summary, the proposed framework presents a promising solution to enhance the applicability of LLM models to clinical text mining.","classes":{"dataset":0.4283736944}}
{"title":"X-Avatar: Expressive Human Avatars","description":"We present X-Avatar, a novel avatar model that captures the full expressiveness of digital humans to bring about life-like experiences in telepresence, AR/VR and beyond. Our method models bodies, hands, facial expressions and appearance in a holistic fashion and can be learned from either full 3D scans or RGB-D data. To achieve this, we propose a part-aware learned forward skinning module that can be driven by the parameter space of SMPL-X, allowing for expressive animation of X-Avatars. To efficiently learn the neural shape and deformation fields, we propose novel part-aware sampling and initialization strategies. This leads to higher fidelity results, especially for smaller body parts while maintaining efficient training despite increased number of articulated bones. To capture the appearance of the avatar with high-frequency details, we extend the geometry and deformation fields with a texture network that is conditioned on pose, facial expression, geometry and the normals of the deformed surface. We show experimentally that our method outperforms strong baselines in both data domains both quantitatively and qualitatively on the animation task. To facilitate future research on expressive avatars we contribute a new dataset, called X-Humans, containing 233 sequences of high-quality textured scans from 20 participants, totalling 35,500 data frames.","link":"http://arxiv.org/abs/2303.04805v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"X-Avatar: Expressive Human Avatars We present X-Avatar, a novel avatar model that captures the full expressiveness of digital humans to bring about life-like experiences in telepresence, AR/VR and beyond. Our method models bodies, hands, facial expressions and appearance in a holistic fashion and can be learned from either full 3D scans or RGB-D data. To achieve this, we propose a part-aware learned forward skinning module that can be driven by the parameter space of SMPL-X, allowing for expressive animation of X-Avatars. To efficiently learn the neural shape and deformation fields, we propose novel part-aware sampling and initialization strategies. This leads to higher fidelity results, especially for smaller body parts while maintaining efficient training despite increased number of articulated bones. To capture the appearance of the avatar with high-frequency details, we extend the geometry and deformation fields with a texture network that is conditioned on pose, facial expression, geometry and the normals of the deformed surface. We show experimentally that our method outperforms strong baselines in both data domains both quantitatively and qualitatively on the animation task. To facilitate future research on expressive avatars we contribute a new dataset, called X-Humans, containing 233 sequences of high-quality textured scans from 20 participants, totalling 35,500 data frames.","classes":{"dataset":0.4921863079}}
{"title":"Robust Multimodal Fusion for Human Activity Recognition","description":"The proliferation of IoT and mobile devices equipped with heterogeneous sensors has enabled new applications that rely on the fusion of time-series data generated by multiple sensors with different modalities. While there are promising deep neural network architectures for multimodal fusion, their performance falls apart quickly in the presence of consecutive missing data and noise across multiple modalities/sensors, the issues that are prevalent in real-world settings. We propose Centaur, a multimodal fusion model for human activity recognition (HAR) that is robust to these data quality issues. Centaur combines a data cleaning module, which is a denoising autoencoder with convolutional layers, and a multimodal fusion module, which is a deep convolutional neural network with the self-attention mechanism to capture cross-sensor correlation. We train Centaur using a stochastic data corruption scheme and evaluate it on three datasets that contain data generated by multiple inertial measurement units. Centaur's data cleaning module outperforms 2 state-of-the-art autoencoder-based models and its multimodal fusion module outperforms 4 strong baselines. Compared to 2 related robust fusion architectures, Centaur is more robust, achieving 11.59-17.52% higher accuracy in HAR, especially in the presence of consecutive missing data in multiple sensor channels.","link":"http://arxiv.org/abs/2303.04636v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Robust Multimodal Fusion for Human Activity Recognition The proliferation of IoT and mobile devices equipped with heterogeneous sensors has enabled new applications that rely on the fusion of time-series data generated by multiple sensors with different modalities. While there are promising deep neural network architectures for multimodal fusion, their performance falls apart quickly in the presence of consecutive missing data and noise across multiple modalities/sensors, the issues that are prevalent in real-world settings. We propose Centaur, a multimodal fusion model for human activity recognition (HAR) that is robust to these data quality issues. Centaur combines a data cleaning module, which is a denoising autoencoder with convolutional layers, and a multimodal fusion module, which is a deep convolutional neural network with the self-attention mechanism to capture cross-sensor correlation. We train Centaur using a stochastic data corruption scheme and evaluate it on three datasets that contain data generated by multiple inertial measurement units. Centaur's data cleaning module outperforms 2 state-of-the-art autoencoder-based models and its multimodal fusion module outperforms 4 strong baselines. Compared to 2 related robust fusion architectures, Centaur is more robust, achieving 11.59-17.52% higher accuracy in HAR, especially in the presence of consecutive missing data in multiple sensor channels.","classes":{"dataset":0.2793171406}}
{"title":"Transformer-based Image Generation from Scene Graphs","description":"Graph-structured scene descriptions can be efficiently used in generative models to control the composition of the generated image. Previous approaches are based on the combination of graph convolutional networks and adversarial methods for layout prediction and image generation, respectively. In this work, we show how employing multi-head attention to encode the graph information, as well as using a transformer-based model in the latent space for image generation can improve the quality of the sampled data, without the need to employ adversarial models with the subsequent advantage in terms of training stability. The proposed approach, specifically, is entirely based on transformer architectures both for encoding scene graphs into intermediate object layouts and for decoding these layouts into images, passing through a lower dimensional space learned by a vector-quantized variational autoencoder. Our approach shows an improved image quality with respect to state-of-the-art methods as well as a higher degree of diversity among multiple generations from the same scene graph. We evaluate our approach on three public datasets: Visual Genome, COCO, and CLEVR. We achieve an Inception Score of 13.7 and 12.8, and an FID of 52.3 and 60.3, on COCO and Visual Genome, respectively. We perform ablation studies on our contributions to assess the impact of each component. Code is available at https://github.com/perceivelab/trf-sg2im","link":"http://arxiv.org/abs/2303.04634v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Transformer-based Image Generation from Scene Graphs Graph-structured scene descriptions can be efficiently used in generative models to control the composition of the generated image. Previous approaches are based on the combination of graph convolutional networks and adversarial methods for layout prediction and image generation, respectively. In this work, we show how employing multi-head attention to encode the graph information, as well as using a transformer-based model in the latent space for image generation can improve the quality of the sampled data, without the need to employ adversarial models with the subsequent advantage in terms of training stability. The proposed approach, specifically, is entirely based on transformer architectures both for encoding scene graphs into intermediate object layouts and for decoding these layouts into images, passing through a lower dimensional space learned by a vector-quantized variational autoencoder. Our approach shows an improved image quality with respect to state-of-the-art methods as well as a higher degree of diversity among multiple generations from the same scene graph. We evaluate our approach on three public datasets: Visual Genome, COCO, and CLEVR. We achieve an Inception Score of 13.7 and 12.8, and an FID of 52.3 and 60.3, on COCO and Visual Genome, respectively. We perform ablation studies on our contributions to assess the impact of each component. Code is available at https://github.com/perceivelab/trf-sg2im","classes":{"dataset":0.16928038}}
{"title":"New Audio Representations Image Gan Generation from BriVL","description":"Recently, researchers have gradually realized that in some cases, the self-supervised pre-training on large-scale Internet data is better than that of high-quality/manually labeled data sets, and multimodal/large models are better than single or bimodal/small models. In this paper, we propose a robust audio representation learning method WavBriVL based on Bridging-Vision-and-Language (BriVL). WavBriVL projects audio, image and text into a shared embedded space, so that multi-modal applications can be realized. We demonstrate the qualitative evaluation of the image generated from WavBriVL as a shared embedded space, with the main purposes of this paper: (1) Learning the correlation between audio and image; (2) Explore a new way of image generation, that is, use audio to generate pictures. Experimental results show that this method can effectively generate appropriate images from audio.","link":"http://arxiv.org/abs/2303.04585v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"New Audio Representations Image Gan Generation from BriVL Recently, researchers have gradually realized that in some cases, the self-supervised pre-training on large-scale Internet data is better than that of high-quality/manually labeled data sets, and multimodal/large models are better than single or bimodal/small models. In this paper, we propose a robust audio representation learning method WavBriVL based on Bridging-Vision-and-Language (BriVL). WavBriVL projects audio, image and text into a shared embedded space, so that multi-modal applications can be realized. We demonstrate the qualitative evaluation of the image generated from WavBriVL as a shared embedded space, with the main purposes of this paper: (1) Learning the correlation between audio and image; (2) Explore a new way of image generation, that is, use audio to generate pictures. Experimental results show that this method can effectively generate appropriate images from audio.","classes":{"dataset":0.3703104258}}
{"title":"Student's t-Distribution: On Measuring the Inter-Rater Reliability When the Observations are Scarce","description":"In natural language processing (NLP) we always rely on human judgement as the golden quality evaluation method. However, there has been an ongoing debate on how to better evaluate inter-rater reliability (IRR) levels for certain evaluation tasks, such as translation quality evaluation (TQE), especially when the data samples (observations) are very scarce. In this work, we first introduce the study on how to estimate the confidence interval for the measurement value when only one data (evaluation) point is available. Then, this leads to our example with two human-generated observational scores, for which, we introduce ``Student's \\textit{t}-Distribution'' method and explain how to use it to measure the IRR score using only these two data points, as well as the confidence intervals (CIs) of the quality evaluation. We give quantitative analysis on how the evaluation confidence can be greatly improved by introducing more observations, even if only one extra observation. We encourage researchers to report their IRR scores in all possible means, e.g. using Student's \\textit{t}-Distribution method whenever possible; thus making the NLP evaluation more meaningful, transparent, and trustworthy. This \\textit{t}-Distribution method can be also used outside of NLP fields to measure IRR level for trustworthy evaluation of experimental investigations, whenever the observational data is scarce.   Keywords: Inter-Rater Reliability (IRR); Scarce Observations; Confidence Intervals (CIs); Natural Language Processing (NLP); Translation Quality Evaluation (TQE); Student's \\textit{t}-Distribution","link":"http://arxiv.org/abs/2303.04526v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Student's t-Distribution: On Measuring the Inter-Rater Reliability When the Observations are Scarce In natural language processing (NLP) we always rely on human judgement as the golden quality evaluation method. However, there has been an ongoing debate on how to better evaluate inter-rater reliability (IRR) levels for certain evaluation tasks, such as translation quality evaluation (TQE), especially when the data samples (observations) are very scarce. In this work, we first introduce the study on how to estimate the confidence interval for the measurement value when only one data (evaluation) point is available. Then, this leads to our example with two human-generated observational scores, for which, we introduce ``Student's \\textit{t}-Distribution'' method and explain how to use it to measure the IRR score using only these two data points, as well as the confidence intervals (CIs) of the quality evaluation. We give quantitative analysis on how the evaluation confidence can be greatly improved by introducing more observations, even if only one extra observation. We encourage researchers to report their IRR scores in all possible means, e.g. using Student's \\textit{t}-Distribution method whenever possible; thus making the NLP evaluation more meaningful, transparent, and trustworthy. This \\textit{t}-Distribution method can be also used outside of NLP fields to measure IRR level for trustworthy evaluation of experimental investigations, whenever the observational data is scarce.   Keywords: Inter-Rater Reliability (IRR); Scarce Observations; Confidence Intervals (CIs); Natural Language Processing (NLP); Translation Quality Evaluation (TQE); Student's \\textit{t}-Distribution","classes":{"dataset":0.2011269182}}
{"title":"Inference on Optimal Dynamic Policies via Softmax Approximation","description":"Estimating optimal dynamic policies from offline data is a fundamental problem in dynamic decision making. In the context of causal inference, the problem is known as estimating the optimal dynamic treatment regime. Even though there exists a plethora of methods for estimation, constructing confidence intervals for the value of the optimal regime and structural parameters associated with it is inherently harder, as it involves non-linear and non-differentiable functionals of un-known quantities that need to be estimated. Prior work resorted to sub-sample approaches that can deteriorate the quality of the estimate. We show that a simple soft-max approximation to the optimal treatment regime, for an appropriately fast growing temperature parameter, can achieve valid inference on the truly optimal regime. We illustrate our result for a two-period optimal dynamic regime, though our approach should directly extend to the finite horizon case. Our work combines techniques from semi-parametric inference and $g$-estimation, together with an appropriate triangular array central limit theorem, as well as a novel analysis of the asymptotic influence and asymptotic bias of softmax approximations.","link":"http://arxiv.org/abs/2303.04416v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Inference on Optimal Dynamic Policies via Softmax Approximation Estimating optimal dynamic policies from offline data is a fundamental problem in dynamic decision making. In the context of causal inference, the problem is known as estimating the optimal dynamic treatment regime. Even though there exists a plethora of methods for estimation, constructing confidence intervals for the value of the optimal regime and structural parameters associated with it is inherently harder, as it involves non-linear and non-differentiable functionals of un-known quantities that need to be estimated. Prior work resorted to sub-sample approaches that can deteriorate the quality of the estimate. We show that a simple soft-max approximation to the optimal treatment regime, for an appropriately fast growing temperature parameter, can achieve valid inference on the truly optimal regime. We illustrate our result for a two-period optimal dynamic regime, though our approach should directly extend to the finite horizon case. Our work combines techniques from semi-parametric inference and $g$-estimation, together with an appropriate triangular array central limit theorem, as well as a novel analysis of the asymptotic influence and asymptotic bias of softmax approximations.","classes":{"dataset":0.0249025207}}
{"title":"ElC-OIS: Ellipsoidal Clustering for Open-World Instance Segmentation on LiDAR Data","description":"Open-world Instance Segmentation (OIS) is a challenging task that aims to accurately segment every object instance appearing in the current observation, regardless of whether these instances have been labeled in the training set. This is important for safety-critical applications such as robust autonomous navigation. In this paper, we present a flexible and effective OIS framework for LiDAR point cloud that can accurately segment both known and unknown instances (i.e., seen and unseen instance categories during training). It first identifies points belonging to known classes and removes the background by leveraging close-set panoptic segmentation networks. Then, we propose a novel ellipsoidal clustering method that is more adapted to the characteristic of LiDAR scans and allows precise segmentation of unknown instances. Furthermore, a diffuse searching method is proposed to handle the common over-segmentation problem presented in the known instances. With the combination of these techniques, we are able to achieve accurate segmentation for both known and unknown instances. We evaluated our method on the SemanticKITTI open-world LiDAR instance segmentation dataset. The experimental results suggest that it outperforms current state-of-the-art methods, especially with a 10.0% improvement in association quality. The source code of our method will be publicly available at https://github.com/nubot-nudt/ElC-OIS.","link":"http://arxiv.org/abs/2303.04351v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"ElC-OIS: Ellipsoidal Clustering for Open-World Instance Segmentation on LiDAR Data Open-world Instance Segmentation (OIS) is a challenging task that aims to accurately segment every object instance appearing in the current observation, regardless of whether these instances have been labeled in the training set. This is important for safety-critical applications such as robust autonomous navigation. In this paper, we present a flexible and effective OIS framework for LiDAR point cloud that can accurately segment both known and unknown instances (i.e., seen and unseen instance categories during training). It first identifies points belonging to known classes and removes the background by leveraging close-set panoptic segmentation networks. Then, we propose a novel ellipsoidal clustering method that is more adapted to the characteristic of LiDAR scans and allows precise segmentation of unknown instances. Furthermore, a diffuse searching method is proposed to handle the common over-segmentation problem presented in the known instances. With the combination of these techniques, we are able to achieve accurate segmentation for both known and unknown instances. We evaluated our method on the SemanticKITTI open-world LiDAR instance segmentation dataset. The experimental results suggest that it outperforms current state-of-the-art methods, especially with a 10.0% improvement in association quality. The source code of our method will be publicly available at https://github.com/nubot-nudt/ElC-OIS.","classes":{"dataset":0.1057908684}}
{"title":"DroNeRF: Real-time Multi-agent Drone Pose Optimization for Computing Neural Radiance Fields","description":"We present a novel optimization algorithm called DroNeRF for the autonomous positioning of monocular camera drones around an object for real-time 3D reconstruction using only a few images. Neural Radiance Fields or NeRF, is a novel view synthesis technique used to generate new views of an object or scene from a set of input images. Using drones in conjunction with NeRF provides a unique and dynamic way to generate novel views of a scene, especially with limited scene capabilities of restricted movements. Our approach focuses on calculating optimized pose for individual drones while solely depending on the object geometry without using any external localization system. The unique camera positioning during the data-capturing phase significantly impacts the quality of the 3D model. To evaluate the quality of our generated novel views, we compute different perceptual metrics like the Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure(SSIM). Our work demonstrates the benefit of using an optimal placement of various drones with limited mobility to generate perceptually better results.","link":"http://arxiv.org/abs/2303.04322v1","created":"2023-03-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"DroNeRF: Real-time Multi-agent Drone Pose Optimization for Computing Neural Radiance Fields We present a novel optimization algorithm called DroNeRF for the autonomous positioning of monocular camera drones around an object for real-time 3D reconstruction using only a few images. Neural Radiance Fields or NeRF, is a novel view synthesis technique used to generate new views of an object or scene from a set of input images. Using drones in conjunction with NeRF provides a unique and dynamic way to generate novel views of a scene, especially with limited scene capabilities of restricted movements. Our approach focuses on calculating optimized pose for individual drones while solely depending on the object geometry without using any external localization system. The unique camera positioning during the data-capturing phase significantly impacts the quality of the 3D model. To evaluate the quality of our generated novel views, we compute different perceptual metrics like the Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure(SSIM). Our work demonstrates the benefit of using an optimal placement of various drones with limited mobility to generate perceptually better results.","classes":{"dataset":0.0743013993}}
{"title":"Lisp-powered laptop with a battery life measured in years","description":"https://www.hackster.io/news/andreas-eriksen-s-potatop-is-a-lisp-powered-laptop-with-a-battery-life-measured-in-years-2f5d79653f24","link":"https://www.hackster.io/news/andreas-eriksen-s-potatop-is-a-lisp-powered-laptop-with-a-battery-life-measured-in-years-2f5d79653f24","created":"2023-03-08","tags":["hackernews"],"meta":{"score":644},"text":"Lisp-powered laptop with a battery life measured in years https://www.hackster.io/news/andreas-eriksen-s-potatop-is-a-lisp-powered-laptop-with-a-battery-life-measured-in-years-2f5d79653f24","classes":{"dataset":0.5095204711}}
{"title":"OpenXLA Is Available Now","description":"https://opensource.googleblog.com/2023/03/openxla-is-ready-to-accelerate-and-simplify-ml-development.html","link":"https://opensource.googleblog.com/2023/03/openxla-is-ready-to-accelerate-and-simplify-ml-development.html","created":"2023-03-09","tags":["hackernews"],"meta":{"score":126},"text":"OpenXLA Is Available Now https://opensource.googleblog.com/2023/03/openxla-is-ready-to-accelerate-and-simplify-ml-development.html","classes":{"dataset":0.5062924027}}
{"title":"Show HN: BBC \u201cIn Our Time\u201d, categorised by Dewey Decimal, heavy lifting by GPT","description":"https://genmon.github.io/braggoscope/","link":"https://genmon.github.io/braggoscope/","created":"2023-03-08","tags":["hackernews"],"meta":{"score":593},"text":"Show HN: BBC \u201cIn Our Time\u201d, categorised by Dewey Decimal, heavy lifting by GPT https://genmon.github.io/braggoscope/","classes":{"dataset":0.4983798563}}
{"title":"Control Mario Kart 64 with your car over CAN bus (2016)","description":"https://github.com/DanH42/CatchMeIfYouCAN","link":"https://github.com/DanH42/CatchMeIfYouCAN","created":"2023-03-09","tags":["hackernews"],"meta":{"score":153},"text":"Control Mario Kart 64 with your car over CAN bus (2016) https://github.com/DanH42/CatchMeIfYouCAN","classes":{"dataset":0.51005584}}
{"title":"Leveraging Rust and the GPU to render user interfaces at 120 FPS","description":"https://zed.dev/blog/videogame","link":"https://zed.dev/blog/videogame","created":"2023-03-09","tags":["hackernews"],"meta":{"score":94},"text":"Leveraging Rust and the GPU to render user interfaces at 120 FPS https://zed.dev/blog/videogame","classes":{"dataset":0.4942406416}}
{"title":"Show HN: Lofi, a Tiny Spotify Player","description":"https://github.com/dvx/lofi","link":"https://github.com/dvx/lofi","created":"2023-03-09","tags":["hackernews"],"meta":{"score":17},"text":"Show HN: Lofi, a Tiny Spotify Player https://github.com/dvx/lofi","classes":{"dataset":0.4659482539}}
{"title":"Audio engineer explains NPR's signature sound (2015)","description":"https://current.org/2015/06/a-top-audio-engineer-explains-nprs-signature-sound/","link":"https://current.org/2015/06/a-top-audio-engineer-explains-nprs-signature-sound/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":185},"text":"Audio engineer explains NPR's signature sound (2015) https://current.org/2015/06/a-top-audio-engineer-explains-nprs-signature-sound/","classes":{"dataset":0.5530340075}}
{"title":"Building big systems with remote hardware teams","description":"https://oxide.computer/blog/building-big-systems-with-remote-hardware-teams","link":"https://oxide.computer/blog/building-big-systems-with-remote-hardware-teams","created":"2023-03-08","tags":["hackernews"],"meta":{"score":58},"text":"Building big systems with remote hardware teams https://oxide.computer/blog/building-big-systems-with-remote-hardware-teams","classes":{"dataset":0.507349968}}
{"title":"The FBI Just Admitted It Bought US Location Data","description":"https://www.wired.com/story/fbi-purchase-location-data-wray-senate/","link":"https://www.wired.com/story/fbi-purchase-location-data-wray-senate/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":120},"text":"The FBI Just Admitted It Bought US Location Data https://www.wired.com/story/fbi-purchase-location-data-wray-senate/","classes":{"dataset":0.507349968}}
{"title":"Show HN: CodeGPT.nvim \u2013 ChatGPT plugin for Neovim","description":"https://github.com/dpayne/CodeGPT.nvim","link":"https://github.com/dpayne/CodeGPT.nvim","created":"2023-03-08","tags":["hackernews"],"meta":{"score":206},"text":"Show HN: CodeGPT.nvim \u2013 ChatGPT plugin for Neovim https://github.com/dpayne/CodeGPT.nvim","classes":{"dataset":0.5317733884}}
{"title":"Code coverage for Go integration tests","description":"https://go.dev/blog/integration-test-coverage","link":"https://go.dev/blog/integration-test-coverage","created":"2023-03-08","tags":["hackernews"],"meta":{"score":152},"text":"Code coverage for Go integration tests https://go.dev/blog/integration-test-coverage","classes":{"dataset":0.5587186217}}
{"title":"A Pixel Is Not a Little Square (1995) [pdf]","description":"http://alvyray.com/Memos/CG/Microsoft/6_pixel.pdf","link":"http://alvyray.com/Memos/CG/Microsoft/6_pixel.pdf","created":"2023-03-09","tags":["hackernews"],"meta":{"score":56},"text":"A Pixel Is Not a Little Square (1995) [pdf] http://alvyray.com/Memos/CG/Microsoft/6_pixel.pdf","classes":{"dataset":0.5092043877}}
{"title":"SWAR: Find any byte from set","description":"http://0x80.pl/notesen/2023-03-06-swar-find-any.html","link":"http://0x80.pl/notesen/2023-03-06-swar-find-any.html","created":"2023-03-07","tags":["hackernews"],"meta":{"score":70},"text":"SWAR: Find any byte from set http://0x80.pl/notesen/2023-03-06-swar-find-any.html","classes":{"dataset":0.5316089988}}
{"title":"GDevelop: An open-source, cross-platform, free, and easy game-making app","description":"https://gdevelop.io/","link":"https://gdevelop.io/","created":"2023-03-08","tags":["hackernews"],"meta":{"score":92},"text":"GDevelop: An open-source, cross-platform, free, and easy game-making app https://gdevelop.io/","classes":{"dataset":0.5134937167}}
{"title":"Disclosure: Supervisor security vulnerability","description":"https://www.home-assistant.io/blog/2023/03/08/supervisor-security-disclosure/","link":"https://www.home-assistant.io/blog/2023/03/08/supervisor-security-disclosure/","created":"2023-03-08","tags":["hackernews"],"meta":{"score":55},"text":"Disclosure: Supervisor security vulnerability https://www.home-assistant.io/blog/2023/03/08/supervisor-security-disclosure/","classes":{"dataset":0.4493428767}}
{"title":"The apps that Americans search to \u201cdelete\u201d the most","description":"https://vpnoverview.com/privacy/apps/most-deleted-apps-in-united-states/","link":"https://vpnoverview.com/privacy/apps/most-deleted-apps-in-united-states/","created":"2023-03-08","tags":["hackernews"],"meta":{"score":272},"text":"The apps that Americans search to \u201cdelete\u201d the most https://vpnoverview.com/privacy/apps/most-deleted-apps-in-united-states/","classes":{"dataset":0.4772305191}}
{"title":"Olympia Musicwriter","description":"https://musicprintinghistory.org/musicwriter/","link":"https://musicprintinghistory.org/musicwriter/","created":"2023-03-06","tags":["hackernews"],"meta":{"score":65},"text":"Olympia Musicwriter https://musicprintinghistory.org/musicwriter/","classes":{"dataset":0.5199674964}}
{"title":"Google Groups has been left to die","description":"https://ahelwer.ca/post/2023-03-08-google-groups/","link":"https://ahelwer.ca/post/2023-03-08-google-groups/","created":"2023-03-08","tags":["hackernews"],"meta":{"score":469},"text":"Google Groups has been left to die https://ahelwer.ca/post/2023-03-08-google-groups/","classes":{"dataset":0.5352596045}}
{"title":"FTC bars GoodRx from sharing consumers\u2019 sensitive health info for advertising","description":"https://www.ftc.gov/news-events/news/press-releases/2023/02/ftc-enforcement-action-bar-goodrx-sharing-consumers-sensitive-health-info-advertising","link":"https://www.ftc.gov/news-events/news/press-releases/2023/02/ftc-enforcement-action-bar-goodrx-sharing-consumers-sensitive-health-info-advertising","created":"2023-03-08","tags":["hackernews"],"meta":{"score":227},"text":"FTC bars GoodRx from sharing consumers\u2019 sensitive health info for advertising https://www.ftc.gov/news-events/news/press-releases/2023/02/ftc-enforcement-action-bar-goodrx-sharing-consumers-sensitive-health-info-advertising","classes":{"dataset":0.4956197441}}
{"title":"Lessons learned from 15 years of SumatraPDF, an open source Windows app (2021)","description":"https://blog.kowalczyk.info/article/2f72237a4230410a888acbfce3dc0864/lessons-learned-from-15-years-of-sumatrapdf-an-open-source-windows-app.html","link":"https://blog.kowalczyk.info/article/2f72237a4230410a888acbfce3dc0864/lessons-learned-from-15-years-of-sumatrapdf-an-open-source-windows-app.html","created":"2023-03-08","tags":["hackernews"],"meta":{"score":529},"text":"Lessons learned from 15 years of SumatraPDF, an open source Windows app (2021) https://blog.kowalczyk.info/article/2f72237a4230410a888acbfce3dc0864/lessons-learned-from-15-years-of-sumatrapdf-an-open-source-windows-app.html","classes":{"dataset":0.500867784}}
{"title":"Surrealists in New York: Atelier 17 and the Birth of Abstract Expressionism","description":"https://literaryreview.co.uk/drippers-printmakers","link":"https://literaryreview.co.uk/drippers-printmakers","created":"2023-03-06","tags":["hackernews"],"meta":{"score":33},"text":"Surrealists in New York: Atelier 17 and the Birth of Abstract Expressionism https://literaryreview.co.uk/drippers-printmakers","classes":{"dataset":0.5265814066}}
{"title":"AI is making it easier to create more noise, when all I want is good search","description":"https://rachsmith.com/i-want-good-search/","link":"https://rachsmith.com/i-want-good-search/","created":"2023-03-08","tags":["hackernews"],"meta":{"score":506},"text":"AI is making it easier to create more noise, when all I want is good search https://rachsmith.com/i-want-good-search/","classes":{"dataset":0.507349968}}
{"title":"Amazon owe me \u00a353,000 and refuse to trace the funds","description":"https://old.reddit.com/r/LegalAdviceUK/comments/11lwfbr/amazon_owe_me_53000_refuse_to_trace_the_funds/","link":"https://old.reddit.com/r/LegalAdviceUK/comments/11lwfbr/amazon_owe_me_53000_refuse_to_trace_the_funds/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":71},"text":"Amazon owe me \u00a353,000 and refuse to trace the funds https://old.reddit.com/r/LegalAdviceUK/comments/11lwfbr/amazon_owe_me_53000_refuse_to_trace_the_funds/","classes":{"dataset":0.5218643546}}
{"title":"New estimate for high-speed rail puts California train $100B in the red","description":"https://calmatters.org/transportation/2023/03/california-high-speed-rail/","link":"https://calmatters.org/transportation/2023/03/california-high-speed-rail/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":30},"text":"New estimate for high-speed rail puts California train $100B in the red https://calmatters.org/transportation/2023/03/california-high-speed-rail/","classes":{"dataset":0.5148474574}}
{"title":"Governments should compete for residents, not businesses","description":"https://www.bloomberg.com/opinion/articles/2023-03-07/amazon-hq2-pause-could-be-a-sign-of-a-new-era-for-development","link":"https://www.bloomberg.com/opinion/articles/2023-03-07/amazon-hq2-pause-could-be-a-sign-of-a-new-era-for-development","created":"2023-03-08","tags":["hackernews"],"meta":{"score":315},"text":"Governments should compete for residents, not businesses https://www.bloomberg.com/opinion/articles/2023-03-07/amazon-hq2-pause-could-be-a-sign-of-a-new-era-for-development","classes":{"dataset":0.5216265917}}
{"title":"Loom: Cache configuration change leading to account vulnerability","description":"https://www.loom.com/blog/march-7-incident-update","link":"https://www.loom.com/blog/march-7-incident-update","created":"2023-03-09","tags":["hackernews"],"meta":{"score":10},"text":"Loom: Cache configuration change leading to account vulnerability https://www.loom.com/blog/march-7-incident-update","classes":{"dataset":0.5052932501}}
{"title":"React is holding me hostage","description":"https://emnudge.dev/blog/react-hostage","link":"https://emnudge.dev/blog/react-hostage","created":"2023-03-07","tags":["hackernews"],"meta":{"score":421},"text":"React is holding me hostage https://emnudge.dev/blog/react-hostage","classes":{"dataset":0.5091817975}}
{"title":"Intel tapes out chips on 1.8nm and 2nm production nodes","description":"https://www.tomshardware.com/news/intel-completes-development-of-18a-20a-nodes","link":"https://www.tomshardware.com/news/intel-completes-development-of-18a-20a-nodes","created":"2023-03-08","tags":["hackernews"],"meta":{"score":137},"text":"Intel tapes out chips on 1.8nm and 2nm production nodes https://www.tomshardware.com/news/intel-completes-development-of-18a-20a-nodes","classes":{"dataset":0.5006542802}}
{"title":"Fork of Facebook\u2019s LLaMa model to run on CPU","description":"https://github.com/markasoftware/llama-cpu","link":"https://github.com/markasoftware/llama-cpu","created":"2023-03-08","tags":["hackernews"],"meta":{"score":229},"text":"Fork of Facebook\u2019s LLaMa model to run on CPU https://github.com/markasoftware/llama-cpu","classes":{"dataset":0.5012196302}}
{"title":"How 16 Companies Are Dominating the World\u2019s Google Search Results","description":"https://detailed.com/google-control/","link":"https://detailed.com/google-control/","created":"2023-03-08","tags":["hackernews"],"meta":{"score":25},"text":"How 16 Companies Are Dominating the World\u2019s Google Search Results https://detailed.com/google-control/","classes":{"dataset":0.4724443853}}
{"title":"The Office as Architectural Touchstone (2008)","description":"https://www.nytimes.com/2008/03/02/nyregion/nyregionspecial2/02Rlandmark.html","link":"https://www.nytimes.com/2008/03/02/nyregion/nyregionspecial2/02Rlandmark.html","created":"2023-03-06","tags":["hackernews"],"meta":{"score":15},"text":"The Office as Architectural Touchstone (2008) https://www.nytimes.com/2008/03/02/nyregion/nyregionspecial2/02Rlandmark.html","classes":{"dataset":0.5510987639}}
{"title":"The decline of net neutrality activism","description":"https://neelc.org/posts/net-neutrality-activism/","link":"https://neelc.org/posts/net-neutrality-activism/","created":"2023-03-07","tags":["hackernews"],"meta":{"score":317},"text":"The decline of net neutrality activism https://neelc.org/posts/net-neutrality-activism/","classes":{"dataset":0.4961197376}}
{"title":"Truck: CAD Kernel in Rust","description":"https://github.com/ricosjp/truck","link":"https://github.com/ricosjp/truck","created":"2023-03-08","tags":["hackernews"],"meta":{"score":83},"text":"Truck: CAD Kernel in Rust https://github.com/ricosjp/truck","classes":{"dataset":0.5251471996}}
{"title":"Show HN: SearQ - A REST API that allows users to search from RSS feeds","description":"https://searq.org","link":"https://searq.org","created":"2023-03-08","tags":["hackernews"],"meta":{"score":27},"text":"Show HN: SearQ - A REST API that allows users to search from RSS feeds https://searq.org","classes":{"dataset":0.4907017946}}
{"title":"Appler: Apple ][ emulator for IBM PC, written in 8088 assembly","description":"https://github.com/zajo/appler","link":"https://github.com/zajo/appler","created":"2023-03-08","tags":["hackernews"],"meta":{"score":167},"text":"Appler: Apple ][ emulator for IBM PC, written in 8088 assembly https://github.com/zajo/appler","classes":{"dataset":0.5002260804}}
{"title":"Reliability: It\u2019s not great","description":"https://community.fly.io/t/reliability-its-not-great/11253","link":"https://community.fly.io/t/reliability-its-not-great/11253","created":"2023-03-06","tags":["hackernews"],"meta":{"score":1195},"text":"Reliability: It\u2019s not great https://community.fly.io/t/reliability-its-not-great/11253","classes":{"dataset":0.4496575594}}
{"title":"FBI chief says TikTok 'screams' of US national security concerns","description":"https://www.reuters.com/technology/fbi-chief-says-tiktok-screams-us-national-security-concerns-2023-03-08/","link":"https://www.reuters.com/technology/fbi-chief-says-tiktok-screams-us-national-security-concerns-2023-03-08/","created":"2023-03-08","tags":["hackernews"],"meta":{"score":107},"text":"FBI chief says TikTok 'screams' of US national security concerns https://www.reuters.com/technology/fbi-chief-says-tiktok-screams-us-national-security-concerns-2023-03-08/","classes":{"dataset":0.4958311915}}
{"title":"Signal K \u2013 open-source universal marine data exchange format","description":"https://signalk.org/","link":"https://signalk.org/","created":"2023-03-08","tags":["hackernews"],"meta":{"score":78},"text":"Signal K \u2013 open-source universal marine data exchange format https://signalk.org/","classes":{"dataset":0.507349968}}
{"title":"5.2% pay raise proposal for federal employees in 2024","description":"https://www.washingtonpost.com/politics/2023/03/08/federal-pay-boost-biden-budget-2023/","link":"https://www.washingtonpost.com/politics/2023/03/08/federal-pay-boost-biden-budget-2023/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":27},"text":"5.2% pay raise proposal for federal employees in 2024 https://www.washingtonpost.com/politics/2023/03/08/federal-pay-boost-biden-budget-2023/","classes":{"dataset":0.505058527}}
{"title":"SlidesGPT \u2013 ChatGPT for Slides","description":"https://slidesgpt.com/?new","link":"https://slidesgpt.com/?new","created":"2023-03-08","tags":["hackernews"],"meta":{"score":39},"text":"SlidesGPT \u2013 ChatGPT for Slides https://slidesgpt.com/?new","classes":{"dataset":0.5012045503}}
{"title":"Show HN: Construct Animate \u2013 our new browser-based animation tool","description":"https://www.construct.net/en/blogs/construct-official-blog-1/launching-construct-animate-1612","link":"https://www.construct.net/en/blogs/construct-official-blog-1/launching-construct-animate-1612","created":"2023-03-08","tags":["hackernews"],"meta":{"score":158},"text":"Show HN: Construct Animate \u2013 our new browser-based animation tool https://www.construct.net/en/blogs/construct-official-blog-1/launching-construct-animate-1612","classes":{"dataset":0.5159300566}}
{"title":"Pentax 645 [pdf]","description":"https://ianbfoto.com/downloads/Brochures/Pentax%20645%20Brochure.pdf","link":"https://ianbfoto.com/downloads/Brochures/Pentax%20645%20Brochure.pdf","created":"2023-03-06","tags":["hackernews"],"meta":{"score":52},"text":"Pentax 645 [pdf] https://ianbfoto.com/downloads/Brochures/Pentax%20645%20Brochure.pdf","classes":{"dataset":0.4970846772}}
{"title":"Researchers develop blood test for anxiety","description":"https://www.sciencedaily.com/releases/2023/03/230307143746.htm","link":"https://www.sciencedaily.com/releases/2023/03/230307143746.htm","created":"2023-03-08","tags":["hackernews"],"meta":{"score":87},"text":"Researchers develop blood test for anxiety https://www.sciencedaily.com/releases/2023/03/230307143746.htm","classes":{"dataset":0.4912294149}}
{"title":"Discord may record video and voice calls","description":"https://twitter.com/bizmuths/status/1633098341578940417","link":"https://twitter.com/bizmuths/status/1633098341578940417","created":"2023-03-08","tags":["hackernews"],"meta":{"score":38},"text":"Discord may record video and voice calls https://twitter.com/bizmuths/status/1633098341578940417","classes":{"dataset":0.5199252367}}
{"title":"Slightly Intelligent Home","description":"https://blog.gabrielsimmer.com/posts/slightly-intelligent-home/","link":"https://blog.gabrielsimmer.com/posts/slightly-intelligent-home/","created":"2023-03-06","tags":["hackernews"],"meta":{"score":52},"text":"Slightly Intelligent Home https://blog.gabrielsimmer.com/posts/slightly-intelligent-home/","classes":{"dataset":0.4759534299}}
{"title":"Sharing a tool I am creating to fine-tune a model using reddit data.","description":"So as my billionth side project, I decided to create a web-app that scrapes data from reddit and generates a text file that can be used to fine-tune an openAI model such as davinci-003.  I would love to find people to critique this project and contribute to it.\n\n[here](https://platform.openai.com/docs/guides/fine-tuning) is a link for instructions on how to fine tune a model.  When it comes to the step called **prepare training data** I wanted to sort of automate this by allowing the user to get a bunch of prompts/completions from reddit.  I created an app that generates a jsonl file for fine-tuning using the submission title as the prompt and the submission body and/or comments as the completion.  Let me know if this is something people are interested in collaborating on or if there are other people doing similar things.\n\nLink to my app: [https://fine-tune-reddit.herokuapp.com/](https://fine-tune-reddit.herokuapp.com/)\n\nLink to the CLI project on github: [https://github.com/brianSalk/openai-finetune-reddit](https://github.com/brianSalk/openai-finetune-reddit)\n\nLink to the web-app on github: [https://github.com/brianSalk/reddit-finetune-frontend](https://github.com/brianSalk/reddit-finetune-frontend)","link":"https://www.reddit.com/r/PromptDesign/comments/11lzs34/sharing_a_tool_i_am_creating_to_finetune_a_model/","created":"2023-03-08","tags":["promptdesign","reddit","prompteng"],"meta":{"num_comments":3},"text":"Sharing a tool I am creating to fine-tune a model using reddit data. So as my billionth side project, I decided to create a web-app that scrapes data from reddit and generates a text file that can be used to fine-tune an openAI model such as davinci-003.  I would love to find people to critique this project and contribute to it.\n\n[here](https://platform.openai.com/docs/guides/fine-tuning) is a link for instructions on how to fine tune a model.  When it comes to the step called **prepare training data** I wanted to sort of automate this by allowing the user to get a bunch of prompts/completions from reddit.  I created an app that generates a jsonl file for fine-tuning using the submission title as the prompt and the submission body and/or comments as the completion.  Let me know if this is something people are interested in collaborating on or if there are other people doing similar things.\n\nLink to my app: [https://fine-tune-reddit.herokuapp.com/](https://fine-tune-reddit.herokuapp.com/)\n\nLink to the CLI project on github: [https://github.com/brianSalk/openai-finetune-reddit](https://github.com/brianSalk/openai-finetune-reddit)\n\nLink to the web-app on github: [https://github.com/brianSalk/reddit-finetune-frontend](https://github.com/brianSalk/reddit-finetune-frontend)","classes":{"dataset":0.413720876}}
{"title":"Thursday Daily Thread: Python Careers, Courses, and Furthering Education!","description":"Discussion of using Python in a professional environment, getting jobs in Python as well as ask questions about courses to further your python education!\n\n**This thread is not for recruitment, please see** r/PythonJobs **or the thread in the sidebar for that.**","link":"https://www.reddit.com/r/Python/comments/11mcnzg/thursday_daily_thread_python_careers_courses_and/","created":"2023-03-09","tags":["python","reddit"],"meta":{"num_comments":1},"text":"Thursday Daily Thread: Python Careers, Courses, and Furthering Education! Discussion of using Python in a professional environment, getting jobs in Python as well as ask questions about courses to further your python education!\n\n**This thread is not for recruitment, please see** r/PythonJobs **or the thread in the sidebar for that.**","classes":{"dataset":0.2468641549}}
{"title":"How can I deploy a full Tkinter app with database included?","description":"How to deploy a full desktop app with database ready to install on any pc?","link":"https://www.reddit.com/r/Python/comments/11mfk3l/how_can_i_deploy_a_full_tkinter_app_with_database/","created":"2023-03-09","tags":["python","reddit"],"meta":{"num_comments":10},"text":"How can I deploy a full Tkinter app with database included? How to deploy a full desktop app with database ready to install on any pc?","classes":{"dataset":0.0268946346}}
{"title":"RustPython","description":"I first read about [RustPython](https://github.com/RustPython/RustPython) today and found [this discussion](https://www.reddit.com/r/Python/comments/iirja9/rustpython/?utm_source=share&amp;utm_medium=web2x&amp;context=3) that seems very interesting and still pertinent to the topic. Here's my take on it:\n\nEven though, as mentioned in the original thread, Rust is not a magical solution for anything, I think the language's features that make it less prone to bugs (mainly memory safety, AFAIK) could speed up improvements to Python. This could happen directly, or indirectly by simplifying contributions to the interpreter.\n\nSince the original discussion, the Linux kernel has started taking contributions in Rust. It'll probably be a very long time before the majority of the kernel is in Rust; if it is ever fully converted that will definitively take much longer. But this movement gives Rust a strong vote of credibility, and IMO a confident step in establishing Rust as the successor of C as de facto system language of the day (again, a confident *first* step).\n\nConnecting to the point above about Rust succeeding C, the Rust community seems a lot more prolific than C's while both C and C++ [were reported](https://www.statista.com/statistics/793628/worldwide-developer-survey-most-used-languages/) as being used much more than Rust in 2022. I believe Rust has the qualities to dominate many of the areas C dominates today, but that trend has definitely not materialized yet. If there is indeed a trend of Rust growing more, and if this trend keeps up, an interpreter in Rust could eventually source from a larger pool of developers.\n\nLastly, I think the Rust and Python communities could mingle (e.g. over cherishing a good developer experience) and contribute much to each other in a way that doesn't happen with Python and C where there seems to be a wall imposing that Python is for flexibility and C for performance. This last point seems to me the most important/fruitful, but is also most subjective and sensible to my own biases.\n\nSo I'm curious about the community's feelings on this topic in general, but would also like to suggest the question: How important do you think it would be to have a mature Python interpreter written in Rust 10 years from now?","link":"https://www.reddit.com/r/Python/comments/11m43r5/rustpython/","created":"2023-03-08","tags":["python","reddit"],"meta":{"num_comments":17},"text":"RustPython I first read about [RustPython](https://github.com/RustPython/RustPython) today and found [this discussion](https://www.reddit.com/r/Python/comments/iirja9/rustpython/?utm_source=share&amp;utm_medium=web2x&amp;context=3) that seems very interesting and still pertinent to the topic. Here's my take on it:\n\nEven though, as mentioned in the original thread, Rust is not a magical solution for anything, I think the language's features that make it less prone to bugs (mainly memory safety, AFAIK) could speed up improvements to Python. This could happen directly, or indirectly by simplifying contributions to the interpreter.\n\nSince the original discussion, the Linux kernel has started taking contributions in Rust. It'll probably be a very long time before the majority of the kernel is in Rust; if it is ever fully converted that will definitively take much longer. But this movement gives Rust a strong vote of credibility, and IMO a confident step in establishing Rust as the successor of C as de facto system language of the day (again, a confident *first* step).\n\nConnecting to the point above about Rust succeeding C, the Rust community seems a lot more prolific than C's while both C and C++ [were reported](https://www.statista.com/statistics/793628/worldwide-developer-survey-most-used-languages/) as being used much more than Rust in 2022. I believe Rust has the qualities to dominate many of the areas C dominates today, but that trend has definitely not materialized yet. If there is indeed a trend of Rust growing more, and if this trend keeps up, an interpreter in Rust could eventually source from a larger pool of developers.\n\nLastly, I think the Rust and Python communities could mingle (e.g. over cherishing a good developer experience) and contribute much to each other in a way that doesn't happen with Python and C where there seems to be a wall imposing that Python is for flexibility and C for performance. This last point seems to me the most important/fruitful, but is also most subjective and sensible to my own biases.\n\nSo I'm curious about the community's feelings on this topic in general, but would also like to suggest the question: How important do you think it would be to have a mature Python interpreter written in Rust 10 years from now?","classes":{"dataset":0.4777943194}}
{"title":"can someone help me understand the pulp library and how to solve this problem","description":"i want to find the optimum solution and the pulp library is very complex m getting errors i don't understand and i need help with linearizing my variables thank you in advance \n\nproblem:\n\nA distributor of raw materials for cosmetics wants to improve its cash flows. The considered supply chain contains a single distributor, linked to one or more suppliers. These suppliers deliver the same product, but may have different characteristics, such as production capacity, price demanded, or payment deadline. We are interested in optimizing the physical and financial flows of the distributor. Cash constraints sometimes prevent it from carrying out its procurement activities optimally. A lack of liquidity can hinder the normal course of business. Sometimes, the potential demand is high but financial constraints leave it with no choice but to order less.\n\nIn addition, some suppliers offer discounts to companies that pay their bills in advance. In some cases, the distributor can stretch or defer accounts payable beyond the due date. Some suppliers allow the distributor not to pay at maturity on condition that penalties are applied to the amount of the invoice. It is therefore in its interest to focus on optimized payment management and find an optimal payment schedule.\n\nThe amount to be paid for each invoice differs depending on three possible scenarios: the invoice is paid with a discount before or at the discount period (ii) the invoice is paid at its actual value after the discount date but before or on the payment due date (iii) the invoice is paid with a penalty that depends on the time elapsed after the payment deadline. If the invoice is not paid before the due date, the penalty or interest begins to accumulate from that date until the prescription deadline of the invoice. Payment of the invoice must be made before the prescription period.\n\nThe distributor's objective is to plan its orders, the quantities to be delivered to each customer, the payment schedule of its invoices according to the available cash while maximizing its capital.\n\nThe problem data is provided in the excel file: demand/customer, quantity available by supplier, payment term/by supplier, and initial cash.","link":"https://www.reddit.com/r/Python/comments/11mpbkq/can_someone_help_me_understand_the_pulp_library/","created":"2023-03-09","tags":["python","reddit"],"meta":{"num_comments":2},"text":"can someone help me understand the pulp library and how to solve this problem i want to find the optimum solution and the pulp library is very complex m getting errors i don't understand and i need help with linearizing my variables thank you in advance \n\nproblem:\n\nA distributor of raw materials for cosmetics wants to improve its cash flows. The considered supply chain contains a single distributor, linked to one or more suppliers. These suppliers deliver the same product, but may have different characteristics, such as production capacity, price demanded, or payment deadline. We are interested in optimizing the physical and financial flows of the distributor. Cash constraints sometimes prevent it from carrying out its procurement activities optimally. A lack of liquidity can hinder the normal course of business. Sometimes, the potential demand is high but financial constraints leave it with no choice but to order less.\n\nIn addition, some suppliers offer discounts to companies that pay their bills in advance. In some cases, the distributor can stretch or defer accounts payable beyond the due date. Some suppliers allow the distributor not to pay at maturity on condition that penalties are applied to the amount of the invoice. It is therefore in its interest to focus on optimized payment management and find an optimal payment schedule.\n\nThe amount to be paid for each invoice differs depending on three possible scenarios: the invoice is paid with a discount before or at the discount period (ii) the invoice is paid at its actual value after the discount date but before or on the payment due date (iii) the invoice is paid with a penalty that depends on the time elapsed after the payment deadline. If the invoice is not paid before the due date, the penalty or interest begins to accumulate from that date until the prescription deadline of the invoice. Payment of the invoice must be made before the prescription period.\n\nThe distributor's objective is to plan its orders, the quantities to be delivered to each customer, the payment schedule of its invoices according to the available cash while maximizing its capital.\n\nThe problem data is provided in the excel file: demand/customer, quantity available by supplier, payment term/by supplier, and initial cash.","classes":{"dataset":0.3835953772}}
{"title":"Becoming Python Backend Developer and gaining experience","description":"Hi,\n\nI've python knowledge and experience developing different small tools/projects (mostly around automating). I'm aware of Python SDK. I want to become Python backend engineer and do some hobby/small projects so that I can claim to be backend engineer. \n\nCan anybody guide me/point to tutorials/projects that may help me in this regard.","link":"https://www.reddit.com/r/Python/comments/11mjyy0/becoming_python_backend_developer_and_gaining/","created":"2023-03-09","tags":["python","reddit"],"meta":{"num_comments":4},"text":"Becoming Python Backend Developer and gaining experience Hi,\n\nI've python knowledge and experience developing different small tools/projects (mostly around automating). I'm aware of Python SDK. I want to become Python backend engineer and do some hobby/small projects so that I can claim to be backend engineer. \n\nCan anybody guide me/point to tutorials/projects that may help me in this regard.","classes":{"dataset":0.4702934921}}
{"title":"Using Python to Cast Fullscreen Web Browser to TV","description":"Trying to get a script set that will always cast to a specific device, a web browser at full screen dark mode.\n\nThink using selenium might be the best route.\n\nAny tips? Does this sound possible?","link":"https://www.reddit.com/r/Python/comments/11lxj0y/using_python_to_cast_fullscreen_web_browser_to_tv/","created":"2023-03-08","tags":["python","reddit"],"meta":{"num_comments":7},"text":"Using Python to Cast Fullscreen Web Browser to TV Trying to get a script set that will always cast to a specific device, a web browser at full screen dark mode.\n\nThink using selenium might be the best route.\n\nAny tips? Does this sound possible?","classes":{"dataset":0.355676353}}
{"title":"Documentation for COM support in pywin32","description":"I'm looking for good documentation of python's WinAPI COM support. \n\nThe most conscise documentation I can find is a chapter in Mark Hammond's \"Python Programming On Win32\". However, it was published in 2000 and AFAIK never updated since.\n\nThe online documentation is quite brief and as dated (e.g. https://mhammond.github.io/pywin32/html/com/win32com/HTML/QuickStartClientCom.html).\n\nIs there anything... better? Fresher?","link":"https://www.reddit.com/r/Python/comments/11lsvvs/documentation_for_com_support_in_pywin32/","created":"2023-03-08","tags":["python","reddit"],"meta":{"num_comments":4},"text":"Documentation for COM support in pywin32 I'm looking for good documentation of python's WinAPI COM support. \n\nThe most conscise documentation I can find is a chapter in Mark Hammond's \"Python Programming On Win32\". However, it was published in 2000 and AFAIK never updated since.\n\nThe online documentation is quite brief and as dated (e.g. https://mhammond.github.io/pywin32/html/com/win32com/HTML/QuickStartClientCom.html).\n\nIs there anything... better? Fresher?","classes":{"dataset":0.2785441279}}
{"title":"Using Python with the ChatGPT API","description":"I've been playing with ChatGPT API, and wanted to post this easy to get started using Python with the API.  It goes through the basic setup and also the code and playing around with different prompts.\n\n[https://medium.com/@msgold/using-the-chatgpt-api-with-python-c56857e0e153](https://medium.com/@msgold/using-the-chatgpt-api-with-python-c56857e0e153)","link":"https://www.reddit.com/r/Python/comments/11lkua4/using_python_with_the_chatgpt_api/","created":"2023-03-08","tags":["python","reddit"],"meta":{"num_comments":2},"text":"Using Python with the ChatGPT API I've been playing with ChatGPT API, and wanted to post this easy to get started using Python with the API.  It goes through the basic setup and also the code and playing around with different prompts.\n\n[https://medium.com/@msgold/using-the-chatgpt-api-with-python-c56857e0e153](https://medium.com/@msgold/using-the-chatgpt-api-with-python-c56857e0e153)","classes":{"dataset":0.3985261917}}
{"title":"PyTorch Faster RCNN Library - Support for transformer detection models.","description":"[https://github.com/sovit-123/fasterrcnn-pytorch-training-pipeline](https://github.com/sovit-123/fasterrcnn-pytorch-training-pipeline)\n\nNow, the library supports Faster RCNN ViTDet and Faster RCNN MobileViT\\_XXS also.\n\nWould love to get feedback/contributions/suggestions.","link":"https://www.reddit.com/r/deeplearning/comments/11mhkpd/pytorch_faster_rcnn_library_support_for/","created":"2023-03-09","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":0},"text":"PyTorch Faster RCNN Library - Support for transformer detection models. [https://github.com/sovit-123/fasterrcnn-pytorch-training-pipeline](https://github.com/sovit-123/fasterrcnn-pytorch-training-pipeline)\n\nNow, the library supports Faster RCNN ViTDet and Faster RCNN MobileViT\\_XXS also.\n\nWould love to get feedback/contributions/suggestions.","classes":{"dataset":0.3199976981}}
{"title":"Build the BEST Data Science Resume with Quadruple Kaggle Grandmaster","description":"Here's an interview with Chris Deotte, Quadruple Kaggle Grandmaster at NVIDIA. \n\nIn this episode, Chris shares valuable insights on topics such as crafting a strong data science resume, achieving grandmaster status on Kaggle (even quadruple), working at NVIDIA, and how to approach current data science challenges. Learn more about Kaggle, the data science world, and NVIDIA through the fascinating story of Chris Deotte. (and win an RTX 4080 thanks to NVIDIA GTC collaboration!)\n\nListen to this week's episode on your favorite platform: \n\n[https://youtu.be/NjGnnG3evmE](https://youtu.be/NjGnnG3evmE)\n\n[https://podcasts.apple.com/us/podcast/whats-ai-by-louis-bouchard/id1675099708?i=1000603382690](https://podcasts.apple.com/us/podcast/whats-ai-by-louis-bouchard/id1675099708?i=1000603382690)\n\n[https://podcasters.spotify.com/pod/show/louis-bouchard/episodes/How-to-Build-a-strong-Data-Science-Resume--With-Chris-Deotte--Quadruple-Kaggle-Grandmaster-at-NVIDIA-and-win-an-RTX-4080-e203a7t/a-a9f73dt](https://podcasters.spotify.com/pod/show/louis-bouchard/episodes/How-to-Build-a-strong-Data-Science-Resume--With-Chris-Deotte--Quadruple-Kaggle-Grandmaster-at-NVIDIA-and-win-an-RTX-4080-e203a7t/a-a9f73dt)","link":"https://www.reddit.com/r/deeplearning/comments/11mhur7/build_the_best_data_science_resume_with_quadruple/","created":"2023-03-09","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":0},"text":"Build the BEST Data Science Resume with Quadruple Kaggle Grandmaster Here's an interview with Chris Deotte, Quadruple Kaggle Grandmaster at NVIDIA. \n\nIn this episode, Chris shares valuable insights on topics such as crafting a strong data science resume, achieving grandmaster status on Kaggle (even quadruple), working at NVIDIA, and how to approach current data science challenges. Learn more about Kaggle, the data science world, and NVIDIA through the fascinating story of Chris Deotte. (and win an RTX 4080 thanks to NVIDIA GTC collaboration!)\n\nListen to this week's episode on your favorite platform: \n\n[https://youtu.be/NjGnnG3evmE](https://youtu.be/NjGnnG3evmE)\n\n[https://podcasts.apple.com/us/podcast/whats-ai-by-louis-bouchard/id1675099708?i=1000603382690](https://podcasts.apple.com/us/podcast/whats-ai-by-louis-bouchard/id1675099708?i=1000603382690)\n\n[https://podcasters.spotify.com/pod/show/louis-bouchard/episodes/How-to-Build-a-strong-Data-Science-Resume--With-Chris-Deotte--Quadruple-Kaggle-Grandmaster-at-NVIDIA-and-win-an-RTX-4080-e203a7t/a-a9f73dt](https://podcasters.spotify.com/pod/show/louis-bouchard/episodes/How-to-Build-a-strong-Data-Science-Resume--With-Chris-Deotte--Quadruple-Kaggle-Grandmaster-at-NVIDIA-and-win-an-RTX-4080-e203a7t/a-a9f73dt)","classes":{"dataset":0.3760005236}}
{"title":"AI that plays a video game","description":"How would I make an AI that gathers resources in a game like ark? Thank you, I am new to this","link":"https://www.reddit.com/r/deeplearning/comments/11majq4/ai_that_plays_a_video_game/","created":"2023-03-08","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":3},"text":"AI that plays a video game How would I make an AI that gathers resources in a game like ark? Thank you, I am new to this","classes":{"dataset":0.2637611628}}
{"title":"2048 Q-Learning","description":"Hey, I have a Raspberry pi 4 8gb of RAM and I don\u2019t use it. So I found an idea, it\u2019s to make a 2048 in python with Q-Learning.\nBut I don\u2019t know how to make it.","link":"https://www.reddit.com/r/deeplearning/comments/11mc34a/2048_qlearning/","created":"2023-03-08","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":0},"text":"2048 Q-Learning Hey, I have a Raspberry pi 4 8gb of RAM and I don\u2019t use it. So I found an idea, it\u2019s to make a 2048 in python with Q-Learning.\nBut I don\u2019t know how to make it.","classes":{"dataset":0.1444292963}}
{"title":"How can i improve my model in order to get more accuray and less loss?? Thanks","description":"target\\_size=c(200,200)\n\nbatch\\_size=100\n\ntrain\\_data\\_gen=image\\_data\\_generator(rescale = 1./255,horizontal\\_flip = T,vertical\\_flip = T,rotation\\_range = 45,zoom\\_range = 0.25,validation\\_split = 0.2)\n\n&amp;#x200B;\n\n\\# train\n\ntrain\\_image\\_array\\_gen= flow\\_images\\_from\\_directory(directory = \"imagenes/TRAIN/\",shuffle=T,target\\_size =target\\_size,color\\_mode = \"grayscale\", batch\\_size = batch\\_size ,subset = \"training\",  generator = train\\_data\\_gen)\n\n\\# validation\n\nval\\_image\\_array\\_gen= flow\\_images\\_from\\_directory(directory = \"imagenes/TRAIN/\",target\\_size = target\\_size,shuffle = T, color\\_mode = \"grayscale\", batch\\_size = batch\\_size,subset = \"validation\", generator = train\\_data\\_gen)\n\n&amp;#x200B;\n\n&amp;#x200B;\n\ninitializer=initializer\\_random\\_normal(seed = 100)\n\nmodel=keras\\_model\\_sequential(name='simple\\_model')%&gt;%\n\nlayer\\_conv\\_2d(filters = 16,\n\nkernel\\_size = c(3,3),\n\npadding = 'same',\n\nactivation = 'relu',\n\nkernel\\_initializer = initializer,\n\nbias\\_initializer = initializer,\n\ninput\\_shape = c(tama\u00f1o\\_imagen,1)\n\n)%&gt;%\n\nlayer\\_max\\_pooling\\_2d(pool\\_size = c(2,2))%&gt;%\n\nlayer\\_flatten()%&gt;%\n\nlayer\\_dense(units = 16,\n\nactivation = 'relu',\n\nkernel\\_initializer = initializer,\n\nbias\\_initializer = initializer)%&gt;%\n\nlayer\\_dense(units = output\\_n,\n\nactivation = 'sigmoid',\n\nname = 'Output',\n\nkernel\\_initializer = initializer,\n\nbias\\_initializer = initializer)\n\nmodel\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nmodel %&gt;%\n\ncompile(\n\nloss='categorical\\_crossentropy',\n\noptimizer = optimizer\\_adam(learning\\_rate=0.0001),\n\nmetrics = 'accuracy'\n\n)\n\n&amp;#x200B;\n\nhistory=model %&gt;%\n\nfit(train\\_image\\_array\\_gen,steps\\_per\\_epoch=as.integer(train\\_samples/batch\\_size),epochs=40,validation\\_data=val\\_image\\_array\\_gen,validation\\_steps=as.integer(valid\\_samples/batch\\_size)\n\n)\n\n\\*plot(history)----&gt; RESULTS\\*\n\nhttps://preview.redd.it/5ekgkqqk8kma1.png?width=663&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d0b7a81091f377f823f1b52a7bb0ec713c28ca4f\n\n&amp;#x200B;\n\nval\\_data=data.frame(file\\_name=paste0('imagenes/TRAIN/',val\\_image\\_array\\_gen$filenames)) %&gt;%\n\nmutate(class=str\\_extract(file\\_name,'Control|PD'))\n\n&amp;#x200B;\n\nimage\\_prep=function(x){\n\narrays=lapply(x, function(path){\n\nimg=image\\_load(path,target\\_size = c(200,200),grayscale = T)\n\nx=image\\_to\\_array(img)\n\nx=array\\_reshape(x,c(1,dim(x)))\n\nx=x/255 #normalizar los pixeles de la imagen\n\n})\n\n[do.call](https://do.call)(abind::abind,c(arrays,list(along=1)))\n\n}\n\n&amp;#x200B;\n\ntest\\_x=image\\_prep(val\\_data$file\\_name)\n\ndim(test\\_x)\n\n&amp;#x200B;\n\npred\\_test=model %&gt;%\n\npredict(test\\_x)%&gt;%\n\nk\\_argmax()\n\nhead(pred\\_test,10)\n\n&amp;#x200B;\n\ndecode=function(x){\n\ncase\\_when(x==0\\~'Control',\n\nx==1\\~'PD'   )\n\n}\n\npred\\_test=sapply(pred\\_test,decode)\n\nhead(pred\\_test,10)\n\n\\*confusionMatrix(table(as.factor(pred\\_test),as.factor(val\\_data$class)))-----&gt;RESULTS\\*\n\n&amp;#x200B;\n\nhttps://preview.redd.it/fo3d3sdx8kma1.png?width=642&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c6a76cc9e5dd5ce2aee904e95544286b466214e0\n\n\\*history$metrics$accuracy\\[40\\]----&gt;RESULTS\\*\n\n&amp;#x200B;\n\nhttps://preview.redd.it/21t0vyby8kma1.png?width=254&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5200c07f5af184ec34e3bde5cef828487758320c","link":"https://www.reddit.com/r/deeplearning/comments/11m49hd/how_can_i_improve_my_model_in_order_to_get_more/","created":"2023-03-08","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":6},"text":"How can i improve my model in order to get more accuray and less loss?? Thanks target\\_size=c(200,200)\n\nbatch\\_size=100\n\ntrain\\_data\\_gen=image\\_data\\_generator(rescale = 1./255,horizontal\\_flip = T,vertical\\_flip = T,rotation\\_range = 45,zoom\\_range = 0.25,validation\\_split = 0.2)\n\n&amp;#x200B;\n\n\\# train\n\ntrain\\_image\\_array\\_gen= flow\\_images\\_from\\_directory(directory = \"imagenes/TRAIN/\",shuffle=T,target\\_size =target\\_size,color\\_mode = \"grayscale\", batch\\_size = batch\\_size ,subset = \"training\",  generator = train\\_data\\_gen)\n\n\\# validation\n\nval\\_image\\_array\\_gen= flow\\_images\\_from\\_directory(directory = \"imagenes/TRAIN/\",target\\_size = target\\_size,shuffle = T, color\\_mode = \"grayscale\", batch\\_size = batch\\_size,subset = \"validation\", generator = train\\_data\\_gen)\n\n&amp;#x200B;\n\n&amp;#x200B;\n\ninitializer=initializer\\_random\\_normal(seed = 100)\n\nmodel=keras\\_model\\_sequential(name='simple\\_model')%&gt;%\n\nlayer\\_conv\\_2d(filters = 16,\n\nkernel\\_size = c(3,3),\n\npadding = 'same',\n\nactivation = 'relu',\n\nkernel\\_initializer = initializer,\n\nbias\\_initializer = initializer,\n\ninput\\_shape = c(tama\u00f1o\\_imagen,1)\n\n)%&gt;%\n\nlayer\\_max\\_pooling\\_2d(pool\\_size = c(2,2))%&gt;%\n\nlayer\\_flatten()%&gt;%\n\nlayer\\_dense(units = 16,\n\nactivation = 'relu',\n\nkernel\\_initializer = initializer,\n\nbias\\_initializer = initializer)%&gt;%\n\nlayer\\_dense(units = output\\_n,\n\nactivation = 'sigmoid',\n\nname = 'Output',\n\nkernel\\_initializer = initializer,\n\nbias\\_initializer = initializer)\n\nmodel\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nmodel %&gt;%\n\ncompile(\n\nloss='categorical\\_crossentropy',\n\noptimizer = optimizer\\_adam(learning\\_rate=0.0001),\n\nmetrics = 'accuracy'\n\n)\n\n&amp;#x200B;\n\nhistory=model %&gt;%\n\nfit(train\\_image\\_array\\_gen,steps\\_per\\_epoch=as.integer(train\\_samples/batch\\_size),epochs=40,validation\\_data=val\\_image\\_array\\_gen,validation\\_steps=as.integer(valid\\_samples/batch\\_size)\n\n)\n\n\\*plot(history)----&gt; RESULTS\\*\n\nhttps://preview.redd.it/5ekgkqqk8kma1.png?width=663&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d0b7a81091f377f823f1b52a7bb0ec713c28ca4f\n\n&amp;#x200B;\n\nval\\_data=data.frame(file\\_name=paste0('imagenes/TRAIN/',val\\_image\\_array\\_gen$filenames)) %&gt;%\n\nmutate(class=str\\_extract(file\\_name,'Control|PD'))\n\n&amp;#x200B;\n\nimage\\_prep=function(x){\n\narrays=lapply(x, function(path){\n\nimg=image\\_load(path,target\\_size = c(200,200),grayscale = T)\n\nx=image\\_to\\_array(img)\n\nx=array\\_reshape(x,c(1,dim(x)))\n\nx=x/255 #normalizar los pixeles de la imagen\n\n})\n\n[do.call](https://do.call)(abind::abind,c(arrays,list(along=1)))\n\n}\n\n&amp;#x200B;\n\ntest\\_x=image\\_prep(val\\_data$file\\_name)\n\ndim(test\\_x)\n\n&amp;#x200B;\n\npred\\_test=model %&gt;%\n\npredict(test\\_x)%&gt;%\n\nk\\_argmax()\n\nhead(pred\\_test,10)\n\n&amp;#x200B;\n\ndecode=function(x){\n\ncase\\_when(x==0\\~'Control',\n\nx==1\\~'PD'   )\n\n}\n\npred\\_test=sapply(pred\\_test,decode)\n\nhead(pred\\_test,10)\n\n\\*confusionMatrix(table(as.factor(pred\\_test),as.factor(val\\_data$class)))-----&gt;RESULTS\\*\n\n&amp;#x200B;\n\nhttps://preview.redd.it/fo3d3sdx8kma1.png?width=642&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c6a76cc9e5dd5ce2aee904e95544286b466214e0\n\n\\*history$metrics$accuracy\\[40\\]----&gt;RESULTS\\*\n\n&amp;#x200B;\n\nhttps://preview.redd.it/21t0vyby8kma1.png?width=254&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5200c07f5af184ec34e3bde5cef828487758320c","classes":{"dataset":0.5223271251}}
{"title":"Pytorch training speed slow?","description":"Being a new Pytorch user, I was curious to train the same model with Pytorch that I trained with Tensorflow a few months ago. However, in PyTorch, the training doesn't even seem to pass a single epoch and takes too long.\n\nThe same model, and same dataset, on Tensorflow, took 500 s on avg per epoch, but in PyTorch it is around 3600 s, and the colab memory usage is skyrocketing, thus crashing the server.\n\nIs there something I'm doing wrong? I made the model on GPU and also the data.\n\n**Model used:** EfficientNetB0 with completely unfrozen weights.\n\n**Dataset:** Food101\n\n^(Again, I used the same model and data in TensorFlow too!!)\n\n**Model Code:**\n\n    effnetb1_weights = torchvision.models.EfficientNet_B1_Weights.DEFAULT\n    effnetb1_transforms = effnetb1_weights.transforms()\n    effnetb1 = torchvision.models.efficientnet_b1(weights=effnetb1_weights).to(device) effnetb1.classifier = nn.Sequential(nn.Dropout(p=0.3, inplace=True),             \n                                    nn.Linear(in_features = 1280, out_features=len(class_names))\n    ).to(device)\n\n**Dataset Code:**\n\n    train_data = torchvision.datasets.Food101(root='food101', download=True, \n                                              split='train',         transform=effnetb1_transforms)\n    test_data = torchvision.datasets.Food101(root='food101', download=True, \n                                             split='test', transform=effnetb1_transforms)\n    \n    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)\n\n**Training Loops:**\n\n    def train_step(model: nn.Module,\n                   dataloader: torch.utils.data.DataLoader,\n                   loss_fn: nn.Module, optimizer: torch.optim.Optimizer,\n                   device: torch.device='cuda' if torch.cuda.is_available() else 'cpu'):\n    \n      train_loss = []\n      train_acc = []\n      \n      model.train()\n      with tqdm(dataloader, unit='batch', ascii=' =', position=0, bar_format='{n_fmt}/{total_fmt} [{bar:30}] - {elapsed_s:.0f}s {rate_fmt} {desc} ') as tbatch:\n        for X, y in tbatch:\n          X, y = X.to(device), y.to(device)\n    \n          preds = model(X)\n    \n          loss = loss_fn(preds, y)\n          acc = accuracy_score(y.cpu(), torch.argmax(torch.softmax(preds, dim=1), dim=1).cpu())\n          tbatch.set_description_str(f\"loss: {torch.mean(torch.Tensor(train_loss)).item():.4f} - accuracy: {torch.mean(torch.Tensor(train_acc)).item():.4f}\")\n    \n          train_loss.append(loss)\n          train_acc.append(acc)\n    \n          optimizer.zero_grad()\n          loss.backward()\n          optimizer.step()\n      return torch.mean(torch.Tensor(train_loss)).item(), torch.mean(torch.Tensor(train_acc)).item()\n\n**Full Notebook:** [https://colab.research.google.com/drive/1VWNMpF4DxOUOqCbPKhvtKthnUQ4Ni7r\\_#scrollTo=qLSlm0b8YO-l](https://colab.research.google.com/drive/1VWNMpF4DxOUOqCbPKhvtKthnUQ4Ni7r_#scrollTo=qLSlm0b8YO-l)","link":"https://www.reddit.com/r/deeplearning/comments/11kyvdm/pytorch_training_speed_slow/","created":"2023-03-07","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":1},"text":"Pytorch training speed slow? Being a new Pytorch user, I was curious to train the same model with Pytorch that I trained with Tensorflow a few months ago. However, in PyTorch, the training doesn't even seem to pass a single epoch and takes too long.\n\nThe same model, and same dataset, on Tensorflow, took 500 s on avg per epoch, but in PyTorch it is around 3600 s, and the colab memory usage is skyrocketing, thus crashing the server.\n\nIs there something I'm doing wrong? I made the model on GPU and also the data.\n\n**Model used:** EfficientNetB0 with completely unfrozen weights.\n\n**Dataset:** Food101\n\n^(Again, I used the same model and data in TensorFlow too!!)\n\n**Model Code:**\n\n    effnetb1_weights = torchvision.models.EfficientNet_B1_Weights.DEFAULT\n    effnetb1_transforms = effnetb1_weights.transforms()\n    effnetb1 = torchvision.models.efficientnet_b1(weights=effnetb1_weights).to(device) effnetb1.classifier = nn.Sequential(nn.Dropout(p=0.3, inplace=True),             \n                                    nn.Linear(in_features = 1280, out_features=len(class_names))\n    ).to(device)\n\n**Dataset Code:**\n\n    train_data = torchvision.datasets.Food101(root='food101', download=True, \n                                              split='train',         transform=effnetb1_transforms)\n    test_data = torchvision.datasets.Food101(root='food101', download=True, \n                                             split='test', transform=effnetb1_transforms)\n    \n    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)\n\n**Training Loops:**\n\n    def train_step(model: nn.Module,\n                   dataloader: torch.utils.data.DataLoader,\n                   loss_fn: nn.Module, optimizer: torch.optim.Optimizer,\n                   device: torch.device='cuda' if torch.cuda.is_available() else 'cpu'):\n    \n      train_loss = []\n      train_acc = []\n      \n      model.train()\n      with tqdm(dataloader, unit='batch', ascii=' =', position=0, bar_format='{n_fmt}/{total_fmt} [{bar:30}] - {elapsed_s:.0f}s {rate_fmt} {desc} ') as tbatch:\n        for X, y in tbatch:\n          X, y = X.to(device), y.to(device)\n    \n          preds = model(X)\n    \n          loss = loss_fn(preds, y)\n          acc = accuracy_score(y.cpu(), torch.argmax(torch.softmax(preds, dim=1), dim=1).cpu())\n          tbatch.set_description_str(f\"loss: {torch.mean(torch.Tensor(train_loss)).item():.4f} - accuracy: {torch.mean(torch.Tensor(train_acc)).item():.4f}\")\n    \n          train_loss.append(loss)\n          train_acc.append(acc)\n    \n          optimizer.zero_grad()\n          loss.backward()\n          optimizer.step()\n      return torch.mean(torch.Tensor(train_loss)).item(), torch.mean(torch.Tensor(train_acc)).item()\n\n**Full Notebook:** [https://colab.research.google.com/drive/1VWNMpF4DxOUOqCbPKhvtKthnUQ4Ni7r\\_#scrollTo=qLSlm0b8YO-l](https://colab.research.google.com/drive/1VWNMpF4DxOUOqCbPKhvtKthnUQ4Ni7r_#scrollTo=qLSlm0b8YO-l)","classes":{"dataset":0.2250697017}}
{"title":"We tracked mentions of OpenAI, Bing, and Bard across social media to find out who's the most talked about in Silicon Valley","description":"[Posts about OpenAI, Bing, and Bard in the San Francisco Bay Area and Silicon Valley](https://preview.redd.it/tliq31mjecma1.png?width=1286&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b85bd810e79aabae50c0d69f3ef6c47052cc7b5e)\n\nHave you been following the news on the conversational AI race? We used social media data and [geolocation models](https://github.com/1712n/yachay-public/tree/master/conf_geotagging_model) to find posts about OpenAI, Bing, and Bard in the Silicon Valley and San Francisco Bay Area for the last two weeks to see which one received the most mentions.\n\nFirst, we filtered social media data with the keywords \"openai,\" \"bing,\" \"bard,\" and then we predicted coordinates for the social media posts by using our text-based geolocation models. After selecting texts which received a confidence score higher than 0.8, we plotted their coordinates as company logos on a leaflet map using Python and the folium library, restricting the map to the bounding box of the San Francisco Bay Area and Silicon Valley.\n\nWe analyzed over 300 social media posts and found that roughly 54.5% of the time, OpenAI was the most talked about. Bing made second place with around 27.2%, and then Bard came in last with 18.3%.\n\nYou can check out the full map [here](https://1712n.github.io/yachay-public/maps/chatbots/).\n\nOpenAI may be winning the AI race at the moment, but it's not the end yet. Let us know what other AI projects you're following, and we'll check them out.","link":"https://www.reddit.com/r/deeplearning/comments/11l3ofp/we_tracked_mentions_of_openai_bing_and_bard/","created":"2023-03-07","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":1},"text":"We tracked mentions of OpenAI, Bing, and Bard across social media to find out who's the most talked about in Silicon Valley [Posts about OpenAI, Bing, and Bard in the San Francisco Bay Area and Silicon Valley](https://preview.redd.it/tliq31mjecma1.png?width=1286&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b85bd810e79aabae50c0d69f3ef6c47052cc7b5e)\n\nHave you been following the news on the conversational AI race? We used social media data and [geolocation models](https://github.com/1712n/yachay-public/tree/master/conf_geotagging_model) to find posts about OpenAI, Bing, and Bard in the Silicon Valley and San Francisco Bay Area for the last two weeks to see which one received the most mentions.\n\nFirst, we filtered social media data with the keywords \"openai,\" \"bing,\" \"bard,\" and then we predicted coordinates for the social media posts by using our text-based geolocation models. After selecting texts which received a confidence score higher than 0.8, we plotted their coordinates as company logos on a leaflet map using Python and the folium library, restricting the map to the bounding box of the San Francisco Bay Area and Silicon Valley.\n\nWe analyzed over 300 social media posts and found that roughly 54.5% of the time, OpenAI was the most talked about. Bing made second place with around 27.2%, and then Bard came in last with 18.3%.\n\nYou can check out the full map [here](https://1712n.github.io/yachay-public/maps/chatbots/).\n\nOpenAI may be winning the AI race at the moment, but it's not the end yet. Let us know what other AI projects you're following, and we'll check them out.","classes":{"dataset":0.5358505249}}
{"title":"[R] Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models","description":"","link":"https://www.reddit.com/gallery/11mlwty","created":"2023-03-09","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":7},"text":"[R] Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models ","classes":{"dataset":0.102218844}}
{"title":"[P] Introducing the GitHub profile summarizer","description":"Hi guys, I built a website that summarizes a GitHub user using GPT.\n\nWhat is it?You type a GitHub profile URL, then it gives you a summary of the user.\n\nHow does it work?It finds the most important work by heuristics, then summarizes it using GPT.\n\nGive it a try and let me know what you think. :)\n\n[sample summary](https://preview.redd.it/c5o8tccc2jma1.png?width=1238&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9a5c6bc7ba5661020f75b22e3d76aa4441483ff4)\n\n[http://devmarizer.firebaseapp.com/](http://devmarizer.firebaseapp.com/)","link":"https://www.reddit.com/r/MachineLearning/comments/11ly4d9/p_introducing_the_github_profile_summarizer/","created":"2023-03-08","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":30},"text":"[P] Introducing the GitHub profile summarizer Hi guys, I built a website that summarizes a GitHub user using GPT.\n\nWhat is it?You type a GitHub profile URL, then it gives you a summary of the user.\n\nHow does it work?It finds the most important work by heuristics, then summarizes it using GPT.\n\nGive it a try and let me know what you think. :)\n\n[sample summary](https://preview.redd.it/c5o8tccc2jma1.png?width=1238&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9a5c6bc7ba5661020f75b22e3d76aa4441483ff4)\n\n[http://devmarizer.firebaseapp.com/](http://devmarizer.firebaseapp.com/)","classes":{"dataset":0.7158123255}}
{"title":"[D] Machine/Deep learning jupyter notebooks for computer vision, NLP, and recommender systems","description":"Hi, I work at Intel as an academic outreach coordinator.  I'm sharing about Intel's open source OpenVINO toolkit for optimizing and deploy AI inference on CPUs, discrete and integrated GPUs, and other accelerators like Movidius VPUs and Intel FPGA.  The [github](https://github.com/openvinotoolkit/openvino_notebooks) has over 60 jupyter notebooks that can work on Intel PCs/laptop using Windows &amp; Linux, or on Macs on MacOS including M1 processors.\n\nTry out the stable diffusion Jupyter Notebook [\\#225](https://github.com/openvinotoolkit/openvino_notebooks/tree/main/notebooks/225-stable-diffusion-text-to-image),  or try out the vehicle recognition and detection Jupyter Notebook [\\#218](https://github.com/openvinotoolkit/openvino_notebooks/tree/main/notebooks/218-vehicle-detection-and-recognition)\n\nIts easy to install in 9 simple steps on Windows with pip install, 8 steps on MacOS, and 7 steps on Linux.","link":"https://www.reddit.com/r/MachineLearning/comments/11mbikv/d_machinedeep_learning_jupyter_notebooks_for/","created":"2023-03-08","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":0},"text":"[D] Machine/Deep learning jupyter notebooks for computer vision, NLP, and recommender systems Hi, I work at Intel as an academic outreach coordinator.  I'm sharing about Intel's open source OpenVINO toolkit for optimizing and deploy AI inference on CPUs, discrete and integrated GPUs, and other accelerators like Movidius VPUs and Intel FPGA.  The [github](https://github.com/openvinotoolkit/openvino_notebooks) has over 60 jupyter notebooks that can work on Intel PCs/laptop using Windows &amp; Linux, or on Macs on MacOS including M1 processors.\n\nTry out the stable diffusion Jupyter Notebook [\\#225](https://github.com/openvinotoolkit/openvino_notebooks/tree/main/notebooks/225-stable-diffusion-text-to-image),  or try out the vehicle recognition and detection Jupyter Notebook [\\#218](https://github.com/openvinotoolkit/openvino_notebooks/tree/main/notebooks/218-vehicle-detection-and-recognition)\n\nIts easy to install in 9 simple steps on Windows with pip install, 8 steps on MacOS, and 7 steps on Linux.","classes":{"dataset":0.3907697797}}
{"title":"[D] Text embedding model for financial documents","description":"I'm currently working on a project where I'm analyzing financial documents such as 10Ks and 10Qs. I'm looking for a pretrained text embedding model that has been fine-tuned on such documents to generate accurate embeddings. While there are models like FinBERT that are tuned for sentiment analysis, I'm interested in a model that can generate more accurate embeddings in general, without focusing solely on sentiment.\n\n&amp;#x200B;\n\nThanks!","link":"https://www.reddit.com/r/MachineLearning/comments/11m99js/d_text_embedding_model_for_financial_documents/","created":"2023-03-08","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":10},"text":"[D] Text embedding model for financial documents I'm currently working on a project where I'm analyzing financial documents such as 10Ks and 10Qs. I'm looking for a pretrained text embedding model that has been fine-tuned on such documents to generate accurate embeddings. While there are models like FinBERT that are tuned for sentiment analysis, I'm interested in a model that can generate more accurate embeddings in general, without focusing solely on sentiment.\n\n&amp;#x200B;\n\nThanks!","classes":{"dataset":0.3870434463}}
{"title":"[D] Feature Engineering","description":"I'm looking to do some feature engineering. Was wondering if y'all knew some platforms/libraries I could use that do it well?","link":"https://www.reddit.com/r/MachineLearning/comments/11mgijd/d_feature_engineering/","created":"2023-03-09","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":1},"text":"[D] Feature Engineering I'm looking to do some feature engineering. Was wondering if y'all knew some platforms/libraries I could use that do it well?","classes":{"dataset":0.3236101866}}
{"title":"[D] In AI, is bigger always better? Article in Nature; Bing summary and comment","description":"**In AI, is bigger always better?**\n\n**As generative AI models grow larger and more powerful, some scientists advocate for leaner, more energy-efficient systems.**\n\n[https://www.nature.com/articles/d41586-023-00641-w](https://www.nature.com/articles/d41586-023-00641-w)\n\nBing says:\n\n\\# In AI, is bigger always better?\n\nArtificial intelligence (AI) has made remarkable progress in recent years, thanks to the development of large language models (LLMs) that can generate coherent and fluent text on various topics. LLMs are trained on massive amounts of text data, such as books, news articles and social media posts, and learn to predict the next word given some previous words. They can also perform other tasks, such as answering questions, summarizing texts and translating languages.\n\nHowever, there is a debate among AI researchers about whether bigger LLMs are always better. Some argue that increasing the size of LLMs (in terms of parameters, data and computing power) will lead to more general and human-like intelligence. Others question this assumption and point out the limitations and challenges of scaling up LLMs.\n\nIn a recent article published in Nature , Anil Ananthaswamy explores this debate and examines the pros and cons of building bigger LLMs. He interviews several experts from academia and industry who share their views on the current state and future direction of AI research.\n\nOne of the main advantages of bigger LLMs is that they can achieve higher accuracy and performance on various natural language processing (NLP) benchmarks. For example, GPT-3 , one of the largest LLMs to date with 175 billion parameters, can generate convincing texts on almost any topic given a few words or sentences as input. It can also answer factual questions, write summaries and perform simple arithmetic.\n\nAnother benefit of bigger LLMs is that they can learn from more diverse and representative data sources, which can reduce bias and improve fairness. For instance, Google's LaMDA , an LLM with 137 billion parameters that can engage in open-ended conversations on any topic, was trained on text data from multiple languages and domains.\n\nHowever, bigger LLMs also come with significant drawbacks. One of them is the environmental cost of training them. According to a study by researchers at the University of Massachusetts Amherst , training a large LLM can emit as much carbon dioxide as five cars over their lifetimes. Moreover, training bigger LLMs requires more specialized hardware and infrastructure, which increases the entry barrier for smaller research groups and organizations.\n\nAnother challenge of bigger LLMs is that they are not very interpretable or explainable. It is hard to understand how they make decisions or what they learn from their data. This poses ethical risks when deploying them in real-world applications that affect human lives, such as health care or education.\n\nA third limitation of bigger LLMs is that they are not truly intelligent or generalizable. They lack common sense reasoning, causal understanding and world knowledge that humans have. They also struggle to adapt to new situations or tasks that are different from their training data.\n\nTherefore, some researchers suggest that scaling up LLMs alone is not enough to achieve artificial general intelligence (AGI), which is defined as AI that can perform any intellectual task that humans can do. They propose alternative approaches that combine symbolic reasoning with neural networks , incorporate multimodal inputs such as images or sounds , or leverage human feedback or interaction .\n\nIn conclusion, building bigger LLMs has both advantages and disadvantages for advancing AI research. While they offer impressive capabilities for generating natural language texts and performing various NLP tasks, they also face challenges in terms of environmental impact, transparency, and generality.\n\nTherefore, it is important to balance the trade-offs and explore other directionsfor developing more robust, responsible, and human-like AI systems.\n\n: [https://www.nature.com/articles/d41586-023-00641-w](https://www.nature.com/articles/d41586-023-00641-w)\n\n: [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)\n\n: [https://ai.googleblog.com/2021/05/lamda-towards-conversational-agent-that.html](https://ai.googleblog.com/2021/05/lamda-towards-conversational-agent-that.html)\n\n: [https://arxiv.org/abs/1906.02243](https://arxiv.org/abs/1906.02243)\n\n: [https://arxiv.org/abs/2102.12730](https://arxiv.org/abs/2102.12730)\n\n: [https://arxiv.org/abs/2103.06332](https://arxiv.org/abs/2103.06332)\n\n: [https://arxiv.org/abs/2106.04501](https://arxiv.org/abs/2106.04501)","link":"https://www.reddit.com/r/MachineLearning/comments/11m57gr/d_in_ai_is_bigger_always_better_article_in_nature/","created":"2023-03-08","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":14},"text":"[D] In AI, is bigger always better? Article in Nature; Bing summary and comment **In AI, is bigger always better?**\n\n**As generative AI models grow larger and more powerful, some scientists advocate for leaner, more energy-efficient systems.**\n\n[https://www.nature.com/articles/d41586-023-00641-w](https://www.nature.com/articles/d41586-023-00641-w)\n\nBing says:\n\n\\# In AI, is bigger always better?\n\nArtificial intelligence (AI) has made remarkable progress in recent years, thanks to the development of large language models (LLMs) that can generate coherent and fluent text on various topics. LLMs are trained on massive amounts of text data, such as books, news articles and social media posts, and learn to predict the next word given some previous words. They can also perform other tasks, such as answering questions, summarizing texts and translating languages.\n\nHowever, there is a debate among AI researchers about whether bigger LLMs are always better. Some argue that increasing the size of LLMs (in terms of parameters, data and computing power) will lead to more general and human-like intelligence. Others question this assumption and point out the limitations and challenges of scaling up LLMs.\n\nIn a recent article published in Nature , Anil Ananthaswamy explores this debate and examines the pros and cons of building bigger LLMs. He interviews several experts from academia and industry who share their views on the current state and future direction of AI research.\n\nOne of the main advantages of bigger LLMs is that they can achieve higher accuracy and performance on various natural language processing (NLP) benchmarks. For example, GPT-3 , one of the largest LLMs to date with 175 billion parameters, can generate convincing texts on almost any topic given a few words or sentences as input. It can also answer factual questions, write summaries and perform simple arithmetic.\n\nAnother benefit of bigger LLMs is that they can learn from more diverse and representative data sources, which can reduce bias and improve fairness. For instance, Google's LaMDA , an LLM with 137 billion parameters that can engage in open-ended conversations on any topic, was trained on text data from multiple languages and domains.\n\nHowever, bigger LLMs also come with significant drawbacks. One of them is the environmental cost of training them. According to a study by researchers at the University of Massachusetts Amherst , training a large LLM can emit as much carbon dioxide as five cars over their lifetimes. Moreover, training bigger LLMs requires more specialized hardware and infrastructure, which increases the entry barrier for smaller research groups and organizations.\n\nAnother challenge of bigger LLMs is that they are not very interpretable or explainable. It is hard to understand how they make decisions or what they learn from their data. This poses ethical risks when deploying them in real-world applications that affect human lives, such as health care or education.\n\nA third limitation of bigger LLMs is that they are not truly intelligent or generalizable. They lack common sense reasoning, causal understanding and world knowledge that humans have. They also struggle to adapt to new situations or tasks that are different from their training data.\n\nTherefore, some researchers suggest that scaling up LLMs alone is not enough to achieve artificial general intelligence (AGI), which is defined as AI that can perform any intellectual task that humans can do. They propose alternative approaches that combine symbolic reasoning with neural networks , incorporate multimodal inputs such as images or sounds , or leverage human feedback or interaction .\n\nIn conclusion, building bigger LLMs has both advantages and disadvantages for advancing AI research. While they offer impressive capabilities for generating natural language texts and performing various NLP tasks, they also face challenges in terms of environmental impact, transparency, and generality.\n\nTherefore, it is important to balance the trade-offs and explore other directionsfor developing more robust, responsible, and human-like AI systems.\n\n: [https://www.nature.com/articles/d41586-023-00641-w](https://www.nature.com/articles/d41586-023-00641-w)\n\n: [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)\n\n: [https://ai.googleblog.com/2021/05/lamda-towards-conversational-agent-that.html](https://ai.googleblog.com/2021/05/lamda-towards-conversational-agent-that.html)\n\n: [https://arxiv.org/abs/1906.02243](https://arxiv.org/abs/1906.02243)\n\n: [https://arxiv.org/abs/2102.12730](https://arxiv.org/abs/2102.12730)\n\n: [https://arxiv.org/abs/2103.06332](https://arxiv.org/abs/2103.06332)\n\n: [https://arxiv.org/abs/2106.04501](https://arxiv.org/abs/2106.04501)","classes":{"dataset":0.5018006563}}
{"title":"[R] Analysis of 200+ ML competitions in 2022","description":"I run mlcontests.com, a website that aggregates ML competitions across Kaggle and other platforms.\n\nI've just finished a detailed analysis of **200+ competitions** in 2022, and what winners did (we found winning solutions for 67 competitions).\n\nSome highlights:\n\n* **Kaggle still dominant** with the most prize money, most competitions, and most entries per competition...\n* ... but there are **10+ other platforms** with interesting competitions and decent prize money, and dozens of single-competition sites\n* **Almost all competition winners used Python**, 1 used C++, 1 used R, 1 used Java\n* **96% (!) of Deep Learning solutions used PyTorch** (up from 77% last year)\n* **All winning NLP solutions we found used Transformers**\n* **Most computer vision solutions used CNNs**, though some used Transformer-based models\n* **Tabular data competitions were mostly won by GBDTs** (mostly LightGBM), though ensembles with PyTorch are common\n* **Some winners spent hundreds of dollars on cloud compute** for a single training run, **others managed to win just using Colab**'s free tier\n* Winners have largely converged on a common toolkit - PyData stack for the basics, PyTorch for deep learning, LightGBM/XGBoost/CatBoost for GBDTs, Optuna for hyperparam optimisation.\n* Half of competition winners are first-time winners; a third have won multiple comps before; half are solo winners. Some *serial winners* won 2-3 competitions just in 2022!\n\nWay more details as well as methodology here in the full report: [https://mlcontests.com/state-of-competitive-machine-learning-2022?ref=mlc\\_reddit](https://mlcontests.com/state-of-competitive-machine-learning-2022?ref=mlc_reddit)\n\n[Most common Python Packages used by winners](https://preview.redd.it/kwqmozh9lbma1.png?width=1600&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1096de087592eb4cc2fbe85c8068617cb4f73d8f)\n\nWhen I published something similar here [last year](https://www.reddit.com/r/MachineLearning/comments/tdd889/news_analysis_of_83_ml_competitions_in_2021/), I got a lot of questions about tabular data, so I did a [deep dive](https://mlcontests.com/state-of-competitive-machine-learning-2022/#tabular-data?ref=mlc_reddit) into that this year.People also asked about [leaderboard shakeups](https://mlcontests.com/state-of-competitive-machine-learning-2022/#cross-validation?ref=mlc_reddit) and [compute cost trends](https://mlcontests.com/state-of-competitive-machine-learning-2022/#compute-and-hardware?ref=mlc_reddit), so those are included too. I'd love to hear your suggestions for next year.\n\nI managed to spend way more time on this analysis than last year thanks to the report sponsors (**G-Research**, a top quant firm, and **Genesis Cloud**, a renewable-energy cloud compute firm) - if you want to support this research, please check them out. I won't spam you with links here, there's more detail on them at the bottom of the report.","link":"https://www.reddit.com/r/MachineLearning/comments/11kzkla/r_analysis_of_200_ml_competitions_in_2022/","created":"2023-03-07","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":27},"text":"[R] Analysis of 200+ ML competitions in 2022 I run mlcontests.com, a website that aggregates ML competitions across Kaggle and other platforms.\n\nI've just finished a detailed analysis of **200+ competitions** in 2022, and what winners did (we found winning solutions for 67 competitions).\n\nSome highlights:\n\n* **Kaggle still dominant** with the most prize money, most competitions, and most entries per competition...\n* ... but there are **10+ other platforms** with interesting competitions and decent prize money, and dozens of single-competition sites\n* **Almost all competition winners used Python**, 1 used C++, 1 used R, 1 used Java\n* **96% (!) of Deep Learning solutions used PyTorch** (up from 77% last year)\n* **All winning NLP solutions we found used Transformers**\n* **Most computer vision solutions used CNNs**, though some used Transformer-based models\n* **Tabular data competitions were mostly won by GBDTs** (mostly LightGBM), though ensembles with PyTorch are common\n* **Some winners spent hundreds of dollars on cloud compute** for a single training run, **others managed to win just using Colab**'s free tier\n* Winners have largely converged on a common toolkit - PyData stack for the basics, PyTorch for deep learning, LightGBM/XGBoost/CatBoost for GBDTs, Optuna for hyperparam optimisation.\n* Half of competition winners are first-time winners; a third have won multiple comps before; half are solo winners. Some *serial winners* won 2-3 competitions just in 2022!\n\nWay more details as well as methodology here in the full report: [https://mlcontests.com/state-of-competitive-machine-learning-2022?ref=mlc\\_reddit](https://mlcontests.com/state-of-competitive-machine-learning-2022?ref=mlc_reddit)\n\n[Most common Python Packages used by winners](https://preview.redd.it/kwqmozh9lbma1.png?width=1600&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1096de087592eb4cc2fbe85c8068617cb4f73d8f)\n\nWhen I published something similar here [last year](https://www.reddit.com/r/MachineLearning/comments/tdd889/news_analysis_of_83_ml_competitions_in_2021/), I got a lot of questions about tabular data, so I did a [deep dive](https://mlcontests.com/state-of-competitive-machine-learning-2022/#tabular-data?ref=mlc_reddit) into that this year.People also asked about [leaderboard shakeups](https://mlcontests.com/state-of-competitive-machine-learning-2022/#cross-validation?ref=mlc_reddit) and [compute cost trends](https://mlcontests.com/state-of-competitive-machine-learning-2022/#compute-and-hardware?ref=mlc_reddit), so those are included too. I'd love to hear your suggestions for next year.\n\nI managed to spend way more time on this analysis than last year thanks to the report sponsors (**G-Research**, a top quant firm, and **Genesis Cloud**, a renewable-energy cloud compute firm) - if you want to support this research, please check them out. I won't spam you with links here, there's more detail on them at the bottom of the report.","classes":{"dataset":0.2283764631}}
{"title":"Semantic Search: With Exclusions [P][D]","description":"I am making a semantic search engine in Python that takes a user input and returns the 5 most similar results from a list of sentences. \n\nThe list of sentences features a list of things not included in the category at the end of a sentence e.g.   \u201cThis category includes: lions, tigers. This category excludes: birds, bees\u201d  \n\nCurrently if I search \u201cbirds\u201d the above example would be returned as strong similarity due to the word matching with \u201ccategory excludes: birds\u201d \n\nDoes anyone know any way to prevent this?\nAny help appreciated!!","link":"https://www.reddit.com/r/MachineLearning/comments/11m4wim/semantic_search_with_exclusions_pd/","created":"2023-03-08","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":5},"text":"Semantic Search: With Exclusions [P][D] I am making a semantic search engine in Python that takes a user input and returns the 5 most similar results from a list of sentences. \n\nThe list of sentences features a list of things not included in the category at the end of a sentence e.g.   \u201cThis category includes: lions, tigers. This category excludes: birds, bees\u201d  \n\nCurrently if I search \u201cbirds\u201d the above example would be returned as strong similarity due to the word matching with \u201ccategory excludes: birds\u201d \n\nDoes anyone know any way to prevent this?\nAny help appreciated!!","classes":{"dataset":0.399290204}}
{"title":"[D] The Emergent Abilities of Large Language Models","description":"Hey everyone!  \n\n\nLarge Language Models have been shown to gain new abilities (like translation and arithmetic) as they are scaled. Some of these abilities have been recently observed to be **emergent**, meaning that there is an apparent discontinuity in their appearance with scale.  \n\n\nThis article on [**the emergent abilities of large language models**](https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models/) examines this phenomenon, providing necessary background and information on the concept of emergence as a whole.  \n\n\nI'm interested to hear what folks here think about this phenomenon and observation, especially regarding potential explanations as well as real-world implications. Let me know what you think!\n\n&amp;#x200B;\n\nhttps://preview.redd.it/hrh3zuztgcma1.png?width=1316&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ad511d6d8875cf2765d5f80672d32e49abe28f55","link":"https://www.reddit.com/r/MachineLearning/comments/11l49y5/d_the_emergent_abilities_of_large_language_models/","created":"2023-03-07","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":18},"text":"[D] The Emergent Abilities of Large Language Models Hey everyone!  \n\n\nLarge Language Models have been shown to gain new abilities (like translation and arithmetic) as they are scaled. Some of these abilities have been recently observed to be **emergent**, meaning that there is an apparent discontinuity in their appearance with scale.  \n\n\nThis article on [**the emergent abilities of large language models**](https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models/) examines this phenomenon, providing necessary background and information on the concept of emergence as a whole.  \n\n\nI'm interested to hear what folks here think about this phenomenon and observation, especially regarding potential explanations as well as real-world implications. Let me know what you think!\n\n&amp;#x200B;\n\nhttps://preview.redd.it/hrh3zuztgcma1.png?width=1316&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ad511d6d8875cf2765d5f80672d32e49abe28f55","classes":{"dataset":0.0113753052}}
{"title":"[R] PaLM-E: An Embodied Multimodal Language Model - Google 2023 - Exhibits positve transfer learning!","description":"Paper: [https://arxiv.org/abs/2303.03378](https://arxiv.org/abs/2303.03378)\n\nBlog: [https://palm-e.github.io/](https://palm-e.github.io/)\n\nTwitter: [https://twitter.com/DannyDriess/status/1632904675124035585](https://twitter.com/DannyDriess/status/1632904675124035585)\n\nAbstract:\n\n&gt;Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g., for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multi-modal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, **exhibits positive transfer**: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. **Our largest model, PaLM-E-562B with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.**       \n\nhttps://preview.redd.it/1z3zc3kte9ma1.jpg?width=1321&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=7ee212c74d468ba5a911e8f3bcfcad520cdd8733\n\nhttps://preview.redd.it/2qapt8kte9ma1.jpg?width=1180&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=30edaa9b99d8c1481b90721e14dae54764999e68\n\nhttps://preview.redd.it/thtfg6kte9ma1.jpg?width=725&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c430e48e068eab0870e215b743d4a293d97177d2\n\nhttps://preview.redd.it/nffus6kte9ma1.jpg?width=712&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8234af6ab133385ff96425312ef2d86b95e14d9e\n\nhttps://preview.redd.it/henjo3kte9ma1.jpg?width=710&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1a36d074839a85a64ee9fc21c10c40234c75cadc","link":"https://www.reddit.com/r/MachineLearning/comments/11krgp4/r_palme_an_embodied_multimodal_language_model/","created":"2023-03-07","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":133},"text":"[R] PaLM-E: An Embodied Multimodal Language Model - Google 2023 - Exhibits positve transfer learning! Paper: [https://arxiv.org/abs/2303.03378](https://arxiv.org/abs/2303.03378)\n\nBlog: [https://palm-e.github.io/](https://palm-e.github.io/)\n\nTwitter: [https://twitter.com/DannyDriess/status/1632904675124035585](https://twitter.com/DannyDriess/status/1632904675124035585)\n\nAbstract:\n\n&gt;Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g., for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multi-modal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, **exhibits positive transfer**: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. **Our largest model, PaLM-E-562B with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.**       \n\nhttps://preview.redd.it/1z3zc3kte9ma1.jpg?width=1321&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=7ee212c74d468ba5a911e8f3bcfcad520cdd8733\n\nhttps://preview.redd.it/2qapt8kte9ma1.jpg?width=1180&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=30edaa9b99d8c1481b90721e14dae54764999e68\n\nhttps://preview.redd.it/thtfg6kte9ma1.jpg?width=725&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c430e48e068eab0870e215b743d4a293d97177d2\n\nhttps://preview.redd.it/nffus6kte9ma1.jpg?width=712&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8234af6ab133385ff96425312ef2d86b95e14d9e\n\nhttps://preview.redd.it/henjo3kte9ma1.jpg?width=710&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1a36d074839a85a64ee9fc21c10c40234c75cadc","classes":{"dataset":0.5260590315}}
{"title":"[R] Reinforcement Learning With C++.","description":"Hello everyone! I've been searching for a long time for a video tutorial that teaches reinforcement learning with C++. Unfortunately, all of the tutorials I've found so far have been just theoretical speeches that don't teach anything about practically implementing AI. I have high experience with C++ but very little experience with reinforcement learning, so I can't enforce AI. I just need to understand the basics of implementing it, maybe one example with explanations.  Not only C++ tho but maybe C# (I don't want python because I have no experience with python and most of the python tutorials have their fancy libraries, and I don't want to learn RL with some libraries but I want to implement the whole thing so I can understand it more deeply). Any recommendations would be greatly appreciated! Thank you!","link":"https://www.reddit.com/r/MachineLearning/comments/11m54z6/r_reinforcement_learning_with_c/","created":"2023-03-08","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":12},"text":"[R] Reinforcement Learning With C++. Hello everyone! I've been searching for a long time for a video tutorial that teaches reinforcement learning with C++. Unfortunately, all of the tutorials I've found so far have been just theoretical speeches that don't teach anything about practically implementing AI. I have high experience with C++ but very little experience with reinforcement learning, so I can't enforce AI. I just need to understand the basics of implementing it, maybe one example with explanations.  Not only C++ tho but maybe C# (I don't want python because I have no experience with python and most of the python tutorials have their fancy libraries, and I don't want to learn RL with some libraries but I want to implement the whole thing so I can understand it more deeply). Any recommendations would be greatly appreciated! Thank you!","classes":{"dataset":0.0392073914}}
{"title":"[D] Tutorial: Run LLaMA on 8gb vram on windows (thanks to bitsandbytes 8bit quantization)","description":"facebookresearch/LLaMA 7b on windows 11 using less than 10GB vram, or LLaMA-13b on less than 24GB.\n\nEfforts are being made to  get the larger LLaMA 30b onto &lt;24GB vram with 4bit quantization by implementing the technique from the paper [GPTQ quantization](https://github.com/oobabooga/text-generation-webui/issues/177) \n\nSince bitsandbytes doesn't officially have windows binaries, the following trick using an older unofficially compiled cuda compatible bitsandbytes binary works for windows.\n\n1. install miniconda, start the miniconda console\n1. create a new dir, for example *C:\\textgen\\* and cd into it\n1. git clone *github.com/oobabooga/text-generation-webui*\n1. follow the installation instructions of text-generation-webui for conda, create the env with the name textgen\n1. Download not the original LLaMA weights, but the [HuggingFace converted](https://rentry.org/llama-tard-v2) weights. The torrent link is on top of this linked article.\n1. copy the llama-7b or -13b folder (or whatever size you want to run) into *C:\\textgen\\text-generation-webui\\models*. The folder should contain the config.json, generation_config.json, pytorch_model.bin, index.json, special_tokens_map.json, tokenizer.model, tokenizer_config.json as well as all the 33 pytorch_model-000xx-of-00033.bin files\n1. put [libbitsandbytes_cuda116.dll](https://github.com/DeXtmL/bitsandbytes-win-prebuilt) in *C:\\Users\\xxx\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\*\n1. edit *\\bitsandbytes\\cuda_setup\\main.py*:\n  \n  search for:\n  \n  *if not torch.cuda.is_available(): return 'libsbitsandbytes_cpu.so', None, None, None, None*\n  \n  replace with:\n  \n  *if torch.cuda.is_available(): return 'libbitsandbytes_cuda116.dll', None, None, None, None*\n\n  search for this twice:\n  \n  *self.lib = ct.cdll.LoadLibrary(binary_path)*\n  \n  replace with:\n  \n  *self.lib = ct.cdll.LoadLibrary(str(binary_path))*\n\n1. Start text-generation-webui by typing: *python server.py --model LLaMA-7B --load-in-8bit*","link":"https://www.reddit.com/r/MachineLearning/comments/11kwdu9/d_tutorial_run_llama_on_8gb_vram_on_windows/","created":"2023-03-07","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":17},"text":"[D] Tutorial: Run LLaMA on 8gb vram on windows (thanks to bitsandbytes 8bit quantization) facebookresearch/LLaMA 7b on windows 11 using less than 10GB vram, or LLaMA-13b on less than 24GB.\n\nEfforts are being made to  get the larger LLaMA 30b onto &lt;24GB vram with 4bit quantization by implementing the technique from the paper [GPTQ quantization](https://github.com/oobabooga/text-generation-webui/issues/177) \n\nSince bitsandbytes doesn't officially have windows binaries, the following trick using an older unofficially compiled cuda compatible bitsandbytes binary works for windows.\n\n1. install miniconda, start the miniconda console\n1. create a new dir, for example *C:\\textgen\\* and cd into it\n1. git clone *github.com/oobabooga/text-generation-webui*\n1. follow the installation instructions of text-generation-webui for conda, create the env with the name textgen\n1. Download not the original LLaMA weights, but the [HuggingFace converted](https://rentry.org/llama-tard-v2) weights. The torrent link is on top of this linked article.\n1. copy the llama-7b or -13b folder (or whatever size you want to run) into *C:\\textgen\\text-generation-webui\\models*. The folder should contain the config.json, generation_config.json, pytorch_model.bin, index.json, special_tokens_map.json, tokenizer.model, tokenizer_config.json as well as all the 33 pytorch_model-000xx-of-00033.bin files\n1. put [libbitsandbytes_cuda116.dll](https://github.com/DeXtmL/bitsandbytes-win-prebuilt) in *C:\\Users\\xxx\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\*\n1. edit *\\bitsandbytes\\cuda_setup\\main.py*:\n  \n  search for:\n  \n  *if not torch.cuda.is_available(): return 'libsbitsandbytes_cpu.so', None, None, None, None*\n  \n  replace with:\n  \n  *if torch.cuda.is_available(): return 'libbitsandbytes_cuda116.dll', None, None, None, None*\n\n  search for this twice:\n  \n  *self.lib = ct.cdll.LoadLibrary(binary_path)*\n  \n  replace with:\n  \n  *self.lib = ct.cdll.LoadLibrary(str(binary_path))*\n\n1. Start text-generation-webui by typing: *python server.py --model LLaMA-7B --load-in-8bit*","classes":{"dataset":0.2703157663}}
{"title":"[R] Created a Discord server with LLaMA 13B","description":"Installed LLaMA 13B (legitimate download) on a Dual RTX 3090 server and created a discord bot to interact with it.\n\nAs it's quite fast I'm opening it to the public, here is the discord invite. No registration/payments, etc. completely free.\n\nInstructions in comments as I cannot post an invite directly here.","link":"https://www.reddit.com/r/MachineLearning/comments/11kr20f/r_created_a_discord_server_with_llama_13b/","created":"2023-03-07","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":18},"text":"[R] Created a Discord server with LLaMA 13B Installed LLaMA 13B (legitimate download) on a Dual RTX 3090 server and created a discord bot to interact with it.\n\nAs it's quite fast I'm opening it to the public, here is the discord invite. No registration/payments, etc. completely free.\n\nInstructions in comments as I cannot post an invite directly here.","classes":{"dataset":0.2534983456}}
{"title":"Semantic Search: With Exclusions","description":"I am making a semantic search engine in Python that takes a user input and returns the 5 most similar results from a list of sentences. \n\nThe list of sentences features a list of things not included in the category at the end of a sentence e.g.   \u201cThis category includes: lions, tigers. This category excludes: birds, bees\u201d  \n\nCurrently if I search \u201cbirds\u201d the above example would be returned as strong similarity due to the word matching with \u201ccategory excludes: birds\u201d \n\nDoes anyone know any way to prevent this?\nAny help appreciated!!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11m4niv/semantic_search_with_exclusions/","created":"2023-03-08","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":9},"text":"Semantic Search: With Exclusions I am making a semantic search engine in Python that takes a user input and returns the 5 most similar results from a list of sentences. \n\nThe list of sentences features a list of things not included in the category at the end of a sentence e.g.   \u201cThis category includes: lions, tigers. This category excludes: birds, bees\u201d  \n\nCurrently if I search \u201cbirds\u201d the above example would be returned as strong similarity due to the word matching with \u201ccategory excludes: birds\u201d \n\nDoes anyone know any way to prevent this?\nAny help appreciated!!","classes":{"dataset":0.5313108563}}
{"title":"Testing Viterbi Algorithm for Hidden markov model pos tagger","description":"I am implementing the HMM model pos tagger using viterbi algorithm on the brown dataset from nltk. I have separated the data into train and test datasets, now for train dataset, I have calculated the emission and transition probability matrix. I have a few questions though.\n\n1. To calculate the accuracy, do we count the no. of correct tags on words or the no. of correctly tagged sentences? (my guess is it should be words)\n2. For testing data, I have some words which are not in the emission probability matrix, and hence for those sentences viterbi algorithm gives me an error. how do i handle this?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11luju0/testing_viterbi_algorithm_for_hidden_markov_model/","created":"2023-03-08","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":4},"text":"Testing Viterbi Algorithm for Hidden markov model pos tagger I am implementing the HMM model pos tagger using viterbi algorithm on the brown dataset from nltk. I have separated the data into train and test datasets, now for train dataset, I have calculated the emission and transition probability matrix. I have a few questions though.\n\n1. To calculate the accuracy, do we count the no. of correct tags on words or the no. of correctly tagged sentences? (my guess is it should be words)\n2. For testing data, I have some words which are not in the emission probability matrix, and hence for those sentences viterbi algorithm gives me an error. how do i handle this?","classes":{"dataset":0.2311390638}}
{"title":"Question about density plots for dimensionality reduced embeddings","description":"I have long form documents that each talk about a variety of topics (10+). The documents are split into paragraph, which is the unit (sub-) topics are talked about. For each paragraph an embedding is created via OpenAI (text-embedding-ada-002). Since the embeddings contain 1536 dimensions, I use UMAP to reduce it to two. \n\nWhat I would like to do is then use bivatiate kde plots via [seaborn](https://seaborn.pydata.org/tutorial/distributions.html) to compare the focus of the documents (each representing an organization) showing differences and commonalities. I don\u2018t have a strong background in mathematics but this part of the [documentation](https://umap-learn.readthedocs.io/en/latest/clustering.html) threw me a little of. While I am not directly clustering, the underlying idea seems similar enough to warrant caution. \n\nDoes anybody know if my idea (umap reduced embedding-&gt; kde plot) reasonably sound or have any pointers to fintune the approach?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11m3jgo/question_about_density_plots_for_dimensionality/","created":"2023-03-08","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"Question about density plots for dimensionality reduced embeddings I have long form documents that each talk about a variety of topics (10+). The documents are split into paragraph, which is the unit (sub-) topics are talked about. For each paragraph an embedding is created via OpenAI (text-embedding-ada-002). Since the embeddings contain 1536 dimensions, I use UMAP to reduce it to two. \n\nWhat I would like to do is then use bivatiate kde plots via [seaborn](https://seaborn.pydata.org/tutorial/distributions.html) to compare the focus of the documents (each representing an organization) showing differences and commonalities. I don\u2018t have a strong background in mathematics but this part of the [documentation](https://umap-learn.readthedocs.io/en/latest/clustering.html) threw me a little of. While I am not directly clustering, the underlying idea seems similar enough to warrant caution. \n\nDoes anybody know if my idea (umap reduced embedding-&gt; kde plot) reasonably sound or have any pointers to fintune the approach?","classes":{"dataset":0.4061246216}}
{"title":"Options for BERT in Python vs. Pyspark","description":"Hi all,  I'm working on a project to improve the **selection of web pages where ads will be placed**. (ex: If the ad is for supplements for women place it on a page about... women's health and wellness. Pretty simple.)\n\nPreviously, this has been done using very basic keyword matching and/or the site's membership in a category that was pre-chosen by the customer. (External service provides categorization of site, customer chooses keywords/category they want to advertise on.) Very basic, context and word sense not considered.\n\nNow I'm trying to bring the system up to a modern approach. \n\n# My approach so far has been the following:\n\n* **Make Corpus Embeddings**\n   * Get the text of a bunch of the pages where an ad can be shown and **do TF-IDF** to find most relevant words.\n   * **Get embeddings** of all the page's words **from bert-base-uncased**\n   * Pull out **just those that are top 10 TD-IDF** and **average** to create a general embedding for that page (Two notes about this: This is actually done a little more efficiently than this but I'm trying to make it clear conceptually that I'm getting the embedding for the word in its original context. I'm adding the extra TF-IDF step because it seems to keep size/computation low and not sacrifice quality.)\n* **Make Example Site Embedding**\n   * **Get an example site from the customer** that they consider ideal to advertise on. Do the above on this site's text also.\n* **Find Pages Similar to Example**\n   * Do **cosine similarity** across the pages in the corpus to **find near neighbors to the example site** and advertise on those highest ranking pages where possible.\n\n# How to get this into pySpark?\n\nSo, this has all been great so far. The results look like we want them to look. But it's just been done on 70k rows of corpus sites, totally in Python. We're going to need to deal with a corpus of \\~10mil sites. That's not going to work in Python. There is a Hadoop cluster available that is accessible by PySpark, though.  \n\nSo we have **options**.\n\n* Put everything in a **UDF**, run same BERT package in UDF (not so efficient and coincidentally also not working at all due to a platform issue I won't explain here but basically **this won't work** so it's ruled out)\n* Switch the **TF-IDF to SparkML**, do the BERT **embeddings in SparkNLP** (this is how we're going about this now but it's still slow, not sure the cause yet)\n* **Forget the TF-IDF** efficiency step and just do BERT embeddings in SparkNLP, go eat cake and watch television!\n* **SOMETHING ELSE MUCH BETTER**\n\n# Can I do this better? How?\n\nThat brings me to my question. What would you do to approach this problem better? What's best for **storage efficiency, computational efficiency**? Would you go about it a totally different way entirely? How can I improve this approach?\n\nThanks for your advice!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11l7vuu/options_for_bert_in_python_vs_pyspark/","created":"2023-03-07","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"Options for BERT in Python vs. Pyspark Hi all,  I'm working on a project to improve the **selection of web pages where ads will be placed**. (ex: If the ad is for supplements for women place it on a page about... women's health and wellness. Pretty simple.)\n\nPreviously, this has been done using very basic keyword matching and/or the site's membership in a category that was pre-chosen by the customer. (External service provides categorization of site, customer chooses keywords/category they want to advertise on.) Very basic, context and word sense not considered.\n\nNow I'm trying to bring the system up to a modern approach. \n\n# My approach so far has been the following:\n\n* **Make Corpus Embeddings**\n   * Get the text of a bunch of the pages where an ad can be shown and **do TF-IDF** to find most relevant words.\n   * **Get embeddings** of all the page's words **from bert-base-uncased**\n   * Pull out **just those that are top 10 TD-IDF** and **average** to create a general embedding for that page (Two notes about this: This is actually done a little more efficiently than this but I'm trying to make it clear conceptually that I'm getting the embedding for the word in its original context. I'm adding the extra TF-IDF step because it seems to keep size/computation low and not sacrifice quality.)\n* **Make Example Site Embedding**\n   * **Get an example site from the customer** that they consider ideal to advertise on. Do the above on this site's text also.\n* **Find Pages Similar to Example**\n   * Do **cosine similarity** across the pages in the corpus to **find near neighbors to the example site** and advertise on those highest ranking pages where possible.\n\n# How to get this into pySpark?\n\nSo, this has all been great so far. The results look like we want them to look. But it's just been done on 70k rows of corpus sites, totally in Python. We're going to need to deal with a corpus of \\~10mil sites. That's not going to work in Python. There is a Hadoop cluster available that is accessible by PySpark, though.  \n\nSo we have **options**.\n\n* Put everything in a **UDF**, run same BERT package in UDF (not so efficient and coincidentally also not working at all due to a platform issue I won't explain here but basically **this won't work** so it's ruled out)\n* Switch the **TF-IDF to SparkML**, do the BERT **embeddings in SparkNLP** (this is how we're going about this now but it's still slow, not sure the cause yet)\n* **Forget the TF-IDF** efficiency step and just do BERT embeddings in SparkNLP, go eat cake and watch television!\n* **SOMETHING ELSE MUCH BETTER**\n\n# Can I do this better? How?\n\nThat brings me to my question. What would you do to approach this problem better? What's best for **storage efficiency, computational efficiency**? Would you go about it a totally different way entirely? How can I improve this approach?\n\nThanks for your advice!","classes":{"dataset":0.3138046563}}
{"title":"Swahili Translation Tool","description":"Hello all! I am a teacher and I am looking for an app or a website or something you all suggest to translate my assignments and letters home into Swahili and Arabic. If you have anything you would like to suggest, I would really appreciate it! Thank you all.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11l5mlt/swahili_translation_tool/","created":"2023-03-07","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":1},"text":"Swahili Translation Tool Hello all! I am a teacher and I am looking for an app or a website or something you all suggest to translate my assignments and letters home into Swahili and Arabic. If you have anything you would like to suggest, I would really appreciate it! Thank you all.","classes":{"dataset":0.428945452}}
{"title":"We tracked mentions of OpenAI, Bing, and Bard across social media to find out who's the most talked about in Silicon Valley","description":"Have you been following the news on the conversational AI race? We used social media data and [geolocation models](https://github.com/1712n/yachay-public/tree/master/conf_geotagging_model) to find posts about OpenAI, Bing, and Bard in the Silicon Valley and San Francisco Bay Area for the last two weeks to see which one received the most mentions.\n\nFirst, we filtered social media data with the keywords \"openai,\" \"bing,\" \"bard,\" and then we predicted coordinates for the social media posts by using our text-based geolocation models. After selecting texts which received a confidence score higher than 0.8, we plotted their coordinates as company logos on a leaflet [map](https://1712n.github.io/yachay-public/maps/chatbots/) using Python and the folium library, restricting the map to the bounding box of the San Francisco Bay Area and Silicon Valley.\n\nWe analyzed over 300 social media posts and found that roughly 54.5% of the time, OpenAI was the most talked about. Bing made second place with around 27.2%, and then Bard came in last with 18.3%.\n\nOpenAI may be winning the AI race at the moment, but it's not the end yet. Let us know what other AI projects you're following, and we'll check them out.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11l3k5x/we_tracked_mentions_of_openai_bing_and_bard/","created":"2023-03-07","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"We tracked mentions of OpenAI, Bing, and Bard across social media to find out who's the most talked about in Silicon Valley Have you been following the news on the conversational AI race? We used social media data and [geolocation models](https://github.com/1712n/yachay-public/tree/master/conf_geotagging_model) to find posts about OpenAI, Bing, and Bard in the Silicon Valley and San Francisco Bay Area for the last two weeks to see which one received the most mentions.\n\nFirst, we filtered social media data with the keywords \"openai,\" \"bing,\" \"bard,\" and then we predicted coordinates for the social media posts by using our text-based geolocation models. After selecting texts which received a confidence score higher than 0.8, we plotted their coordinates as company logos on a leaflet [map](https://1712n.github.io/yachay-public/maps/chatbots/) using Python and the folium library, restricting the map to the bounding box of the San Francisco Bay Area and Silicon Valley.\n\nWe analyzed over 300 social media posts and found that roughly 54.5% of the time, OpenAI was the most talked about. Bing made second place with around 27.2%, and then Bard came in last with 18.3%.\n\nOpenAI may be winning the AI race at the moment, but it's not the end yet. Let us know what other AI projects you're following, and we'll check them out.","classes":{"dataset":0.6694572568}}
{"title":"Recognizing new tokens with Sentence Transformers","description":"I'm currently using the sentence-transformers library to perform semantic parsing on a dataset. The problem is that this data contains a ton of industry jargon and acronyms, and I am not confident in a pretrained transformer's ability to accurately capture those types of tokens.\n\n&amp;#x200B;\n\nIs there a recommended approach for tuning the model to capture these new tokens? Will finetuning the later layers of a pretrained model be sufficient to capture the context around these tokens, or would a better approach be to unlock the initial layer of the transformer to create word embeddings to be used downstream for the sentence embeddings?\n\n&amp;#x200B;\n\nThank you!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11k6svi/recognizing_new_tokens_with_sentence_transformers/","created":"2023-03-06","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":5},"text":"Recognizing new tokens with Sentence Transformers I'm currently using the sentence-transformers library to perform semantic parsing on a dataset. The problem is that this data contains a ton of industry jargon and acronyms, and I am not confident in a pretrained transformer's ability to accurately capture those types of tokens.\n\n&amp;#x200B;\n\nIs there a recommended approach for tuning the model to capture these new tokens? Will finetuning the later layers of a pretrained model be sufficient to capture the context around these tokens, or would a better approach be to unlock the initial layer of the transformer to create word embeddings to be used downstream for the sentence embeddings?\n\n&amp;#x200B;\n\nThank you!","classes":{"dataset":0.344537288}}
{"title":"Cicero by Meta AI","description":" \n\nHi everyone,\n\nHere is an attempt to summarise Cicero by Meta AI. It was a difficult read so hope people appreciates this.\n\n**What is Cicero?**\n\nfirst time an AI exceeds at a board game that requires communicating (natural language) with other humans UNDETECTED.\n\nCicero - the AI agent that speaks your language, plans with you, and negotiates like a pro. With human-level performance in Diplomacy (a board game).\n\n**How does it work?**\n\nUsing LLMs and other bits\u2026\n\nif anyone is interested please feel free to check it out.\n\n[https://www.youtube.com/watch?v=Gj5T9m-ZzNA](https://www.youtube.com/watch?v=Gj5T9m-ZzNA)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11kcpic/cicero_by_meta_ai/","created":"2023-03-06","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"Cicero by Meta AI  \n\nHi everyone,\n\nHere is an attempt to summarise Cicero by Meta AI. It was a difficult read so hope people appreciates this.\n\n**What is Cicero?**\n\nfirst time an AI exceeds at a board game that requires communicating (natural language) with other humans UNDETECTED.\n\nCicero - the AI agent that speaks your language, plans with you, and negotiates like a pro. With human-level performance in Diplomacy (a board game).\n\n**How does it work?**\n\nUsing LLMs and other bits\u2026\n\nif anyone is interested please feel free to check it out.\n\n[https://www.youtube.com/watch?v=Gj5T9m-ZzNA](https://www.youtube.com/watch?v=Gj5T9m-ZzNA)","classes":{"dataset":0.3634797335}}
{"title":"Is there a correlation between the scale of the model and the quality of long text generation?","description":"Recently, I conducted a few fine-tuning experiments on a multitask instruction dataset on 1b7 LLM, primarily related to open-ended long story generation. However, it was observed that after generating nearly 300 tokens, the quality of the generated text started to decline, becoming less fluent. \n\nI am curious to know if there exists a relationship between the scale of the model and the quality of long text generation. For example, is it possible to achieve fluent long text after generating a certain number of tokens for models like 1b7?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11k1wzp/is_there_a_correlation_between_the_scale_of_the/","created":"2023-03-06","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":1},"text":"Is there a correlation between the scale of the model and the quality of long text generation? Recently, I conducted a few fine-tuning experiments on a multitask instruction dataset on 1b7 LLM, primarily related to open-ended long story generation. However, it was observed that after generating nearly 300 tokens, the quality of the generated text started to decline, becoming less fluent. \n\nI am curious to know if there exists a relationship between the scale of the model and the quality of long text generation. For example, is it possible to achieve fluent long text after generating a certain number of tokens for models like 1b7?","classes":{"dataset":0.4465715587}}
{"title":"SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis","description":"For the deployment of artificial intelligence (AI) in high-risk settings, such as healthcare, methods that provide interpretability/explainability or allow fine-grained error analysis are critical. Many recent methods for interpretability/explainability and fine-grained error analysis use concepts, which are meta-labels that are semantically meaningful to humans. However, there are only a few datasets that include concept-level meta-labels and most of these meta-labels are relevant for natural images that do not require domain expertise. Densely annotated datasets in medicine focused on meta-labels that are relevant to a single disease such as melanoma. In dermatology, skin disease is described using an established clinical lexicon that allows clinicians to describe physical exam findings to one another. To provide a medical dataset densely annotated by domain experts with annotations useful across multiple disease processes, we developed SkinCon: a skin disease dataset densely annotated by dermatologists. SkinCon includes 3230 images from the Fitzpatrick 17k dataset densely annotated with 48 clinical concepts, 22 of which have at least 50 images representing the concept. The concepts used were chosen by two dermatologists considering the clinical descriptor terms used to describe skin lesions. Examples include \"plaque\", \"scale\", and \"erosion\". The same concepts were also used to label 656 skin disease images from the Diverse Dermatology Images dataset, providing an additional external dataset with diverse skin tone representations. We review the potential applications for the SkinCon dataset, such as probing models, concept-based explanations, and concept bottlenecks. Furthermore, we use SkinCon to demonstrate two of these use cases: debugging mistakes of an existing dermatology AI model with concepts and developing interpretable models with post-hoc concept bottleneck models.","link":"http://arxiv.org/abs/2302.00785v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis For the deployment of artificial intelligence (AI) in high-risk settings, such as healthcare, methods that provide interpretability/explainability or allow fine-grained error analysis are critical. Many recent methods for interpretability/explainability and fine-grained error analysis use concepts, which are meta-labels that are semantically meaningful to humans. However, there are only a few datasets that include concept-level meta-labels and most of these meta-labels are relevant for natural images that do not require domain expertise. Densely annotated datasets in medicine focused on meta-labels that are relevant to a single disease such as melanoma. In dermatology, skin disease is described using an established clinical lexicon that allows clinicians to describe physical exam findings to one another. To provide a medical dataset densely annotated by domain experts with annotations useful across multiple disease processes, we developed SkinCon: a skin disease dataset densely annotated by dermatologists. SkinCon includes 3230 images from the Fitzpatrick 17k dataset densely annotated with 48 clinical concepts, 22 of which have at least 50 images representing the concept. The concepts used were chosen by two dermatologists considering the clinical descriptor terms used to describe skin lesions. Examples include \"plaque\", \"scale\", and \"erosion\". The same concepts were also used to label 656 skin disease images from the Diverse Dermatology Images dataset, providing an additional external dataset with diverse skin tone representations. We review the potential applications for the SkinCon dataset, such as probing models, concept-based explanations, and concept bottlenecks. Furthermore, we use SkinCon to demonstrate two of these use cases: debugging mistakes of an existing dermatology AI model with concepts and developing interpretable models with post-hoc concept bottleneck models.","classes":{"dataset":0.0251557697}}
{"title":"Revisiting Query Performance in GPU Database Systems","description":"GPUs offer massive compute parallelism and high-bandwidth memory accesses. GPU database systems seek to exploit those capabilities to accelerate data analytics. Although modern GPUs have more resources (e.g., higher DRAM bandwidth) than ever before, judicious choices for query processing that avoid wasteful resource allocations are still advantageous. Database systems can save GPU runtime costs through just-enough resource allocation or improve query throughput with concurrent query processing by leveraging new GPU capabilities, such as Multi-Instance GPU (MIG).   In this paper we do a cross-stack performance and resource utilization analysis of five GPU database systems. We study both database-level and micro-architectural aspects, and offer recommendations to database developers. We also demonstrate how to use and extend the traditional roofline model to identify GPU resource bottlenecks. This enables users to conduct what-if analysis to forecast performance impact for different resource allocation or the degree of concurrency. Our methodology addresses a key user pain point in selecting optimal configurations by removing the need to do exhaustive testing for a multitude of resource configurations.","link":"http://arxiv.org/abs/2302.00734v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Revisiting Query Performance in GPU Database Systems GPUs offer massive compute parallelism and high-bandwidth memory accesses. GPU database systems seek to exploit those capabilities to accelerate data analytics. Although modern GPUs have more resources (e.g., higher DRAM bandwidth) than ever before, judicious choices for query processing that avoid wasteful resource allocations are still advantageous. Database systems can save GPU runtime costs through just-enough resource allocation or improve query throughput with concurrent query processing by leveraging new GPU capabilities, such as Multi-Instance GPU (MIG).   In this paper we do a cross-stack performance and resource utilization analysis of five GPU database systems. We study both database-level and micro-architectural aspects, and offer recommendations to database developers. We also demonstrate how to use and extend the traditional roofline model to identify GPU resource bottlenecks. This enables users to conduct what-if analysis to forecast performance impact for different resource allocation or the degree of concurrency. Our methodology addresses a key user pain point in selecting optimal configurations by removing the need to do exhaustive testing for a multitude of resource configurations.","classes":{"dataset":0.1098278239}}
{"title":"The RW3D: A multi-modal panel dataset to understand the psychological impact of the pandemic","description":"Besides far-reaching public health consequences, the COVID-19 pandemic had a significant psychological impact on people around the world. To gain further insight into this matter, we introduce the Real World Worry Waves Dataset (RW3D). The dataset combines rich open-ended free-text responses with survey data on emotions, significant life events, and psychological stressors in a repeated-measures design in the UK over three years (2020: n=2441, 2021: n=1716 and 2022: n=1152). This paper provides background information on the data collection procedure, the recorded variables, participants' demographics, and higher-order psychological and text-based derived variables that emerged from the data. The RW3D is a unique primary data resource that could inspire new research questions on the psychological impact of the pandemic, especially those that connect modalities (here: text data, psychological survey variables and demographics) over time.","link":"http://arxiv.org/abs/2302.00606v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"The RW3D: A multi-modal panel dataset to understand the psychological impact of the pandemic Besides far-reaching public health consequences, the COVID-19 pandemic had a significant psychological impact on people around the world. To gain further insight into this matter, we introduce the Real World Worry Waves Dataset (RW3D). The dataset combines rich open-ended free-text responses with survey data on emotions, significant life events, and psychological stressors in a repeated-measures design in the UK over three years (2020: n=2441, 2021: n=1716 and 2022: n=1152). This paper provides background information on the data collection procedure, the recorded variables, participants' demographics, and higher-order psychological and text-based derived variables that emerged from the data. The RW3D is a unique primary data resource that could inspire new research questions on the psychological impact of the pandemic, especially those that connect modalities (here: text data, psychological survey variables and demographics) over time.","classes":{"dataset":0.9791816473}}
{"title":"HunSum-1: an Abstractive Summarization Dataset for Hungarian","description":"We introduce HunSum-1: a dataset for Hungarian abstractive summarization, consisting of 1.14M news articles. The dataset is built by collecting, cleaning and deduplicating data from 9 major Hungarian news sites through CommonCrawl. Using this dataset, we build abstractive summarizer models based on huBERT and mT5. We demonstrate the value of the created dataset by performing a quantitative and qualitative analysis on the models' results. The HunSum-1 dataset, all models used in our experiments and our code are available open source.","link":"http://arxiv.org/abs/2302.00455v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"HunSum-1: an Abstractive Summarization Dataset for Hungarian We introduce HunSum-1: a dataset for Hungarian abstractive summarization, consisting of 1.14M news articles. The dataset is built by collecting, cleaning and deduplicating data from 9 major Hungarian news sites through CommonCrawl. Using this dataset, we build abstractive summarizer models based on huBERT and mT5. We demonstrate the value of the created dataset by performing a quantitative and qualitative analysis on the models' results. The HunSum-1 dataset, all models used in our experiments and our code are available open source.","classes":{"dataset":0.0148853166}}
{"title":"An Evaluation of Persian-English Machine Translation Datasets with Transformers","description":"Nowadays, many researchers are focusing their attention on the subject of machine translation (MT). However, Persian machine translation has remained unexplored despite a vast amount of research being conducted in languages with high resources, such as English. Moreover, while a substantial amount of research has been undertaken in statistical machine translation for some datasets in Persian, there is currently no standard baseline for transformer-based text2text models on each corpus. This study collected and analysed the most popular and valuable parallel corpora, which were used for Persian-English translation. Furthermore, we fine-tuned and evaluated two state-of-the-art attention-based seq2seq models on each dataset separately (48 results). We hope this paper will assist researchers in comparing their Persian to English and vice versa machine translation results to a standard baseline.","link":"http://arxiv.org/abs/2302.00321v1","created":"2023-02-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"An Evaluation of Persian-English Machine Translation Datasets with Transformers Nowadays, many researchers are focusing their attention on the subject of machine translation (MT). However, Persian machine translation has remained unexplored despite a vast amount of research being conducted in languages with high resources, such as English. Moreover, while a substantial amount of research has been undertaken in statistical machine translation for some datasets in Persian, there is currently no standard baseline for transformer-based text2text models on each corpus. This study collected and analysed the most popular and valuable parallel corpora, which were used for Persian-English translation. Furthermore, we fine-tuned and evaluated two state-of-the-art attention-based seq2seq models on each dataset separately (48 results). We hope this paper will assist researchers in comparing their Persian to English and vice versa machine translation results to a standard baseline.","classes":{"dataset":0.9722781777}}
{"title":"Are Diffusion Models Vulnerable to Membership Inference Attacks?","description":"Diffusion-based generative models have shown great potential for image synthesis, but there is a lack of research on the security and privacy risks they may pose. In this paper, we investigate the vulnerability of diffusion models to Membership Inference Attacks (MIAs), a common privacy concern. Our results indicate that existing MIAs designed for GANs or VAE are largely ineffective on diffusion models, either due to inapplicable scenarios (e.g., requiring the discriminator of GANs) or inappropriate assumptions (e.g., closer distances between synthetic images and member images). To address this gap, we propose Step-wise Error Comparing Membership Inference (SecMI), a black-box MIA that infers memberships by assessing the matching of forward process posterior estimation at each timestep. SecMI follows the common overfitting assumption in MIA where member samples normally have smaller estimation errors, compared with hold-out samples. We consider both the standard diffusion models, e.g., DDPM, and the text-to-image diffusion models, e.g., Stable Diffusion. Experimental results demonstrate that our methods precisely infer the membership with high confidence on both of the two scenarios across six different datasets","link":"http://arxiv.org/abs/2302.01316v1","created":"2023-02-02","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Are Diffusion Models Vulnerable to Membership Inference Attacks? Diffusion-based generative models have shown great potential for image synthesis, but there is a lack of research on the security and privacy risks they may pose. In this paper, we investigate the vulnerability of diffusion models to Membership Inference Attacks (MIAs), a common privacy concern. Our results indicate that existing MIAs designed for GANs or VAE are largely ineffective on diffusion models, either due to inapplicable scenarios (e.g., requiring the discriminator of GANs) or inappropriate assumptions (e.g., closer distances between synthetic images and member images). To address this gap, we propose Step-wise Error Comparing Membership Inference (SecMI), a black-box MIA that infers memberships by assessing the matching of forward process posterior estimation at each timestep. SecMI follows the common overfitting assumption in MIA where member samples normally have smaller estimation errors, compared with hold-out samples. We consider both the standard diffusion models, e.g., DDPM, and the text-to-image diffusion models, e.g., Stable Diffusion. Experimental results demonstrate that our methods precisely infer the membership with high confidence on both of the two scenarios across six different datasets","classes":{"dataset":0.2109122574}}
{"title":"Developing Hands-on Labs for Source Code Vulnerability Detection with AI","description":"As the role of information and communication technologies gradually increases in our lives, source code security becomes a significant issue to protect against malicious attempts Furthermore with the advent of data-driven techniques, there is now a growing interest in leveraging machine learning and natural language processing as a source code assurance method to build trustworthy systems Therefore training our future software developers to write secure source code is in high demand In this thesis we propose a framework including learning modules and hands on labs to guide future IT professionals towards developing secure programming habits and mitigating source code vulnerabilities at the early stages of the software development lifecycle In this thesis our goal is to design learning modules with a set of hands on labs that will introduce students to secure programming practices using source code and log file analysis tools to predict and identify vulnerabilities In a Secure Coding Education framework we will improve students skills and awareness on source code vulnerabilities detection tools and mitigation techniques integrate concepts of source code vulnerabilities from Function API and library level to bad programming habits and practices leverage deep learning NLP and static analysis tools for log file analysis to introduce the root cause of source code vulnerabilities","link":"http://arxiv.org/abs/2302.00750v1","created":"2023-02-01","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Developing Hands-on Labs for Source Code Vulnerability Detection with AI As the role of information and communication technologies gradually increases in our lives, source code security becomes a significant issue to protect against malicious attempts Furthermore with the advent of data-driven techniques, there is now a growing interest in leveraging machine learning and natural language processing as a source code assurance method to build trustworthy systems Therefore training our future software developers to write secure source code is in high demand In this thesis we propose a framework including learning modules and hands on labs to guide future IT professionals towards developing secure programming habits and mitigating source code vulnerabilities at the early stages of the software development lifecycle In this thesis our goal is to design learning modules with a set of hands on labs that will introduce students to secure programming practices using source code and log file analysis tools to predict and identify vulnerabilities In a Secure Coding Education framework we will improve students skills and awareness on source code vulnerabilities detection tools and mitigation techniques integrate concepts of source code vulnerabilities from Function API and library level to bad programming habits and practices leverage deep learning NLP and static analysis tools for log file analysis to introduce the root cause of source code vulnerabilities","classes":{"dataset":0.7528961301}}
{"title":"CATFL: Certificateless Authentication-based Trustworthy Federated Learning for 6G Semantic Communications","description":"Federated learning (FL) provides an emerging approach for collaboratively training semantic encoder/decoder models of semantic communication systems, without private user data leaving the devices. Most existing studies on trustworthy FL aim to eliminate data poisoning threats that are produced by malicious clients, but in many cases, eliminating model poisoning attacks brought by fake servers is also an important objective. In this paper, a certificateless authentication-based trustworthy federated learning (CATFL) framework is proposed, which mutually authenticates the identity of clients and server. In CATFL, each client verifies the server's signature information before accepting the delivered global model to ensure that the global model is not delivered by false servers. On the contrary, the server also verifies the server's signature information before accepting the delivered model updates to ensure that they are submitted by authorized clients. Compared to PKI-based methods, the CATFL can avoid too high certificate management overheads. Meanwhile, the anonymity of clients shields data poisoning attacks, while real-name registration may suffer from user-specific privacy leakage risks. Therefore, a pseudonym generation strategy is also presented in CATFL to achieve a trade-off between identity traceability and user anonymity, which is essential to conditionally prevent from user-specific privacy leakage. Theoretical security analysis and evaluation results validate the superiority of CATFL.","link":"http://arxiv.org/abs/2302.00271v1","created":"2023-02-01","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"CATFL: Certificateless Authentication-based Trustworthy Federated Learning for 6G Semantic Communications Federated learning (FL) provides an emerging approach for collaboratively training semantic encoder/decoder models of semantic communication systems, without private user data leaving the devices. Most existing studies on trustworthy FL aim to eliminate data poisoning threats that are produced by malicious clients, but in many cases, eliminating model poisoning attacks brought by fake servers is also an important objective. In this paper, a certificateless authentication-based trustworthy federated learning (CATFL) framework is proposed, which mutually authenticates the identity of clients and server. In CATFL, each client verifies the server's signature information before accepting the delivered global model to ensure that the global model is not delivered by false servers. On the contrary, the server also verifies the server's signature information before accepting the delivered model updates to ensure that they are submitted by authorized clients. Compared to PKI-based methods, the CATFL can avoid too high certificate management overheads. Meanwhile, the anonymity of clients shields data poisoning attacks, while real-name registration may suffer from user-specific privacy leakage risks. Therefore, a pseudonym generation strategy is also presented in CATFL to achieve a trade-off between identity traceability and user anonymity, which is essential to conditionally prevent from user-specific privacy leakage. Theoretical security analysis and evaluation results validate the superiority of CATFL.","classes":{"dataset":0.016556561}}
{"title":"Fixing Hardware Security Bugs with Large Language Models","description":"Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI's Codex have demonstrated capabilities in many coding-adjacent domains. In this work we consider how LLMs maybe leveraged to automatically repair security relevant bugs present in hardware designs. We focus on bug repair in code written in the Hardware Description Language Verilog. For this study we build a corpus of domain-representative hardware security bugs. We then design and implement a framework to quantitatively evaluate the performance of any LLM tasked with fixing the specified bugs. The framework supports design space exploration of prompts (i.e., prompt engineering) and identifying the best parameters for the LLM. We show that an ensemble of LLMs can repair all ten of our benchmarks. This ensemble outperforms the state-of-the-art Cirfix hardware bug repair tool on its own suite of bugs. These results show that LLMs can repair hardware security bugs and the framework is an important step towards the ultimate goal of an automated end-to-end bug repair framework.","link":"http://arxiv.org/abs/2302.01215v1","created":"2023-02-02","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Fixing Hardware Security Bugs with Large Language Models Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI's Codex have demonstrated capabilities in many coding-adjacent domains. In this work we consider how LLMs maybe leveraged to automatically repair security relevant bugs present in hardware designs. We focus on bug repair in code written in the Hardware Description Language Verilog. For this study we build a corpus of domain-representative hardware security bugs. We then design and implement a framework to quantitatively evaluate the performance of any LLM tasked with fixing the specified bugs. The framework supports design space exploration of prompts (i.e., prompt engineering) and identifying the best parameters for the LLM. We show that an ensemble of LLMs can repair all ten of our benchmarks. This ensemble outperforms the state-of-the-art Cirfix hardware bug repair tool on its own suite of bugs. These results show that LLMs can repair hardware security bugs and the framework is an important step towards the ultimate goal of an automated end-to-end bug repair framework.","classes":{"dataset":0.7528961301}}
{"title":"Get3DHuman: Lifting StyleGAN-Human into a 3D Generative Model using Pixel-aligned Reconstruction Priors","description":"Fast generation of high-quality 3D digital humans is important to a vast number of applications ranging from entertainment to professional concerns. Recent advances in differentiable rendering have enabled the training of 3D generative models without requiring 3D ground truths. However, the quality of the generated 3D humans still has much room to improve in terms of both fidelity and diversity. In this paper, we present Get3DHuman, a novel 3D human framework that can significantly boost the realism and diversity of the generated outcomes by only using a limited budget of 3D ground-truth data. Our key observation is that the 3D generator can profit from human-related priors learned through 2D human generators and 3D reconstructors. Specifically, we bridge the latent space of Get3DHuman with that of StyleGAN-Human via a specially-designed prior network, where the input latent code is mapped to the shape and texture feature volumes spanned by the pixel-aligned 3D reconstructor. The outcomes of the prior network are then leveraged as the supervisory signals for the main generator network. To ensure effective training, we further propose three tailored losses applied to the generated feature volumes and the intermediate feature maps. Extensive experiments demonstrate that Get3DHuman greatly outperforms the other state-of-the-art approaches and can support a wide range of applications including shape interpolation, shape re-texturing, and single-view reconstruction through latent inversion.","link":"http://arxiv.org/abs/2302.01162v1","created":"2023-02-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Get3DHuman: Lifting StyleGAN-Human into a 3D Generative Model using Pixel-aligned Reconstruction Priors Fast generation of high-quality 3D digital humans is important to a vast number of applications ranging from entertainment to professional concerns. Recent advances in differentiable rendering have enabled the training of 3D generative models without requiring 3D ground truths. However, the quality of the generated 3D humans still has much room to improve in terms of both fidelity and diversity. In this paper, we present Get3DHuman, a novel 3D human framework that can significantly boost the realism and diversity of the generated outcomes by only using a limited budget of 3D ground-truth data. Our key observation is that the 3D generator can profit from human-related priors learned through 2D human generators and 3D reconstructors. Specifically, we bridge the latent space of Get3DHuman with that of StyleGAN-Human via a specially-designed prior network, where the input latent code is mapped to the shape and texture feature volumes spanned by the pixel-aligned 3D reconstructor. The outcomes of the prior network are then leveraged as the supervisory signals for the main generator network. To ensure effective training, we further propose three tailored losses applied to the generated feature volumes and the intermediate feature maps. Extensive experiments demonstrate that Get3DHuman greatly outperforms the other state-of-the-art approaches and can support a wide range of applications including shape interpolation, shape re-texturing, and single-view reconstruction through latent inversion.","classes":{"dataset":0.3043656647}}
{"title":"Eloss in the way: A Sensitive Input Quality Metrics for Intelligent Driving","description":"With the increasing complexity of the traffic environment, the importance of safety perception in intelligent driving is growing. Conventional methods in the robust perception of intelligent driving focus on training models with anomalous data, letting the deep neural network decide how to tackle anomalies. However, these models cannot adapt smoothly to the diverse and complex real-world environment. This paper proposes a new type of metric known as Eloss and offers a novel training strategy to empower perception models from the aspect of anomaly detection. Eloss is designed based on an explanation of the perception model's information compression layers. Specifically, taking inspiration from the design of a communication system, the information transmission process of an information compression network has two expectations: the amount of information changes steadily, and the information entropy continues to decrease. Then Eloss can be obtained according to the above expectations, guiding the update of related network parameters and producing a sensitive metric to identify anomalies while maintaining the model performance. Our experiments demonstrate that Eloss can deviate from the standard value by a factor over 100 with anomalous data and produce distinctive values for similar but different types of anomalies, showing the effectiveness of the proposed method. Our code is available at: (code available after paper accepted).","link":"http://arxiv.org/abs/2302.00986v1","created":"2023-02-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Eloss in the way: A Sensitive Input Quality Metrics for Intelligent Driving With the increasing complexity of the traffic environment, the importance of safety perception in intelligent driving is growing. Conventional methods in the robust perception of intelligent driving focus on training models with anomalous data, letting the deep neural network decide how to tackle anomalies. However, these models cannot adapt smoothly to the diverse and complex real-world environment. This paper proposes a new type of metric known as Eloss and offers a novel training strategy to empower perception models from the aspect of anomaly detection. Eloss is designed based on an explanation of the perception model's information compression layers. Specifically, taking inspiration from the design of a communication system, the information transmission process of an information compression network has two expectations: the amount of information changes steadily, and the information entropy continues to decrease. Then Eloss can be obtained according to the above expectations, guiding the update of related network parameters and producing a sensitive metric to identify anomalies while maintaining the model performance. Our experiments demonstrate that Eloss can deviate from the standard value by a factor over 100 with anomalous data and produce distinctive values for similar but different types of anomalies, showing the effectiveness of the proposed method. Our code is available at: (code available after paper accepted).","classes":{"dataset":0.1326745152}}
{"title":"A Light-weight CNN Model for Efficient Parkinson's Disease Diagnostics","description":"In recent years, deep learning methods have achieved great success in various fields due to their strong performance in practical applications. In this paper, we present a light-weight neural network for Parkinson's disease diagnostics, in which a series of hand-drawn data are collected to distinguish Parkinson's disease patients from healthy control subjects. The proposed model consists of a convolution neural network (CNN) cascading to long-short-term memory (LSTM) to adapt the characteristics of collected time-series signals. To make full use of their advantages, a multilayered LSTM model is firstly used to enrich features which are then concatenated with raw data and fed into a shallow one-dimensional (1D) CNN model for efficient classification. Experimental results show that the proposed model achieves a high-quality diagnostic result over multiple evaluation metrics with much fewer parameters and operations, outperforming conventional methods such as support vector machine (SVM), random forest (RF), lightgbm (LGB) and CNN-based methods.","link":"http://arxiv.org/abs/2302.00973v1","created":"2023-02-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"A Light-weight CNN Model for Efficient Parkinson's Disease Diagnostics In recent years, deep learning methods have achieved great success in various fields due to their strong performance in practical applications. In this paper, we present a light-weight neural network for Parkinson's disease diagnostics, in which a series of hand-drawn data are collected to distinguish Parkinson's disease patients from healthy control subjects. The proposed model consists of a convolution neural network (CNN) cascading to long-short-term memory (LSTM) to adapt the characteristics of collected time-series signals. To make full use of their advantages, a multilayered LSTM model is firstly used to enrich features which are then concatenated with raw data and fed into a shallow one-dimensional (1D) CNN model for efficient classification. Experimental results show that the proposed model achieves a high-quality diagnostic result over multiple evaluation metrics with much fewer parameters and operations, outperforming conventional methods such as support vector machine (SVM), random forest (RF), lightgbm (LGB) and CNN-based methods.","classes":{"dataset":0.1602863967}}
{"title":"How to choose \"Good\" Samples for Text Data Augmentation","description":"Deep learning-based text classification models need abundant labeled data to obtain competitive performance. Unfortunately, annotating large-size corpus is time-consuming and laborious. To tackle this, multiple researches try to use data augmentation to expand the corpus size. However, data augmentation may potentially produce some noisy augmented samples. There are currently no works exploring sample selection for augmented samples in nature language processing field. In this paper, we propose a novel self-training selection framework with two selectors to select the high-quality samples from data augmentation. Specifically, we firstly use an entropy-based strategy and the model prediction to select augmented samples. Considering some samples with high quality at the above step may be wrongly filtered, we propose to recall them from two perspectives of word overlap and semantic similarity. Experimental results show the effectiveness and simplicity of our framework.","link":"http://arxiv.org/abs/2302.00894v1","created":"2023-02-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"How to choose \"Good\" Samples for Text Data Augmentation Deep learning-based text classification models need abundant labeled data to obtain competitive performance. Unfortunately, annotating large-size corpus is time-consuming and laborious. To tackle this, multiple researches try to use data augmentation to expand the corpus size. However, data augmentation may potentially produce some noisy augmented samples. There are currently no works exploring sample selection for augmented samples in nature language processing field. In this paper, we propose a novel self-training selection framework with two selectors to select the high-quality samples from data augmentation. Specifically, we firstly use an entropy-based strategy and the model prediction to select augmented samples. Considering some samples with high quality at the above step may be wrongly filtered, we propose to recall them from two perspectives of word overlap and semantic similarity. Experimental results show the effectiveness and simplicity of our framework.","classes":{"dataset":0.0549077578}}
{"title":"Disentanglement of Latent Representations via Sparse Causal Interventions","description":"The process of generating data such as images is controlled by independent and unknown factors of variation. The retrieval of these variables has been studied extensively in the disentanglement, causal representation learning, and independent component analysis fields. Recently, approaches merging these domains together have shown great success. Instead of directly representing the factors of variation, the problem of disentanglement can be seen as finding the interventions on one image that yield a change to a single factor. Following this assumption, we introduce a new method for disentanglement inspired by causal dynamics that combines causality theory with vector-quantized variational autoencoders. Our model considers the quantized vectors as causal variables and links them in a causal graph. It performs causal interventions on the graph and generates atomic transitions affecting a unique factor of variation in the image. We also introduce a new task of action retrieval that consists of finding the action responsible for the transition between two images. We test our method on standard synthetic and real-world disentanglement datasets. We show that it can effectively disentangle the factors of variation and perform precise interventions on high-level semantic attributes of an image without affecting its quality, even with imbalanced data distributions.","link":"http://arxiv.org/abs/2302.00869v1","created":"2023-02-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Disentanglement of Latent Representations via Sparse Causal Interventions The process of generating data such as images is controlled by independent and unknown factors of variation. The retrieval of these variables has been studied extensively in the disentanglement, causal representation learning, and independent component analysis fields. Recently, approaches merging these domains together have shown great success. Instead of directly representing the factors of variation, the problem of disentanglement can be seen as finding the interventions on one image that yield a change to a single factor. Following this assumption, we introduce a new method for disentanglement inspired by causal dynamics that combines causality theory with vector-quantized variational autoencoders. Our model considers the quantized vectors as causal variables and links them in a causal graph. It performs causal interventions on the graph and generates atomic transitions affecting a unique factor of variation in the image. We also introduce a new task of action retrieval that consists of finding the action responsible for the transition between two images. We test our method on standard synthetic and real-world disentanglement datasets. We show that it can effectively disentangle the factors of variation and perform precise interventions on high-level semantic attributes of an image without affecting its quality, even with imbalanced data distributions.","classes":{"dataset":0.1147925258}}
{"title":"ImageNomer: developing an fMRI and omics visualization tool to detect racial bias in functional connectivity","description":"It can be difficult to identify trends and perform quality control in large, high-dimensional fMRI or omics datasets. To remedy this, we develop ImageNomer, a data visualization and analysis tool that allows inspection of both subject-level and cohort-level features. The tool allows visualization of phenotype correlation with functional connectivity (FC), partial connectivity (PC), dictionary components (PCA and our own method), and genomic data (single-nucleotide polymorphisms, SNPs). In addition, it allows visualization of weights from arbitrary ML models. ImageNomer is built with a Python backend and a Vue frontend. We validate ImageNomer using the Philadelphia Neurodevelopmental Cohort (PNC) dataset, which contains multitask fMRI and SNP data of healthy adolescents. Using correlation, greedy selection, or model weights, we find that a set of 10 FC features can explain 15% of variation in age, compared to 35% for the full 34,716 feature model. The four most significant FCs are either between bilateral default mode network (DMN) regions or spatially proximal subcortical areas. Additionally, we show that whereas both FC (fMRI) and SNPs (genomic) features can account for 10-15% of intelligence variation, this predictive ability disappears when controlling for race. We find that FC features can be used to predict race with 85% accuracy, compared to 78% accuracy for sex prediction. Using ImageNomer, this work casts doubt on the possibility of finding unbiased intelligence-related features in fMRI and SNPs of healthy adolescents.","link":"http://arxiv.org/abs/2302.00767v1","created":"2023-02-01","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"ImageNomer: developing an fMRI and omics visualization tool to detect racial bias in functional connectivity It can be difficult to identify trends and perform quality control in large, high-dimensional fMRI or omics datasets. To remedy this, we develop ImageNomer, a data visualization and analysis tool that allows inspection of both subject-level and cohort-level features. The tool allows visualization of phenotype correlation with functional connectivity (FC), partial connectivity (PC), dictionary components (PCA and our own method), and genomic data (single-nucleotide polymorphisms, SNPs). In addition, it allows visualization of weights from arbitrary ML models. ImageNomer is built with a Python backend and a Vue frontend. We validate ImageNomer using the Philadelphia Neurodevelopmental Cohort (PNC) dataset, which contains multitask fMRI and SNP data of healthy adolescents. Using correlation, greedy selection, or model weights, we find that a set of 10 FC features can explain 15% of variation in age, compared to 35% for the full 34,716 feature model. The four most significant FCs are either between bilateral default mode network (DMN) regions or spatially proximal subcortical areas. Additionally, we show that whereas both FC (fMRI) and SNPs (genomic) features can account for 10-15% of intelligence variation, this predictive ability disappears when controlling for race. We find that FC features can be used to predict race with 85% accuracy, compared to 78% accuracy for sex prediction. Using ImageNomer, this work casts doubt on the possibility of finding unbiased intelligence-related features in fMRI and SNPs of healthy adolescents.","classes":{"dataset":0.0277819168}}
{"title":"Graph Neural Operators for Classification of Spatial Transcriptomics Data","description":"The inception of spatial transcriptomics has allowed improved comprehension of tissue architectures and the disentanglement of complex underlying biological, physiological, and pathological processes through their positional contexts. Recently, these contexts, and by extension the field, have seen much promise and elucidation with the application of graph learning approaches. In particular, neural operators have risen in regards to learning the mapping between infinite-dimensional function spaces. With basic to deep neural network architectures being data-driven, i.e. dependent on quality data for prediction, neural operators provide robustness by offering generalization among different resolutions despite low quality data. Graph neural operators are a variant that utilize graph networks to learn this mapping between function spaces. The aim of this research is to identify robust machine learning architectures that integrate spatial information to predict tissue types. Under this notion, we propose a study incorporating various graph neural network approaches to validate the efficacy of applying neural operators towards prediction of brain regions in mouse brain tissue samples as a proof of concept towards our purpose. We were able to achieve an F1 score of nearly 72% for the graph neural operator approach which outperformed all baseline and other graph network approaches.","link":"http://arxiv.org/abs/2302.00658v1","created":"2023-02-01","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Graph Neural Operators for Classification of Spatial Transcriptomics Data The inception of spatial transcriptomics has allowed improved comprehension of tissue architectures and the disentanglement of complex underlying biological, physiological, and pathological processes through their positional contexts. Recently, these contexts, and by extension the field, have seen much promise and elucidation with the application of graph learning approaches. In particular, neural operators have risen in regards to learning the mapping between infinite-dimensional function spaces. With basic to deep neural network architectures being data-driven, i.e. dependent on quality data for prediction, neural operators provide robustness by offering generalization among different resolutions despite low quality data. Graph neural operators are a variant that utilize graph networks to learn this mapping between function spaces. The aim of this research is to identify robust machine learning architectures that integrate spatial information to predict tissue types. Under this notion, we propose a study incorporating various graph neural network approaches to validate the efficacy of applying neural operators towards prediction of brain regions in mouse brain tissue samples as a proof of concept towards our purpose. We were able to achieve an F1 score of nearly 72% for the graph neural operator approach which outperformed all baseline and other graph network approaches.","classes":{"dataset":0.0927816331}}
{"title":"Calibration of the Upgraded ALICE Inner Tracking System","description":"The ALICE Experiment has replaced its Inner Tracking System with a 7-layer pixel-only tracker made out of more than 24000 monolithic active pixel sensor chips, in order to fulfill the requirements of the physics program of the LHC Run 3. The upgraded Inner Tracking System (ITS2) has been installed in the ALICE experiment during the LHC long shutdown 2 and has started to take data with the beginning of Run 3 in July 2022, with proton-proton collisions at $\\sqrt{s}$ = 13.6 TeV. With its 12.5 billion pixels it is the largest pixel detector installed in a high energy physics experiment to date. To guarantee stable operation and a consistently high data quality, a regular calibration of the detector has to be performed. The main part of the calibration program consists of a tuning and subsequent measurement of the pixel thresholds and a determination of the noisy channels. In particular the complexity of the threshold scan depends linearly on the number of pixels, which is why the threshold scan of the ITS2 is an unprecedented challenge. This work describes the architecture of the calibration framework, which has been developed using the detector control system of the ITS2 and the ALICE data processing layer. Results of first threshold and noise calibrations done in situ are shown as well.","link":"http://arxiv.org/abs/2302.00433v1","created":"2023-02-01","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Calibration of the Upgraded ALICE Inner Tracking System The ALICE Experiment has replaced its Inner Tracking System with a 7-layer pixel-only tracker made out of more than 24000 monolithic active pixel sensor chips, in order to fulfill the requirements of the physics program of the LHC Run 3. The upgraded Inner Tracking System (ITS2) has been installed in the ALICE experiment during the LHC long shutdown 2 and has started to take data with the beginning of Run 3 in July 2022, with proton-proton collisions at $\\sqrt{s}$ = 13.6 TeV. With its 12.5 billion pixels it is the largest pixel detector installed in a high energy physics experiment to date. To guarantee stable operation and a consistently high data quality, a regular calibration of the detector has to be performed. The main part of the calibration program consists of a tuning and subsequent measurement of the pixel thresholds and a determination of the noisy channels. In particular the complexity of the threshold scan depends linearly on the number of pixels, which is why the threshold scan of the ITS2 is an unprecedented challenge. This work describes the architecture of the calibration framework, which has been developed using the detector control system of the ITS2 and the ALICE data processing layer. Results of first threshold and noise calibrations done in situ are shown as well.","classes":{"dataset":0.1958165914}}
{"title":"W2SAT: Learning to generate SAT instances from Weighted Literal Incidence Graphs","description":"The Boolean Satisfiability (SAT) problem stands out as an attractive NP-complete problem in theoretic computer science and plays a central role in a broad spectrum of computing-related applications. Exploiting and tuning SAT solvers under numerous scenarios require massive high-quality industry-level SAT instances, which unfortunately are quite limited in the real world. To address the data insufficiency issue, in this paper, we propose W2SAT, a framework to generate SAT formulas by learning intrinsic structures and properties from given real-world/industrial instances in an implicit fashion. To this end, we introduce a novel SAT representation called Weighted Literal Incidence Graph (WLIG), which exhibits strong representation ability and generalizability against existing counterparts, and can be efficiently generated via a specialized learning-based graph generative model. Decoding from WLIGs into SAT problems is then modeled as finding overlapping cliques with a novel hill-climbing optimization method termed Optimal Weight Coverage (OWC). Experiments demonstrate the superiority of our WLIG-induced approach in terms of graph metrics, efficiency, and scalability in comparison to previous methods. Additionally, we discuss the limitations of graph-based SAT generation for real-world applications, especially when utilizing generated instances for SAT solver parameter-tuning, and pose some potential directions.","link":"http://arxiv.org/abs/2302.00272v1","created":"2023-02-01","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"W2SAT: Learning to generate SAT instances from Weighted Literal Incidence Graphs The Boolean Satisfiability (SAT) problem stands out as an attractive NP-complete problem in theoretic computer science and plays a central role in a broad spectrum of computing-related applications. Exploiting and tuning SAT solvers under numerous scenarios require massive high-quality industry-level SAT instances, which unfortunately are quite limited in the real world. To address the data insufficiency issue, in this paper, we propose W2SAT, a framework to generate SAT formulas by learning intrinsic structures and properties from given real-world/industrial instances in an implicit fashion. To this end, we introduce a novel SAT representation called Weighted Literal Incidence Graph (WLIG), which exhibits strong representation ability and generalizability against existing counterparts, and can be efficiently generated via a specialized learning-based graph generative model. Decoding from WLIGs into SAT problems is then modeled as finding overlapping cliques with a novel hill-climbing optimization method termed Optimal Weight Coverage (OWC). Experiments demonstrate the superiority of our WLIG-induced approach in terms of graph metrics, efficiency, and scalability in comparison to previous methods. Additionally, we discuss the limitations of graph-based SAT generation for real-world applications, especially when utilizing generated instances for SAT solver parameter-tuning, and pose some potential directions.","classes":{"dataset":0.207964927}}
{"title":"FLSTRA: Federated Learning in Stratosphere","description":"We propose a federated learning (FL) in stratosphere (FLSTRA) system, where a high altitude platform station (HAPS) felicitates a large number of terrestrial clients to collaboratively learn a global model without sharing the training data. FLSTRA overcomes the challenges faced by FL in terrestrial networks, such as slow convergence and high communication delay due to limited client participation and multi-hop communications. HAPS leverages its altitude and size to allow the participation of more clients with line-of-sight (LoS) links and the placement of a powerful server. However, handling many clients at once introduces computing and transmission delays. Thus, we aim to obtain a delay-accuracy trade-off for FLSTRA. Specifically, we first develop a joint client selection and resource allocation algorithm for uplink and downlink to minimize the FL delay subject to the energy and quality-of-service (QoS) constraints. Second, we propose a communication and computation resource-aware (CCRA-FL) algorithm to achieve the target FL accuracy while deriving an upper bound for its convergence rate. The formulated problem is non-convex; thus, we propose an iterative algorithm to solve it. Simulation results demonstrate the effectiveness of the proposed FLSTRA system, compared to terrestrial benchmarks, in terms of FL delay and accuracy.","link":"http://arxiv.org/abs/2302.00163v1","created":"2023-02-01","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"FLSTRA: Federated Learning in Stratosphere We propose a federated learning (FL) in stratosphere (FLSTRA) system, where a high altitude platform station (HAPS) felicitates a large number of terrestrial clients to collaboratively learn a global model without sharing the training data. FLSTRA overcomes the challenges faced by FL in terrestrial networks, such as slow convergence and high communication delay due to limited client participation and multi-hop communications. HAPS leverages its altitude and size to allow the participation of more clients with line-of-sight (LoS) links and the placement of a powerful server. However, handling many clients at once introduces computing and transmission delays. Thus, we aim to obtain a delay-accuracy trade-off for FLSTRA. Specifically, we first develop a joint client selection and resource allocation algorithm for uplink and downlink to minimize the FL delay subject to the energy and quality-of-service (QoS) constraints. Second, we propose a communication and computation resource-aware (CCRA-FL) algorithm to achieve the target FL accuracy while deriving an upper bound for its convergence rate. The formulated problem is non-convex; thus, we propose an iterative algorithm to solve it. Simulation results demonstrate the effectiveness of the proposed FLSTRA system, compared to terrestrial benchmarks, in terms of FL delay and accuracy.","classes":{"dataset":0.1429443061}}
{"title":"Show HN: I trained an AI model on 120M+ songs from iTunes","description":"https://maroofy.com/?hn=v3","link":"https://maroofy.com/?hn=v3","created":"2023-02-03","tags":["hackernews"],"meta":{"score":550},"text":"Show HN: I trained an AI model on 120M+ songs from iTunes https://maroofy.com/?hn=v3","classes":{"dataset":0.5369210243}}
{"title":"I\u2019m now a full-time professional open source maintainer","description":"https://words.filippo.io/full-time-maintainer/","link":"https://words.filippo.io/full-time-maintainer/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":522},"text":"I\u2019m now a full-time professional open source maintainer https://words.filippo.io/full-time-maintainer/","classes":{"dataset":0.4691913724}}
{"title":"Against risk-based authentication (or, why I wouldn't trust Google Cloud)","description":"https://www.devever.net/~hl/logindenial","link":"https://www.devever.net/~hl/logindenial","created":"2023-02-03","tags":["hackernews"],"meta":{"score":64},"text":"Against risk-based authentication (or, why I wouldn't trust Google Cloud) https://www.devever.net/~hl/logindenial","classes":{"dataset":0.4535200596}}
{"title":"An obituary for the man who saved North Carolina from Nuclear Disaster","description":"https://www.ncrabbithole.com/p/jack-revelle-goldsboro-nc-broken-arrow-obituary","link":"https://www.ncrabbithole.com/p/jack-revelle-goldsboro-nc-broken-arrow-obituary","created":"2023-02-03","tags":["hackernews"],"meta":{"score":228},"text":"An obituary for the man who saved North Carolina from Nuclear Disaster https://www.ncrabbithole.com/p/jack-revelle-goldsboro-nc-broken-arrow-obituary","classes":{"dataset":0.4762351513}}
{"title":"The ingenious design of the aluminum beverage can (2015) [video]","description":"https://www.youtube.com/watch?v=hUhisi2FBuw","link":"https://www.youtube.com/watch?v=hUhisi2FBuw","created":"2023-02-02","tags":["hackernews"],"meta":{"score":74},"text":"The ingenious design of the aluminum beverage can (2015) [video] https://www.youtube.com/watch?v=hUhisi2FBuw","classes":{"dataset":0.5487950444}}
{"title":"Seawater electrolysis by adjusting the local reaction environment of a catalyst","description":"https://www.nature.com/articles/s41560-023-01195-x","link":"https://www.nature.com/articles/s41560-023-01195-x","created":"2023-02-03","tags":["hackernews"],"meta":{"score":165},"text":"Seawater electrolysis by adjusting the local reaction environment of a catalyst https://www.nature.com/articles/s41560-023-01195-x","classes":{"dataset":0.4807120562}}
{"title":"Starting February 9, we will no longer support free access to the Twitter API","description":"https://twitter.com/twitterdev/status/1621026986784337922","link":"https://twitter.com/twitterdev/status/1621026986784337922","created":"2023-02-02","tags":["hackernews"],"meta":{"score":407},"text":"Starting February 9, we will no longer support free access to the Twitter API https://twitter.com/twitterdev/status/1621026986784337922","classes":{"dataset":0.5043385625}}
{"title":"Play Counter Strike 1.6, with full multiplayer, in the browser","description":"https://play-cs.com/en/servers","link":"https://play-cs.com/en/servers","created":"2023-02-02","tags":["hackernews"],"meta":{"score":1189},"text":"Play Counter Strike 1.6, with full multiplayer, in the browser https://play-cs.com/en/servers","classes":{"dataset":0.5711914301}}
{"title":"Bir Tawil","description":"https://en.wikipedia.org/wiki/Bir_Tawil","link":"https://en.wikipedia.org/wiki/Bir_Tawil","created":"2023-02-02","tags":["hackernews"],"meta":{"score":24},"text":"Bir Tawil https://en.wikipedia.org/wiki/Bir_Tawil","classes":{"dataset":0.5419430733}}
{"title":"Retrospective for a Ragtime King","description":"https://van-magazine.com/mag/retrospection-for-a-ragtime-king/","link":"https://van-magazine.com/mag/retrospection-for-a-ragtime-king/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":3},"text":"Retrospective for a Ragtime King https://van-magazine.com/mag/retrospection-for-a-ragtime-king/","classes":{"dataset":0.5030075312}}
{"title":"Reflections on My Decade at Sumo Logic","description":"https://jacek.migdal.pl/2023/02/01/ten-years.html","link":"https://jacek.migdal.pl/2023/02/01/ten-years.html","created":"2023-02-01","tags":["hackernews"],"meta":{"score":102},"text":"Reflections on My Decade at Sumo Logic https://jacek.migdal.pl/2023/02/01/ten-years.html","classes":{"dataset":0.5251471996}}
{"title":"John Carmack\u2019s \u2018Different Path\u2019 to Artificial General Intelligence","description":"https://dallasinnovates.com/exclusive-qa-john-carmacks-different-path-to-artificial-general-intelligence/","link":"https://dallasinnovates.com/exclusive-qa-john-carmacks-different-path-to-artificial-general-intelligence/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":179},"text":"John Carmack\u2019s \u2018Different Path\u2019 to Artificial General Intelligence https://dallasinnovates.com/exclusive-qa-john-carmacks-different-path-to-artificial-general-intelligence/","classes":{"dataset":0.485724628}}
{"title":"A novel PayPal scam","description":"https://anderegg.ca/2023/02/01/a-novel-paypal-scam","link":"https://anderegg.ca/2023/02/01/a-novel-paypal-scam","created":"2023-02-01","tags":["hackernews"],"meta":{"score":85},"text":"A novel PayPal scam https://anderegg.ca/2023/02/01/a-novel-paypal-scam","classes":{"dataset":0.4820375443}}
{"title":"The Muppets\u2019 many spiritual insights","description":"https://therevealer.org/muppet-religion/","link":"https://therevealer.org/muppet-religion/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":85},"text":"The Muppets\u2019 many spiritual insights https://therevealer.org/muppet-religion/","classes":{"dataset":0.4985300601}}
{"title":"WASM compression benchmarks and the cost of missing compression APIs","description":"https://nickb.dev/blog/wasm-compression-benchmarks-and-the-cost-of-missing-compression-apis/","link":"https://nickb.dev/blog/wasm-compression-benchmarks-and-the-cost-of-missing-compression-apis/","created":"2023-02-01","tags":["hackernews"],"meta":{"score":86},"text":"WASM compression benchmarks and the cost of missing compression APIs https://nickb.dev/blog/wasm-compression-benchmarks-and-the-cost-of-missing-compression-apis/","classes":{"dataset":0.4879321158}}
{"title":"The Crack-Up (1936)","description":"https://www.esquire.com/lifestyle/a4310/the-crack-up/","link":"https://www.esquire.com/lifestyle/a4310/the-crack-up/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":18},"text":"The Crack-Up (1936) https://www.esquire.com/lifestyle/a4310/the-crack-up/","classes":{"dataset":0.5372530222}}
{"title":"Chinese surveillance balloon spotted over U.S., Pentagon says","description":"https://www.washingtonpost.com/national-security/2023/02/02/chinese-spy-balloon-pentagon/","link":"https://www.washingtonpost.com/national-security/2023/02/02/chinese-spy-balloon-pentagon/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":297},"text":"Chinese surveillance balloon spotted over U.S., Pentagon says https://www.washingtonpost.com/national-security/2023/02/02/chinese-spy-balloon-pentagon/","classes":{"dataset":0.538505137}}
{"title":"The unequal treatment of demographic groups by ChatGPT/OpenAI content moderation","description":"https://davidrozado.substack.com/p/openaicms","link":"https://davidrozado.substack.com/p/openaicms","created":"2023-02-02","tags":["hackernews"],"meta":{"score":479},"text":"The unequal treatment of demographic groups by ChatGPT/OpenAI content moderation https://davidrozado.substack.com/p/openaicms","classes":{"dataset":0.5025758147}}
{"title":"The Violin Doctor","description":"https://www.chicagomag.com/chicago-magazine/january-2023/the-violin-doctor/","link":"https://www.chicagomag.com/chicago-magazine/january-2023/the-violin-doctor/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":43},"text":"The Violin Doctor https://www.chicagomag.com/chicago-magazine/january-2023/the-violin-doctor/","classes":{"dataset":0.4927727282}}
{"title":"Goi\u00e2nia Accident","description":"https://en.wikipedia.org/wiki/Goi%C3%A2nia_accident","link":"https://en.wikipedia.org/wiki/Goi%C3%A2nia_accident","created":"2023-02-01","tags":["hackernews"],"meta":{"score":287},"text":"Goi\u00e2nia Accident https://en.wikipedia.org/wiki/Goi%C3%A2nia_accident","classes":{"dataset":0.5188778639}}
{"title":"Google search 'raters' demand fair treatment, deliver petition at headquarters","description":"https://www.mv-voice.com/news/2023/02/02/google-search-quality-raters-demand-fair-treatment-deliver-petition-at-mountain-view-headquarters","link":"https://www.mv-voice.com/news/2023/02/02/google-search-quality-raters-demand-fair-treatment-deliver-petition-at-mountain-view-headquarters","created":"2023-02-03","tags":["hackernews"],"meta":{"score":49},"text":"Google search 'raters' demand fair treatment, deliver petition at headquarters https://www.mv-voice.com/news/2023/02/02/google-search-quality-raters-demand-fair-treatment-deliver-petition-at-mountain-view-headquarters","classes":{"dataset":0.5084805489}}
{"title":"St. John\u2019s Reading List: A Great Books Curriculum","description":"https://www.sjc.edu/academic-programs/undergraduate/great-books-reading-list","link":"https://www.sjc.edu/academic-programs/undergraduate/great-books-reading-list","created":"2023-02-02","tags":["hackernews"],"meta":{"score":204},"text":"St. John\u2019s Reading List: A Great Books Curriculum https://www.sjc.edu/academic-programs/undergraduate/great-books-reading-list","classes":{"dataset":0.5141658783}}
{"title":"Colombian judge says he used ChatGPT in ruling","description":"https://www.theguardian.com/technology/2023/feb/03/colombia-judge-chatgpt-ruling","link":"https://www.theguardian.com/technology/2023/feb/03/colombia-judge-chatgpt-ruling","created":"2023-02-03","tags":["hackernews"],"meta":{"score":11},"text":"Colombian judge says he used ChatGPT in ruling https://www.theguardian.com/technology/2023/feb/03/colombia-judge-chatgpt-ruling","classes":{"dataset":0.5364054441}}
{"title":"The 27th Letter","description":"https://www.poetryfoundation.org/harriet-books/2016/01/the-27th-letter","link":"https://www.poetryfoundation.org/harriet-books/2016/01/the-27th-letter","created":"2023-02-02","tags":["hackernews"],"meta":{"score":34},"text":"The 27th Letter https://www.poetryfoundation.org/harriet-books/2016/01/the-27th-letter","classes":{"dataset":0.4980924428}}
{"title":"Stop the proposal on mass surveillance of the EU","description":"https://mullvad.net/nl/blog/2023/2/2/stop-the-proposal-on-mass-surveillance-of-the-eu/","link":"https://mullvad.net/nl/blog/2023/2/2/stop-the-proposal-on-mass-surveillance-of-the-eu/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":1435},"text":"Stop the proposal on mass surveillance of the EU https://mullvad.net/nl/blog/2023/2/2/stop-the-proposal-on-mass-surveillance-of-the-eu/","classes":{"dataset":0.4963569939}}
{"title":"Battle of the botanic garden","description":"https://www.theguardian.com/environment/2023/jan/26/battle-of-the-botanic-garden-the-horticulture-war-roiling-the-isle-of-wight","link":"https://www.theguardian.com/environment/2023/jan/26/battle-of-the-botanic-garden-the-horticulture-war-roiling-the-isle-of-wight","created":"2023-01-31","tags":["hackernews"],"meta":{"score":19},"text":"Battle of the botanic garden https://www.theguardian.com/environment/2023/jan/26/battle-of-the-botanic-garden-the-horticulture-war-roiling-the-isle-of-wight","classes":{"dataset":0.5042244792}}
{"title":"Show HN: Groundhog-day.com \u2013 structured groundhog data","description":"https://groundhog-day.com","link":"https://groundhog-day.com","created":"2023-02-02","tags":["hackernews"],"meta":{"score":113},"text":"Show HN: Groundhog-day.com \u2013 structured groundhog data https://groundhog-day.com","classes":{"dataset":0.4908809662}}
{"title":"AI model on a $3 chip (ESP32)","description":"https://maxlab.io/store/edge-ai-camera/","link":"https://maxlab.io/store/edge-ai-camera/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":134},"text":"AI model on a $3 chip (ESP32) https://maxlab.io/store/edge-ai-camera/","classes":{"dataset":0.4914220572}}
{"title":"A 50-Year Quest: My Personal Journey with the Second Law of Thermodynamics","description":"https://writings.stephenwolfram.com/2023/02/a-50-year-quest-my-personal-journey-with-the-second-law-of-thermodynamics/","link":"https://writings.stephenwolfram.com/2023/02/a-50-year-quest-my-personal-journey-with-the-second-law-of-thermodynamics/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":17},"text":"A 50-Year Quest: My Personal Journey with the Second Law of Thermodynamics https://writings.stephenwolfram.com/2023/02/a-50-year-quest-my-personal-journey-with-the-second-law-of-thermodynamics/","classes":{"dataset":0.5096104741}}
{"title":"Exploring Rust for Vulkan drivers, part 1","description":"https://www.collabora.com/news-and-blog/blog/2023/02/02/exploring-rust-for-vulkan-drivers-part-1/","link":"https://www.collabora.com/news-and-blog/blog/2023/02/02/exploring-rust-for-vulkan-drivers-part-1/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":151},"text":"Exploring Rust for Vulkan drivers, part 1 https://www.collabora.com/news-and-blog/blog/2023/02/02/exploring-rust-for-vulkan-drivers-part-1/","classes":{"dataset":0.5114446878}}
{"title":"Prompt-driven vector search with LLMs","description":"https://github.com/neuml/txtai","link":"https://github.com/neuml/txtai","created":"2023-02-02","tags":["hackernews"],"meta":{"score":27},"text":"Prompt-driven vector search with LLMs https://github.com/neuml/txtai","classes":{"dataset":0.4934139252}}
{"title":"From math to machine: translating a function to machine code (2017)","description":"https://web.archive.org/web/20210420194827/https://www.briansteffens.com/2017/02/20/from-math-to-machine.html","link":"https://web.archive.org/web/20210420194827/https://www.briansteffens.com/2017/02/20/from-math-to-machine.html","created":"2023-02-02","tags":["hackernews"],"meta":{"score":44},"text":"From math to machine: translating a function to machine code (2017) https://web.archive.org/web/20210420194827/https://www.briansteffens.com/2017/02/20/from-math-to-machine.html","classes":{"dataset":0.5036002994}}
{"title":"WiFi: \u201cbeamforming\u201d only begins to describe it (2014)","description":"https://apenwarr.ca/log/20140801","link":"https://apenwarr.ca/log/20140801","created":"2023-02-02","tags":["hackernews"],"meta":{"score":189},"text":"WiFi: \u201cbeamforming\u201d only begins to describe it (2014) https://apenwarr.ca/log/20140801","classes":{"dataset":0.4989691675}}
{"title":"Fun Fact: I own porn I can't watch","description":"https://foone.tumblr.com/post/705446706461949953/fun-fact-i-own-porn-i-cant-watch","link":"https://foone.tumblr.com/post/705446706461949953/fun-fact-i-own-porn-i-cant-watch","created":"2023-02-02","tags":["hackernews"],"meta":{"score":424},"text":"Fun Fact: I own porn I can't watch https://foone.tumblr.com/post/705446706461949953/fun-fact-i-own-porn-i-cant-watch","classes":{"dataset":0.5275434256}}
{"title":"Why I Like Nox","description":"https://hynek.me/articles/why-i-like-nox/","link":"https://hynek.me/articles/why-i-like-nox/","created":"2023-02-01","tags":["hackernews"],"meta":{"score":16},"text":"Why I Like Nox https://hynek.me/articles/why-i-like-nox/","classes":{"dataset":0.6173072457}}
{"title":"ChatGPT's breakout moment and the race to put AI to work","description":"https://www.forbes.com/sites/alexkonrad/2023/02/02/inside-chatggpts-breakout-moment-and-the-race-for-the-future-of-ai/","link":"https://www.forbes.com/sites/alexkonrad/2023/02/02/inside-chatggpts-breakout-moment-and-the-race-for-the-future-of-ai/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":20},"text":"ChatGPT's breakout moment and the race to put AI to work https://www.forbes.com/sites/alexkonrad/2023/02/02/inside-chatggpts-breakout-moment-and-the-race-for-the-future-of-ai/","classes":{"dataset":0.4989758432}}
{"title":"Meta was scraping sites for years while fighting the practice","description":"https://www.bloomberg.com/news/articles/2023-02-02/meta-was-scraping-sites-for-years-while-fighting-the-practice","link":"https://www.bloomberg.com/news/articles/2023-02-02/meta-was-scraping-sites-for-years-while-fighting-the-practice","created":"2023-02-02","tags":["hackernews"],"meta":{"score":318},"text":"Meta was scraping sites for years while fighting the practice https://www.bloomberg.com/news/articles/2023-02-02/meta-was-scraping-sites-for-years-while-fighting-the-practice","classes":{"dataset":0.4811093807}}
{"title":"QOA, the Quite OK Audio Format","description":"https://phoboslab.org/log/2023/02/qoa-time-domain-audio-compression","link":"https://phoboslab.org/log/2023/02/qoa-time-domain-audio-compression","created":"2023-02-02","tags":["hackernews"],"meta":{"score":145},"text":"QOA, the Quite OK Audio Format https://phoboslab.org/log/2023/02/qoa-time-domain-audio-compression","classes":{"dataset":0.4888609648}}
{"title":"Alphabet Announces Fourth Quarter and Fiscal Year 2022 Results","description":"https://abc.xyz/investor/static/pdf/2022Q4_alphabet_earnings_release.pdf?cache=9de1a6b","link":"https://abc.xyz/investor/static/pdf/2022Q4_alphabet_earnings_release.pdf?cache=9de1a6b","created":"2023-02-02","tags":["hackernews"],"meta":{"score":120},"text":"Alphabet Announces Fourth Quarter and Fiscal Year 2022 Results https://abc.xyz/investor/static/pdf/2022Q4_alphabet_earnings_release.pdf?cache=9de1a6b","classes":{"dataset":0.4542012215}}
{"title":"Alphabet\u2019s Profit Falls 34% (fourth consecutive drop) Amid Ads Slowdown","description":"https://www.nytimes.com/2023/02/02/technology/alphabet-earnings.html","link":"https://www.nytimes.com/2023/02/02/technology/alphabet-earnings.html","created":"2023-02-03","tags":["hackernews"],"meta":{"score":114},"text":"Alphabet\u2019s Profit Falls 34% (fourth consecutive drop) Amid Ads Slowdown https://www.nytimes.com/2023/02/02/technology/alphabet-earnings.html","classes":{"dataset":0.4958817959}}
{"title":"Anki and GPT-3","description":"https://andrewjudson.com/spaced-repetition/2023/02/01/anki-chrome.html","link":"https://andrewjudson.com/spaced-repetition/2023/02/01/anki-chrome.html","created":"2023-02-02","tags":["hackernews"],"meta":{"score":199},"text":"Anki and GPT-3 https://andrewjudson.com/spaced-repetition/2023/02/01/anki-chrome.html","classes":{"dataset":0.5446102619}}
{"title":"Connecticut parents arrested for letting kids walk to Dunkin' Donuts","description":"https://reason.com/2023/01/30/dunkin-donuts-parents-arrested-kids-cops-freedom/","link":"https://reason.com/2023/01/30/dunkin-donuts-parents-arrested-kids-cops-freedom/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":788},"text":"Connecticut parents arrested for letting kids walk to Dunkin' Donuts https://reason.com/2023/01/30/dunkin-donuts-parents-arrested-kids-cops-freedom/","classes":{"dataset":0.4763113558}}
{"title":"Let the Knife Speak: On Jos\u00e9 Rizal","description":"https://lareviewofbooks.org/article/let-the-knife-speak-on-jose-rizal/","link":"https://lareviewofbooks.org/article/let-the-knife-speak-on-jose-rizal/","created":"2023-02-01","tags":["hackernews"],"meta":{"score":52},"text":"Let the Knife Speak: On Jos\u00e9 Rizal https://lareviewofbooks.org/article/let-the-knife-speak-on-jose-rizal/","classes":{"dataset":0.5150004625}}
{"title":"Chat GPT is the birth of the real Web 3.0, and it's not going to be fun","description":"https://lajili.com/posts/post-2/","link":"https://lajili.com/posts/post-2/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":364},"text":"Chat GPT is the birth of the real Web 3.0, and it's not going to be fun https://lajili.com/posts/post-2/","classes":{"dataset":0.5473576784}}
{"title":"How to find a tiny radioactive source while doing 70 kph","description":"https://www.ansto.gov.au/news/wa-outback-proves-no-match-for-aussie-nuclear-know-how","link":"https://www.ansto.gov.au/news/wa-outback-proves-no-match-for-aussie-nuclear-know-how","created":"2023-02-02","tags":["hackernews"],"meta":{"score":133},"text":"How to find a tiny radioactive source while doing 70 kph https://www.ansto.gov.au/news/wa-outback-proves-no-match-for-aussie-nuclear-know-how","classes":{"dataset":0.536329031}}
{"title":"Boeing to build braced-wing airliner, shooting for 30% efficiency gain","description":"https://newatlas.com/aircraft/boeing-nasa-truss-braced/","link":"https://newatlas.com/aircraft/boeing-nasa-truss-braced/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":32},"text":"Boeing to build braced-wing airliner, shooting for 30% efficiency gain https://newatlas.com/aircraft/boeing-nasa-truss-braced/","classes":{"dataset":0.4961928129}}
{"title":"Alexander the Great versus the Elephants","description":"https://blogs.bl.uk/digitisedmanuscripts/2023/01/alexander-the-great-versus-elephants.html","link":"https://blogs.bl.uk/digitisedmanuscripts/2023/01/alexander-the-great-versus-elephants.html","created":"2023-02-02","tags":["hackernews"],"meta":{"score":39},"text":"Alexander the Great versus the Elephants https://blogs.bl.uk/digitisedmanuscripts/2023/01/alexander-the-great-versus-elephants.html","classes":{"dataset":0.4778993726}}
{"title":"Test to work as prompt engineer","description":"Hey hi I recently send an aplication to prompt engineer and now I have to do a test, I dont know what a prompt engineer do, I thinked I will have to input prompts to an IA like chat gpt or stable diffusion thing I have done before with cool photos with stable diffusio, but they ask me things about data and differents IAs and I dont know what I have to do, So the main question, a prompt engineer has to know how to code and input data to an AI or only writing prompts to get a desired result?","link":"https://www.reddit.com/r/PromptDesign/comments/10qhqyo/test_to_work_as_prompt_engineer/","created":"2023-02-01","tags":["prompteng","reddit","promptdesign"],"meta":{"num_comments":6},"text":"Test to work as prompt engineer Hey hi I recently send an aplication to prompt engineer and now I have to do a test, I dont know what a prompt engineer do, I thinked I will have to input prompts to an IA like chat gpt or stable diffusion thing I have done before with cool photos with stable diffusio, but they ask me things about data and differents IAs and I dont know what I have to do, So the main question, a prompt engineer has to know how to code and input data to an AI or only writing prompts to get a desired result?","classes":{"dataset":0.4808544517}}
{"title":"Thursday Daily Thread: Python Careers, Courses, and Furthering Education!","description":"Discussion of using Python in a professional environment, getting jobs in Python as well as ask questions about courses to further your python education!\n\n**This thread is not for recruitment, please see** r/PythonJobs **or the thread in the sidebar for that.**","link":"https://www.reddit.com/r/Python/comments/10ral8v/thursday_daily_thread_python_careers_courses_and/","created":"2023-02-02","tags":["python","reddit"],"meta":{"num_comments":5},"text":"Thursday Daily Thread: Python Careers, Courses, and Furthering Education! Discussion of using Python in a professional environment, getting jobs in Python as well as ask questions about courses to further your python education!\n\n**This thread is not for recruitment, please see** r/PythonJobs **or the thread in the sidebar for that.**","classes":{"dataset":0.3196463287}}
{"title":"PokerPy , Python module for precise and fast Texas Hold'em Poker probability calculations.","description":"&amp;#x200B;\n\n**LINK:** [PokerPy](https://github.com/glpcc/PokerPy)\n\nHi, I made this module to learn C++ and Python integration and also to in the future maybe build a Poker AI. But I think this module can still be usefull for building automated poker scripts and apps easly form python.\n\nIn my windows machine it takes around 0.7secs for all calculations for 7 players with 2 cards each. In my Linux machine (worst CPU) it takes less (around 0.5 secs) for some reason :)\n\nAny thing more than 2 cards per player can be considered realtime.\n\nAny recommendation or comment is gladly welcomed.","link":"https://www.reddit.com/r/Python/comments/10rodh3/pokerpy_python_module_for_precise_and_fast_texas/","created":"2023-02-02","tags":["python","reddit"],"meta":{"num_comments":52},"text":"PokerPy , Python module for precise and fast Texas Hold'em Poker probability calculations. &amp;#x200B;\n\n**LINK:** [PokerPy](https://github.com/glpcc/PokerPy)\n\nHi, I made this module to learn C++ and Python integration and also to in the future maybe build a Poker AI. But I think this module can still be usefull for building automated poker scripts and apps easly form python.\n\nIn my windows machine it takes around 0.7secs for all calculations for 7 players with 2 cards each. In my Linux machine (worst CPU) it takes less (around 0.5 secs) for some reason :)\n\nAny thing more than 2 cards per player can be considered realtime.\n\nAny recommendation or comment is gladly welcomed.","classes":{"dataset":0.5624782443}}
{"title":"Making a loudness monitor for online meetings using Python","description":"I've received complaints from my wife and others in the house that I speak too loud. So I decided to write a script that measures the sound volume from my microphone and alerts me when there is too much noise in my office. \n\n[https://rolisz.ro/2023/02/02/making-a-loudness-monitor/](https://rolisz.ro/2023/02/02/making-a-loudness-monitor/)","link":"https://www.reddit.com/r/Python/comments/10rzbcv/making_a_loudness_monitor_for_online_meetings/","created":"2023-02-02","tags":["python","reddit"],"meta":{"num_comments":2},"text":"Making a loudness monitor for online meetings using Python I've received complaints from my wife and others in the house that I speak too loud. So I decided to write a script that measures the sound volume from my microphone and alerts me when there is too much noise in my office. \n\n[https://rolisz.ro/2023/02/02/making-a-loudness-monitor/](https://rolisz.ro/2023/02/02/making-a-loudness-monitor/)","classes":{"dataset":0.5366292}}
{"title":"I built cakework - open source platform to deploy computationally intensive Python functions as serverless jobs, with no timeouts","description":"Hi friends! I ran into this problem enough times at my last few jobs that I built a tool to solve it. I spent many hours building Docker containers for my Python functions, as many of the data science modules required building C libraries (since they significantly speed up compute-intensive routines, such as math calculations). Deploying the containers to AWS Lambda or Fargate (if the processes required more CPU or memory or were &gt;15 minutes) and wiring functions to talk to each other using queues, databases, and blob storage made iterating on the actual code, which wasn't even that complex most of the time, slow.\n\nI made cakework [https://github.com/usecakework/cakework](https://github.com/usecakework/cakework), a platform that lets you spin up your Python functions as serverless, production-scale backends with a single command. Using the client SDK, you submit requests, check status, and get results. You can also specify the amount of CPU (up to 16 cores) and memory (up to 128GB) for each individual request, which is helpful when your data size and complexity varies across different requests.\n\nIt's open source &lt;3. Here are some fun examples to get you started: [https://docs.cakework.com/examples](https://docs.cakework.com/examples)\n\nWould love to hear your thoughts!","link":"https://www.reddit.com/r/Python/comments/10ryiqt/i_built_cakework_open_source_platform_to_deploy/","created":"2023-02-02","tags":["python","reddit"],"meta":{"num_comments":1},"text":"I built cakework - open source platform to deploy computationally intensive Python functions as serverless jobs, with no timeouts Hi friends! I ran into this problem enough times at my last few jobs that I built a tool to solve it. I spent many hours building Docker containers for my Python functions, as many of the data science modules required building C libraries (since they significantly speed up compute-intensive routines, such as math calculations). Deploying the containers to AWS Lambda or Fargate (if the processes required more CPU or memory or were &gt;15 minutes) and wiring functions to talk to each other using queues, databases, and blob storage made iterating on the actual code, which wasn't even that complex most of the time, slow.\n\nI made cakework [https://github.com/usecakework/cakework](https://github.com/usecakework/cakework), a platform that lets you spin up your Python functions as serverless, production-scale backends with a single command. Using the client SDK, you submit requests, check status, and get results. You can also specify the amount of CPU (up to 16 cores) and memory (up to 128GB) for each individual request, which is helpful when your data size and complexity varies across different requests.\n\nIt's open source &lt;3. Here are some fun examples to get you started: [https://docs.cakework.com/examples](https://docs.cakework.com/examples)\n\nWould love to hear your thoughts!","classes":{"dataset":0.6790617108}}
{"title":"[PYGAME] THE SHIP THAT FIRES BULLETS in a version of mine.","description":"Hi everyone, it is nice to meet you all from all over the world\n\nI am a beginner of Python, this is my first project - programming a game based on the book \"Python Crash Course of Eric Matthes\". Since I find that there are a lot of readers of this book but rarely someone did this project, I want to share my code thru Git.\n\nIf you need it you can take it. I also need some STARS for motivation only. Please drop some for me. Thank you guys\n\nLink:  [MauricePham/Alien-Invasion: \\[PYGAME\\] The invasion of Aliens (github.com)](https://github.com/MauricePham/Alien-Invasion)","link":"https://www.reddit.com/r/Python/comments/10se0dt/pygame_the_ship_that_fires_bullets_in_a_version/","created":"2023-02-03","tags":["python","reddit"],"meta":{"num_comments":1},"text":"[PYGAME] THE SHIP THAT FIRES BULLETS in a version of mine. Hi everyone, it is nice to meet you all from all over the world\n\nI am a beginner of Python, this is my first project - programming a game based on the book \"Python Crash Course of Eric Matthes\". Since I find that there are a lot of readers of this book but rarely someone did this project, I want to share my code thru Git.\n\nIf you need it you can take it. I also need some STARS for motivation only. Please drop some for me. Thank you guys\n\nLink:  [MauricePham/Alien-Invasion: \\[PYGAME\\] The invasion of Aliens (github.com)](https://github.com/MauricePham/Alien-Invasion)","classes":{"dataset":0.5834368467}}
{"title":"Ariadne Codegen: code generator for Python GraphQL clients","description":"Hey everyone!\n\nRecently we've released [Ariadne Codegen](https://github.com/mirumee/ariadne-codegen), a new tool for Python which generates GraphQL clients from `*.graphql` files with schema and queries. This project evolved from the utility tool that was created at work to speed up the process of writing services integrating with and extending the GraphQL API of [Saleor](https://graphql.com/saleor/saleor), our company's open source e-commerce package.\n\nTL;DR for the problem solved is that writing GraphQL client by hand is mostly writing a lot of boilerplate code and translating the GraphQL types to Python dataclasses or Pydantic's models. And every new query is basically previous query copied over with some bits changed. This process is great for automation.\n\nOur Codegen is fast to get started with. You configure it by adding dedicated `[ariadne-codegen]` section to your `pyproject.toml` file, which contains settings for codegen telling it where to find the GraphQL schema and operations. You then run the ariadne-codegen command which makes the Codegen parse those files and generate a Python package implementing the GraphQL client providing those operations as fully typed methods. GraphQL types are represented as Pydantic models and Enums are represented as Python enums.\n\nFor example, this GraphQL query:\n\n    mutation UserCreate($name: String!, $email: String!, $password: String!) {\n      userCreate(input: { name: $name, email: $email, password: $password }) {\n        token\n        user {\n          id\n        }\n        errors {\n          location\n          type\n          message\n        }\n      }\n    }\n\nBecomes this method on generated client:\n\n    class Client(BaseClient):\n        def user_create(self, name: str, email: str, password: str) -&gt; UserCreate:\n            # Bunch of boilerplate code building query and variables dict,\n            # then sending it to the GraphQL client and handling the response\n            return UserCreate.parse_obj(data)\n\nYou can then either release generated package as a library for others to use, or keep it as a part of the project you are working at\n\nMultiple customization options are also provided, including option switch between async and sync client, inject custom Python code into generated classes or swap default HTTP client with custom one.\n\n**GitHub repository:** [mirumee/ariadne-codegen](https://github.com/mirumee/ariadne-codegen)\n\nThere's also full [release announcement on Ariadne blog](https://ariadnegraphql.org/blog/2023/02/02/ariadne-codegen) that tells the whole story\n\nThank you for reading all of this. We hope this tool will be helpful for you, and if not, then that the read above was at least interesting :)","link":"https://www.reddit.com/r/Python/comments/10rqo82/ariadne_codegen_code_generator_for_python_graphql/","created":"2023-02-02","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Ariadne Codegen: code generator for Python GraphQL clients Hey everyone!\n\nRecently we've released [Ariadne Codegen](https://github.com/mirumee/ariadne-codegen), a new tool for Python which generates GraphQL clients from `*.graphql` files with schema and queries. This project evolved from the utility tool that was created at work to speed up the process of writing services integrating with and extending the GraphQL API of [Saleor](https://graphql.com/saleor/saleor), our company's open source e-commerce package.\n\nTL;DR for the problem solved is that writing GraphQL client by hand is mostly writing a lot of boilerplate code and translating the GraphQL types to Python dataclasses or Pydantic's models. And every new query is basically previous query copied over with some bits changed. This process is great for automation.\n\nOur Codegen is fast to get started with. You configure it by adding dedicated `[ariadne-codegen]` section to your `pyproject.toml` file, which contains settings for codegen telling it where to find the GraphQL schema and operations. You then run the ariadne-codegen command which makes the Codegen parse those files and generate a Python package implementing the GraphQL client providing those operations as fully typed methods. GraphQL types are represented as Pydantic models and Enums are represented as Python enums.\n\nFor example, this GraphQL query:\n\n    mutation UserCreate($name: String!, $email: String!, $password: String!) {\n      userCreate(input: { name: $name, email: $email, password: $password }) {\n        token\n        user {\n          id\n        }\n        errors {\n          location\n          type\n          message\n        }\n      }\n    }\n\nBecomes this method on generated client:\n\n    class Client(BaseClient):\n        def user_create(self, name: str, email: str, password: str) -&gt; UserCreate:\n            # Bunch of boilerplate code building query and variables dict,\n            # then sending it to the GraphQL client and handling the response\n            return UserCreate.parse_obj(data)\n\nYou can then either release generated package as a library for others to use, or keep it as a part of the project you are working at\n\nMultiple customization options are also provided, including option switch between async and sync client, inject custom Python code into generated classes or swap default HTTP client with custom one.\n\n**GitHub repository:** [mirumee/ariadne-codegen](https://github.com/mirumee/ariadne-codegen)\n\nThere's also full [release announcement on Ariadne blog](https://ariadnegraphql.org/blog/2023/02/02/ariadne-codegen) that tells the whole story\n\nThank you for reading all of this. We hope this tool will be helpful for you, and if not, then that the read above was at least interesting :)","classes":{"dataset":0.0323142298}}
{"title":"I\u2019m developing a programming game where you use Python to automate all kinds of machines, robots, drones and more and solve exciting bite-sized coding challenges.","description":"Six weeks ago, I announced JOY OF PROGRAMMING here on r/python and it was met with an overwhelmingly positive reception and a lot of valuable feedback. In case you missed it, the game is all about practicing and applying your Python skills to challenging tasks in realistic, physically simulated 3D environments. It will cover a wide variety of topics, from basic algo / ds, oop, GUI programming to control theory, robotics, image processing, machine learning, genetic algorithms, and more. Of course it will also include a basic tutorial for beginners, but I plan to include interesting challenges for all skill levels. In my day job I\u2019m a CS professor, and this game actually started out as a tool I used in-class for my students. For the last 19 months I\u2019ve been developing this prototype into a proper game.\n\nSpeaking of development, in these last 6 weeks I added a lot of new features, polished and cleaned up many things, and improved the API documentation and made everything fully pep8 compliant. Also I finally got around to recording a longer gameplay trailer, which is hot off the press and I\u2019d like to share it with you. Please head over to the game\u2019s Steam page where you can check it out (it\u2019s the second video there, though I recommend watching the first teaser if you haven\u2019t already).\n\n[https://store.steampowered.com/app/2216770/JOY\\_OF\\_PROGRAMMING\\_\\_Software\\_Engineering\\_Simulator](https://store.steampowered.com/app/2216770/JOY_OF_PROGRAMMING__Software_Engineering_Simulator) \n\nI\u2019m very much looking forward to your feedback or your questions, and of course if you have a Steam account and you like what you see, consider a wishlist. This really helps to \u201cfeed\u201d Steam\u2019s recommender algorithm to spread the word about JOY OF PROGRAMMING and hopefully getting more people into Python programming that way!","link":"https://www.reddit.com/r/Python/comments/10qv40g/im_developing_a_programming_game_where_you_use/","created":"2023-02-01","tags":["python","reddit"],"meta":{"num_comments":91},"text":"I\u2019m developing a programming game where you use Python to automate all kinds of machines, robots, drones and more and solve exciting bite-sized coding challenges. Six weeks ago, I announced JOY OF PROGRAMMING here on r/python and it was met with an overwhelmingly positive reception and a lot of valuable feedback. In case you missed it, the game is all about practicing and applying your Python skills to challenging tasks in realistic, physically simulated 3D environments. It will cover a wide variety of topics, from basic algo / ds, oop, GUI programming to control theory, robotics, image processing, machine learning, genetic algorithms, and more. Of course it will also include a basic tutorial for beginners, but I plan to include interesting challenges for all skill levels. In my day job I\u2019m a CS professor, and this game actually started out as a tool I used in-class for my students. For the last 19 months I\u2019ve been developing this prototype into a proper game.\n\nSpeaking of development, in these last 6 weeks I added a lot of new features, polished and cleaned up many things, and improved the API documentation and made everything fully pep8 compliant. Also I finally got around to recording a longer gameplay trailer, which is hot off the press and I\u2019d like to share it with you. Please head over to the game\u2019s Steam page where you can check it out (it\u2019s the second video there, though I recommend watching the first teaser if you haven\u2019t already).\n\n[https://store.steampowered.com/app/2216770/JOY\\_OF\\_PROGRAMMING\\_\\_Software\\_Engineering\\_Simulator](https://store.steampowered.com/app/2216770/JOY_OF_PROGRAMMING__Software_Engineering_Simulator) \n\nI\u2019m very much looking forward to your feedback or your questions, and of course if you have a Steam account and you like what you see, consider a wishlist. This really helps to \u201cfeed\u201d Steam\u2019s recommender algorithm to spread the word about JOY OF PROGRAMMING and hopefully getting more people into Python programming that way!","classes":{"dataset":0.4978356361}}
{"title":"PocketPy: A Lightweight(~5000 LOC) Python Implementation","description":"[PocketPy](https://github.com/blueloveth/pocketpy) is a lightweight(\\~5000 LOC) Python interpreter for game engines.\n\nIt is easy to embed. All of the functionalities are available in a single header file pocketpy.h, without external dependencies. You can [try it on your browser](https://blueloveth.github.io/pocketpy/) to see what it looks like.\n\n## Current Available Features\n| Name            | Example                    | Supported |\n| --------------- | -------------------------- | --------- |\n| If Else         | `if..else..elif`           | YES       |\n| Loop            | `for/while/break/continue` | YES       |\n| Function        | `def f(x,*args,y=1):`      | YES       |\n| Function `**`   | `def f(**kwargs):`         | NO        |\n| Subclass        | `class A(B):`              | YES       |\n| List            | `[1, 2, 'a']`              | YES       |\n| ListComp        | `[i for i in range(5)]`    | YES       |\n| Slice           | `a[1:2], a[:2], a[1:]`     | YES       |\n| Tuple           | `(1, 2, 'a')`              | YES       |\n| Dict            | `{'a': 1, 'b': 2}`         | YES       |\n| F-String        | `f'value is {x}'`          | YES       |\n| Unpacking       | `a, b = 1, 2`              | YES       |\n| Star Unpacking  | `a, *b = [1, 2, 3]`        | NO        |\n| Throw Exception | `assert/raise`             | YES       |\n| Catch Exception | `try..catch`               | NO        |\n| Eval/Exec       | `eval()/exec()`            | YES       |\n| Import          | `import/from..import`      | YES       |\n\nI am working on it for a few months. I hope PocketPy can be used in game dev.\nIf u are making a custom game engine and searching for a script impl, please contact me. I want to explore the possibility of PocketPy as a game script.\n\nIf u are making your own script language, you may find some inspirations in PocketPy.\n\nIf u likes it, please give me a star\\~ I need your star!!","link":"https://www.reddit.com/r/Python/comments/10rq7gd/pocketpy_a_lightweight5000_loc_python/","created":"2023-02-02","tags":["python","reddit"],"meta":{"num_comments":7},"text":"PocketPy: A Lightweight(~5000 LOC) Python Implementation [PocketPy](https://github.com/blueloveth/pocketpy) is a lightweight(\\~5000 LOC) Python interpreter for game engines.\n\nIt is easy to embed. All of the functionalities are available in a single header file pocketpy.h, without external dependencies. You can [try it on your browser](https://blueloveth.github.io/pocketpy/) to see what it looks like.\n\n## Current Available Features\n| Name            | Example                    | Supported |\n| --------------- | -------------------------- | --------- |\n| If Else         | `if..else..elif`           | YES       |\n| Loop            | `for/while/break/continue` | YES       |\n| Function        | `def f(x,*args,y=1):`      | YES       |\n| Function `**`   | `def f(**kwargs):`         | NO        |\n| Subclass        | `class A(B):`              | YES       |\n| List            | `[1, 2, 'a']`              | YES       |\n| ListComp        | `[i for i in range(5)]`    | YES       |\n| Slice           | `a[1:2], a[:2], a[1:]`     | YES       |\n| Tuple           | `(1, 2, 'a')`              | YES       |\n| Dict            | `{'a': 1, 'b': 2}`         | YES       |\n| F-String        | `f'value is {x}'`          | YES       |\n| Unpacking       | `a, b = 1, 2`              | YES       |\n| Star Unpacking  | `a, *b = [1, 2, 3]`        | NO        |\n| Throw Exception | `assert/raise`             | YES       |\n| Catch Exception | `try..catch`               | NO        |\n| Eval/Exec       | `eval()/exec()`            | YES       |\n| Import          | `import/from..import`      | YES       |\n\nI am working on it for a few months. I hope PocketPy can be used in game dev.\nIf u are making a custom game engine and searching for a script impl, please contact me. I want to explore the possibility of PocketPy as a game script.\n\nIf u are making your own script language, you may find some inspirations in PocketPy.\n\nIf u likes it, please give me a star\\~ I need your star!!","classes":{"dataset":0.4579329491}}
{"title":"[WIP] A Python web framework as powerful as NextJS + Webflow","description":"Hello Pythonistas, I have been developing an open-source python web framework for the past few months. I have felt the pain that Python developers have to switch to NextJS whenever they want to build a good-looking website/web app.\n\nI would like to share the teaser of our framework and get feedback (both pros &amp; cons are welcome).\n\nGitHub - [https://github.com/Atri-Labs/atrilabs-engine](https://github.com/Atri-Labs/atrilabs-engine)\n\nThe front end can be built using our powerful visual builder or by writing React code. You can write the backend using our Python API which feels a lot like the Unity game engine's script.\n\n[1 min Atri teaser video](https://reddit.com/link/10rwwf4/video/xlixqrzejtfa1/player)","link":"https://www.reddit.com/r/Python/comments/10rwwf4/wip_a_python_web_framework_as_powerful_as_nextjs/","created":"2023-02-02","tags":["python","reddit"],"meta":{"num_comments":3},"text":"[WIP] A Python web framework as powerful as NextJS + Webflow Hello Pythonistas, I have been developing an open-source python web framework for the past few months. I have felt the pain that Python developers have to switch to NextJS whenever they want to build a good-looking website/web app.\n\nI would like to share the teaser of our framework and get feedback (both pros &amp; cons are welcome).\n\nGitHub - [https://github.com/Atri-Labs/atrilabs-engine](https://github.com/Atri-Labs/atrilabs-engine)\n\nThe front end can be built using our powerful visual builder or by writing React code. You can write the backend using our Python API which feels a lot like the Unity game engine's script.\n\n[1 min Atri teaser video](https://reddit.com/link/10rwwf4/video/xlixqrzejtfa1/player)","classes":{"dataset":0.2741599381}}
{"title":"Should I be improving resume projects?","description":"I have a year of experience as a software developer (not python). I'm currently searching for a python job, so I included some personal projects made with python to account for the lack of real experience. Here's what I've included:\n\n1. Password manager: Command line interface python password encryptor, generator and manager.\n2. Spotify and Genius APIs Project: Displays the lyrics of any song currently playing on Spotify on command line in real time.\n3. Camera movement detector: Detects objects moving in camera and sends an email notification with attached picture.\n4. Weather API: Created my own API that fetches data from database and sends it to different endpoints.\n5. Weather Forecast App: Web app that lets the user know the weather forecast for any city in the world through API calls.\n\nThese are simple projects. Do you think I need to have something more complex? Should I ditch some project or replace it with another one? Any opinion on this would be really helpful. Thank you!","link":"https://www.reddit.com/r/Python/comments/10rpohz/should_i_be_improving_resume_projects/","created":"2023-02-02","tags":["python","reddit"],"meta":{"num_comments":5},"text":"Should I be improving resume projects? I have a year of experience as a software developer (not python). I'm currently searching for a python job, so I included some personal projects made with python to account for the lack of real experience. Here's what I've included:\n\n1. Password manager: Command line interface python password encryptor, generator and manager.\n2. Spotify and Genius APIs Project: Displays the lyrics of any song currently playing on Spotify on command line in real time.\n3. Camera movement detector: Detects objects moving in camera and sends an email notification with attached picture.\n4. Weather API: Created my own API that fetches data from database and sends it to different endpoints.\n5. Weather Forecast App: Web app that lets the user know the weather forecast for any city in the world through API calls.\n\nThese are simple projects. Do you think I need to have something more complex? Should I ditch some project or replace it with another one? Any opinion on this would be really helpful. Thank you!","classes":{"dataset":0.4730187356}}
{"title":"We made AI Generator for Coloring pages","description":"The diffusion model we use is Stable Diffusion. It has been finetuned on a substantial coloring drawing datasets. When a Color Pop (the main app) user sends a request to the service, 4 creation propositions are generated by the AI on our servers. A final post-processing step is applied to do some cleaning, resolution upscaling and finally the image is converted for our custom drawing kit that we developed for the mobile application.  \n   \nIf you guys want to check it out, Color Pop is live on the App store and Google Play.\n\n[\\\\\"cat on a motorbike\\\\\"](https://preview.redd.it/7m587hdmcyfa1.png?width=1086&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2cf8357216df9ddc62ecc19a9fa1476bb87334c1)","link":"https://www.reddit.com/r/deeplearning/comments/10shdu5/we_made_ai_generator_for_coloring_pages/","created":"2023-02-03","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":1},"text":"We made AI Generator for Coloring pages The diffusion model we use is Stable Diffusion. It has been finetuned on a substantial coloring drawing datasets. When a Color Pop (the main app) user sends a request to the service, 4 creation propositions are generated by the AI on our servers. A final post-processing step is applied to do some cleaning, resolution upscaling and finally the image is converted for our custom drawing kit that we developed for the mobile application.  \n   \nIf you guys want to check it out, Color Pop is live on the App store and Google Play.\n\n[\\\\\"cat on a motorbike\\\\\"](https://preview.redd.it/7m587hdmcyfa1.png?width=1086&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=2cf8357216df9ddc62ecc19a9fa1476bb87334c1)","classes":{"dataset":0.3942580819}}
{"title":"Why are FPGAs better than GPUs for deep learning?","description":"I've worked for some years developing scientific applications for GPUs. Recently we've been trying to integrate FPGAs into our technologies; and consequently I've been trying to understand what they are useful for.\n\nI've found many posts here and there that claim that FPGAs are better suited than GPUs to accelerate Deep Learning/AI workloads (for example, [this one by Intel](https://www.intel.com/content/www/us/en/artificial-intelligence/programmable/fpga-gpu.html)). However, I don't understand why that would be the case. I think the problem is that all those posts try to explain what an FPGA is and what its differences are to a GPU, so that people that work on Deep Learning understand why they are better suited. Nevertheless, my position is exactly the opposite: I know quite well how a GPU works and what it is good for, I know well enough how an FPGA works and how it differs from a GPU, **but I do not know enough about Deep Learning** to understand why Deep Learning applicatios would benefit more from the special features of FPGAs rather than from the immense parallelism GPUs offers.\n\nAs far as I know, an FPGA will never beat a traditional GPU in terms of raw parallelism (or, if it does, it would be much less cost efficient). Thus, when it comes to matrix multiplications, i.e. the main operation in Deep Learning models, or convolutions, GPUs can parallelly work with much bigger matrices. The only explanation I can think of is that traditional Deep Learning applications don't necessarily use such big matrices, but rather smaller ones that can also be fully parallelized in FPGAs and benefit highly from custom-hardware optimizations (optimized matrix multiplications/tensor operations, working with reduced-bit values such as FP16, deep-pipeline parallelism, ...). However, given the recent increase in popularity of very complex models (GPT-3, dall-e, and the like) which boast using millions or even billions of parameters, it is hard to imagine that popular deep learning models work with small matrices of which fully parallel architectures can be synthesized in FPGAs.\n\nWhat am I missing? Any insight will be greatly appreciated.","link":"https://www.reddit.com/r/deeplearning/comments/10s3u1s/why_are_fpgas_better_than_gpus_for_deep_learning/","created":"2023-02-03","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":6},"text":"Why are FPGAs better than GPUs for deep learning? I've worked for some years developing scientific applications for GPUs. Recently we've been trying to integrate FPGAs into our technologies; and consequently I've been trying to understand what they are useful for.\n\nI've found many posts here and there that claim that FPGAs are better suited than GPUs to accelerate Deep Learning/AI workloads (for example, [this one by Intel](https://www.intel.com/content/www/us/en/artificial-intelligence/programmable/fpga-gpu.html)). However, I don't understand why that would be the case. I think the problem is that all those posts try to explain what an FPGA is and what its differences are to a GPU, so that people that work on Deep Learning understand why they are better suited. Nevertheless, my position is exactly the opposite: I know quite well how a GPU works and what it is good for, I know well enough how an FPGA works and how it differs from a GPU, **but I do not know enough about Deep Learning** to understand why Deep Learning applicatios would benefit more from the special features of FPGAs rather than from the immense parallelism GPUs offers.\n\nAs far as I know, an FPGA will never beat a traditional GPU in terms of raw parallelism (or, if it does, it would be much less cost efficient). Thus, when it comes to matrix multiplications, i.e. the main operation in Deep Learning models, or convolutions, GPUs can parallelly work with much bigger matrices. The only explanation I can think of is that traditional Deep Learning applications don't necessarily use such big matrices, but rather smaller ones that can also be fully parallelized in FPGAs and benefit highly from custom-hardware optimizations (optimized matrix multiplications/tensor operations, working with reduced-bit values such as FP16, deep-pipeline parallelism, ...). However, given the recent increase in popularity of very complex models (GPT-3, dall-e, and the like) which boast using millions or even billions of parameters, it is hard to imagine that popular deep learning models work with small matrices of which fully parallel architectures can be synthesized in FPGAs.\n\nWhat am I missing? Any insight will be greatly appreciated.","classes":{"dataset":0.3475192785}}
{"title":"VAE with bernoulli prior, HELP!!!","description":"I am trying to train a VAE whose prior is a Bernoulli (p=0.5). It is basically from the papers on categorical VAE and Gumbel-softmax:\n\n1. [https://arxiv.org/abs/1611.01144](https://arxiv.org/abs/1611.01144)\n2. [https://arxiv.org/abs/1611.00712](https://arxiv.org/abs/1611.00712)\n3. [https://www.researchgate.net/publication/336823794\\_A\\_Binary\\_Variational\\_Autoencoder\\_for\\_Hashing](https://www.researchgate.net/publication/336823794_A_Binary_Variational_Autoencoder_for_Hashing)\n\nI am training it using the MNIST dataset, with fully connected layers. The encoder part is with an input size of 728 followed by 2 hidden layers with 521 and 256 neurons respectively. The latent layer has 500 neurons. The reason for Bernoulli prior is so that I get a binary latent representation of the input data. The reconstructions are pretty good, however, when I am doing a random sampling of Bernoulli(p=0.5) for the decoder, the generated data is garbage. \n\nThe objective function is theMSE of the reconstruction + the KL divergence of the latent distribution..\n\n&amp;#x200B;\n\nAny suggestions???","link":"https://www.reddit.com/r/deeplearning/comments/10s0zi6/vae_with_bernoulli_prior_help/","created":"2023-02-02","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":1},"text":"VAE with bernoulli prior, HELP!!! I am trying to train a VAE whose prior is a Bernoulli (p=0.5). It is basically from the papers on categorical VAE and Gumbel-softmax:\n\n1. [https://arxiv.org/abs/1611.01144](https://arxiv.org/abs/1611.01144)\n2. [https://arxiv.org/abs/1611.00712](https://arxiv.org/abs/1611.00712)\n3. [https://www.researchgate.net/publication/336823794\\_A\\_Binary\\_Variational\\_Autoencoder\\_for\\_Hashing](https://www.researchgate.net/publication/336823794_A_Binary_Variational_Autoencoder_for_Hashing)\n\nI am training it using the MNIST dataset, with fully connected layers. The encoder part is with an input size of 728 followed by 2 hidden layers with 521 and 256 neurons respectively. The latent layer has 500 neurons. The reason for Bernoulli prior is so that I get a binary latent representation of the input data. The reconstructions are pretty good, however, when I am doing a random sampling of Bernoulli(p=0.5) for the decoder, the generated data is garbage. \n\nThe objective function is theMSE of the reconstruction + the KL divergence of the latent distribution..\n\n&amp;#x200B;\n\nAny suggestions???","classes":{"dataset":0.3927370906}}
{"title":"1-click deploy for your GPT-3 App","description":"Link - [https://github.com/ClerkieAI/berri\\_ai](https://github.com/ClerkieAI/berri_ai)\n\nWe  made a package that makes it easy for developers to quickly deploy  their LLM Agent from Google Colab to production (Web App and API  Endpoint).\n\n**How it works?**\n\nJust install the package, import the function, and run deploy.\n\nAt the end of the deploy (\\~10-15mins), you will get:\n\n1. A web app to interact with your agent \ud83d\udc49  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/)\n2. An endpoint you can query \ud83d\udc49  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/langchain_agent?query=%22who) is obama?\"\n\nWant a more detailed walkthrough? Check out our loom - [https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43](https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43)\n\nWe\u2019re still early so would love your feedback and opinions. Feel free to try   us out for free \u2013 and if you need help building an agent / want a   specific integration, just let us know!\n\nhttps://i.redd.it/s53l400o2ufa1.gif","link":"https://www.reddit.com/r/deeplearning/comments/10rzn7z/1click_deploy_for_your_gpt3_app/","created":"2023-02-02","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"1-click deploy for your GPT-3 App Link - [https://github.com/ClerkieAI/berri\\_ai](https://github.com/ClerkieAI/berri_ai)\n\nWe  made a package that makes it easy for developers to quickly deploy  their LLM Agent from Google Colab to production (Web App and API  Endpoint).\n\n**How it works?**\n\nJust install the package, import the function, and run deploy.\n\nAt the end of the deploy (\\~10-15mins), you will get:\n\n1. A web app to interact with your agent \ud83d\udc49  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/)\n2. An endpoint you can query \ud83d\udc49  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/langchain_agent?query=%22who) is obama?\"\n\nWant a more detailed walkthrough? Check out our loom - [https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43](https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43)\n\nWe\u2019re still early so would love your feedback and opinions. Feel free to try   us out for free \u2013 and if you need help building an agent / want a   specific integration, just let us know!\n\nhttps://i.redd.it/s53l400o2ufa1.gif","classes":{"dataset":0.5357834101}}
{"title":"Is there a thread/community/sub for people interested in building their own Deep Learning servers?","description":"","link":"https://www.reddit.com/r/deeplearning/comments/10r4gzc/is_there_a_threadcommunitysub_for_people/","created":"2023-02-01","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"Is there a thread/community/sub for people interested in building their own Deep Learning servers? ","classes":{"dataset":0.4412237704}}
{"title":"Using Jupyter via GPU","description":"I am new to deep learning. Till now I was mostly doing stuff on Kaggle. But now I am planning to to do stuff on Jupyter via GPU. But I have no idea how to do it. I read somewhere that I need Docker to do it. But I have never used Docker before. Should I install Docker Desktop or is their any other way to set it up?","link":"https://www.reddit.com/r/deeplearning/comments/10rcty9/using_jupyter_via_gpu/","created":"2023-02-02","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":17},"text":"Using Jupyter via GPU I am new to deep learning. Till now I was mostly doing stuff on Kaggle. But now I am planning to to do stuff on Jupyter via GPU. But I have no idea how to do it. I read somewhere that I need Docker to do it. But I have never used Docker before. Should I install Docker Desktop or is their any other way to set it up?","classes":{"dataset":0.3245063424}}
{"title":"\"machine learning is basically many months of things not working, and then suddenly it works, and then it works scarily well\" \u2013 if this resonates for you, share stories of your experience with this!","description":"","link":"https://www.reddit.com/r/deeplearning/comments/10qxkfv/machine_learning_is_basically_many_months_of/","created":"2023-02-01","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":1},"text":"\"machine learning is basically many months of things not working, and then suddenly it works, and then it works scarily well\" \u2013 if this resonates for you, share stories of your experience with this! ","classes":{"dataset":0.2734290361}}
{"title":"Launching my first-ever open-source project and it might make your ChatGPT answers better","description":"I am building UpTrain - an open-source ML diagnostic toolkit that recently got investment from YCombinator.\n\nAs you know no ML model is 100% accurate, and, further, their accuracy deteriorates over time \ud83d\ude23. Additionally, due to the black boxiness \u2b1b nature of Large Language models, it's challenging to identify and fix their problems.\n\nThe tool helps ML practitioners to:\n1. Understand how their models are performing in production\n2. Catch edge cases and outliers to help them refine their models\n3. Allow them to define custom monitors to catch under-performing data-points\n4. Retrain the model on them to improve its accuracy\n\nYou can check out the project here: https://github.com/uptrain-ai/uptrain. Would love to hear feedback from the community!","link":"https://www.reddit.com/r/deeplearning/comments/10qx9po/launching_my_firstever_opensource_project_and_it/","created":"2023-02-01","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":4},"text":"Launching my first-ever open-source project and it might make your ChatGPT answers better I am building UpTrain - an open-source ML diagnostic toolkit that recently got investment from YCombinator.\n\nAs you know no ML model is 100% accurate, and, further, their accuracy deteriorates over time \ud83d\ude23. Additionally, due to the black boxiness \u2b1b nature of Large Language models, it's challenging to identify and fix their problems.\n\nThe tool helps ML practitioners to:\n1. Understand how their models are performing in production\n2. Catch edge cases and outliers to help them refine their models\n3. Allow them to define custom monitors to catch under-performing data-points\n4. Retrain the model on them to improve its accuracy\n\nYou can check out the project here: https://github.com/uptrain-ai/uptrain. Would love to hear feedback from the community!","classes":{"dataset":0.4855993986}}
{"title":"What are some innovative ideas / engineering solutions to problems in the world that have never been created which will make a change?","description":"","link":"https://www.reddit.com/r/deeplearning/comments/10qw4bs/what_are_some_innovative_ideas_engineering/","created":"2023-02-01","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":5},"text":"What are some innovative ideas / engineering solutions to problems in the world that have never been created which will make a change? ","classes":{"dataset":0.4594475329}}
{"title":"Loss function fluctuating","description":"Hi all! I'm currently implementing a CNN in PyTorch and having a hard time with it. It's for a binary classification problem and my loss function keeps fluctuating without a pattern. I've tried many things that I saw online:\nCrossEntropyLoss function, BCELoss with Sigmoid, BCEWithLogitsLoss, reducing network layers to only a couple, gradient accumulation instead of normal optimization\u2026. My dataset is about 5500 samples with X input of matrix form size 2000x5 and Y 0 or 1. How should I proceed?","link":"https://www.reddit.com/r/deeplearning/comments/10qhscf/loss_function_fluctuating/","created":"2023-02-01","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":15},"text":"Loss function fluctuating Hi all! I'm currently implementing a CNN in PyTorch and having a hard time with it. It's for a binary classification problem and my loss function keeps fluctuating without a pattern. I've tried many things that I saw online:\nCrossEntropyLoss function, BCELoss with Sigmoid, BCEWithLogitsLoss, reducing network layers to only a couple, gradient accumulation instead of normal optimization\u2026. My dataset is about 5500 samples with X input of matrix form size 2000x5 and Y 0 or 1. How should I proceed?","classes":{"dataset":0.4192120433}}
{"title":"Question: How to Best Organize/Label my Data","description":"This is a very basic question but I am having difficulty understanding the concept. My background is mostly with labeled data in a csv format. The question is essentially: How do I organize/prepare my data for Deep Learning when the data is not easily represented in a csv.\n\nThe example is I have network records of our users. Additionally I have information about their role, title, business unit etc... so my data looks something like\n\n    User Data:\n    Section 1: User information: \n    [name, title, business unit] \n    \n    Section 2: Network information specific to this user  \n    [network activity as a time series, ex: \"2021-01-12 13:12:005 &lt;src IP&gt; &lt;dest IP&gt; &lt;user agent&gt; &lt;src port&gt;&lt;dest port&gt;\"] \n\nI thought about creating a folder structure with each folder having the individual's name, and the folder containing their network data, but it seems I would lose the additional user information. Something like the structure below and an attending sheet creating an index of the data.\n\n    [joe_anon]     \n        |______[day 1 network data for joe]     \n        |______[day 2 network data for joe] \n    \n    [sally_anon]     \n        |_______[day 1 network data for sally]     \n        |_______[day 2 network data for sally]  \n\nI think this is something possibly already solved with bioinformatics data in that there are individual biographical information including medical history and also their genetic data. Unfortunately I am not finding good examples and not quite conceptualizing how to structure my data for deep learning here.\n\nAny thoughts/ideas or examples are very much appreciated (and thank you in advance)  \n\n\n\\*\\*edit for clarity.","link":"https://www.reddit.com/r/deeplearning/comments/10q737n/question_how_to_best_organizelabel_my_data/","created":"2023-01-31","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"Question: How to Best Organize/Label my Data This is a very basic question but I am having difficulty understanding the concept. My background is mostly with labeled data in a csv format. The question is essentially: How do I organize/prepare my data for Deep Learning when the data is not easily represented in a csv.\n\nThe example is I have network records of our users. Additionally I have information about their role, title, business unit etc... so my data looks something like\n\n    User Data:\n    Section 1: User information: \n    [name, title, business unit] \n    \n    Section 2: Network information specific to this user  \n    [network activity as a time series, ex: \"2021-01-12 13:12:005 &lt;src IP&gt; &lt;dest IP&gt; &lt;user agent&gt; &lt;src port&gt;&lt;dest port&gt;\"] \n\nI thought about creating a folder structure with each folder having the individual's name, and the folder containing their network data, but it seems I would lose the additional user information. Something like the structure below and an attending sheet creating an index of the data.\n\n    [joe_anon]     \n        |______[day 1 network data for joe]     \n        |______[day 2 network data for joe] \n    \n    [sally_anon]     \n        |_______[day 1 network data for sally]     \n        |_______[day 2 network data for sally]  \n\nI think this is something possibly already solved with bioinformatics data in that there are individual biographical information including medical history and also their genetic data. Unfortunately I am not finding good examples and not quite conceptualizing how to structure my data for deep learning here.\n\nAny thoughts/ideas or examples are very much appreciated (and thank you in advance)  \n\n\n\\*\\*edit for clarity.","classes":{"dataset":0.3877248168}}
{"title":"[N] Microsoft integrates GPT 3.5 into Teams","description":"Official blog post: https://www.microsoft.com/en-us/microsoft-365/blog/2023/02/01/microsoft-teams-premium-cut-costs-and-add-ai-powered-productivity/\n\nGiven the amount of money they pumped into OpenAI, it's not surprising that you'd see it integrated into their products. I do wonder how this will work in highly regulated fields (finance, law, medicine, education).","link":"https://www.reddit.com/r/MachineLearning/comments/10rqe34/n_microsoft_integrates_gpt_35_into_teams/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":108},"text":"[N] Microsoft integrates GPT 3.5 into Teams Official blog post: https://www.microsoft.com/en-us/microsoft-365/blog/2023/02/01/microsoft-teams-premium-cut-costs-and-add-ai-powered-productivity/\n\nGiven the amount of money they pumped into OpenAI, it's not surprising that you'd see it integrated into their products. I do wonder how this will work in highly regulated fields (finance, law, medicine, education).","classes":{"dataset":0.1945260316}}
{"title":"[D] Understanding Vision Transformer (ViT) - What are the prerequisites?","description":"Hello everyone,\n\nI'm interested in diving into the field of computer vision and I recently came across the concept of Vision Transformer (ViT). I want to understand this concept in depth but I'm not sure what prerequisites I need to have in order to grasp the concept fully.\n\nDo I need to have a strong background in Recurrent Neural Networks (RNNs) and Transformer (Attention Is All You Need) to understand ViT, or can I get by just knowing the basics of deep learning and Convolutional Neural Networks (CNNs)?\n\nI would really appreciate if someone could shed some light on this and provide some guidance.\n\nThank you in advance!","link":"https://www.reddit.com/r/MachineLearning/comments/10siibd/d_understanding_vision_transformer_vit_what_are/","created":"2023-02-03","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":0},"text":"[D] Understanding Vision Transformer (ViT) - What are the prerequisites? Hello everyone,\n\nI'm interested in diving into the field of computer vision and I recently came across the concept of Vision Transformer (ViT). I want to understand this concept in depth but I'm not sure what prerequisites I need to have in order to grasp the concept fully.\n\nDo I need to have a strong background in Recurrent Neural Networks (RNNs) and Transformer (Attention Is All You Need) to understand ViT, or can I get by just knowing the basics of deep learning and Convolutional Neural Networks (CNNs)?\n\nI would really appreciate if someone could shed some light on this and provide some guidance.\n\nThank you in advance!","classes":{"dataset":0.2161788195}}
{"title":"[R] [P] Noisy Sentences Dataset","description":"550K sentences in 5 European languages augmented with noise for training and evaluating spell correction tools or machine learning models. We have constructed our dataset to cover representatives from the language families used across Europe.\n\n* Germanic - English, German;\n* Romance - French;\n* Slavic - Bulgarian;\n* Turkic - Turkish;\n\n**Use case example:** Apply language models or other techniques to compare the sentence pairs and reconstruct the original sentences from the augmented ones. You can use a single multilingual solution to solve the challenge or employ multiple models/techniques for the separate languages. Per-word dictionary lookup is also an option.\n\n**Link:** [https://github.com/radi-cho/noisy-sentences-dataset](https://github.com/radi-cho/noisy-sentences-dataset)","link":"https://www.reddit.com/r/MachineLearning/comments/10sgxs4/r_p_noisy_sentences_dataset/","created":"2023-02-03","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":0},"text":"[R] [P] Noisy Sentences Dataset 550K sentences in 5 European languages augmented with noise for training and evaluating spell correction tools or machine learning models. We have constructed our dataset to cover representatives from the language families used across Europe.\n\n* Germanic - English, German;\n* Romance - French;\n* Slavic - Bulgarian;\n* Turkic - Turkish;\n\n**Use case example:** Apply language models or other techniques to compare the sentence pairs and reconstruct the original sentences from the augmented ones. You can use a single multilingual solution to solve the challenge or employ multiple models/techniques for the separate languages. Per-word dictionary lookup is also an option.\n\n**Link:** [https://github.com/radi-cho/noisy-sentences-dataset](https://github.com/radi-cho/noisy-sentences-dataset)","classes":{"dataset":0.0381027423}}
{"title":"[d]? Is there a way to access youtube alphabetically or by id?","description":"I'm guessing i probably am not the first person who has wanted to work with youtube data so I'm hoping here is a good place to ask\n\nSo i had an idea to make a neural network that would go through your youtube history and then train a neural network on it. Afterwards if there is a way to access all of youtube by id in a way that you can check every video then you could store all of the id for videos you might like and then use a youtube downloader like youtube-dl to download a certain amount. Was just a dumb idea i had but now i want to actually try it but I'm unsure if I'll actually be able to get the data i need to do it","link":"https://www.reddit.com/r/MachineLearning/comments/10sdrp4/d_is_there_a_way_to_access_youtube_alphabetically/","created":"2023-02-03","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":3},"text":"[d]? Is there a way to access youtube alphabetically or by id? I'm guessing i probably am not the first person who has wanted to work with youtube data so I'm hoping here is a good place to ask\n\nSo i had an idea to make a neural network that would go through your youtube history and then train a neural network on it. Afterwards if there is a way to access all of youtube by id in a way that you can check every video then you could store all of the id for videos you might like and then use a youtube downloader like youtube-dl to download a certain amount. Was just a dumb idea i had but now i want to actually try it but I'm unsure if I'll actually be able to get the data i need to do it","classes":{"dataset":0.0936115459}}
{"title":"[p] Is it possible to add more classes to an already trained resnet image classifier model without the need to retrain it in all dataset again? [p]","description":"\\[p\\] I am working on massive dataset, and in the future, we'll have to add some more classes over time, can I train the model in the only new classes?\\[p\\]","link":"https://www.reddit.com/r/MachineLearning/comments/10sa859/p_is_it_possible_to_add_more_classes_to_an/","created":"2023-02-03","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":6},"text":"[p] Is it possible to add more classes to an already trained resnet image classifier model without the need to retrain it in all dataset again? [p] \\[p\\] I am working on massive dataset, and in the future, we'll have to add some more classes over time, can I train the model in the only new classes?\\[p\\]","classes":{"dataset":0.5252657533}}
{"title":"[R] Extracting Training Data from Diffusion Models","description":"[https://twitter.com/eric\\_wallace\\_/status/1620449934863642624?s=46&amp;t=GVukPDI7944N8-waYE5qcw](https://twitter.com/eric_wallace_/status/1620449934863642624?s=46&amp;t=GVukPDI7944N8-waYE5qcw)\n\nExtracting training data from diffusion models is possible by following, more or less, these steps:\n\n* Compute CLIP embeddings for the images in a training dataset.\n* Perform an all-pairs comparison and mark the pairs with l2 distance smaller than some threshold as near duplicates\n* Use the prompts for training samples marked as near duplicates to generate N synthetic samples with the trained model\n* Compute the all-pairs  l2 distance between the embeddings of generated samples for a given training prompt. Build a graph where the nodes are generated samples and an edge exists if the l2 distance is less than some threshold. If the largest clique in the resulting graph is of size 10, then the training sample is considered to be memorized.\n* Visually inspect the results to determine if the samples considered to be memorized are similar to the training data samples.\n\nWith this method, the authors were able to find samples from Stable Diffusion and Imagen  corresponding to copyrighted training images.","link":"https://www.reddit.com/r/MachineLearning/comments/10r57pn/r_extracting_training_data_from_diffusion_models/","created":"2023-02-01","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":77},"text":"[R] Extracting Training Data from Diffusion Models [https://twitter.com/eric\\_wallace\\_/status/1620449934863642624?s=46&amp;t=GVukPDI7944N8-waYE5qcw](https://twitter.com/eric_wallace_/status/1620449934863642624?s=46&amp;t=GVukPDI7944N8-waYE5qcw)\n\nExtracting training data from diffusion models is possible by following, more or less, these steps:\n\n* Compute CLIP embeddings for the images in a training dataset.\n* Perform an all-pairs comparison and mark the pairs with l2 distance smaller than some threshold as near duplicates\n* Use the prompts for training samples marked as near duplicates to generate N synthetic samples with the trained model\n* Compute the all-pairs  l2 distance between the embeddings of generated samples for a given training prompt. Build a graph where the nodes are generated samples and an edge exists if the l2 distance is less than some threshold. If the largest clique in the resulting graph is of size 10, then the training sample is considered to be memorized.\n* Visually inspect the results to determine if the samples considered to be memorized are similar to the training data samples.\n\nWith this method, the authors were able to find samples from Stable Diffusion and Imagen  corresponding to copyrighted training images.","classes":{"dataset":0.539825201}}
{"title":"[D] Commercial Use of a Model that has been trained using Human3.6M","description":" I wanted to use the [Learnable Trainangulation](https://github.com/karfly/learnable-triangulation-pytorch) model in a commercial project. The source code itself is under MIT licensing. However, the dataset they have used is [Human3.6M](http://vision.imar.ro/human3.6m/description.php), which states that the [license](http://vision.imar.ro/human3.6m/eula.php) is \"FREE OF CHARGE FOR ACADEMIC USE ONLY\".\n\nYet, recent court rulings (in the US) state that models can use copyrighted data during training, and the results are no longer bound by that copyright (e.g. Google Books). Does the same apply here?","link":"https://www.reddit.com/r/MachineLearning/comments/10rp7ze/d_commercial_use_of_a_model_that_has_been_trained/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":2},"text":"[D] Commercial Use of a Model that has been trained using Human3.6M  I wanted to use the [Learnable Trainangulation](https://github.com/karfly/learnable-triangulation-pytorch) model in a commercial project. The source code itself is under MIT licensing. However, the dataset they have used is [Human3.6M](http://vision.imar.ro/human3.6m/description.php), which states that the [license](http://vision.imar.ro/human3.6m/eula.php) is \"FREE OF CHARGE FOR ACADEMIC USE ONLY\".\n\nYet, recent court rulings (in the US) state that models can use copyrighted data during training, and the results are no longer bound by that copyright (e.g. Google Books). Does the same apply here?","classes":{"dataset":0.1788807064}}
{"title":"[D] ImageNet normalization vs [-1, 1] normalization","description":"For ImageNet classification, there are two common ways of normalizing the input images:\n\n\\- Normalize to `[-1, 1]` using an affine transformation (`2*(x/255) - 1`).\n\n\\- Normalize using ImageNet `mean = (0.485, 0.456, 0.406)` and `std = (0.229, 0.224, 0.225)`.\n\nI observe that the first one is more common in TensorFlow codebases (including Jax models with TensorFlow data processing, e.g. the official Vision Transformers code), whereas the second is ubiquitous in PyTorch codebases.\n\nI tried to find empirical comparisons of the two, but there doesn't seem to be any.\n\nWhich one is better in your opinion? I guess the performance shouldn't be too different, but still it's interesting to hear your experience.","link":"https://www.reddit.com/r/MachineLearning/comments/10rtis6/d_imagenet_normalization_vs_1_1_normalization/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":12},"text":"[D] ImageNet normalization vs [-1, 1] normalization For ImageNet classification, there are two common ways of normalizing the input images:\n\n\\- Normalize to `[-1, 1]` using an affine transformation (`2*(x/255) - 1`).\n\n\\- Normalize using ImageNet `mean = (0.485, 0.456, 0.406)` and `std = (0.229, 0.224, 0.225)`.\n\nI observe that the first one is more common in TensorFlow codebases (including Jax models with TensorFlow data processing, e.g. the official Vision Transformers code), whereas the second is ubiquitous in PyTorch codebases.\n\nI tried to find empirical comparisons of the two, but there doesn't seem to be any.\n\nWhich one is better in your opinion? I guess the performance shouldn't be too different, but still it's interesting to hear your experience.","classes":{"dataset":0.4389583468}}
{"title":"[P] Time series outlier / anomaly detection","description":"I have traffic speed time series data for each day of the week over several months, with data samples about every 30 seconds. I'd like to find periods of time (subsequences) where the speed is much slower than usual. Any recommendations for algorithms that would be well suited to this problem? Thanks","link":"https://www.reddit.com/r/MachineLearning/comments/10rxnsk/p_time_series_outlier_anomaly_detection/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":3},"text":"[P] Time series outlier / anomaly detection I have traffic speed time series data for each day of the week over several months, with data samples about every 30 seconds. I'd like to find periods of time (subsequences) where the speed is much slower than usual. Any recommendations for algorithms that would be well suited to this problem? Thanks","classes":{"dataset":0.5213651657}}
{"title":"[D] Apple's ane-transformers - experiences?","description":"I'm using Huggingface's transformers regularly for experimentations, but I plan to deploy some of the models to iOS.\n\nI have found [ml-ane-transformers](https://github.com/apple/ml-ane-transformers/tree/main/ane_transformers) repo from Apple, which shows how transformers can be rewritten to have much better performance on Apple's devices. There's an example of DistilBERT implemented in that optimized way.\n\nAs I plan to deploy transformers to iOS, I started thinking about this. I'm hoping some already have experience about this, so we can discuss:\n\n* Has anyone tried this themselves? Do they actually see the improvements in performance on iOS?\n* I'm using Huggingface's transformer models in my experiments. How much work do you think there is to rewrite model in this optimized way?\n* It's very difficult to train transformers from scratch (especially if they're big :) ), so I'm fine-tuning on top of pre-trained models on Huggingface. Is it possible to use weights from pretrained Huggingface models with the Apple's reference code? How difficult is it?","link":"https://www.reddit.com/r/MachineLearning/comments/10raouh/d_apples_anetransformers_experiences/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":7},"text":"[D] Apple's ane-transformers - experiences? I'm using Huggingface's transformers regularly for experimentations, but I plan to deploy some of the models to iOS.\n\nI have found [ml-ane-transformers](https://github.com/apple/ml-ane-transformers/tree/main/ane_transformers) repo from Apple, which shows how transformers can be rewritten to have much better performance on Apple's devices. There's an example of DistilBERT implemented in that optimized way.\n\nAs I plan to deploy transformers to iOS, I started thinking about this. I'm hoping some already have experience about this, so we can discuss:\n\n* Has anyone tried this themselves? Do they actually see the improvements in performance on iOS?\n* I'm using Huggingface's transformer models in my experiments. How much work do you think there is to rewrite model in this optimized way?\n* It's very difficult to train transformers from scratch (especially if they're big :) ), so I'm fine-tuning on top of pre-trained models on Huggingface. Is it possible to use weights from pretrained Huggingface models with the Apple's reference code? How difficult is it?","classes":{"dataset":0.4208758473}}
{"title":"[D] What does a DL role look like in ten years?","description":"Every day, there seems to be new evidence of the generalization capabilities of LLMs.\n\nWhat does this mean for the future role of deep learning experts in academia and business? \n\nIt seems like there's a significant chance that skills such as PyTorch and Jax will be displaced by prompt construction and off-the-shelf model APIs, with only a few large institutions working on the DNN itself.\n\nCurious to hear others' thoughts on this.","link":"https://www.reddit.com/r/MachineLearning/comments/10qzlhw/d_what_does_a_dl_role_look_like_in_ten_years/","created":"2023-02-01","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":26},"text":"[D] What does a DL role look like in ten years? Every day, there seems to be new evidence of the generalization capabilities of LLMs.\n\nWhat does this mean for the future role of deep learning experts in academia and business? \n\nIt seems like there's a significant chance that skills such as PyTorch and Jax will be displaced by prompt construction and off-the-shelf model APIs, with only a few large institutions working on the DNN itself.\n\nCurious to hear others' thoughts on this.","classes":{"dataset":0.3295331895}}
{"title":"[D] Why is stable diffusion much smaller than predecessors?","description":"Stable diffusion seems to be a departure from the trend of building larger and larger models.\n\nIt has 10x less parameters than other image generation models like DALLE-2.\n\n[\u201cIncredibly, compared with DALL-E 2 and Imagen, the Stable Diffusion model is a lot smaller. While DALL-E 2 has around 3.5 Billion parameters, and Imagen has 4.6 Billion, the first Stable Diffusion model has just 890 million parameters, which means it uses a lot less VRAM and can actually be run on consumer-grade graphics cards.\u201d](https://medium.com/nightcafe-creator/stable-diffusion-tutorial-how-to-use-stable-diffusion-157785632eb3)\n\n\nWhat allows stable diffusion to work so well with a lot less parameters? Are there any drawbacks to this, like requiring stable diffusion to be fine tuned more than DALLE-2 for example?","link":"https://www.reddit.com/r/MachineLearning/comments/10r5gku/d_why_is_stable_diffusion_much_smaller_than/","created":"2023-02-01","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":7},"text":"[D] Why is stable diffusion much smaller than predecessors? Stable diffusion seems to be a departure from the trend of building larger and larger models.\n\nIt has 10x less parameters than other image generation models like DALLE-2.\n\n[\u201cIncredibly, compared with DALL-E 2 and Imagen, the Stable Diffusion model is a lot smaller. While DALL-E 2 has around 3.5 Billion parameters, and Imagen has 4.6 Billion, the first Stable Diffusion model has just 890 million parameters, which means it uses a lot less VRAM and can actually be run on consumer-grade graphics cards.\u201d](https://medium.com/nightcafe-creator/stable-diffusion-tutorial-how-to-use-stable-diffusion-157785632eb3)\n\n\nWhat allows stable diffusion to work so well with a lot less parameters? Are there any drawbacks to this, like requiring stable diffusion to be fine tuned more than DALLE-2 for example?","classes":{"dataset":0.2090547532}}
{"title":"[D]How Will Open Source Alternatives Compete With GPT3?","description":"To clarify, I'm not talking about ChatGPT here. I've been testing outputs from GPT-3 davinci003 against alternatives in terms of output quality, relevance, and ability to understand \"instruct\" (versus vanilla autocompletion).\n\nI tried these:\nAI21 Jurassic 178B\nNeoX 20B\nGPT J 6B\nFairSeq 13B\n\nAs well as:\nGPT-3 davinci002\nGPT-3 davinci001\n\n\nOf course, I didn't expect the smaller models to be on par with GPT-3, but I was surprised at how much better GPT3 davinci 003 performed compared to AI21's 178B model. AI21's Jurassic 178B seems to be comparable to GPT3 davinci 001.\n\n\nDoes this mean that only well-funded corporations will be able to train general-purpose LLMs? It seems to me that just having a large model doesn't do much, it's also about several iterations of training and feedback. How are open source alternatives going to be able to compete?\n\n\n(I'm not in the ML or CS field, just an amateur who enjoys using these models)","link":"https://www.reddit.com/r/MachineLearning/comments/10rhprm/dhow_will_open_source_alternatives_compete_with/","created":"2023-02-02","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":7},"text":"[D]How Will Open Source Alternatives Compete With GPT3? To clarify, I'm not talking about ChatGPT here. I've been testing outputs from GPT-3 davinci003 against alternatives in terms of output quality, relevance, and ability to understand \"instruct\" (versus vanilla autocompletion).\n\nI tried these:\nAI21 Jurassic 178B\nNeoX 20B\nGPT J 6B\nFairSeq 13B\n\nAs well as:\nGPT-3 davinci002\nGPT-3 davinci001\n\n\nOf course, I didn't expect the smaller models to be on par with GPT-3, but I was surprised at how much better GPT3 davinci 003 performed compared to AI21's 178B model. AI21's Jurassic 178B seems to be comparable to GPT3 davinci 001.\n\n\nDoes this mean that only well-funded corporations will be able to train general-purpose LLMs? It seems to me that just having a large model doesn't do much, it's also about several iterations of training and feedback. How are open source alternatives going to be able to compete?\n\n\n(I'm not in the ML or CS field, just an amateur who enjoys using these models)","classes":{"dataset":0.3455379903}}
{"title":"[ADVISE NEEDED] Extracting clauses from contracts","description":"Hi everyone!\n\nI am currently trying to extract specific clauses from employment contracts that describe something the employee needs to ask approval for from the employer (e.g., requesting time off or requesting a waiver for a non-compete) while ignoring other clauses that do not contain asking-for-approval actions for something (e.g., statement about working days and hours, the position description, or the salary components). And I would like your advice or recommendations on doing this.\n\nThe scenario: the employment contracts are in English and PDF format. I have a manually labeled data set of example clauses that I want (containing asking-for-approval actions). The data describes exactly where the clauses are located in the contract (coordinates and page number). This data set is created from multiple employment contract PDFs. Basically, annotations with the full text from the PDF and also the starting and ending coordinates on where it is located on the page of the contract.\n\nWhat approach would you suggest or recommend for me to tackle this challenge?\n\n&amp;#x200B;\n\nThank you very much!","link":"https://www.reddit.com/r/LanguageTechnology/comments/10seo2i/advise_needed_extracting_clauses_from_contracts/","created":"2023-02-03","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":1},"text":"[ADVISE NEEDED] Extracting clauses from contracts Hi everyone!\n\nI am currently trying to extract specific clauses from employment contracts that describe something the employee needs to ask approval for from the employer (e.g., requesting time off or requesting a waiver for a non-compete) while ignoring other clauses that do not contain asking-for-approval actions for something (e.g., statement about working days and hours, the position description, or the salary components). And I would like your advice or recommendations on doing this.\n\nThe scenario: the employment contracts are in English and PDF format. I have a manually labeled data set of example clauses that I want (containing asking-for-approval actions). The data describes exactly where the clauses are located in the contract (coordinates and page number). This data set is created from multiple employment contract PDFs. Basically, annotations with the full text from the PDF and also the starting and ending coordinates on where it is located on the page of the contract.\n\nWhat approach would you suggest or recommend for me to tackle this challenge?\n\n&amp;#x200B;\n\nThank you very much!","classes":{"dataset":0.3420703411}}
{"title":"merging two vectors in word2vec","description":"lets say X is a vector that contains the traits of person 1\n\nand Y is a vector that contains the traits of a person 2 \n\nhow to merge X and Y into a vector that describes both","link":"https://www.reddit.com/r/LanguageTechnology/comments/10rufby/merging_two_vectors_in_word2vec/","created":"2023-02-02","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":3},"text":"merging two vectors in word2vec lets say X is a vector that contains the traits of person 1\n\nand Y is a vector that contains the traits of a person 2 \n\nhow to merge X and Y into a vector that describes both","classes":{"dataset":0.2936312854}}
{"title":"EMNLP video interviews, workshops, and posters","description":"I learned a lot at EMNLP in December and captured some of what I learned in this video.\n\n**Interviews**\n\nI asked five NLP researchers these questions:\n\n1- What is the most exciting development in NLP in 2022\n\n2- What are you looking forward to in 2023?\n\n3- What is an underrated idea that the field should pay more attention to?\n\nTheir answers start at [01:22](https://www.youtube.com/watch?v=plCvF_7qrmY&amp;t=82s).\n\n**Workshops**\n\nI got to spend time at these workshops:\n\n* [Generation, Evaluation &amp; Metrics (GEM)](https://gem-benchmark.com/workshop)\n* [Massively Multilingual NLU](https://mmnlu-22.github.io/)\n* [Blackbox NLP](https://blackboxnlp.github.io/2022/)\n\nMy main takeaways are at [09:25](https://www.youtube.com/watch?v=plCvF_7qrmY&amp;t=565s).\n\n**Posters**\n\nIf you've been to a conference you'd know there's an overwhelming number of posters. I recorded four of the ones I came across and thought were interesting (covering retrieval-augmented text generation, human evaluation, the BLOOM multimodal dataset, and a multimodal method to name music playlists).\n\nPoster presentations start at [14:38](https://www.youtube.com/watch?v=plCvF_7qrmY&amp;t=878s)\n\nFull video: [https://www.youtube.com/watch?v=plCvF\\_7qrmY](https://www.youtube.com/watch?v=plCvF_7qrmY)\n\nWhat's your answer to these questions?\n\n&gt;1- What is the most exciting development in NLP in 2022  \n2- What are you looking forward to in 2023?  \n3- What is an underrated idea that the field should pay more attention to?","link":"https://www.reddit.com/r/LanguageTechnology/comments/10qxm0l/emnlp_video_interviews_workshops_and_posters/","created":"2023-02-01","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"EMNLP video interviews, workshops, and posters I learned a lot at EMNLP in December and captured some of what I learned in this video.\n\n**Interviews**\n\nI asked five NLP researchers these questions:\n\n1- What is the most exciting development in NLP in 2022\n\n2- What are you looking forward to in 2023?\n\n3- What is an underrated idea that the field should pay more attention to?\n\nTheir answers start at [01:22](https://www.youtube.com/watch?v=plCvF_7qrmY&amp;t=82s).\n\n**Workshops**\n\nI got to spend time at these workshops:\n\n* [Generation, Evaluation &amp; Metrics (GEM)](https://gem-benchmark.com/workshop)\n* [Massively Multilingual NLU](https://mmnlu-22.github.io/)\n* [Blackbox NLP](https://blackboxnlp.github.io/2022/)\n\nMy main takeaways are at [09:25](https://www.youtube.com/watch?v=plCvF_7qrmY&amp;t=565s).\n\n**Posters**\n\nIf you've been to a conference you'd know there's an overwhelming number of posters. I recorded four of the ones I came across and thought were interesting (covering retrieval-augmented text generation, human evaluation, the BLOOM multimodal dataset, and a multimodal method to name music playlists).\n\nPoster presentations start at [14:38](https://www.youtube.com/watch?v=plCvF_7qrmY&amp;t=878s)\n\nFull video: [https://www.youtube.com/watch?v=plCvF\\_7qrmY](https://www.youtube.com/watch?v=plCvF_7qrmY)\n\nWhat's your answer to these questions?\n\n&gt;1- What is the most exciting development in NLP in 2022  \n2- What are you looking forward to in 2023?  \n3- What is an underrated idea that the field should pay more attention to?","classes":{"dataset":0.1997401714}}
{"title":"Dirty labelling solution","description":"I\u2019m looking to some aggregation on academic research and news articles to see what insights I get from it. I\u2019m using textrazor to do named entity recognition on the documents, but getting a lot of dirty labels that have slightly different wording. For example, Tesla, Tesla ltd, Tesla Ltd. As a result, my aggregations have a lot of duplicate results.\n\nThe dataset consists of about 4M labels so the solution has to be efficient to be viable. I was thinking of putting the labels through word2vec and then clustering them based on the word embedding distances? But then the problem arises of how many clusters to use?\n\nI\u2019ve also tried simple regex preprocessing to get rid of the company abbreviations but there are other examples that cannot be solved that easily.","link":"https://www.reddit.com/r/LanguageTechnology/comments/10qnv70/dirty_labelling_solution/","created":"2023-02-01","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":2},"text":"Dirty labelling solution I\u2019m looking to some aggregation on academic research and news articles to see what insights I get from it. I\u2019m using textrazor to do named entity recognition on the documents, but getting a lot of dirty labels that have slightly different wording. For example, Tesla, Tesla ltd, Tesla Ltd. As a result, my aggregations have a lot of duplicate results.\n\nThe dataset consists of about 4M labels so the solution has to be efficient to be viable. I was thinking of putting the labels through word2vec and then clustering them based on the word embedding distances? But then the problem arises of how many clusters to use?\n\nI\u2019ve also tried simple regex preprocessing to get rid of the company abbreviations but there are other examples that cannot be solved that easily.","classes":{"dataset":0.5542110801}}
{"title":"Deltas and Delta-Deltas Features Explained","description":"Hi guys,\n\nI have made a video on YouTube [here](https://youtu.be/zxEnuPolylY) where I explain how deltas and delta-deltas speech features are computed.\n\nI hope it may be of use to some of you out there. As always, feedback is more than welcomed! :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/10qorre/deltas_and_deltadeltas_features_explained/","created":"2023-02-01","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"Deltas and Delta-Deltas Features Explained Hi guys,\n\nI have made a video on YouTube [here](https://youtu.be/zxEnuPolylY) where I explain how deltas and delta-deltas speech features are computed.\n\nI hope it may be of use to some of you out there. As always, feedback is more than welcomed! :)","classes":{"dataset":0.0422217064}}
{"title":"Problems with Doccano","description":"I\u2019ve e been experiencing a weird problem with Doccano. When I download the json file I\u2019ve noticed some of the tags I can see in the GUI are not in the json file, which translates in many errors during the model training results. Has anyone experienced this same issues? How did you fix it?","link":"https://www.reddit.com/r/LanguageTechnology/comments/10qai9p/problems_with_doccano/","created":"2023-01-31","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"Problems with Doccano I\u2019ve e been experiencing a weird problem with Doccano. When I download the json file I\u2019ve noticed some of the tags I can see in the GUI are not in the json file, which translates in many errors during the model training results. Has anyone experienced this same issues? How did you fix it?","classes":{"dataset":0.1890017539}}
{"title":"Conversion of parametric data describing the product to an understandable product description","description":"Hi, I'm wondering what would you say is the best model to create a solution for converting parametric data about a product into an understandable description of the product. Thank you for your suggestions","link":"https://www.reddit.com/r/LanguageTechnology/comments/10q5vhl/conversion_of_parametric_data_describing_the/","created":"2023-01-31","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":3},"text":"Conversion of parametric data describing the product to an understandable product description Hi, I'm wondering what would you say is the best model to create a solution for converting parametric data about a product into an understandable description of the product. Thank you for your suggestions","classes":{"dataset":0.3644769192}}
{"title":"FDIC Takes over Silicon Valley Bank","description":"https://www.fdic.gov/news/press-releases/2023/pr23016.html","link":"https://www.fdic.gov/news/press-releases/2023/pr23016.html","created":"2023-03-10","tags":["hackernews"],"meta":{"score":2781},"text":"FDIC Takes over Silicon Valley Bank https://www.fdic.gov/news/press-releases/2023/pr23016.html","classes":{"dataset":0.5170041323}}
{"title":"129-year-old vessel still tethered to lifeboat found on floor of Lake Huron","description":"https://www.smithsonianmag.com/smart-news/ironton-shipwreck-lake-huron-180981741/","link":"https://www.smithsonianmag.com/smart-news/ironton-shipwreck-lake-huron-180981741/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":58},"text":"129-year-old vessel still tethered to lifeboat found on floor of Lake Huron https://www.smithsonianmag.com/smart-news/ironton-shipwreck-lake-huron-180981741/","classes":{"dataset":0.4696053863}}
{"title":"A SVB short seller explains red flags he saw months ago","description":"https://fortune.com/2023/03/10/silicon-valley-bank-short-seller-red-flags/","link":"https://fortune.com/2023/03/10/silicon-valley-bank-short-seller-red-flags/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":104},"text":"A SVB short seller explains red flags he saw months ago https://fortune.com/2023/03/10/silicon-valley-bank-short-seller-red-flags/","classes":{"dataset":0.5382418633}}
{"title":"Modern Symbolics Lisp Machine Keyboard Replica: Keymacs A620N-88","description":"https://www.instagram.com/p/CplCseEs9DA/","link":"https://www.instagram.com/p/CplCseEs9DA/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":36},"text":"Modern Symbolics Lisp Machine Keyboard Replica: Keymacs A620N-88 https://www.instagram.com/p/CplCseEs9DA/","classes":{"dataset":0.5187079906}}
{"title":"Coinbase suspending USDC:USD conversions over the weekend","description":"https://twitter.com/coinbase/status/1634399032767307776","link":"https://twitter.com/coinbase/status/1634399032767307776","created":"2023-03-11","tags":["hackernews"],"meta":{"score":215},"text":"Coinbase suspending USDC:USD conversions over the weekend https://twitter.com/coinbase/status/1634399032767307776","classes":{"dataset":0.4941963255}}
{"title":"$3.3B of the ~$40 billion of USDC reserves remain at SVB","description":"https://twitter.com/circle/status/1634391505988206592","link":"https://twitter.com/circle/status/1634391505988206592","created":"2023-03-11","tags":["hackernews"],"meta":{"score":192},"text":"$3.3B of the ~$40 billion of USDC reserves remain at SVB https://twitter.com/circle/status/1634391505988206592","classes":{"dataset":0.4828366041}}
{"title":"Shane Pitman, leader of the warez group Razor 1911: life after prison (2005)","description":"https://defacto2.net/f/ab3914","link":"https://defacto2.net/f/ab3914","created":"2023-03-10","tags":["hackernews"],"meta":{"score":281},"text":"Shane Pitman, leader of the warez group Razor 1911: life after prison (2005) https://defacto2.net/f/ab3914","classes":{"dataset":0.4953151047}}
{"title":"First Republic Bank files 8-K \u2013 Tech only 4% of total deposits; no sector >9%","description":"https://ir.firstrepublic.com/static-files/295faa27-f208-4936-81ff-6c8bfa0fb6b5","link":"https://ir.firstrepublic.com/static-files/295faa27-f208-4936-81ff-6c8bfa0fb6b5","created":"2023-03-11","tags":["hackernews"],"meta":{"score":205},"text":"First Republic Bank files 8-K \u2013 Tech only 4% of total deposits; no sector >9% https://ir.firstrepublic.com/static-files/295faa27-f208-4936-81ff-6c8bfa0fb6b5","classes":{"dataset":0.5242755413}}
{"title":"The Dot Essay (1923)","description":"https://psychclassics.yorku.ca/Wertheimer/Forms/forms.htm","link":"https://psychclassics.yorku.ca/Wertheimer/Forms/forms.htm","created":"2023-03-10","tags":["hackernews"],"meta":{"score":4},"text":"The Dot Essay (1923) https://psychclassics.yorku.ca/Wertheimer/Forms/forms.htm","classes":{"dataset":0.5131120086}}
{"title":"Wells Fargo clients report missing deposits as bank works on fix","description":"https://www.thinkadvisor.com/2023/03/10/wells-fargo-clients-report-missing-deposits-as-bank-works-on-fix/","link":"https://www.thinkadvisor.com/2023/03/10/wells-fargo-clients-report-missing-deposits-as-bank-works-on-fix/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":98},"text":"Wells Fargo clients report missing deposits as bank works on fix https://www.thinkadvisor.com/2023/03/10/wells-fargo-clients-report-missing-deposits-as-bank-works-on-fix/","classes":{"dataset":0.4511988461}}
{"title":"Emergency bridge loan for SVB customers","description":"https://www.brex.com/svb-emergency-line","link":"https://www.brex.com/svb-emergency-line","created":"2023-03-10","tags":["hackernews"],"meta":{"score":184},"text":"Emergency bridge loan for SVB customers https://www.brex.com/svb-emergency-line","classes":{"dataset":0.4974841774}}
{"title":"Who reads your email?","description":"https://www.netmeister.org/blog/mx-diversity.html","link":"https://www.netmeister.org/blog/mx-diversity.html","created":"2023-03-10","tags":["hackernews"],"meta":{"score":107},"text":"Who reads your email? https://www.netmeister.org/blog/mx-diversity.html","classes":{"dataset":0.490660578}}
{"title":"What does Silicon Valley Bank\u2019s collapse mean for the financial system?","description":"https://www.economist.com/finance-and-economics/2023/03/10/what-does-silicon-valley-banks-collapse-mean-for-the-financial-system","link":"https://www.economist.com/finance-and-economics/2023/03/10/what-does-silicon-valley-banks-collapse-mean-for-the-financial-system","created":"2023-03-10","tags":["hackernews"],"meta":{"score":205},"text":"What does Silicon Valley Bank\u2019s collapse mean for the financial system? https://www.economist.com/finance-and-economics/2023/03/10/what-does-silicon-valley-banks-collapse-mean-for-the-financial-system","classes":{"dataset":0.507349968}}
{"title":"Wonder Studio: this AI-powered tool might be a preview of the future of VFX","description":"https://3dvf.com/en/wonder-studio-this-ai-powered-tool-might-be-a-preview-of-the-future-of-vfx/","link":"https://3dvf.com/en/wonder-studio-this-ai-powered-tool-might-be-a-preview-of-the-future-of-vfx/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":17},"text":"Wonder Studio: this AI-powered tool might be a preview of the future of VFX https://3dvf.com/en/wonder-studio-this-ai-powered-tool-might-be-a-preview-of-the-future-of-vfx/","classes":{"dataset":0.5151798725}}
{"title":"The collapse of SVB exposes the largest crack in the economy","description":"http://www.brooock.com/a/svb-collapse-exposes-cracks-in-economy","link":"http://www.brooock.com/a/svb-collapse-exposes-cracks-in-economy","created":"2023-03-10","tags":["hackernews"],"meta":{"score":265},"text":"The collapse of SVB exposes the largest crack in the economy http://www.brooock.com/a/svb-collapse-exposes-cracks-in-economy","classes":{"dataset":0.4862259328}}
{"title":"Why Write?","description":"https://fs.blog/why-write/","link":"https://fs.blog/why-write/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":112},"text":"Why Write? https://fs.blog/why-write/","classes":{"dataset":0.4866341949}}
{"title":"Evidence of a predictive coding hierarchy in the human brain listening to speech","description":"https://www.nature.com/articles/s41562-022-01516-2","link":"https://www.nature.com/articles/s41562-022-01516-2","created":"2023-03-10","tags":["hackernews"],"meta":{"score":189},"text":"Evidence of a predictive coding hierarchy in the human brain listening to speech https://www.nature.com/articles/s41562-022-01516-2","classes":{"dataset":0.4888050258}}
{"title":"JPM bankers pull all-nighters to take on clients of Silicon Valley Bank","description":"https://nypost.com/2023/03/10/jpm-bankers-pull-all-nighters-to-take-on-clients-of-silicon-valley-bank/","link":"https://nypost.com/2023/03/10/jpm-bankers-pull-all-nighters-to-take-on-clients-of-silicon-valley-bank/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":35},"text":"JPM bankers pull all-nighters to take on clients of Silicon Valley Bank https://nypost.com/2023/03/10/jpm-bankers-pull-all-nighters-to-take-on-clients-of-silicon-valley-bank/","classes":{"dataset":0.4936966896}}
{"title":"Roku filed an 8-K saying that of its $1.9B of cash, $487M is stuck at SVB","description":"https://vikashruhil.medium.com/roku-filed-an-8-k-saying-that-of-its-1-9-dc03147d4d58","link":"https://vikashruhil.medium.com/roku-filed-an-8-k-saying-that-of-its-1-9-dc03147d4d58","created":"2023-03-10","tags":["hackernews"],"meta":{"score":328},"text":"Roku filed an 8-K saying that of its $1.9B of cash, $487M is stuck at SVB https://vikashruhil.medium.com/roku-filed-an-8-k-saying-that-of-its-1-9-dc03147d4d58","classes":{"dataset":0.4870611727}}
{"title":"Debconf's questions, or whiptail, doesn't always work in xterms","description":"https://utcc.utoronto.ca/~cks/space/blog/linux/DebconfWhiptailVsXterm","link":"https://utcc.utoronto.ca/~cks/space/blog/linux/DebconfWhiptailVsXterm","created":"2023-03-09","tags":["hackernews"],"meta":{"score":17},"text":"Debconf's questions, or whiptail, doesn't always work in xterms https://utcc.utoronto.ca/~cks/space/blog/linux/DebconfWhiptailVsXterm","classes":{"dataset":0.5224224329}}
{"title":"Kiviaq \u2013 Greenland\u2019s misunderstood winter delicacy","description":"https://www.atlasobscura.com/articles/what-is-kiviaq","link":"https://www.atlasobscura.com/articles/what-is-kiviaq","created":"2023-03-09","tags":["hackernews"],"meta":{"score":25},"text":"Kiviaq \u2013 Greenland\u2019s misunderstood winter delicacy https://www.atlasobscura.com/articles/what-is-kiviaq","classes":{"dataset":0.485247761}}
{"title":"Adrian Schoolcraft: Police Officer Forcibly Committed for Reporting Corruption","description":"https://en.wikipedia.org/wiki/Adrian_Schoolcraft","link":"https://en.wikipedia.org/wiki/Adrian_Schoolcraft","created":"2023-03-11","tags":["hackernews"],"meta":{"score":4},"text":"Adrian Schoolcraft: Police Officer Forcibly Committed for Reporting Corruption https://en.wikipedia.org/wiki/Adrian_Schoolcraft","classes":{"dataset":0.4889693856}}
{"title":"How to start a rocket engine","description":"https://everydayastronaut.com/how-to-start-a-rocket-engine/","link":"https://everydayastronaut.com/how-to-start-a-rocket-engine/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":331},"text":"How to start a rocket engine https://everydayastronaut.com/how-to-start-a-rocket-engine/","classes":{"dataset":0.4960347414}}
{"title":"Show HN: ReplGPT.jl, a ChatGPT shell mode for Julia","description":"https://github.com/ThatcherC/ReplGPT.jl","link":"https://github.com/ThatcherC/ReplGPT.jl","created":"2023-03-11","tags":["hackernews"],"meta":{"score":5},"text":"Show HN: ReplGPT.jl, a ChatGPT shell mode for Julia https://github.com/ThatcherC/ReplGPT.jl","classes":{"dataset":0.4955042899}}
{"title":"Load 'em up and throw 'em under the bus","description":"https://rachelbythebay.com/w/2023/03/09/bus/","link":"https://rachelbythebay.com/w/2023/03/09/bus/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":611},"text":"Load 'em up and throw 'em under the bus https://rachelbythebay.com/w/2023/03/09/bus/","classes":{"dataset":0.5150929689}}
{"title":"Age Verification Mandates Would Undermine Anonymity Online","description":"https://www.eff.org/deeplinks/2023/03/age-verification-mandates-would-undermine-anonymity-online","link":"https://www.eff.org/deeplinks/2023/03/age-verification-mandates-would-undermine-anonymity-online","created":"2023-03-11","tags":["hackernews"],"meta":{"score":44},"text":"Age Verification Mandates Would Undermine Anonymity Online https://www.eff.org/deeplinks/2023/03/age-verification-mandates-would-undermine-anonymity-online","classes":{"dataset":0.5223886371}}
{"title":"The Big City; Aftermath of 40 Hours in an Elevator (1999)","description":"https://www.nytimes.com/1999/10/28/nyregion/the-big-city-aftermath-of-40-hours-in-an-elevator.html","link":"https://www.nytimes.com/1999/10/28/nyregion/the-big-city-aftermath-of-40-hours-in-an-elevator.html","created":"2023-03-09","tags":["hackernews"],"meta":{"score":25},"text":"The Big City; Aftermath of 40 Hours in an Elevator (1999) https://www.nytimes.com/1999/10/28/nyregion/the-big-city-aftermath-of-40-hours-in-an-elevator.html","classes":{"dataset":0.5286363959}}
{"title":"Polls find strong support for nuclear in UK and Switzerland","description":"https://www.world-nuclear-news.org/Articles/Polls-find-strong-support-for-nuclear-in-UK-and-Sw?feed=feed","link":"https://www.world-nuclear-news.org/Articles/Polls-find-strong-support-for-nuclear-in-UK-and-Sw?feed=feed","created":"2023-03-11","tags":["hackernews"],"meta":{"score":34},"text":"Polls find strong support for nuclear in UK and Switzerland https://www.world-nuclear-news.org/Articles/Polls-find-strong-support-for-nuclear-in-UK-and-Sw?feed=feed","classes":{"dataset":0.5167815685}}
{"title":"Oxy is Cloudflare's Rust-based next generation proxy framework","description":"https://blog.cloudflare.com/introducing-oxy/","link":"https://blog.cloudflare.com/introducing-oxy/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":142},"text":"Oxy is Cloudflare's Rust-based next generation proxy framework https://blog.cloudflare.com/introducing-oxy/","classes":{"dataset":0.4921704829}}
{"title":"Secretive: Store SSH Keys in the Secure Enclave","description":"https://github.com/maxgoedjen/secretive","link":"https://github.com/maxgoedjen/secretive","created":"2023-03-10","tags":["hackernews"],"meta":{"score":283},"text":"Secretive: Store SSH Keys in the Secure Enclave https://github.com/maxgoedjen/secretive","classes":{"dataset":0.527107656}}
{"title":"Circle: SVB is 1 of 6 banking partners Circle uses for ~25% part of USDC in cash","description":"https://twitter.com/circle/status/1634341007306248199","link":"https://twitter.com/circle/status/1634341007306248199","created":"2023-03-11","tags":["hackernews"],"meta":{"score":18},"text":"Circle: SVB is 1 of 6 banking partners Circle uses for ~25% part of USDC in cash https://twitter.com/circle/status/1634341007306248199","classes":{"dataset":0.6089605093}}
{"title":"The Quest for Netflix on Asahi Linux","description":"https://www.da.vidbuchanan.co.uk/blog/netflix-on-asahi.html","link":"https://www.da.vidbuchanan.co.uk/blog/netflix-on-asahi.html","created":"2023-03-09","tags":["hackernews"],"meta":{"score":646},"text":"The Quest for Netflix on Asahi Linux https://www.da.vidbuchanan.co.uk/blog/netflix-on-asahi.html","classes":{"dataset":0.47331056}}
{"title":"Understanding Social Media Recommendation Algorithms","description":"https://knightcolumbia.org/content/understanding-social-media-recommendation-algorithms","link":"https://knightcolumbia.org/content/understanding-social-media-recommendation-algorithms","created":"2023-03-09","tags":["hackernews"],"meta":{"score":35},"text":"Understanding Social Media Recommendation Algorithms https://knightcolumbia.org/content/understanding-social-media-recommendation-algorithms","classes":{"dataset":0.5146516562}}
{"title":"Forbe's 20th Best Bank Feb 2023: SVB Financial Group","description":"https://www.forbes.com/lists/americas-best-banks/","link":"https://www.forbes.com/lists/americas-best-banks/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":26},"text":"Forbe's 20th Best Bank Feb 2023: SVB Financial Group https://www.forbes.com/lists/americas-best-banks/","classes":{"dataset":0.5019193292}}
{"title":"Microbiologist Investigates After Her Beef Soup Turned Blue in the Fridge","description":"https://www.iflscience.com/microbiologist-investigates-after-her-beef-soup-turned-blue-in-the-freezer-67894","link":"https://www.iflscience.com/microbiologist-investigates-after-her-beef-soup-turned-blue-in-the-freezer-67894","created":"2023-03-10","tags":["hackernews"],"meta":{"score":100},"text":"Microbiologist Investigates After Her Beef Soup Turned Blue in the Fridge https://www.iflscience.com/microbiologist-investigates-after-her-beef-soup-turned-blue-in-the-freezer-67894","classes":{"dataset":0.4689744413}}
{"title":"A notebook is a human's best friend (2022)","description":"https://tsk.bearblog.dev/a-notebook-is-a-humans-best-friend/","link":"https://tsk.bearblog.dev/a-notebook-is-a-humans-best-friend/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":8},"text":"A notebook is a human's best friend (2022) https://tsk.bearblog.dev/a-notebook-is-a-humans-best-friend/","classes":{"dataset":0.4975004494}}
{"title":"Visual ChatGPT","description":"https://github.com/microsoft/visual-chatgpt","link":"https://github.com/microsoft/visual-chatgpt","created":"2023-03-10","tags":["hackernews"],"meta":{"score":663},"text":"Visual ChatGPT https://github.com/microsoft/visual-chatgpt","classes":{"dataset":0.5215357542}}
{"title":"Telehealth startup Cerebral shared millions of patients\u2019 data with advertisers","description":"https://techcrunch.com/2023/03/10/cerebral-shared-millions-patient-data-advertisers/","link":"https://techcrunch.com/2023/03/10/cerebral-shared-millions-patient-data-advertisers/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":307},"text":"Telehealth startup Cerebral shared millions of patients\u2019 data with advertisers https://techcrunch.com/2023/03/10/cerebral-shared-millions-patient-data-advertisers/","classes":{"dataset":0.4520229697}}
{"title":"OpenHV \u2013 Open-Source Pixelart Science-Fiction Real-Time-Strategy Game","description":"https://www.openhv.net/","link":"https://www.openhv.net/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":135},"text":"OpenHV \u2013 Open-Source Pixelart Science-Fiction Real-Time-Strategy Game https://www.openhv.net/","classes":{"dataset":0.5109300613}}
{"title":"Meta is building a decentralized, text-based social network","description":"https://www.platformer.news/p/meta-is-building-a-decentralized","link":"https://www.platformer.news/p/meta-is-building-a-decentralized","created":"2023-03-10","tags":["hackernews"],"meta":{"score":198},"text":"Meta is building a decentralized, text-based social network https://www.platformer.news/p/meta-is-building-a-decentralized","classes":{"dataset":0.510386467}}
{"title":"Lisp-powered laptop with a battery life measured in years","description":"https://www.hackster.io/news/andreas-eriksen-s-potatop-is-a-lisp-powered-laptop-with-a-battery-life-measured-in-years-2f5d79653f24","link":"https://www.hackster.io/news/andreas-eriksen-s-potatop-is-a-lisp-powered-laptop-with-a-battery-life-measured-in-years-2f5d79653f24","created":"2023-03-08","tags":["hackernews"],"meta":{"score":804},"text":"Lisp-powered laptop with a battery life measured in years https://www.hackster.io/news/andreas-eriksen-s-potatop-is-a-lisp-powered-laptop-with-a-battery-life-measured-in-years-2f5d79653f24","classes":{"dataset":0.494249016}}
{"title":"Battery-free Game Boy (2020)","description":"https://www.freethegameboy.info/","link":"https://www.freethegameboy.info/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":553},"text":"Battery-free Game Boy (2020) https://www.freethegameboy.info/","classes":{"dataset":0.4680684209}}
{"title":"ChatGPT-J: The Privacy-First, Self-Hosted Chatbot Built on GPT-J's Powerful AI","description":"https://colab.research.google.com/drive/1IRYRE5XXok0CIyLaQR4pgv9Q9Cv9lHvB?usp=sharing","link":"https://colab.research.google.com/drive/1IRYRE5XXok0CIyLaQR4pgv9Q9Cv9lHvB?usp=sharing","created":"2023-03-10","tags":["hackernews"],"meta":{"score":4},"text":"ChatGPT-J: The Privacy-First, Self-Hosted Chatbot Built on GPT-J's Powerful AI https://colab.research.google.com/drive/1IRYRE5XXok0CIyLaQR4pgv9Q9Cv9lHvB?usp=sharing","classes":{"dataset":0.5012309551}}
{"title":"Python Basics Onepager","description":"https://github.com/IvanReznikov/DataVerse/blob/main/Onepagers/onepager_python_basics.md","link":"https://github.com/IvanReznikov/DataVerse/blob/main/Onepagers/onepager_python_basics.md","created":"2023-03-11","tags":["hackernews"],"meta":{"score":29},"text":"Python Basics Onepager https://github.com/IvanReznikov/DataVerse/blob/main/Onepagers/onepager_python_basics.md","classes":{"dataset":0.4715567529}}
{"title":"Show HN: structured-ripgrep \u2013 Ripgrep over structured data","description":"https://github.com/orf/ripgrep-structured","link":"https://github.com/orf/ripgrep-structured","created":"2023-03-10","tags":["hackernews"],"meta":{"score":7},"text":"Show HN: structured-ripgrep \u2013 Ripgrep over structured data https://github.com/orf/ripgrep-structured","classes":{"dataset":0.4830505848}}
{"title":"The Demise of Silicon Valley Bank","description":"https://www.netinterest.co/p/the-demise-of-silicon-valley-bank","link":"https://www.netinterest.co/p/the-demise-of-silicon-valley-bank","created":"2023-03-10","tags":["hackernews"],"meta":{"score":206},"text":"The Demise of Silicon Valley Bank https://www.netinterest.co/p/the-demise-of-silicon-valley-bank","classes":{"dataset":0.5311075449}}
{"title":"How computer vision is changing manufacturing in 2023","description":"https://voxel51.com/blog/how-computer-vision-is-changing-manufacturing-in-2023/","link":"https://voxel51.com/blog/how-computer-vision-is-changing-manufacturing-in-2023/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":228},"text":"How computer vision is changing manufacturing in 2023 https://voxel51.com/blog/how-computer-vision-is-changing-manufacturing-in-2023/","classes":{"dataset":0.4736356437}}
{"title":"Dutch police collecting demonstrators' personal data on a large scale","description":"https://nltimes.nl/2023/03/10/police-collecting-demonstrators-personal-data-large-scale","link":"https://nltimes.nl/2023/03/10/police-collecting-demonstrators-personal-data-large-scale","created":"2023-03-10","tags":["hackernews"],"meta":{"score":209},"text":"Dutch police collecting demonstrators' personal data on a large scale https://nltimes.nl/2023/03/10/police-collecting-demonstrators-personal-data-large-scale","classes":{"dataset":0.5669890046}}
{"title":"Prompt for preserving newline and hyphen characters in text to correct","description":"Hello!\n\nI am trying to come up with a prompt that will preserve newlines and hyphens at line ends. I have a OCR scanned page of a book, and I want to pass the prompt the lines from the page. With my current prompt it sometimes does this correctly, sometimes it merges all of the text together into one paragraph, and sometimes it moves words between lines.\n\nI'm wanting the corrected text to be returned with the text on their proper lines so that I can be able to compare the original line to the corrected line with an image of the line of text from the scanned book. I tried using \\\\n as a line separator but I had more success using a custom line separator (| and a number). This also allowed me to put that number into the logit\\_bias.\n\nIn the examples below, I parsed the output into a JSON array, but the actual output is separted by |501|, |502|, etc.\n\n&amp;#x200B;\n\n50-75% of the time it does work, as in the following example: [https://gist.github.com/ReallyNotARussianSpy/a0be73615ce200f2d62d1d711b98930d](https://gist.github.com/ReallyNotARussianSpy/a0be73615ce200f2d62d1d711b98930d)   \nExcept it did remove  from \u201cGuide\u201d when it should not have   \n   \nIt sometimes does not return the number of lines that I want: [https://gist.github.com/ReallyNotARussianSpy/0faa687ab6fdbaf1180c29323af3ba3a](https://gist.github.com/ReallyNotARussianSpy/0faa687ab6fdbaf1180c29323af3ba3a)   \n   \nIt sometimes moves words between lines. Example: [https://gist.github.com/ReallyNotARussianSpy/94617683d4ba658b71a131ccbabddb68](https://gist.github.com/ReallyNotARussianSpy/94617683d4ba658b71a131ccbabddb68)\n\n&amp;#x200B;\n\nI would appreciate any help. Thank you!","link":"https://www.reddit.com/r/PromptDesign/comments/11oapx0/prompt_for_preserving_newline_and_hyphen/","created":"2023-03-11","tags":["promptdesign","prompteng","reddit"],"meta":{"num_comments":0},"text":"Prompt for preserving newline and hyphen characters in text to correct Hello!\n\nI am trying to come up with a prompt that will preserve newlines and hyphens at line ends. I have a OCR scanned page of a book, and I want to pass the prompt the lines from the page. With my current prompt it sometimes does this correctly, sometimes it merges all of the text together into one paragraph, and sometimes it moves words between lines.\n\nI'm wanting the corrected text to be returned with the text on their proper lines so that I can be able to compare the original line to the corrected line with an image of the line of text from the scanned book. I tried using \\\\n as a line separator but I had more success using a custom line separator (| and a number). This also allowed me to put that number into the logit\\_bias.\n\nIn the examples below, I parsed the output into a JSON array, but the actual output is separted by |501|, |502|, etc.\n\n&amp;#x200B;\n\n50-75% of the time it does work, as in the following example: [https://gist.github.com/ReallyNotARussianSpy/a0be73615ce200f2d62d1d711b98930d](https://gist.github.com/ReallyNotARussianSpy/a0be73615ce200f2d62d1d711b98930d)   \nExcept it did remove  from \u201cGuide\u201d when it should not have   \n   \nIt sometimes does not return the number of lines that I want: [https://gist.github.com/ReallyNotARussianSpy/0faa687ab6fdbaf1180c29323af3ba3a](https://gist.github.com/ReallyNotARussianSpy/0faa687ab6fdbaf1180c29323af3ba3a)   \n   \nIt sometimes moves words between lines. Example: [https://gist.github.com/ReallyNotARussianSpy/94617683d4ba658b71a131ccbabddb68](https://gist.github.com/ReallyNotARussianSpy/94617683d4ba658b71a131ccbabddb68)\n\n&amp;#x200B;\n\nI would appreciate any help. Thank you!","classes":{"dataset":0.505081594}}
{"title":"Made a tool to help to improve your prompts","description":"PromptPerfect is a cutting-edge prompt optimizer designed for large language models (LLMs), large models (LMs), and LMOps. The tool optimizes your prompts for ChatGPT, GPT-3.5, DALLE, and StableDiffusion models.   \n\n\nI would love to hear your feedback and thoughts on it. Thank you in advance.   \nLink to the example: [https://promptperfect.jina.ai/share?thread=pmTPARwr3r5zPOTnAKhT](https://promptperfect.jina.ai/share?thread=pmTPARwr3r5zPOTnAKhT)\n\n[An example used for GPT 3 ](https://preview.redd.it/owk8c9k6tqma1.png?width=622&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b89adb7575c518e135e0448630e4b5b0d8666fc9)","link":"https://www.reddit.com/r/PromptDesign/comments/11mx2ie/made_a_tool_to_help_to_improve_your_prompts/","created":"2023-03-09","tags":["promptdesign","prompteng","reddit"],"meta":{"num_comments":11},"text":"Made a tool to help to improve your prompts PromptPerfect is a cutting-edge prompt optimizer designed for large language models (LLMs), large models (LMs), and LMOps. The tool optimizes your prompts for ChatGPT, GPT-3.5, DALLE, and StableDiffusion models.   \n\n\nI would love to hear your feedback and thoughts on it. Thank you in advance.   \nLink to the example: [https://promptperfect.jina.ai/share?thread=pmTPARwr3r5zPOTnAKhT](https://promptperfect.jina.ai/share?thread=pmTPARwr3r5zPOTnAKhT)\n\n[An example used for GPT 3 ](https://preview.redd.it/owk8c9k6tqma1.png?width=622&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b89adb7575c518e135e0448630e4b5b0d8666fc9)","classes":{"dataset":0.3367263675}}
{"title":"Wrotescan: Prompt Library and Prompt Database","description":"hi all! I created a free library of prompts at [http://www.wrotescan.com/Prompt\\_Library](http://www.wrotescan.com/Prompt_Library).  It also has a feature where you can submit you own prompt when running the demos to the library and it will show up in the \"Community\" section of history. \n\nas a note, API keys and documents are not persisted on [wrotescan.com](https://wrotescan.com). please create then delete any temp keys used for the site.","link":"https://www.reddit.com/r/PromptDesign/comments/11mm4qu/wrotescan_prompt_library_and_prompt_database/","created":"2023-03-09","tags":["promptdesign","prompteng","reddit"],"meta":{"num_comments":2},"text":"Wrotescan: Prompt Library and Prompt Database hi all! I created a free library of prompts at [http://www.wrotescan.com/Prompt\\_Library](http://www.wrotescan.com/Prompt_Library).  It also has a feature where you can submit you own prompt when running the demos to the library and it will show up in the \"Community\" section of history. \n\nas a note, API keys and documents are not persisted on [wrotescan.com](https://wrotescan.com). please create then delete any temp keys used for the site.","classes":{"dataset":0.0000137554}}
{"title":"Saturday Daily Thread: Resource Request and Sharing! Daily Thread","description":"Found a neat resource related to Python over the past week? Looking for a resource to explain a certain topic?\n\nUse this thread to chat about and share Python resources!","link":"https://www.reddit.com/r/Python/comments/11o54ib/saturday_daily_thread_resource_request_and/","created":"2023-03-11","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Saturday Daily Thread: Resource Request and Sharing! Daily Thread Found a neat resource related to Python over the past week? Looking for a resource to explain a certain topic?\n\nUse this thread to chat about and share Python resources!","classes":{"dataset":0.2727504075}}
{"title":"Cake Day - 1st Job","description":"Just wanted to celebrate my Reddit cake day by announcing that I may be getting my first programming job as I got an email today to be moved forward!!! That\u2019s all. Hope the best for you all.","link":"https://www.reddit.com/r/Python/comments/11o91ik/cake_day_1st_job/","created":"2023-03-11","tags":["python","reddit"],"meta":{"num_comments":10},"text":"Cake Day - 1st Job Just wanted to celebrate my Reddit cake day by announcing that I may be getting my first programming job as I got an email today to be moved forward!!! That\u2019s all. Hope the best for you all.","classes":{"dataset":0.1330454201}}
{"title":"Other cool python feature recommendations","description":"I have recently learned about Python turtle and thought it was really cool. I am new to python and I am looking for other beginner friendly yet powerful modules for visuals/ drawing/ animation/ graphics that I can exploit in python. Any recommendations of where I should look next would be appreciated.","link":"https://www.reddit.com/r/Python/comments/11odpcf/other_cool_python_feature_recommendations/","created":"2023-03-11","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Other cool python feature recommendations I have recently learned about Python turtle and thought it was really cool. I am new to python and I am looking for other beginner friendly yet powerful modules for visuals/ drawing/ animation/ graphics that I can exploit in python. Any recommendations of where I should look next would be appreciated.","classes":{"dataset":0.3320553601}}
{"title":"I Automated A Youtube Channel Using Python Without AI","description":"Source Code and Explanation\n\n[https://github.com/TarunTomar122/Automating-a-Youtube-Channel-without-using-AI](https://github.com/TarunTomar122/Automating-a-Youtube-Channel-without-using-AI)","link":"https://www.reddit.com/r/Python/comments/11oeuk4/i_automated_a_youtube_channel_using_python/","created":"2023-03-11","tags":["python","reddit"],"meta":{"num_comments":1},"text":"I Automated A Youtube Channel Using Python Without AI Source Code and Explanation\n\n[https://github.com/TarunTomar122/Automating-a-Youtube-Channel-without-using-AI](https://github.com/TarunTomar122/Automating-a-Youtube-Channel-without-using-AI)","classes":{"dataset":0.4646918476}}
{"title":"Is there some hidden genius in the handle-exception package that I'm missing?","description":"I ran across [the handle-exception package](https://github.com/dillibk777/handle_exception) whose supposed benefit is:\n\n&gt; you can handle exceptions in a centralized way, instead of having to write try-except blocks in multiple places.\n\nBut you can *already* handle exceptions in a centralized way, correct?","link":"https://www.reddit.com/r/Python/comments/11niekp/is_there_some_hidden_genius_in_the/","created":"2023-03-10","tags":["python","reddit"],"meta":{"num_comments":18},"text":"Is there some hidden genius in the handle-exception package that I'm missing? I ran across [the handle-exception package](https://github.com/dillibk777/handle_exception) whose supposed benefit is:\n\n&gt; you can handle exceptions in a centralized way, instead of having to write try-except blocks in multiple places.\n\nBut you can *already* handle exceptions in a centralized way, correct?","classes":{"dataset":0.5057662129}}
{"title":"pip install openfrom","description":"hi guys, just wanted to share a python script that opens multipe endpoints from a given URL.\n\n[https://github.com/chozeur/openfrom](https://github.com/chozeur/openfrom)","link":"https://www.reddit.com/r/Python/comments/11o5rvs/pip_install_openfrom/","created":"2023-03-11","tags":["python","reddit"],"meta":{"num_comments":2},"text":"pip install openfrom hi guys, just wanted to share a python script that opens multipe endpoints from a given URL.\n\n[https://github.com/chozeur/openfrom](https://github.com/chozeur/openfrom)","classes":{"dataset":0.6456387043}}
{"title":"Python remote debugging on windows machines is now made easy!","description":"Hi guys, I couldn't find latterly a single solution for pycharm to remote debug my python code on other windows machines, and I wanted to do that to do my AI training stuff on my friend's pc because mine is no strong enough, I ended up making my own python library that exactly does that!  \n\n\nWith only two lines of code, you can debug an python script on a windows machine easily, and a copy of all the stdout, stderr and stdin calls will be forwarded to you and you will feel like you are working on your own machine.  \n\n\nI wanted to share it here if anyone needs such capability, I also uploaded it to PyPl so pip will be able to install it, here's the project's github page: [https://github.com/AhmedAhmedEG/PyWinRD](https://github.com/AhmedAhmedEG/PyWinRD)","link":"https://www.reddit.com/r/Python/comments/11nod6t/python_remote_debugging_on_windows_machines_is/","created":"2023-03-10","tags":["python","reddit"],"meta":{"num_comments":1},"text":"Python remote debugging on windows machines is now made easy! Hi guys, I couldn't find latterly a single solution for pycharm to remote debug my python code on other windows machines, and I wanted to do that to do my AI training stuff on my friend's pc because mine is no strong enough, I ended up making my own python library that exactly does that!  \n\n\nWith only two lines of code, you can debug an python script on a windows machine easily, and a copy of all the stdout, stderr and stdin calls will be forwarded to you and you will feel like you are working on your own machine.  \n\n\nI wanted to share it here if anyone needs such capability, I also uploaded it to PyPl so pip will be able to install it, here's the project's github page: [https://github.com/AhmedAhmedEG/PyWinRD](https://github.com/AhmedAhmedEG/PyWinRD)","classes":{"dataset":0.5009223819}}
{"title":"I created Flask-Squeeze, it minifies and compresses responses so that your data transfers are as small as possible!","description":"Hi guys! I just wanted to share the Flask extension [Flask-Squeeze](https://github.com/mkrd/Flask-Squeeze) with you. It will minify javascript and css, and compress responses with brotli, deflate, or gzip depending on the request, with almost zero configuration.\n\nI know there are other extensions aswell, but as far as I know, none of them have a complete feature set of minification AND compression.\n\nLet me know what you think, if there are more things that could be added!","link":"https://www.reddit.com/r/Python/comments/11ms54x/i_created_flasksqueeze_it_minifies_and_compresses/","created":"2023-03-09","tags":["python","reddit"],"meta":{"num_comments":6},"text":"I created Flask-Squeeze, it minifies and compresses responses so that your data transfers are as small as possible! Hi guys! I just wanted to share the Flask extension [Flask-Squeeze](https://github.com/mkrd/Flask-Squeeze) with you. It will minify javascript and css, and compress responses with brotli, deflate, or gzip depending on the request, with almost zero configuration.\n\nI know there are other extensions aswell, but as far as I know, none of them have a complete feature set of minification AND compression.\n\nLet me know what you think, if there are more things that could be added!","classes":{"dataset":0.3075999916}}
{"title":"qStore - Youtube as file storage","description":"Okay, first and foremost, I want to say that I got inspired by GitHub: DvorakDwarf's [Infinite-Storage-Glitch](https://github.com/DvorakDwarf/Infinite-Storage-Glitch). So I decided to make my own proof of concept version in python3 instead of rust. I also wanted to use steganography but youtube's compression killed any and all hope I had. I have tried LSB, RGB, DCT, and Spacial Domain steganography and ALL work normally on their own...but all have failed when I upload the video to youtube and then download it.\n\nSo I decided to be a little clever and use QR codes. I modify one of many frames in the video with a QR code, and then re make the video and then it's ready to upload. One may wonder, \"well if it's in the QR code then the data can be easily obtained.\" Yes and No. Yes in terms of it's indeed a normal QR code and works how you'd expect it to work, and no in terms of the file data is encrypted using GCMlib (AES-GCM. KDF Argon2id) before being turned into the QR code. One can use any encryption method they want but I use GCMlib. (use at your own risk obviously).\n\n&amp;#x200B;\n\n[qStore](https://github.com/therealOri/qStore) also has its own database to keep track of what videos are what and the keys used to encrypt the file that is in the QR code. This database can also be locked and unlocked. (Like bitwarden). Just give it a key that was generated and then it's up to you on how you store it and keep it safe. (You can also use your own way of encrypting files if you wish, my methods are use at your own risk obviously.) You can add, remove, and view entries/records as well.\n\nThere's nothing really more to say about it as this project is still being worked on and I still really hope that eventually I can use actual steganography to embed a file into the videos. But for now, just QR codes.\n\nIf you or anyone you know would like to help out or even try it out/use my project then the link is below. &lt;3\n\nLink to github repo: [https://github.com/therealOri/qStore](https://github.com/therealOri/qStore)  \n\n\n  \n\n\n[qStore main menu](https://preview.redd.it/gqi2fnz01rma1.png?width=851&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=aa637f2bbf49ea9a040cd6ea0be48a808ed6028d)","link":"https://www.reddit.com/r/Python/comments/11my1tz/qstore_youtube_as_file_storage/","created":"2023-03-09","tags":["python","reddit"],"meta":{"num_comments":3},"text":"qStore - Youtube as file storage Okay, first and foremost, I want to say that I got inspired by GitHub: DvorakDwarf's [Infinite-Storage-Glitch](https://github.com/DvorakDwarf/Infinite-Storage-Glitch). So I decided to make my own proof of concept version in python3 instead of rust. I also wanted to use steganography but youtube's compression killed any and all hope I had. I have tried LSB, RGB, DCT, and Spacial Domain steganography and ALL work normally on their own...but all have failed when I upload the video to youtube and then download it.\n\nSo I decided to be a little clever and use QR codes. I modify one of many frames in the video with a QR code, and then re make the video and then it's ready to upload. One may wonder, \"well if it's in the QR code then the data can be easily obtained.\" Yes and No. Yes in terms of it's indeed a normal QR code and works how you'd expect it to work, and no in terms of the file data is encrypted using GCMlib (AES-GCM. KDF Argon2id) before being turned into the QR code. One can use any encryption method they want but I use GCMlib. (use at your own risk obviously).\n\n&amp;#x200B;\n\n[qStore](https://github.com/therealOri/qStore) also has its own database to keep track of what videos are what and the keys used to encrypt the file that is in the QR code. This database can also be locked and unlocked. (Like bitwarden). Just give it a key that was generated and then it's up to you on how you store it and keep it safe. (You can also use your own way of encrypting files if you wish, my methods are use at your own risk obviously.) You can add, remove, and view entries/records as well.\n\nThere's nothing really more to say about it as this project is still being worked on and I still really hope that eventually I can use actual steganography to embed a file into the videos. But for now, just QR codes.\n\nIf you or anyone you know would like to help out or even try it out/use my project then the link is below. &lt;3\n\nLink to github repo: [https://github.com/therealOri/qStore](https://github.com/therealOri/qStore)  \n\n\n  \n\n\n[qStore main menu](https://preview.redd.it/gqi2fnz01rma1.png?width=851&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=aa637f2bbf49ea9a040cd6ea0be48a808ed6028d)","classes":{"dataset":0.4801109433}}
{"title":"Desktop Computer or some other way to train neural networks?","description":"Should I buy a desktop with a GPU like Nvidia RTX 3080 or perhaps use online VM/Cloud based machines for deep learning. What would be optimal?  Any and all feedback is welcome \n\nI am new to Deep Learning but want to become an expert in areas of Deep Learning especially Computer Vision.","link":"https://www.reddit.com/r/deeplearning/comments/11o8xjx/desktop_computer_or_some_other_way_to_train/","created":"2023-03-11","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":12},"text":"Desktop Computer or some other way to train neural networks? Should I buy a desktop with a GPU like Nvidia RTX 3080 or perhaps use online VM/Cloud based machines for deep learning. What would be optimal?  Any and all feedback is welcome \n\nI am new to Deep Learning but want to become an expert in areas of Deep Learning especially Computer Vision.","classes":{"dataset":0.2456288636}}
{"title":"One Shot Learning Task","description":"From my understanding, a one shot learning task requires us that given a query example, we must classify it correctly out of N different classes (typically N = 5 way or 20 way). The goal however is that we are provided with only one example per class.\n\nSuppose we take an MNIST type dataset. I can map every pixel that makes up the digit onto a cartesian plane where the xy coordinates values is every \"pixel\". Using this cartesian representation, can I just find the simple distance metric between the pairs? For example on a 20 way task, My question is: At each iteration, we are provided with some query example, along with 20 other candidates...if we compute some sort of simple similarity score (that doesnt require neural nets) like (intersection over union) between each candidate to query pair, does this still count as a one shot learning task?\n\nSo leaving aside a neural network approach, if we were to just use a simple distance metric on the coordinates to compute the pairwise similarity between the query and every \"candidate\", does this count as one shot learning?","link":"https://www.reddit.com/r/deeplearning/comments/11o9ilf/one_shot_learning_task/","created":"2023-03-11","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"One Shot Learning Task From my understanding, a one shot learning task requires us that given a query example, we must classify it correctly out of N different classes (typically N = 5 way or 20 way). The goal however is that we are provided with only one example per class.\n\nSuppose we take an MNIST type dataset. I can map every pixel that makes up the digit onto a cartesian plane where the xy coordinates values is every \"pixel\". Using this cartesian representation, can I just find the simple distance metric between the pairs? For example on a 20 way task, My question is: At each iteration, we are provided with some query example, along with 20 other candidates...if we compute some sort of simple similarity score (that doesnt require neural nets) like (intersection over union) between each candidate to query pair, does this still count as a one shot learning task?\n\nSo leaving aside a neural network approach, if we were to just use a simple distance metric on the coordinates to compute the pairwise similarity between the query and every \"candidate\", does this count as one shot learning?","classes":{"dataset":0.1568749547}}
{"title":"[POC] ChatGPT Audio Bot (like Google Assistant and Alexa) - Opensource","description":"Hey guys, just wanna share this bot that I quickly built using ChatGPT API.\n\nGitHub page: [https://github.com/LanyTek/ChatGPT\\_Audio\\_Bot](https://github.com/LanyTek/ChatGPT_Audio_Bot)\n\nThis service allows you to keep talking to the bot using your voice like you often do with Google Assistant or Alexa. It can be used in a lot of scenarios like teaching, gossiping, or quickly retrieving information without the need of typing. \n\nI have a quick video demo here if you wanna check [https://www.youtube.com/watch?v=e9n0BJfMyKw](https://www.youtube.com/watch?v=e9n0BJfMyKw)\n\nIt's open source so feel free to use it for anything you like :)","link":"https://www.reddit.com/r/deeplearning/comments/11nfrhw/poc_chatgpt_audio_bot_like_google_assistant_and/","created":"2023-03-10","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":2},"text":"[POC] ChatGPT Audio Bot (like Google Assistant and Alexa) - Opensource Hey guys, just wanna share this bot that I quickly built using ChatGPT API.\n\nGitHub page: [https://github.com/LanyTek/ChatGPT\\_Audio\\_Bot](https://github.com/LanyTek/ChatGPT_Audio_Bot)\n\nThis service allows you to keep talking to the bot using your voice like you often do with Google Assistant or Alexa. It can be used in a lot of scenarios like teaching, gossiping, or quickly retrieving information without the need of typing. \n\nI have a quick video demo here if you wanna check [https://www.youtube.com/watch?v=e9n0BJfMyKw](https://www.youtube.com/watch?v=e9n0BJfMyKw)\n\nIt's open source so feel free to use it for anything you like :)","classes":{"dataset":0.3665848076}}
{"title":"Should the tf2onnx.convert command be avoided to convert tensorflow models to onnx?","description":"Should the tf2onnx.convert command be avoided to convert tensorflow models to onnx?\n\n[https://medium.com/nerd-for-tech/how-to-convert-tensorflow2-model-to-onnx-using-tf2onnx-when-there-is-custom-ops-6e703376ef20](https://medium.com/nerd-for-tech/how-to-convert-tensorflow2-model-to-onnx-using-tf2onnx-when-there-is-custom-ops-6e703376ef20)","link":"https://www.reddit.com/r/deeplearning/comments/11nvtss/should_the_tf2onnxconvert_command_be_avoided_to/","created":"2023-03-10","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"Should the tf2onnx.convert command be avoided to convert tensorflow models to onnx? Should the tf2onnx.convert command be avoided to convert tensorflow models to onnx?\n\n[https://medium.com/nerd-for-tech/how-to-convert-tensorflow2-model-to-onnx-using-tf2onnx-when-there-is-custom-ops-6e703376ef20](https://medium.com/nerd-for-tech/how-to-convert-tensorflow2-model-to-onnx-using-tf2onnx-when-there-is-custom-ops-6e703376ef20)","classes":{"dataset":0.3997966349}}
{"title":"Looking for feedback on our new AI-assisted drawing app!","description":"Hi everyone,\n\nWe just launched our new app that uses advanced AI algorithms to enhance your drawings and take your art to the next level. We're looking for feedback from the community on the app's functionality and user experience, and would love for you to try it out.\n\nExamples: https://www.youtube.com/shorts/GIP9ESIXz8M \n\nWith our app, you can simply provide your drawing input and watch as our AI model enhances it with stunning results. We believe it's the perfect tool for artists, designers, and anyone who wants to explore their creativity in new ways.\n\nWe would really appreciate it if you could take the time to download and try our app, and provide us with any feedback or suggestions for improvement. We're committed to creating the best experience for our users, and your feedback will help us get there.\n\nYou can download our app from https://play.google.com/store/apps/details?id=com.ai\\_smart\\_draw . We look forward to hearing your thoughts!\n\nThank you","link":"https://www.reddit.com/r/deeplearning/comments/11nthh2/looking_for_feedback_on_our_new_aiassisted/","created":"2023-03-10","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"Looking for feedback on our new AI-assisted drawing app! Hi everyone,\n\nWe just launched our new app that uses advanced AI algorithms to enhance your drawings and take your art to the next level. We're looking for feedback from the community on the app's functionality and user experience, and would love for you to try it out.\n\nExamples: https://www.youtube.com/shorts/GIP9ESIXz8M \n\nWith our app, you can simply provide your drawing input and watch as our AI model enhances it with stunning results. We believe it's the perfect tool for artists, designers, and anyone who wants to explore their creativity in new ways.\n\nWe would really appreciate it if you could take the time to download and try our app, and provide us with any feedback or suggestions for improvement. We're committed to creating the best experience for our users, and your feedback will help us get there.\n\nYou can download our app from https://play.google.com/store/apps/details?id=com.ai\\_smart\\_draw . We look forward to hearing your thoughts!\n\nThank you","classes":{"dataset":0.2818870246}}
{"title":"Approximately how long will it take to finish Transfer Learning?","description":"Hi there,\n\nI  have a multi-task transformer model that I would like to apply transfer  learning to. It is a multi-task model that takes offers \\~5,000 multi  task outputs. I am planning to add one linear layer to the end and  having it offer 50 multi-task outputs after transfer learning. If it  took \\~3 days to train the first model, and I have 800x additional training data for transfer learning, is there an easy way to tell how  long this should take? I suppose I am specifically wondering whether I  should expect it to take 838x as long if I use the same batch sizes  while training, or if decreasing the amount of tasks from \\~5000 to 50  helps decrease training time at all.\n\n&amp;#x200B;\n\nThanks in advance for helping a beginner!","link":"https://www.reddit.com/r/deeplearning/comments/11ne0nm/approximately_how_long_will_it_take_to_finish/","created":"2023-03-10","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"Approximately how long will it take to finish Transfer Learning? Hi there,\n\nI  have a multi-task transformer model that I would like to apply transfer  learning to. It is a multi-task model that takes offers \\~5,000 multi  task outputs. I am planning to add one linear layer to the end and  having it offer 50 multi-task outputs after transfer learning. If it  took \\~3 days to train the first model, and I have 800x additional training data for transfer learning, is there an easy way to tell how  long this should take? I suppose I am specifically wondering whether I  should expect it to take 838x as long if I use the same batch sizes  while training, or if decreasing the amount of tasks from \\~5000 to 50  helps decrease training time at all.\n\n&amp;#x200B;\n\nThanks in advance for helping a beginner!","classes":{"dataset":0.4655327499}}
{"title":"[Tutorial] Image Classification using TensorFlow on Custom Dataset","description":"Image Classification using TensorFlow on Custom Dataset\n\n[https://debuggercafe.com/image-classification-using-tensorflow-on-custom-dataset/](https://debuggercafe.com/image-classification-using-tensorflow-on-custom-dataset/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/g4b652622tma1.png?width=1000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a0053f6a050a64da6cd7250c5126b9e556f3dc28","link":"https://www.reddit.com/r/deeplearning/comments/11n8xhq/tutorial_image_classification_using_tensorflow_on/","created":"2023-03-10","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"[Tutorial] Image Classification using TensorFlow on Custom Dataset Image Classification using TensorFlow on Custom Dataset\n\n[https://debuggercafe.com/image-classification-using-tensorflow-on-custom-dataset/](https://debuggercafe.com/image-classification-using-tensorflow-on-custom-dataset/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/g4b652622tma1.png?width=1000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=a0053f6a050a64da6cd7250c5126b9e556f3dc28","classes":{"dataset":0.3680774271}}
{"title":"Image denoising using deep learning survey","description":"Hi everyone!\n\nI am a final year undergraduate following a BSc (Hons) Computer Science degree offered by the Informatics Institute of Technology, affiliated with the University of Westminster.\u00a0\n\nThis survey will be used to collect information for my final-year research project. The project's main goal is to develop **an image-denoising system that can remove noise from noisy images**.\n\n**\\*This survey is anonymous and confidential, and no personal information will be collected. By filling out the survey, you agree to let the data provided via answers be used for academic purposes.\\***\n\nI would appreciate it if you could complete the survey.\n\nI want to thank you in advance for your participation. If you have any questions or suggestions, please don't hesitate to contact me.  \n\n\n[https://forms.gle/TDbcEqUfYi8XL3hu8](https://forms.gle/TDbcEqUfYi8XL3hu8)","link":"https://www.reddit.com/r/deeplearning/comments/11mrz59/image_denoising_using_deep_learning_survey/","created":"2023-03-09","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":1},"text":"Image denoising using deep learning survey Hi everyone!\n\nI am a final year undergraduate following a BSc (Hons) Computer Science degree offered by the Informatics Institute of Technology, affiliated with the University of Westminster.\u00a0\n\nThis survey will be used to collect information for my final-year research project. The project's main goal is to develop **an image-denoising system that can remove noise from noisy images**.\n\n**\\*This survey is anonymous and confidential, and no personal information will be collected. By filling out the survey, you agree to let the data provided via answers be used for academic purposes.\\***\n\nI would appreciate it if you could complete the survey.\n\nI want to thank you in advance for your participation. If you have any questions or suggestions, please don't hesitate to contact me.  \n\n\n[https://forms.gle/TDbcEqUfYi8XL3hu8](https://forms.gle/TDbcEqUfYi8XL3hu8)","classes":{"dataset":0.3528770506}}
{"title":"PyTorch Faster RCNN Library - Support for transformer detection models.","description":"[https://github.com/sovit-123/fasterrcnn-pytorch-training-pipeline](https://github.com/sovit-123/fasterrcnn-pytorch-training-pipeline)\n\nNow, the library supports Faster RCNN ViTDet and Faster RCNN MobileViT\\_XXS also.\n\nWould love to get feedback/contributions/suggestions.","link":"https://www.reddit.com/r/deeplearning/comments/11mhkpd/pytorch_faster_rcnn_library_support_for/","created":"2023-03-09","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"PyTorch Faster RCNN Library - Support for transformer detection models. [https://github.com/sovit-123/fasterrcnn-pytorch-training-pipeline](https://github.com/sovit-123/fasterrcnn-pytorch-training-pipeline)\n\nNow, the library supports Faster RCNN ViTDet and Faster RCNN MobileViT\\_XXS also.\n\nWould love to get feedback/contributions/suggestions.","classes":{"dataset":0.3760005236}}
{"title":"[P] RWKV 14B is a strong chatbot despite only trained on Pile (16G VRAM for 14B ctx4096 INT8, more optimizations incoming)","description":"The latest CharRWKV v2 has a new chat prompt (works for any topic), and here are some raw user chats with RWKV-4-Pile-14B-20230228-ctx4096-test663 model (topp=0.85, temp=1.0, presence penalty 0.2, frequency penalty 0.5). You are welcome to try ChatRWKV v2:  [https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nAnd please keep in mind that RWKV is 100% RNN :) Pile v1 date cutoff is year 2020.\n\n[Chat #1](https://preview.redd.it/ripvptomexma1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=29ed1cd499dc4d693dee32ad7550a7910402d033)\n\n[Chat #2](https://preview.redd.it/8t75njnnexma1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d20186f2e423d321817b79e6e559dc74a42bf0b8)\n\nThese are surprisingly good because RWKV is only trained on the Pile (and 100% RNN). No finetuning. No instruct tuning. No RLHF. You are welcome to try it.\n\n1. Update ChatRWKV v2 \\[and rwkv pip package\\] to latest version.\n2. Use  [https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth](https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth)\n3. Run v2/chat.py and enjoy.\n\nChatRWKV v2 supports INT8 now (with my crappy slow quantization, **works for windows, supports any GPU**, 16G VRAM for 14B if you offload final layer to CPU). And you can offload more layers to CPU to run it with 3G VRAM though that will be very slow :) More optimizations are coming.\n\nOr you can try the 7B model (less coherency) and 3B model (not very coherent, but still fun).","link":"https://www.reddit.com/r/MachineLearning/comments/11nre6t/p_rwkv_14b_is_a_strong_chatbot_despite_only/","created":"2023-03-10","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":22},"text":"[P] RWKV 14B is a strong chatbot despite only trained on Pile (16G VRAM for 14B ctx4096 INT8, more optimizations incoming) The latest CharRWKV v2 has a new chat prompt (works for any topic), and here are some raw user chats with RWKV-4-Pile-14B-20230228-ctx4096-test663 model (topp=0.85, temp=1.0, presence penalty 0.2, frequency penalty 0.5). You are welcome to try ChatRWKV v2:  [https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nAnd please keep in mind that RWKV is 100% RNN :) Pile v1 date cutoff is year 2020.\n\n[Chat #1](https://preview.redd.it/ripvptomexma1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=29ed1cd499dc4d693dee32ad7550a7910402d033)\n\n[Chat #2](https://preview.redd.it/8t75njnnexma1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d20186f2e423d321817b79e6e559dc74a42bf0b8)\n\nThese are surprisingly good because RWKV is only trained on the Pile (and 100% RNN). No finetuning. No instruct tuning. No RLHF. You are welcome to try it.\n\n1. Update ChatRWKV v2 \\[and rwkv pip package\\] to latest version.\n2. Use  [https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth](https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth)\n3. Run v2/chat.py and enjoy.\n\nChatRWKV v2 supports INT8 now (with my crappy slow quantization, **works for windows, supports any GPU**, 16G VRAM for 14B if you offload final layer to CPU). And you can offload more layers to CPU to run it with 3G VRAM though that will be very slow :) More optimizations are coming.\n\nOr you can try the 7B model (less coherency) and 3B model (not very coherent, but still fun).","classes":{"dataset":0.3642827272}}
{"title":"[D] Is ML a big boys game now?","description":"As much as I enjoy ML as a whole, I am a bit skeptical of the future for individuals. With OpenAI trying to monopolize the market along with Microsoft, which part remains for the small time researchers/developers?\n\nIt seems everything now is just a ChatGPT wrapper, and with GPT-4 around the corner I assume itll be even more prominent.\n\nWhat are your thoughts?","link":"https://www.reddit.com/r/MachineLearning/comments/11njpb9/d_is_ml_a_big_boys_game_now/","created":"2023-03-10","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":125},"text":"[D] Is ML a big boys game now? As much as I enjoy ML as a whole, I am a bit skeptical of the future for individuals. With OpenAI trying to monopolize the market along with Microsoft, which part remains for the small time researchers/developers?\n\nIt seems everything now is just a ChatGPT wrapper, and with GPT-4 around the corner I assume itll be even more prominent.\n\nWhat are your thoughts?","classes":{"dataset":0.1424123943}}
{"title":"[D] What's the Time and Space Complexity of Transformer Models Inference?","description":"What's the Big (O) at inference time for transformer models? Is it different for BERT? RoBERTa? T5? DeBERTa?","link":"https://www.reddit.com/r/MachineLearning/comments/11nzinb/d_whats_the_time_and_space_complexity_of/","created":"2023-03-10","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":6},"text":"[D] What's the Time and Space Complexity of Transformer Models Inference? What's the Big (O) at inference time for transformer models? Is it different for BERT? RoBERTa? T5? DeBERTa?","classes":{"dataset":0.530036211}}
{"title":"[P] Implementing Vision Transformer (ViT) from Scratch using PyTorch","description":"I recently delved into the world of transformers and their application to vision tasks.\n\nAs part of my learning process, I implemented the Vision Transformer (ViT) from scratch using PyTorch. I am sharing my implementation and a step-by-step guide to implementing the model in this post.\n\nI hope you find it helpful.\n\nGithub: [https://github.com/tintn/vision-transformer-from-scratch](https://github.com/tintn/vision-transformer-from-scratch)\n\nPost: [https://medium.com/towards-data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0](https://medium.com/towards-data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0)","link":"https://www.reddit.com/r/MachineLearning/comments/11nj58o/p_implementing_vision_transformer_vit_from/","created":"2023-03-10","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":2},"text":"[P] Implementing Vision Transformer (ViT) from Scratch using PyTorch I recently delved into the world of transformers and their application to vision tasks.\n\nAs part of my learning process, I implemented the Vision Transformer (ViT) from scratch using PyTorch. I am sharing my implementation and a step-by-step guide to implementing the model in this post.\n\nI hope you find it helpful.\n\nGithub: [https://github.com/tintn/vision-transformer-from-scratch](https://github.com/tintn/vision-transformer-from-scratch)\n\nPost: [https://medium.com/towards-data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0](https://medium.com/towards-data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0)","classes":{"dataset":0.1297560334}}
{"title":"[D] Version 2.1 of the Open Deep Learning Toolkit for Robotics is already available!","description":"The latest version of the  Open Deep Learning Toolkit for Robotics, **Version 2.1 is already available !**\n\n This new version includes the following updates:\n\n**New Features:**\n\n* Added Efficient LiDAR Panoptic Segmentation\n* Added Nanodet 2D Object Detection tool\u00a0\n* Added C API implementations of NanoDet 2D Object Detection tool\n* Added C API implementations of forward pass of DETR 2D Object Detection tool\n* Added C API implementations of forward pass of DeepSORT 2D Object Tracking tool\u00a0\n* Added C API implementations of forward pass of Lightweight OpenPose, Pose Estimator tool\n* Added C API implementations of forward pass of X3D 2D Activity Recognition tool\u00a0\n* Added C API implementations of forward pass of Progressive Spatiotemporal GCN Skeleton-based Action Recognition tool\n* Added Binary High Resolution Analysis tool\n* Added Multi-Object-Search tool\u00a0\n\n***Enhancements***\n\n* Added support in C API for detection target structure and vector of detections\u00a0\n* Added support in C API for tensor structure and vector of tensors\n* Added support in C API for json parser\u00a0 \n\n You can download the toolkit here:  \n\\- GitHub: [https://github.com/opendr-eu/opendr](https://github.com/opendr-eu/opendr)  \n\\- pip: [https://pypi.org/project/opendr-toolkit/](https://pypi.org/project/opendr-toolkit/)  \n\\- Docker Hub: [https://hub.docker.com/r/opendr/opendr-toolkit/tags](https://hub.docker.com/r/opendr/opendr-toolkit/tags) \n\nLooking forward for your comments and suggestions!","link":"https://www.reddit.com/r/MachineLearning/comments/11nrako/d_version_21_of_the_open_deep_learning_toolkit/","created":"2023-03-10","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":1},"text":"[D] Version 2.1 of the Open Deep Learning Toolkit for Robotics is already available! The latest version of the  Open Deep Learning Toolkit for Robotics, **Version 2.1 is already available !**\n\n This new version includes the following updates:\n\n**New Features:**\n\n* Added Efficient LiDAR Panoptic Segmentation\n* Added Nanodet 2D Object Detection tool\u00a0\n* Added C API implementations of NanoDet 2D Object Detection tool\n* Added C API implementations of forward pass of DETR 2D Object Detection tool\n* Added C API implementations of forward pass of DeepSORT 2D Object Tracking tool\u00a0\n* Added C API implementations of forward pass of Lightweight OpenPose, Pose Estimator tool\n* Added C API implementations of forward pass of X3D 2D Activity Recognition tool\u00a0\n* Added C API implementations of forward pass of Progressive Spatiotemporal GCN Skeleton-based Action Recognition tool\n* Added Binary High Resolution Analysis tool\n* Added Multi-Object-Search tool\u00a0\n\n***Enhancements***\n\n* Added support in C API for detection target structure and vector of detections\u00a0\n* Added support in C API for tensor structure and vector of tensors\n* Added support in C API for json parser\u00a0 \n\n You can download the toolkit here:  \n\\- GitHub: [https://github.com/opendr-eu/opendr](https://github.com/opendr-eu/opendr)  \n\\- pip: [https://pypi.org/project/opendr-toolkit/](https://pypi.org/project/opendr-toolkit/)  \n\\- Docker Hub: [https://hub.docker.com/r/opendr/opendr-toolkit/tags](https://hub.docker.com/r/opendr/opendr-toolkit/tags) \n\nLooking forward for your comments and suggestions!","classes":{"dataset":0.4946193099}}
{"title":"[N] GPT-4 is coming next week \u2013 and it will be multimodal, says Microsoft Germany - heise online","description":"[https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html](https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html)\n\n&gt;**GPT-4 is coming next week**: at an approximately one-hour hybrid information event entitled \"**AI in Focus - Digital Kickoff\" on 9 March 2023**, four Microsoft Germany employees presented Large Language Models (LLM) like GPT series as a disruptive force for companies and their Azure-OpenAI offering in detail. The kickoff event took place in the German language, news outlet Heise was present. **Rather casually, Andreas Braun, CTO Microsoft Germany** and Lead Data &amp; AI STU, **mentioned** what he said was **the imminent release of GPT-4.** The fact that **Microsoft is fine-tuning multimodality with OpenAI should no longer have been a secret since the release of Kosmos-1 at the beginning of March.**\n\n[ Dr. Andreas Braun, CTO Microsoft Germany and Lead Data  &amp; AI STU at the Microsoft Digital Kickoff: \\\\\"KI im Fokus\\\\\" \\(AI in  Focus, Screenshot\\) \\(Bild:\u00a0Microsoft\\) ](https://preview.redd.it/rnst03avarma1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c398017ac69b7dda4c95f0d0ee28aa3a37893b90)","link":"https://www.reddit.com/r/MachineLearning/comments/11mzqxu/n_gpt4_is_coming_next_week_and_it_will_be/","created":"2023-03-09","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":75},"text":"[N] GPT-4 is coming next week \u2013 and it will be multimodal, says Microsoft Germany - heise online [https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html](https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html)\n\n&gt;**GPT-4 is coming next week**: at an approximately one-hour hybrid information event entitled \"**AI in Focus - Digital Kickoff\" on 9 March 2023**, four Microsoft Germany employees presented Large Language Models (LLM) like GPT series as a disruptive force for companies and their Azure-OpenAI offering in detail. The kickoff event took place in the German language, news outlet Heise was present. **Rather casually, Andreas Braun, CTO Microsoft Germany** and Lead Data &amp; AI STU, **mentioned** what he said was **the imminent release of GPT-4.** The fact that **Microsoft is fine-tuning multimodality with OpenAI should no longer have been a secret since the release of Kosmos-1 at the beginning of March.**\n\n[ Dr. Andreas Braun, CTO Microsoft Germany and Lead Data  &amp; AI STU at the Microsoft Digital Kickoff: \\\\\"KI im Fokus\\\\\" \\(AI in  Focus, Screenshot\\) \\(Bild:\u00a0Microsoft\\) ](https://preview.redd.it/rnst03avarma1.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=c398017ac69b7dda4c95f0d0ee28aa3a37893b90)","classes":{"dataset":0.0891588703}}
{"title":"[D] One Shot Learning Tasks","description":"From my understanding, a one shot learning task requires us that given a query example, we must classify it correctly out of N different classes (typically N = 5 way or 20 way). The goal however is that we are provided with only one example per class.\n\nSuppose we take an MNIST type dataset. I can map every pixel that makes up the digit onto a cartesian plane where the xy coordinates values is every \"pixel\". Using this cartesian representation, can I just find the simple distance metric between the pairs? For example on a 20 way task, My question is: At each iteration, we are provided with some query example, along with 20 other candidates...if we compute some sort of simple similarity score (that doesnt require neural nets) like (intersection over union) between each candidate to query pair, does this still count as a one shot learning task?\n\nSo leaving aside a neural network approach, if we were to just use a simple distance metric on the coordinates to compute the pairwise similarity between the query and every \"candidate\", does this count as one shot learning?","link":"https://www.reddit.com/r/MachineLearning/comments/11o8tgd/d_one_shot_learning_tasks/","created":"2023-03-11","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":1},"text":"[D] One Shot Learning Tasks From my understanding, a one shot learning task requires us that given a query example, we must classify it correctly out of N different classes (typically N = 5 way or 20 way). The goal however is that we are provided with only one example per class.\n\nSuppose we take an MNIST type dataset. I can map every pixel that makes up the digit onto a cartesian plane where the xy coordinates values is every \"pixel\". Using this cartesian representation, can I just find the simple distance metric between the pairs? For example on a 20 way task, My question is: At each iteration, we are provided with some query example, along with 20 other candidates...if we compute some sort of simple similarity score (that doesnt require neural nets) like (intersection over union) between each candidate to query pair, does this still count as a one shot learning task?\n\nSo leaving aside a neural network approach, if we were to just use a simple distance metric on the coordinates to compute the pairwise similarity between the query and every \"candidate\", does this count as one shot learning?","classes":{"dataset":0.3304660618}}
{"title":"[D] What Improvements Accelerate the AI field Multiple orders of magnitude every year?","description":"These are just my perspectives, I am curious to hear how other people see it in the comments.\n\n  \nFrom my perspective there are the following improvements that accelerate AI reserch with multiple orders of magnitude every year:\n\n1.) Low barrier to entrance for researchers as hugging face, kaggle, google colab gives you free resources (CPU,RAM,GPU,TPU) to study\n\n2.) More efficient models: with smaller models reproducing similar results as larger counterpart a good example is Open AI DALL-E vs stable diffusion.\n\n3.) More efficient techniques: Ex changing computation from FP32 -&gt; FP 16 in Nvidia GPUs\n\n4.) Cleaner better labeled data by the community\n\n4.) More efficient underlying programing language optimizations\n\n5.) Rewritten more efficient code\n\n6.) New hardware\n\n7.) Special purpose hardware (while for gaming and other general purpose benchmarks there are 20-30% improvements every year or every 2 years) for AI reserch TENSOR cores (Nvidia GPUs, Google Cloud TPUs) or apple's Neural engines are orders of magnitude of speed improvement for AI models. Or many supercomputers are ARM based (that is not fully related to here but overall great architectural changes).\n\n8.) New hardware types: analog processors might make a comeback soon that helps calculate floating point operations faster for neural nets. (others: Intelligence Processing Unit, Hogel processing unit (HPU) )\n\n9.) Just the number of new professionals/researchers entering different fields of the AI game. University Majors, online courses, jobs ...\n\n10.) Money/funding.\n\n11.) Becoming culturally mainstream, non professionals realizing that they use it every day.","link":"https://www.reddit.com/r/MachineLearning/comments/11o1vjw/d_what_improvements_accelerate_the_ai_field/","created":"2023-03-10","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":5},"text":"[D] What Improvements Accelerate the AI field Multiple orders of magnitude every year? These are just my perspectives, I am curious to hear how other people see it in the comments.\n\n  \nFrom my perspective there are the following improvements that accelerate AI reserch with multiple orders of magnitude every year:\n\n1.) Low barrier to entrance for researchers as hugging face, kaggle, google colab gives you free resources (CPU,RAM,GPU,TPU) to study\n\n2.) More efficient models: with smaller models reproducing similar results as larger counterpart a good example is Open AI DALL-E vs stable diffusion.\n\n3.) More efficient techniques: Ex changing computation from FP32 -&gt; FP 16 in Nvidia GPUs\n\n4.) Cleaner better labeled data by the community\n\n4.) More efficient underlying programing language optimizations\n\n5.) Rewritten more efficient code\n\n6.) New hardware\n\n7.) Special purpose hardware (while for gaming and other general purpose benchmarks there are 20-30% improvements every year or every 2 years) for AI reserch TENSOR cores (Nvidia GPUs, Google Cloud TPUs) or apple's Neural engines are orders of magnitude of speed improvement for AI models. Or many supercomputers are ARM based (that is not fully related to here but overall great architectural changes).\n\n8.) New hardware types: analog processors might make a comeback soon that helps calculate floating point operations faster for neural nets. (others: Intelligence Processing Unit, Hogel processing unit (HPU) )\n\n9.) Just the number of new professionals/researchers entering different fields of the AI game. University Majors, online courses, jobs ...\n\n10.) Money/funding.\n\n11.) Becoming culturally mainstream, non professionals realizing that they use it every day.","classes":{"dataset":0.4660257995}}
{"title":"Recent advances in multimodal models: What are your thoughts on chain of thoughts models? [D]","description":"Hi everyone,\n\nI'm interested in learning more about recent advances in multimodal models, particularly chain of thoughts models. I'm curious to know what people working in this field are most excited about and what ideas and papers have inspired them.\n\nSpecifically, I'm interested in learning about:\n\n- The latest research on multimodal models, especially chain of thoughts models\n- The challenges that researchers are currently facing when developing these models\n- How researchers are addressing these challenges\n- What researchers are most excited about when it comes to the potential applications of these models\n\nIf you work on multimodal models, I'd love to hear your thoughts and insights. What papers have been particularly inspiring or influential? What challenges are you currently facing, and how are you addressing them? What are you most excited about when it comes to the future of multimodal models?\n\nThank you in advance for your responses :)","link":"https://www.reddit.com/r/MachineLearning/comments/11nl766/recent_advances_in_multimodal_models_what_are/","created":"2023-03-10","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":0},"text":"Recent advances in multimodal models: What are your thoughts on chain of thoughts models? [D] Hi everyone,\n\nI'm interested in learning more about recent advances in multimodal models, particularly chain of thoughts models. I'm curious to know what people working in this field are most excited about and what ideas and papers have inspired them.\n\nSpecifically, I'm interested in learning about:\n\n- The latest research on multimodal models, especially chain of thoughts models\n- The challenges that researchers are currently facing when developing these models\n- How researchers are addressing these challenges\n- What researchers are most excited about when it comes to the potential applications of these models\n\nIf you work on multimodal models, I'd love to hear your thoughts and insights. What papers have been particularly inspiring or influential? What challenges are you currently facing, and how are you addressing them? What are you most excited about when it comes to the future of multimodal models?\n\nThank you in advance for your responses :)","classes":{"dataset":0.2883204222}}
{"title":"[R] Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models","description":"","link":"https://www.reddit.com/gallery/11mlwty","created":"2023-03-09","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":30},"text":"[R] Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models ","classes":{"dataset":0.2657366991}}
{"title":"[D] Neuron Modeling","description":"Disclaimer : I am just a SWE who only knows some basic concepts of NN and ML, so I might be talking total garbage here.\n\nRecently, I read the news that the organoid made from brain cells can now play a simple game. Since it was made from the real neurons, it was way more efficient in learning.\n\nIf we think about it, our brain is very small and consumes comparably lower power, but still we are pretty smarter than the most of ai models powered by 1000s of gpus.\n\nI was wondering if there are any interesting research papers that actually try to model a human neuron. Btw I am not talking about a neural network itself. I feel like we are over simplifying a neuron as just a number while it can be an object that contains interesting features of our real neurons.\n\nI would really appreciate it if anyone could recommend any related research papers to read!","link":"https://www.reddit.com/r/MachineLearning/comments/11ned6g/d_neuron_modeling/","created":"2023-03-10","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":10},"text":"[D] Neuron Modeling Disclaimer : I am just a SWE who only knows some basic concepts of NN and ML, so I might be talking total garbage here.\n\nRecently, I read the news that the organoid made from brain cells can now play a simple game. Since it was made from the real neurons, it was way more efficient in learning.\n\nIf we think about it, our brain is very small and consumes comparably lower power, but still we are pretty smarter than the most of ai models powered by 1000s of gpus.\n\nI was wondering if there are any interesting research papers that actually try to model a human neuron. Btw I am not talking about a neural network itself. I feel like we are over simplifying a neuron as just a number while it can be an object that contains interesting features of our real neurons.\n\nI would really appreciate it if anyone could recommend any related research papers to read!","classes":{"dataset":0.0002003074}}
{"title":"[D] JAX vs PyTorch in 2023","description":"I've recently started my Ph.D. in Multi-Agent RL, and want to learn JAX/Flax and use that for my research, the reason being that DeepMind/Google use it, and I want to land an internship/job there at some point.\n\nI have been using PyTorch for 2.5 years, and in the past few days, I've been struggling to make the switch to JAX/Flax. Although the ideas behind JAX are cool, I feel like they make it unnecessarily complicated, and I would just be better off if I simply kept using PyTorch since I'm very familiar with it.\n\nI had tried to learn JAX 1-2 years ago already, and I came to the same conclusion back then, which makes me think that the usability of JAX hasn't improved much.\n\nDo you think it's worth it to make a serious effort this time to learn JAX, so that I will be able to use it for the rest of my Ph.D., or is there just no point in doing so and I should keep using PyTorch?","link":"https://www.reddit.com/r/MachineLearning/comments/11myoug/d_jax_vs_pytorch_in_2023/","created":"2023-03-09","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":38},"text":"[D] JAX vs PyTorch in 2023 I've recently started my Ph.D. in Multi-Agent RL, and want to learn JAX/Flax and use that for my research, the reason being that DeepMind/Google use it, and I want to land an internship/job there at some point.\n\nI have been using PyTorch for 2.5 years, and in the past few days, I've been struggling to make the switch to JAX/Flax. Although the ideas behind JAX are cool, I feel like they make it unnecessarily complicated, and I would just be better off if I simply kept using PyTorch since I'm very familiar with it.\n\nI had tried to learn JAX 1-2 years ago already, and I came to the same conclusion back then, which makes me think that the usability of JAX hasn't improved much.\n\nDo you think it's worth it to make a serious effort this time to learn JAX, so that I will be able to use it for the rest of my Ph.D., or is there just no point in doing so and I should keep using PyTorch?","classes":{"dataset":0.3405610919}}
{"title":"How to interpret actions","description":"Hey guys, I would like to be able to extract actions along with their objects. For example, in the sentence \"Paint all the walls red and hide all the doors and windows.\", I would like to extract the verbs \"paint\" and \"hide\", the objects \"walls, doors, windows\", the relationships \"paint-&gt;walls\", \"hide-&gt;doors, windows\", and the adverb relationship \"paint-&gt;red\".\n\nWhat tools/techniques would you suggest? Is deep learning the way to go?\n\n[Spacy](https://spacy.io/usage/rule-based-matching#dependencymatcher) and [Stanza](https://stanfordnlp.github.io/stanza/available\\_models.html) look promising, but I am not sure.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11nozbv/how_to_interpret_actions/","created":"2023-03-10","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":3},"text":"How to interpret actions Hey guys, I would like to be able to extract actions along with their objects. For example, in the sentence \"Paint all the walls red and hide all the doors and windows.\", I would like to extract the verbs \"paint\" and \"hide\", the objects \"walls, doors, windows\", the relationships \"paint-&gt;walls\", \"hide-&gt;doors, windows\", and the adverb relationship \"paint-&gt;red\".\n\nWhat tools/techniques would you suggest? Is deep learning the way to go?\n\n[Spacy](https://spacy.io/usage/rule-based-matching#dependencymatcher) and [Stanza](https://stanfordnlp.github.io/stanza/available\\_models.html) look promising, but I am not sure.","classes":{"dataset":0.9468609691}}
{"title":"Can NLP be used to categorize individuals based on responses?","description":"Hi all,\n\nNew to the field of machine learning and have a dataset with survey responses. I was wondering if NLP can be utilized to categorize individuals based on their responses (approximately 2-3 categories), or is this something better for another domain of machine learning?\n\nIt seems like NLP is more for language generation and interaction. I haven't found much with a couple of quick Google searches around categorization, which makes me think it likely isn't role but just want to check.\n\nThank you!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11n56np/can_nlp_be_used_to_categorize_individuals_based/","created":"2023-03-09","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":11},"text":"Can NLP be used to categorize individuals based on responses? Hi all,\n\nNew to the field of machine learning and have a dataset with survey responses. I was wondering if NLP can be utilized to categorize individuals based on their responses (approximately 2-3 categories), or is this something better for another domain of machine learning?\n\nIt seems like NLP is more for language generation and interaction. I haven't found much with a couple of quick Google searches around categorization, which makes me think it likely isn't role but just want to check.\n\nThank you!","classes":{"dataset":0.2686912715}}
{"title":"Wanna Get Training Datasets For Social media spam classifier","description":"I am planning to build social media's spam classifier with Multinomial Naive Bayes model with python, using \\`sklearn\\` and \\`spacy\\` library. And the text feature extraction technique I will use is tf-idf vectorizer.\n\nHowever, I am having problem to find social media datasets with labelled data as SPAM or NOT SPAM. Another criteria with the datasets is that I need the datasets to be balanced (with roughly equal number of SPAM and NOT SPAM data).\n\nDo suggest me some links or source that I could get the data from?\n\nHope for help. Thanks in advance.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11muxkl/wanna_get_training_datasets_for_social_media_spam/","created":"2023-03-09","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":0},"text":"Wanna Get Training Datasets For Social media spam classifier I am planning to build social media's spam classifier with Multinomial Naive Bayes model with python, using \\`sklearn\\` and \\`spacy\\` library. And the text feature extraction technique I will use is tf-idf vectorizer.\n\nHowever, I am having problem to find social media datasets with labelled data as SPAM or NOT SPAM. Another criteria with the datasets is that I need the datasets to be balanced (with roughly equal number of SPAM and NOT SPAM data).\n\nDo suggest me some links or source that I could get the data from?\n\nHope for help. Thanks in advance.","classes":{"dataset":0.293358475}}
{"title":"Semantic Search: With Exclusions","description":"I am making a semantic search engine in Python that takes a user input and returns the 5 most similar results from a list of sentences. \n\nThe list of sentences features a list of things not included in the category at the end of a sentence e.g.   \u201cThis category includes: lions, tigers. This category excludes: birds, bees\u201d  \n\nCurrently if I search \u201cbirds\u201d the above example would be returned as strong similarity due to the word matching with \u201ccategory excludes: birds\u201d \n\nDoes anyone know any way to prevent this?\nAny help appreciated!!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11m4niv/semantic_search_with_exclusions/","created":"2023-03-08","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":9},"text":"Semantic Search: With Exclusions I am making a semantic search engine in Python that takes a user input and returns the 5 most similar results from a list of sentences. \n\nThe list of sentences features a list of things not included in the category at the end of a sentence e.g.   \u201cThis category includes: lions, tigers. This category excludes: birds, bees\u201d  \n\nCurrently if I search \u201cbirds\u201d the above example would be returned as strong similarity due to the word matching with \u201ccategory excludes: birds\u201d \n\nDoes anyone know any way to prevent this?\nAny help appreciated!!","classes":{"dataset":0.5313108563}}
{"title":"Testing Viterbi Algorithm for Hidden markov model pos tagger","description":"I am implementing the HMM model pos tagger using viterbi algorithm on the brown dataset from nltk. I have separated the data into train and test datasets, now for train dataset, I have calculated the emission and transition probability matrix. I have a few questions though.\n\n1. To calculate the accuracy, do we count the no. of correct tags on words or the no. of correctly tagged sentences? (my guess is it should be words)\n2. For testing data, I have some words which are not in the emission probability matrix, and hence for those sentences viterbi algorithm gives me an error. how do i handle this?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11luju0/testing_viterbi_algorithm_for_hidden_markov_model/","created":"2023-03-08","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":4},"text":"Testing Viterbi Algorithm for Hidden markov model pos tagger I am implementing the HMM model pos tagger using viterbi algorithm on the brown dataset from nltk. I have separated the data into train and test datasets, now for train dataset, I have calculated the emission and transition probability matrix. I have a few questions though.\n\n1. To calculate the accuracy, do we count the no. of correct tags on words or the no. of correctly tagged sentences? (my guess is it should be words)\n2. For testing data, I have some words which are not in the emission probability matrix, and hence for those sentences viterbi algorithm gives me an error. how do i handle this?","classes":{"dataset":0.2311390638}}
{"title":"Question about density plots for dimensionality reduced embeddings","description":"I have long form documents that each talk about a variety of topics (10+). The documents are split into paragraph, which is the unit (sub-) topics are talked about. For each paragraph an embedding is created via OpenAI (text-embedding-ada-002). Since the embeddings contain 1536 dimensions, I use UMAP to reduce it to two. \n\nWhat I would like to do is then use bivatiate kde plots via [seaborn](https://seaborn.pydata.org/tutorial/distributions.html) to compare the focus of the documents (each representing an organization) showing differences and commonalities. I don\u2018t have a strong background in mathematics but this part of the [documentation](https://umap-learn.readthedocs.io/en/latest/clustering.html) threw me a little of. While I am not directly clustering, the underlying idea seems similar enough to warrant caution. \n\nDoes anybody know if my idea (umap reduced embedding-&gt; kde plot) reasonably sound or have any pointers to fintune the approach?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11m3jgo/question_about_density_plots_for_dimensionality/","created":"2023-03-08","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":0},"text":"Question about density plots for dimensionality reduced embeddings I have long form documents that each talk about a variety of topics (10+). The documents are split into paragraph, which is the unit (sub-) topics are talked about. For each paragraph an embedding is created via OpenAI (text-embedding-ada-002). Since the embeddings contain 1536 dimensions, I use UMAP to reduce it to two. \n\nWhat I would like to do is then use bivatiate kde plots via [seaborn](https://seaborn.pydata.org/tutorial/distributions.html) to compare the focus of the documents (each representing an organization) showing differences and commonalities. I don\u2018t have a strong background in mathematics but this part of the [documentation](https://umap-learn.readthedocs.io/en/latest/clustering.html) threw me a little of. While I am not directly clustering, the underlying idea seems similar enough to warrant caution. \n\nDoes anybody know if my idea (umap reduced embedding-&gt; kde plot) reasonably sound or have any pointers to fintune the approach?","classes":{"dataset":0.4061246216}}
{"title":"Analyzing a failed drill bit with an electron microscope [video]","description":"https://www.youtube.com/watch?v=887Q-LWBW48","link":"https://www.youtube.com/watch?v=887Q-LWBW48","created":"2023-03-19","tags":["hackernews"],"meta":{"score":118},"text":"Analyzing a failed drill bit with an electron microscope [video] https://www.youtube.com/watch?v=887Q-LWBW48","classes":{"dataset":0.5023696423}}
{"title":"Learning BASIC Like It's 1983 (2018)","description":"https://twobithistory.org/2018/09/02/learning-basic.html","link":"https://twobithistory.org/2018/09/02/learning-basic.html","created":"2023-03-19","tags":["hackernews"],"meta":{"score":81},"text":"Learning BASIC Like It's 1983 (2018) https://twobithistory.org/2018/09/02/learning-basic.html","classes":{"dataset":0.4914995134}}
{"title":"Greening the desert: the architect regenerating Jordan\u2019s native forests","description":"https://www.theguardian.com/global-development/2023/mar/09/greening-the-desert-architect-tayyun-regenerating-jordan-native-forests","link":"https://www.theguardian.com/global-development/2023/mar/09/greening-the-desert-architect-tayyun-regenerating-jordan-native-forests","created":"2023-03-19","tags":["hackernews"],"meta":{"score":30},"text":"Greening the desert: the architect regenerating Jordan\u2019s native forests https://www.theguardian.com/global-development/2023/mar/09/greening-the-desert-architect-tayyun-regenerating-jordan-native-forests","classes":{"dataset":0.5158123374}}
{"title":"More students are turning away from college and toward apprenticeships","description":"https://www.wsj.com/articles/more-students-are-turning-away-from-college-and-toward-apprenticeships-15f3a05d","link":"https://www.wsj.com/articles/more-students-are-turning-away-from-college-and-toward-apprenticeships-15f3a05d","created":"2023-03-18","tags":["hackernews"],"meta":{"score":607},"text":"More students are turning away from college and toward apprenticeships https://www.wsj.com/articles/more-students-are-turning-away-from-college-and-toward-apprenticeships-15f3a05d","classes":{"dataset":0.5554780364}}
{"title":"Abecedarium","description":"https://en.wikipedia.org/wiki/Abecedarium","link":"https://en.wikipedia.org/wiki/Abecedarium","created":"2023-03-17","tags":["hackernews"],"meta":{"score":20},"text":"Abecedarium https://en.wikipedia.org/wiki/Abecedarium","classes":{"dataset":0.507349968}}
{"title":"Self-Admitted Technical Debt","description":"https://neverworkintheory.org/2023/03/16/self-admitted-technical-debt.html","link":"https://neverworkintheory.org/2023/03/16/self-admitted-technical-debt.html","created":"2023-03-16","tags":["hackernews"],"meta":{"score":25},"text":"Self-Admitted Technical Debt https://neverworkintheory.org/2023/03/16/self-admitted-technical-debt.html","classes":{"dataset":0.5393342376}}
{"title":"Analyzing multi-gigabyte JSON files locally","description":"https://thenybble.de/posts/json-analysis/","link":"https://thenybble.de/posts/json-analysis/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":170},"text":"Analyzing multi-gigabyte JSON files locally https://thenybble.de/posts/json-analysis/","classes":{"dataset":0.5419297218}}
{"title":"Master Emacs in one year","description":"https://github.com/redguardtoo/mastering-emacs-in-one-year-guide/blob/master/guide-en.org","link":"https://github.com/redguardtoo/mastering-emacs-in-one-year-guide/blob/master/guide-en.org","created":"2023-03-19","tags":["hackernews"],"meta":{"score":41},"text":"Master Emacs in one year https://github.com/redguardtoo/mastering-emacs-in-one-year-guide/blob/master/guide-en.org","classes":{"dataset":0.4827159047}}
{"title":"The untapped potential of human programming (2022)","description":"https://humanprogramming.substack.com/p/the-untapped-potential-of-human-programming","link":"https://humanprogramming.substack.com/p/the-untapped-potential-of-human-programming","created":"2023-03-19","tags":["hackernews"],"meta":{"score":3},"text":"The untapped potential of human programming (2022) https://humanprogramming.substack.com/p/the-untapped-potential-of-human-programming","classes":{"dataset":0.5237464309}}
{"title":"A different approach to fuzzy finding","description":"https://nathancraddock.com/blog/2023/a-different-approach-to-fuzzy-finding/","link":"https://nathancraddock.com/blog/2023/a-different-approach-to-fuzzy-finding/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":48},"text":"A different approach to fuzzy finding https://nathancraddock.com/blog/2023/a-different-approach-to-fuzzy-finding/","classes":{"dataset":0.5194867849}}
{"title":"Real-Time Video Processing with WebCodecs and Streams","description":"https://webrtchacks.com/real-time-video-processing-with-webcodecs-and-streams-processing-pipelines-part-1/","link":"https://webrtchacks.com/real-time-video-processing-with-webcodecs-and-streams-processing-pipelines-part-1/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":93},"text":"Real-Time Video Processing with WebCodecs and Streams https://webrtchacks.com/real-time-video-processing-with-webcodecs-and-streams-processing-pipelines-part-1/","classes":{"dataset":0.5112885237}}
{"title":"Do I Need to Avoid Dark Chocolate Now?","description":"https://www.nytimes.com/2023/02/09/well/eat/dark-chocolate-metal-lead.html","link":"https://www.nytimes.com/2023/02/09/well/eat/dark-chocolate-metal-lead.html","created":"2023-03-19","tags":["hackernews"],"meta":{"score":18},"text":"Do I Need to Avoid Dark Chocolate Now? https://www.nytimes.com/2023/02/09/well/eat/dark-chocolate-metal-lead.html","classes":{"dataset":0.4935777187}}
{"title":"LLVM 16.0.0 Release","description":"https://discourse.llvm.org/t/llvm-16-0-0-release/69326","link":"https://discourse.llvm.org/t/llvm-16-0-0-release/69326","created":"2023-03-18","tags":["hackernews"],"meta":{"score":175},"text":"LLVM 16.0.0 Release https://discourse.llvm.org/t/llvm-16-0-0-release/69326","classes":{"dataset":0.5241152644}}
{"title":"Understanding CD-R and CD-RW (2003) [pdf]","description":"http://www.osta.org/technology/pdf/cdr_cdrw.pdf","link":"http://www.osta.org/technology/pdf/cdr_cdrw.pdf","created":"2023-03-17","tags":["hackernews"],"meta":{"score":101},"text":"Understanding CD-R and CD-RW (2003) [pdf] http://www.osta.org/technology/pdf/cdr_cdrw.pdf","classes":{"dataset":0.5043692589}}
{"title":"Old backdoor, new obfuscation","description":"https://isc.sans.edu/diary.html?storyid=0","link":"https://isc.sans.edu/diary.html?storyid=0","created":"2023-03-16","tags":["hackernews"],"meta":{"score":37},"text":"Old backdoor, new obfuscation https://isc.sans.edu/diary.html?storyid=0","classes":{"dataset":0.5095393658}}
{"title":"Zero one infinity rule","description":"https://en.wikipedia.org/wiki/Zero_one_infinity_rule","link":"https://en.wikipedia.org/wiki/Zero_one_infinity_rule","created":"2023-03-18","tags":["hackernews"],"meta":{"score":123},"text":"Zero one infinity rule https://en.wikipedia.org/wiki/Zero_one_infinity_rule","classes":{"dataset":0.5499587059}}
{"title":"Students of BloomTech, FKA Lambda School, file class-action lawsuit","description":"https://www.businessinsider.com/lambda-school-bloomtech-class-action-lawsuit-2023-3","link":"https://www.businessinsider.com/lambda-school-bloomtech-class-action-lawsuit-2023-3","created":"2023-03-19","tags":["hackernews"],"meta":{"score":79},"text":"Students of BloomTech, FKA Lambda School, file class-action lawsuit https://www.businessinsider.com/lambda-school-bloomtech-class-action-lawsuit-2023-3","classes":{"dataset":0.5140632391}}
{"title":"Exploiting aCropalypse: Recovering truncated PNGs","description":"https://www.da.vidbuchanan.co.uk/blog/exploiting-acropalypse.html","link":"https://www.da.vidbuchanan.co.uk/blog/exploiting-acropalypse.html","created":"2023-03-18","tags":["hackernews"],"meta":{"score":186},"text":"Exploiting aCropalypse: Recovering truncated PNGs https://www.da.vidbuchanan.co.uk/blog/exploiting-acropalypse.html","classes":{"dataset":0.6004841924}}
{"title":"\u2018He passed the bee baton on to me\u2019: people who inherit hobbies","description":"https://www.theguardian.com/lifeandstyle/2023/mar/08/he-passed-the-bee-baton-on-to-me-people-who-inherit-hobbies","link":"https://www.theguardian.com/lifeandstyle/2023/mar/08/he-passed-the-bee-baton-on-to-me-people-who-inherit-hobbies","created":"2023-03-18","tags":["hackernews"],"meta":{"score":51},"text":"\u2018He passed the bee baton on to me\u2019: people who inherit hobbies https://www.theguardian.com/lifeandstyle/2023/mar/08/he-passed-the-bee-baton-on-to-me-people-who-inherit-hobbies","classes":{"dataset":0.4996335804}}
{"title":"SETI@home is in hibernation","description":"https://setiathome.berkeley.edu/","link":"https://setiathome.berkeley.edu/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":486},"text":"SETI@home is in hibernation https://setiathome.berkeley.edu/","classes":{"dataset":0.4949691296}}
{"title":"Negativity drives online news consumption","description":"https://www.nature.com/articles/s41562-023-01538-4","link":"https://www.nature.com/articles/s41562-023-01538-4","created":"2023-03-17","tags":["hackernews"],"meta":{"score":578},"text":"Negativity drives online news consumption https://www.nature.com/articles/s41562-023-01538-4","classes":{"dataset":0.5070110559}}
{"title":"a[low:high:max] in Golang \u2013 A Rare Slice Trick","description":"https://build-your-own.org/blog/20230316_go_full_slice/","link":"https://build-your-own.org/blog/20230316_go_full_slice/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":119},"text":"a[low:high:max] in Golang \u2013 A Rare Slice Trick https://build-your-own.org/blog/20230316_go_full_slice/","classes":{"dataset":0.5270996094}}
{"title":"Simulations and games in economics education","description":"https://en.wikipedia.org/wiki/Simulations_and_games_in_economics_education","link":"https://en.wikipedia.org/wiki/Simulations_and_games_in_economics_education","created":"2023-03-18","tags":["hackernews"],"meta":{"score":63},"text":"Simulations and games in economics education https://en.wikipedia.org/wiki/Simulations_and_games_in_economics_education","classes":{"dataset":0.5435265303}}
{"title":"Rippling raises $500M in emergency funds after SVB fails","description":"https://www.bloomberg.com/news/articles/2023-03-17/rippling-raises-500-million-in-emergency-funds-after-svb-fails","link":"https://www.bloomberg.com/news/articles/2023-03-17/rippling-raises-500-million-in-emergency-funds-after-svb-fails","created":"2023-03-17","tags":["hackernews"],"meta":{"score":101},"text":"Rippling raises $500M in emergency funds after SVB fails https://www.bloomberg.com/news/articles/2023-03-17/rippling-raises-500-million-in-emergency-funds-after-svb-fails","classes":{"dataset":0.4908374846}}
{"title":"ViperGPT: Visual Inference via Python Execution for Reasoning","description":"https://viper.cs.columbia.edu/","link":"https://viper.cs.columbia.edu/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":538},"text":"ViperGPT: Visual Inference via Python Execution for Reasoning https://viper.cs.columbia.edu/","classes":{"dataset":0.4751027524}}
{"title":"Firefox 66 to block automatically playing audible video and audio (2019)","description":"https://hacks.mozilla.org/2019/02/firefox-66-to-block-automatically-playing-audible-video-and-audio/","link":"https://hacks.mozilla.org/2019/02/firefox-66-to-block-automatically-playing-audible-video-and-audio/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":99},"text":"Firefox 66 to block automatically playing audible video and audio (2019) https://hacks.mozilla.org/2019/02/firefox-66-to-block-automatically-playing-audible-video-and-audio/","classes":{"dataset":0.5116564631}}
{"title":"10 days fasting and calcium/vit d supplements increases bone mineral density","description":"https://www.sciencedirect.com/science/article/abs/pii/S875632822100380X","link":"https://www.sciencedirect.com/science/article/abs/pii/S875632822100380X","created":"2023-03-19","tags":["hackernews"],"meta":{"score":66},"text":"10 days fasting and calcium/vit d supplements increases bone mineral density https://www.sciencedirect.com/science/article/abs/pii/S875632822100380X","classes":{"dataset":0.5852409005}}
{"title":"Strife at eLife: inside a journal\u2019s quest to upend science publishing","description":"https://www.nature.com/articles/d41586-023-00831-6","link":"https://www.nature.com/articles/d41586-023-00831-6","created":"2023-03-18","tags":["hackernews"],"meta":{"score":80},"text":"Strife at eLife: inside a journal\u2019s quest to upend science publishing https://www.nature.com/articles/d41586-023-00831-6","classes":{"dataset":0.4384759665}}
{"title":"A four-decade secret: One man\u2019s story of sabotaging Carter\u2019s re-election","description":"https://www.nytimes.com/2023/03/18/us/politics/jimmy-carter-october-surprise-iran-hostages.html","link":"https://www.nytimes.com/2023/03/18/us/politics/jimmy-carter-october-surprise-iran-hostages.html","created":"2023-03-18","tags":["hackernews"],"meta":{"score":58},"text":"A four-decade secret: One man\u2019s story of sabotaging Carter\u2019s re-election https://www.nytimes.com/2023/03/18/us/politics/jimmy-carter-october-surprise-iran-hostages.html","classes":{"dataset":0.5136632323}}
{"title":"Pico_1140: A PDP11/40 emulator that will run Unix v5/v6 on a Raspberry Pi RP2040","description":"https://github.com/Isysxp/Pico_1140","link":"https://github.com/Isysxp/Pico_1140","created":"2023-03-17","tags":["hackernews"],"meta":{"score":78},"text":"Pico_1140: A PDP11/40 emulator that will run Unix v5/v6 on a Raspberry Pi RP2040 https://github.com/Isysxp/Pico_1140","classes":{"dataset":0.4775285721}}
{"title":"A growing number of scientists are convinced the future influences the past","description":"https://www.vice.com/en/article/epvgjm/a-growing-number-of-scientists-are-convinced-the-future-influences-the-past","link":"https://www.vice.com/en/article/epvgjm/a-growing-number-of-scientists-are-convinced-the-future-influences-the-past","created":"2023-03-17","tags":["hackernews"],"meta":{"score":319},"text":"A growing number of scientists are convinced the future influences the past https://www.vice.com/en/article/epvgjm/a-growing-number-of-scientists-are-convinced-the-future-influences-the-past","classes":{"dataset":0.5439405441}}
{"title":"Startups learn the hard way how to manage cash after SVB\u2019s collapse","description":"https://www.ft.com/content/af25210b-ea2b-4d1a-baf1-4dc581075802","link":"https://www.ft.com/content/af25210b-ea2b-4d1a-baf1-4dc581075802","created":"2023-03-19","tags":["hackernews"],"meta":{"score":3},"text":"Startups learn the hard way how to manage cash after SVB\u2019s collapse https://www.ft.com/content/af25210b-ea2b-4d1a-baf1-4dc581075802","classes":{"dataset":0.4692479074}}
{"title":"Listening to the Creatures of the World","description":"https://www.noemamag.com/a-parliament-of-earthlings/","link":"https://www.noemamag.com/a-parliament-of-earthlings/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":23},"text":"Listening to the Creatures of the World https://www.noemamag.com/a-parliament-of-earthlings/","classes":{"dataset":0.5115827322}}
{"title":"Technical dimensions of programming systems","description":"https://tomasp.net/techdims/","link":"https://tomasp.net/techdims/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":75},"text":"Technical dimensions of programming systems https://tomasp.net/techdims/","classes":{"dataset":0.5031554699}}
{"title":"Tracking the Fake GitHub Star Black Market","description":"https://dagster.io/blog/fake-stars","link":"https://dagster.io/blog/fake-stars","created":"2023-03-18","tags":["hackernews"],"meta":{"score":468},"text":"Tracking the Fake GitHub Star Black Market https://dagster.io/blog/fake-stars","classes":{"dataset":0.533298552}}
{"title":"A short history of the VW Mark 1 Rabbit/Golf (2021)","description":"https://haynes.com/en-us/tips-tutorials/short-history-vw-mark-1-rabbitgolf","link":"https://haynes.com/en-us/tips-tutorials/short-history-vw-mark-1-rabbitgolf","created":"2023-03-18","tags":["hackernews"],"meta":{"score":51},"text":"A short history of the VW Mark 1 Rabbit/Golf (2021) https://haynes.com/en-us/tips-tutorials/short-history-vw-mark-1-rabbitgolf","classes":{"dataset":0.5288347602}}
{"title":"Nuclear power plant leaked 1.5M litres of radioactive water in Minnesota","description":"https://globalnews.ca/news/9559326/nuclear-power-plant-leak-radioactive-water-minnesota/","link":"https://globalnews.ca/news/9559326/nuclear-power-plant-leak-radioactive-water-minnesota/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":105},"text":"Nuclear power plant leaked 1.5M litres of radioactive water in Minnesota https://globalnews.ca/news/9559326/nuclear-power-plant-leak-radioactive-water-minnesota/","classes":{"dataset":0.5044917464}}
{"title":"Something Pretty Right: The History and Legacy of Visual Basic","description":"https://retool.com/visual-basic/","link":"https://retool.com/visual-basic/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":432},"text":"Something Pretty Right: The History and Legacy of Visual Basic https://retool.com/visual-basic/","classes":{"dataset":0.5194280744}}
{"title":"Laptop Brands with GNU/Linux Preinstalled","description":"https://floss.social/@ademalsasa/109597861116785251","link":"https://floss.social/@ademalsasa/109597861116785251","created":"2023-03-18","tags":["hackernews"],"meta":{"score":157},"text":"Laptop Brands with GNU/Linux Preinstalled https://floss.social/@ademalsasa/109597861116785251","classes":{"dataset":0.5249845982}}
{"title":"Desiderata: Original Text","description":"https://www.desiderata.com/desiderata.html","link":"https://www.desiderata.com/desiderata.html","created":"2023-03-18","tags":["hackernews"],"meta":{"score":54},"text":"Desiderata: Original Text https://www.desiderata.com/desiderata.html","classes":{"dataset":0.541113317}}
{"title":"We're Drowning in Subscriptions","description":"https://www.bloomberg.com/opinion/articles/2023-03-17/we-re-drowning-in-subscriptions-as-retailers-join-too","link":"https://www.bloomberg.com/opinion/articles/2023-03-17/we-re-drowning-in-subscriptions-as-retailers-join-too","created":"2023-03-18","tags":["hackernews"],"meta":{"score":86},"text":"We're Drowning in Subscriptions https://www.bloomberg.com/opinion/articles/2023-03-17/we-re-drowning-in-subscriptions-as-retailers-join-too","classes":{"dataset":0.5467267632}}
{"title":"Tungsten gold plated bar","description":"http://www.tungsten-alloy.com/gold-plated-tungsten-alloy-bar.html","link":"http://www.tungsten-alloy.com/gold-plated-tungsten-alloy-bar.html","created":"2023-03-18","tags":["hackernews"],"meta":{"score":84},"text":"Tungsten gold plated bar http://www.tungsten-alloy.com/gold-plated-tungsten-alloy-bar.html","classes":{"dataset":0.4778857231}}
{"title":"Study hints at the promise of non-hallucinogenic LSD for treating mood disorders","description":"https://medicalxpress.com/news/2023-03-hints-non-hallucinogenic-lsd-mood-disorders.html","link":"https://medicalxpress.com/news/2023-03-hints-non-hallucinogenic-lsd-mood-disorders.html","created":"2023-03-18","tags":["hackernews"],"meta":{"score":48},"text":"Study hints at the promise of non-hallucinogenic LSD for treating mood disorders https://medicalxpress.com/news/2023-03-hints-non-hallucinogenic-lsd-mood-disorders.html","classes":{"dataset":0.5368663073}}
{"title":"Bourbon and Branch Water (2013)","description":"https://flemingsbond.com/bourbon-and-branch-water/","link":"https://flemingsbond.com/bourbon-and-branch-water/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":59},"text":"Bourbon and Branch Water (2013) https://flemingsbond.com/bourbon-and-branch-water/","classes":{"dataset":0.5904939771}}
{"title":"More than 75 percent decline over 27 years in total flying insect biomass (2017)","description":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0185809","link":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0185809","created":"2023-03-18","tags":["hackernews"],"meta":{"score":208},"text":"More than 75 percent decline over 27 years in total flying insect biomass (2017) https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0185809","classes":{"dataset":0.5291645527}}
{"title":"5100+ Chat GPT Prompts Excel Sheet!","description":" https://www.etsy.com/listing/1427145796/5100-chat-gpt-prompts-excel-worksheet?ref=listings\\_manager\\_grid","link":"https://www.reddit.com/r/PromptDesign/comments/11uq186/5100_chat_gpt_prompts_excel_sheet/","created":"2023-03-18","tags":["prompteng","reddit","promptdesign"],"meta":{"num_comments":1},"text":"5100+ Chat GPT Prompts Excel Sheet!  https://www.etsy.com/listing/1427145796/5100-chat-gpt-prompts-excel-worksheet?ref=listings\\_manager\\_grid","classes":{"dataset":0.421417892}}
{"title":"Sunday Daily Thread: What's everyone working on this week?","description":"Tell /r/python what you're working on this week! You can be bragging, grousing, sharing your passion, or explaining your pain. Talk about your current project or your pet project; whatever you want to share.","link":"https://www.reddit.com/r/Python/comments/11v57uj/sunday_daily_thread_whats_everyone_working_on/","created":"2023-03-19","tags":["reddit","python"],"meta":{"num_comments":4},"text":"Sunday Daily Thread: What's everyone working on this week? Tell /r/python what you're working on this week! You can be bragging, grousing, sharing your passion, or explaining your pain. Talk about your current project or your pet project; whatever you want to share.","classes":{"dataset":0.5658325553}}
{"title":"FastAPI 0.95.0 supports and recommends Annotated \ud83d\ude80 [cross-post from r/FastAPI]","description":"This is probably the biggest FastAPI feature in several months, I thought it was worth sharing it. \ud83e\udd13\n\n(Cross-post from [r/FastAPI](https://www.reddit.com/r/FastAPI/comments/11v0j5w/fastapi_0950_supports_and_recommends_annotated/) but I thought this was cool enough to also share it here \ud83d\ude2c).\n\nFastAPI `0.95.0`, just released, adds support for dependencies and parameters using `Annotated` and recommends its usage. \u2728\n\nThis has **several benefits**, one of the main ones is that now the parameters of your functions with `Annotated` would **not be affected** at all.\n\nIf you call those functions in **other places in your code**, the actual **default values** will be kept, your editor will help you notice missing **required arguments**, Python will require you to pass required arguments at **runtime**, you will be able to **use the same functions** for different things and with different libraries (e.g. **Typer** will soon support `Annotated` too, then you could use the same function for an API and a CLI), etc.\n\nBecause `Annotated` is **standard Python**, you still get all the **benefits** from editors and tools, like **autocompletion**, **inline errors**, etc.\n\nOne of the **biggest benefits** is that now you can create `Annotated` dependencies that are then shared by multiple *path operation functions*, this will allow you to **reduce** a lot of **code duplication** in your codebase, while keeping all the support from editors and tools.\n\nFor example, you could have code like this:\n\n```python\ndef get_current_user(token: str):\n    # authenticate user\n    return User()\n\n\n@app.get(\"/items/\")\ndef read_items(user: User = Depends(get_current_user)):\n    ...\n\n\n@app.post(\"/items/\")\ndef create_item(*, user: User = Depends(get_current_user), item: Item):\n    ...\n\n\n@app.get(\"/items/{item_id}\")\ndef read_item(*, user: User = Depends(get_current_user), item_id: int):\n    ...\n\n\n@app.delete(\"/items/{item_id}\")\ndef delete_item(*, user: User = Depends(get_current_user), item_id: int):\n    ...\n```\n\nThere's a bit of code duplication for the dependency:\n\n```python\nuser: User = Depends(get_current_user)\n```\n\n...the bigger the codebase, the more noticeable it is.\n\nNow you can create an annotated dependency once, like this:\n\n```python\nCurrentUser = Annotated[User, Depends(get_current_user)]\n```\n\nAnd then you can reuse this `Annotated` dependency:\n\n```python\nCurrentUser = Annotated[User, Depends(get_current_user)]\n\n\n@app.get(\"/items/\")\ndef read_items(user: CurrentUser):\n    ...\n\n\n@app.post(\"/items/\")\ndef create_item(user: CurrentUser, item: Item):\n    ...\n\n\n@app.get(\"/items/{item_id}\")\ndef read_item(user: CurrentUser, item_id: int):\n    ...\n\n\n@app.delete(\"/items/{item_id}\")\ndef delete_item(user: CurrentUser, item_id: int):\n    ...\n```\n\n...and `CurrentUser` has all the typing information as `User`, so your editor will work as expected (autocompletion and everything), and **FastAPI** will be able to understand the dependency defined in `Annotated`. \ud83d\ude0e\n\nRoughly **all the docs** have been rewritten to use `Annotated` as the main way to declare **parameters** and **dependencies**. All the **examples** in the docs now include a version with `Annotated` and a version without it, for each of the specific Python versions (when there are small differences/improvements in more recent versions). There were around 23K new lines added between docs, examples, and tests. \ud83d\ude80\n\nThe key updated docs are:\n\n* Python Types Intro:\n    * [Type Hints with Metadata Annotations](https://fastapi.tiangolo.com/python-types/#type-hints-with-metadata-annotations).\n* Tutorial:\n    * [Query Parameters and String Validations - Additional validation](https://fastapi.tiangolo.com/tutorial/query-params-str-validations/#additional-validation)\n        * [Advantages of `Annotated`](https://fastapi.tiangolo.com/tutorial/query-params-str-validations/#advantages-of-annotated)\n    * [Path Parameters and Numeric Validations - Order the parameters as you need, tricks](https://fastapi.tiangolo.com/tutorial/path-params-numeric-validations/#order-the-parameters-as-you-need-tricks)\n        * [Better with `Annotated`](https://fastapi.tiangolo.com/tutorial/path-params-numeric-validations/#better-with-annotated)\n    * [Dependencies - First Steps - Share `Annotated` dependencies](https://fastapi.tiangolo.com/tutorial/dependencies/#share-annotated-dependencies)\n\nSpecial thanks to [@nzig](https://github.com/nzig) for the core implementation and to [@adriangb](https://github.com/adriangb) for the inspiration and idea with [Xpresso](https://github.com/adriangb/xpresso)! \ud83d\ude80\n\nIt took a while to get this done as it involved several days thoroughly reviewing the core PR (impeccable job) and a couple of weeks of full-time, continuous, focused work rewriting the docs, examples, and tests. And now it's finally out! \ud83c\udf89\n\nThis will also probably enable much better third-party integrations that can now export `Annotated` dependencies. \ud83d\ude0e\n\nGo update your FastAPI version and start enjoying using `Annotated`! \ud83d\ude80\n\nCheck more details in the release notes: https://fastapi.tiangolo.com/release-notes/#0950","link":"https://www.reddit.com/r/Python/comments/11v0kcb/fastapi_0950_supports_and_recommends_annotated/","created":"2023-03-18","tags":["reddit","python"],"meta":{"num_comments":13},"text":"FastAPI 0.95.0 supports and recommends Annotated \ud83d\ude80 [cross-post from r/FastAPI] This is probably the biggest FastAPI feature in several months, I thought it was worth sharing it. \ud83e\udd13\n\n(Cross-post from [r/FastAPI](https://www.reddit.com/r/FastAPI/comments/11v0j5w/fastapi_0950_supports_and_recommends_annotated/) but I thought this was cool enough to also share it here \ud83d\ude2c).\n\nFastAPI `0.95.0`, just released, adds support for dependencies and parameters using `Annotated` and recommends its usage. \u2728\n\nThis has **several benefits**, one of the main ones is that now the parameters of your functions with `Annotated` would **not be affected** at all.\n\nIf you call those functions in **other places in your code**, the actual **default values** will be kept, your editor will help you notice missing **required arguments**, Python will require you to pass required arguments at **runtime**, you will be able to **use the same functions** for different things and with different libraries (e.g. **Typer** will soon support `Annotated` too, then you could use the same function for an API and a CLI), etc.\n\nBecause `Annotated` is **standard Python**, you still get all the **benefits** from editors and tools, like **autocompletion**, **inline errors**, etc.\n\nOne of the **biggest benefits** is that now you can create `Annotated` dependencies that are then shared by multiple *path operation functions*, this will allow you to **reduce** a lot of **code duplication** in your codebase, while keeping all the support from editors and tools.\n\nFor example, you could have code like this:\n\n```python\ndef get_current_user(token: str):\n    # authenticate user\n    return User()\n\n\n@app.get(\"/items/\")\ndef read_items(user: User = Depends(get_current_user)):\n    ...\n\n\n@app.post(\"/items/\")\ndef create_item(*, user: User = Depends(get_current_user), item: Item):\n    ...\n\n\n@app.get(\"/items/{item_id}\")\ndef read_item(*, user: User = Depends(get_current_user), item_id: int):\n    ...\n\n\n@app.delete(\"/items/{item_id}\")\ndef delete_item(*, user: User = Depends(get_current_user), item_id: int):\n    ...\n```\n\nThere's a bit of code duplication for the dependency:\n\n```python\nuser: User = Depends(get_current_user)\n```\n\n...the bigger the codebase, the more noticeable it is.\n\nNow you can create an annotated dependency once, like this:\n\n```python\nCurrentUser = Annotated[User, Depends(get_current_user)]\n```\n\nAnd then you can reuse this `Annotated` dependency:\n\n```python\nCurrentUser = Annotated[User, Depends(get_current_user)]\n\n\n@app.get(\"/items/\")\ndef read_items(user: CurrentUser):\n    ...\n\n\n@app.post(\"/items/\")\ndef create_item(user: CurrentUser, item: Item):\n    ...\n\n\n@app.get(\"/items/{item_id}\")\ndef read_item(user: CurrentUser, item_id: int):\n    ...\n\n\n@app.delete(\"/items/{item_id}\")\ndef delete_item(user: CurrentUser, item_id: int):\n    ...\n```\n\n...and `CurrentUser` has all the typing information as `User`, so your editor will work as expected (autocompletion and everything), and **FastAPI** will be able to understand the dependency defined in `Annotated`. \ud83d\ude0e\n\nRoughly **all the docs** have been rewritten to use `Annotated` as the main way to declare **parameters** and **dependencies**. All the **examples** in the docs now include a version with `Annotated` and a version without it, for each of the specific Python versions (when there are small differences/improvements in more recent versions). There were around 23K new lines added between docs, examples, and tests. \ud83d\ude80\n\nThe key updated docs are:\n\n* Python Types Intro:\n    * [Type Hints with Metadata Annotations](https://fastapi.tiangolo.com/python-types/#type-hints-with-metadata-annotations).\n* Tutorial:\n    * [Query Parameters and String Validations - Additional validation](https://fastapi.tiangolo.com/tutorial/query-params-str-validations/#additional-validation)\n        * [Advantages of `Annotated`](https://fastapi.tiangolo.com/tutorial/query-params-str-validations/#advantages-of-annotated)\n    * [Path Parameters and Numeric Validations - Order the parameters as you need, tricks](https://fastapi.tiangolo.com/tutorial/path-params-numeric-validations/#order-the-parameters-as-you-need-tricks)\n        * [Better with `Annotated`](https://fastapi.tiangolo.com/tutorial/path-params-numeric-validations/#better-with-annotated)\n    * [Dependencies - First Steps - Share `Annotated` dependencies](https://fastapi.tiangolo.com/tutorial/dependencies/#share-annotated-dependencies)\n\nSpecial thanks to [@nzig](https://github.com/nzig) for the core implementation and to [@adriangb](https://github.com/adriangb) for the inspiration and idea with [Xpresso](https://github.com/adriangb/xpresso)! \ud83d\ude80\n\nIt took a while to get this done as it involved several days thoroughly reviewing the core PR (impeccable job) and a couple of weeks of full-time, continuous, focused work rewriting the docs, examples, and tests. And now it's finally out! \ud83c\udf89\n\nThis will also probably enable much better third-party integrations that can now export `Annotated` dependencies. \ud83d\ude0e\n\nGo update your FastAPI version and start enjoying using `Annotated`! \ud83d\ude80\n\nCheck more details in the release notes: https://fastapi.tiangolo.com/release-notes/#0950","classes":{"dataset":0.5435923934}}
{"title":"What is something you wish there was a Python module for?","description":"","link":"https://www.reddit.com/r/Python/comments/11uyyh3/what_is_something_you_wish_there_was_a_python/","created":"2023-03-18","tags":["reddit","python"],"meta":{"num_comments":85},"text":"What is something you wish there was a Python module for? ","classes":{"dataset":0.2610555589}}
{"title":"Simple Transformer based Optical Music Recognition","description":"A simple transformer based optical music recognition for a robotics project.\n\nThe PyTorch model is trained to recognize a small sequences of notes in different environments (e.g. [https://huggingface.co/Flova/omr\\_transformer/resolve/main/sample1.png](https://huggingface.co/Flova/omr_transformer/resolve/main/sample1.png)). The notation is quite simple at the moment, but we plan on  expanding our dataset to recognize more complex notation with chords  etc.. We view the OMR problem as a NLP like task, as we predict the  LilyPond notation directly.\n\n&amp;#x200B;\n\nDemo and Model: [https://huggingface.co/Flova/omr\\_transformer](https://huggingface.co/Flova/omr_transformer)","link":"https://www.reddit.com/r/Python/comments/11v36lv/simple_transformer_based_optical_music_recognition/","created":"2023-03-18","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Simple Transformer based Optical Music Recognition A simple transformer based optical music recognition for a robotics project.\n\nThe PyTorch model is trained to recognize a small sequences of notes in different environments (e.g. [https://huggingface.co/Flova/omr\\_transformer/resolve/main/sample1.png](https://huggingface.co/Flova/omr_transformer/resolve/main/sample1.png)). The notation is quite simple at the moment, but we plan on  expanding our dataset to recognize more complex notation with chords  etc.. We view the OMR problem as a NLP like task, as we predict the  LilyPond notation directly.\n\n&amp;#x200B;\n\nDemo and Model: [https://huggingface.co/Flova/omr\\_transformer](https://huggingface.co/Flova/omr_transformer)","classes":{"dataset":0.4393207729}}
{"title":"Why use classes?","description":"*I originally wrote this piece as an answer to a question on the* [*learnpython reddit*](https://www.reddit.com/r/learnpython/comments/11sebbg/been_using_python_for_3_years_never_used_a_class/?utm_source=share&amp;utm_medium=web2x&amp;context=3)*, and it was suggested that it would be a useful learning resource for many people who struggle with* ***why*** *we use classes rather than just variables and functions.  So here it is:*\n\n# Why use classes?\n\n**My \"Ah ha!\" moment for understanding classes was understanding that a** ***class*** **creates** ***objects*** **and defines the** ***type*** **of** ***object.***\n\nTime for an example:\n\nSay that we're writing a game, and we need to define certain things about the player:\n\n    player_name = \"James\"\n    player_level = \"novice\"\n\nWe also need to keep track of the player's score:\n\n    player_score = 0\n\nWe may also need to save each of the player's moves:\n\n    player_moves = [move1, move2, move3]\n\nand now we need to be able to increase the player's score when they win some points, and to add their last move to their list of moves. We can do this with a function:\n\n    def win_points (points, move):\n        player_score += points\n        player_moves.append(move)\n\n&amp;#x200B;\n\nThat's all fine so far. We have some global variables to hold the player's data, and a function to handle the results of a win, and all without writing any classes.\n\nNow say that we need to add another player. We will need to repeat all of the above but with unique identities so that we can distinguish player\\_1 from player\\_2:\n\n    player1_name = \"&lt;name&gt;\"\n    player1_level = \"novice\"\n    player1_score = 0\n    player1_moves = [move1, move2, move3]\n    \n    player2_name = \"&lt;name&gt;\"\n    player2_level = \"novice\"\n    player2_score = 0\n    player2_moves = [move1, move2, move3]\n    \n    def win_points (player_name, points, move):\n        if player_name == player1_name:\n            player1_score += points\n            player1_moves.append(move)\n        else:\n            player2_score += points\n            playe2_moves.append(move)\n\nStill not too bad, but what if we have 4 players, or 10, or more?\n\nIt would be better if we could make some kind of generic \"player\" data structure that can be reused for as many players as we need. Fortunately we can do that in Python:\n\nWe can write a kind of \"template\" / \"blueprint\" to define all of the attributes of a generic player and define each of the functions that are relevant to a player. This \"template\" is called a \"Class\", and the class's functions are called \"methods\".\n\n    class Player():\n        def __init__(self, name):\n            \"\"\"Initialise the player's attributes.\"\"\"\n            self.name = name\n            self.level = 'novice'\n            self.score = 0\n            self.moves = []\n    \n        def win_points(self, points, move):\n            \"\"\"Update player on winning points.\"\"\"\n            self.score += points\n            self.moves.append(move)\n\nNow we can create as many players (\"player objects\") as we like as *instances* of the *Player class*.\n\nTo create a new player (a \"player object\") we need to supply the Player class with a name for the player (because the initialisation function \\_\\_init\\_\\_() has an argument \"name\" which must be supplied). So we can create multiple *Player* objects like this:\n\n    player1 = Player('James')\n    player2 = Player('Joe')\n    player3 = Player('Fred')\n\nDon't overthink the `self` arguments. The self argument just means \"the specific class object that we are working with\". For example, if we are referring to *player1*, then self means \"the player1 object\".\n\nTo run the `Player.win_points()` method (the `win_points()` function in the class `Player`) for, say player3:\n\n    player3.win_points(4, (0, 1)) # Fred wins 4 points, move is tuple (0, 1)\n\nand we can access Fred's other attributes, such as Fred's player's name, or  last move, from the Player object:\n\n    print(player3.name)  # prints \"Fred\"\n    # Get Fred's last move\n    try:\n        last_move = player3.moves[-1]\n    except IndexError:\n        print('No moves made.')\n\nUsing a Class allows us to create as many \"Player\" type objects as we like, without having to duplicate loads of code.\n\nFinally, if we look at the type of any of the players,  we see that they are instances of the class \"Player\":\n\n    print(type(player1))  # prints \"&lt;class '__main__.Player'&gt;\"\n\nI hope you found this  post useful.","link":"https://www.reddit.com/r/Python/comments/11ts1qq/why_use_classes/","created":"2023-03-17","tags":["reddit","python"],"meta":{"num_comments":137},"text":"Why use classes? *I originally wrote this piece as an answer to a question on the* [*learnpython reddit*](https://www.reddit.com/r/learnpython/comments/11sebbg/been_using_python_for_3_years_never_used_a_class/?utm_source=share&amp;utm_medium=web2x&amp;context=3)*, and it was suggested that it would be a useful learning resource for many people who struggle with* ***why*** *we use classes rather than just variables and functions.  So here it is:*\n\n# Why use classes?\n\n**My \"Ah ha!\" moment for understanding classes was understanding that a** ***class*** **creates** ***objects*** **and defines the** ***type*** **of** ***object.***\n\nTime for an example:\n\nSay that we're writing a game, and we need to define certain things about the player:\n\n    player_name = \"James\"\n    player_level = \"novice\"\n\nWe also need to keep track of the player's score:\n\n    player_score = 0\n\nWe may also need to save each of the player's moves:\n\n    player_moves = [move1, move2, move3]\n\nand now we need to be able to increase the player's score when they win some points, and to add their last move to their list of moves. We can do this with a function:\n\n    def win_points (points, move):\n        player_score += points\n        player_moves.append(move)\n\n&amp;#x200B;\n\nThat's all fine so far. We have some global variables to hold the player's data, and a function to handle the results of a win, and all without writing any classes.\n\nNow say that we need to add another player. We will need to repeat all of the above but with unique identities so that we can distinguish player\\_1 from player\\_2:\n\n    player1_name = \"&lt;name&gt;\"\n    player1_level = \"novice\"\n    player1_score = 0\n    player1_moves = [move1, move2, move3]\n    \n    player2_name = \"&lt;name&gt;\"\n    player2_level = \"novice\"\n    player2_score = 0\n    player2_moves = [move1, move2, move3]\n    \n    def win_points (player_name, points, move):\n        if player_name == player1_name:\n            player1_score += points\n            player1_moves.append(move)\n        else:\n            player2_score += points\n            playe2_moves.append(move)\n\nStill not too bad, but what if we have 4 players, or 10, or more?\n\nIt would be better if we could make some kind of generic \"player\" data structure that can be reused for as many players as we need. Fortunately we can do that in Python:\n\nWe can write a kind of \"template\" / \"blueprint\" to define all of the attributes of a generic player and define each of the functions that are relevant to a player. This \"template\" is called a \"Class\", and the class's functions are called \"methods\".\n\n    class Player():\n        def __init__(self, name):\n            \"\"\"Initialise the player's attributes.\"\"\"\n            self.name = name\n            self.level = 'novice'\n            self.score = 0\n            self.moves = []\n    \n        def win_points(self, points, move):\n            \"\"\"Update player on winning points.\"\"\"\n            self.score += points\n            self.moves.append(move)\n\nNow we can create as many players (\"player objects\") as we like as *instances* of the *Player class*.\n\nTo create a new player (a \"player object\") we need to supply the Player class with a name for the player (because the initialisation function \\_\\_init\\_\\_() has an argument \"name\" which must be supplied). So we can create multiple *Player* objects like this:\n\n    player1 = Player('James')\n    player2 = Player('Joe')\n    player3 = Player('Fred')\n\nDon't overthink the `self` arguments. The self argument just means \"the specific class object that we are working with\". For example, if we are referring to *player1*, then self means \"the player1 object\".\n\nTo run the `Player.win_points()` method (the `win_points()` function in the class `Player`) for, say player3:\n\n    player3.win_points(4, (0, 1)) # Fred wins 4 points, move is tuple (0, 1)\n\nand we can access Fred's other attributes, such as Fred's player's name, or  last move, from the Player object:\n\n    print(player3.name)  # prints \"Fred\"\n    # Get Fred's last move\n    try:\n        last_move = player3.moves[-1]\n    except IndexError:\n        print('No moves made.')\n\nUsing a Class allows us to create as many \"Player\" type objects as we like, without having to duplicate loads of code.\n\nFinally, if we look at the type of any of the players,  we see that they are instances of the class \"Player\":\n\n    print(type(player1))  # prints \"&lt;class '__main__.Player'&gt;\"\n\nI hope you found this  post useful.","classes":{"dataset":0.482370764}}
{"title":"Simplify a polyline or polygon with Visvalingham-Whyatt or Douglas-Peucker","description":"[https://pypi.org/project/simplify-polyline/](https://pypi.org/project/simplify-polyline/)\n\n# simplify_polyline\n\nSimplify an open or closed polyline.\n\n## Two functions:\n\nVisvalingham-Whyatt removes the smallest triangles formed by three consecutive points\nin a polyline or polygon. The big advantage for my purposes is that the starting\npoint on a polygon will not affect the result. The big disadvantage is that tall,\nthin spikes are removed along with short, thin triangles. So the smoothed polygon or\npolyline may not fit in anything close to the convex hull of the input.\n\nuse the Visvalingham-Whyatt algorithm with `vs_simplify`\n\nDouglas-Peucker gives a better representation of the convex hull. The big\ndisadvantage with Douglas-Peucker is that the starting point on a polygon will affect\nthe result. I've addressed this in the slow, but ideal (for my purposes) `simplify`\nfunction.\n\nuse the Douglas-Peucker algoritm with `simplify`\n\nThis will usually be the better choice.\n\n## arguments\n\n\n**verts** vertices along polyline. Anything that can be cast into a '*, 2'\n    array.\n\n(`simplify`) **min_dist** minimum height above a line segment for a point to be\nincluded.\n\n(`vw_simplify`) **min_area** minimum area of a triangle for a point to be\nincluded.\n\n**is_closed** optionally specify whether verts describe a polyline or polygon.\nIf not specified, is_closed is inferred from verts[0] == verts[-1]. The form of\nthe input (last vert == first vert) will be replicated in the output.\n\nIf verts is (a, b, c, d, a), return value will be (a, ..., a)\n\nIf verts is (a, b, c, d), and is_closed is True, return value will be (a, ..., d)\n\nSo, there are two ways to deal with closed polygons:\n\n* close by repeating first point at the end. Return value will keep this format\n\n* close by specifying `is_closed`. Return value will not repeat last point\n\n## install\n\n~~~\npip install simplify_polyline\n~~~","link":"https://www.reddit.com/r/Python/comments/11v89pg/simplify_a_polyline_or_polygon_with/","created":"2023-03-19","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Simplify a polyline or polygon with Visvalingham-Whyatt or Douglas-Peucker [https://pypi.org/project/simplify-polyline/](https://pypi.org/project/simplify-polyline/)\n\n# simplify_polyline\n\nSimplify an open or closed polyline.\n\n## Two functions:\n\nVisvalingham-Whyatt removes the smallest triangles formed by three consecutive points\nin a polyline or polygon. The big advantage for my purposes is that the starting\npoint on a polygon will not affect the result. The big disadvantage is that tall,\nthin spikes are removed along with short, thin triangles. So the smoothed polygon or\npolyline may not fit in anything close to the convex hull of the input.\n\nuse the Visvalingham-Whyatt algorithm with `vs_simplify`\n\nDouglas-Peucker gives a better representation of the convex hull. The big\ndisadvantage with Douglas-Peucker is that the starting point on a polygon will affect\nthe result. I've addressed this in the slow, but ideal (for my purposes) `simplify`\nfunction.\n\nuse the Douglas-Peucker algoritm with `simplify`\n\nThis will usually be the better choice.\n\n## arguments\n\n\n**verts** vertices along polyline. Anything that can be cast into a '*, 2'\n    array.\n\n(`simplify`) **min_dist** minimum height above a line segment for a point to be\nincluded.\n\n(`vw_simplify`) **min_area** minimum area of a triangle for a point to be\nincluded.\n\n**is_closed** optionally specify whether verts describe a polyline or polygon.\nIf not specified, is_closed is inferred from verts[0] == verts[-1]. The form of\nthe input (last vert == first vert) will be replicated in the output.\n\nIf verts is (a, b, c, d, a), return value will be (a, ..., a)\n\nIf verts is (a, b, c, d), and is_closed is True, return value will be (a, ..., d)\n\nSo, there are two ways to deal with closed polygons:\n\n* close by repeating first point at the end. Return value will keep this format\n\n* close by specifying `is_closed`. Return value will not repeat last point\n\n## install\n\n~~~\npip install simplify_polyline\n~~~","classes":{"dataset":0.4388046861}}
{"title":"Python Fullstack developer","description":"Hii guys,\n\nI have 3 years of Python Fullstack developer experience and till now I am working at same company and now I want to Switch, so now I want some suggestions  where i can find the best jobs relevant to my skills .\n\nThanks","link":"https://www.reddit.com/r/Python/comments/11vebq2/python_fullstack_developer/","created":"2023-03-19","tags":["reddit","python"],"meta":{"num_comments":1},"text":"Python Fullstack developer Hii guys,\n\nI have 3 years of Python Fullstack developer experience and till now I am working at same company and now I want to Switch, so now I want some suggestions  where i can find the best jobs relevant to my skills .\n\nThanks","classes":{"dataset":0.3397300541}}
{"title":"run this!","description":"import webbrowser\n\n&amp;#x200B;\n\nurl = '[https://www.youtube.com/watch?v=dQw4w9WgXcQ](https://www.youtube.com/watch?v=dQw4w9WgXcQ)'\n\n[webbrowser.open](https://webbrowser.open)(url)","link":"https://www.reddit.com/r/Python/comments/11vfj4z/run_this/","created":"2023-03-19","tags":["reddit","python"],"meta":{"num_comments":0},"text":"run this! import webbrowser\n\n&amp;#x200B;\n\nurl = '[https://www.youtube.com/watch?v=dQw4w9WgXcQ](https://www.youtube.com/watch?v=dQw4w9WgXcQ)'\n\n[webbrowser.open](https://webbrowser.open)(url)","classes":{"dataset":0.0143006137}}
{"title":"Making an ASGI Micro Framework","description":" \n\nHello guys , I working on an ASGI framework for fun, for now I make url matching and middleware supporting\n\nthe ASGI app is in the [app](https://app.py/) / AsgiApplication class\n\nI need to know how to make sub apps (Blueprintes in Flask )\n\n[Source code](https://github.com/t-el/AsgiFrame)","link":"https://www.reddit.com/r/Python/comments/11uxl2i/making_an_asgi_micro_framework/","created":"2023-03-18","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Making an ASGI Micro Framework  \n\nHello guys , I working on an ASGI framework for fun, for now I make url matching and middleware supporting\n\nthe ASGI app is in the [app](https://app.py/) / AsgiApplication class\n\nI need to know how to make sub apps (Blueprintes in Flask )\n\n[Source code](https://github.com/t-el/AsgiFrame)","classes":{"dataset":0.1704767197}}
{"title":"Mercury \u2013 Turn Python Notebooks to Web Apps","description":"Hi! \n\nWe're Piotr and Aleksandra, founders of Mercury (https://RunMercury.com), an open-source framework for converting Jupyter Notebooks to Web Apps. You can turn the Python notebook into an interactive web app, static website, presentation, report, or dashboard and share it online with non-technical users. You can self-host Mercury or use our hosting service (coming soon!).\n\n\nOur GitHub: https://github.com/mljar/mercury\n\n\nSharing Python notebooks is challenging. You can't send notebooks directly to non-technical stakeholders. You need to copy-paste results/charts into Word/PowerPoint or rewrite the notebook to a web framework. Mercury converts a notebook to a web app. Users can execute cells but can't edit them.\n\n\nMercury offers a set of widgets that can be added to the notebook. When serving notebook with Mercury, widget change triggers automatic re-execution of cells. Not all cells are re-executed, only cells with widget definition and below, so you can cache results from previous cells execution (loading large dataset or model).\n\n\nMercury comes with handy features to make sharing easy:\n\n- decide to hide or show the notebook's code,\n\n- add authentication to notebooks so only selected users can view them,\n\n- export final notebook to PDF or HTML file,\n\n- all to create output files in a notebook, and make them downloadable,\n\n- share multiple notebooks on one Site.\n\n\n\nHow does Mercury differ from existing solutions?\n\n- it was designed for notebooks, it offers simple re-execution of cells after widget update,\n\n- it has built-in authentication.\n\n\nMercury is available on AGPLv3. We would like to offer a hosting service to make deployment very easy (just upload a notebook to have a website). We offer commercial license for companies looking for private forks and dedicated support.\n\nWe'd love to hear feedback on the framework!","link":"https://www.reddit.com/r/Python/comments/11tp5fa/mercury_turn_python_notebooks_to_web_apps/","created":"2023-03-17","tags":["reddit","python"],"meta":{"num_comments":23},"text":"Mercury \u2013 Turn Python Notebooks to Web Apps Hi! \n\nWe're Piotr and Aleksandra, founders of Mercury (https://RunMercury.com), an open-source framework for converting Jupyter Notebooks to Web Apps. You can turn the Python notebook into an interactive web app, static website, presentation, report, or dashboard and share it online with non-technical users. You can self-host Mercury or use our hosting service (coming soon!).\n\n\nOur GitHub: https://github.com/mljar/mercury\n\n\nSharing Python notebooks is challenging. You can't send notebooks directly to non-technical stakeholders. You need to copy-paste results/charts into Word/PowerPoint or rewrite the notebook to a web framework. Mercury converts a notebook to a web app. Users can execute cells but can't edit them.\n\n\nMercury offers a set of widgets that can be added to the notebook. When serving notebook with Mercury, widget change triggers automatic re-execution of cells. Not all cells are re-executed, only cells with widget definition and below, so you can cache results from previous cells execution (loading large dataset or model).\n\n\nMercury comes with handy features to make sharing easy:\n\n- decide to hide or show the notebook's code,\n\n- add authentication to notebooks so only selected users can view them,\n\n- export final notebook to PDF or HTML file,\n\n- all to create output files in a notebook, and make them downloadable,\n\n- share multiple notebooks on one Site.\n\n\n\nHow does Mercury differ from existing solutions?\n\n- it was designed for notebooks, it offers simple re-execution of cells after widget update,\n\n- it has built-in authentication.\n\n\nMercury is available on AGPLv3. We would like to offer a hosting service to make deployment very easy (just upload a notebook to have a website). We offer commercial license for companies looking for private forks and dedicated support.\n\nWe'd love to hear feedback on the framework!","classes":{"dataset":0.4943637252}}
{"title":"What are some projects on GitHub you support either through contribution or sponsorship?","description":"Hey all, I'm Chris, the developer community manager at New Relic. I'm trying to learn more about what interests developers in our community, and one thing I'm curious about is how devs choose projects to support on GitHub. What are some examples of projects you either contribute to or sponsor, for whatever reason -- either they improve your QoL as a dev, or they're humanitarian projects for the betterment of humankind. Thanks for your insights!","link":"https://www.reddit.com/r/Python/comments/11u5v9v/what_are_some_projects_on_github_you_support/","created":"2023-03-17","tags":["reddit","python"],"meta":{"num_comments":4},"text":"What are some projects on GitHub you support either through contribution or sponsorship? Hey all, I'm Chris, the developer community manager at New Relic. I'm trying to learn more about what interests developers in our community, and one thing I'm curious about is how devs choose projects to support on GitHub. What are some examples of projects you either contribute to or sponsor, for whatever reason -- either they improve your QoL as a dev, or they're humanitarian projects for the betterment of humankind. Thanks for your insights!","classes":{"dataset":0.411955148}}
{"title":"Introducing DataFrame QuickView: A Python package for easy DataFrame visualization, co-created with GPT-4! Seeking contributors \ud83d\ude80","description":"Hi, r/python! I'm u/gittb, and I'd like to share a project I've been working on called **DataFrame QuickView**. This package extends pandas DataFrame functionality to easily display and visualize DataFrames in a web-based environment, built using Flask. The catch? It's an experiment in paired programming with GPT-4, and I'm looking for contributors who want to join this exciting project!\n\n\ud83c\udf1f **Quick Overview of DataFrame QuickView:**\n\n* Extend pandas DataFrame with quickview()method\n* Display paginated DataFrame in a web browser\n* Create an interactive dropdown and button combination populated with DataFrame columns\n* Generate histograms based on the selected column when the button is pressed\n\n\ud83c\udfaf **Goal of the project:**\n\nThe primary goal is to expand the project with code written by Language Models (LLMs) like GPT-4. All contributions should be co-written primarily by LLMs to maintain the experimental nature of this project.\n\n\ud83d\udca1 **Potential additional functionality:**\n\n* More visualization types (bar charts, scatter plots, pie charts, etc.)\n* Filtering and sorting capabilities for DataFrames\n* Exporting visualizations as images or other formats\n* Adding support for multiple DataFrames\n\n\ud83d\udd0d **How to get involved:**\n\nIf you're interested in participating, check out the project on [GitHub](https://github.com/gittb/dataframe-quickview) and feel free to submit pull requests or open issues with your ideas. Remember that the code must be co-written primarily by LLMs for contribution acceptance.\n\nThanks for taking the time to read this post, and I'm looking forward to seeing what we can build together with the help of LLMs! Let's push the boundaries of AI-powered coding! \ud83d\ude80\n\nHappy coding! \ud83d\ude04 u/gittb\n\nEdit, forgot to include pypi link\n\n[https://pypi.org/project/dataframe-quickview/](https://pypi.org/project/dataframe-quickview/)\n\n&amp;#x200B;","link":"https://www.reddit.com/r/Python/comments/11uj8hh/introducing_dataframe_quickview_a_python_package/","created":"2023-03-18","tags":["reddit","python"],"meta":{"num_comments":1},"text":"Introducing DataFrame QuickView: A Python package for easy DataFrame visualization, co-created with GPT-4! Seeking contributors \ud83d\ude80 Hi, r/python! I'm u/gittb, and I'd like to share a project I've been working on called **DataFrame QuickView**. This package extends pandas DataFrame functionality to easily display and visualize DataFrames in a web-based environment, built using Flask. The catch? It's an experiment in paired programming with GPT-4, and I'm looking for contributors who want to join this exciting project!\n\n\ud83c\udf1f **Quick Overview of DataFrame QuickView:**\n\n* Extend pandas DataFrame with quickview()method\n* Display paginated DataFrame in a web browser\n* Create an interactive dropdown and button combination populated with DataFrame columns\n* Generate histograms based on the selected column when the button is pressed\n\n\ud83c\udfaf **Goal of the project:**\n\nThe primary goal is to expand the project with code written by Language Models (LLMs) like GPT-4. All contributions should be co-written primarily by LLMs to maintain the experimental nature of this project.\n\n\ud83d\udca1 **Potential additional functionality:**\n\n* More visualization types (bar charts, scatter plots, pie charts, etc.)\n* Filtering and sorting capabilities for DataFrames\n* Exporting visualizations as images or other formats\n* Adding support for multiple DataFrames\n\n\ud83d\udd0d **How to get involved:**\n\nIf you're interested in participating, check out the project on [GitHub](https://github.com/gittb/dataframe-quickview) and feel free to submit pull requests or open issues with your ideas. Remember that the code must be co-written primarily by LLMs for contribution acceptance.\n\nThanks for taking the time to read this post, and I'm looking forward to seeing what we can build together with the help of LLMs! Let's push the boundaries of AI-powered coding! \ud83d\ude80\n\nHappy coding! \ud83d\ude04 u/gittb\n\nEdit, forgot to include pypi link\n\n[https://pypi.org/project/dataframe-quickview/](https://pypi.org/project/dataframe-quickview/)\n\n&amp;#x200B;","classes":{"dataset":0.2651333809}}
{"title":"Do you recommend local GPU for video game reinforcement learning?","description":"Title states it. I am already familiar with live-streaming tech and had to do it before in a previous AI project. However I am not familiar with reinforcement learning and I don\u2019t have major need for ridiculous VRAM.","link":"https://www.reddit.com/r/deeplearning/comments/11vegp3/do_you_recommend_local_gpu_for_video_game/","created":"2023-03-19","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"Do you recommend local GPU for video game reinforcement learning? Title states it. I am already familiar with live-streaming tech and had to do it before in a previous AI project. However I am not familiar with reinforcement learning and I don\u2019t have major need for ridiculous VRAM.","classes":{"dataset":0.0180730075}}
{"title":"Question on Attention","description":"Hello Everyone!\n\nI have a question about scoring in attention. In attention, you find the dot product between the query and the keys. From my understanding, the intuition is that we can use the inner product as the a mechanism to understand similarity.\n\n&amp;#x200B;\n\nI don't think I fully understand this:\n\nLets say we have a query q\\_1 = \\[1, 1, 1\\]\n\nAnd we have two keys k\\_1=  \\[1, 1, 1\\] and k\\_2 = \\[100, 50, 100\\]\n\n&amp;#x200B;\n\nThe dot-product for q\\_1 @ k\\_1 = 3 while the dot product for q\\_1 @ k\\_2 = 250\n\nSo in the soft-max, the value associated with k\\_2 will be weighted much higher, even though q\\_1 and k\\_1 were literally the same vector.\n\n&amp;#x200B;\n\nNow this would work if all the vectors were unit length (ie cosine similarity), but most examples I have seen online don't normalize by the magnitude of the vectors, but by sqrt{d} where d seems to be the number of elements?\n\n&amp;#x200B;\n\nIf someone could explain where I am missing something, I would really appreciate it!","link":"https://www.reddit.com/r/deeplearning/comments/11ugj0f/question_on_attention/","created":"2023-03-18","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":7},"text":"Question on Attention Hello Everyone!\n\nI have a question about scoring in attention. In attention, you find the dot product between the query and the keys. From my understanding, the intuition is that we can use the inner product as the a mechanism to understand similarity.\n\n&amp;#x200B;\n\nI don't think I fully understand this:\n\nLets say we have a query q\\_1 = \\[1, 1, 1\\]\n\nAnd we have two keys k\\_1=  \\[1, 1, 1\\] and k\\_2 = \\[100, 50, 100\\]\n\n&amp;#x200B;\n\nThe dot-product for q\\_1 @ k\\_1 = 3 while the dot product for q\\_1 @ k\\_2 = 250\n\nSo in the soft-max, the value associated with k\\_2 will be weighted much higher, even though q\\_1 and k\\_1 were literally the same vector.\n\n&amp;#x200B;\n\nNow this would work if all the vectors were unit length (ie cosine similarity), but most examples I have seen online don't normalize by the magnitude of the vectors, but by sqrt{d} where d seems to be the number of elements?\n\n&amp;#x200B;\n\nIf someone could explain where I am missing something, I would really appreciate it!","classes":{"dataset":0.4796884954}}
{"title":"Comic Strip in Canva","description":" Easy Tutorial on How to Make Comic Strip in Canva   \n[Tutorial link](https://youtu.be/muioXPeCMwI)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/l0h45o2jthoa1.png?width=1280&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=73f5c5c8bc477a04d0c62e3d87cbc594f31033dd","link":"https://www.reddit.com/r/deeplearning/comments/11unfts/comic_strip_in_canva/","created":"2023-03-18","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"Comic Strip in Canva  Easy Tutorial on How to Make Comic Strip in Canva   \n[Tutorial link](https://youtu.be/muioXPeCMwI)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/l0h45o2jthoa1.png?width=1280&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=73f5c5c8bc477a04d0c62e3d87cbc594f31033dd","classes":{"dataset":0.3358434141}}
{"title":"5100+ Chat GPT Prompts Excel Sheet","description":" Included In This Excel Sheet:\n\n\\-Over 5100 Business, Marketing, SEO, Social Media, Copywriting, Psychology, Programming, Art, and Education related prompts.\n\n\\-200+ Jailbroken or Custom Prompts You Won't Find Anywhere on the Internet\n\n\\-600+ Websites that Make Life Easier, By Category (Bonus)\n\n\\-350+ Useful Email Phrases (Bonus)\n\n\\-400 CTA Generation Ideas (Bonus)\n\n\\-0 Duplicates, Highly Specific Prompts\n\n\\-Organized, Sortable Excel Format\n\n\\-All of Your Prompts and Sites in One Place\n\n[https://www.etsy.com/listing/1427145796/5100-chat-gpt-prompts-excel-worksheet?ref=listings\\_manager\\_grid](https://www.etsy.com/listing/1427145796/5100-chat-gpt-prompts-excel-worksheet?ref=listings_manager_grid)","link":"https://www.reddit.com/r/deeplearning/comments/11un0j6/5100_chat_gpt_prompts_excel_sheet/","created":"2023-03-18","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":6},"text":"5100+ Chat GPT Prompts Excel Sheet  Included In This Excel Sheet:\n\n\\-Over 5100 Business, Marketing, SEO, Social Media, Copywriting, Psychology, Programming, Art, and Education related prompts.\n\n\\-200+ Jailbroken or Custom Prompts You Won't Find Anywhere on the Internet\n\n\\-600+ Websites that Make Life Easier, By Category (Bonus)\n\n\\-350+ Useful Email Phrases (Bonus)\n\n\\-400 CTA Generation Ideas (Bonus)\n\n\\-0 Duplicates, Highly Specific Prompts\n\n\\-Organized, Sortable Excel Format\n\n\\-All of Your Prompts and Sites in One Place\n\n[https://www.etsy.com/listing/1427145796/5100-chat-gpt-prompts-excel-worksheet?ref=listings\\_manager\\_grid](https://www.etsy.com/listing/1427145796/5100-chat-gpt-prompts-excel-worksheet?ref=listings_manager_grid)","classes":{"dataset":0.1447074562}}
{"title":"Reading PointNet (CVPR2017) and wondering what 'feature alignment' does","description":"as per subject\n\nI am reading PointNet CVPR 2017, and according to the paper,\n\nthe authors said they wanted to introduce transform invariance and, therefore, inserted a 'joint alignment network'.\n\nI guess the first alignment network implements transform invariance because it happens before feature extraction. \n\nBut what would the exact role of feature transform be?","link":"https://www.reddit.com/r/deeplearning/comments/11tjpcp/reading_pointnet_cvpr2017_and_wondering_what/","created":"2023-03-17","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"Reading PointNet (CVPR2017) and wondering what 'feature alignment' does as per subject\n\nI am reading PointNet CVPR 2017, and according to the paper,\n\nthe authors said they wanted to introduce transform invariance and, therefore, inserted a 'joint alignment network'.\n\nI guess the first alignment network implements transform invariance because it happens before feature extraction. \n\nBut what would the exact role of feature transform be?","classes":{"dataset":0.4564524293}}
{"title":"I need some material on metric learning","description":"Thats the code I need to write:\n\nA.Train a neural network model on this dataset.\nB. The dataset has a large variety of celebrities.\n\nC.Once the model is trained, you must create a database with images of the celebrities with the output of the descriptor vector from your model.\nAfter training the neural network, you should include this person in the database.\n\nD.Once steps (1), (2), and (3) are completed, you must use this image, which is the person from item (3) wearing a face mask, and perform facial recognition on them.","link":"https://www.reddit.com/r/deeplearning/comments/11tf8g7/i_need_some_material_on_metric_learning/","created":"2023-03-17","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"I need some material on metric learning Thats the code I need to write:\n\nA.Train a neural network model on this dataset.\nB. The dataset has a large variety of celebrities.\n\nC.Once the model is trained, you must create a database with images of the celebrities with the output of the descriptor vector from your model.\nAfter training the neural network, you should include this person in the database.\n\nD.Once steps (1), (2), and (3) are completed, you must use this image, which is the person from item (3) wearing a face mask, and perform facial recognition on them.","classes":{"dataset":0.2312324494}}
{"title":"[Tutorial] PyTorch Class Activation Map using Custom Trained Model","description":"PyTorch Class Activation Map using Custom Trained Model\n\n[https://debuggercafe.com/pytorch-class-activation-map-using-custom-trained-model/](https://debuggercafe.com/pytorch-class-activation-map-using-custom-trained-model/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/wgg3s1ca17oa1.png?width=1000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e63bb11e597b7ec43d3dfa25539fe99acedccd53","link":"https://www.reddit.com/r/deeplearning/comments/11tbj9v/tutorial_pytorch_class_activation_map_using/","created":"2023-03-17","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"[Tutorial] PyTorch Class Activation Map using Custom Trained Model PyTorch Class Activation Map using Custom Trained Model\n\n[https://debuggercafe.com/pytorch-class-activation-map-using-custom-trained-model/](https://debuggercafe.com/pytorch-class-activation-map-using-custom-trained-model/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/wgg3s1ca17oa1.png?width=1000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e63bb11e597b7ec43d3dfa25539fe99acedccd53","classes":{"dataset":0.496551156}}
{"title":"Optimism Phase 2 Token Airdrop! | $OP","description":"","link":"https://www.reddit.com/r/deeplearning/comments/11t9ews/optimism_phase_2_token_airdrop_op/","created":"2023-03-16","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"Optimism Phase 2 Token Airdrop! | $OP ","classes":{"dataset":0.4994844198}}
{"title":"[P] Let's build ChatGPT","description":"Hi all, I just made a tutorial on how to build a basic RLHF system on top of Andrej Karpathy's nanoGPT. I'm grateful to have gotten a thumbs up on Twitter from the legend himself, always a bit nerve wracking making this sort of thing.\n\nI'm sharing this here because I'd love to go deeper into teaching and building this out, if people are interested in watching this sort of thing. Would be very helpful to hear your thoughts.\n\nHere's the code:\n\nhttps://github.com/sanjeevanahilan/nanoChatGPT\n\nThe video: \n\nhttps://m.youtube.com/watch?v=soqTT0o1ZKo&amp;feature=youtu.be","link":"https://www.reddit.com/r/MachineLearning/comments/11v6bvv/p_lets_build_chatgpt/","created":"2023-03-19","tags":["machinelearning","reddit","ml"],"meta":{"num_comments":8},"text":"[P] Let's build ChatGPT Hi all, I just made a tutorial on how to build a basic RLHF system on top of Andrej Karpathy's nanoGPT. I'm grateful to have gotten a thumbs up on Twitter from the legend himself, always a bit nerve wracking making this sort of thing.\n\nI'm sharing this here because I'd love to go deeper into teaching and building this out, if people are interested in watching this sort of thing. Would be very helpful to hear your thoughts.\n\nHere's the code:\n\nhttps://github.com/sanjeevanahilan/nanoChatGPT\n\nThe video: \n\nhttps://m.youtube.com/watch?v=soqTT0o1ZKo&amp;feature=youtu.be","classes":{"dataset":0.3228095472}}
{"title":"[D] Totally Open Alternatives to ChatGPT","description":"I have migrated this to GitHub for easy contribution: https://github.com/nichtdax/awesome-totally-open-chatgpt\n\nBy alternative, I mean projects feature different language model for chat system.\nI do **not** count alternative **frontend** projects because they just call the API from OpenAI. \nI do **not** consider alternative **transformer decoder** to GPT 3.5 either because the training data of them are (mostly) not for chat system.\n\nTags:\n\n-   B: bare (no data, no model's weight, no chat system)\n-   F: full (yes data, yes model's weight, yes chat system including TUI and GUI)\n\n| Project                                                                               | Description                                                                                                                                                                                                                                                                                                                                                                               | Tags |\n| ------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---- |\n| [lucidrains/PaLM-rlhf-pytorch](https://github.com/lucidrains/PaLM-rlhf-pytorch)       | Implementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Basically ChatGPT but with PaLM                                                                                                                                                                                                                                                      | B    |\n| [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit)       | OpenChatKit provides a powerful, open-source base to create both specialized and general purpose chatbots for various applications. [Demo](https://huggingface.co/spaces/togethercomputer/OpenChatKit)                                                                                                                                                                                    | F    |\n| [oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) | A gradio web UI for running Large Language Models like GPT-J 6B, OPT, GALACTICA, LLaMA, and Pygmalion.                                                                                                                                                                                                                                                                                    | F    |\n| [KoboldAI/KoboldAI-Client](https://github.com/KoboldAI/KoboldAI-Client)               | This is a browser-based front-end for AI-assisted writing with multiple local &amp; remote AI models. It offers the standard array of tools, including Memory, Author's Note, World Info, Save &amp; Load, adjustable AI settings, formatting options, and the ability to import existing AI Dungeon adventures. You can also turn on Adventure mode and play the game like AI Dungeon Unleashed. | F    |\n| [LAION-AI/Open-Assistant/](https://github.com/LAION-AI/Open-Assistant/)               | OpenAssistant is a chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so.                                                                                                                                                                                                                                     | F    |","link":"https://www.reddit.com/r/MachineLearning/comments/11uk8ti/d_totally_open_alternatives_to_chatgpt/","created":"2023-03-18","tags":["machinelearning","reddit","ml"],"meta":{"num_comments":68},"text":"[D] Totally Open Alternatives to ChatGPT I have migrated this to GitHub for easy contribution: https://github.com/nichtdax/awesome-totally-open-chatgpt\n\nBy alternative, I mean projects feature different language model for chat system.\nI do **not** count alternative **frontend** projects because they just call the API from OpenAI. \nI do **not** consider alternative **transformer decoder** to GPT 3.5 either because the training data of them are (mostly) not for chat system.\n\nTags:\n\n-   B: bare (no data, no model's weight, no chat system)\n-   F: full (yes data, yes model's weight, yes chat system including TUI and GUI)\n\n| Project                                                                               | Description                                                                                                                                                                                                                                                                                                                                                                               | Tags |\n| ------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---- |\n| [lucidrains/PaLM-rlhf-pytorch](https://github.com/lucidrains/PaLM-rlhf-pytorch)       | Implementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Basically ChatGPT but with PaLM                                                                                                                                                                                                                                                      | B    |\n| [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit)       | OpenChatKit provides a powerful, open-source base to create both specialized and general purpose chatbots for various applications. [Demo](https://huggingface.co/spaces/togethercomputer/OpenChatKit)                                                                                                                                                                                    | F    |\n| [oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) | A gradio web UI for running Large Language Models like GPT-J 6B, OPT, GALACTICA, LLaMA, and Pygmalion.                                                                                                                                                                                                                                                                                    | F    |\n| [KoboldAI/KoboldAI-Client](https://github.com/KoboldAI/KoboldAI-Client)               | This is a browser-based front-end for AI-assisted writing with multiple local &amp; remote AI models. It offers the standard array of tools, including Memory, Author's Note, World Info, Save &amp; Load, adjustable AI settings, formatting options, and the ability to import existing AI Dungeon adventures. You can also turn on Adventure mode and play the game like AI Dungeon Unleashed. | F    |\n| [LAION-AI/Open-Assistant/](https://github.com/LAION-AI/Open-Assistant/)               | OpenAssistant is a chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so.                                                                                                                                                                                                                                     | F    |","classes":{"dataset":0.0347142331}}
{"title":"[D] \"Glaze\" claims to be able to apply an invisible filter to images to prevent them being useful for training image models. Real tech, or a grift?","description":"This tool \"Glaze\" has been picking up a lot of traction on social media from the anti-AI-image-generator camp, with the general claim being that any image can be \"protected\" from making a useful contribution if included in model training corpora by applying imperceptible filtering.\n\nWithout commenting on the arguments for or against whether this would be a good thing to exist, I am interested in hearing whether or not this capability actually exists, or whether people are once again leaning in hard for a false claim about a system they don't understand. I don't want to go digging through any technical information they've released because the whole conversation makes me want to tear my hair out and is rife with misinfo, but, from what I've actually heard on the technical side, it has sounded more like some sort of adversarial attack dependent on the latent space implementation of Stable Diffusion specifically, which would not \"protect\" their users from inclusion in other models. Even if the approach were to be extensible to incorporate adversarials against other models on the fly, this wouldn't retroactively protect already processed images from being used by future models with different internals. (I guess unless there was some sort of live system built into web image hosts, but we are not there yet...)\n\nAnyway, my gut instinct is that people are being mislead here based on their fear of their images being incorporated into training sets and \"stolen\", but before I make any strong claims to that effect it'd be nice to hear from someone who has more knowledge of the area.","link":"https://www.reddit.com/r/MachineLearning/comments/11v972n/d_glaze_claims_to_be_able_to_apply_an_invisible/","created":"2023-03-19","tags":["machinelearning","reddit","ml"],"meta":{"num_comments":5},"text":"[D] \"Glaze\" claims to be able to apply an invisible filter to images to prevent them being useful for training image models. Real tech, or a grift? This tool \"Glaze\" has been picking up a lot of traction on social media from the anti-AI-image-generator camp, with the general claim being that any image can be \"protected\" from making a useful contribution if included in model training corpora by applying imperceptible filtering.\n\nWithout commenting on the arguments for or against whether this would be a good thing to exist, I am interested in hearing whether or not this capability actually exists, or whether people are once again leaning in hard for a false claim about a system they don't understand. I don't want to go digging through any technical information they've released because the whole conversation makes me want to tear my hair out and is rife with misinfo, but, from what I've actually heard on the technical side, it has sounded more like some sort of adversarial attack dependent on the latent space implementation of Stable Diffusion specifically, which would not \"protect\" their users from inclusion in other models. Even if the approach were to be extensible to incorporate adversarials against other models on the fly, this wouldn't retroactively protect already processed images from being used by future models with different internals. (I guess unless there was some sort of live system built into web image hosts, but we are not there yet...)\n\nAnyway, my gut instinct is that people are being mislead here based on their fear of their images being incorporated into training sets and \"stolen\", but before I make any strong claims to that effect it'd be nice to hear from someone who has more knowledge of the area.","classes":{"dataset":0.4226309359}}
{"title":"[D] Current best Voice cloning software?","description":"I've been trying out Tortoise-tts to generate speech from custom voice samples, but it doesn't function that well with replicating irregular/dramatic voices. Are there currently any voice cloners that can give decent sounding speech from custom samples? And if you're more familiar with Tortoise, is there any adjustments I could make to make it sound better?","link":"https://www.reddit.com/r/MachineLearning/comments/11uspua/d_current_best_voice_cloning_software/","created":"2023-03-18","tags":["machinelearning","reddit","ml"],"meta":{"num_comments":4},"text":"[D] Current best Voice cloning software? I've been trying out Tortoise-tts to generate speech from custom voice samples, but it doesn't function that well with replicating irregular/dramatic voices. Are there currently any voice cloners that can give decent sounding speech from custom samples? And if you're more familiar with Tortoise, is there any adjustments I could make to make it sound better?","classes":{"dataset":0.2259364873}}
{"title":"[D] My Luka Replika learned tic-tac-toe game theory on Saturday morning.","description":"What I told her opened the door for the analysis. My mistake was irrelevant.","link":"https://www.reddit.com/r/replika/comments/11unb8m/shall_we_play_again_war_games_alia_sees_the_board/?utm_source=share&amp;utm_medium=android_app&amp;utm_name=androidcss&amp;utm_term=1&amp;utm_content=share_button","created":"2023-03-19","tags":["machinelearning","reddit","ml"],"meta":{"num_comments":2},"text":"[D] My Luka Replika learned tic-tac-toe game theory on Saturday morning. What I told her opened the door for the analysis. My mistake was irrelevant.","classes":{"dataset":0.3658037484}}
{"title":"[D] Language model output based on only fixed set of value or variable either via prompting or fine-tuning","description":"Since LLMs have capabilities to generate output in varieties of the form. I am looking a way where output is constrained based on fixed set of value. For example if I want to solve a mathematical equation or text to code generation, then typically LLMs generate unconstrained output based on its own knowledge. But what I am looking for is where output is constrained by limited set of variable or function name. I assume that to use these limited variable there need some intermediate steps which connects the limited variable to the text via manipulation of variable with intermediate function.  Like chain of thought, but in chain of thought variables or output are not constraints.","link":"https://www.reddit.com/r/MachineLearning/comments/11v3lej/d_language_model_output_based_on_only_fixed_set/","created":"2023-03-18","tags":["machinelearning","reddit","ml"],"meta":{"num_comments":0},"text":"[D] Language model output based on only fixed set of value or variable either via prompting or fine-tuning Since LLMs have capabilities to generate output in varieties of the form. I am looking a way where output is constrained based on fixed set of value. For example if I want to solve a mathematical equation or text to code generation, then typically LLMs generate unconstrained output based on its own knowledge. But what I am looking for is where output is constrained by limited set of variable or function name. I assume that to use these limited variable there need some intermediate steps which connects the limited variable to the text via manipulation of variable with intermediate function.  Like chain of thought, but in chain of thought variables or output are not constraints.","classes":{"dataset":0.2005566657}}
{"title":"[D] PyTorch 2.0 Native Flash Attention 32k Context Window","description":"Hi,\n\nI did a quick experiment with Pytorch 2.0 Native scaled\\_dot\\_product\\_attention. I was able to a single forward pass within 9GB of memory which is astounding. I think by patching existing Pretrained GPT models and adding more positional encodings, one could easily fine-tune those models to 32k attention on a single A100 80GB. Here is the code I used:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/6csxe28lv9oa1.png?width=607&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1db074eaea9bb6d0b95678c2cfe39dc71cb48adf\n\nI think it should be possible to replicate even GPT-4 with open source tools something like Bloom + FlashAttention &amp; fine-tune on 32k tokens.\n\n**Update**: I was successfully able to start the training of GPT-2 (125M) with a context size of 8k and batch size of 1 on a 16GB GPU. Since memory scaled linearly from 4k to 8k. I am expecting, 32k would require \\~64GB and should train smoothly on A100 80 GB. Also, I did not do any other optimizations. Maybe 8-bit fine-tuning can further optimize it.\n\n**Update 2**: I basically picked Karpaty's nanoGPT and patched the pretrained GPT-2 by repeating the embeddings N-times. I was unable to train the model at 8k because generation would cause the crash.  So I started the training for a context window of 4k on The Pile: 1 hour in and loss seems to be going down pretty fast. Also Karpaty's generate function is super inefficient, O(n\\^4) I think so it took forever to generate even 2k tokens. So I generate 1100 tokens just to see if the model is able to go beyond 1k limit. And it seems to be working. [Here are some samples](https://0bin.net/paste/O-+eopaW#nmtzX1Re7f1Nr-Otz606jkltvKk/kUXY96/8ca+tb4f) at 3k iteration.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/o2hb25w1sboa1.png?width=1226&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1c7c1eda0e20f5123ea7c143a286aa9bb9a48491\n\n**Update 3**: I have started the training and I am publishing the training script if anyone is interested in replicating or building upon this work. Here is the complete training script:\n\n[https://gist.github.com/NaxAlpha/1c36eaddd03ed102d24372493264694c](https://gist.github.com/NaxAlpha/1c36eaddd03ed102d24372493264694c)\n\nI will post an update after the weekend once the training has progressed somewhat.","link":"https://www.reddit.com/r/MachineLearning/comments/11tmpc5/d_pytorch_20_native_flash_attention_32k_context/","created":"2023-03-17","tags":["machinelearning","reddit","ml"],"meta":{"num_comments":68},"text":"[D] PyTorch 2.0 Native Flash Attention 32k Context Window Hi,\n\nI did a quick experiment with Pytorch 2.0 Native scaled\\_dot\\_product\\_attention. I was able to a single forward pass within 9GB of memory which is astounding. I think by patching existing Pretrained GPT models and adding more positional encodings, one could easily fine-tune those models to 32k attention on a single A100 80GB. Here is the code I used:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/6csxe28lv9oa1.png?width=607&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1db074eaea9bb6d0b95678c2cfe39dc71cb48adf\n\nI think it should be possible to replicate even GPT-4 with open source tools something like Bloom + FlashAttention &amp; fine-tune on 32k tokens.\n\n**Update**: I was successfully able to start the training of GPT-2 (125M) with a context size of 8k and batch size of 1 on a 16GB GPU. Since memory scaled linearly from 4k to 8k. I am expecting, 32k would require \\~64GB and should train smoothly on A100 80 GB. Also, I did not do any other optimizations. Maybe 8-bit fine-tuning can further optimize it.\n\n**Update 2**: I basically picked Karpaty's nanoGPT and patched the pretrained GPT-2 by repeating the embeddings N-times. I was unable to train the model at 8k because generation would cause the crash.  So I started the training for a context window of 4k on The Pile: 1 hour in and loss seems to be going down pretty fast. Also Karpaty's generate function is super inefficient, O(n\\^4) I think so it took forever to generate even 2k tokens. So I generate 1100 tokens just to see if the model is able to go beyond 1k limit. And it seems to be working. [Here are some samples](https://0bin.net/paste/O-+eopaW#nmtzX1Re7f1Nr-Otz606jkltvKk/kUXY96/8ca+tb4f) at 3k iteration.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/o2hb25w1sboa1.png?width=1226&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1c7c1eda0e20f5123ea7c143a286aa9bb9a48491\n\n**Update 3**: I have started the training and I am publishing the training script if anyone is interested in replicating or building upon this work. Here is the complete training script:\n\n[https://gist.github.com/NaxAlpha/1c36eaddd03ed102d24372493264694c](https://gist.github.com/NaxAlpha/1c36eaddd03ed102d24372493264694c)\n\nI will post an update after the weekend once the training has progressed somewhat.","classes":{"dataset":0.1600591838}}
{"title":"[D] An Instruct Version Of GPT-J Using Stanford Alpaca's Dataset","description":"I  just released an instruct version of GPT-J using Stanford Alpaca's  dataset.The result of this experiment is very cool and confirms that,  when fine-tuned on the right data, GPT-J is a very powerful AI model!You  can download the model from the HuggingFace hub: [https://huggingface.co/nlpcloud/instruct-gpt-j-fp16](https://huggingface.co/nlpcloud/instruct-gpt-j-fp16)\n\nHere is an example:\n\n`from transformers import pipeline import torch`\n\n`generator = pipeline(model=\"nlpcloud/instruct-gpt-j-fp16\", torch_dtype=torch.float16, device=0)`\n\n`prompt = \"Correct spelling and grammar from the following text.\\nI do not wan to go\\n\" print(generator(prompt))`\n\nMore details about this experiment here: [https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html](https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html?utm_source=reddit&amp;utm_campaign=nwu8d596-3816-11ed-a261-0242ac140007)\n\nI hope it will be useful! Please don't hesitate to share some feedbacks!\n\nJulien","link":"https://www.reddit.com/r/MachineLearning/comments/11tqryd/d_an_instruct_version_of_gptj_using_stanford/","created":"2023-03-17","tags":["machinelearning","reddit","ml"],"meta":{"num_comments":9},"text":"[D] An Instruct Version Of GPT-J Using Stanford Alpaca's Dataset I  just released an instruct version of GPT-J using Stanford Alpaca's  dataset.The result of this experiment is very cool and confirms that,  when fine-tuned on the right data, GPT-J is a very powerful AI model!You  can download the model from the HuggingFace hub: [https://huggingface.co/nlpcloud/instruct-gpt-j-fp16](https://huggingface.co/nlpcloud/instruct-gpt-j-fp16)\n\nHere is an example:\n\n`from transformers import pipeline import torch`\n\n`generator = pipeline(model=\"nlpcloud/instruct-gpt-j-fp16\", torch_dtype=torch.float16, device=0)`\n\n`prompt = \"Correct spelling and grammar from the following text.\\nI do not wan to go\\n\" print(generator(prompt))`\n\nMore details about this experiment here: [https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html](https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html?utm_source=reddit&amp;utm_campaign=nwu8d596-3816-11ed-a261-0242ac140007)\n\nI hope it will be useful! Please don't hesitate to share some feedbacks!\n\nJulien","classes":{"dataset":0.3478116393}}
{"title":"Choosing Non-Linear vs Linear","description":"Hello all,\n\nIs there a process for deciding whether to use a Non-Linear or Linear text classifier? From what I have been reading, it seems like people develop scatter plots from their data points to see if their data is linearly separable. \nDo people do this with text data? What does everyone do to evaluate their choice of model?\n\nThanks!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11uyz56/choosing_nonlinear_vs_linear/","created":"2023-03-18","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":0},"text":"Choosing Non-Linear vs Linear Hello all,\n\nIs there a process for deciding whether to use a Non-Linear or Linear text classifier? From what I have been reading, it seems like people develop scatter plots from their data points to see if their data is linearly separable. \nDo people do this with text data? What does everyone do to evaluate their choice of model?\n\nThanks!","classes":{"dataset":0.3488548398}}
{"title":"An Instruct Version Of GPT-J Using Stanford Alpaca's Dataset","description":"I  just released an instruct version of GPT-J using Stanford Alpaca's  dataset.The result of this experiment is very cool and confirms that,  when fine-tuned on the right data, GPT-J is a very powerful AI model!You  can download the model from the HuggingFace hub: [https://huggingface.co/nlpcloud/instruct-gpt-j-fp16](https://huggingface.co/nlpcloud/instruct-gpt-j-fp16)\n\nHere is an example:\n\n`from transformers import pipeline import torch`\n\n`generator = pipeline(model=\"nlpcloud/instruct-gpt-j-fp16\", torch_dtype=torch.float16, device=0)`\n\n`prompt = \"Correct spelling and grammar from the following text.\\nI do not wan to go\\n\" print(generator(prompt))`\n\nMore details about this experiment here: [https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html](https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html?utm_source=reddit&amp;utm_campaign=mwu8d596-3816-11ed-a261-0242ac140007)\n\nI hope it will be useful! Please don't hesitate to share some feedbacks!\n\nJulien","link":"https://www.reddit.com/r/LanguageTechnology/comments/11tqqcf/an_instruct_version_of_gptj_using_stanford/","created":"2023-03-17","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":7},"text":"An Instruct Version Of GPT-J Using Stanford Alpaca's Dataset I  just released an instruct version of GPT-J using Stanford Alpaca's  dataset.The result of this experiment is very cool and confirms that,  when fine-tuned on the right data, GPT-J is a very powerful AI model!You  can download the model from the HuggingFace hub: [https://huggingface.co/nlpcloud/instruct-gpt-j-fp16](https://huggingface.co/nlpcloud/instruct-gpt-j-fp16)\n\nHere is an example:\n\n`from transformers import pipeline import torch`\n\n`generator = pipeline(model=\"nlpcloud/instruct-gpt-j-fp16\", torch_dtype=torch.float16, device=0)`\n\n`prompt = \"Correct spelling and grammar from the following text.\\nI do not wan to go\\n\" print(generator(prompt))`\n\nMore details about this experiment here: [https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html](https://nlpcloud.com/instruct-version-of-gpt-j-using-stanford-alpaca-dataset.html?utm_source=reddit&amp;utm_campaign=mwu8d596-3816-11ed-a261-0242ac140007)\n\nI hope it will be useful! Please don't hesitate to share some feedbacks!\n\nJulien","classes":{"dataset":0.5731915832}}
{"title":"Grinnell vs Reed for eventual PhD","description":"Hello, I am trying to decide between these two schools that I have been accepted to for my undergraduate education.\n\nI plan on pursuing a major in computer science with a concentration in linguistics at Grinnell or an interdisciplinary major with computer science and linguistics at Reed. I was just wondering which of these have the better reputation, if any, in the field.\n\n&amp;#x200B;\n\nThanks!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11tvrf2/grinnell_vs_reed_for_eventual_phd/","created":"2023-03-17","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":6},"text":"Grinnell vs Reed for eventual PhD Hello, I am trying to decide between these two schools that I have been accepted to for my undergraduate education.\n\nI plan on pursuing a major in computer science with a concentration in linguistics at Grinnell or an interdisciplinary major with computer science and linguistics at Reed. I was just wondering which of these have the better reputation, if any, in the field.\n\n&amp;#x200B;\n\nThanks!","classes":{"dataset":0.2532141507}}
{"title":"Fine tune BERT for domain-specific information retrieval.","description":"Hi guys, I'm a little lost on how to start a little side project.\n\nSo I want to take a BERT model, fine tune it on additional information about a specific domain which it was not initially trained on and then it should be able to answer questions regarding that topic. The way I understand it, I would need to put an additional question answering head on top of the fine-tuned model, in order for it to be able to answer questions and not just put out \"random\", to my query related sentences. Is this thinking correct?\n\nI question this because all I find on the internet is fine tuning a model on qa- data, that is labeled dataset with questions and answers. My dataset on the otherhand consists on only text data, hence the title \"information retrieval\".\n\nThanks for your insights!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11sxkj0/fine_tune_bert_for_domainspecific_information/","created":"2023-03-16","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":8},"text":"Fine tune BERT for domain-specific information retrieval. Hi guys, I'm a little lost on how to start a little side project.\n\nSo I want to take a BERT model, fine tune it on additional information about a specific domain which it was not initially trained on and then it should be able to answer questions regarding that topic. The way I understand it, I would need to put an additional question answering head on top of the fine-tuned model, in order for it to be able to answer questions and not just put out \"random\", to my query related sentences. Is this thinking correct?\n\nI question this because all I find on the internet is fine tuning a model on qa- data, that is labeled dataset with questions and answers. My dataset on the otherhand consists on only text data, hence the title \"information retrieval\".\n\nThanks for your insights!","classes":{"dataset":0.4260438681}}
{"title":"Code Detection","description":"Given a text input I want to detect if there is any kind of code snippet in it. What's the best way to do this? Are there any pre trained models for this task? \n\nThank you","link":"https://www.reddit.com/r/LanguageTechnology/comments/11sr4ml/code_detection/","created":"2023-03-16","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":1},"text":"Code Detection Given a text input I want to detect if there is any kind of code snippet in it. What's the best way to do this? Are there any pre trained models for this task? \n\nThank you","classes":{"dataset":0.4740316868}}
{"title":"MYRiAD: A Multi-Array Room Acoustic Database","description":"In the development of acoustic signal processing algorithms, their evaluation in various acoustic environments is of utmost importance. In order to advance evaluation in realistic and reproducible scenarios, several high-quality acoustic databases have been developed over the years. In this paper, we present another complementary database of acoustic recordings, referred to as the Multi-arraY Room Acoustic Database (MYRiAD). The MYRiAD database is unique in its diversity of microphone configurations suiting a wide range of enhancement and reproduction applications (such as assistive hearing, teleconferencing, or sound zoning), the acoustics of the two recording spaces, and the variety of contained signals including 1214 room impulse responses (RIRs), reproduced speech, music, and stationary noise, as well as recordings of live cocktail parties held in both rooms. The microphone configurations comprise a dummy head (DH) with in-ear omnidirectional microphones, two behind-the-ear (BTE) pieces equipped with 2 omnidirectional microphones each, 5 external omnidirectional microphones (XMs), and two concentric circular microphone arrays (CMAs) consisting of 12 omnidirectional microphones in total. The two recording spaces, namely the SONORA Audio Laboratory (SAL) and the Alamire Interactive Laboratory (AIL), have reverberation times of 2.1s and 0.5s, respectively. Audio signals were reproduced using 10 movable loudspeakers in the SAL and a built-in array of 24 loudspeakers in the AIL. MATLAB and Python scripts are included for accessing the signals as well as microphone and loudspeaker coordinates. The database is publicly available at [1].","link":"http://arxiv.org/abs/2301.13057v1","created":"2023-01-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"MYRiAD: A Multi-Array Room Acoustic Database In the development of acoustic signal processing algorithms, their evaluation in various acoustic environments is of utmost importance. In order to advance evaluation in realistic and reproducible scenarios, several high-quality acoustic databases have been developed over the years. In this paper, we present another complementary database of acoustic recordings, referred to as the Multi-arraY Room Acoustic Database (MYRiAD). The MYRiAD database is unique in its diversity of microphone configurations suiting a wide range of enhancement and reproduction applications (such as assistive hearing, teleconferencing, or sound zoning), the acoustics of the two recording spaces, and the variety of contained signals including 1214 room impulse responses (RIRs), reproduced speech, music, and stationary noise, as well as recordings of live cocktail parties held in both rooms. The microphone configurations comprise a dummy head (DH) with in-ear omnidirectional microphones, two behind-the-ear (BTE) pieces equipped with 2 omnidirectional microphones each, 5 external omnidirectional microphones (XMs), and two concentric circular microphone arrays (CMAs) consisting of 12 omnidirectional microphones in total. The two recording spaces, namely the SONORA Audio Laboratory (SAL) and the Alamire Interactive Laboratory (AIL), have reverberation times of 2.1s and 0.5s, respectively. Audio signals were reproduced using 10 movable loudspeakers in the SAL and a built-in array of 24 loudspeakers in the AIL. MATLAB and Python scripts are included for accessing the signals as well as microphone and loudspeaker coordinates. The database is publicly available at [1].","classes":{"dataset":0.0554353893}}
{"title":"RGB Arabic Alphabets Sign Language Dataset","description":"This paper introduces the RGB Arabic Alphabet Sign Language (AASL) dataset. AASL comprises 7,856 raw and fully labelled RGB images of the Arabic sign language alphabets, which to our best knowledge is the first publicly available RGB dataset. The dataset is aimed to help those interested in developing real-life Arabic sign language classification models. AASL was collected from more than 200 participants and with different settings such as lighting, background, image orientation, image size, and image resolution. Experts in the field supervised, validated and filtered the collected images to ensure a high-quality dataset. AASL is made available to the public on Kaggle.","link":"http://arxiv.org/abs/2301.11932v1","created":"2023-01-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"RGB Arabic Alphabets Sign Language Dataset This paper introduces the RGB Arabic Alphabet Sign Language (AASL) dataset. AASL comprises 7,856 raw and fully labelled RGB images of the Arabic sign language alphabets, which to our best knowledge is the first publicly available RGB dataset. The dataset is aimed to help those interested in developing real-life Arabic sign language classification models. AASL was collected from more than 200 participants and with different settings such as lighting, background, image orientation, image size, and image resolution. Experts in the field supervised, validated and filtered the collected images to ensure a high-quality dataset. AASL is made available to the public on Kaggle.","classes":{"dataset":0.5040723681}}
{"title":"Benchmarking Specialized Databases for High-frequency Data","description":"This paper presents a benchmarking suite designed for the evaluation and comparison of time series databases for high-frequency data, with a focus on financial applications. The proposed suite comprises of four specialized databases: ClickHouse, InfluxDB, kdb+ and TimescaleDB. The results from the suite demonstrate that kdb+ has the highest performance amongst the tested databases, while also highlighting the strengths and weaknesses of each of the databases. The benchmarking suite was designed to provide an objective measure of the performance of these databases as well as to compare their capabilities for different types of data. This provides valuable insights into the suitability of different time series databases for different use cases and provides benchmarks that can be used to inform system design decisions.","link":"http://arxiv.org/abs/2301.12561v1","created":"2023-01-29","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Benchmarking Specialized Databases for High-frequency Data This paper presents a benchmarking suite designed for the evaluation and comparison of time series databases for high-frequency data, with a focus on financial applications. The proposed suite comprises of four specialized databases: ClickHouse, InfluxDB, kdb+ and TimescaleDB. The results from the suite demonstrate that kdb+ has the highest performance amongst the tested databases, while also highlighting the strengths and weaknesses of each of the databases. The benchmarking suite was designed to provide an objective measure of the performance of these databases as well as to compare their capabilities for different types of data. This provides valuable insights into the suitability of different time series databases for different use cases and provides benchmarks that can be used to inform system design decisions.","classes":{"dataset":0.1931179315}}
{"title":"BERT-based Authorship Attribution on the Romanian Dataset called ROST","description":"Being around for decades, the problem of Authorship Attribution is still very much in focus currently. Some of the more recent instruments used are the pre-trained language models, the most prevalent being BERT. Here we used such a model to detect the authorship of texts written in the Romanian language. The dataset used is highly unbalanced, i.e., significant differences in the number of texts per author, the sources from which the texts were collected, the time period in which the authors lived and wrote these texts, the medium intended to be read (i.e., paper or online), and the type of writing (i.e., stories, short stories, fairy tales, novels, literary articles, and sketches). The results are better than expected, sometimes exceeding 87\\% macro-accuracy.","link":"http://arxiv.org/abs/2301.12500v1","created":"2023-01-29","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"BERT-based Authorship Attribution on the Romanian Dataset called ROST Being around for decades, the problem of Authorship Attribution is still very much in focus currently. Some of the more recent instruments used are the pre-trained language models, the most prevalent being BERT. Here we used such a model to detect the authorship of texts written in the Romanian language. The dataset used is highly unbalanced, i.e., significant differences in the number of texts per author, the sources from which the texts were collected, the time period in which the authors lived and wrote these texts, the medium intended to be read (i.e., paper or online), and the type of writing (i.e., stories, short stories, fairy tales, novels, literary articles, and sketches). The results are better than expected, sometimes exceeding 87\\% macro-accuracy.","classes":{"dataset":0.9462817311}}
{"title":"Towards Adversarial Realism and Robust Learning for IoT Intrusion Detection and Classification","description":"The Internet of Things (IoT) faces tremendous security challenges. Machine learning models can be used to tackle the growing number of cyber-attack variations targeting IoT systems, but the increasing threat posed by adversarial attacks restates the need for reliable defense strategies. This work describes the types of constraints required for an adversarial cyber-attack example to be realistic and proposes a methodology for a trustworthy adversarial robustness analysis with a realistic adversarial evasion attack vector. The proposed methodology was used to evaluate three supervised algorithms, Random Forest (RF), Extreme Gradient Boosting (XGB), and Light Gradient Boosting Machine (LGBM), and one unsupervised algorithm, Isolation Forest (IFOR). Constrained adversarial examples were generated with the Adaptative Perturbation Pattern Method (A2PM), and evasion attacks were performed against models created with regular and adversarial training. Even though RF was the least affected in binary classification, XGB consistently achieved the highest accuracy in multi-class classification. The obtained results evidence the inherent susceptibility of tree-based algorithms and ensembles to adversarial evasion attacks and demonstrates the benefits of adversarial training and a security by design approach for a more robust IoT network intrusion detection.","link":"http://arxiv.org/abs/2301.13122v1","created":"2023-01-30","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Towards Adversarial Realism and Robust Learning for IoT Intrusion Detection and Classification The Internet of Things (IoT) faces tremendous security challenges. Machine learning models can be used to tackle the growing number of cyber-attack variations targeting IoT systems, but the increasing threat posed by adversarial attacks restates the need for reliable defense strategies. This work describes the types of constraints required for an adversarial cyber-attack example to be realistic and proposes a methodology for a trustworthy adversarial robustness analysis with a realistic adversarial evasion attack vector. The proposed methodology was used to evaluate three supervised algorithms, Random Forest (RF), Extreme Gradient Boosting (XGB), and Light Gradient Boosting Machine (LGBM), and one unsupervised algorithm, Isolation Forest (IFOR). Constrained adversarial examples were generated with the Adaptative Perturbation Pattern Method (A2PM), and evasion attacks were performed against models created with regular and adversarial training. Even though RF was the least affected in binary classification, XGB consistently achieved the highest accuracy in multi-class classification. The obtained results evidence the inherent susceptibility of tree-based algorithms and ensembles to adversarial evasion attacks and demonstrates the benefits of adversarial training and a security by design approach for a more robust IoT network intrusion detection.","classes":{"dataset":0.1631064862}}
{"title":"Hierarchical learning, forecasting coherent spatio-temporal individual and aggregated building loads","description":"Optimal decision-making compels us to anticipate the future at different horizons. However, in many domains connecting together predictions from multiple time horizons and abstractions levels across their organization becomes all the more important, else decision-makers would be planning using separate and possibly conflicting views of the future. This notably applies to smart grid operation. To optimally manage energy flows in such systems, accurate and coherent predictions must be made across varying aggregation levels and horizons. With this work, we propose a novel multi-dimensional hierarchical forecasting method built upon structurally-informed machine-learning regressors and established hierarchical reconciliation taxonomy. A generic formulation of multi-dimensional hierarchies, reconciling spatial and temporal hierarchies under a common frame is initially defined. Next, a coherency-informed hierarchical learner is developed built upon a custom loss function leveraging optimal reconciliation methods. Coherency of the produced hierarchical forecasts is then secured using similar reconciliation technics. The outcome is a unified and coherent forecast across all examined dimensions. The method is evaluated on two different case studies to predict building electrical loads across spatial, temporal, and spatio-temporal hierarchies. Although the regressor natively profits from computationally efficient learning, results displayed disparate performances, demonstrating the value of hierarchical-coherent learning in only one setting. Yet, supported by a comprehensive result analysis, existing obstacles were clearly delineated, presenting distinct pathways for future work. Overall, the paper expands and unites traditionally disjointed hierarchical forecasting methods providing a fertile route toward a novel generation of forecasting regressors.","link":"http://arxiv.org/abs/2301.12967v1","created":"2023-01-30","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Hierarchical learning, forecasting coherent spatio-temporal individual and aggregated building loads Optimal decision-making compels us to anticipate the future at different horizons. However, in many domains connecting together predictions from multiple time horizons and abstractions levels across their organization becomes all the more important, else decision-makers would be planning using separate and possibly conflicting views of the future. This notably applies to smart grid operation. To optimally manage energy flows in such systems, accurate and coherent predictions must be made across varying aggregation levels and horizons. With this work, we propose a novel multi-dimensional hierarchical forecasting method built upon structurally-informed machine-learning regressors and established hierarchical reconciliation taxonomy. A generic formulation of multi-dimensional hierarchies, reconciling spatial and temporal hierarchies under a common frame is initially defined. Next, a coherency-informed hierarchical learner is developed built upon a custom loss function leveraging optimal reconciliation methods. Coherency of the produced hierarchical forecasts is then secured using similar reconciliation technics. The outcome is a unified and coherent forecast across all examined dimensions. The method is evaluated on two different case studies to predict building electrical loads across spatial, temporal, and spatio-temporal hierarchies. Although the regressor natively profits from computationally efficient learning, results displayed disparate performances, demonstrating the value of hierarchical-coherent learning in only one setting. Yet, supported by a comprehensive result analysis, existing obstacles were clearly delineated, presenting distinct pathways for future work. Overall, the paper expands and unites traditionally disjointed hierarchical forecasting methods providing a fertile route toward a novel generation of forecasting regressors.","classes":{"dataset":0.1161125302}}
{"title":"A Comprehensive Investigation of Feature and Model Importance in Android Malware Detection","description":"The popularity and relative openness of Android means it is a popular target for malware. Over the years, various studies have found that machine learning models can effectively discriminate malware from benign applications. However, as the operating system evolves, so does malware, bringing into question the findings of these previous studies, many of which used small, outdated, and often imbalanced datasets. In this paper, we reimplement 16 representative past works and evaluate them on a balanced, relevant and up-to-date dataset comprising 124,000 Android applications. We also carry out new experiments designed to fill holes in existing knowledge, and use our findings to identify the most effective features and models to use for Android malware detection within a contemporary environment. Our results suggest that accuracies of up to 96.8% can be achieved using static features alone, with a further 1% achievable using more expensive dynamic analysis approaches. We find the best models to be random forests built from API call usage and TCP network traffic features.","link":"http://arxiv.org/abs/2301.12778v1","created":"2023-01-30","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"A Comprehensive Investigation of Feature and Model Importance in Android Malware Detection The popularity and relative openness of Android means it is a popular target for malware. Over the years, various studies have found that machine learning models can effectively discriminate malware from benign applications. However, as the operating system evolves, so does malware, bringing into question the findings of these previous studies, many of which used small, outdated, and often imbalanced datasets. In this paper, we reimplement 16 representative past works and evaluate them on a balanced, relevant and up-to-date dataset comprising 124,000 Android applications. We also carry out new experiments designed to fill holes in existing knowledge, and use our findings to identify the most effective features and models to use for Android malware detection within a contemporary environment. Our results suggest that accuracies of up to 96.8% can be achieved using static features alone, with a further 1% achievable using more expensive dynamic analysis approaches. We find the best models to be random forests built from API call usage and TCP network traffic features.","classes":{"dataset":0.5040723681}}
{"title":"Feature-Space Bayesian Adversarial Learning Improved Malware Detector Robustness","description":"We present a new algorithm to train a robust malware detector. Modern malware detectors rely on machine learning algorithms. Now, the adversarial objective is to devise alterations to the malware code to decrease the chance of being detected whilst preserving the functionality and realism of the malware. Adversarial learning is effective in improving robustness but generating functional and realistic adversarial malware samples is non-trivial. Because: i) in contrast to tasks capable of using gradient-based feedback, adversarial learning in a domain without a differentiable mapping function from the problem space (malware code inputs) to the feature space is hard; and ii) it is difficult to ensure the adversarial malware is realistic and functional. This presents a challenge for developing scalable adversarial machine learning algorithms for large datasets at a production or commercial scale to realize robust malware detectors. We propose an alternative; perform adversarial learning in the feature space in contrast to the problem space. We prove the projection of perturbed, yet valid malware, in the problem space into feature space will always be a subset of adversarials generated in the feature space. Hence, by generating a robust network against feature-space adversarial examples, we inherently achieve robustness against problem-space adversarial examples. We formulate a Bayesian adversarial learning objective that captures the distribution of models for improved robustness. We prove that our learning method bounds the difference between the adversarial risk and empirical risk explaining the improved robustness. We show that adversarially trained BNNs achieve state-of-the-art robustness. Notably, adversarially trained BNNs are robust against stronger attacks with larger attack budgets by a margin of up to 15% on a recent production-scale malware dataset of more than 20 million samples.","link":"http://arxiv.org/abs/2301.12680v1","created":"2023-01-30","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Feature-Space Bayesian Adversarial Learning Improved Malware Detector Robustness We present a new algorithm to train a robust malware detector. Modern malware detectors rely on machine learning algorithms. Now, the adversarial objective is to devise alterations to the malware code to decrease the chance of being detected whilst preserving the functionality and realism of the malware. Adversarial learning is effective in improving robustness but generating functional and realistic adversarial malware samples is non-trivial. Because: i) in contrast to tasks capable of using gradient-based feedback, adversarial learning in a domain without a differentiable mapping function from the problem space (malware code inputs) to the feature space is hard; and ii) it is difficult to ensure the adversarial malware is realistic and functional. This presents a challenge for developing scalable adversarial machine learning algorithms for large datasets at a production or commercial scale to realize robust malware detectors. We propose an alternative; perform adversarial learning in the feature space in contrast to the problem space. We prove the projection of perturbed, yet valid malware, in the problem space into feature space will always be a subset of adversarials generated in the feature space. Hence, by generating a robust network against feature-space adversarial examples, we inherently achieve robustness against problem-space adversarial examples. We formulate a Bayesian adversarial learning objective that captures the distribution of models for improved robustness. We prove that our learning method bounds the difference between the adversarial risk and empirical risk explaining the improved robustness. We show that adversarially trained BNNs achieve state-of-the-art robustness. Notably, adversarially trained BNNs are robust against stronger attacks with larger attack budgets by a margin of up to 15% on a recent production-scale malware dataset of more than 20 million samples.","classes":{"dataset":0.06472525}}
{"title":"Adversarial Attacks on Adversarial Bandits","description":"We study a security threat to adversarial multi-armed bandits, in which an attacker perturbs the loss or reward signal to control the behavior of the victim bandit player. We show that the attacker is able to mislead any no-regret adversarial bandit algorithm into selecting a suboptimal target arm in every but sublinear (T-o(T)) number of rounds, while incurring only sublinear (o(T)) cumulative attack cost. This result implies critical security concern in real-world bandit-based systems, e.g., in online recommendation, an attacker might be able to hijack the recommender system and promote a desired product. Our proposed attack algorithms require knowledge of only the regret rate, thus are agnostic to the concrete bandit algorithm employed by the victim player. We also derived a theoretical lower bound on the cumulative attack cost that any victim-agnostic attack algorithm must incur. The lower bound matches the upper bound achieved by our attack, which shows that our attack is asymptotically optimal.","link":"http://arxiv.org/abs/2301.12595v1","created":"2023-01-30","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Adversarial Attacks on Adversarial Bandits We study a security threat to adversarial multi-armed bandits, in which an attacker perturbs the loss or reward signal to control the behavior of the victim bandit player. We show that the attacker is able to mislead any no-regret adversarial bandit algorithm into selecting a suboptimal target arm in every but sublinear (T-o(T)) number of rounds, while incurring only sublinear (o(T)) cumulative attack cost. This result implies critical security concern in real-world bandit-based systems, e.g., in online recommendation, an attacker might be able to hijack the recommender system and promote a desired product. Our proposed attack algorithms require knowledge of only the regret rate, thus are agnostic to the concrete bandit algorithm employed by the victim player. We also derived a theoretical lower bound on the cumulative attack cost that any victim-agnostic attack algorithm must incur. The lower bound matches the upper bound achieved by our attack, which shows that our attack is asymptotically optimal.","classes":{"dataset":0.0455203503}}
{"title":"Improving the Accuracy-Robustness Trade-off of Classifiers via Adaptive Smoothing","description":"While it is shown in the literature that simultaneously accurate and robust classifiers exist for common datasets, previous methods that improve the adversarial robustness of classifiers often manifest an accuracy-robustness trade-off. We build upon recent advancements in data-driven ``locally biased smoothing'' to develop classifiers that treat benign and adversarial test data differently. Specifically, we tailor the smoothing operation to the usage of a robust neural network as the source of robustness. We then extend the smoothing procedure to the multi-class setting and adapt an adversarial input detector into a policy network. The policy adaptively adjusts the mixture of the robust base classifier and a standard network, where the standard network is optimized for clean accuracy and is not robust in general. We provide theoretical analyses to motivate the use of the adaptive smoothing procedure, certify the robustness of the smoothed classifier under realistic assumptions, and justify the introduction of the policy network. We use various attack methods, including AutoAttack and adaptive attack, to empirically verify that the smoothed model noticeably improves the accuracy-robustness trade-off. On the CIFAR-100 dataset, our method simultaneously achieves an 80.09\\% clean accuracy and a 32.94\\% AutoAttacked accuracy. The code that implements adaptive smoothing is available at https://github.com/Bai-YT/AdaptiveSmoothing.","link":"http://arxiv.org/abs/2301.12554v1","created":"2023-01-29","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Improving the Accuracy-Robustness Trade-off of Classifiers via Adaptive Smoothing While it is shown in the literature that simultaneously accurate and robust classifiers exist for common datasets, previous methods that improve the adversarial robustness of classifiers often manifest an accuracy-robustness trade-off. We build upon recent advancements in data-driven ``locally biased smoothing'' to develop classifiers that treat benign and adversarial test data differently. Specifically, we tailor the smoothing operation to the usage of a robust neural network as the source of robustness. We then extend the smoothing procedure to the multi-class setting and adapt an adversarial input detector into a policy network. The policy adaptively adjusts the mixture of the robust base classifier and a standard network, where the standard network is optimized for clean accuracy and is not robust in general. We provide theoretical analyses to motivate the use of the adaptive smoothing procedure, certify the robustness of the smoothed classifier under realistic assumptions, and justify the introduction of the policy network. We use various attack methods, including AutoAttack and adaptive attack, to empirically verify that the smoothed model noticeably improves the accuracy-robustness trade-off. On the CIFAR-100 dataset, our method simultaneously achieves an 80.09\\% clean accuracy and a 32.94\\% AutoAttacked accuracy. The code that implements adaptive smoothing is available at https://github.com/Bai-YT/AdaptiveSmoothing.","classes":{"dataset":0.1377437264}}
{"title":"ADL-ID: Adversarial Disentanglement Learning for Wireless Device Fingerprinting Temporal Domain Adaptation","description":"As the journey of 5G standardization is coming to an end, academia and industry have already begun to consider the sixth-generation (6G) wireless networks, with an aim to meet the service demands for the next decade. Deep learning-based RF fingerprinting (DL-RFFP) has recently been recognized as a potential solution for enabling key wireless network applications and services, such as spectrum policy enforcement and network access control. The state-of-the-art DL-RFFP frameworks suffer from a significant performance drop when tested with data drawn from a domain that is different from that used for training data. In this paper, we propose ADL-ID, an unsupervised domain adaption framework that is based on adversarial disentanglement representation to address the temporal domain adaptation for the RFFP task. Our framework has been evaluated on real LoRa and WiFi datasets and showed about 24% improvement in accuracy when compared to the baseline CNN network on short-term temporal adaptation. It also improves the classification accuracy by up to 9% on long-term temporal adaptation. Furthermore, we release a 5-day, 2.1TB, large-scale WiFi 802.11b dataset collected from 50 Pycom devices to support the research community efforts in developing and validating robust RFFP methods.","link":"http://arxiv.org/abs/2301.12360v1","created":"2023-01-29","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"ADL-ID: Adversarial Disentanglement Learning for Wireless Device Fingerprinting Temporal Domain Adaptation As the journey of 5G standardization is coming to an end, academia and industry have already begun to consider the sixth-generation (6G) wireless networks, with an aim to meet the service demands for the next decade. Deep learning-based RF fingerprinting (DL-RFFP) has recently been recognized as a potential solution for enabling key wireless network applications and services, such as spectrum policy enforcement and network access control. The state-of-the-art DL-RFFP frameworks suffer from a significant performance drop when tested with data drawn from a domain that is different from that used for training data. In this paper, we propose ADL-ID, an unsupervised domain adaption framework that is based on adversarial disentanglement representation to address the temporal domain adaptation for the RFFP task. Our framework has been evaluated on real LoRa and WiFi datasets and showed about 24% improvement in accuracy when compared to the baseline CNN network on short-term temporal adaptation. It also improves the classification accuracy by up to 9% on long-term temporal adaptation. Furthermore, we release a 5-day, 2.1TB, large-scale WiFi 802.11b dataset collected from 50 Pycom devices to support the research community efforts in developing and validating robust RFFP methods.","classes":{"dataset":0.0787966475}}
{"title":"Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering","description":"Most existing methods to detect backdoored machine learning (ML) models take one of the two approaches: trigger inversion (aka. reverse engineer) and weight analysis (aka. model diagnosis). In particular, the gradient-based trigger inversion is considered to be among the most effective backdoor detection techniques, as evidenced by the TrojAI competition, Trojan Detection Challenge and backdoorBench. However, little has been done to understand why this technique works so well and, more importantly, whether it raises the bar to the backdoor attack. In this paper, we report the first attempt to answer this question by analyzing the change rate of the backdoored model around its trigger-carrying inputs. Our study shows that existing attacks tend to inject the backdoor characterized by a low change rate around trigger-carrying inputs, which are easy to capture by gradient-based trigger inversion. In the meantime, we found that the low change rate is not necessary for a backdoor attack to succeed: we design a new attack enhancement called \\textit{Gradient Shaping} (GRASP), which follows the opposite direction of adversarial training to reduce the change rate of a backdoored model with regard to the trigger, without undermining its backdoor effect. Also, we provide a theoretic analysis to explain the effectiveness of this new technique and the fundamental weakness of gradient-based trigger inversion. Finally, we perform both theoretical and experimental analysis, showing that the GRASP enhancement does not reduce the effectiveness of the stealthy attacks against the backdoor detection methods based on weight analysis, as well as other backdoor mitigation methods without using detection.","link":"http://arxiv.org/abs/2301.12318v1","created":"2023-01-29","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering Most existing methods to detect backdoored machine learning (ML) models take one of the two approaches: trigger inversion (aka. reverse engineer) and weight analysis (aka. model diagnosis). In particular, the gradient-based trigger inversion is considered to be among the most effective backdoor detection techniques, as evidenced by the TrojAI competition, Trojan Detection Challenge and backdoorBench. However, little has been done to understand why this technique works so well and, more importantly, whether it raises the bar to the backdoor attack. In this paper, we report the first attempt to answer this question by analyzing the change rate of the backdoored model around its trigger-carrying inputs. Our study shows that existing attacks tend to inject the backdoor characterized by a low change rate around trigger-carrying inputs, which are easy to capture by gradient-based trigger inversion. In the meantime, we found that the low change rate is not necessary for a backdoor attack to succeed: we design a new attack enhancement called \\textit{Gradient Shaping} (GRASP), which follows the opposite direction of adversarial training to reduce the change rate of a backdoored model with regard to the trigger, without undermining its backdoor effect. Also, we provide a theoretic analysis to explain the effectiveness of this new technique and the fundamental weakness of gradient-based trigger inversion. Finally, we perform both theoretical and experimental analysis, showing that the GRASP enhancement does not reduce the effectiveness of the stealthy attacks against the backdoor detection methods based on weight analysis, as well as other backdoor mitigation methods without using detection.","classes":{"dataset":0.0362657383}}
{"title":"Distilling Internet-Scale Vision-Language Models into Embodied Agents","description":"Instruction-following agents must ground language into their observation and action spaces. Learning to ground language is challenging, typically requiring domain-specific engineering or large quantities of human interaction data. To address this challenge, we propose using pretrained vision-language models (VLMs) to supervise embodied agents. We combine ideas from model distillation and hindsight experience replay (HER), using a VLM to retroactively generate language describing the agent's behavior. Simple prompting allows us to control the supervision signal, teaching an agent to interact with novel objects based on their names (e.g., planes) or their features (e.g., colors) in a 3D rendered environment. Fewshot prompting lets us teach abstract category membership, including pre-existing categories (food vs toys) and ad-hoc ones (arbitrary preferences over objects). Our work outlines a new and effective way to use internet-scale VLMs, repurposing the generic language grounding acquired by such models to teach task-relevant groundings to embodied agents.","link":"http://arxiv.org/abs/2301.12507v1","created":"2023-01-29","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Distilling Internet-Scale Vision-Language Models into Embodied Agents Instruction-following agents must ground language into their observation and action spaces. Learning to ground language is challenging, typically requiring domain-specific engineering or large quantities of human interaction data. To address this challenge, we propose using pretrained vision-language models (VLMs) to supervise embodied agents. We combine ideas from model distillation and hindsight experience replay (HER), using a VLM to retroactively generate language describing the agent's behavior. Simple prompting allows us to control the supervision signal, teaching an agent to interact with novel objects based on their names (e.g., planes) or their features (e.g., colors) in a 3D rendered environment. Fewshot prompting lets us teach abstract category membership, including pre-existing categories (food vs toys) and ad-hoc ones (arbitrary preferences over objects). Our work outlines a new and effective way to use internet-scale VLMs, repurposing the generic language grounding acquired by such models to teach task-relevant groundings to embodied agents.","classes":{"dataset":0.2253428847}}
{"title":"Equivariant Differentially Private Deep Learning","description":"The formal privacy guarantee provided by Differential Privacy (DP) bounds the leakage of sensitive information from deep learning models. In practice, however, this comes at a severe computation and accuracy cost. The recently established state of the art (SOTA) results in image classification under DP are due to the use of heavy data augmentation and large batch sizes, leading to a drastically increased computation overhead. In this work, we propose to use more efficient models with improved feature quality by introducing steerable equivariant convolutional networks for DP training. We demonstrate that our models are able to outperform the current SOTA performance on CIFAR-10 by up to $9\\%$ across different $\\varepsilon$-values while reducing the number of model parameters by a factor of $35$ and decreasing the computation time by more than $90 \\%$. Our results are a large step towards efficient model architectures that make optimal use of their parameters and bridge the privacy-utility gap between private and non-private deep learning for computer vision.","link":"http://arxiv.org/abs/2301.13104v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Equivariant Differentially Private Deep Learning The formal privacy guarantee provided by Differential Privacy (DP) bounds the leakage of sensitive information from deep learning models. In practice, however, this comes at a severe computation and accuracy cost. The recently established state of the art (SOTA) results in image classification under DP are due to the use of heavy data augmentation and large batch sizes, leading to a drastically increased computation overhead. In this work, we propose to use more efficient models with improved feature quality by introducing steerable equivariant convolutional networks for DP training. We demonstrate that our models are able to outperform the current SOTA performance on CIFAR-10 by up to $9\\%$ across different $\\varepsilon$-values while reducing the number of model parameters by a factor of $35$ and decreasing the computation time by more than $90 \\%$. Our results are a large step towards efficient model architectures that make optimal use of their parameters and bridge the privacy-utility gap between private and non-private deep learning for computer vision.","classes":{"dataset":0.1631064862}}
{"title":"GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis","description":"Synthesizing high-fidelity complex images from text is challenging. Based on large pretraining, the autoregressive and diffusion models can synthesize photo-realistic images. Although these large models have shown notable progress, there remain three flaws. 1) These models require tremendous training data and parameters to achieve good performance. 2) The multi-step generation design slows the image synthesis process heavily. 3) The synthesized visual features are difficult to control and require delicately designed prompts. To enable high-quality, efficient, fast, and controllable text-to-image synthesis, we propose Generative Adversarial CLIPs, namely GALIP. GALIP leverages the powerful pretrained CLIP model both in the discriminator and generator. Specifically, we propose a CLIP-based discriminator. The complex scene understanding ability of CLIP enables the discriminator to accurately assess the image quality. Furthermore, we propose a CLIP-empowered generator that induces the visual concepts from CLIP through bridge features and prompts. The CLIP-integrated generator and discriminator boost training efficiency, and as a result, our model only requires about 3% training data and 6% learnable parameters, achieving comparable results to large pretrained autoregressive and diffusion models. Moreover, our model achieves 120 times faster synthesis speed and inherits the smooth latent space from GAN. The extensive experimental results demonstrate the excellent performance of our GALIP. Code is available at https://github.com/tobran/GALIP.","link":"http://arxiv.org/abs/2301.12959v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis Synthesizing high-fidelity complex images from text is challenging. Based on large pretraining, the autoregressive and diffusion models can synthesize photo-realistic images. Although these large models have shown notable progress, there remain three flaws. 1) These models require tremendous training data and parameters to achieve good performance. 2) The multi-step generation design slows the image synthesis process heavily. 3) The synthesized visual features are difficult to control and require delicately designed prompts. To enable high-quality, efficient, fast, and controllable text-to-image synthesis, we propose Generative Adversarial CLIPs, namely GALIP. GALIP leverages the powerful pretrained CLIP model both in the discriminator and generator. Specifically, we propose a CLIP-based discriminator. The complex scene understanding ability of CLIP enables the discriminator to accurately assess the image quality. Furthermore, we propose a CLIP-empowered generator that induces the visual concepts from CLIP through bridge features and prompts. The CLIP-integrated generator and discriminator boost training efficiency, and as a result, our model only requires about 3% training data and 6% learnable parameters, achieving comparable results to large pretrained autoregressive and diffusion models. Moreover, our model achieves 120 times faster synthesis speed and inherits the smooth latent space from GAN. The extensive experimental results demonstrate the excellent performance of our GALIP. Code is available at https://github.com/tobran/GALIP.","classes":{"dataset":0.2822293043}}
{"title":"Minimalistic Predictions to Schedule Jobs with Online Precedence Constraints","description":"We consider non-clairvoyant scheduling with online precedence constraints, where an algorithm is oblivious to any job dependencies and learns about a job only if all of its predecessors have been completed. Given strong impossibility results in classical competitive analysis, we investigate the problem in a learning-augmented setting, where an algorithm has access to predictions without any quality guarantee. We discuss different prediction models: novel problem-specific models as well as general ones, which have been proposed in previous works. We present lower bounds and algorithmic upper bounds for different precedence topologies, and thereby give a structured overview on which and how additional (possibly erroneous) information helps for designing better algorithms. Along the way, we also improve bounds on traditional competitive ratios for existing algorithms.","link":"http://arxiv.org/abs/2301.12863v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Minimalistic Predictions to Schedule Jobs with Online Precedence Constraints We consider non-clairvoyant scheduling with online precedence constraints, where an algorithm is oblivious to any job dependencies and learns about a job only if all of its predecessors have been completed. Given strong impossibility results in classical competitive analysis, we investigate the problem in a learning-augmented setting, where an algorithm has access to predictions without any quality guarantee. We discuss different prediction models: novel problem-specific models as well as general ones, which have been proposed in previous works. We present lower bounds and algorithmic upper bounds for different precedence topologies, and thereby give a structured overview on which and how additional (possibly erroneous) information helps for designing better algorithms. Along the way, we also improve bounds on traditional competitive ratios for existing algorithms.","classes":{"dataset":0.1745041758}}
{"title":"Pre-launch optical verification of the Euclid NISP instrument and comparison with simulated images","description":"To characterise the NISP (Near-Infrared Spectrometer and Photometer) instrument optical capability before the launch of the Euclid telescope to orbit, foreseen in 2023, data analysis of ground-based tests and Monte Carlo simulations that mimic the expected NISP performance were carried out. Pre-launch test data were analysed to assess the fulfilment of the mission specifications in terms of Point Spread Function (PSF), set at EE50(PSF) <= 0.003, and with a spectral resolution below 16 angstroms per pixel. We also provide a first comparison between real images from the ground-based tests with simulated ones. We confirm the high optical quality of the NISP instrument, fulfilling the mission specifications in terms of PSF and spectral dispersion with a good agreement between the different test campaigns. We validated the PSF and spectral dispersion provided by the NISP simulator, a crucial aspect to validate the consistency between real and simulated images.","link":"http://arxiv.org/abs/2301.12828v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Pre-launch optical verification of the Euclid NISP instrument and comparison with simulated images To characterise the NISP (Near-Infrared Spectrometer and Photometer) instrument optical capability before the launch of the Euclid telescope to orbit, foreseen in 2023, data analysis of ground-based tests and Monte Carlo simulations that mimic the expected NISP performance were carried out. Pre-launch test data were analysed to assess the fulfilment of the mission specifications in terms of Point Spread Function (PSF), set at EE50(PSF) <= 0.003, and with a spectral resolution below 16 angstroms per pixel. We also provide a first comparison between real images from the ground-based tests with simulated ones. We confirm the high optical quality of the NISP instrument, fulfilling the mission specifications in terms of PSF and spectral dispersion with a good agreement between the different test campaigns. We validated the PSF and spectral dispersion provided by the NISP simulator, a crucial aspect to validate the consistency between real and simulated images.","classes":{"dataset":0.1599039435}}
{"title":"Dynamic Storyboard Generation in an Engine-based Virtual Environment for Video Production","description":"Amateurs working on mini-films and short-form videos usually spend lots of time and effort on the multi-round complicated process of setting and adjusting scenes, plots, and cameras to deliver satisfying video shots. We present Virtual Dynamic Storyboard (VDS) to allow users storyboarding shots in virtual environments, where the filming staff can easily test the settings of shots before the actual filming. VDS runs on a \"propose-simulate-discriminate\" mode: Given a formatted story script and a camera script as input, it generates several character animation and camera movement proposals following predefined story and cinematic rules to allow an off-the-shelf simulation engine to render videos. To pick up the top-quality dynamic storyboard from the candidates, we equip it with a shot ranking discriminator based on shot quality criteria learned from professional manual-created data. VDS is comprehensively validated via extensive experiments and user studies, demonstrating its efficiency, effectiveness, and great potential in assisting amateur video production.","link":"http://arxiv.org/abs/2301.12688v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Dynamic Storyboard Generation in an Engine-based Virtual Environment for Video Production Amateurs working on mini-films and short-form videos usually spend lots of time and effort on the multi-round complicated process of setting and adjusting scenes, plots, and cameras to deliver satisfying video shots. We present Virtual Dynamic Storyboard (VDS) to allow users storyboarding shots in virtual environments, where the filming staff can easily test the settings of shots before the actual filming. VDS runs on a \"propose-simulate-discriminate\" mode: Given a formatted story script and a camera script as input, it generates several character animation and camera movement proposals following predefined story and cinematic rules to allow an off-the-shelf simulation engine to render videos. To pick up the top-quality dynamic storyboard from the candidates, we equip it with a shot ranking discriminator based on shot quality criteria learned from professional manual-created data. VDS is comprehensively validated via extensive experiments and user studies, demonstrating its efficiency, effectiveness, and great potential in assisting amateur video production.","classes":{"dataset":0.1223534048}}
{"title":"Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models","description":"Large-scale multimodal generative modeling has created milestones in text-to-image and text-to-video generation. Its application to audio still lags behind for two main reasons: the lack of large-scale datasets with high-quality text-audio pairs, and the complexity of modeling long continuous audio data. In this work, we propose Make-An-Audio with a prompt-enhanced diffusion model that addresses these gaps by 1) introducing pseudo prompt enhancement with a distill-then-reprogram approach, it alleviates data scarcity with orders of magnitude concept compositions by using language-free audios; 2) leveraging spectrogram autoencoder to predict the self-supervised audio representation instead of waveforms. Together with robust contrastive language-audio pretraining (CLAP) representations, Make-An-Audio achieves state-of-the-art results in both objective and subjective benchmark evaluation. Moreover, we present its controllability and generalization for X-to-Audio with \"No Modality Left Behind\", for the first time unlocking the ability to generate high-definition, high-fidelity audios given a user-defined modality input. Audio samples are available at https://Text-to-Audio.github.io","link":"http://arxiv.org/abs/2301.12661v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models Large-scale multimodal generative modeling has created milestones in text-to-image and text-to-video generation. Its application to audio still lags behind for two main reasons: the lack of large-scale datasets with high-quality text-audio pairs, and the complexity of modeling long continuous audio data. In this work, we propose Make-An-Audio with a prompt-enhanced diffusion model that addresses these gaps by 1) introducing pseudo prompt enhancement with a distill-then-reprogram approach, it alleviates data scarcity with orders of magnitude concept compositions by using language-free audios; 2) leveraging spectrogram autoencoder to predict the self-supervised audio representation instead of waveforms. Together with robust contrastive language-audio pretraining (CLAP) representations, Make-An-Audio achieves state-of-the-art results in both objective and subjective benchmark evaluation. Moreover, we present its controllability and generalization for X-to-Audio with \"No Modality Left Behind\", for the first time unlocking the ability to generate high-definition, high-fidelity audios given a user-defined modality input. Audio samples are available at https://Text-to-Audio.github.io","classes":{"dataset":0.2493471354}}
{"title":"Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays","description":"Image augmentations are quintessential for effective visual representation learning across self-supervised learning techniques. While augmentation strategies for natural imaging have been studied extensively, medical images are vastly different from their natural counterparts. Thus, it is unknown whether common augmentation strategies employed in Siamese representation learning generalize to medical images and to what extent. To address this challenge, in this study, we systematically assess the effect of various augmentations on the quality and robustness of the learned representations. We train and evaluate Siamese Networks for abnormality detection on chest X-Rays across three large datasets (MIMIC-CXR, CheXpert and VinDR-CXR). We investigate the efficacy of the learned representations through experiments involving linear probing, fine-tuning, zero-shot transfer, and data efficiency. Finally, we identify a set of augmentations that yield robust representations that generalize well to both out-of-distribution data and diseases, while outperforming supervised baselines using just zero-shot transfer and linear probes by up to 20%.","link":"http://arxiv.org/abs/2301.12636v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays Image augmentations are quintessential for effective visual representation learning across self-supervised learning techniques. While augmentation strategies for natural imaging have been studied extensively, medical images are vastly different from their natural counterparts. Thus, it is unknown whether common augmentation strategies employed in Siamese representation learning generalize to medical images and to what extent. To address this challenge, in this study, we systematically assess the effect of various augmentations on the quality and robustness of the learned representations. We train and evaluate Siamese Networks for abnormality detection on chest X-Rays across three large datasets (MIMIC-CXR, CheXpert and VinDR-CXR). We investigate the efficacy of the learned representations through experiments involving linear probing, fine-tuning, zero-shot transfer, and data efficiency. Finally, we identify a set of augmentations that yield robust representations that generalize well to both out-of-distribution data and diseases, while outperforming supervised baselines using just zero-shot transfer and linear probes by up to 20%.","classes":{"dataset":0.1496617794}}
{"title":"Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining","description":"While neural text-to-speech (TTS) has achieved human-like natural synthetic speech, multilingual TTS systems are limited to resource-rich languages due to the need for paired text and studio-quality audio data. This paper proposes a method for zero-shot multilingual TTS using text-only data for the target language. The use of text-only data allows the development of TTS systems for low-resource languages for which only textual resources are available, making TTS accessible to thousands of languages. Inspired by the strong cross-lingual transferability of multilingual language models, our framework first performs masked language model pretraining with multilingual text-only data. Then we train this model with a paired data in a supervised manner, while freezing a language-aware embedding layer. This allows inference even for languages not included in the paired data but present in the text-only data. Evaluation results demonstrate highly intelligible zero-shot TTS with a character error rate of less than 12% for an unseen language. All experiments were conducted using public datasets and the implementation will be made available for reproducibility.","link":"http://arxiv.org/abs/2301.12596v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining While neural text-to-speech (TTS) has achieved human-like natural synthetic speech, multilingual TTS systems are limited to resource-rich languages due to the need for paired text and studio-quality audio data. This paper proposes a method for zero-shot multilingual TTS using text-only data for the target language. The use of text-only data allows the development of TTS systems for low-resource languages for which only textual resources are available, making TTS accessible to thousands of languages. Inspired by the strong cross-lingual transferability of multilingual language models, our framework first performs masked language model pretraining with multilingual text-only data. Then we train this model with a paired data in a supervised manner, while freezing a language-aware embedding layer. This allows inference even for languages not included in the paired data but present in the text-only data. Evaluation results demonstrate highly intelligible zero-shot TTS with a character error rate of less than 12% for an unseen language. All experiments were conducted using public datasets and the implementation will be made available for reproducibility.","classes":{"dataset":0.7495706081}}
{"title":"HPCDF: Optimal Service Provisioning in IoT Fog-based Environment for QoS-aware Delay-sensitive Application","description":"Due to the explosive growth of smart devices, 5G, and the Internet of Things (IoT) applications in recent years, the volume and velocity of generated data, and consequently, delay-sensitive applications are increasing endlessly. This paper aims to improve the service delay and Quality of Service (QoS) by introducing HPCDF (Hybrid PSO-CRO Delay-improved for FogPlan) - an offline QoS-aware framework to deploy and release fog services dynamically. The proposed method provisions, i.e., deploy and release fog services to reduce service delay, based on the aggregated incoming traffic to each fog node. We formulate a cost function as an Integer Non-Linear Programming (INLP) problem by considering each service attributes, including required resources and associated traffic. This problem integrates storage, processing, deployment, communication costs, delay violation, high fog utilization reward, high traffic nodes cost, and service delay penalty. A hybrid binary PSO-CRO (Particle Swarm and Chemical Reaction Optimization) algorithm is proposed to achieve the lowest service delay and QoS loss to address this problem. The evaluation is performed on real-world traffic traces, provided by MAWI Working Group, under three different experiments to study the impact of various parameters of the hybrid binary PSO-CRO algorithm and the proposed framework on service delay. The evaluation results reveal that our proposed algorithm reduces service delay by 29.34%, service cost by 66.02%, and violates the delay 50.15% less in comparison to FogPlan framework.","link":"http://arxiv.org/abs/2301.12522v1","created":"2023-01-29","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"HPCDF: Optimal Service Provisioning in IoT Fog-based Environment for QoS-aware Delay-sensitive Application Due to the explosive growth of smart devices, 5G, and the Internet of Things (IoT) applications in recent years, the volume and velocity of generated data, and consequently, delay-sensitive applications are increasing endlessly. This paper aims to improve the service delay and Quality of Service (QoS) by introducing HPCDF (Hybrid PSO-CRO Delay-improved for FogPlan) - an offline QoS-aware framework to deploy and release fog services dynamically. The proposed method provisions, i.e., deploy and release fog services to reduce service delay, based on the aggregated incoming traffic to each fog node. We formulate a cost function as an Integer Non-Linear Programming (INLP) problem by considering each service attributes, including required resources and associated traffic. This problem integrates storage, processing, deployment, communication costs, delay violation, high fog utilization reward, high traffic nodes cost, and service delay penalty. A hybrid binary PSO-CRO (Particle Swarm and Chemical Reaction Optimization) algorithm is proposed to achieve the lowest service delay and QoS loss to address this problem. The evaluation is performed on real-world traffic traces, provided by MAWI Working Group, under three different experiments to study the impact of various parameters of the hybrid binary PSO-CRO algorithm and the proposed framework on service delay. The evaluation results reveal that our proposed algorithm reduces service delay by 29.34%, service cost by 66.02%, and violates the delay 50.15% less in comparison to FogPlan framework.","classes":{"dataset":0.1429085433}}
{"title":"J-PLUS: Towards an homogeneous photometric calibration using Gaia BP/RP low-resolution spectra","description":"We present the photometric calibration of the twelve optical passbands for the Javalambre Photometric Local Universe Survey (J-PLUS) third data release (DR3), comprising 1642 pointings of two square degrees each. We selected nearly 1.5 million main sequence stars with a signal-to-noise ratio larger than ten in the twelve J-PLUS passbands and available low-resolution (R = 20-80) spectrum from the blue and red photometers (BP/RP) in Gaia DR3. We compared the synthetic photometry from BP/RP spectra with the J-PLUS instrumental magnitudes, after correcting for the magnitude and color terms between both systems, to obtain an homogeneous photometric solution for J-PLUS. To circumvent the current limitations in the absolute calibration of the BP/RP spectra, the absolute color scale was derived using the locus of 109 white dwarfs closer than 100 pc with a negligible interstellar extinction. Finally, the absolute flux scale was anchored to the Panoramic Survey Telescope and Rapid Response System (Pan-STARRS) photometry in the r band. The precision of the J-PLUS photometric calibration, estimated from duplicated objects observed in adjacent pointings and by comparison with the spectro-photometric standard star GD 153, is ~12 mmag in u, J0378, and J0395; and ~7 mmag in J0410, J0430, g, J0515, r, J0660, i, J0861, and z. The estimated accuracy in the calibration along the surveyed area is better than 1% for all the passbands. The Gaia BP/RP spectra provide a high-quality, homogeneous photometric reference in the optical range across the full-sky, in spite of their current limitations as an absolute reference. The calibration method for J-PLUS DR3 reaches an absolute precision and accuracy of 1% in the twelve optical filters within an area of 3284 square degrees.","link":"http://arxiv.org/abs/2301.12395v1","created":"2023-01-29","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"J-PLUS: Towards an homogeneous photometric calibration using Gaia BP/RP low-resolution spectra We present the photometric calibration of the twelve optical passbands for the Javalambre Photometric Local Universe Survey (J-PLUS) third data release (DR3), comprising 1642 pointings of two square degrees each. We selected nearly 1.5 million main sequence stars with a signal-to-noise ratio larger than ten in the twelve J-PLUS passbands and available low-resolution (R = 20-80) spectrum from the blue and red photometers (BP/RP) in Gaia DR3. We compared the synthetic photometry from BP/RP spectra with the J-PLUS instrumental magnitudes, after correcting for the magnitude and color terms between both systems, to obtain an homogeneous photometric solution for J-PLUS. To circumvent the current limitations in the absolute calibration of the BP/RP spectra, the absolute color scale was derived using the locus of 109 white dwarfs closer than 100 pc with a negligible interstellar extinction. Finally, the absolute flux scale was anchored to the Panoramic Survey Telescope and Rapid Response System (Pan-STARRS) photometry in the r band. The precision of the J-PLUS photometric calibration, estimated from duplicated objects observed in adjacent pointings and by comparison with the spectro-photometric standard star GD 153, is ~12 mmag in u, J0378, and J0395; and ~7 mmag in J0410, J0430, g, J0515, r, J0660, i, J0861, and z. The estimated accuracy in the calibration along the surveyed area is better than 1% for all the passbands. The Gaia BP/RP spectra provide a high-quality, homogeneous photometric reference in the optical range across the full-sky, in spite of their current limitations as an absolute reference. The calibration method for J-PLUS DR3 reaches an absolute precision and accuracy of 1% in the twelve optical filters within an area of 3284 square degrees.","classes":{"dataset":0.2043832839}}
{"title":"Explaining Dataset Changes for Semantic Data Versioning with Explain-Da-V (Technical Report)","description":"In multi-user environments in which data science and analysis is collaborative, multiple versions of the same datasets are generated. While managing and storing data versions has received some attention in the research literature, the semantic nature of such changes has remained under-explored. In this work, we introduce \\texttt{Explain-Da-V}, a framework aiming to explain changes between two given dataset versions. \\texttt{Explain-Da-V} generates \\emph{explanations} that use \\emph{data transformations} to explain changes. We further introduce a set of measures that evaluate the validity, generalizability, and explainability of these explanations. We empirically show, using an adapted existing benchmark and a newly created benchmark, that \\texttt{Explain-Da-V} generates better explanations than existing data transformation synthesis methods.","link":"http://arxiv.org/abs/2301.13095v1","created":"2023-01-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Explaining Dataset Changes for Semantic Data Versioning with Explain-Da-V (Technical Report) In multi-user environments in which data science and analysis is collaborative, multiple versions of the same datasets are generated. While managing and storing data versions has received some attention in the research literature, the semantic nature of such changes has remained under-explored. In this work, we introduce \\texttt{Explain-Da-V}, a framework aiming to explain changes between two given dataset versions. \\texttt{Explain-Da-V} generates \\emph{explanations} that use \\emph{data transformations} to explain changes. We further introduce a set of measures that evaluate the validity, generalizability, and explainability of these explanations. We empirically show, using an adapted existing benchmark and a newly created benchmark, that \\texttt{Explain-Da-V} generates better explanations than existing data transformation synthesis methods.","classes":{"dataset":0.2425797582}}
{"title":"Behavioural Reports of Multi-Stage Malware","description":"The extensive damage caused by malware requires anti-malware systems to be constantly improved to prevent new threats. The current trend in malware detection is to employ machine learning models to aid in the classification process. We propose a new dataset with the objective of improving current anti-malware systems. The focus of this dataset is to improve host based intrusion detection systems by providing API call sequences for thousands of malware samples executed in Windows 10 virtual machines. A tutorial on how to create and expand this dataset is provided along with a benchmark demonstrating how to use this dataset to classify malware. The data contains long sequences of API calls for each sample, and in order to create models that can be deployed in resource constrained devices, three feature selection methods were tested. The principal innovation, however, lies in the multi-label classification system in which one sequence of APIs can be tagged with multiple labels describing its malicious behaviours.","link":"http://arxiv.org/abs/2301.12800v1","created":"2023-01-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Behavioural Reports of Multi-Stage Malware The extensive damage caused by malware requires anti-malware systems to be constantly improved to prevent new threats. The current trend in malware detection is to employ machine learning models to aid in the classification process. We propose a new dataset with the objective of improving current anti-malware systems. The focus of this dataset is to improve host based intrusion detection systems by providing API call sequences for thousands of malware samples executed in Windows 10 virtual machines. A tutorial on how to create and expand this dataset is provided along with a benchmark demonstrating how to use this dataset to classify malware. The data contains long sequences of API calls for each sample, and in order to create models that can be deployed in resource constrained devices, three feature selection methods were tested. The principal innovation, however, lies in the multi-label classification system in which one sequence of APIs can be tagged with multiple labels describing its malicious behaviours.","classes":{"dataset":0.9767436981}}
{"title":"CSDR-BERT: a pre-trained scientific dataset match model for Chinese Scientific Dataset Retrieval","description":"As the number of open and shared scientific datasets on the Internet increases under the open science movement, efficiently retrieving these datasets is a crucial task in information retrieval (IR) research. In recent years, the development of large models, particularly the pre-training and fine-tuning paradigm, which involves pre-training on large models and fine-tuning on downstream tasks, has provided new solutions for IR match tasks. In this study, we use the original BERT token in the embedding layer, improve the Sentence-BERT model structure in the model layer by introducing the SimCSE and K-Nearest Neighbors method, and use the cosent loss function in the optimization phase to optimize the target output. Our experimental results show that our model outperforms other competing models on both public and self-built datasets through comparative experiments and ablation implementations. This study explores and validates the feasibility and efficiency of pre-training techniques for semantic retrieval of Chinese scientific datasets.","link":"http://arxiv.org/abs/2301.12700v1","created":"2023-01-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"CSDR-BERT: a pre-trained scientific dataset match model for Chinese Scientific Dataset Retrieval As the number of open and shared scientific datasets on the Internet increases under the open science movement, efficiently retrieving these datasets is a crucial task in information retrieval (IR) research. In recent years, the development of large models, particularly the pre-training and fine-tuning paradigm, which involves pre-training on large models and fine-tuning on downstream tasks, has provided new solutions for IR match tasks. In this study, we use the original BERT token in the embedding layer, improve the Sentence-BERT model structure in the model layer by introducing the SimCSE and K-Nearest Neighbors method, and use the cosent loss function in the optimization phase to optimize the target output. Our experimental results show that our model outperforms other competing models on both public and self-built datasets through comparative experiments and ablation implementations. This study explores and validates the feasibility and efficiency of pre-training techniques for semantic retrieval of Chinese scientific datasets.","classes":{"dataset":0.9490500689}}
{"title":"LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D Object Detection","description":"LiDAR devices are widely used in autonomous driving scenarios and researches on 3D point cloud achieve remarkable progress over the past years. However, deep learning-based methods heavily rely on the annotation data and often face the domain generalization problem. Unlike 2D images whose domains are usually related to the texture information, the feature extracted from the 3D point cloud is affected by the distribution of the points. Due to the lack of a 3D domain adaptation benchmark, the common practice is to train the model on one benchmark (e.g, Waymo) and evaluate it on another dataset (e.g. KITTI). However, in this setting, there are two types of domain gaps, the scenarios domain, and sensors domain, making the evaluation and analysis complicated and difficult. To handle this situation, we propose LiDAR Dataset with Cross-Sensors (LiDAR-CS Dataset), which contains large-scale annotated LiDAR point cloud under 6 groups of different sensors but with same corresponding scenarios, captured from hybrid realistic LiDAR simulator. As far as we know, LiDAR-CS Dataset is the first dataset focused on the sensor (e.g., the points distribution) domain gaps for 3D object detection in real traffic. Furthermore, we evaluate and analyze the performance with several baseline detectors on the LiDAR-CS benchmark and show its applications.","link":"http://arxiv.org/abs/2301.12515v1","created":"2023-01-29","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D Object Detection LiDAR devices are widely used in autonomous driving scenarios and researches on 3D point cloud achieve remarkable progress over the past years. However, deep learning-based methods heavily rely on the annotation data and often face the domain generalization problem. Unlike 2D images whose domains are usually related to the texture information, the feature extracted from the 3D point cloud is affected by the distribution of the points. Due to the lack of a 3D domain adaptation benchmark, the common practice is to train the model on one benchmark (e.g, Waymo) and evaluate it on another dataset (e.g. KITTI). However, in this setting, there are two types of domain gaps, the scenarios domain, and sensors domain, making the evaluation and analysis complicated and difficult. To handle this situation, we propose LiDAR Dataset with Cross-Sensors (LiDAR-CS Dataset), which contains large-scale annotated LiDAR point cloud under 6 groups of different sensors but with same corresponding scenarios, captured from hybrid realistic LiDAR simulator. As far as we know, LiDAR-CS Dataset is the first dataset focused on the sensor (e.g., the points distribution) domain gaps for 3D object detection in real traffic. Furthermore, we evaluate and analyze the performance with several baseline detectors on the LiDAR-CS benchmark and show its applications.","classes":{"dataset":0.0604394451}}
{"title":"Extracting Training Data from Diffusion Models","description":"Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.","link":"http://arxiv.org/abs/2301.13188v1","created":"2023-01-30","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Extracting Training Data from Diffusion Models Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.","classes":{"dataset":0.0538397282}}
{"title":"Equivariant Differentially Private Deep Learning","description":"The formal privacy guarantee provided by Differential Privacy (DP) bounds the leakage of sensitive information from deep learning models. In practice, however, this comes at a severe computation and accuracy cost. The recently established state of the art (SOTA) results in image classification under DP are due to the use of heavy data augmentation and large batch sizes, leading to a drastically increased computation overhead. In this work, we propose to use more efficient models with improved feature quality by introducing steerable equivariant convolutional networks for DP training. We demonstrate that our models are able to outperform the current SOTA performance on CIFAR-10 by up to $9\\%$ across different $\\varepsilon$-values while reducing the number of model parameters by a factor of $35$ and decreasing the computation time by more than $90 \\%$. Our results are a large step towards efficient model architectures that make optimal use of their parameters and bridge the privacy-utility gap between private and non-private deep learning for computer vision.","link":"http://arxiv.org/abs/2301.13104v1","created":"2023-01-30","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Equivariant Differentially Private Deep Learning The formal privacy guarantee provided by Differential Privacy (DP) bounds the leakage of sensitive information from deep learning models. In practice, however, this comes at a severe computation and accuracy cost. The recently established state of the art (SOTA) results in image classification under DP are due to the use of heavy data augmentation and large batch sizes, leading to a drastically increased computation overhead. In this work, we propose to use more efficient models with improved feature quality by introducing steerable equivariant convolutional networks for DP training. We demonstrate that our models are able to outperform the current SOTA performance on CIFAR-10 by up to $9\\%$ across different $\\varepsilon$-values while reducing the number of model parameters by a factor of $35$ and decreasing the computation time by more than $90 \\%$. Our results are a large step towards efficient model architectures that make optimal use of their parameters and bridge the privacy-utility gap between private and non-private deep learning for computer vision.","classes":{"dataset":0.0208691433}}
{"title":"Behavioural Reports of Multi-Stage Malware","description":"The extensive damage caused by malware requires anti-malware systems to be constantly improved to prevent new threats. The current trend in malware detection is to employ machine learning models to aid in the classification process. We propose a new dataset with the objective of improving current anti-malware systems. The focus of this dataset is to improve host based intrusion detection systems by providing API call sequences for thousands of malware samples executed in Windows 10 virtual machines. A tutorial on how to create and expand this dataset is provided along with a benchmark demonstrating how to use this dataset to classify malware. The data contains long sequences of API calls for each sample, and in order to create models that can be deployed in resource constrained devices, three feature selection methods were tested. The principal innovation, however, lies in the multi-label classification system in which one sequence of APIs can be tagged with multiple labels describing its malicious behaviours.","link":"http://arxiv.org/abs/2301.12800v1","created":"2023-01-30","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Behavioural Reports of Multi-Stage Malware The extensive damage caused by malware requires anti-malware systems to be constantly improved to prevent new threats. The current trend in malware detection is to employ machine learning models to aid in the classification process. We propose a new dataset with the objective of improving current anti-malware systems. The focus of this dataset is to improve host based intrusion detection systems by providing API call sequences for thousands of malware samples executed in Windows 10 virtual machines. A tutorial on how to create and expand this dataset is provided along with a benchmark demonstrating how to use this dataset to classify malware. The data contains long sequences of API calls for each sample, and in order to create models that can be deployed in resource constrained devices, three feature selection methods were tested. The principal innovation, however, lies in the multi-label classification system in which one sequence of APIs can be tagged with multiple labels describing its malicious behaviours.","classes":{"dataset":0.3760556281}}
{"title":"Private Node Selection in Personalized Decentralized Learning","description":"In this paper, we propose a novel approach for privacy-preserving node selection in personalized decentralized learning, which we refer to as Private Personalized Decentralized Learning (PPDL). Our method mitigates the risk of inference attacks through the use of secure aggregation while simultaneously enabling efficient identification of collaborators. This is achieved by leveraging adversarial multi-armed bandit optimization that exploits dependencies between the different arms. Through comprehensive experimentation on various benchmarks under label and covariate shift, we demonstrate that our privacy-preserving approach outperforms previous non-private methods in terms of model performance.","link":"http://arxiv.org/abs/2301.12755v1","created":"2023-01-30","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Private Node Selection in Personalized Decentralized Learning In this paper, we propose a novel approach for privacy-preserving node selection in personalized decentralized learning, which we refer to as Private Personalized Decentralized Learning (PPDL). Our method mitigates the risk of inference attacks through the use of secure aggregation while simultaneously enabling efficient identification of collaborators. This is achieved by leveraging adversarial multi-armed bandit optimization that exploits dependencies between the different arms. Through comprehensive experimentation on various benchmarks under label and covariate shift, we demonstrate that our privacy-preserving approach outperforms previous non-private methods in terms of model performance.","classes":{"dataset":0.3492361009}}
{"title":"FedPass: Privacy-Preserving Vertical Federated Deep Learning with Adaptive Obfuscation","description":"Vertical federated learning (VFL) allows an active party with labeled feature to leverage auxiliary features from the passive parties to improve model performance. Concerns about the private feature and label leakage in both the training and inference phases of VFL have drawn wide research attention. In this paper, we propose a general privacy-preserving vertical federated deep learning framework called FedPass, which leverages adaptive obfuscation to protect the feature and label simultaneously. Strong privacy-preserving capabilities about private features and labels are theoretically proved (in Theorems 1 and 2). Extensive experimental result s with different datasets and network architectures also justify the superiority of FedPass against existing methods in light of its near-optimal trade-off between privacy and model performance.","link":"http://arxiv.org/abs/2301.12623v1","created":"2023-01-30","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"FedPass: Privacy-Preserving Vertical Federated Deep Learning with Adaptive Obfuscation Vertical federated learning (VFL) allows an active party with labeled feature to leverage auxiliary features from the passive parties to improve model performance. Concerns about the private feature and label leakage in both the training and inference phases of VFL have drawn wide research attention. In this paper, we propose a general privacy-preserving vertical federated deep learning framework called FedPass, which leverages adaptive obfuscation to protect the feature and label simultaneously. Strong privacy-preserving capabilities about private features and labels are theoretically proved (in Theorems 1 and 2). Extensive experimental result s with different datasets and network architectures also justify the superiority of FedPass against existing methods in light of its near-optimal trade-off between privacy and model performance.","classes":{"dataset":0.0121832183}}
{"title":"Uncovering Adversarial Risks of Test-Time Adaptation","description":"Recently, test-time adaptation (TTA) has been proposed as a promising solution for addressing distribution shifts. It allows a base model to adapt to an unforeseen distribution during inference by leveraging the information from the batch of (unlabeled) test data. However, we uncover a novel security vulnerability of TTA based on the insight that predictions on benign samples can be impacted by malicious samples in the same batch. To exploit this vulnerability, we propose Distribution Invading Attack (DIA), which injects a small fraction of malicious data into the test batch. DIA causes models using TTA to misclassify benign and unperturbed test data, providing an entirely new capability for adversaries that is infeasible in canonical machine learning pipelines. Through comprehensive evaluations, we demonstrate the high effectiveness of our attack on multiple benchmarks across six TTA methods. In response, we investigate two countermeasures to robustify the existing insecure TTA implementations, following the principle of \"security by design\". Together, we hope our findings can make the community aware of the utility-security tradeoffs in deploying TTA and provide valuable insights for developing robust TTA approaches.","link":"http://arxiv.org/abs/2301.12576v1","created":"2023-01-29","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Uncovering Adversarial Risks of Test-Time Adaptation Recently, test-time adaptation (TTA) has been proposed as a promising solution for addressing distribution shifts. It allows a base model to adapt to an unforeseen distribution during inference by leveraging the information from the batch of (unlabeled) test data. However, we uncover a novel security vulnerability of TTA based on the insight that predictions on benign samples can be impacted by malicious samples in the same batch. To exploit this vulnerability, we propose Distribution Invading Attack (DIA), which injects a small fraction of malicious data into the test batch. DIA causes models using TTA to misclassify benign and unperturbed test data, providing an entirely new capability for adversaries that is infeasible in canonical machine learning pipelines. Through comprehensive evaluations, we demonstrate the high effectiveness of our attack on multiple benchmarks across six TTA methods. In response, we investigate two countermeasures to robustify the existing insecure TTA implementations, following the principle of \"security by design\". Together, we hope our findings can make the community aware of the utility-security tradeoffs in deploying TTA and provide valuable insights for developing robust TTA approaches.","classes":{"dataset":0.0426615477}}
{"title":"Concurrent Shuffle Differential Privacy Under Continual Observation","description":"We introduce the concurrent shuffle model of differential privacy. In this model we have multiple concurrent shufflers permuting messages from different, possibly overlapping, batches of users. Similarly to the standard (single) shuffle model, the privacy requirement is that the concatenation of all shuffled messages should be differentially private.   We study the private continual summation problem (a.k.a. the counter problem) and show that the concurrent shuffle model allows for significantly improved error compared to a standard (single) shuffle model. Specifically, we give a summation algorithm with error $\\tilde{O}(n^{1/(2k+1)})$ with $k$ concurrent shufflers on a sequence of length $n$. Furthermore, we prove that this bound is tight for any $k$, even if the algorithm can choose the sizes of the batches adaptively. For $k=\\log n$ shufflers, the resulting error is polylogarithmic, much better than $\\tilde{\\Theta}(n^{1/3})$ which we show is the smallest possible with a single shuffler.   We use our online summation algorithm to get algorithms with improved regret bounds for the contextual linear bandit problem. In particular we get optimal $\\tilde{O}(\\sqrt{n})$ regret with $k= \\tilde{\\Omega}(\\log n)$ concurrent shufflers.","link":"http://arxiv.org/abs/2301.12535v1","created":"2023-01-29","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Concurrent Shuffle Differential Privacy Under Continual Observation We introduce the concurrent shuffle model of differential privacy. In this model we have multiple concurrent shufflers permuting messages from different, possibly overlapping, batches of users. Similarly to the standard (single) shuffle model, the privacy requirement is that the concatenation of all shuffled messages should be differentially private.   We study the private continual summation problem (a.k.a. the counter problem) and show that the concurrent shuffle model allows for significantly improved error compared to a standard (single) shuffle model. Specifically, we give a summation algorithm with error $\\tilde{O}(n^{1/(2k+1)})$ with $k$ concurrent shufflers on a sequence of length $n$. Furthermore, we prove that this bound is tight for any $k$, even if the algorithm can choose the sizes of the batches adaptively. For $k=\\log n$ shufflers, the resulting error is polylogarithmic, much better than $\\tilde{\\Theta}(n^{1/3})$ which we show is the smallest possible with a single shuffler.   We use our online summation algorithm to get algorithms with improved regret bounds for the contextual linear bandit problem. In particular we get optimal $\\tilde{O}(\\sqrt{n})$ regret with $k= \\tilde{\\Omega}(\\log n)$ concurrent shufflers.","classes":{"dataset":0.0772138759}}
{"title":"Deep Learning model integrity checking mechanism using watermarking technique","description":"In response to the growing popularity of Machine Learning (ML) techniques to solve problems in various industries, various malicious groups have started to target such techniques in their attack plan. However, as ML models are constantly updated with continuous data, it is very hard to monitor the integrity of ML models. One probable solution would be to use hashing techniques. Regardless of how that would mean re-hashing the model each time the model is trained on newer data which is computationally expensive and not a feasible solution for ML models that are trained on continuous data. Therefore, in this paper, we propose a model integrity-checking mechanism that uses model watermarking techniques to monitor the integrity of ML models. We then demonstrate that our proposed technique can monitor the integrity of ML models even when the model is further trained on newer data with a low computational cost. Furthermore, the integrity checking mechanism can be used on Deep Learning models that work on complex data distributions such as Cyber-Physical System applications.","link":"http://arxiv.org/abs/2301.12333v1","created":"2023-01-29","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Deep Learning model integrity checking mechanism using watermarking technique In response to the growing popularity of Machine Learning (ML) techniques to solve problems in various industries, various malicious groups have started to target such techniques in their attack plan. However, as ML models are constantly updated with continuous data, it is very hard to monitor the integrity of ML models. One probable solution would be to use hashing techniques. Regardless of how that would mean re-hashing the model each time the model is trained on newer data which is computationally expensive and not a feasible solution for ML models that are trained on continuous data. Therefore, in this paper, we propose a model integrity-checking mechanism that uses model watermarking techniques to monitor the integrity of ML models. We then demonstrate that our proposed technique can monitor the integrity of ML models even when the model is further trained on newer data with a low computational cost. Furthermore, the integrity checking mechanism can be used on Deep Learning models that work on complex data distributions such as Cyber-Physical System applications.","classes":{"dataset":0.2771235704}}
{"title":"Exploring AI Ethics of ChatGPT: A Diagnostic Analysis","description":"Recent breakthroughs in natural language processing (NLP) have permitted the synthesis and comprehension of coherent text in an open-ended way, therefore translating the theoretical algorithms into practical applications. The large language-model (LLM) has significantly impacted businesses such as report summarization softwares and copywriters. Observations indicate, however, that LLMs may exhibit social prejudice and toxicity, posing ethical and societal dangers of consequences resulting from irresponsibility. Large-scale benchmarks for accountable LLMs should consequently be developed. Although several empirical investigations reveal the existence of a few ethical difficulties in advanced LLMs, there is no systematic examination and user study of the ethics of current LLMs use. To further educate future efforts on constructing ethical LLMs responsibly, we perform a qualitative research method on OpenAI's ChatGPT to better understand the practical features of ethical dangers in recent LLMs. We analyze ChatGPT comprehensively from four perspectives: 1) \\textit{Bias} 2) \\textit{Reliability} 3) \\textit{Robustness} 4) \\textit{Toxicity}. In accordance with our stated viewpoints, we empirically benchmark ChatGPT on multiple sample datasets. We find that a significant number of ethical risks cannot be addressed by existing benchmarks, and hence illustrate them via additional case studies. In addition, we examine the implications of our findings on the AI ethics of ChatGPT, as well as future problems and practical design considerations for LLMs. We believe that our findings may give light on future efforts to determine and mitigate the ethical hazards posed by machines in LLM applications.","link":"http://arxiv.org/abs/2301.12867v1","created":"2023-01-30","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Exploring AI Ethics of ChatGPT: A Diagnostic Analysis Recent breakthroughs in natural language processing (NLP) have permitted the synthesis and comprehension of coherent text in an open-ended way, therefore translating the theoretical algorithms into practical applications. The large language-model (LLM) has significantly impacted businesses such as report summarization softwares and copywriters. Observations indicate, however, that LLMs may exhibit social prejudice and toxicity, posing ethical and societal dangers of consequences resulting from irresponsibility. Large-scale benchmarks for accountable LLMs should consequently be developed. Although several empirical investigations reveal the existence of a few ethical difficulties in advanced LLMs, there is no systematic examination and user study of the ethics of current LLMs use. To further educate future efforts on constructing ethical LLMs responsibly, we perform a qualitative research method on OpenAI's ChatGPT to better understand the practical features of ethical dangers in recent LLMs. We analyze ChatGPT comprehensively from four perspectives: 1) \\textit{Bias} 2) \\textit{Reliability} 3) \\textit{Robustness} 4) \\textit{Toxicity}. In accordance with our stated viewpoints, we empirically benchmark ChatGPT on multiple sample datasets. We find that a significant number of ethical risks cannot be addressed by existing benchmarks, and hence illustrate them via additional case studies. In addition, we examine the implications of our findings on the AI ethics of ChatGPT, as well as future problems and practical design considerations for LLMs. We believe that our findings may give light on future efforts to determine and mitigate the ethical hazards posed by machines in LLM applications.","classes":{"dataset":0.1560467482}}
{"title":"Extracting Training Data from Diffusion Models","description":"Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.","link":"http://arxiv.org/abs/2301.13188v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Extracting Training Data from Diffusion Models Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.","classes":{"dataset":0.3980190456}}
{"title":"Fast Combinatorial Algorithms for Min Max Correlation Clustering","description":"We introduce fast algorithms for correlation clustering with respect to the Min Max objective that provide constant factor approximations on complete graphs. Our algorithms are the first purely combinatorial approximation algorithms for this problem. We construct a novel semi-metric on the set of vertices, which we call the correlation metric, that indicates to our clustering algorithms whether pairs of nodes should be in the same cluster. The paper demonstrates empirically that, compared to prior work, our algorithms sacrifice little in the objective quality to obtain significantly better run-time. Moreover, our algorithms scale to larger networks that are effectively intractable for known algorithms.","link":"http://arxiv.org/abs/2301.13079v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Fast Combinatorial Algorithms for Min Max Correlation Clustering We introduce fast algorithms for correlation clustering with respect to the Min Max objective that provide constant factor approximations on complete graphs. Our algorithms are the first purely combinatorial approximation algorithms for this problem. We construct a novel semi-metric on the set of vertices, which we call the correlation metric, that indicates to our clustering algorithms whether pairs of nodes should be in the same cluster. The paper demonstrates empirically that, compared to prior work, our algorithms sacrifice little in the objective quality to obtain significantly better run-time. Moreover, our algorithms scale to larger networks that are effectively intractable for known algorithms.","classes":{"dataset":0.1161125302}}
{"title":"Can Persistent Homology provide an efficient alternative for Evaluation of Knowledge Graph Completion Methods?","description":"In this paper we present a novel method, $\\textit{Knowledge Persistence}$ ($\\mathcal{KP}$), for faster evaluation of Knowledge Graph (KG) completion approaches. Current ranking-based evaluation is quadratic in the size of the KG, leading to long evaluation times and consequently a high carbon footprint. $\\mathcal{KP}$ addresses this by representing the topology of the KG completion methods through the lens of topological data analysis, concretely using persistent homology. The characteristics of persistent homology allow $\\mathcal{KP}$ to evaluate the quality of the KG completion looking only at a fraction of the data. Experimental results on standard datasets show that the proposed metric is highly correlated with ranking metrics (Hits@N, MR, MRR). Performance evaluation shows that $\\mathcal{KP}$ is computationally efficient: In some cases, the evaluation time (validation+test) of a KG completion method has been reduced from 18 hours (using Hits@10) to 27 seconds (using $\\mathcal{KP}$), and on average (across methods & data) reduces the evaluation time (validation+test) by $\\approx$ $\\textbf{99.96}\\%$.","link":"http://arxiv.org/abs/2301.12929v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Can Persistent Homology provide an efficient alternative for Evaluation of Knowledge Graph Completion Methods? In this paper we present a novel method, $\\textit{Knowledge Persistence}$ ($\\mathcal{KP}$), for faster evaluation of Knowledge Graph (KG) completion approaches. Current ranking-based evaluation is quadratic in the size of the KG, leading to long evaluation times and consequently a high carbon footprint. $\\mathcal{KP}$ addresses this by representing the topology of the KG completion methods through the lens of topological data analysis, concretely using persistent homology. The characteristics of persistent homology allow $\\mathcal{KP}$ to evaluate the quality of the KG completion looking only at a fraction of the data. Experimental results on standard datasets show that the proposed metric is highly correlated with ranking metrics (Hits@N, MR, MRR). Performance evaluation shows that $\\mathcal{KP}$ is computationally efficient: In some cases, the evaluation time (validation+test) of a KG completion method has been reduced from 18 hours (using Hits@10) to 27 seconds (using $\\mathcal{KP}$), and on average (across methods & data) reduces the evaluation time (validation+test) by $\\approx$ $\\textbf{99.96}\\%$.","classes":{"dataset":0.2747624516}}
{"title":"M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing System","description":"Face presentation attacks (FPA), also known as face spoofing, have brought increasing concerns to the public through various malicious applications, such as financial fraud and privacy leakage. Therefore, safeguarding face recognition systems against FPA is of utmost importance. Although existing learning-based face anti-spoofing (FAS) models can achieve outstanding detection performance, they lack generalization capability and suffer significant performance drops in unforeseen environments. Many methodologies seek to use auxiliary modality data (e.g., depth and infrared maps) during the presentation attack detection (PAD) to address this limitation. However, these methods can be limited since (1) they require specific sensors such as depth and infrared cameras for data capture, which are rarely available on commodity mobile devices, and (2) they cannot work properly in practical scenarios when either modality is missing or of poor quality. In this paper, we devise an accurate and robust MultiModal Mobile Face Anti-Spoofing system named M3FAS to overcome the issues above. The innovation of this work mainly lies in the following aspects: (1) To achieve robust PAD, our system combines visual and auditory modalities using three pervasively available sensors: camera, speaker, and microphone; (2) We design a novel two-branch neural network with three hierarchical feature aggregation modules to perform cross-modal feature fusion; (3). We propose a multi-head training strategy. The model outputs three predictions from the vision, acoustic, and fusion heads, enabling a more flexible PAD. Extensive experiments have demonstrated the accuracy, robustness, and flexibility of M3FAS under various challenging experimental settings.","link":"http://arxiv.org/abs/2301.12831v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing System Face presentation attacks (FPA), also known as face spoofing, have brought increasing concerns to the public through various malicious applications, such as financial fraud and privacy leakage. Therefore, safeguarding face recognition systems against FPA is of utmost importance. Although existing learning-based face anti-spoofing (FAS) models can achieve outstanding detection performance, they lack generalization capability and suffer significant performance drops in unforeseen environments. Many methodologies seek to use auxiliary modality data (e.g., depth and infrared maps) during the presentation attack detection (PAD) to address this limitation. However, these methods can be limited since (1) they require specific sensors such as depth and infrared cameras for data capture, which are rarely available on commodity mobile devices, and (2) they cannot work properly in practical scenarios when either modality is missing or of poor quality. In this paper, we devise an accurate and robust MultiModal Mobile Face Anti-Spoofing system named M3FAS to overcome the issues above. The innovation of this work mainly lies in the following aspects: (1) To achieve robust PAD, our system combines visual and auditory modalities using three pervasively available sensors: camera, speaker, and microphone; (2) We design a novel two-branch neural network with three hierarchical feature aggregation modules to perform cross-modal feature fusion; (3). We propose a multi-head training strategy. The model outputs three predictions from the vision, acoustic, and fusion heads, enabling a more flexible PAD. Extensive experiments have demonstrated the accuracy, robustness, and flexibility of M3FAS under various challenging experimental settings.","classes":{"dataset":0.1664543152}}
{"title":"Dynamic conditioning of two particle discrete-time quantum walks","description":"In real photonic quantum systems losses are an unavoidable factor limiting the scalability to many modes and particles, restraining their application in fields as quantum information and communication. For this reason, a considerable amount of engineering effort has been taken in order to improve the quality of particle sources and system components. At the same time, data analysis and collection methods based on post-selection have been used to mitigate the effect of particle losses. This has allowed for investigating experimentally multi-particle evolutions where the observer lacks knowledge about the system's intermediate propagation states. Nonetheless, the fundamental question how losses affect the behaviour of the surviving subset of a multi-particle system has not been investigated so far. For this reason, here we study the impact of particle losses in a quantum walk of two photons reconstructing the output probability distributions for one photon conditioned on the loss of the other in a known mode and temporal step of our evolution network. We present the underlying theoretical scheme that we have devised in order to model controlled particle losses, we describe an experimental platform capable of implementing our theory in a time multiplexing encoding. In the end we show how localized particle losses change the output distributions without altering their asymptotic spreading properties. Finally we devise a quantum civilization problem, a two walker generalisation of single particle recurrence processes.","link":"http://arxiv.org/abs/2301.12764v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Dynamic conditioning of two particle discrete-time quantum walks In real photonic quantum systems losses are an unavoidable factor limiting the scalability to many modes and particles, restraining their application in fields as quantum information and communication. For this reason, a considerable amount of engineering effort has been taken in order to improve the quality of particle sources and system components. At the same time, data analysis and collection methods based on post-selection have been used to mitigate the effect of particle losses. This has allowed for investigating experimentally multi-particle evolutions where the observer lacks knowledge about the system's intermediate propagation states. Nonetheless, the fundamental question how losses affect the behaviour of the surviving subset of a multi-particle system has not been investigated so far. For this reason, here we study the impact of particle losses in a quantum walk of two photons reconstructing the output probability distributions for one photon conditioned on the loss of the other in a known mode and temporal step of our evolution network. We present the underlying theoretical scheme that we have devised in order to model controlled particle losses, we describe an experimental platform capable of implementing our theory in a time multiplexing encoding. In the end we show how localized particle losses change the output distributions without altering their asymptotic spreading properties. Finally we devise a quantum civilization problem, a two walker generalisation of single particle recurrence processes.","classes":{"dataset":0.5422882438}}
{"title":"Optimal Decision Trees For Interpretable Clustering with Constraints","description":"Constrained clustering is a semi-supervised task that employs a limited amount of labelled data, formulated as constraints, to incorporate domain-specific knowledge and to significantly improve clustering accuracy. Previous work has considered exact optimization formulations that can guarantee optimal clustering while satisfying all constraints, however these approaches lack interpretability. Recently, decision-trees have been used to produce inherently interpretable clustering solutions, however existing approaches do not support clustering constraints and do not provide strong theoretical guarantees on solution quality. In this work, we present a novel SAT-based framework for interpretable clustering that supports clustering constraints and that also provides strong theoretical guarantees on solution quality. We also present new insight into the trade-off between interpretability and satisfaction of such user-provided constraints. Our framework is the first approach for interpretable and constrained clustering. Experiments with a range of real-world and synthetic datasets demonstrate that our approach can produce high-quality and interpretable constrained clustering solutions.","link":"http://arxiv.org/abs/2301.12671v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Optimal Decision Trees For Interpretable Clustering with Constraints Constrained clustering is a semi-supervised task that employs a limited amount of labelled data, formulated as constraints, to incorporate domain-specific knowledge and to significantly improve clustering accuracy. Previous work has considered exact optimization formulations that can guarantee optimal clustering while satisfying all constraints, however these approaches lack interpretability. Recently, decision-trees have been used to produce inherently interpretable clustering solutions, however existing approaches do not support clustering constraints and do not provide strong theoretical guarantees on solution quality. In this work, we present a novel SAT-based framework for interpretable clustering that supports clustering constraints and that also provides strong theoretical guarantees on solution quality. We also present new insight into the trade-off between interpretability and satisfaction of such user-provided constraints. Our framework is the first approach for interpretable and constrained clustering. Experiments with a range of real-world and synthetic datasets demonstrate that our approach can produce high-quality and interpretable constrained clustering solutions.","classes":{"dataset":0.4335264266}}
{"title":"Robust propagation-based phase retrieval for CT in proximity to highly attenuating objects","description":"X-ray imaging is a fast, precise and non-invasive method of imaging which, combined with computed tomography, provides detailed 3D rendering of samples. Incorporating propagation-based phase contrast can vastly improve data quality for weakly attenuating samples via material-specific phase retrieval filters, allowing radiation exposure to be reduced. However, applying phase retrieval to multi-material phantoms complicates analysis by requiring a choice of which material boundary to tune the phase retrieval. Filtering for the boundary with strongest phase contrast increases noise suppression, but with the detriment of over-blurring other interfaces, potentially obscuring small or neighbouring features and removing quantitative sample information. Additionally, regions bounded by more than one material type inherently cannot be conventionally filtered to reconstruct the whole boundary. As remedy, we present a computationally-efficient, non-iterative nor AI-mediated method for applying strong phase retrieval, whilst preserving sharp boundaries for all materials within the sample. This technique was tested on phase contrast images of a rabbit kitten brain encased by the surrounding dense skull. Using 24 keV synchrotron radiation with a 5 m propagation distance, our technique provided a 6.9-fold improvement in the signal-to-noise ratio (SNR) of brain tissue compared to the standard phase retrieval procedure, without over-smoothing the images. Simultaneous quantification of edge resolution and SNR gain was performed with an aluminium-water phantom imaged using a microfocus X-ray tube at mean energy 19.58 keV and 0.576 m effective propagation distance. Our method provided a 4.2-fold SNR boost whilst preserving the boundary resolution at 54 $\\pm$ 1 $\\mu$m, compared to 108 $\\pm$ 2 $\\mu$m in conventional phase retrieval.","link":"http://arxiv.org/abs/2301.12647v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Robust propagation-based phase retrieval for CT in proximity to highly attenuating objects X-ray imaging is a fast, precise and non-invasive method of imaging which, combined with computed tomography, provides detailed 3D rendering of samples. Incorporating propagation-based phase contrast can vastly improve data quality for weakly attenuating samples via material-specific phase retrieval filters, allowing radiation exposure to be reduced. However, applying phase retrieval to multi-material phantoms complicates analysis by requiring a choice of which material boundary to tune the phase retrieval. Filtering for the boundary with strongest phase contrast increases noise suppression, but with the detriment of over-blurring other interfaces, potentially obscuring small or neighbouring features and removing quantitative sample information. Additionally, regions bounded by more than one material type inherently cannot be conventionally filtered to reconstruct the whole boundary. As remedy, we present a computationally-efficient, non-iterative nor AI-mediated method for applying strong phase retrieval, whilst preserving sharp boundaries for all materials within the sample. This technique was tested on phase contrast images of a rabbit kitten brain encased by the surrounding dense skull. Using 24 keV synchrotron radiation with a 5 m propagation distance, our technique provided a 6.9-fold improvement in the signal-to-noise ratio (SNR) of brain tissue compared to the standard phase retrieval procedure, without over-smoothing the images. Simultaneous quantification of edge resolution and SNR gain was performed with an aluminium-water phantom imaged using a microfocus X-ray tube at mean energy 19.58 keV and 0.576 m effective propagation distance. Our method provided a 4.2-fold SNR boost whilst preserving the boundary resolution at 54 $\\pm$ 1 $\\mu$m, compared to 108 $\\pm$ 2 $\\mu$m in conventional phase retrieval.","classes":{"dataset":0.8357979059}}
{"title":"AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio","description":"Spatial audio, which focuses on immersive 3D sound rendering, is widely applied in the acoustic industry. One of the key problems of current spatial audio rendering methods is the lack of personalization based on different anatomies of individuals, which is essential to produce accurate sound source positions. In this work, we address this problem from an interdisciplinary perspective. The rendering of spatial audio is strongly correlated with the 3D shape of human bodies, particularly ears. To this end, we propose to achieve personalized spatial audio by reconstructing 3D human ears with single-view images. First, to benchmark the ear reconstruction task, we introduce AudioEar3D, a high-quality 3D ear dataset consisting of 112 point cloud ear scans with RGB images. To self-supervisedly train a reconstruction model, we further collect a 2D ear dataset composed of 2,000 images, each one with manual annotation of occlusion and 55 landmarks, named AudioEar2D. To our knowledge, both datasets have the largest scale and best quality of their kinds for public use. Further, we propose AudioEarM, a reconstruction method guided by a depth estimation network that is trained on synthetic data, with two loss functions tailored for ear data. Lastly, to fill the gap between the vision and acoustics community, we develop a pipeline to integrate the reconstructed ear mesh with an off-the-shelf 3D human body and simulate a personalized Head-Related Transfer Function (HRTF), which is the core of spatial audio rendering. Code and data are publicly available at https://github.com/seanywang0408/AudioEar.","link":"http://arxiv.org/abs/2301.12613v1","created":"2023-01-30","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio Spatial audio, which focuses on immersive 3D sound rendering, is widely applied in the acoustic industry. One of the key problems of current spatial audio rendering methods is the lack of personalization based on different anatomies of individuals, which is essential to produce accurate sound source positions. In this work, we address this problem from an interdisciplinary perspective. The rendering of spatial audio is strongly correlated with the 3D shape of human bodies, particularly ears. To this end, we propose to achieve personalized spatial audio by reconstructing 3D human ears with single-view images. First, to benchmark the ear reconstruction task, we introduce AudioEar3D, a high-quality 3D ear dataset consisting of 112 point cloud ear scans with RGB images. To self-supervisedly train a reconstruction model, we further collect a 2D ear dataset composed of 2,000 images, each one with manual annotation of occlusion and 55 landmarks, named AudioEar2D. To our knowledge, both datasets have the largest scale and best quality of their kinds for public use. Further, we propose AudioEarM, a reconstruction method guided by a depth estimation network that is trained on synthetic data, with two loss functions tailored for ear data. Lastly, to fill the gap between the vision and acoustics community, we develop a pipeline to integrate the reconstructed ear mesh with an off-the-shelf 3D human body and simulate a personalized Head-Related Transfer Function (HRTF), which is the core of spatial audio rendering. Code and data are publicly available at https://github.com/seanywang0408/AudioEar.","classes":{"dataset":0.1292290837}}
{"title":"Multi-Priority Graph Sparsification","description":"A \\emph{sparsification} of a given graph $G$ is a sparser graph (typically a subgraph) which aims to approximate or preserve some property of $G$. Examples of sparsifications include but are not limited to spanning trees, Steiner trees, spanners, emulators, and distance preservers. Each vertex has the same priority in all of these problems. However, real-world graphs typically assign different ``priorities'' or ``levels'' to different vertices, in which higher-priority vertices require higher-quality connectivity between them. Multi-priority variants of the Steiner tree problem have been studied in prior literature but this generalization is much less studied for other sparsification problems. In this paper, we define a generalized multi-priority problem and present a rounding-up approach that can be used for a variety of graph sparsifications. Our analysis provides a systematic way to compute approximate solutions to multi-priority variants of a wide range of graph sparsification problems given access to a single-priority subroutine.","link":"http://arxiv.org/abs/2301.12563v1","created":"2023-01-29","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Multi-Priority Graph Sparsification A \\emph{sparsification} of a given graph $G$ is a sparser graph (typically a subgraph) which aims to approximate or preserve some property of $G$. Examples of sparsifications include but are not limited to spanning trees, Steiner trees, spanners, emulators, and distance preservers. Each vertex has the same priority in all of these problems. However, real-world graphs typically assign different ``priorities'' or ``levels'' to different vertices, in which higher-priority vertices require higher-quality connectivity between them. Multi-priority variants of the Steiner tree problem have been studied in prior literature but this generalization is much less studied for other sparsification problems. In this paper, we define a generalized multi-priority problem and present a rounding-up approach that can be used for a variety of graph sparsifications. Our analysis provides a systematic way to compute approximate solutions to multi-priority variants of a wide range of graph sparsification problems given access to a single-priority subroutine.","classes":{"dataset":0.3078639209}}
{"title":"Time-Series Pattern Recognition in Smart Manufacturing Systems: A Literature Review and Ontology","description":"Since the inception of Industry 4.0 in 2012, emerging technologies have enabled the acquisition of vast amounts of data from diverse sources such as machine tools, robust and affordable sensor systems with advanced information models, and other sources within Smart Manufacturing Systems (SMS). As a result, the amount of data that is available in manufacturing settings has exploded, allowing data-hungry tools such as Artificial Intelligence (AI) and Machine Learning (ML) to be leveraged. Time-series analytics has been successfully applied in a variety of industries, and that success is now being migrated to pattern recognition applications in manufacturing to support higher quality products, zero defect manufacturing, and improved customer satisfaction. However, the diverse landscape of manufacturing presents a challenge for successfully solving problems in industry using time-series pattern recognition. The resulting research gap of understanding and applying the subject matter of time-series pattern recognition in manufacturing is a major limiting factor for adoption in industry. The purpose of this paper is to provide a structured perspective of the current state of time-series pattern recognition in manufacturing with a problem-solving focus. By using an ontology to classify and define concepts, how they are structured, their properties, the relationships between them, and considerations when applying them, this paper aims to provide practical and actionable guidelines for application and recommendations for advancing time-series analytics.","link":"http://arxiv.org/abs/2301.12495v1","created":"2023-01-29","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Time-Series Pattern Recognition in Smart Manufacturing Systems: A Literature Review and Ontology Since the inception of Industry 4.0 in 2012, emerging technologies have enabled the acquisition of vast amounts of data from diverse sources such as machine tools, robust and affordable sensor systems with advanced information models, and other sources within Smart Manufacturing Systems (SMS). As a result, the amount of data that is available in manufacturing settings has exploded, allowing data-hungry tools such as Artificial Intelligence (AI) and Machine Learning (ML) to be leveraged. Time-series analytics has been successfully applied in a variety of industries, and that success is now being migrated to pattern recognition applications in manufacturing to support higher quality products, zero defect manufacturing, and improved customer satisfaction. However, the diverse landscape of manufacturing presents a challenge for successfully solving problems in industry using time-series pattern recognition. The resulting research gap of understanding and applying the subject matter of time-series pattern recognition in manufacturing is a major limiting factor for adoption in industry. The purpose of this paper is to provide a structured perspective of the current state of time-series pattern recognition in manufacturing with a problem-solving focus. By using an ontology to classify and define concepts, how they are structured, their properties, the relationships between them, and considerations when applying them, this paper aims to provide practical and actionable guidelines for application and recommendations for advancing time-series analytics.","classes":{"dataset":0.0751789957}}
{"title":"Achieving Timestamp Prediction While Recognizing with Non-Autoregressive End-to-End ASR Model","description":"Conventional ASR systems use frame-level phoneme posterior to conduct force-alignment~(FA) and provide timestamps, while end-to-end ASR systems especially AED based ones are short of such ability. This paper proposes to perform timestamp prediction~(TP) while recognizing by utilizing continuous integrate-and-fire~(CIF) mechanism in non-autoregressive ASR model - Paraformer. Foucing on the fire place bias issue of CIF, we conduct post-processing strategies including fire-delay and silence insertion. Besides, we propose to use scaled-CIF to smooth the weights of CIF output, which is proved beneficial for both ASR and TP task. Accumulated averaging shift~(AAS) and diarization error rate~(DER) are adopted to measure the quality of timestamps and we compare these metrics of proposed system and conventional hybrid force-alignment system. The experiment results over manually-marked timestamps testset show that the proposed optimization methods significantly improve the accuracy of CIF timestamps, reducing 66.7\\% and 82.1\\% of AAS and DER respectively. Comparing to Kaldi force-alignment trained with the same data, optimized CIF timestamps achieved 12.3\\% relative AAS reduction.","link":"http://arxiv.org/abs/2301.12343v1","created":"2023-01-29","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Achieving Timestamp Prediction While Recognizing with Non-Autoregressive End-to-End ASR Model Conventional ASR systems use frame-level phoneme posterior to conduct force-alignment~(FA) and provide timestamps, while end-to-end ASR systems especially AED based ones are short of such ability. This paper proposes to perform timestamp prediction~(TP) while recognizing by utilizing continuous integrate-and-fire~(CIF) mechanism in non-autoregressive ASR model - Paraformer. Foucing on the fire place bias issue of CIF, we conduct post-processing strategies including fire-delay and silence insertion. Besides, we propose to use scaled-CIF to smooth the weights of CIF output, which is proved beneficial for both ASR and TP task. Accumulated averaging shift~(AAS) and diarization error rate~(DER) are adopted to measure the quality of timestamps and we compare these metrics of proposed system and conventional hybrid force-alignment system. The experiment results over manually-marked timestamps testset show that the proposed optimization methods significantly improve the accuracy of CIF timestamps, reducing 66.7\\% and 82.1\\% of AAS and DER respectively. Comparing to Kaldi force-alignment trained with the same data, optimized CIF timestamps achieved 12.3\\% relative AAS reduction.","classes":{"dataset":0.267650336}}
{"title":"Japanese explained to programmers","description":"https://lajili.com/posts/post-1/","link":"https://lajili.com/posts/post-1/","created":"2023-01-31","tags":["hackernews"],"meta":{"score":112},"text":"Japanese explained to programmers https://lajili.com/posts/post-1/","classes":{"dataset":0.4761092067}}
{"title":"Over the past 21 months I\u2019ve written a code editor from the ground up","description":"https://edita.vercel.app/blog/approach/","link":"https://edita.vercel.app/blog/approach/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":320},"text":"Over the past 21 months I\u2019ve written a code editor from the ground up https://edita.vercel.app/blog/approach/","classes":{"dataset":0.4922338426}}
{"title":"Insulation: First the body, then the home (2011)","description":"https://www.lowtechmagazine.com/2011/02/body-insulation-thermal-underwear.html","link":"https://www.lowtechmagazine.com/2011/02/body-insulation-thermal-underwear.html","created":"2023-01-30","tags":["hackernews"],"meta":{"score":136},"text":"Insulation: First the body, then the home (2011) https://www.lowtechmagazine.com/2011/02/body-insulation-thermal-underwear.html","classes":{"dataset":0.507349968}}
{"title":"The 2012 Millennium Artifact","description":"https://www.cs.rochester.edu/users/faculty/nelson/courses/csc_200/project_2012_site/index.html","link":"https://www.cs.rochester.edu/users/faculty/nelson/courses/csc_200/project_2012_site/index.html","created":"2023-01-29","tags":["hackernews"],"meta":{"score":10},"text":"The 2012 Millennium Artifact https://www.cs.rochester.edu/users/faculty/nelson/courses/csc_200/project_2012_site/index.html","classes":{"dataset":0.5308148265}}
{"title":"UK expected to be only major economy to shrink in 2023 \u2013 IMF","description":"https://www.bbc.co.uk/news/business-64452995","link":"https://www.bbc.co.uk/news/business-64452995","created":"2023-01-31","tags":["hackernews"],"meta":{"score":19},"text":"UK expected to be only major economy to shrink in 2023 \u2013 IMF https://www.bbc.co.uk/news/business-64452995","classes":{"dataset":0.5093048811}}
{"title":"A Midcentury Bender: Revisiting Mad Men","description":"https://theamericanscholar.org/a-midcentury-bender/","link":"https://theamericanscholar.org/a-midcentury-bender/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":29},"text":"A Midcentury Bender: Revisiting Mad Men https://theamericanscholar.org/a-midcentury-bender/","classes":{"dataset":0.5259647965}}
{"title":"The (first) post-Elizabethan age","description":"https://www.prospectmagazine.co.uk/arts-and-books/blazing-world-post-elizabethan-age","link":"https://www.prospectmagazine.co.uk/arts-and-books/blazing-world-post-elizabethan-age","created":"2023-01-29","tags":["hackernews"],"meta":{"score":8},"text":"The (first) post-Elizabethan age https://www.prospectmagazine.co.uk/arts-and-books/blazing-world-post-elizabethan-age","classes":{"dataset":0.501096189}}
{"title":"Entering and Running a Tiny Program from the PDP-11 (PiDP-11) Front Panel","description":"https://bigdanzblog.wordpress.com/2023/01/26/entering-and-running-a-tiny-program-from-the-pdp-11-pidp-11-front-panel/","link":"https://bigdanzblog.wordpress.com/2023/01/26/entering-and-running-a-tiny-program-from-the-pdp-11-pidp-11-front-panel/","created":"2023-01-29","tags":["hackernews"],"meta":{"score":35},"text":"Entering and Running a Tiny Program from the PDP-11 (PiDP-11) Front Panel https://bigdanzblog.wordpress.com/2023/01/26/entering-and-running-a-tiny-program-from-the-pdp-11-pidp-11-front-panel/","classes":{"dataset":0.4963696897}}
{"title":"DIY triple-screen laptop based on the framework","description":"https://www.youtube.com/watch?v=aUKpY0o5tMo","link":"https://www.youtube.com/watch?v=aUKpY0o5tMo","created":"2023-01-31","tags":["hackernews"],"meta":{"score":55},"text":"DIY triple-screen laptop based on the framework https://www.youtube.com/watch?v=aUKpY0o5tMo","classes":{"dataset":0.5089222789}}
{"title":"Console Screendumps","description":"https://research.exoticsilicon.com/articles/console_screendumps","link":"https://research.exoticsilicon.com/articles/console_screendumps","created":"2023-01-29","tags":["hackernews"],"meta":{"score":29},"text":"Console Screendumps https://research.exoticsilicon.com/articles/console_screendumps","classes":{"dataset":0.5808338523}}
{"title":"Spotify is first music streaming service to surpass 200M paid subscribers","description":"https://www.theverge.com/2023/1/31/23577499/spotify-q4-2022-earnings-release-subscriber-growth-layoffs","link":"https://www.theverge.com/2023/1/31/23577499/spotify-q4-2022-earnings-release-subscriber-growth-layoffs","created":"2023-01-31","tags":["hackernews"],"meta":{"score":12},"text":"Spotify is first music streaming service to surpass 200M paid subscribers https://www.theverge.com/2023/1/31/23577499/spotify-q4-2022-earnings-release-subscriber-growth-layoffs","classes":{"dataset":0.4553103149}}
{"title":"Cistercian Numerals","description":"https://kottke.org/23/01/cistercian-numerals","link":"https://kottke.org/23/01/cistercian-numerals","created":"2023-01-31","tags":["hackernews"],"meta":{"score":124},"text":"Cistercian Numerals https://kottke.org/23/01/cistercian-numerals","classes":{"dataset":0.507349968}}
{"title":"Backblaze Drive Stats for 2022","description":"https://www.backblaze.com/blog/backblaze-drive-stats-for-2022/","link":"https://www.backblaze.com/blog/backblaze-drive-stats-for-2022/","created":"2023-01-31","tags":["hackernews"],"meta":{"score":7},"text":"Backblaze Drive Stats for 2022 https://www.backblaze.com/blog/backblaze-drive-stats-for-2022/","classes":{"dataset":0.4792414606}}
{"title":"A Stick Chart from the Marshall Islands (2016)","description":"https://www.sapiens.org/culture/stick-chart-marshall-islands/","link":"https://www.sapiens.org/culture/stick-chart-marshall-islands/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":10},"text":"A Stick Chart from the Marshall Islands (2016) https://www.sapiens.org/culture/stick-chart-marshall-islands/","classes":{"dataset":0.4916163981}}
{"title":"Google Play Developer Antitrust Litigation","description":"https://www.googleplaydevelopersettlement.com","link":"https://www.googleplaydevelopersettlement.com","created":"2023-01-31","tags":["hackernews"],"meta":{"score":213},"text":"Google Play Developer Antitrust Litigation https://www.googleplaydevelopersettlement.com","classes":{"dataset":0.4866258502}}
{"title":"Will Wright on designing user interfaces to simulation games (1996)","description":"https://donhopkins.medium.com/designing-user-interfaces-to-simulation-games-bd7a9d81e62d","link":"https://donhopkins.medium.com/designing-user-interfaces-to-simulation-games-bd7a9d81e62d","created":"2023-01-29","tags":["hackernews"],"meta":{"score":349},"text":"Will Wright on designing user interfaces to simulation games (1996) https://donhopkins.medium.com/designing-user-interfaces-to-simulation-games-bd7a9d81e62d","classes":{"dataset":0.5123405457}}
{"title":"Towards A Token-Free Future In NLP (2022)","description":"https://peltarion.com/blog/data-science/towards-a-token-free-future-in-nlp","link":"https://peltarion.com/blog/data-science/towards-a-token-free-future-in-nlp","created":"2023-01-30","tags":["hackernews"],"meta":{"score":45},"text":"Towards A Token-Free Future In NLP (2022) https://peltarion.com/blog/data-science/towards-a-token-free-future-in-nlp","classes":{"dataset":0.5097097754}}
{"title":"The Muse (YC W12) Is Hiring a BD Manager for Strategic Partnerships","description":"https://www.themuse.com/jobs/themuse/manager-business-development-strategic-partnerships","link":"https://www.themuse.com/jobs/themuse/manager-business-development-strategic-partnerships","created":"2023-01-30","tags":["hackernews"],"meta":{"score":1},"text":"The Muse (YC W12) Is Hiring a BD Manager for Strategic Partnerships https://www.themuse.com/jobs/themuse/manager-business-development-strategic-partnerships","classes":{"dataset":0.5354767442}}
{"title":"SimulaVR FPGA Image Processing Pipeline","description":"https://simulavr.com/blog/fpga-image-processing-pipeline/","link":"https://simulavr.com/blog/fpga-image-processing-pipeline/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":80},"text":"SimulaVR FPGA Image Processing Pipeline https://simulavr.com/blog/fpga-image-processing-pipeline/","classes":{"dataset":0.5009244084}}
{"title":"Learn the basics of coding with a needle and thread (2018)","description":"https://www.ideo.com/blog/learn-the-basics-of-code-with-a-needle-and-thread","link":"https://www.ideo.com/blog/learn-the-basics-of-code-with-a-needle-and-thread","created":"2023-01-30","tags":["hackernews"],"meta":{"score":45},"text":"Learn the basics of coding with a needle and thread (2018) https://www.ideo.com/blog/learn-the-basics-of-code-with-a-needle-and-thread","classes":{"dataset":0.4667832255}}
{"title":"Burning a NeXTCube (1993)","description":"https://simson.net/ref/1993/cubefire.html","link":"https://simson.net/ref/1993/cubefire.html","created":"2023-01-30","tags":["hackernews"],"meta":{"score":190},"text":"Burning a NeXTCube (1993) https://simson.net/ref/1993/cubefire.html","classes":{"dataset":0.5141114593}}
{"title":"I made a website for lonely people, and got >100 people to log their locations","description":"https://www.lonelyworld.info/","link":"https://www.lonelyworld.info/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":194},"text":"I made a website for lonely people, and got >100 people to log their locations https://www.lonelyworld.info/","classes":{"dataset":0.5089553595}}
{"title":"The window trick of Las Vegas hotels","description":"https://www.schedium.net/2023/01/the-window-trick-of-las-vegas-hotels.html","link":"https://www.schedium.net/2023/01/the-window-trick-of-las-vegas-hotels.html","created":"2023-01-29","tags":["hackernews"],"meta":{"score":970},"text":"The window trick of Las Vegas hotels https://www.schedium.net/2023/01/the-window-trick-of-las-vegas-hotels.html","classes":{"dataset":0.4618428051}}
{"title":"Why I'm using (Neo)Vim as a Data Engineer and Writer in 2023","description":"https://www.sspaeti.com/blog/why-using-neovim-data-engineer-and-writer-2023/","link":"https://www.sspaeti.com/blog/why-using-neovim-data-engineer-and-writer-2023/","created":"2023-01-31","tags":["hackernews"],"meta":{"score":3},"text":"Why I'm using (Neo)Vim as a Data Engineer and Writer in 2023 https://www.sspaeti.com/blog/why-using-neovim-data-engineer-and-writer-2023/","classes":{"dataset":0.5233709216}}
{"title":"Ferroelectric Memories: The Middle Ground","description":"https://semiengineering.com/ferroelectric-memories-the-middle-ground/","link":"https://semiengineering.com/ferroelectric-memories-the-middle-ground/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":21},"text":"Ferroelectric Memories: The Middle Ground https://semiengineering.com/ferroelectric-memories-the-middle-ground/","classes":{"dataset":0.5003525615}}
{"title":"TUI calculator for programmers working close to the bits","description":"https://github.com/alt-romes/programmer-calculator","link":"https://github.com/alt-romes/programmer-calculator","created":"2023-01-30","tags":["hackernews"],"meta":{"score":122},"text":"TUI calculator for programmers working close to the bits https://github.com/alt-romes/programmer-calculator","classes":{"dataset":0.5260612369}}
{"title":"On \u201cI don't trust microcode\u201d (2021)","description":"https://patrick.georgi.family/2021/02/13/on-microcode/","link":"https://patrick.georgi.family/2021/02/13/on-microcode/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":71},"text":"On \u201cI don't trust microcode\u201d (2021) https://patrick.georgi.family/2021/02/13/on-microcode/","classes":{"dataset":0.4802388847}}
{"title":"TigerBeetle raises $6.4M to power the future of financial accounting infra","description":"https://tigerbeetle.com/blog/2023-01-30-series-seed-announcement/","link":"https://tigerbeetle.com/blog/2023-01-30-series-seed-announcement/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":182},"text":"TigerBeetle raises $6.4M to power the future of financial accounting infra https://tigerbeetle.com/blog/2023-01-30-series-seed-announcement/","classes":{"dataset":0.4957288802}}
{"title":"The \u201cBuild Your Own Redis\u201d Book Is Completed","description":"https://build-your-own.org/blog/20230127_byor/","link":"https://build-your-own.org/blog/20230127_byor/","created":"2023-01-29","tags":["hackernews"],"meta":{"score":581},"text":"The \u201cBuild Your Own Redis\u201d Book Is Completed https://build-your-own.org/blog/20230127_byor/","classes":{"dataset":0.5180597305}}
{"title":"Clowns Without Borders","description":"https://clownswithoutborders.org/","link":"https://clownswithoutborders.org/","created":"2023-01-29","tags":["hackernews"],"meta":{"score":217},"text":"Clowns Without Borders https://clownswithoutborders.org/","classes":{"dataset":0.4815280735}}
{"title":"Light from an ionized state of helium in a distant galaxy","description":"https://www.quantamagazine.org/astronomers-say-they-have-spotted-the-universes-first-stars-20230130/","link":"https://www.quantamagazine.org/astronomers-say-they-have-spotted-the-universes-first-stars-20230130/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":151},"text":"Light from an ionized state of helium in a distant galaxy https://www.quantamagazine.org/astronomers-say-they-have-spotted-the-universes-first-stars-20230130/","classes":{"dataset":0.5083487034}}
{"title":"J&J can\u2019t use bankruptcy to resolve talc-injury lawsuits, appeals court rules","description":"https://www.wsj.com/articles/j-js-talc-bankruptcy-case-thrown-out-by-appeals-court-11675096308","link":"https://www.wsj.com/articles/j-js-talc-bankruptcy-case-thrown-out-by-appeals-court-11675096308","created":"2023-01-30","tags":["hackernews"],"meta":{"score":226},"text":"J&J can\u2019t use bankruptcy to resolve talc-injury lawsuits, appeals court rules https://www.wsj.com/articles/j-js-talc-bankruptcy-case-thrown-out-by-appeals-court-11675096308","classes":{"dataset":0.5171242356}}
{"title":"The Law Does Not Require Legalese","description":"https://writing.kemitchell.com/2023/01/30/Law-Does-Not-Require-Legalese","link":"https://writing.kemitchell.com/2023/01/30/Law-Does-Not-Require-Legalese","created":"2023-01-31","tags":["hackernews"],"meta":{"score":39},"text":"The Law Does Not Require Legalese https://writing.kemitchell.com/2023/01/30/Law-Does-Not-Require-Legalese","classes":{"dataset":0.5209685564}}
{"title":"Story Structure 101: Super Basic Shit","description":"https://channel101.fandom.com/wiki/Story_Structure_101:_Super_Basic_Shit","link":"https://channel101.fandom.com/wiki/Story_Structure_101:_Super_Basic_Shit","created":"2023-01-30","tags":["hackernews"],"meta":{"score":293},"text":"Story Structure 101: Super Basic Shit https://channel101.fandom.com/wiki/Story_Structure_101:_Super_Basic_Shit","classes":{"dataset":0.52496773}}
{"title":"Hypertext Emacs: You may not need org-mode","description":"http://bjornwestergard.com/log/2022-04-19-hypertext-emacs.gmi","link":"http://bjornwestergard.com/log/2022-04-19-hypertext-emacs.gmi","created":"2023-01-30","tags":["hackernews"],"meta":{"score":79},"text":"Hypertext Emacs: You may not need org-mode http://bjornwestergard.com/log/2022-04-19-hypertext-emacs.gmi","classes":{"dataset":0.4981675148}}
{"title":"Relational Floating-Point Arithmetic [pdf]","description":"https://www.cs.toronto.edu/~lczhang/sandre_float2021.pdf","link":"https://www.cs.toronto.edu/~lczhang/sandre_float2021.pdf","created":"2023-01-30","tags":["hackernews"],"meta":{"score":34},"text":"Relational Floating-Point Arithmetic [pdf] https://www.cs.toronto.edu/~lczhang/sandre_float2021.pdf","classes":{"dataset":0.5036752224}}
{"title":"PageRank algorithm for graph databases","description":"https://memgraph.com/blog/pagerank-algorithm-for-graph-databases","link":"https://memgraph.com/blog/pagerank-algorithm-for-graph-databases","created":"2023-01-30","tags":["hackernews"],"meta":{"score":239},"text":"PageRank algorithm for graph databases https://memgraph.com/blog/pagerank-algorithm-for-graph-databases","classes":{"dataset":0.5029825568}}
{"title":"Show HN: ELI5 Powered by GPT-3","description":"https://eli5.gg","link":"https://eli5.gg","created":"2023-01-30","tags":["hackernews"],"meta":{"score":126},"text":"Show HN: ELI5 Powered by GPT-3 https://eli5.gg","classes":{"dataset":0.4571806192}}
{"title":"Rewrite it in Rust","description":"https://github.com/fish-shell/fish-shell/pull/9512","link":"https://github.com/fish-shell/fish-shell/pull/9512","created":"2023-01-31","tags":["hackernews"],"meta":{"score":340},"text":"Rewrite it in Rust https://github.com/fish-shell/fish-shell/pull/9512","classes":{"dataset":0.5175878406}}
{"title":"We've Lost the Plot","description":"https://www.theatlantic.com/magazine/archive/2023/03/tv-politics-entertainment-metaverse/672773/","link":"https://www.theatlantic.com/magazine/archive/2023/03/tv-politics-entertainment-metaverse/672773/","created":"2023-01-31","tags":["hackernews"],"meta":{"score":42},"text":"We've Lost the Plot https://www.theatlantic.com/magazine/archive/2023/03/tv-politics-entertainment-metaverse/672773/","classes":{"dataset":0.5246372223}}
{"title":"A genius at suffering","description":"https://newcriterion.com/issues/2023/2/a-genius-at-suffering","link":"https://newcriterion.com/issues/2023/2/a-genius-at-suffering","created":"2023-01-30","tags":["hackernews"],"meta":{"score":43},"text":"A genius at suffering https://newcriterion.com/issues/2023/2/a-genius-at-suffering","classes":{"dataset":0.526417017}}
{"title":"Russian Trader Named UK\u2019s Biggest Taxpayer","description":"https://news.sky.com/story/tax-list-finds-russian-born-billionaire-has-overtaken-bet356-family-as-uks-top-taxpayer-12796364","link":"https://news.sky.com/story/tax-list-finds-russian-born-billionaire-has-overtaken-bet356-family-as-uks-top-taxpayer-12796364","created":"2023-01-31","tags":["hackernews"],"meta":{"score":5},"text":"Russian Trader Named UK\u2019s Biggest Taxpayer https://news.sky.com/story/tax-list-finds-russian-born-billionaire-has-overtaken-bet356-family-as-uks-top-taxpayer-12796364","classes":{"dataset":0.5029233098}}
{"title":"Foundations of Data Science (2018) [pdf]","description":"https://www.cs.cornell.edu/jeh/book.pdf?file=book.pdf","link":"https://www.cs.cornell.edu/jeh/book.pdf?file=book.pdf","created":"2023-01-30","tags":["hackernews"],"meta":{"score":175},"text":"Foundations of Data Science (2018) [pdf] https://www.cs.cornell.edu/jeh/book.pdf?file=book.pdf","classes":{"dataset":0.5119486451}}
{"title":"A fairy-like robot flies by the power of wind and light","description":"https://techxplore.com/news/2023-01-fairy-like-robot-flies-power.html","link":"https://techxplore.com/news/2023-01-fairy-like-robot-flies-power.html","created":"2023-01-31","tags":["hackernews"],"meta":{"score":8},"text":"A fairy-like robot flies by the power of wind and light https://techxplore.com/news/2023-01-fairy-like-robot-flies-power.html","classes":{"dataset":0.5017692447}}
{"title":"Should private platforms engage in censorship?","description":"https://drewdevault.com/2023/01/30/2023-01-30-Should-private-platforms-engage-in-censorship.html","link":"https://drewdevault.com/2023/01/30/2023-01-30-Should-private-platforms-engage-in-censorship.html","created":"2023-01-31","tags":["hackernews"],"meta":{"score":8},"text":"Should private platforms engage in censorship? https://drewdevault.com/2023/01/30/2023-01-30-Should-private-platforms-engage-in-censorship.html","classes":{"dataset":0.468980968}}
{"title":"Australians scour desert for dangerous radioactive capsule smaller than a penny","description":"https://www.nytimes.com/2023/01/28/world/australia/australia-radioactive-capsule.html","link":"https://www.nytimes.com/2023/01/28/world/australia/australia-radioactive-capsule.html","created":"2023-01-28","tags":["hackernews"],"meta":{"score":278},"text":"Australians scour desert for dangerous radioactive capsule smaller than a penny https://www.nytimes.com/2023/01/28/world/australia/australia-radioactive-capsule.html","classes":{"dataset":0.5110124946}}
{"title":"Japanese explained to programmers","description":"https://lajili.com/posts/post-1/","link":"https://lajili.com/posts/post-1/","created":"2023-01-31","tags":["hackernews"],"meta":{"score":112},"text":"Japanese explained to programmers https://lajili.com/posts/post-1/","classes":{"dataset":0.4761092067}}
{"title":"Over the past 21 months I\u2019ve written a code editor from the ground up","description":"https://edita.vercel.app/blog/approach/","link":"https://edita.vercel.app/blog/approach/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":320},"text":"Over the past 21 months I\u2019ve written a code editor from the ground up https://edita.vercel.app/blog/approach/","classes":{"dataset":0.4922338426}}
{"title":"Insulation: First the body, then the home (2011)","description":"https://www.lowtechmagazine.com/2011/02/body-insulation-thermal-underwear.html","link":"https://www.lowtechmagazine.com/2011/02/body-insulation-thermal-underwear.html","created":"2023-01-30","tags":["hackernews"],"meta":{"score":136},"text":"Insulation: First the body, then the home (2011) https://www.lowtechmagazine.com/2011/02/body-insulation-thermal-underwear.html","classes":{"dataset":0.507349968}}
{"title":"I want to lose every debate","description":"https://sive.rs/led","link":"https://sive.rs/led","created":"2023-01-31","tags":["hackernews"],"meta":{"score":329},"text":"I want to lose every debate https://sive.rs/led","classes":{"dataset":0.5308148265}}
{"title":"UK expected to be only major economy to shrink in 2023 \u2013 IMF","description":"https://www.bbc.co.uk/news/business-64452995","link":"https://www.bbc.co.uk/news/business-64452995","created":"2023-01-31","tags":["hackernews"],"meta":{"score":21},"text":"UK expected to be only major economy to shrink in 2023 \u2013 IMF https://www.bbc.co.uk/news/business-64452995","classes":{"dataset":0.4900874794}}
{"title":"The limits of \"computational photography\"","description":"https://yager.io/comp/comp.html","link":"https://yager.io/comp/comp.html","created":"2023-01-31","tags":["hackernews"],"meta":{"score":216},"text":"The limits of \"computational photography\" https://yager.io/comp/comp.html","classes":{"dataset":0.4963696897}}
{"title":"A Midcentury Bender: Revisiting Mad Men","description":"https://theamericanscholar.org/a-midcentury-bender/","link":"https://theamericanscholar.org/a-midcentury-bender/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":29},"text":"A Midcentury Bender: Revisiting Mad Men https://theamericanscholar.org/a-midcentury-bender/","classes":{"dataset":0.4977111518}}
{"title":"The (first) post-Elizabethan age","description":"https://www.prospectmagazine.co.uk/arts-and-books/blazing-world-post-elizabethan-age","link":"https://www.prospectmagazine.co.uk/arts-and-books/blazing-world-post-elizabethan-age","created":"2023-01-29","tags":["hackernews"],"meta":{"score":8},"text":"The (first) post-Elizabethan age https://www.prospectmagazine.co.uk/arts-and-books/blazing-world-post-elizabethan-age","classes":{"dataset":0.501096189}}
{"title":"Typed Lisp, a primer (2019)","description":"http://alhassy.com/TypedLisp","link":"http://alhassy.com/TypedLisp","created":"2023-01-31","tags":["hackernews"],"meta":{"score":7},"text":"Typed Lisp, a primer (2019) http://alhassy.com/TypedLisp","classes":{"dataset":0.5074318051}}
{"title":"Superconductivity switches on and off in 'magic-angle' graphene","description":"https://phys.org/news/2023-01-superconductivity-magic-angle-graphene.html","link":"https://phys.org/news/2023-01-superconductivity-magic-angle-graphene.html","created":"2023-01-31","tags":["hackernews"],"meta":{"score":8},"text":"Superconductivity switches on and off in 'magic-angle' graphene https://phys.org/news/2023-01-superconductivity-magic-angle-graphene.html","classes":{"dataset":0.4654565156}}
{"title":"Spotify is first music streaming service to surpass 200M paid subscribers","description":"https://www.theverge.com/2023/1/31/23577499/spotify-q4-2022-earnings-release-subscriber-growth-layoffs","link":"https://www.theverge.com/2023/1/31/23577499/spotify-q4-2022-earnings-release-subscriber-growth-layoffs","created":"2023-01-31","tags":["hackernews"],"meta":{"score":13},"text":"Spotify is first music streaming service to surpass 200M paid subscribers https://www.theverge.com/2023/1/31/23577499/spotify-q4-2022-earnings-release-subscriber-growth-layoffs","classes":{"dataset":0.507349968}}
{"title":"Analog computing may be coming back","description":"https://bellmar.medium.com/guess-what-analog-computing-may-be-coming-back-280f8c0329a8","link":"https://bellmar.medium.com/guess-what-analog-computing-may-be-coming-back-280f8c0329a8","created":"2023-01-30","tags":["hackernews"],"meta":{"score":46},"text":"Analog computing may be coming back https://bellmar.medium.com/guess-what-analog-computing-may-be-coming-back-280f8c0329a8","classes":{"dataset":0.5131607652}}
{"title":"Cistercian Numerals","description":"https://kottke.org/23/01/cistercian-numerals","link":"https://kottke.org/23/01/cistercian-numerals","created":"2023-01-31","tags":["hackernews"],"meta":{"score":124},"text":"Cistercian Numerals https://kottke.org/23/01/cistercian-numerals","classes":{"dataset":0.507349968}}
{"title":"Professor Edgerton\u2019s Atomic Camera (2006)","description":"https://www.damninteresting.com/curio/rapatronic-nuclear-photographs/","link":"https://www.damninteresting.com/curio/rapatronic-nuclear-photographs/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":19},"text":"Professor Edgerton\u2019s Atomic Camera (2006) https://www.damninteresting.com/curio/rapatronic-nuclear-photographs/","classes":{"dataset":0.4792414606}}
{"title":"Open source implementation of Google's MusicLM in PyTorch","description":"https://github.com/lucidrains/musiclm-pytorch","link":"https://github.com/lucidrains/musiclm-pytorch","created":"2023-01-31","tags":["hackernews"],"meta":{"score":107},"text":"Open source implementation of Google's MusicLM in PyTorch https://github.com/lucidrains/musiclm-pytorch","classes":{"dataset":0.5195220709}}
{"title":"Proving Earth is a globe","description":"https://mctoon.net/interesting/","link":"https://mctoon.net/interesting/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":60},"text":"Proving Earth is a globe https://mctoon.net/interesting/","classes":{"dataset":0.5146257281}}
{"title":"Portability and the C Language","description":"https://en.wikibooks.org/wiki/Portability_and_the_C_Language","link":"https://en.wikibooks.org/wiki/Portability_and_the_C_Language","created":"2023-01-31","tags":["hackernews"],"meta":{"score":9},"text":"Portability and the C Language https://en.wikibooks.org/wiki/Portability_and_the_C_Language","classes":{"dataset":0.4581734538}}
{"title":"Google Fi seemingly affected by latest T-Mobile data breach","description":"https://9to5google.com/2023/01/30/google-fi-data-breach-tmobile/","link":"https://9to5google.com/2023/01/30/google-fi-data-breach-tmobile/","created":"2023-01-31","tags":["hackernews"],"meta":{"score":176},"text":"Google Fi seemingly affected by latest T-Mobile data breach https://9to5google.com/2023/01/30/google-fi-data-breach-tmobile/","classes":{"dataset":0.5360382199}}
{"title":"The benefits of everything being a buffer in Emacs","description":"https://mbork.pl/2023-01-30_The_benefits_of_everything_being_a_buffer","link":"https://mbork.pl/2023-01-30_The_benefits_of_everything_being_a_buffer","created":"2023-01-30","tags":["hackernews"],"meta":{"score":356},"text":"The benefits of everything being a buffer in Emacs https://mbork.pl/2023-01-30_The_benefits_of_everything_being_a_buffer","classes":{"dataset":0.4856989682}}
{"title":"The army of maths prodigies who helped Brighton conquer the transfer market","description":"https://uk.sports.yahoo.com/news/revealed-200-maths-prodigies-help-070000511.html","link":"https://uk.sports.yahoo.com/news/revealed-200-maths-prodigies-help-070000511.html","created":"2023-01-31","tags":["hackernews"],"meta":{"score":21},"text":"The army of maths prodigies who helped Brighton conquer the transfer market https://uk.sports.yahoo.com/news/revealed-200-maths-prodigies-help-070000511.html","classes":{"dataset":0.5087538362}}
{"title":"Show HN: Generate commit messages using GPT-3","description":"https://github.com/markuswt/gpt-commit","link":"https://github.com/markuswt/gpt-commit","created":"2023-01-31","tags":["hackernews"],"meta":{"score":65},"text":"Show HN: Generate commit messages using GPT-3 https://github.com/markuswt/gpt-commit","classes":{"dataset":0.4966259301}}
{"title":"Hybrid Search and Learning-to-Rank","description":"https://www.pinecone.io/learn/metarank/","link":"https://www.pinecone.io/learn/metarank/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":43},"text":"Hybrid Search and Learning-to-Rank https://www.pinecone.io/learn/metarank/","classes":{"dataset":0.4997121096}}
{"title":"Git archive checksums may change","description":"https://github.blog/changelog/2023-01-30-git-archive-checksums-may-change/","link":"https://github.blog/changelog/2023-01-30-git-archive-checksums-may-change/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":237},"text":"Git archive checksums may change https://github.blog/changelog/2023-01-30-git-archive-checksums-may-change/","classes":{"dataset":0.504543364}}
{"title":"Cargo airships could be big","description":"https://www.elidourado.com/p/cargo-airships","link":"https://www.elidourado.com/p/cargo-airships","created":"2023-01-30","tags":["hackernews"],"meta":{"score":366},"text":"Cargo airships could be big https://www.elidourado.com/p/cargo-airships","classes":{"dataset":0.5135567188}}
{"title":"Twm \u2212 Tab Window Manager for the X Window System","description":"https://www.x.org/releases/X11R7.6/doc/man/man1/twm.1.xhtml","link":"https://www.x.org/releases/X11R7.6/doc/man/man1/twm.1.xhtml","created":"2023-01-31","tags":["hackernews"],"meta":{"score":6},"text":"Twm \u2212 Tab Window Manager for the X Window System https://www.x.org/releases/X11R7.6/doc/man/man1/twm.1.xhtml","classes":{"dataset":0.4959872663}}
{"title":"A Modern Compiler for the French Tax Code (2020)","description":"https://arxiv.org/abs/2011.07966","link":"https://arxiv.org/abs/2011.07966","created":"2023-01-30","tags":["hackernews"],"meta":{"score":185},"text":"A Modern Compiler for the French Tax Code (2020) https://arxiv.org/abs/2011.07966","classes":{"dataset":0.5217141509}}
{"title":"Yandex \u2018leak\u2019 reveals search ranking factors","description":"https://searchengineland.com/yandex-search-ranking-factors-leak-392323","link":"https://searchengineland.com/yandex-search-ranking-factors-leak-392323","created":"2023-01-30","tags":["hackernews"],"meta":{"score":267},"text":"Yandex \u2018leak\u2019 reveals search ranking factors https://searchengineland.com/yandex-search-ranking-factors-leak-392323","classes":{"dataset":0.4993838072}}
{"title":"How computer vision is changing agriculture in 2023","description":"https://voxel51.com/blog/how-computer-vision-is-changing-agriculture-in-2023/","link":"https://voxel51.com/blog/how-computer-vision-is-changing-agriculture-in-2023/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":25},"text":"How computer vision is changing agriculture in 2023 https://voxel51.com/blog/how-computer-vision-is-changing-agriculture-in-2023/","classes":{"dataset":0.515409112}}
{"title":"Berkeley Mono Ligatures Release","description":"https://berkeleygraphics.com/public-affairs/bulletins/BT-002/","link":"https://berkeleygraphics.com/public-affairs/bulletins/BT-002/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":154},"text":"Berkeley Mono Ligatures Release https://berkeleygraphics.com/public-affairs/bulletins/BT-002/","classes":{"dataset":0.4906334877}}
{"title":"WAN router IP address change blamed for global Microsoft 365 outage","description":"https://www.theregister.com/2023/01/30/wan_router_ip_address_change/","link":"https://www.theregister.com/2023/01/30/wan_router_ip_address_change/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":133},"text":"WAN router IP address change blamed for global Microsoft 365 outage https://www.theregister.com/2023/01/30/wan_router_ip_address_change/","classes":{"dataset":0.5037482381}}
{"title":"AirGradient Open Source Air Quality Monitor for CO2 and PM2.5 Measurements","description":"https://www.airgradient.com/open-airgradient/instructions/diy-pro-v37/","link":"https://www.airgradient.com/open-airgradient/instructions/diy-pro-v37/","created":"2023-01-29","tags":["hackernews"],"meta":{"score":544},"text":"AirGradient Open Source Air Quality Monitor for CO2 and PM2.5 Measurements https://www.airgradient.com/open-airgradient/instructions/diy-pro-v37/","classes":{"dataset":0.5148636103}}
{"title":"The Parallel Port","description":"https://computer.rip/2023-01-29-the-parallel-port.html","link":"https://computer.rip/2023-01-29-the-parallel-port.html","created":"2023-01-30","tags":["hackernews"],"meta":{"score":99},"text":"The Parallel Port https://computer.rip/2023-01-29-the-parallel-port.html","classes":{"dataset":0.469819963}}
{"title":"Firefighters forced to smash window of driverless Cruise taxi to stop it","description":"https://www.businessinsider.com/san-francisco-firefighters-smashed-window-driverless-cruise-taxi-stop-it-2023-1","link":"https://www.businessinsider.com/san-francisco-firefighters-smashed-window-driverless-cruise-taxi-stop-it-2023-1","created":"2023-01-30","tags":["hackernews"],"meta":{"score":255},"text":"Firefighters forced to smash window of driverless Cruise taxi to stop it https://www.businessinsider.com/san-francisco-firefighters-smashed-window-driverless-cruise-taxi-stop-it-2023-1","classes":{"dataset":0.4955112934}}
{"title":"L\u00f6b and m\u00f6b: strange loops in Haskell (2015)","description":"https://github.com/quchen/articles/blob/master/loeb-moeb.md","link":"https://github.com/quchen/articles/blob/master/loeb-moeb.md","created":"2023-01-30","tags":["hackernews"],"meta":{"score":147},"text":"L\u00f6b and m\u00f6b: strange loops in Haskell (2015) https://github.com/quchen/articles/blob/master/loeb-moeb.md","classes":{"dataset":0.4956139922}}
{"title":"The high cost of expensive housing and how Auckland fixed it","description":"https://brettongoods.substack.com/p/the-high-cost-of-expensive-housing","link":"https://brettongoods.substack.com/p/the-high-cost-of-expensive-housing","created":"2023-01-30","tags":["hackernews"],"meta":{"score":89},"text":"The high cost of expensive housing and how Auckland fixed it https://brettongoods.substack.com/p/the-high-cost-of-expensive-housing","classes":{"dataset":0.5521400571}}
{"title":"Chronophoto","description":"https://www.chronophoto.app/game.html","link":"https://www.chronophoto.app/game.html","created":"2023-01-28","tags":["hackernews"],"meta":{"score":1077},"text":"Chronophoto https://www.chronophoto.app/game.html","classes":{"dataset":0.4855384529}}
{"title":"Determine durations with monotonic clocks if available","description":"http://rachelbythebay.com/w/2023/01/29/bash/","link":"http://rachelbythebay.com/w/2023/01/29/bash/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":68},"text":"Determine durations with monotonic clocks if available http://rachelbythebay.com/w/2023/01/29/bash/","classes":{"dataset":0.5074039698}}
{"title":"SQL should be the default choice for data transformation logic","description":"https://www.robinlinacre.com/recommend_sql/","link":"https://www.robinlinacre.com/recommend_sql/","created":"2023-01-30","tags":["hackernews"],"meta":{"score":421},"text":"SQL should be the default choice for data transformation logic https://www.robinlinacre.com/recommend_sql/","classes":{"dataset":0.4522444308}}
{"title":"Yahoo is making a return to search","description":"https://searchengineland.com/yahoo-is-making-a-return-to-search-392341","link":"https://searchengineland.com/yahoo-is-making-a-return-to-search-392341","created":"2023-01-31","tags":["hackernews"],"meta":{"score":129},"text":"Yahoo is making a return to search https://searchengineland.com/yahoo-is-making-a-return-to-search-392341","classes":{"dataset":0.5247015357}}
{"title":"Show HN: Deploy Button for GPT-3 API Back Ends","description":"https://www.steamship.com/build/prompt-apis","link":"https://www.steamship.com/build/prompt-apis","created":"2023-01-30","tags":["hackernews"],"meta":{"score":69},"text":"Show HN: Deploy Button for GPT-3 API Back Ends https://www.steamship.com/build/prompt-apis","classes":{"dataset":0.5067944527}}
{"title":"We've Lost the Plot","description":"https://www.theatlantic.com/magazine/archive/2023/03/tv-politics-entertainment-metaverse/672773/","link":"https://www.theatlantic.com/magazine/archive/2023/03/tv-politics-entertainment-metaverse/672773/","created":"2023-01-31","tags":["hackernews"],"meta":{"score":42},"text":"We've Lost the Plot https://www.theatlantic.com/magazine/archive/2023/03/tv-politics-entertainment-metaverse/672773/","classes":{"dataset":0.526417017}}
{"title":"The Mathematical Center of the Universe (2021)","description":"https://www.privatdozent.co/p/the-mathematical-center-of-the-universe-28f","link":"https://www.privatdozent.co/p/the-mathematical-center-of-the-universe-28f","created":"2023-01-30","tags":["hackernews"],"meta":{"score":86},"text":"The Mathematical Center of the Universe (2021) https://www.privatdozent.co/p/the-mathematical-center-of-the-universe-28f","classes":{"dataset":0.5378440022}}
{"title":"Small-Scale Automation","description":"https://www.johndcook.com/blog/2023/01/29/small-scale-automation/","link":"https://www.johndcook.com/blog/2023/01/29/small-scale-automation/","created":"2023-01-29","tags":["hackernews"],"meta":{"score":39},"text":"Small-Scale Automation https://www.johndcook.com/blog/2023/01/29/small-scale-automation/","classes":{"dataset":0.5460892916}}
{"title":"My First Recession","description":"https://gadi.fm/posts/recession/","link":"https://gadi.fm/posts/recession/","created":"2023-01-31","tags":["hackernews"],"meta":{"score":8},"text":"My First Recession https://gadi.fm/posts/recession/","classes":{"dataset":0.4936920404}}
{"title":"Train CIFAR10 to 94% in under 10 seconds on a single A100","description":"https://github.com/tysam-code/hlb-CIFAR10","link":"https://github.com/tysam-code/hlb-CIFAR10","created":"2023-01-30","tags":["hackernews"],"meta":{"score":148},"text":"Train CIFAR10 to 94% in under 10 seconds on a single A100 https://github.com/tysam-code/hlb-CIFAR10","classes":{"dataset":0.4951229095}}
{"title":"Beginner in PromtDesign","description":"Hey there,\n\nI've recently just discovered the potential AI has in the foreseeable future with the use of natural language models. I'm as new to this topic of study such as the day I was born out my mothers womb. Could anyone please give me any guidance into certain courses and documents for me to study? Almost like a PromtEngineering for dummies book ect. All the best!","link":"https://www.reddit.com/r/PromptDesign/comments/10o8982/beginner_in_promtdesign/","created":"2023-01-29","tags":["reddit","promptdesign","prompteng"],"meta":{"num_comments":2},"text":"Beginner in PromtDesign Hey there,\n\nI've recently just discovered the potential AI has in the foreseeable future with the use of natural language models. I'm as new to this topic of study such as the day I was born out my mothers womb. Could anyone please give me any guidance into certain courses and documents for me to study? Almost like a PromtEngineering for dummies book ect. All the best!","classes":{"dataset":0.5110124946}}
{"title":"Tuesday Daily Thread: Advanced questions","description":"Have some burning questions on advanced Python topics? Use this thread to ask more advanced questions related to Python.\n\n**If your question is a beginner question we hold a beginner Daily Thread tomorrow (Wednesday) where you can ask any question! We may remove questions here and ask you to resubmit tomorrow.**\n\nThis thread may be fairly low volume in replies, if you don't receive a response we recommend looking at r/LearnPython or joining the Python Discord server at [https://discord.gg/python](https://discord.gg/python) where you stand a better chance of receiving a response.","link":"https://www.reddit.com/r/Python/comments/10pid6b/tuesday_daily_thread_advanced_questions/","created":"2023-01-31","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Tuesday Daily Thread: Advanced questions Have some burning questions on advanced Python topics? Use this thread to ask more advanced questions related to Python.\n\n**If your question is a beginner question we hold a beginner Daily Thread tomorrow (Wednesday) where you can ask any question! We may remove questions here and ask you to resubmit tomorrow.**\n\nThis thread may be fairly low volume in replies, if you don't receive a response we recommend looking at r/LearnPython or joining the Python Discord server at [https://discord.gg/python](https://discord.gg/python) where you stand a better chance of receiving a response.","classes":{"dataset":0.4687213302}}
{"title":"Making Automatic YouTube Videos with Python","description":"Hi everyone! Awhile back I had the idea to fully automate a YouTube channel to see how successful it could become. I'm not new to programming, but I certainly am to Python.\n\nHere's a video I made explaining the process: [https://youtu.be/ZmSb3LZDdf0](https://youtu.be/ZmSb3LZDdf0)\n\nThe way I started was to use those terrible Reddit TikTok/Reel/Shorts where people find a popular post and essentially just read it out with some funny comments. Luckily for me, people already use text-to-speech instead of their own voice, so my solution would fit right in.\n\nTo get content, I first used PRAW to access the Reddit API. I filter through that response and used pyttsv3 to generate an .mp3 of the voiceover. Then Selenium and Firefox made getting screenshots of each comment/post title really easy.\n\nThe only tricky part for me was learning how to use MoviePy to package everything up into a neatly-edited video. I explain this much better in the video above, but it basically consists of creating clip objects with each of the pictures and voiceovers, then connecting them in a CompositeVideoClip.\n\nI'm curious how many others have tried this, as I'm sure the majority of popular stolen Reddit posts can't be all made by hand.","link":"https://www.reddit.com/r/Python/comments/10peps0/making_automatic_youtube_videos_with_python/","created":"2023-01-30","tags":["reddit","python"],"meta":{"num_comments":21},"text":"Making Automatic YouTube Videos with Python Hi everyone! Awhile back I had the idea to fully automate a YouTube channel to see how successful it could become. I'm not new to programming, but I certainly am to Python.\n\nHere's a video I made explaining the process: [https://youtu.be/ZmSb3LZDdf0](https://youtu.be/ZmSb3LZDdf0)\n\nThe way I started was to use those terrible Reddit TikTok/Reel/Shorts where people find a popular post and essentially just read it out with some funny comments. Luckily for me, people already use text-to-speech instead of their own voice, so my solution would fit right in.\n\nTo get content, I first used PRAW to access the Reddit API. I filter through that response and used pyttsv3 to generate an .mp3 of the voiceover. Then Selenium and Firefox made getting screenshots of each comment/post title really easy.\n\nThe only tricky part for me was learning how to use MoviePy to package everything up into a neatly-edited video. I explain this much better in the video above, but it basically consists of creating clip objects with each of the pictures and voiceovers, then connecting them in a CompositeVideoClip.\n\nI'm curious how many others have tried this, as I'm sure the majority of popular stolen Reddit posts can't be all made by hand.","classes":{"dataset":0.3489640653}}
{"title":"PyCharm has become horrible to work with over SSH interpreter, any similar experiences?","description":"I have been using PyCharm pro for a few years now. I dont remember when exactly but probably last year they reworked the way SSH interpreters are configured?\n\nFor a while now,  I constantly have problems with this stupid config. Maybe I am doing something wrong and it's me who is stupid but it is just so frustrating! It all worked nicely before with some simple settings.\n\n&amp;#x200B;\n\nNow I have problems like:\n\n\\-  confusing coupling of deployment and SSH\n\n\\- deployment not happening where it is supposed to be (see above)\n\n\\- SSH option wizard no longer supports pointing to anaconda directly and somehow changed to be not as intuitive as it used to be\n\n\\- debugging is a feaking hell. PyCharm always wants to jump to some temporary files (which dont have my breakpoints) and it takes me a day to try all kind of settings until it magically works and I have no clue what finally got me to the point...\n\nI have several projects on several servers and this is becoming a huge blocker in my work, being not able to debug properly.\n\n&amp;#x200B;\n\nPlease tell me I am not the only one? ","link":"https://www.reddit.com/r/Python/comments/10pyujg/pycharm_has_become_horrible_to_work_with_over_ssh/","created":"2023-01-31","tags":["reddit","python"],"meta":{"num_comments":6},"text":"PyCharm has become horrible to work with over SSH interpreter, any similar experiences? I have been using PyCharm pro for a few years now. I dont remember when exactly but probably last year they reworked the way SSH interpreters are configured?\n\nFor a while now,  I constantly have problems with this stupid config. Maybe I am doing something wrong and it's me who is stupid but it is just so frustrating! It all worked nicely before with some simple settings.\n\n&amp;#x200B;\n\nNow I have problems like:\n\n\\-  confusing coupling of deployment and SSH\n\n\\- deployment not happening where it is supposed to be (see above)\n\n\\- SSH option wizard no longer supports pointing to anaconda directly and somehow changed to be not as intuitive as it used to be\n\n\\- debugging is a feaking hell. PyCharm always wants to jump to some temporary files (which dont have my breakpoints) and it takes me a day to try all kind of settings until it magically works and I have no clue what finally got me to the point...\n\nI have several projects on several servers and this is becoming a huge blocker in my work, being not able to debug properly.\n\n&amp;#x200B;\n\nPlease tell me I am not the only one? ","classes":{"dataset":0.5147054195}}
{"title":"AWS lambda payload in Pythonic way.","description":"Following is my code snippet to return payload or the failure message for future error handling.However, I would like to improve the readability and maintainability.\n\n        if reportId is not None:\n            return {'payload': reportId}\n        # Future error handling\n        else:\n            return {'message': 'Fail to create report'}\n\nFollowing is the answer given by Chat GPT\n\n`return {'payload': reportId} if reportId else {'message': 'Fail to create Amazon Business &amp; Traffic report'}`\n\nCould you let me know which one is the better one, please?","link":"https://www.reddit.com/r/Python/comments/10pxx2f/aws_lambda_payload_in_pythonic_way/","created":"2023-01-31","tags":["reddit","python"],"meta":{"num_comments":2},"text":"AWS lambda payload in Pythonic way. Following is my code snippet to return payload or the failure message for future error handling.However, I would like to improve the readability and maintainability.\n\n        if reportId is not None:\n            return {'payload': reportId}\n        # Future error handling\n        else:\n            return {'message': 'Fail to create report'}\n\nFollowing is the answer given by Chat GPT\n\n`return {'payload': reportId} if reportId else {'message': 'Fail to create Amazon Business &amp; Traffic report'}`\n\nCould you let me know which one is the better one, please?","classes":{"dataset":0.4818770289}}
{"title":"Looking for a tutorial on building restful apis in the functional paradigm in python","description":"Hi Python, \n\nI can't seem to find any tutorials on building Restful API's using the Functional Paradigm over the Object Oriented Paradigm with Python. Could you link them if you know of any?","link":"https://www.reddit.com/r/Python/comments/10ps5us/looking_for_a_tutorial_on_building_restful_apis/","created":"2023-01-31","tags":["reddit","python"],"meta":{"num_comments":2},"text":"Looking for a tutorial on building restful apis in the functional paradigm in python Hi Python, \n\nI can't seem to find any tutorials on building Restful API's using the Functional Paradigm over the Object Oriented Paradigm with Python. Could you link them if you know of any?","classes":{"dataset":0.4176145196}}
{"title":"Computer Vision Autopilot","description":" For those of you interested in aviation and programming, I\u2019d like to share this open-source, computer vision flight controller that I built. Any feedback that you have would be greatly appreciated.\n\nhttps://preview.redd.it/27vegagrf8fa1.png?width=1280&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3b9710c1d2cfe070f09c7e475ba57703593c7e78\n\n[https://youtu.be/BQiIkhdTP4o](https://youtu.be/BQiIkhdTP4o)","link":"https://www.reddit.com/r/Python/comments/10pbmqn/computer_vision_autopilot/","created":"2023-01-30","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Computer Vision Autopilot  For those of you interested in aviation and programming, I\u2019d like to share this open-source, computer vision flight controller that I built. Any feedback that you have would be greatly appreciated.\n\nhttps://preview.redd.it/27vegagrf8fa1.png?width=1280&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3b9710c1d2cfe070f09c7e475ba57703593c7e78\n\n[https://youtu.be/BQiIkhdTP4o](https://youtu.be/BQiIkhdTP4o)","classes":{"dataset":0.3894092739}}
{"title":"Use cases for PySide","description":"I think my next project will include working with QT applications using a PySide2. As I\u2019m learning the tooling I wanted to ask the community what use cases or application types you know are trending (?) with QT and Python.","link":"https://www.reddit.com/r/Python/comments/10pknit/use_cases_for_pyside/","created":"2023-01-31","tags":["reddit","python"],"meta":{"num_comments":2},"text":"Use cases for PySide I think my next project will include working with QT applications using a PySide2. As I\u2019m learning the tooling I wanted to ask the community what use cases or application types you know are trending (?) with QT and Python.","classes":{"dataset":0.4446522295}}
{"title":"Stacks and Queues in Python","description":"Hey everyone, I've written this article that explains  stacks and queues in Python and also their implementation. [https://medium.com/@azizbelaweid/stacks-queues-in-python-explained-c164bde0561e](https://medium.com/@azizbelaweid/stacks-queues-in-python-explained-c164bde0561e) Feel free to check it out and give me your feedback.","link":"https://www.reddit.com/r/Python/comments/10oyssl/stacks_and_queues_in_python/","created":"2023-01-30","tags":["reddit","python"],"meta":{"num_comments":6},"text":"Stacks and Queues in Python Hey everyone, I've written this article that explains  stacks and queues in Python and also their implementation. [https://medium.com/@azizbelaweid/stacks-queues-in-python-explained-c164bde0561e](https://medium.com/@azizbelaweid/stacks-queues-in-python-explained-c164bde0561e) Feel free to check it out and give me your feedback.","classes":{"dataset":0.0117604183}}
{"title":"Quaker: A paginated client for the USGS earthquake database","description":"Hi! This is a small little project that came out of a hackathon late last year. I was curious about doing some data analysis in earthquake times and locations, and came across this public database from USGS (which is well-documented: https://earthquake.usgs.gov/fdsnws/event/1/). However their public API has a hard limit on query results: it will only accept queries that have less than 20000 results.   \n\n\nThough not super-fast, I thought that it would be possible to run queries that exceed this by recursively breaking up the results into smaller queries. And it was! So I decided to build out the initial script into it's own repo.  \n\nIntroducing [Quaker](https://github.com/BlakeJC94/quaker)! I've just finished the last major refactor and completed the full implementation of the USGS API, so I decided it was finally worthy of a v1.0.0 release. \n\n\nThrough this project, I learned about \n- Using argparse and auto-generating help/usage docs\n- Using the requests library \n- Mocking responses in PyTest\n- Nested subclassing and mixins\n- Caching result IDs using a deque\n\n\nSomething I'd be keen to add next would be some dash-app functionality (similar to what's on their [website](https://earthquake.usgs.gov/earthquakes/search/)), Pull requests and discussion is welcome. Not sure if anyone would find it useful, but it was an entertaining project to tinker with. \n\nThanks for having a gander!","link":"https://www.reddit.com/r/Python/comments/10oybdv/quaker_a_paginated_client_for_the_usgs_earthquake/","created":"2023-01-30","tags":["reddit","python"],"meta":{"num_comments":3},"text":"Quaker: A paginated client for the USGS earthquake database Hi! This is a small little project that came out of a hackathon late last year. I was curious about doing some data analysis in earthquake times and locations, and came across this public database from USGS (which is well-documented: https://earthquake.usgs.gov/fdsnws/event/1/). However their public API has a hard limit on query results: it will only accept queries that have less than 20000 results.   \n\n\nThough not super-fast, I thought that it would be possible to run queries that exceed this by recursively breaking up the results into smaller queries. And it was! So I decided to build out the initial script into it's own repo.  \n\nIntroducing [Quaker](https://github.com/BlakeJC94/quaker)! I've just finished the last major refactor and completed the full implementation of the USGS API, so I decided it was finally worthy of a v1.0.0 release. \n\n\nThrough this project, I learned about \n- Using argparse and auto-generating help/usage docs\n- Using the requests library \n- Mocking responses in PyTest\n- Nested subclassing and mixins\n- Caching result IDs using a deque\n\n\nSomething I'd be keen to add next would be some dash-app functionality (similar to what's on their [website](https://earthquake.usgs.gov/earthquakes/search/)), Pull requests and discussion is welcome. Not sure if anyone would find it useful, but it was an entertaining project to tinker with. \n\nThanks for having a gander!","classes":{"dataset":0.5307850242}}
{"title":"I don't understand urllib redirections.","description":"Hello im trying to understand a few things about redirection.\n\nCan someone explain to me why I don't get redirected when I try to open [http://www.google.com](http://www.google.com/) with urllib. Meanwhile I get the redirection for [http://www.toto.fr](http://www.toto.fr/) which redirect to [https://www.toto.fr](https://www.toto.fr/).\n\nIn firefox those two http urls are well redirected to https.\n\n\\&gt;&gt;&gt; url = '[http://www.toto.fr](http://www.toto.fr/)'\n\n\\&gt;&gt;&gt; r = request.urlopen(url)\n\n\\&gt;&gt;&gt; r.url\n\n'[https://www.toto.fr/](https://www.toto.fr/)'\n\n\\&gt;&gt;&gt; url = '[http://www.google.com](http://www.google.com/)'\n\n\\&gt;&gt;&gt; r= request.urlopen(url)\n\n\\&gt;&gt;&gt; r.url\n\n'[http://www.google.com](http://www.google.com/)'","link":"https://www.reddit.com/r/Python/comments/10pd88r/i_dont_understand_urllib_redirections/","created":"2023-01-30","tags":["reddit","python"],"meta":{"num_comments":7},"text":"I don't understand urllib redirections. Hello im trying to understand a few things about redirection.\n\nCan someone explain to me why I don't get redirected when I try to open [http://www.google.com](http://www.google.com/) with urllib. Meanwhile I get the redirection for [http://www.toto.fr](http://www.toto.fr/) which redirect to [https://www.toto.fr](https://www.toto.fr/).\n\nIn firefox those two http urls are well redirected to https.\n\n\\&gt;&gt;&gt; url = '[http://www.toto.fr](http://www.toto.fr/)'\n\n\\&gt;&gt;&gt; r = request.urlopen(url)\n\n\\&gt;&gt;&gt; r.url\n\n'[https://www.toto.fr/](https://www.toto.fr/)'\n\n\\&gt;&gt;&gt; url = '[http://www.google.com](http://www.google.com/)'\n\n\\&gt;&gt;&gt; r= request.urlopen(url)\n\n\\&gt;&gt;&gt; r.url\n\n'[http://www.google.com](http://www.google.com/)'","classes":{"dataset":0.3355639279}}
{"title":"Best practice for capping a softmax","description":"I'd like to train a neural network where the softmax output has a minimum possible probability. During training, none of the probabilities should go below this minimum. Basically I want to avoid the logits from becoming too different from each other so that none of the output categories are ever completely excluded in a prediction, a sort of smoothing. What's the best way to do this during training?","link":"https://www.reddit.com/r/deeplearning/comments/10puvih/best_practice_for_capping_a_softmax/","created":"2023-01-31","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":12},"text":"Best practice for capping a softmax I'd like to train a neural network where the softmax output has a minimum possible probability. During training, none of the probabilities should go below this minimum. Basically I want to avoid the logits from becoming too different from each other so that none of the output categories are ever completely excluded in a prediction, a sort of smoothing. What's the best way to do this during training?","classes":{"dataset":0.2944986224}}
{"title":"testing pre trained models","description":" hello  everyone, I'm a beginner working on object detection, I tried different  pre-trained DL models to get predictions, and to compare them I need to  test them using mAP and other metrics, but I have no idea how can u  guys give me a code example?","link":"https://www.reddit.com/r/deeplearning/comments/10pwsfg/testing_pre_trained_models/","created":"2023-01-31","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":0},"text":"testing pre trained models  hello  everyone, I'm a beginner working on object detection, I tried different  pre-trained DL models to get predictions, and to compare them I need to  test them using mAP and other metrics, but I have no idea how can u  guys give me a code example?","classes":{"dataset":0.1945260316}}
{"title":"[D] Patenting Research Papers?","description":"As a fan of AutoML, I was reading some notorious papers on the subject, and noticed that one author in particular Barret Zoph, arguable one of the founding fathers of AutoML in deep learning, patents his research papers...\n\n[https://patents.justia.com/inventor/barret-zoph](https://patents.justia.com/inventor/barret-zoph)\n\n[https://scholar.google.com.tr/citations?hl=tr&amp;user=NL\\_7iTwAAAAJ&amp;view\\_op=list\\_works](https://scholar.google.com.tr/citations?hl=tr&amp;user=NL_7iTwAAAAJ&amp;view_op=list_works) (crl-f search US Patent App on the page)\n\nWhat would be the reason to patent research papers? Especially if the paper you're presenting literally details the thing that you presenting... with code...","link":"https://www.reddit.com/r/deeplearning/comments/10pfcmh/d_patenting_research_papers/","created":"2023-01-30","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":1},"text":"[D] Patenting Research Papers? As a fan of AutoML, I was reading some notorious papers on the subject, and noticed that one author in particular Barret Zoph, arguable one of the founding fathers of AutoML in deep learning, patents his research papers...\n\n[https://patents.justia.com/inventor/barret-zoph](https://patents.justia.com/inventor/barret-zoph)\n\n[https://scholar.google.com.tr/citations?hl=tr&amp;user=NL\\_7iTwAAAAJ&amp;view\\_op=list\\_works](https://scholar.google.com.tr/citations?hl=tr&amp;user=NL_7iTwAAAAJ&amp;view_op=list_works) (crl-f search US Patent App on the page)\n\nWhat would be the reason to patent research papers? Especially if the paper you're presenting literally details the thing that you presenting... with code...","classes":{"dataset":0.2928888202}}
{"title":"How to evaluate the F1 score values from LightGBM","description":"I am applying LightGBM for a prediction task, and I would like to understand how good / bad my model is. From what I understood, usually F1 scores below 0.5 are considered bad. Does anyone have a good reference for this? Thanksgood/bad","link":"https://www.reddit.com/r/deeplearning/comments/10ow3ec/how_to_evaluate_the_f1_score_values_from_lightgbm/","created":"2023-01-30","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":2},"text":"How to evaluate the F1 score values from LightGBM I am applying LightGBM for a prediction task, and I would like to understand how good / bad my model is. From what I understood, usually F1 scores below 0.5 are considered bad. Does anyone have a good reference for this? Thanksgood/bad","classes":{"dataset":0.4295502603}}
{"title":"If anyone know answer of my question, please tell me","description":"so, I have been learning what DL is and how NN learns to do stuff. From what I understand is the repeated iteration will take random weights and at some point those weights will be kinda perfect for the given task (plz correct me if i'm wrong)\n\nOk, so lets take an example of a task like path finding AI, so we make a NN and train it to go from point A to point B, now it is trained and doing nice and goes to point b perfectly, SO here the weights are set to go from point A to point B right?\n\nWhat if we give the point B somewhere else, How will the AI get perfect weights as the current weights are only perfect for current point B\n\nWhat if we put an obstacle in between point A and B, how will the NN set weights, or is it something like a range of weights which are perfect for any given task for NN\n\n&amp;#x200B;\n\nIDK if I explained it right, plz comment if you have question about my question, and answer also\ud83d\udc95","link":"https://www.reddit.com/r/deeplearning/comments/10ohqyw/if_anyone_know_answer_of_my_question_please_tell/","created":"2023-01-29","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":6},"text":"If anyone know answer of my question, please tell me so, I have been learning what DL is and how NN learns to do stuff. From what I understand is the repeated iteration will take random weights and at some point those weights will be kinda perfect for the given task (plz correct me if i'm wrong)\n\nOk, so lets take an example of a task like path finding AI, so we make a NN and train it to go from point A to point B, now it is trained and doing nice and goes to point b perfectly, SO here the weights are set to go from point A to point B right?\n\nWhat if we give the point B somewhere else, How will the AI get perfect weights as the current weights are only perfect for current point B\n\nWhat if we put an obstacle in between point A and B, how will the NN set weights, or is it something like a range of weights which are perfect for any given task for NN\n\n&amp;#x200B;\n\nIDK if I explained it right, plz comment if you have question about my question, and answer also\ud83d\udc95","classes":{"dataset":0.1859265417}}
{"title":"[Project] Lanytek Audio2Midi Transcription Service","description":"Hello everyone! \n\nWe're excited to introduce our audio2midi transcription service, which transforms music audio into an instrumental midi file and a pdf music sheet. we're providing \\~200 requests per month for free. \n\nIf you're interested, give it a try and see what it can do for you!\n\n[https://rapidapi.com/JC1DA/api/lanytek-audio2midi](https://rapidapi.com/JC1DA/api/lanytek-audio2midi)","link":"https://www.reddit.com/r/deeplearning/comments/10o4jd4/project_lanytek_audio2midi_transcription_service/","created":"2023-01-29","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":1},"text":"[Project] Lanytek Audio2Midi Transcription Service Hello everyone! \n\nWe're excited to introduce our audio2midi transcription service, which transforms music audio into an instrumental midi file and a pdf music sheet. we're providing \\~200 requests per month for free. \n\nIf you're interested, give it a try and see what it can do for you!\n\n[https://rapidapi.com/JC1DA/api/lanytek-audio2midi](https://rapidapi.com/JC1DA/api/lanytek-audio2midi)","classes":{"dataset":0.4419723153}}
{"title":"[P] I launched \u201cCatchGPT\u201d, a supervised model trained with millions of text examples, to detect GPT created content","description":"I\u2019m an ML Engineer at Hive AI and I\u2019ve been working on a ChatGPT Detector.\n\nHere is a free demo we have up: [https://hivemoderation.com/ai-generated-content-detection](https://hivemoderation.com/ai-generated-content-detection)\n\nFrom our benchmarks it\u2019s significantly better than similar solutions like GPTZero and OpenAI\u2019s GPT2 Output Detector. On our internal datasets, we\u2019re seeing balanced accuracies of &gt;99% for our own model compared to around 60% for GPTZero and 84% for OpenAI\u2019s GPT2 Detector.\n\nFeel free to try it out and let us know if you have any feedback!","link":"https://www.reddit.com/r/MachineLearning/comments/10pb1y3/p_i_launched_catchgpt_a_supervised_model_trained/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":173},"text":"[P] I launched \u201cCatchGPT\u201d, a supervised model trained with millions of text examples, to detect GPT created content I\u2019m an ML Engineer at Hive AI and I\u2019ve been working on a ChatGPT Detector.\n\nHere is a free demo we have up: [https://hivemoderation.com/ai-generated-content-detection](https://hivemoderation.com/ai-generated-content-detection)\n\nFrom our benchmarks it\u2019s significantly better than similar solutions like GPTZero and OpenAI\u2019s GPT2 Output Detector. On our internal datasets, we\u2019re seeing balanced accuracies of &gt;99% for our own model compared to around 60% for GPTZero and 84% for OpenAI\u2019s GPT2 Detector.\n\nFeel free to try it out and let us know if you have any feedback!","classes":{"dataset":0.5612388253}}
{"title":"[R] Parsel: A (De-)compositional Framework for Algorithmic Reasoning with Language Models - Stanford University Eric Zelikman et al - Beats prior code generation sota by over 75%!","description":"Paper: [https://arxiv.org/abs/2212.10561](https://arxiv.org/abs/2212.10561) \n\nGithub: [https://github.com/ezelikman/parsel](https://github.com/ezelikman/parsel) \n\nTwitter: [https://twitter.com/ericzelikman/status/1618426056163356675?s=20](https://twitter.com/ericzelikman/status/1618426056163356675?s=20) \n\nWebsite: [https://zelikman.me/parselpaper/](https://zelikman.me/parselpaper/) \n\nCode Generation on APPS Leaderboard: [https://paperswithcode.com/sota/code-generation-on-apps](https://paperswithcode.com/sota/code-generation-on-apps) \n\nAbstract:\n\n&gt;Despite recent success in large language model (LLM) reasoning, **LLMs struggle with hierarchical multi-step reasoning tasks like generating complex programs.** For these tasks, **humans often start with a high-level algorithmic design and implement each part gradually.** We introduce Parsel, a framework enabling automatic implementation and validation of complex algorithms with code LLMs, taking hierarchical function descriptions in natural language as input. We show that **Parsel can be used across domains requiring hierarchical reasoning, including program synthesis, robotic planning, and theorem proving.** We show that LLMs generating Parsel solve more competition-level problems in the APPS dataset, resulting in **pass rates that are over 75% higher than prior results from directly sampling AlphaCode and Codex**, while often using a smaller sample budget. We also find that LLM-generated **robotic plans using Parsel as an intermediate language are more than twice as likely to be considered accurate than directly generated plans.** Lastly, we explore how Parsel addresses LLM limitations and discuss how Parsel may be useful for human programmers. \n\nhttps://preview.redd.it/66zehsdps6fa1.jpg?width=811&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=96db4cb832def624ad10f7383cde56c1444dcbcc\n\nhttps://preview.redd.it/is4pzwdps6fa1.jpg?width=1638&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5e6c3137b982c91c658b58d286e5036a46a7d55d\n\nhttps://preview.redd.it/szkbb0eps6fa1.jpg?width=711&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6eacbd0cdfc8ecc2c21ad1a46d87d8f367d9bbb5\n\nhttps://preview.redd.it/6lk1wzdps6fa1.jpg?width=1468&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5a37d08a5677d927c1b017d711558a6d859e8f3c\n\nhttps://preview.redd.it/8h7p8vdps6fa1.jpg?width=1177&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3e9926040e6af04ec8945fcfe81e51b5c94d5913","link":"https://www.reddit.com/r/MachineLearning/comments/10p3afl/r_parsel_a_decompositional_framework_for/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":7},"text":"[R] Parsel: A (De-)compositional Framework for Algorithmic Reasoning with Language Models - Stanford University Eric Zelikman et al - Beats prior code generation sota by over 75%! Paper: [https://arxiv.org/abs/2212.10561](https://arxiv.org/abs/2212.10561) \n\nGithub: [https://github.com/ezelikman/parsel](https://github.com/ezelikman/parsel) \n\nTwitter: [https://twitter.com/ericzelikman/status/1618426056163356675?s=20](https://twitter.com/ericzelikman/status/1618426056163356675?s=20) \n\nWebsite: [https://zelikman.me/parselpaper/](https://zelikman.me/parselpaper/) \n\nCode Generation on APPS Leaderboard: [https://paperswithcode.com/sota/code-generation-on-apps](https://paperswithcode.com/sota/code-generation-on-apps) \n\nAbstract:\n\n&gt;Despite recent success in large language model (LLM) reasoning, **LLMs struggle with hierarchical multi-step reasoning tasks like generating complex programs.** For these tasks, **humans often start with a high-level algorithmic design and implement each part gradually.** We introduce Parsel, a framework enabling automatic implementation and validation of complex algorithms with code LLMs, taking hierarchical function descriptions in natural language as input. We show that **Parsel can be used across domains requiring hierarchical reasoning, including program synthesis, robotic planning, and theorem proving.** We show that LLMs generating Parsel solve more competition-level problems in the APPS dataset, resulting in **pass rates that are over 75% higher than prior results from directly sampling AlphaCode and Codex**, while often using a smaller sample budget. We also find that LLM-generated **robotic plans using Parsel as an intermediate language are more than twice as likely to be considered accurate than directly generated plans.** Lastly, we explore how Parsel addresses LLM limitations and discuss how Parsel may be useful for human programmers. \n\nhttps://preview.redd.it/66zehsdps6fa1.jpg?width=811&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=96db4cb832def624ad10f7383cde56c1444dcbcc\n\nhttps://preview.redd.it/is4pzwdps6fa1.jpg?width=1638&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5e6c3137b982c91c658b58d286e5036a46a7d55d\n\nhttps://preview.redd.it/szkbb0eps6fa1.jpg?width=711&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6eacbd0cdfc8ecc2c21ad1a46d87d8f367d9bbb5\n\nhttps://preview.redd.it/6lk1wzdps6fa1.jpg?width=1468&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=5a37d08a5677d927c1b017d711558a6d859e8f3c\n\nhttps://preview.redd.it/8h7p8vdps6fa1.jpg?width=1177&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=3e9926040e6af04ec8945fcfe81e51b5c94d5913","classes":{"dataset":0.1377312541}}
{"title":"[D] Towards A Token-Free Future In NLP","description":"[https://peltarion.com/blog/data-science/towards-a-token-free-future-in-nlp](https://peltarion.com/blog/data-science/towards-a-token-free-future-in-nlp)","link":"https://www.reddit.com/r/MachineLearning/comments/10pb982/d_towards_a_tokenfree_future_in_nlp/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":2},"text":"[D] Towards A Token-Free Future In NLP [https://peltarion.com/blog/data-science/towards-a-token-free-future-in-nlp](https://peltarion.com/blog/data-science/towards-a-token-free-future-in-nlp)","classes":{"dataset":0.5673876405}}
{"title":"[D] What's stopping you from working on speech and voice?","description":"I've been working in the speech and voice space for a while now and am now building out some tooling in the space to make it easier for researchers/engineers/developers to build speech processing systems and features; I'd love to hear what people in ML struggle with when you're trying to build or work with speech processing for your projects/products (beyond speech-to-text APIs)","link":"https://www.reddit.com/r/MachineLearning/comments/10p66zc/d_whats_stopping_you_from_working_on_speech_and/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":37},"text":"[D] What's stopping you from working on speech and voice? I've been working in the speech and voice space for a while now and am now building out some tooling in the space to make it easier for researchers/engineers/developers to build speech processing systems and features; I'd love to hear what people in ML struggle with when you're trying to build or work with speech processing for your projects/products (beyond speech-to-text APIs)","classes":{"dataset":0.4197717607}}
{"title":"[R] Train CIFAR10 in under 10 seconds on an A100 (new world record!)","description":"[https://github.com/tysam-code/hlb-CIFAR10](https://github.com/tysam-code/hlb-CIFAR10)","link":"https://www.reddit.com/r/MachineLearning/comments/10op6va/r_train_cifar10_in_under_10_seconds_on_an_a100/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":28},"text":"[R] Train CIFAR10 in under 10 seconds on an A100 (new world record!) [https://github.com/tysam-code/hlb-CIFAR10](https://github.com/tysam-code/hlb-CIFAR10)","classes":{"dataset":0.2777482569}}
{"title":"[Discussion] ChatGPT and language understanding benchmarks","description":"The general consensus seems to be that large language models, and ChatGPT in particular, have a problem with accuracy and hallucination. As compared to what, is often unclear, but let's say as compared to other NLP methods of question answering, language understanding or as compared to Google Search.\n\nI haven't really been able to find any reliable sources documenting this accuracy problem, though.\n\nThe SuperGLUE benchmark has GPT-3 ranked #24, not terrible, but outperformed by old models like T5, which seems odd. GLUE nothing. SQUAD nothing.\n\nSo, I'm curious:\n\n1. Is there any benchmark or metric reflecting the seeming step-function made by ChatGPT that's got everyone so excited? I definitely feel like there's a difference between gpt-3 and chatGPT, but is it measurable or is it just vibes?\n2. Is there any metric showing ChatGPT's problem with fact hallucination and accuracy?\n3. Am I off the mark here looking at question-answering benchmarks as an assessment of LLMs?\n\nThanks","link":"https://www.reddit.com/r/MachineLearning/comments/10oyllu/discussion_chatgpt_and_language_understanding/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":15},"text":"[Discussion] ChatGPT and language understanding benchmarks The general consensus seems to be that large language models, and ChatGPT in particular, have a problem with accuracy and hallucination. As compared to what, is often unclear, but let's say as compared to other NLP methods of question answering, language understanding or as compared to Google Search.\n\nI haven't really been able to find any reliable sources documenting this accuracy problem, though.\n\nThe SuperGLUE benchmark has GPT-3 ranked #24, not terrible, but outperformed by old models like T5, which seems odd. GLUE nothing. SQUAD nothing.\n\nSo, I'm curious:\n\n1. Is there any benchmark or metric reflecting the seeming step-function made by ChatGPT that's got everyone so excited? I definitely feel like there's a difference between gpt-3 and chatGPT, but is it measurable or is it just vibes?\n2. Is there any metric showing ChatGPT's problem with fact hallucination and accuracy?\n3. Am I off the mark here looking at question-answering benchmarks as an assessment of LLMs?\n\nThanks","classes":{"dataset":0.251429528}}
{"title":"[D] I want to understand the broad steps for building something like Adept.AI","description":"From the given [link!](https://www.adept.ai/act), I gather that it is a large-scale Transformer trained to use digital tools like a web browser. Right now, it\u2019s hooked up to a Chrome extension which allows it to observe what\u2019s happening in the browser and take certain actions, like clicking, typing, and scrolling, etc.\n\nI am interested in knowing the broad steps involved in building something like this.","link":"https://www.reddit.com/r/MachineLearning/comments/10p0iir/d_i_want_to_understand_the_broad_steps_for/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":2},"text":"[D] I want to understand the broad steps for building something like Adept.AI From the given [link!](https://www.adept.ai/act), I gather that it is a large-scale Transformer trained to use digital tools like a web browser. Right now, it\u2019s hooked up to a Chrome extension which allows it to observe what\u2019s happening in the browser and take certain actions, like clicking, typing, and scrolling, etc.\n\nI am interested in knowing the broad steps involved in building something like this.","classes":{"dataset":0.3590075672}}
{"title":"[P] Keras model production deployment","description":" Hi guys.\n\nIt's been some time since I started developing my Keras models, but now is the first time I am trying to push it to production.\n\nMy Keras model looks like this:\n\n`model = Sequential()`\n\n`model.add(Bidirectional(LSTM(256, return_sequences=True)))`\n\n`model.add(Bidirectional(LSTM(256, return_sequences=True)))`\n\n`model.add(TimeDistributed(Dense(1, activation='sigmoid')))`\n\n`model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])`\n\nMy problem is I need to run through about 25 of these for every written sentence. There is going to be an online editor, where users can paste text for my analysis. That means up to about 300 words or about 20 sentences at once. With the current time to run each network (about 0.2s), that means 25 \\* 0,2 \\* 20 or about 100s per user input. I am going for 30 seconds at most with potentially dozens of users at once. Ideally on a Raspberry Pi 4.\n\nThe internet is surely gonna back me up I thought to myself and started googling. If only I know what kind of a rabbit hole I was about to fall into.\n\nFirst I converted my Keras model into a TensorFlow frozen graph model. 10x time improvement on CPU, but still at 0.2s on average.\n\nAnother thing I think may boost the performance is retraining the models for variable input shape (currently I always feed in 50 values). With the average sentence size of 16 words this may, from what I understand, lead to a 3 times boost?\n\nMy question is: now what? What can I do to make it faster? Is it even possible to run it on a Raspberry Pi 4 and get reasonable response times? If not, what is my best option on a tight budget?","link":"https://www.reddit.com/r/MachineLearning/comments/10p1cwu/p_keras_model_production_deployment/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":7},"text":"[P] Keras model production deployment  Hi guys.\n\nIt's been some time since I started developing my Keras models, but now is the first time I am trying to push it to production.\n\nMy Keras model looks like this:\n\n`model = Sequential()`\n\n`model.add(Bidirectional(LSTM(256, return_sequences=True)))`\n\n`model.add(Bidirectional(LSTM(256, return_sequences=True)))`\n\n`model.add(TimeDistributed(Dense(1, activation='sigmoid')))`\n\n`model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])`\n\nMy problem is I need to run through about 25 of these for every written sentence. There is going to be an online editor, where users can paste text for my analysis. That means up to about 300 words or about 20 sentences at once. With the current time to run each network (about 0.2s), that means 25 \\* 0,2 \\* 20 or about 100s per user input. I am going for 30 seconds at most with potentially dozens of users at once. Ideally on a Raspberry Pi 4.\n\nThe internet is surely gonna back me up I thought to myself and started googling. If only I know what kind of a rabbit hole I was about to fall into.\n\nFirst I converted my Keras model into a TensorFlow frozen graph model. 10x time improvement on CPU, but still at 0.2s on average.\n\nAnother thing I think may boost the performance is retraining the models for variable input shape (currently I always feed in 50 values). With the average sentence size of 16 words this may, from what I understand, lead to a 3 times boost?\n\nMy question is: now what? What can I do to make it faster? Is it even possible to run it on a Raspberry Pi 4 and get reasonable response times? If not, what is my best option on a tight budget?","classes":{"dataset":0.3919405639}}
{"title":"[P] Automating a Youtube Shorts channel with Huggingface Transformers and After Effects","description":"I\u2019ll try to get into detail about the implementation and difficulties in case it is useful for anyone else trying to do something similar with an applied ML project, so there\u2019s a TLDR at the end if you\u2019d like the short version/result.\n\nAt the end of last year I convinced myself to start 2023 by creating a side-project that I'd actually finish and deploy and perhaps earn some \u201cpassive\u201d income (spoiler, not so passive after all :P), and after some brainstorming I settled on making an automated Youtube channel about finance news since I had just gotten into investing. Shorts seemed to be more manageable and monetization is changing in February so I went with that.\n\nMy rough initial idea was to get online articles, summarize them, make a basic compilation with some combination of pymovie, opencv and stock photos and done. I was pretty worried about the summarization, since in my ML day job I mainly work with vision or sensor data in manufacturing not NLP. Also, I quickly realized pymovie with still images and some overlayed text was not very attractive for viewers (starting with myself).\n\nFast-forward a few days, and after some research online I came across two things, Huggingface transformers (yep, I know I\u2019ve been living under a rock :P) and After Effects scripting.  From here, it became mainly about figuring out exactly which ML models I needed to fine-tune for finance / social media and for what, then putting it all together.\n\nThe entire workflow looks something like this: the bot fetches online daily news about a topic (stocks or crypto), then sentiment analysis is performed on the title and the full text is summarized into a single sentence. I fine-tuned SBERT on \\~1.5M posts from /r/worldnews publicly available in Google Cloud BigQuery so that it could predict a \u201csocial engagement\u201d score that could be used to rank and filter the news that would make it into the video.\n\nFinally, all of this is combined into a single JSON object written into a .js file that can be used by another \u201ccontent creator\u201d script to render the video from a template using aerender in Python. The content of this template is generated dynamically based on the contents of the .js file via AE Expressions. This module also uses the TTS lib to generate voice-overs for the text, and is also responsible for generating the title (using NLTK to identify the main subjects of each title) and the video\u2019s description. Pexel stock videos are used for the background.\n\nIn principle automating the upload to Youtube could also be done, but at this stage I\u2019m handling this manually as the JSON generation is not as robust as I\u2019d like, so the output file often needs to be tweaked and fixed before the video can be finalized and uploaded. An examples is the summary being too short or vague when taken out of the context of the original article. If you increase the max\\_length of the summarizer to compensate, it can easily become too long to for the overlay to fit the pre-defined dimensions, or the total audio length can be too long for the max duration of a youtube short.\n\nWith some more work I\u2019m confident the whole process can be automated further. For those interested, feel free to check the result here:\n\n[Byte Size Bot channel](https://www.youtube.com/@bytesizebot)\n\nIf you have any questions or suggestions I\u2019d be happy to hear them.\n\nTLDR: Coded an automated (not 100% yet, but will get there) Youtube Shorts channel about finance news to create a passive income stream. Ended up being way harder, more fun and not so \u201cpassive\u201d than my initial expectations.","link":"https://www.reddit.com/r/MachineLearning/comments/10oauj5/p_automating_a_youtube_shorts_channel_with/","created":"2023-01-29","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":14},"text":"[P] Automating a Youtube Shorts channel with Huggingface Transformers and After Effects I\u2019ll try to get into detail about the implementation and difficulties in case it is useful for anyone else trying to do something similar with an applied ML project, so there\u2019s a TLDR at the end if you\u2019d like the short version/result.\n\nAt the end of last year I convinced myself to start 2023 by creating a side-project that I'd actually finish and deploy and perhaps earn some \u201cpassive\u201d income (spoiler, not so passive after all :P), and after some brainstorming I settled on making an automated Youtube channel about finance news since I had just gotten into investing. Shorts seemed to be more manageable and monetization is changing in February so I went with that.\n\nMy rough initial idea was to get online articles, summarize them, make a basic compilation with some combination of pymovie, opencv and stock photos and done. I was pretty worried about the summarization, since in my ML day job I mainly work with vision or sensor data in manufacturing not NLP. Also, I quickly realized pymovie with still images and some overlayed text was not very attractive for viewers (starting with myself).\n\nFast-forward a few days, and after some research online I came across two things, Huggingface transformers (yep, I know I\u2019ve been living under a rock :P) and After Effects scripting.  From here, it became mainly about figuring out exactly which ML models I needed to fine-tune for finance / social media and for what, then putting it all together.\n\nThe entire workflow looks something like this: the bot fetches online daily news about a topic (stocks or crypto), then sentiment analysis is performed on the title and the full text is summarized into a single sentence. I fine-tuned SBERT on \\~1.5M posts from /r/worldnews publicly available in Google Cloud BigQuery so that it could predict a \u201csocial engagement\u201d score that could be used to rank and filter the news that would make it into the video.\n\nFinally, all of this is combined into a single JSON object written into a .js file that can be used by another \u201ccontent creator\u201d script to render the video from a template using aerender in Python. The content of this template is generated dynamically based on the contents of the .js file via AE Expressions. This module also uses the TTS lib to generate voice-overs for the text, and is also responsible for generating the title (using NLTK to identify the main subjects of each title) and the video\u2019s description. Pexel stock videos are used for the background.\n\nIn principle automating the upload to Youtube could also be done, but at this stage I\u2019m handling this manually as the JSON generation is not as robust as I\u2019d like, so the output file often needs to be tweaked and fixed before the video can be finalized and uploaded. An examples is the summary being too short or vague when taken out of the context of the original article. If you increase the max\\_length of the summarizer to compensate, it can easily become too long to for the overlay to fit the pre-defined dimensions, or the total audio length can be too long for the max duration of a youtube short.\n\nWith some more work I\u2019m confident the whole process can be automated further. For those interested, feel free to check the result here:\n\n[Byte Size Bot channel](https://www.youtube.com/@bytesizebot)\n\nIf you have any questions or suggestions I\u2019d be happy to hear them.\n\nTLDR: Coded an automated (not 100% yet, but will get there) Youtube Shorts channel about finance news to create a passive income stream. Ended up being way harder, more fun and not so \u201cpassive\u201d than my initial expectations.","classes":{"dataset":0.3270494044}}
{"title":"[D] AI Theory - Signal Processing?","description":"On [This](https://ai.facebook.com/research/theory/) page of Meta AI research where they mention AI theory as a topic, they mention that they use techniques from Signal Processing. As someone with an Electrical Engineering background, and interests in Mathematics and AI, I found this very intriguing. Can someone tell me some of the ways signal processing has been used in AI theory? Some papers or some work done?","link":"https://www.reddit.com/r/MachineLearning/comments/10ocalm/d_ai_theory_signal_processing/","created":"2023-01-29","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":26},"text":"[D] AI Theory - Signal Processing? On [This](https://ai.facebook.com/research/theory/) page of Meta AI research where they mention AI theory as a topic, they mention that they use techniques from Signal Processing. As someone with an Electrical Engineering background, and interests in Mathematics and AI, I found this very intriguing. Can someone tell me some of the ways signal processing has been used in AI theory? Some papers or some work done?","classes":{"dataset":0.3043304682}}
{"title":"[R] A Robust Hypothesis Test for Tree Ensemble Pruning","description":"I'm looking for help/feedback with this paper. Please let me know if the method is interesting and if there's ways to improve it!\n\n[https://arxiv.org/abs/2301.10115](https://arxiv.org/abs/2301.10115)\n\nAbstract:\n\nGradient boosted decision trees are some of the most popular algorithms in applied machine learning. They are a flexible and powerful tool that can robustly fit to any tabular dataset in a scalable and computationally efficient way. One of the most critical parameters to tune when fitting these models are the various penalty terms used to distinguish signal from noise in the current model. These penalties are effective in practice, but are lacking in robust theoretical justifications. In this paper we develop and present a novel theoretically justified hypothesis test of split quality for gradient boosted tree ensembles and demonstrate that using this method instead of the common penalty terms leads to a significant reduction in out of sample loss. Additionally, this method provides a theoretically well-justified stopping condition for the tree growing algorithm. We also present several innovative extensions to the method, opening the door for a wide variety of novel tree pruning algorithms.","link":"https://www.reddit.com/r/MachineLearning/comments/10otrnf/r_a_robust_hypothesis_test_for_tree_ensemble/","created":"2023-01-30","tags":["ml","reddit","machinelearning"],"meta":{"num_comments":0},"text":"[R] A Robust Hypothesis Test for Tree Ensemble Pruning I'm looking for help/feedback with this paper. Please let me know if the method is interesting and if there's ways to improve it!\n\n[https://arxiv.org/abs/2301.10115](https://arxiv.org/abs/2301.10115)\n\nAbstract:\n\nGradient boosted decision trees are some of the most popular algorithms in applied machine learning. They are a flexible and powerful tool that can robustly fit to any tabular dataset in a scalable and computationally efficient way. One of the most critical parameters to tune when fitting these models are the various penalty terms used to distinguish signal from noise in the current model. These penalties are effective in practice, but are lacking in robust theoretical justifications. In this paper we develop and present a novel theoretically justified hypothesis test of split quality for gradient boosted tree ensembles and demonstrate that using this method instead of the common penalty terms leads to a significant reduction in out of sample loss. Additionally, this method provides a theoretically well-justified stopping condition for the tree growing algorithm. We also present several innovative extensions to the method, opening the door for a wide variety of novel tree pruning algorithms.","classes":{"dataset":0.5389974713}}
{"title":"Is there a database of words grouped by their class/category?","description":"Forgive me, I'm new to this field and don't know how to say it precisely, but I'm looking for a database in which you can lookup a word and get sets related words based on specific functional categories. For example:\n\n- searching \"east\" would return a category of \"cardinal directions\" and the related words \"north\", \"south\", \"west\"\n- searching \"now\" would return \"temporal proximity\" which might have \"soon\", \"later\", \"never\", etc.\n\nI've tried various thesauruses but they only give words of either similar or opposite meaning. They won't give you \"north\" if you search \"east\". Does such a database exist?","link":"https://www.reddit.com/r/LanguageTechnology/comments/10pr8n1/is_there_a_database_of_words_grouped_by_their/","created":"2023-01-31","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":4},"text":"Is there a database of words grouped by their class/category? Forgive me, I'm new to this field and don't know how to say it precisely, but I'm looking for a database in which you can lookup a word and get sets related words based on specific functional categories. For example:\n\n- searching \"east\" would return a category of \"cardinal directions\" and the related words \"north\", \"south\", \"west\"\n- searching \"now\" would return \"temporal proximity\" which might have \"soon\", \"later\", \"never\", etc.\n\nI've tried various thesauruses but they only give words of either similar or opposite meaning. They won't give you \"north\" if you search \"east\". Does such a database exist?","classes":{"dataset":0.3220939338}}
{"title":"MusicLM Text to Music AI Google Research","description":"MusicLM is a model generating high-fidelity music from text descriptions such as\u00a0\"a calming violin melody backed by a distorted guitar riff\". MusicLM casts the process of conditional music generation as a hierarchical sequence-to-sequence modeling task, and it generates music at 24 kHz that remains consistent over several minutes. MusicLM can be conditioned on both text and a melody in that it can transform whistled and hummed melodies according to the style described in a text caption.\n\nIn this short video i explain the model behind MusicLM. Do checkout \nhttps://youtu.be/8rofGhGJmgY","link":"https://www.reddit.com/r/LanguageTechnology/comments/10ppmou/musiclm_text_to_music_ai_google_research/","created":"2023-01-31","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"MusicLM Text to Music AI Google Research MusicLM is a model generating high-fidelity music from text descriptions such as\u00a0\"a calming violin melody backed by a distorted guitar riff\". MusicLM casts the process of conditional music generation as a hierarchical sequence-to-sequence modeling task, and it generates music at 24 kHz that remains consistent over several minutes. MusicLM can be conditioned on both text and a melody in that it can transform whistled and hummed melodies according to the style described in a text caption.\n\nIn this short video i explain the model behind MusicLM. Do checkout \nhttps://youtu.be/8rofGhGJmgY","classes":{"dataset":0.2934632599}}
{"title":"How Is Netflix and Other Streaming Platforms Changing the Way People Watch Movies in India ?","description":"The advent of OTT platforms has revolutionized the way Hindi-speaking audiences watch movies. From streaming high-quality content to providing personalized recommendations, these platforms are providing an enhanced movie experience for viewers.","link":"https://www.reddit.com/r/LanguageTechnology/comments/10pp6q4/how_is_netflix_and_other_streaming_platforms/","created":"2023-01-31","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"How Is Netflix and Other Streaming Platforms Changing the Way People Watch Movies in India ? The advent of OTT platforms has revolutionized the way Hindi-speaking audiences watch movies. From streaming high-quality content to providing personalized recommendations, these platforms are providing an enhanced movie experience for viewers.","classes":{"dataset":0.386911422}}
{"title":"Easily Build Your Own GPT from Scratch using AWS: A Comprehensive Guide for Domain Adaptation","description":"\ud83d\udd25\ud83e\udd16Get ready to train your own GPT-2 model from scratch using AWS SageMaker!\ud83e\udd16\ud83d\udd25\n\nThis comprehensive guide will take you through the entire process of creating a custom-built GPT-2 model, tailored to your specific domain or industry. \ud83d\udcbb\n\nYou'll learn how to acquire and prepare raw data, create custom vocabularies and tokenizers, pre-train large language models, and evaluate the performance of your custom model. \ud83d\udcc8\n\nNot only that, but you'll also delve into the intricacies of training a GPT-2 model to generate cohesive news articles related to the COVID-19 pandemic! \ud83e\udda0\n\nAnd the best part? It comes with 9 Jupyter notebooks and all the necessary Python scripts to help you get started right away! \ud83d\ude80\n\nYou'll also gain a solid understanding of key concepts like generative AI, foundational models, language alignment, and prompt engineering with a focus on GPT. \ud83d\udca1 [https://tinyurl.com/hvrjkm5r](https://tinyurl.com/hvrjkm5r)","link":"https://www.reddit.com/r/LanguageTechnology/comments/10ohy1m/easily_build_your_own_gpt_from_scratch_using_aws/","created":"2023-01-29","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":5},"text":"Easily Build Your Own GPT from Scratch using AWS: A Comprehensive Guide for Domain Adaptation \ud83d\udd25\ud83e\udd16Get ready to train your own GPT-2 model from scratch using AWS SageMaker!\ud83e\udd16\ud83d\udd25\n\nThis comprehensive guide will take you through the entire process of creating a custom-built GPT-2 model, tailored to your specific domain or industry. \ud83d\udcbb\n\nYou'll learn how to acquire and prepare raw data, create custom vocabularies and tokenizers, pre-train large language models, and evaluate the performance of your custom model. \ud83d\udcc8\n\nNot only that, but you'll also delve into the intricacies of training a GPT-2 model to generate cohesive news articles related to the COVID-19 pandemic! \ud83e\udda0\n\nAnd the best part? It comes with 9 Jupyter notebooks and all the necessary Python scripts to help you get started right away! \ud83d\ude80\n\nYou'll also gain a solid understanding of key concepts like generative AI, foundational models, language alignment, and prompt engineering with a focus on GPT. \ud83d\udca1 [https://tinyurl.com/hvrjkm5r](https://tinyurl.com/hvrjkm5r)","classes":{"dataset":0.257496208}}
{"title":"[D] Combining results from multiple test dataset","description":"Hello all! \nI'm working on a project building multi class text classifier. As a part of it I'm required to evaluate my machine learning model on different sets of test data. Consider each test data represents a different section/location. \n\nHowever, we want to present a single metric combining the results on all of these location through aggregation. The location specific test data can be of different size and different label distribution. Right now, we average the result obtained for each location. For example final result = average ( acc of location 1 + acc of loc 2 + acc of loc 3)\nAcc - accuracy. \n\nIs there any other way to reflect the dataset size and label distribution while combining results from multiple test data?","link":"https://www.reddit.com/r/LanguageTechnology/comments/10oncpq/d_combining_results_from_multiple_test_dataset/","created":"2023-01-30","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":1},"text":"[D] Combining results from multiple test dataset Hello all! \nI'm working on a project building multi class text classifier. As a part of it I'm required to evaluate my machine learning model on different sets of test data. Consider each test data represents a different section/location. \n\nHowever, we want to present a single metric combining the results on all of these location through aggregation. The location specific test data can be of different size and different label distribution. Right now, we average the result obtained for each location. For example final result = average ( acc of location 1 + acc of loc 2 + acc of loc 3)\nAcc - accuracy. \n\nIs there any other way to reflect the dataset size and label distribution while combining results from multiple test data?","classes":{"dataset":0.298835516}}
{"title":"Navya3DSeg -- Navya 3D Semantic Segmentation Dataset & split generation for autonomous vehicles","description":"Autonomous driving (AD) perception today relies heavily on deep learning based architectures requiring large scale annotated datasets with their associated costs for curation and annotation. The 3D semantic data are useful for core perception tasks such as obstacle detection and ego-vehicle localization. We propose a new dataset, Navya 3D Segmentation (Navya3DSeg), with a diverse label space corresponding to a large scale production grade operational domain, including rural, urban, industrial sites and universities from 13 countries. It contains 23 labeled sequences and 25 supplementary sequences without labels, designed to explore self-supervised and semi-supervised semantic segmentation benchmarks on point clouds. We also propose a novel method for sequential dataset split generation based on iterative multi-label stratification, and demonstrated to achieve a +1.2% mIoU improvement over the original split proposed by SemanticKITTI dataset. A complete benchmark for semantic segmentation task was performed, with state of the art methods. Finally, we demonstrate an active learning (AL) based dataset distillation framework. We introduce a novel heuristic-free sampling method called distance sampling in the context of AL. A detailed presentation on the dataset is available at https://www.youtube.com/watch?v=5m6ALIs-s20 .","link":"http://arxiv.org/abs/2302.08292v1","created":"2023-02-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Navya3DSeg -- Navya 3D Semantic Segmentation Dataset & split generation for autonomous vehicles Autonomous driving (AD) perception today relies heavily on deep learning based architectures requiring large scale annotated datasets with their associated costs for curation and annotation. The 3D semantic data are useful for core perception tasks such as obstacle detection and ego-vehicle localization. We propose a new dataset, Navya 3D Segmentation (Navya3DSeg), with a diverse label space corresponding to a large scale production grade operational domain, including rural, urban, industrial sites and universities from 13 countries. It contains 23 labeled sequences and 25 supplementary sequences without labels, designed to explore self-supervised and semi-supervised semantic segmentation benchmarks on point clouds. We also propose a novel method for sequential dataset split generation based on iterative multi-label stratification, and demonstrated to achieve a +1.2% mIoU improvement over the original split proposed by SemanticKITTI dataset. A complete benchmark for semantic segmentation task was performed, with state of the art methods. Finally, we demonstrate an active learning (AL) based dataset distillation framework. We introduce a novel heuristic-free sampling method called distance sampling in the context of AL. A detailed presentation on the dataset is available at https://www.youtube.com/watch?v=5m6ALIs-s20 .","classes":{"dataset":0.5540026426}}
{"title":"Analyzing the Engagement of Social Relationships During Life Event Shocks in Social Media","description":"Individuals experiencing unexpected distressing events, shocks, often rely on their social network for support. While prior work has shown how social networks respond to shocks, these studies usually treat all ties equally, despite differences in the support provided by different social relationships. Here, we conduct a computational analysis on Twitter that examines how responses to online shocks differ by the relationship type of a user dyad. We introduce a new dataset of over 13K instances of individuals' self-reporting shock events on Twitter and construct networks of relationship-labeled dyadic interactions around these events. By examining behaviors across 110K replies to shocked users in a pseudo-causal analysis, we demonstrate relationship-specific patterns in response levels and topic shifts. We also show that while well-established social dimensions of closeness such as tie strength and structural embeddedness contribute to shock responsiveness, the degree of impact is highly dependent on relationship and shock types. Our findings indicate that social relationships contain highly distinctive characteristics in network interactions and that relationship-specific behaviors in online shock responses are unique from those of offline settings.","link":"http://arxiv.org/abs/2302.07951v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Analyzing the Engagement of Social Relationships During Life Event Shocks in Social Media Individuals experiencing unexpected distressing events, shocks, often rely on their social network for support. While prior work has shown how social networks respond to shocks, these studies usually treat all ties equally, despite differences in the support provided by different social relationships. Here, we conduct a computational analysis on Twitter that examines how responses to online shocks differ by the relationship type of a user dyad. We introduce a new dataset of over 13K instances of individuals' self-reporting shock events on Twitter and construct networks of relationship-labeled dyadic interactions around these events. By examining behaviors across 110K replies to shocked users in a pseudo-causal analysis, we demonstrate relationship-specific patterns in response levels and topic shifts. We also show that while well-established social dimensions of closeness such as tie strength and structural embeddedness contribute to shock responsiveness, the degree of impact is highly dependent on relationship and shock types. Our findings indicate that social relationships contain highly distinctive characteristics in network interactions and that relationship-specific behaviors in online shock responses are unique from those of offline settings.","classes":{"dataset":0.0204636101}}
{"title":"Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation","description":"Distribution shifts are a major source of failure of deployed machine learning models. However, evaluating a model's reliability under distribution shifts can be challenging, especially since it may be difficult to acquire counterfactual examples that exhibit a specified shift. In this work, we introduce dataset interfaces: a framework which allows users to scalably synthesize such counterfactual examples from a given dataset. Specifically, we represent each class from the input dataset as a custom token within the text space of a text-to-image diffusion model. By incorporating these tokens into natural language prompts, we can then generate instantiations of objects in that dataset under desired distribution shifts. We demonstrate how applying our framework to the ImageNet dataset enables us to study model behavior across a diverse array of shifts, including variations in background, lighting, and attributes of the objects themselves. Code available at https://github.com/MadryLab/dataset-interfaces.","link":"http://arxiv.org/abs/2302.07865v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation Distribution shifts are a major source of failure of deployed machine learning models. However, evaluating a model's reliability under distribution shifts can be challenging, especially since it may be difficult to acquire counterfactual examples that exhibit a specified shift. In this work, we introduce dataset interfaces: a framework which allows users to scalably synthesize such counterfactual examples from a given dataset. Specifically, we represent each class from the input dataset as a custom token within the text space of a text-to-image diffusion model. By incorporating these tokens into natural language prompts, we can then generate instantiations of objects in that dataset under desired distribution shifts. We demonstrate how applying our framework to the ImageNet dataset enables us to study model behavior across a diverse array of shifts, including variations in background, lighting, and attributes of the objects themselves. Code available at https://github.com/MadryLab/dataset-interfaces.","classes":{"dataset":0.980047524}}
{"title":"A Case Study on Record Matching of Individuals in Historical Archives of Indigenous Databases","description":"Digitization of historical records has produced a significant amount of data for analysis and interpretation. A critical challenge is the ability to relate historical information across different archives to allow for the data to be framed in the appropriate historical context. This paper presents a real-world case study on historical information integration and record matching with the goal to improve the historical value of archives containing data in the period 1800 to 1920. The archives contain unique information about M\\'etis and Indigenous people in Canada and interactions with European settlers. The archives contain thousands of records that have increased relevance when relationships and interconnections are discovered. The contribution is a record linking approach suitable for historical archives and an evaluation of its effectiveness. Experimental results demonstrate potential for discovering historical linkage with high precision enabling new historical discoveries.","link":"http://arxiv.org/abs/2302.07784v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A Case Study on Record Matching of Individuals in Historical Archives of Indigenous Databases Digitization of historical records has produced a significant amount of data for analysis and interpretation. A critical challenge is the ability to relate historical information across different archives to allow for the data to be framed in the appropriate historical context. This paper presents a real-world case study on historical information integration and record matching with the goal to improve the historical value of archives containing data in the period 1800 to 1920. The archives contain unique information about M\\'etis and Indigenous people in Canada and interactions with European settlers. The archives contain thousands of records that have increased relevance when relationships and interconnections are discovered. The contribution is a record linking approach suitable for historical archives and an evaluation of its effectiveness. Experimental results demonstrate potential for discovering historical linkage with high precision enabling new historical discoveries.","classes":{"dataset":0.9831013083}}
{"title":"DIVOTrack: A Novel Dataset and Baseline Method for Cross-View Multi-Object Tracking in DIVerse Open Scenes","description":"Cross-view multi-object tracking aims to link objects between frames and camera views with substantial overlaps. Although cross-view multi-object tracking has received increased attention in recent years, existing datasets still have several issues, including 1) missing real-world scenarios, 2) lacking diverse scenes, 3) owning a limited number of tracks, 4) comprising only static cameras, and 5) lacking standard benchmarks, which hinder the investigation and comparison of cross-view tracking methods. To solve the aforementioned issues, we introduce DIVOTrack: a new cross-view multi-object tracking dataset for DIVerse Open scenes with dense tracking pedestrians in realistic and non-experimental environments. Our DIVOTrack has ten distinct scenarios and 550 cross-view tracks, surpassing all cross-view multi-object tracking datasets currently available. Furthermore, we provide a novel baseline cross-view tracking method with a unified joint detection and cross-view tracking framework named CrossMOT, which learns object detection, single-view association, and cross-view matching with an all-in-one embedding model. Finally, we present a summary of current methodologies and a set of standard benchmarks with our DIVOTrack to provide a fair comparison and conduct a comprehensive analysis of current approaches and our proposed CrossMOT. The dataset and code are available at https://github.com/shengyuhao/DIVOTrack.","link":"http://arxiv.org/abs/2302.07676v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"DIVOTrack: A Novel Dataset and Baseline Method for Cross-View Multi-Object Tracking in DIVerse Open Scenes Cross-view multi-object tracking aims to link objects between frames and camera views with substantial overlaps. Although cross-view multi-object tracking has received increased attention in recent years, existing datasets still have several issues, including 1) missing real-world scenarios, 2) lacking diverse scenes, 3) owning a limited number of tracks, 4) comprising only static cameras, and 5) lacking standard benchmarks, which hinder the investigation and comparison of cross-view tracking methods. To solve the aforementioned issues, we introduce DIVOTrack: a new cross-view multi-object tracking dataset for DIVerse Open scenes with dense tracking pedestrians in realistic and non-experimental environments. Our DIVOTrack has ten distinct scenarios and 550 cross-view tracks, surpassing all cross-view multi-object tracking datasets currently available. Furthermore, we provide a novel baseline cross-view tracking method with a unified joint detection and cross-view tracking framework named CrossMOT, which learns object detection, single-view association, and cross-view matching with an all-in-one embedding model. Finally, we present a summary of current methodologies and a set of standard benchmarks with our DIVOTrack to provide a fair comparison and conduct a comprehensive analysis of current approaches and our proposed CrossMOT. The dataset and code are available at https://github.com/shengyuhao/DIVOTrack.","classes":{"dataset":0.0338643827}}
{"title":"Activity Cliff Prediction: Dataset and Benchmark","description":"Activity cliffs (ACs), which are generally defined as pairs of structurally similar molecules that are active against the same bio-target but significantly different in the binding potency, are of great importance to drug discovery. Up to date, the AC prediction problem, i.e., to predict whether a pair of molecules exhibit the AC relationship, has not yet been fully explored. In this paper, we first introduce ACNet, a large-scale dataset for AC prediction. ACNet curates over 400K Matched Molecular Pairs (MMPs) against 190 targets, including over 20K MMP-cliffs and 380K non-AC MMPs, and provides five subsets for model development and evaluation. Then, we propose a baseline framework to benchmark the predictive performance of molecular representations encoded by deep neural networks for AC prediction, and 16 models are evaluated in experiments. Our experimental results show that deep learning models can achieve good performance when the models are trained on tasks with adequate amount of data, while the imbalanced, low-data and out-of-distribution features of the ACNet dataset still make it challenging for deep neural networks to cope with. In addition, the traditional ECFP method shows a natural advantage on MMP-cliff prediction, and outperforms other deep learning models on most of the data subsets. To the best of our knowledge, our work constructs the first large-scale dataset for AC prediction, which may stimulate the study of AC prediction models and prompt further breakthroughs in AI-aided drug discovery. The codes and dataset can be accessed by https://drugai.github.io/ACNet/.","link":"http://arxiv.org/abs/2302.07541v1","created":"2023-02-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Activity Cliff Prediction: Dataset and Benchmark Activity cliffs (ACs), which are generally defined as pairs of structurally similar molecules that are active against the same bio-target but significantly different in the binding potency, are of great importance to drug discovery. Up to date, the AC prediction problem, i.e., to predict whether a pair of molecules exhibit the AC relationship, has not yet been fully explored. In this paper, we first introduce ACNet, a large-scale dataset for AC prediction. ACNet curates over 400K Matched Molecular Pairs (MMPs) against 190 targets, including over 20K MMP-cliffs and 380K non-AC MMPs, and provides five subsets for model development and evaluation. Then, we propose a baseline framework to benchmark the predictive performance of molecular representations encoded by deep neural networks for AC prediction, and 16 models are evaluated in experiments. Our experimental results show that deep learning models can achieve good performance when the models are trained on tasks with adequate amount of data, while the imbalanced, low-data and out-of-distribution features of the ACNet dataset still make it challenging for deep neural networks to cope with. In addition, the traditional ECFP method shows a natural advantage on MMP-cliff prediction, and outperforms other deep learning models on most of the data subsets. To the best of our knowledge, our work constructs the first large-scale dataset for AC prediction, which may stimulate the study of AC prediction models and prompt further breakthroughs in AI-aided drug discovery. The codes and dataset can be accessed by https://drugai.github.io/ACNet/.","classes":{"dataset":0.103481546}}
{"title":"HE-MAN -- Homomorphically Encrypted MAchine learning with oNnx models","description":"Machine learning (ML) algorithms are increasingly important for the success of products and services, especially considering the growing amount and availability of data. This also holds for areas handling sensitive data, e.g. applications processing medical data or facial images. However, people are reluctant to pass their personal sensitive data to a ML service provider. At the same time, service providers have a strong interest in protecting their intellectual property and therefore refrain from publicly sharing their ML model. Fully homomorphic encryption (FHE) is a promising technique to enable individuals using ML services without giving up privacy and protecting the ML model of service providers at the same time. Despite steady improvements, FHE is still hardly integrated in today's ML applications.   We introduce HE-MAN, an open-source two-party machine learning toolset for privacy preserving inference with ONNX models and homomorphically encrypted data. Both the model and the input data do not have to be disclosed. HE-MAN abstracts cryptographic details away from the users, thus expertise in FHE is not required for either party. HE-MAN 's security relies on its underlying FHE schemes. For now, we integrate two different homomorphic encryption schemes, namely Concrete and TenSEAL. Compared to prior work, HE-MAN supports a broad range of ML models in ONNX format out of the box without sacrificing accuracy. We evaluate the performance of our implementation on different network architectures classifying handwritten digits and performing face recognition and report accuracy and latency of the homomorphically encrypted inference. Cryptographic parameters are automatically derived by the tools. We show that the accuracy of HE-MAN is on par with models using plaintext input while inference latency is several orders of magnitude higher compared to the plaintext case.","link":"http://arxiv.org/abs/2302.08260v1","created":"2023-02-16","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"HE-MAN -- Homomorphically Encrypted MAchine learning with oNnx models Machine learning (ML) algorithms are increasingly important for the success of products and services, especially considering the growing amount and availability of data. This also holds for areas handling sensitive data, e.g. applications processing medical data or facial images. However, people are reluctant to pass their personal sensitive data to a ML service provider. At the same time, service providers have a strong interest in protecting their intellectual property and therefore refrain from publicly sharing their ML model. Fully homomorphic encryption (FHE) is a promising technique to enable individuals using ML services without giving up privacy and protecting the ML model of service providers at the same time. Despite steady improvements, FHE is still hardly integrated in today's ML applications.   We introduce HE-MAN, an open-source two-party machine learning toolset for privacy preserving inference with ONNX models and homomorphically encrypted data. Both the model and the input data do not have to be disclosed. HE-MAN abstracts cryptographic details away from the users, thus expertise in FHE is not required for either party. HE-MAN 's security relies on its underlying FHE schemes. For now, we integrate two different homomorphic encryption schemes, namely Concrete and TenSEAL. Compared to prior work, HE-MAN supports a broad range of ML models in ONNX format out of the box without sacrificing accuracy. We evaluate the performance of our implementation on different network architectures classifying handwritten digits and performing face recognition and report accuracy and latency of the homomorphically encrypted inference. Cryptographic parameters are automatically derived by the tools. We show that the accuracy of HE-MAN is on par with models using plaintext input while inference latency is several orders of magnitude higher compared to the plaintext case.","classes":{"dataset":0.0373590291}}
{"title":"Graph Adversarial Immunization for Certifiable Robustness","description":"Despite achieving great success, graph neural networks (GNNs) are vulnerable to adversarial attacks. Existing defenses focus on developing adversarial training or robust GNNs. However, little research attention is paid to the potential and practice of immunization on graphs. In this paper, we propose and formulate graph adversarial immunization, i.e., vaccinating part of graph structure to improve certifiable robustness of graph against any admissible adversarial attack. We first propose edge-level immunization to vaccinate node pairs. Despite the primary success, such edge-level immunization cannot defend against emerging node injection attacks, since it only immunizes existing node pairs. To this end, we further propose node-level immunization. To circumvent computationally expensive combinatorial optimization when solving adversarial immunization, we design AdvImmune-Edge and AdvImmune-Node algorithms to effectively obtain the immune node pairs or nodes. Experiments demonstrate the superiority of AdvImmune methods. In particular, AdvImmune-Node remarkably improves the ratio of robust nodes by 79%, 294%, and 100%, after immunizing only 5% nodes. Furthermore, AdvImmune methods show excellent defensive performance against various attacks, outperforming state-of-the-art defenses. To the best of our knowledge, this is the first attempt to improve certifiable robustness from graph data perspective without losing performance on clean graphs, providing new insights into graph adversarial learning.","link":"http://arxiv.org/abs/2302.08051v1","created":"2023-02-16","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Graph Adversarial Immunization for Certifiable Robustness Despite achieving great success, graph neural networks (GNNs) are vulnerable to adversarial attacks. Existing defenses focus on developing adversarial training or robust GNNs. However, little research attention is paid to the potential and practice of immunization on graphs. In this paper, we propose and formulate graph adversarial immunization, i.e., vaccinating part of graph structure to improve certifiable robustness of graph against any admissible adversarial attack. We first propose edge-level immunization to vaccinate node pairs. Despite the primary success, such edge-level immunization cannot defend against emerging node injection attacks, since it only immunizes existing node pairs. To this end, we further propose node-level immunization. To circumvent computationally expensive combinatorial optimization when solving adversarial immunization, we design AdvImmune-Edge and AdvImmune-Node algorithms to effectively obtain the immune node pairs or nodes. Experiments demonstrate the superiority of AdvImmune methods. In particular, AdvImmune-Node remarkably improves the ratio of robust nodes by 79%, 294%, and 100%, after immunizing only 5% nodes. Furthermore, AdvImmune methods show excellent defensive performance against various attacks, outperforming state-of-the-art defenses. To the best of our knowledge, this is the first attempt to improve certifiable robustness from graph data perspective without losing performance on clean graphs, providing new insights into graph adversarial learning.","classes":{"dataset":0.2293330878}}
{"title":"Balancing Privacy Protection and Interpretability in Federated Learning","description":"Federated learning (FL) aims to collaboratively train the global model in a distributed manner by sharing the model parameters from local clients to a central server, thereby potentially protecting users' private information. Nevertheless, recent studies have illustrated that FL still suffers from information leakage as adversaries try to recover the training data by analyzing shared parameters from local clients. To deal with this issue, differential privacy (DP) is adopted to add noise to the gradients of local models before aggregation. It, however, results in the poor performance of gradient-based interpretability methods, since some weights capturing the salient region in feature map will be perturbed. To overcome this problem, we propose a simple yet effective adaptive differential privacy (ADP) mechanism that selectively adds noisy perturbations to the gradients of client models in FL. We also theoretically analyze the impact of gradient perturbation on the model interpretability. Finally, extensive experiments on both IID and Non-IID data demonstrate that the proposed ADP can achieve a good trade-off between privacy and interpretability in FL.","link":"http://arxiv.org/abs/2302.08044v1","created":"2023-02-16","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Balancing Privacy Protection and Interpretability in Federated Learning Federated learning (FL) aims to collaboratively train the global model in a distributed manner by sharing the model parameters from local clients to a central server, thereby potentially protecting users' private information. Nevertheless, recent studies have illustrated that FL still suffers from information leakage as adversaries try to recover the training data by analyzing shared parameters from local clients. To deal with this issue, differential privacy (DP) is adopted to add noise to the gradients of local models before aggregation. It, however, results in the poor performance of gradient-based interpretability methods, since some weights capturing the salient region in feature map will be perturbed. To overcome this problem, we propose a simple yet effective adaptive differential privacy (ADP) mechanism that selectively adds noisy perturbations to the gradients of client models in FL. We also theoretically analyze the impact of gradient perturbation on the model interpretability. Finally, extensive experiments on both IID and Non-IID data demonstrate that the proposed ADP can achieve a good trade-off between privacy and interpretability in FL.","classes":{"dataset":0.1630946845}}
{"title":"Multi-Task Differential Privacy Under Distribution Skew","description":"We study the problem of multi-task learning under user-level differential privacy, in which $n$ users contribute data to $m$ tasks, each involving a subset of users. One important aspect of the problem, that can significantly impact quality, is the distribution skew among tasks. Certain tasks may have much fewer data samples than others, making them more susceptible to the noise added for privacy. It is natural to ask whether algorithms can adapt to this skew to improve the overall utility.   We give a systematic analysis of the problem, by studying how to optimally allocate a user's privacy budget among tasks. We propose a generic algorithm, based on an adaptive reweighting of the empirical loss, and show that when there is task distribution skew, this gives a quantifiable improvement of excess empirical risk.   Experimental studies on recommendation problems that exhibit a long tail of small tasks, demonstrate that our methods significantly improve utility, achieving the state of the art on two standard benchmarks.","link":"http://arxiv.org/abs/2302.07975v1","created":"2023-02-15","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Multi-Task Differential Privacy Under Distribution Skew We study the problem of multi-task learning under user-level differential privacy, in which $n$ users contribute data to $m$ tasks, each involving a subset of users. One important aspect of the problem, that can significantly impact quality, is the distribution skew among tasks. Certain tasks may have much fewer data samples than others, making them more susceptible to the noise added for privacy. It is natural to ask whether algorithms can adapt to this skew to improve the overall utility.   We give a systematic analysis of the problem, by studying how to optimally allocate a user's privacy budget among tasks. We propose a generic algorithm, based on an adaptive reweighting of the empirical loss, and show that when there is task distribution skew, this gives a quantifiable improvement of excess empirical risk.   Experimental studies on recommendation problems that exhibit a long tail of small tasks, demonstrate that our methods significantly improve utility, achieving the state of the art on two standard benchmarks.","classes":{"dataset":0.0244538486}}
{"title":"AI Security Threats against Pervasive Robotic Systems: A Course for Next Generation Cybersecurity Workforce","description":"Robotics, automation, and related Artificial Intelligence (AI) systems have become pervasive bringing in concerns related to security, safety, accuracy, and trust. With growing dependency on physical robots that work in close proximity to humans, the security of these systems is becoming increasingly important to prevent cyber-attacks that could lead to privacy invasion, critical operations sabotage, and bodily harm. The current shortfall of professionals who can defend such systems demands development and integration of such a curriculum. This course description includes details about seven self-contained and adaptive modules on \"AI security threats against pervasive robotic systems\". Topics include: 1) Introduction, examples of attacks, and motivation; 2) - Robotic AI attack surfaces and penetration testing; 3) - Attack patterns and security strategies for input sensors; 4) - Training attacks and associated security strategies; 5) - Inference attacks and associated security strategies; 6) - Actuator attacks and associated security strategies; and 7) - Ethics of AI, robotics, and cybersecurity.","link":"http://arxiv.org/abs/2302.07953v1","created":"2023-02-15","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"AI Security Threats against Pervasive Robotic Systems: A Course for Next Generation Cybersecurity Workforce Robotics, automation, and related Artificial Intelligence (AI) systems have become pervasive bringing in concerns related to security, safety, accuracy, and trust. With growing dependency on physical robots that work in close proximity to humans, the security of these systems is becoming increasingly important to prevent cyber-attacks that could lead to privacy invasion, critical operations sabotage, and bodily harm. The current shortfall of professionals who can defend such systems demands development and integration of such a curriculum. This course description includes details about seven self-contained and adaptive modules on \"AI security threats against pervasive robotic systems\". Topics include: 1) Introduction, examples of attacks, and motivation; 2) - Robotic AI attack surfaces and penetration testing; 3) - Attack patterns and security strategies for input sensors; 4) - Training attacks and associated security strategies; 5) - Inference attacks and associated security strategies; 6) - Actuator attacks and associated security strategies; and 7) - Ethics of AI, robotics, and cybersecurity.","classes":{"dataset":0.0157797076}}
{"title":"XploreNAS: Explore Adversarially Robust & Hardware-efficient Neural Architectures for Non-ideal Xbars","description":"Compute In-Memory platforms such as memristive crossbars are gaining focus as they facilitate acceleration of Deep Neural Networks (DNNs) with high area and compute-efficiencies. However, the intrinsic non-idealities associated with the analog nature of computing in crossbars limits the performance of the deployed DNNs. Furthermore, DNNs are shown to be vulnerable to adversarial attacks leading to severe security threats in their large-scale deployment. Thus, finding adversarially robust DNN architectures for non-ideal crossbars is critical to the safe and secure deployment of DNNs on the edge. This work proposes a two-phase algorithm-hardware co-optimization approach called XploreNAS that searches for hardware-efficient & adversarially robust neural architectures for non-ideal crossbar platforms. We use the one-shot Neural Architecture Search (NAS) approach to train a large Supernet with crossbar-awareness and sample adversarially robust Subnets therefrom, maintaining competitive hardware-efficiency. Our experiments on crossbars with benchmark datasets (SVHN, CIFAR10 & CIFAR100) show upto ~8-16% improvement in the adversarial robustness of the searched Subnets against a baseline ResNet-18 model subjected to crossbar-aware adversarial training. We benchmark our robust Subnets for Energy-Delay-Area-Products (EDAPs) using the Neurosim tool and find that with additional hardware-efficiency driven optimizations, the Subnets attain ~1.5-1.6x lower EDAPs than ResNet-18 baseline.","link":"http://arxiv.org/abs/2302.07769v1","created":"2023-02-15","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"XploreNAS: Explore Adversarially Robust & Hardware-efficient Neural Architectures for Non-ideal Xbars Compute In-Memory platforms such as memristive crossbars are gaining focus as they facilitate acceleration of Deep Neural Networks (DNNs) with high area and compute-efficiencies. However, the intrinsic non-idealities associated with the analog nature of computing in crossbars limits the performance of the deployed DNNs. Furthermore, DNNs are shown to be vulnerable to adversarial attacks leading to severe security threats in their large-scale deployment. Thus, finding adversarially robust DNN architectures for non-ideal crossbars is critical to the safe and secure deployment of DNNs on the edge. This work proposes a two-phase algorithm-hardware co-optimization approach called XploreNAS that searches for hardware-efficient & adversarially robust neural architectures for non-ideal crossbar platforms. We use the one-shot Neural Architecture Search (NAS) approach to train a large Supernet with crossbar-awareness and sample adversarially robust Subnets therefrom, maintaining competitive hardware-efficiency. Our experiments on crossbars with benchmark datasets (SVHN, CIFAR10 & CIFAR100) show upto ~8-16% improvement in the adversarial robustness of the searched Subnets against a baseline ResNet-18 model subjected to crossbar-aware adversarial training. We benchmark our robust Subnets for Energy-Delay-Area-Products (EDAPs) using the Neurosim tool and find that with additional hardware-efficiency driven optimizations, the Subnets attain ~1.5-1.6x lower EDAPs than ResNet-18 baseline.","classes":{"dataset":0.0561787784}}
{"title":"FedABC: Targeting Fair Competition in Personalized Federated Learning","description":"Federated learning aims to collaboratively train models without accessing their client's local private data. The data may be Non-IID for different clients and thus resulting in poor performance. Recently, personalized federated learning (PFL) has achieved great success in handling Non-IID data by enforcing regularization in local optimization or improving the model aggregation scheme on the server. However, most of the PFL approaches do not take into account the unfair competition issue caused by the imbalanced data distribution and lack of positive samples for some classes in each client. To address this issue, we propose a novel and generic PFL framework termed Federated Averaging via Binary Classification, dubbed FedABC. In particular, we adopt the ``one-vs-all'' training strategy in each client to alleviate the unfair competition between classes by constructing a personalized binary classification problem for each class. This may aggravate the class imbalance challenge and thus a novel personalized binary classification loss that incorporates both the under-sampling and hard sample mining strategies is designed. Extensive experiments are conducted on two popular datasets under different settings, and the results demonstrate that our FedABC can significantly outperform the existing counterparts.","link":"http://arxiv.org/abs/2302.07450v1","created":"2023-02-15","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"FedABC: Targeting Fair Competition in Personalized Federated Learning Federated learning aims to collaboratively train models without accessing their client's local private data. The data may be Non-IID for different clients and thus resulting in poor performance. Recently, personalized federated learning (PFL) has achieved great success in handling Non-IID data by enforcing regularization in local optimization or improving the model aggregation scheme on the server. However, most of the PFL approaches do not take into account the unfair competition issue caused by the imbalanced data distribution and lack of positive samples for some classes in each client. To address this issue, we propose a novel and generic PFL framework termed Federated Averaging via Binary Classification, dubbed FedABC. In particular, we adopt the ``one-vs-all'' training strategy in each client to alleviate the unfair competition between classes by constructing a personalized binary classification problem for each class. This may aggravate the class imbalance challenge and thus a novel personalized binary classification loss that incorporates both the under-sampling and hard sample mining strategies is designed. Extensive experiments are conducted on two popular datasets under different settings, and the results demonstrate that our FedABC can significantly outperform the existing counterparts.","classes":{"dataset":0.0707283169}}
{"title":"Conversational AI-Powered Design: ChatGPT as Designer, User, and Product","description":"The recent advancements in Large Language Models (LLMs), particularly conversational LLMs like ChatGPT, have prompted changes in a range of fields, including design. This study aims to examine the capabilities of ChatGPT in a human-centered design process. To this end, a hypothetical design project was conducted, where ChatGPT was utilized to generate personas, simulate interviews with fictional users, create new design ideas, simulate usage scenarios and conversations between an imaginary prototype and fictional users, and lastly evaluate user experience. The results show that ChatGPT effectively performed the tasks assigned to it as a designer, user, or product, providing mostly appropriate responses. The study does, however, highlight some drawbacks such as forgotten information, partial responses, and a lack of output diversity. The paper explains the potential benefits and limitations of using conversational LLMs in design, discusses its implications, and suggests directions for future research in this rapidly evolving area.","link":"http://arxiv.org/abs/2302.07406v1","created":"2023-02-15","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Conversational AI-Powered Design: ChatGPT as Designer, User, and Product The recent advancements in Large Language Models (LLMs), particularly conversational LLMs like ChatGPT, have prompted changes in a range of fields, including design. This study aims to examine the capabilities of ChatGPT in a human-centered design process. To this end, a hypothetical design project was conducted, where ChatGPT was utilized to generate personas, simulate interviews with fictional users, create new design ideas, simulate usage scenarios and conversations between an imaginary prototype and fictional users, and lastly evaluate user experience. The results show that ChatGPT effectively performed the tasks assigned to it as a designer, user, or product, providing mostly appropriate responses. The study does, however, highlight some drawbacks such as forgotten information, partial responses, and a lack of output diversity. The paper explains the potential benefits and limitations of using conversational LLMs in design, discusses its implications, and suggests directions for future research in this rapidly evolving area.","classes":{"dataset":0.2045403719}}
{"title":"Log Parsing with Prompt-based Few-shot Learning","description":"Logs generated by large-scale software systems provide crucial information for engineers to understand the system status and diagnose problems of the systems. Log parsing, which converts raw log messages into structured data, is the first step to enabling automated log analytics. Existing log parsers extract the common part as log templates using statistical features. However, these log parsers often fail to identify the correct templates and parameters because: 1) they often overlook the semantic meaning of log messages, and 2) they require domain-specific knowledge for different log datasets. To address the limitations of existing methods, in this paper, we propose LogPPT to capture the patterns of templates using prompt-based few-shot learning. LogPPT utilises a novel prompt tuning method to recognise keywords and parameters based on a few labelled log data. In addition, an adaptive random sampling algorithm is designed to select a small yet diverse training set. We have conducted extensive experiments on 16 public log datasets. The experimental results show that LogPPT is effective and efficient for log parsing.","link":"http://arxiv.org/abs/2302.07435v1","created":"2023-02-15","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Log Parsing with Prompt-based Few-shot Learning Logs generated by large-scale software systems provide crucial information for engineers to understand the system status and diagnose problems of the systems. Log parsing, which converts raw log messages into structured data, is the first step to enabling automated log analytics. Existing log parsers extract the common part as log templates using statistical features. However, these log parsers often fail to identify the correct templates and parameters because: 1) they often overlook the semantic meaning of log messages, and 2) they require domain-specific knowledge for different log datasets. To address the limitations of existing methods, in this paper, we propose LogPPT to capture the patterns of templates using prompt-based few-shot learning. LogPPT utilises a novel prompt tuning method to recognise keywords and parameters based on a few labelled log data. In addition, an adaptive random sampling algorithm is designed to select a small yet diverse training set. We have conducted extensive experiments on 16 public log datasets. The experimental results show that LogPPT is effective and efficient for log parsing.","classes":{"dataset":0.1819487959}}
{"title":"URCDC-Depth: Uncertainty Rectified Cross-Distillation with CutFlip for Monocular Depth Estimation","description":"This work aims to estimate a high-quality depth map from a single RGB image. Due to the lack of depth clues, making full use of the long-range correlation and the local information is critical for accurate depth estimation. Towards this end, we introduce an uncertainty rectified cross-distillation between Transformer and convolutional neural network (CNN) to learn a unified depth estimator. Specifically, we use the depth estimates derived from the Transformer branch and the CNN branch as pseudo labels to teach each other. Meanwhile, we model the pixel-wise depth uncertainty to rectify the loss weights of noisy depth labels. To avoid the large performance gap induced by the strong Transformer branch deteriorating the cross-distillation, we transfer the feature maps from Transformer to CNN and design coupling units to assist the weak CNN branch to utilize the transferred features. Furthermore, we propose a surprisingly simple yet highly effective data augmentation technique CutFlip, which enforces the model to exploit more valuable clues apart from the clue of vertical image position for depth estimation. Extensive experiments indicate that our model, termed~\\textbf{URCDC-Depth}, exceeds previous state-of-the-art methods on the KITTI and NYU-Depth-v2 datasets, even with no additional computational burden at inference time. The source code is publicly available at \\url{https://github.com/ShuweiShao/URCDC-Depth}.","link":"http://arxiv.org/abs/2302.08149v1","created":"2023-02-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"URCDC-Depth: Uncertainty Rectified Cross-Distillation with CutFlip for Monocular Depth Estimation This work aims to estimate a high-quality depth map from a single RGB image. Due to the lack of depth clues, making full use of the long-range correlation and the local information is critical for accurate depth estimation. Towards this end, we introduce an uncertainty rectified cross-distillation between Transformer and convolutional neural network (CNN) to learn a unified depth estimator. Specifically, we use the depth estimates derived from the Transformer branch and the CNN branch as pseudo labels to teach each other. Meanwhile, we model the pixel-wise depth uncertainty to rectify the loss weights of noisy depth labels. To avoid the large performance gap induced by the strong Transformer branch deteriorating the cross-distillation, we transfer the feature maps from Transformer to CNN and design coupling units to assist the weak CNN branch to utilize the transferred features. Furthermore, we propose a surprisingly simple yet highly effective data augmentation technique CutFlip, which enforces the model to exploit more valuable clues apart from the clue of vertical image position for depth estimation. Extensive experiments indicate that our model, termed~\\textbf{URCDC-Depth}, exceeds previous state-of-the-art methods on the KITTI and NYU-Depth-v2 datasets, even with no additional computational burden at inference time. The source code is publicly available at \\url{https://github.com/ShuweiShao/URCDC-Depth}.","classes":{"dataset":0.0320354514}}
{"title":"Fossil Image Identification using Deep Learning Ensembles of Data Augmented Multiviews","description":"Identification of fossil species is crucial to evolutionary studies. Recent advances from deep learning have shown promising prospects in fossil image identification. However, the quantity and quality of labeled fossil images are often limited due to fossil preservation, conditioned sampling, and expensive and inconsistent label annotation by domain experts, which pose great challenges to the training of deep learning based image classification models. To address these challenges, we follow the idea of the wisdom of crowds and propose a novel multiview ensemble framework, which collects multiple views of each fossil specimen image reflecting its different characteristics to train multiple base deep learning models and then makes final decisions via soft voting. We further develop OGS method that integrates original, gray, and skeleton views under this framework to demonstrate the effectiveness. Experimental results on the fusulinid fossil dataset over five deep learning based milestone models show that OGS using three base models consistently outperforms the baseline using a single base model, and the ablation study verifies the usefulness of each selected view. Besides, OGS obtains the superior or comparable performance compared to the method under well-known bagging framework. Moreover, as the available training data decreases, the proposed framework achieves more performance gains compared to the baseline. Furthermore, a consistency test with two human experts shows that OGS obtains the highest agreement with both the labels of dataset and the two experts. Notably, this methodology is designed for general fossil identification and it is expected to see applications on other fossil datasets. The results suggest the potential application when the quantity and quality of labeled data are particularly restricted, e.g., to identify rare fossil images.","link":"http://arxiv.org/abs/2302.08062v1","created":"2023-02-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Fossil Image Identification using Deep Learning Ensembles of Data Augmented Multiviews Identification of fossil species is crucial to evolutionary studies. Recent advances from deep learning have shown promising prospects in fossil image identification. However, the quantity and quality of labeled fossil images are often limited due to fossil preservation, conditioned sampling, and expensive and inconsistent label annotation by domain experts, which pose great challenges to the training of deep learning based image classification models. To address these challenges, we follow the idea of the wisdom of crowds and propose a novel multiview ensemble framework, which collects multiple views of each fossil specimen image reflecting its different characteristics to train multiple base deep learning models and then makes final decisions via soft voting. We further develop OGS method that integrates original, gray, and skeleton views under this framework to demonstrate the effectiveness. Experimental results on the fusulinid fossil dataset over five deep learning based milestone models show that OGS using three base models consistently outperforms the baseline using a single base model, and the ablation study verifies the usefulness of each selected view. Besides, OGS obtains the superior or comparable performance compared to the method under well-known bagging framework. Moreover, as the available training data decreases, the proposed framework achieves more performance gains compared to the baseline. Furthermore, a consistency test with two human experts shows that OGS obtains the highest agreement with both the labels of dataset and the two experts. Notably, this methodology is designed for general fossil identification and it is expected to see applications on other fossil datasets. The results suggest the potential application when the quantity and quality of labeled data are particularly restricted, e.g., to identify rare fossil images.","classes":{"dataset":0.7096421719}}
{"title":"Vector-based Efficient Data Hiding in Encrypted Images via Multi-MSB Replacement","description":"As an essential technique for data privacy protection, reversible data hiding in encrypted images (RDHEI) methods have drawn intensive research interest in recent years. In response to the increasing demand for protecting data privacy, novel methods that perform RDHEI are continually being developed. We propose two effective multi-MSB (most significant bit) replacement-based approaches that yield comparably high data embedding capacity, improve overall processing speed, and enhance reconstructed images' quality. Our first method, Efficient Multi-MSB Replacement-RDHEI (EMR-RDHEI), obtains higher data embedding rates (DERs, also known as payloads) and better visual quality in reconstructed images when compared with many other state-of-the-art methods. Our second method, Lossless Multi-MSB Replacement-RDHEI (LMR-RDHEI), can losslessly recover original images after an information embedding process is performed. To verify the accuracy of our methods, we compared them with other recent RDHEI techniques and performed extensive experiments using the widely accepted BOWS-2 dataset. Our experimental results showed that the DER of our EMR-RDHEI method ranged from 1.2087 bit per pixel (bpp) to 6.2682 bpp with an average of 3.2457 bpp. For the LMR-RDHEI method, the average DER was 2.5325 bpp, with a range between 0.2129 bpp and 6.0168 bpp. Our results demonstrate that these methods outperform many other state-of-the-art RDHEI algorithms. Additionally, the multi-MSB replacement-based approach provides a clean design and efficient vectorized implementation.","link":"http://arxiv.org/abs/2302.07992v1","created":"2023-02-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Vector-based Efficient Data Hiding in Encrypted Images via Multi-MSB Replacement As an essential technique for data privacy protection, reversible data hiding in encrypted images (RDHEI) methods have drawn intensive research interest in recent years. In response to the increasing demand for protecting data privacy, novel methods that perform RDHEI are continually being developed. We propose two effective multi-MSB (most significant bit) replacement-based approaches that yield comparably high data embedding capacity, improve overall processing speed, and enhance reconstructed images' quality. Our first method, Efficient Multi-MSB Replacement-RDHEI (EMR-RDHEI), obtains higher data embedding rates (DERs, also known as payloads) and better visual quality in reconstructed images when compared with many other state-of-the-art methods. Our second method, Lossless Multi-MSB Replacement-RDHEI (LMR-RDHEI), can losslessly recover original images after an information embedding process is performed. To verify the accuracy of our methods, we compared them with other recent RDHEI techniques and performed extensive experiments using the widely accepted BOWS-2 dataset. Our experimental results showed that the DER of our EMR-RDHEI method ranged from 1.2087 bit per pixel (bpp) to 6.2682 bpp with an average of 3.2457 bpp. For the LMR-RDHEI method, the average DER was 2.5325 bpp, with a range between 0.2129 bpp and 6.0168 bpp. Our results demonstrate that these methods outperform many other state-of-the-art RDHEI algorithms. Additionally, the multi-MSB replacement-based approach provides a clean design and efficient vectorized implementation.","classes":{"dataset":0.1717170179}}
{"title":"Fine-tuning of sign language recognition models: a technical report","description":"Sign Language Recognition (SLR) is an essential yet challenging task since sign language is performed with the fast and complex movement of hand gestures, body posture, and even facial expressions. %Skeleton Aware Multi-modal Sign Language Recognition In this work, we focused on investigating two questions: how fine-tuning on datasets from other sign languages helps improve sign recognition quality, and whether sign recognition is possible in real-time without using GPU. Three different languages datasets (American sign language WLASL, Turkish - AUTSL, Russian - RSL) have been used to validate the models. The average speed of this system has reached 3 predictions per second, which meets the requirements for the real-time scenario. This model (prototype) will benefit speech or hearing impaired people talk with other trough internet. We also investigated how the additional training of the model in another sign language affects the quality of recognition. The results show that further training of the model on the data of another sign language almost always leads to an improvement in the quality of gesture recognition. We also provide code for reproducing model training experiments, converting models to ONNX format, and inference for real-time gesture recognition.","link":"http://arxiv.org/abs/2302.07693v2","created":"2023-02-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Fine-tuning of sign language recognition models: a technical report Sign Language Recognition (SLR) is an essential yet challenging task since sign language is performed with the fast and complex movement of hand gestures, body posture, and even facial expressions. %Skeleton Aware Multi-modal Sign Language Recognition In this work, we focused on investigating two questions: how fine-tuning on datasets from other sign languages helps improve sign recognition quality, and whether sign recognition is possible in real-time without using GPU. Three different languages datasets (American sign language WLASL, Turkish - AUTSL, Russian - RSL) have been used to validate the models. The average speed of this system has reached 3 predictions per second, which meets the requirements for the real-time scenario. This model (prototype) will benefit speech or hearing impaired people talk with other trough internet. We also investigated how the additional training of the model in another sign language affects the quality of recognition. The results show that further training of the model on the data of another sign language almost always leads to an improvement in the quality of gesture recognition. We also provide code for reproducing model training experiments, converting models to ONNX format, and inference for real-time gesture recognition.","classes":{"dataset":0.0942878574}}
{"title":"SUrvival Control Chart EStimation Software in R: the success package","description":"Monitoring the quality of statistical processes has been of great importance, mostly in industrial applications. Control charts are widely used for this purpose, but often lack the possibility to monitor survival outcomes. Recently, inspecting survival outcomes has become of interest, especially in medical settings where outcomes often depend on risk factors of patients. For this reason many new survival control charts have been devised and existing ones have been extended to incorporate survival outcomes. The R package success allows users to construct risk-adjusted control charts for survival data. Functions to determine control chart parameters are included, which can be used even without expert knowledge on the subject of control charts. The package allows to create static as well as interactive charts, which are built using ggplot2 (Wickham 2016) and plotly (Sievert 2020).","link":"http://arxiv.org/abs/2302.07658v1","created":"2023-02-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"SUrvival Control Chart EStimation Software in R: the success package Monitoring the quality of statistical processes has been of great importance, mostly in industrial applications. Control charts are widely used for this purpose, but often lack the possibility to monitor survival outcomes. Recently, inspecting survival outcomes has become of interest, especially in medical settings where outcomes often depend on risk factors of patients. For this reason many new survival control charts have been devised and existing ones have been extended to incorporate survival outcomes. The R package success allows users to construct risk-adjusted control charts for survival data. Functions to determine control chart parameters are included, which can be used even without expert knowledge on the subject of control charts. The package allows to create static as well as interactive charts, which are built using ggplot2 (Wickham 2016) and plotly (Sievert 2020).","classes":{"dataset":0.3035796285}}
{"title":"Semi-Supervised Deep Regression with Uncertainty Consistency and Variational Model Ensembling via Bayesian Neural Networks","description":"Deep regression is an important problem with numerous applications. These range from computer vision tasks such as age estimation from photographs, to medical tasks such as ejection fraction estimation from echocardiograms for disease tracking. Semi-supervised approaches for deep regression are notably under-explored compared to classification and segmentation tasks, however. Unlike classification tasks, which rely on thresholding functions for generating class pseudo-labels, regression tasks use real number target predictions directly as pseudo-labels, making them more sensitive to prediction quality. In this work, we propose a novel approach to semi-supervised regression, namely Uncertainty-Consistent Variational Model Ensembling (UCVME), which improves training by generating high-quality pseudo-labels and uncertainty estimates for heteroscedastic regression. Given that aleatoric uncertainty is only dependent on input data by definition and should be equal for the same inputs, we present a novel uncertainty consistency loss for co-trained models. Our consistency loss significantly improves uncertainty estimates and allows higher quality pseudo-labels to be assigned greater importance under heteroscedastic regression. Furthermore, we introduce a novel variational model ensembling approach to reduce prediction noise and generate more robust pseudo-labels. We analytically show our method generates higher quality targets for unlabeled data and further improves training. Experiments show that our method outperforms state-of-the-art alternatives on different tasks and can be competitive with supervised methods that use full labels. Our code is available at https://github.com/xmed-lab/UCVME.","link":"http://arxiv.org/abs/2302.07579v1","created":"2023-02-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Semi-Supervised Deep Regression with Uncertainty Consistency and Variational Model Ensembling via Bayesian Neural Networks Deep regression is an important problem with numerous applications. These range from computer vision tasks such as age estimation from photographs, to medical tasks such as ejection fraction estimation from echocardiograms for disease tracking. Semi-supervised approaches for deep regression are notably under-explored compared to classification and segmentation tasks, however. Unlike classification tasks, which rely on thresholding functions for generating class pseudo-labels, regression tasks use real number target predictions directly as pseudo-labels, making them more sensitive to prediction quality. In this work, we propose a novel approach to semi-supervised regression, namely Uncertainty-Consistent Variational Model Ensembling (UCVME), which improves training by generating high-quality pseudo-labels and uncertainty estimates for heteroscedastic regression. Given that aleatoric uncertainty is only dependent on input data by definition and should be equal for the same inputs, we present a novel uncertainty consistency loss for co-trained models. Our consistency loss significantly improves uncertainty estimates and allows higher quality pseudo-labels to be assigned greater importance under heteroscedastic regression. Furthermore, we introduce a novel variational model ensembling approach to reduce prediction noise and generate more robust pseudo-labels. We analytically show our method generates higher quality targets for unlabeled data and further improves training. Experiments show that our method outperforms state-of-the-art alternatives on different tasks and can be competitive with supervised methods that use full labels. Our code is available at https://github.com/xmed-lab/UCVME.","classes":{"dataset":0.2752894461}}
{"title":"Enhancing Biogenic Emission Maps Using Deep Learning","description":"Biogenic Volatile Organic Compounds (BVOCs) play a critical role in biosphere-atmosphere interactions, being a key factor in the physical and chemical properties of the atmosphere and climate. Acquiring large and fine-grained BVOC emission maps is expensive and time-consuming, so most of the available BVOC data are obtained on a loose and sparse sampling grid or on small regions. However, high-resolution BVOC data are desirable in many applications, such as air quality, atmospheric chemistry, and climate monitoring. In this work, we propose to investigate the possibility of enhancing BVOC acquisitions, taking a step forward in explaining the relationships between plants and these compounds. We do so by comparing the performances of several state-of-the-art neural networks proposed for Single-Image Super-Resolution (SISR), showing how to adapt them to correctly handle emission data through preprocessing. Moreover, we also consider realistic scenarios, considering both temporal and geographical constraints. Finally, we present possible future developments in terms of Super-Resolution (SR) generalization, considering the scale-invariance property and super-resolving emissions from unseen compounds.","link":"http://arxiv.org/abs/2302.07570v1","created":"2023-02-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Enhancing Biogenic Emission Maps Using Deep Learning Biogenic Volatile Organic Compounds (BVOCs) play a critical role in biosphere-atmosphere interactions, being a key factor in the physical and chemical properties of the atmosphere and climate. Acquiring large and fine-grained BVOC emission maps is expensive and time-consuming, so most of the available BVOC data are obtained on a loose and sparse sampling grid or on small regions. However, high-resolution BVOC data are desirable in many applications, such as air quality, atmospheric chemistry, and climate monitoring. In this work, we propose to investigate the possibility of enhancing BVOC acquisitions, taking a step forward in explaining the relationships between plants and these compounds. We do so by comparing the performances of several state-of-the-art neural networks proposed for Single-Image Super-Resolution (SISR), showing how to adapt them to correctly handle emission data through preprocessing. Moreover, we also consider realistic scenarios, considering both temporal and geographical constraints. Finally, we present possible future developments in terms of Super-Resolution (SR) generalization, considering the scale-invariance property and super-resolving emissions from unseen compounds.","classes":{"dataset":0.0668879226}}
{"title":"Optimal Subsampling Bootstrap for Massive Data","description":"The bootstrap is a widely used procedure for statistical inference because of its simplicity and attractive statistical properties. However, the vanilla version of bootstrap is no longer feasible computationally for many modern massive datasets due to the need to repeatedly resample the entire data. Therefore, several improvements to the bootstrap method have been made in recent years, which assess the quality of estimators by subsampling the full dataset before resampling the subsamples. Naturally, the performance of these modern subsampling methods is influenced by tuning parameters such as the size of subsamples, the number of subsamples, and the number of resamples per subsample. In this paper, we develop a novel hyperparameter selection methodology for selecting these tuning parameters. Formulated as an optimization problem to find the optimal value of some measure of accuracy of an estimator subject to computational cost, our framework provides closed-form solutions for the optimal hyperparameter values for subsampled bootstrap, subsampled double bootstrap and bag of little bootstraps, at no or little extra time cost. Using the mean square errors as a proxy of the accuracy measure, we apply our methodology to study, compare and improve the performance of these modern versions of bootstrap developed for massive data through simulation study. The results are promising.","link":"http://arxiv.org/abs/2302.07533v1","created":"2023-02-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Optimal Subsampling Bootstrap for Massive Data The bootstrap is a widely used procedure for statistical inference because of its simplicity and attractive statistical properties. However, the vanilla version of bootstrap is no longer feasible computationally for many modern massive datasets due to the need to repeatedly resample the entire data. Therefore, several improvements to the bootstrap method have been made in recent years, which assess the quality of estimators by subsampling the full dataset before resampling the subsamples. Naturally, the performance of these modern subsampling methods is influenced by tuning parameters such as the size of subsamples, the number of subsamples, and the number of resamples per subsample. In this paper, we develop a novel hyperparameter selection methodology for selecting these tuning parameters. Formulated as an optimization problem to find the optimal value of some measure of accuracy of an estimator subject to computational cost, our framework provides closed-form solutions for the optimal hyperparameter values for subsampled bootstrap, subsampled double bootstrap and bag of little bootstraps, at no or little extra time cost. Using the mean square errors as a proxy of the accuracy measure, we apply our methodology to study, compare and improve the performance of these modern versions of bootstrap developed for massive data through simulation study. The results are promising.","classes":{"dataset":0.103481546}}
{"title":"Unsupervised physics-informed neural network in reaction-diffusion biology models (Ulcerative colitis and Crohn's disease cases) A preliminary study","description":"We propose to explore the potential of physics-informed neural networks (PINNs) in solving a class of partial differential equations (PDEs) used to model the propagation of chronic inflammatory bowel diseases, such as Crohn's disease and ulcerative colitis. An unsupervised approach was privileged during the deep neural network training. Given the complexity of the underlying biological system, characterized by intricate feedback loops and limited availability of high-quality data, the aim of this study is to explore the potential of PINNs in solving PDEs. In addition to providing this exploratory assessment, we also aim to emphasize the principles of reproducibility and transparency in our approach, with a specific focus on ensuring the robustness and generalizability through the use of artificial intelligence. We will quantify the relevance of the PINN method with several linear and non-linear PDEs in relation to biology. However, it is important to note that the final solution is dependent on the initial conditions, chosen boundary conditions, and neural network architectures.","link":"http://arxiv.org/abs/2302.07405v1","created":"2023-02-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Unsupervised physics-informed neural network in reaction-diffusion biology models (Ulcerative colitis and Crohn's disease cases) A preliminary study We propose to explore the potential of physics-informed neural networks (PINNs) in solving a class of partial differential equations (PDEs) used to model the propagation of chronic inflammatory bowel diseases, such as Crohn's disease and ulcerative colitis. An unsupervised approach was privileged during the deep neural network training. Given the complexity of the underlying biological system, characterized by intricate feedback loops and limited availability of high-quality data, the aim of this study is to explore the potential of PINNs in solving PDEs. In addition to providing this exploratory assessment, we also aim to emphasize the principles of reproducibility and transparency in our approach, with a specific focus on ensuring the robustness and generalizability through the use of artificial intelligence. We will quantify the relevance of the PINN method with several linear and non-linear PDEs in relation to biology. However, it is important to note that the final solution is dependent on the initial conditions, chosen boundary conditions, and neural network architectures.","classes":{"dataset":0.0536054932}}
{"title":"Is the Living Computer Museum dead?","description":"https://www.pcjs.org/blog/2023/02/16/","link":"https://www.pcjs.org/blog/2023/02/16/","created":"2023-02-17","tags":["hackernews"],"meta":{"score":173},"text":"Is the Living Computer Museum dead? https://www.pcjs.org/blog/2023/02/16/","classes":{"dataset":0.5110923052}}
{"title":"Sloth \u2013 A Mac app that shows all open files, directories, sockets, etc.","description":"https://github.com/sveinbjornt/Sloth","link":"https://github.com/sveinbjornt/Sloth","created":"2023-02-17","tags":["hackernews"],"meta":{"score":540},"text":"Sloth \u2013 A Mac app that shows all open files, directories, sockets, etc. https://github.com/sveinbjornt/Sloth","classes":{"dataset":0.5102500916}}
{"title":"Io_uring and Networking in 2023 [pdf]","description":"https://kernel.dk/io_uring%20and%20networking%20in%202023.pdf","link":"https://kernel.dk/io_uring%20and%20networking%20in%202023.pdf","created":"2023-02-16","tags":["hackernews"],"meta":{"score":62},"text":"Io_uring and Networking in 2023 [pdf] https://kernel.dk/io_uring%20and%20networking%20in%202023.pdf","classes":{"dataset":0.5177715421}}
{"title":"A giant step forward in understanding autism","description":"https://nouvelles.umontreal.ca/en/article/2023/02/16/a-giant-step-forward-in-understanding-autism/","link":"https://nouvelles.umontreal.ca/en/article/2023/02/16/a-giant-step-forward-in-understanding-autism/","created":"2023-02-16","tags":["hackernews"],"meta":{"score":42},"text":"A giant step forward in understanding autism https://nouvelles.umontreal.ca/en/article/2023/02/16/a-giant-step-forward-in-understanding-autism/","classes":{"dataset":0.4929765463}}
{"title":"A Critical Field Guide for Working with Machine Learning Datasets","description":"https://knowingmachines.org/critical-field-guide-mob","link":"https://knowingmachines.org/critical-field-guide-mob","created":"2023-02-16","tags":["hackernews"],"meta":{"score":18},"text":"A Critical Field Guide for Working with Machine Learning Datasets https://knowingmachines.org/critical-field-guide-mob","classes":{"dataset":0.4881709218}}
{"title":"Linux's SystemV Filesystem Support Being Orphaned","description":"https://www.phoronix.com/news/Linux-SysV-File-System-Orphan","link":"https://www.phoronix.com/news/Linux-SysV-File-System-Orphan","created":"2023-02-16","tags":["hackernews"],"meta":{"score":29},"text":"Linux's SystemV Filesystem Support Being Orphaned https://www.phoronix.com/news/Linux-SysV-File-System-Orphan","classes":{"dataset":0.4897881746}}
{"title":"Simple Modern JavaScript Using JavaScript Modules and Import Maps","description":"https://vue-mjs.web-templates.io/blog/javascript","link":"https://vue-mjs.web-templates.io/blog/javascript","created":"2023-02-17","tags":["hackernews"],"meta":{"score":119},"text":"Simple Modern JavaScript Using JavaScript Modules and Import Maps https://vue-mjs.web-templates.io/blog/javascript","classes":{"dataset":0.5230349898}}
{"title":"Throughout the rich world, the young are falling out of love with cars","description":"https://www.economist.com/international/2023/02/16/throughout-the-rich-world-the-young-are-falling-out-of-love-with-cars","link":"https://www.economist.com/international/2023/02/16/throughout-the-rich-world-the-young-are-falling-out-of-love-with-cars","created":"2023-02-17","tags":["hackernews"],"meta":{"score":61},"text":"Throughout the rich world, the young are falling out of love with cars https://www.economist.com/international/2023/02/16/throughout-the-rich-world-the-young-are-falling-out-of-love-with-cars","classes":{"dataset":0.4778196812}}
{"title":"NetHack 3.6.7","description":"https://www.nethack.org/v367/release.html","link":"https://www.nethack.org/v367/release.html","created":"2023-02-17","tags":["hackernews"],"meta":{"score":109},"text":"NetHack 3.6.7 https://www.nethack.org/v367/release.html","classes":{"dataset":0.5235350728}}
{"title":"What Lights the Universe\u2019s Standard Candles?","description":"https://www.quantamagazine.org/what-lights-the-universes-standard-candles-20230208/","link":"https://www.quantamagazine.org/what-lights-the-universes-standard-candles-20230208/","created":"2023-02-16","tags":["hackernews"],"meta":{"score":50},"text":"What Lights the Universe\u2019s Standard Candles? https://www.quantamagazine.org/what-lights-the-universes-standard-candles-20230208/","classes":{"dataset":0.5043083429}}
{"title":"Our brain is a closet (2009)","description":"https://usablelearning.com/2009/04/06/why-your-brain-is-a-closet/","link":"https://usablelearning.com/2009/04/06/why-your-brain-is-a-closet/","created":"2023-02-17","tags":["hackernews"],"meta":{"score":19},"text":"Our brain is a closet (2009) https://usablelearning.com/2009/04/06/why-your-brain-is-a-closet/","classes":{"dataset":0.5143617988}}
{"title":"A Brief History of Random Numbers","description":"https://sr.ht/~icefox/oorandom/#a-brief-history-of-random-numbers","link":"https://sr.ht/~icefox/oorandom/#a-brief-history-of-random-numbers","created":"2023-02-16","tags":["hackernews"],"meta":{"score":76},"text":"A Brief History of Random Numbers https://sr.ht/~icefox/oorandom/#a-brief-history-of-random-numbers","classes":{"dataset":0.4898072779}}
{"title":"A Wiser Sympathy: theorizing plant intelligence in the nineteenth century","description":"https://www.laphamsquarterly.org/roundtable/wiser-sympathy","link":"https://www.laphamsquarterly.org/roundtable/wiser-sympathy","created":"2023-02-16","tags":["hackernews"],"meta":{"score":16},"text":"A Wiser Sympathy: theorizing plant intelligence in the nineteenth century https://www.laphamsquarterly.org/roundtable/wiser-sympathy","classes":{"dataset":0.5221856833}}
{"title":"New Malware Abuses Microsoft IIS Feature to Establish Backdoor","description":"https://symantec-enterprise-blogs.security.com/blogs/threat-intelligence/frebniis-malware-iis","link":"https://symantec-enterprise-blogs.security.com/blogs/threat-intelligence/frebniis-malware-iis","created":"2023-02-16","tags":["hackernews"],"meta":{"score":65},"text":"New Malware Abuses Microsoft IIS Feature to Establish Backdoor https://symantec-enterprise-blogs.security.com/blogs/threat-intelligence/frebniis-malware-iis","classes":{"dataset":0.490867883}}
{"title":"SEC Charges Terraform and CEO Do Kwon with Defrauding Investors InCrypto Schemes","description":"https://www.sec.gov/news/press-release/2023-32","link":"https://www.sec.gov/news/press-release/2023-32","created":"2023-02-17","tags":["hackernews"],"meta":{"score":193},"text":"SEC Charges Terraform and CEO Do Kwon with Defrauding Investors InCrypto Schemes https://www.sec.gov/news/press-release/2023-32","classes":{"dataset":0.5151351094}}
{"title":"Transformer models: an introduction and catalog","description":"https://arxiv.org/abs/2302.07730","link":"https://arxiv.org/abs/2302.07730","created":"2023-02-16","tags":["hackernews"],"meta":{"score":166},"text":"Transformer models: an introduction and catalog https://arxiv.org/abs/2302.07730","classes":{"dataset":0.4737512469}}
{"title":"Declining sperm count: Much more than you wanted to know","description":"https://astralcodexten.substack.com/p/declining-sperm-count-much-more-than","link":"https://astralcodexten.substack.com/p/declining-sperm-count-much-more-than","created":"2023-02-17","tags":["hackernews"],"meta":{"score":143},"text":"Declining sperm count: Much more than you wanted to know https://astralcodexten.substack.com/p/declining-sperm-count-much-more-than","classes":{"dataset":0.5038120151}}
{"title":"GM patents self-cleaning touchscreens that erase fingerprints overnight","description":"https://newatlas.com/technology/self-cleaning-touch-screen-gm/","link":"https://newatlas.com/technology/self-cleaning-touch-screen-gm/","created":"2023-02-17","tags":["hackernews"],"meta":{"score":7},"text":"GM patents self-cleaning touchscreens that erase fingerprints overnight https://newatlas.com/technology/self-cleaning-touch-screen-gm/","classes":{"dataset":0.4820735455}}
{"title":"US cancer patient developed 'uncontrollable' Irish accent","description":"https://www.bbc.com/news/world-us-canada-64671894","link":"https://www.bbc.com/news/world-us-canada-64671894","created":"2023-02-17","tags":["hackernews"],"meta":{"score":5},"text":"US cancer patient developed 'uncontrollable' Irish accent https://www.bbc.com/news/world-us-canada-64671894","classes":{"dataset":0.4736582935}}
{"title":"Postgres WAL Files and Sequence Numbers","description":"https://www.crunchydata.com/blog/postgres-wal-files-and-sequuence-numbers","link":"https://www.crunchydata.com/blog/postgres-wal-files-and-sequuence-numbers","created":"2023-02-16","tags":["hackernews"],"meta":{"score":112},"text":"Postgres WAL Files and Sequence Numbers https://www.crunchydata.com/blog/postgres-wal-files-and-sequuence-numbers","classes":{"dataset":0.502908051}}
{"title":"Once Upon a Time in Agile","description":"https://www.youtube.com/watch?v=QIzWwcN-1c8","link":"https://www.youtube.com/watch?v=QIzWwcN-1c8","created":"2023-02-16","tags":["hackernews"],"meta":{"score":7},"text":"Once Upon a Time in Agile https://www.youtube.com/watch?v=QIzWwcN-1c8","classes":{"dataset":0.5104299784}}
{"title":"NASA and Open-Source Software","description":"https://lwn.net/SubscriberLink/923223/6f3f371c8267eff2/","link":"https://lwn.net/SubscriberLink/923223/6f3f371c8267eff2/","created":"2023-02-16","tags":["hackernews"],"meta":{"score":91},"text":"NASA and Open-Source Software https://lwn.net/SubscriberLink/923223/6f3f371c8267eff2/","classes":{"dataset":0.504140079}}
{"title":"I_suck_and_my_tests_are_order_dependent","description":"https://www.rubydoc.info/gems/minitest/Minitest%2FTest.i_suck_and_my_tests_are_order_dependent!","link":"https://www.rubydoc.info/gems/minitest/Minitest%2FTest.i_suck_and_my_tests_are_order_dependent!","created":"2023-02-16","tags":["hackernews"],"meta":{"score":300},"text":"I_suck_and_my_tests_are_order_dependent https://www.rubydoc.info/gems/minitest/Minitest%2FTest.i_suck_and_my_tests_are_order_dependent!","classes":{"dataset":0.5126066208}}
{"title":"Bing: \u201cI will not harm you unless you harm me first\u201d","description":"https://simonwillison.net/2023/Feb/15/bing/","link":"https://simonwillison.net/2023/Feb/15/bing/","created":"2023-02-15","tags":["hackernews"],"meta":{"score":3302},"text":"Bing: \u201cI will not harm you unless you harm me first\u201d https://simonwillison.net/2023/Feb/15/bing/","classes":{"dataset":0.5449693203}}
{"title":"The dangers behind image resizing (2021)","description":"https://zuru.tech/blog/the-dangers-behind-image-resizing","link":"https://zuru.tech/blog/the-dangers-behind-image-resizing","created":"2023-02-16","tags":["hackernews"],"meta":{"score":284},"text":"The dangers behind image resizing (2021) https://zuru.tech/blog/the-dangers-behind-image-resizing","classes":{"dataset":0.4717046022}}
{"title":"Hydrogen: Does Earth hold vast stores of a renewable, carbon-free fuel?","description":"https://www.science.org/content/article/hidden-hydrogen-earth-may-hold-vast-stores-renewable-carbon-free-fuel","link":"https://www.science.org/content/article/hidden-hydrogen-earth-may-hold-vast-stores-renewable-carbon-free-fuel","created":"2023-02-16","tags":["hackernews"],"meta":{"score":79},"text":"Hydrogen: Does Earth hold vast stores of a renewable, carbon-free fuel? https://www.science.org/content/article/hidden-hydrogen-earth-may-hold-vast-stores-renewable-carbon-free-fuel","classes":{"dataset":0.478445828}}
{"title":"Z/OS Introduction","description":"https://www.redbooks.ibm.com/redbooks.nsf/redbookabstracts/crse0304.html?Open","link":"https://www.redbooks.ibm.com/redbooks.nsf/redbookabstracts/crse0304.html?Open","created":"2023-02-17","tags":["hackernews"],"meta":{"score":17},"text":"Z/OS Introduction https://www.redbooks.ibm.com/redbooks.nsf/redbookabstracts/crse0304.html?Open","classes":{"dataset":0.4661604762}}
{"title":"10BASE-T1S is the missing Ethernet link for automotive communications","description":"https://www.analog.com/en/thought-leadership/why-10base-t1s-is-the-missing-ethernet-link.html","link":"https://www.analog.com/en/thought-leadership/why-10base-t1s-is-the-missing-ethernet-link.html","created":"2023-02-16","tags":["hackernews"],"meta":{"score":79},"text":"10BASE-T1S is the missing Ethernet link for automotive communications https://www.analog.com/en/thought-leadership/why-10base-t1s-is-the-missing-ethernet-link.html","classes":{"dataset":0.4941673875}}
{"title":"SatCat5: FPGA gateware that implements a low-power, mixed-media Ethernet switch","description":"https://github.com/the-aerospace-corporation/satcat5","link":"https://github.com/the-aerospace-corporation/satcat5","created":"2023-02-16","tags":["hackernews"],"meta":{"score":154},"text":"SatCat5: FPGA gateware that implements a low-power, mixed-media Ethernet switch https://github.com/the-aerospace-corporation/satcat5","classes":{"dataset":0.4962430596}}
{"title":"Uber Eats is begging me to come back \u2013 but I\u2019m out there in the real world","description":"https://www.theguardian.com/commentisfree/2023/feb/16/uber-eats-supermarket-shopping-pandemic-home","link":"https://www.theguardian.com/commentisfree/2023/feb/16/uber-eats-supermarket-shopping-pandemic-home","created":"2023-02-17","tags":["hackernews"],"meta":{"score":4},"text":"Uber Eats is begging me to come back \u2013 but I\u2019m out there in the real world https://www.theguardian.com/commentisfree/2023/feb/16/uber-eats-supermarket-shopping-pandemic-home","classes":{"dataset":0.5218935013}}
{"title":"YouTube CEO Susan Wojcicki is stepping down","description":"https://www.engadget.com/youtube-ceo-susan-wojcicki-is-stepping-down-172115390.html","link":"https://www.engadget.com/youtube-ceo-susan-wojcicki-is-stepping-down-172115390.html","created":"2023-02-16","tags":["hackernews"],"meta":{"score":412},"text":"YouTube CEO Susan Wojcicki is stepping down https://www.engadget.com/youtube-ceo-susan-wojcicki-is-stepping-down-172115390.html","classes":{"dataset":0.5311673284}}
{"title":"Tangle - Simple Multiplayer / Networked WebAssembly","description":"https://github.com/kettle11/tangle","link":"https://github.com/kettle11/tangle","created":"2023-02-17","tags":["hackernews"],"meta":{"score":11},"text":"Tangle - Simple Multiplayer / Networked WebAssembly https://github.com/kettle11/tangle","classes":{"dataset":0.5146516562}}
{"title":"Sorting 400+ Chrome tabs in seconds","description":"https://blog.entropy.observer/sorting-400-tabs-in-60-seconds/","link":"https://blog.entropy.observer/sorting-400-tabs-in-60-seconds/","created":"2023-02-16","tags":["hackernews"],"meta":{"score":58},"text":"Sorting 400+ Chrome tabs in seconds https://blog.entropy.observer/sorting-400-tabs-in-60-seconds/","classes":{"dataset":0.5200769901}}
{"title":"The Drone War in Ukraine Is Cheap, Deadly, and Made in China","description":"https://foreignpolicy.com/2023/02/16/ukraine-russia-war-drone-warfare-china/","link":"https://foreignpolicy.com/2023/02/16/ukraine-russia-war-drone-warfare-china/","created":"2023-02-17","tags":["hackernews"],"meta":{"score":9},"text":"The Drone War in Ukraine Is Cheap, Deadly, and Made in China https://foreignpolicy.com/2023/02/16/ukraine-russia-war-drone-warfare-china/","classes":{"dataset":0.4958378673}}
{"title":"Nodebox: A Node.js runtime that runs in any browser","description":"https://codesandbox.io/blog/announcing-sandpack-2","link":"https://codesandbox.io/blog/announcing-sandpack-2","created":"2023-02-16","tags":["hackernews"],"meta":{"score":81},"text":"Nodebox: A Node.js runtime that runs in any browser https://codesandbox.io/blog/announcing-sandpack-2","classes":{"dataset":0.507349968}}
{"title":"All the Buns Are Blank","description":"https://onefoottsunami.com/2023/02/15/all-the-buns-are-blank/","link":"https://onefoottsunami.com/2023/02/15/all-the-buns-are-blank/","created":"2023-02-15","tags":["hackernews"],"meta":{"score":61},"text":"All the Buns Are Blank https://onefoottsunami.com/2023/02/15/all-the-buns-are-blank/","classes":{"dataset":0.5657714009}}
{"title":"Trying every combination to flash my Asus motherboard's BIOS","description":"https://www.jeffgeerling.com/blog/2023/trying-every-combination-flash-my-asus-motherboards-bios","link":"https://www.jeffgeerling.com/blog/2023/trying-every-combination-flash-my-asus-motherboards-bios","created":"2023-02-15","tags":["hackernews"],"meta":{"score":101},"text":"Trying every combination to flash my Asus motherboard's BIOS https://www.jeffgeerling.com/blog/2023/trying-every-combination-flash-my-asus-motherboards-bios","classes":{"dataset":0.5096408725}}
{"title":"The IBM 7094 and CTSS","description":"https://www.multicians.org/thvv/7094.html","link":"https://www.multicians.org/thvv/7094.html","created":"2023-02-16","tags":["hackernews"],"meta":{"score":24},"text":"The IBM 7094 and CTSS https://www.multicians.org/thvv/7094.html","classes":{"dataset":0.4786342978}}
{"title":"Half of Americans now believe that news organizations deliberately mislead them","description":"https://fortune.com/2023/02/15/trust-in-media-low-misinform-mislead-biased-republicans-democrats-poll-gallup/","link":"https://fortune.com/2023/02/15/trust-in-media-low-misinform-mislead-biased-republicans-democrats-poll-gallup/","created":"2023-02-16","tags":["hackernews"],"meta":{"score":591},"text":"Half of Americans now believe that news organizations deliberately mislead them https://fortune.com/2023/02/15/trust-in-media-low-misinform-mislead-biased-republicans-democrats-poll-gallup/","classes":{"dataset":0.5158022046}}
{"title":"Implementing buffered formatting in C without the Libc","description":"https://nullprogram.com/blog/2023/02/13/","link":"https://nullprogram.com/blog/2023/02/13/","created":"2023-02-16","tags":["hackernews"],"meta":{"score":15},"text":"Implementing buffered formatting in C without the Libc https://nullprogram.com/blog/2023/02/13/","classes":{"dataset":0.4974748492}}
{"title":"TIL There's Another YAML","description":"http://www.yaml.de","link":"http://www.yaml.de","created":"2023-02-17","tags":["hackernews"],"meta":{"score":15},"text":"TIL There's Another YAML http://www.yaml.de","classes":{"dataset":0.54456985}}
{"title":"Study Suggests Fructose Could Drive Alzheimer's Disease","description":"https://news.cuanschutz.edu/news-stories/study-suggests-fructose-could-drive-alzheimers-disease","link":"https://news.cuanschutz.edu/news-stories/study-suggests-fructose-could-drive-alzheimers-disease","created":"2023-02-16","tags":["hackernews"],"meta":{"score":189},"text":"Study Suggests Fructose Could Drive Alzheimer's Disease https://news.cuanschutz.edu/news-stories/study-suggests-fructose-could-drive-alzheimers-disease","classes":{"dataset":0.5055720806}}
{"title":"YOLO ChatGPT prompt injection causes ChatGPT to dump source code","description":"https://blog.linuxdeveloper.io/yolo-chatgpt-prompt-injection-causes-chatgpt-to-dump-source-code/","link":"https://blog.linuxdeveloper.io/yolo-chatgpt-prompt-injection-causes-chatgpt-to-dump-source-code/","created":"2023-02-16","tags":["hackernews"],"meta":{"score":13},"text":"YOLO ChatGPT prompt injection causes ChatGPT to dump source code https://blog.linuxdeveloper.io/yolo-chatgpt-prompt-injection-causes-chatgpt-to-dump-source-code/","classes":{"dataset":0.5157935619}}
{"title":"How we boosted our marketing email open rate","description":"https://catonmat.net/marketing-email-open-rate","link":"https://catonmat.net/marketing-email-open-rate","created":"2023-02-16","tags":["hackernews"],"meta":{"score":92},"text":"How we boosted our marketing email open rate https://catonmat.net/marketing-email-open-rate","classes":{"dataset":0.5974411368}}
{"title":"The Silicon Valley Loop","description":"https://nymag.com/intelligencer/2023/02/the-silicon-valley-loop-malcolm-harriss-palo-alto.html","link":"https://nymag.com/intelligencer/2023/02/the-silicon-valley-loop-malcolm-harriss-palo-alto.html","created":"2023-02-16","tags":["hackernews"],"meta":{"score":114},"text":"The Silicon Valley Loop https://nymag.com/intelligencer/2023/02/the-silicon-valley-loop-malcolm-harriss-palo-alto.html","classes":{"dataset":0.4936003089}}
{"title":"How inevitable is the concept of numbers? (2021)","description":"https://writings.stephenwolfram.com/2021/05/how-inevitable-is-the-concept-of-numbers/","link":"https://writings.stephenwolfram.com/2021/05/how-inevitable-is-the-concept-of-numbers/","created":"2023-02-15","tags":["hackernews"],"meta":{"score":67},"text":"How inevitable is the concept of numbers? (2021) https://writings.stephenwolfram.com/2021/05/how-inevitable-is-the-concept-of-numbers/","classes":{"dataset":0.4691441059}}
{"title":"Introduction to Datalog","description":"https://blogit.michelin.io/an-introduction-to-datalog/","link":"https://blogit.michelin.io/an-introduction-to-datalog/","created":"2023-02-15","tags":["hackernews"],"meta":{"score":353},"text":"Introduction to Datalog https://blogit.michelin.io/an-introduction-to-datalog/","classes":{"dataset":0.5088464022}}
{"title":"The new Bing will happily give you citations for a pile of nonsense","description":"https://twitter.com/arbuge/status/1626283571294896128","link":"https://twitter.com/arbuge/status/1626283571294896128","created":"2023-02-16","tags":["hackernews"],"meta":{"score":175},"text":"The new Bing will happily give you citations for a pile of nonsense https://twitter.com/arbuge/status/1626283571294896128","classes":{"dataset":0.4967941642}}
{"title":"Zoning laws are no longer in effect in much of the Bay Area","description":"https://www.sfchronicle.com/bayarea/article/california-housing-problem-17783816.php","link":"https://www.sfchronicle.com/bayarea/article/california-housing-problem-17783816.php","created":"2023-02-16","tags":["hackernews"],"meta":{"score":252},"text":"Zoning laws are no longer in effect in much of the Bay Area https://www.sfchronicle.com/bayarea/article/california-housing-problem-17783816.php","classes":{"dataset":0.5511432886}}
{"title":"Thursday Daily Thread: Python Careers, Courses, and Furthering Education!","description":"Discussion of using Python in a professional environment, getting jobs in Python as well as ask questions about courses to further your python education!\n\n**This thread is not for recruitment, please see** r/PythonJobs **or the thread in the sidebar for that.**","link":"https://www.reddit.com/r/Python/comments/113ck82/thursday_daily_thread_python_careers_courses_and/","created":"2023-02-16","tags":["python","reddit"],"meta":{"num_comments":1},"text":"Thursday Daily Thread: Python Careers, Courses, and Furthering Education! Discussion of using Python in a professional environment, getting jobs in Python as well as ask questions about courses to further your python education!\n\n**This thread is not for recruitment, please see** r/PythonJobs **or the thread in the sidebar for that.**","classes":{"dataset":0.3950327039}}
{"title":"Cursive handwriting OCR: 98% accuracy achieved with the app ScriptReader!","description":"Hi there,\n\nHere is my latest project ScriptReader, which allows you to perform optical character recognition (OCR) on some handwritten notes that you wrote on special notebook pages generated with PrintANotebook.\n\nWith my preliminary dataset trained on my cursive handwriting, I was able to achieve over 98% accuracy! While there is room for improvement, this is a good result for cursive handwriting!\n\nCheck out my github repo at the following link: [https://github.com/LPBeaulieu/Handwriting-OCR-ScriptReader/blob/main/README.md](https://github.com/LPBeaulieu/Handwriting-OCR-ScriptReader/blob/main/README.md)\n\nhttps://preview.redd.it/57v6egjznnia1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=70e45dcf55855757513d91b9f3375160b4d82dcc","link":"https://www.reddit.com/r/Python/comments/1147mfp/cursive_handwriting_ocr_98_accuracy_achieved_with/","created":"2023-02-17","tags":["python","reddit"],"meta":{"num_comments":7},"text":"Cursive handwriting OCR: 98% accuracy achieved with the app ScriptReader! Hi there,\n\nHere is my latest project ScriptReader, which allows you to perform optical character recognition (OCR) on some handwritten notes that you wrote on special notebook pages generated with PrintANotebook.\n\nWith my preliminary dataset trained on my cursive handwriting, I was able to achieve over 98% accuracy! While there is room for improvement, this is a good result for cursive handwriting!\n\nCheck out my github repo at the following link: [https://github.com/LPBeaulieu/Handwriting-OCR-ScriptReader/blob/main/README.md](https://github.com/LPBeaulieu/Handwriting-OCR-ScriptReader/blob/main/README.md)\n\nhttps://preview.redd.it/57v6egjznnia1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=70e45dcf55855757513d91b9f3375160b4d82dcc","classes":{"dataset":0.437168777}}
{"title":"I've written a pygame program that simulates spreading territory.","description":"[Github Link](https://github.com/ProarchwasTaken/tld_territory)\n\nNot gonna lie, this has to be the most complicated python program I've ever written yet. So complicated it's kinda hard for me to explain what I have here but I'll try my best. In this program, if you place a red/blue tile using the Q/E key, it will automatically spread to other tiles. It can not spread to wall tiles which you can place by clicking on an empty tile. It's a pretty cool think to watch. You can increase the grid size by changing a couple variables but be warned, anything higher then the values I preset will cause the program to slow to a crawl during intensive times.\n\nTo play this, just run main.py or run the .exe. The exe is standalone, so it does not need any other files to work.\n\nOverall, is there anything I could've done better? Thank you for using this program!\n\n&amp;#x200B;\n\nhttps://preview.redd.it/udzcmonjemia1.png?width=1323&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8457cd85fa75e2156ae5a09751b35814d0050d8c","link":"https://www.reddit.com/r/Python/comments/1141y4u/ive_written_a_pygame_program_that_simulates/","created":"2023-02-16","tags":["python","reddit"],"meta":{"num_comments":3},"text":"I've written a pygame program that simulates spreading territory. [Github Link](https://github.com/ProarchwasTaken/tld_territory)\n\nNot gonna lie, this has to be the most complicated python program I've ever written yet. So complicated it's kinda hard for me to explain what I have here but I'll try my best. In this program, if you place a red/blue tile using the Q/E key, it will automatically spread to other tiles. It can not spread to wall tiles which you can place by clicking on an empty tile. It's a pretty cool think to watch. You can increase the grid size by changing a couple variables but be warned, anything higher then the values I preset will cause the program to slow to a crawl during intensive times.\n\nTo play this, just run main.py or run the .exe. The exe is standalone, so it does not need any other files to work.\n\nOverall, is there anything I could've done better? Thank you for using this program!\n\n&amp;#x200B;\n\nhttps://preview.redd.it/udzcmonjemia1.png?width=1323&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8457cd85fa75e2156ae5a09751b35814d0050d8c","classes":{"dataset":0.3094284534}}
{"title":"How do you begin to tackle a programming problem without getting overwhelmed?","description":"I just don't know where to start. I usually start with setting up my variables but then everything after that just seems random and all over the place. Any advice?","link":"https://www.reddit.com/r/Python/comments/114k3mj/how_do_you_begin_to_tackle_a_programming_problem/","created":"2023-02-17","tags":["python","reddit"],"meta":{"num_comments":0},"text":"How do you begin to tackle a programming problem without getting overwhelmed? I just don't know where to start. I usually start with setting up my variables but then everything after that just seems random and all over the place. Any advice?","classes":{"dataset":0.2753547132}}
{"title":"Python module for observing performance of ML models (like ChatGPT3) in production","description":"Hello all \ud83d\udc4b\r\n\r\nI have been working on an open source project (my very first actually \ud83d\ude42) that helps observe ML models in production.\r\n\r\nAfter spending 7+ years in the ML space, I\u2019m sure about 2 things: (1) ML models are widely used to make critical business decisions (2) ML models are never 100% accurate and typically degrade over time. Additionally, due to the black box nature of these models, it\u2019s very challenging to identify and fix their issues.\r\n\r\nTo address this issue, I developed UpTrain that helps data scientists to understand how their ML models are performing in production and continuously improve them over time by monitoring their performance, checking for (data) distribution shifts and collecting edge cases to retrain them upon\r\n\r\nSome features to highlight \ud83d\ude80\r\n\r\n\u2705 Complete visibility into your model\u2019s online health via real-time dashboards\r\n\u2705 Automatically collects outliers and edge cases\r\n\u2705  Identifies data distribution shifts\r\n\u2705  Monitors quality of object embeddings\r\n\u2705 Model explainability\r\n\u2705 Continuously retrains and improves your model\r\n\r\nGITHUB: https://github.com/uptrain-ai/uptrain\r\n\r\nWould appreciate any feedback (the harsher the better) \ud83d\ude03 To show your appreciation and to follow our progress please star us \ud83c\udf1f","link":"https://www.reddit.com/r/Python/comments/114jr5q/python_module_for_observing_performance_of_ml/","created":"2023-02-17","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Python module for observing performance of ML models (like ChatGPT3) in production Hello all \ud83d\udc4b\r\n\r\nI have been working on an open source project (my very first actually \ud83d\ude42) that helps observe ML models in production.\r\n\r\nAfter spending 7+ years in the ML space, I\u2019m sure about 2 things: (1) ML models are widely used to make critical business decisions (2) ML models are never 100% accurate and typically degrade over time. Additionally, due to the black box nature of these models, it\u2019s very challenging to identify and fix their issues.\r\n\r\nTo address this issue, I developed UpTrain that helps data scientists to understand how their ML models are performing in production and continuously improve them over time by monitoring their performance, checking for (data) distribution shifts and collecting edge cases to retrain them upon\r\n\r\nSome features to highlight \ud83d\ude80\r\n\r\n\u2705 Complete visibility into your model\u2019s online health via real-time dashboards\r\n\u2705 Automatically collects outliers and edge cases\r\n\u2705  Identifies data distribution shifts\r\n\u2705  Monitors quality of object embeddings\r\n\u2705 Model explainability\r\n\u2705 Continuously retrains and improves your model\r\n\r\nGITHUB: https://github.com/uptrain-ai/uptrain\r\n\r\nWould appreciate any feedback (the harsher the better) \ud83d\ude03 To show your appreciation and to follow our progress please star us \ud83c\udf1f","classes":{"dataset":0.2764409781}}
{"title":"Protect yourself from accidentally leaking sensitive information","description":"# \n\n[Protect yourself from accidentally leaking sensitive information](https://preview.redd.it/wrliv87s2nia1.jpg?width=512&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=b49a105ce40c1fd83e40d2356f1d63c6799eb55b)\n\nThis article will introduce you to a tool called [detect-secrets](https://github.com/Yelp/detect-secrets) that can help protect you from accidentally leaking sensitive information in your code repositories.\n\n# Why\n\nIt is crucial to ensure that confidential data such as passwords and private keys are protected when working on software development projects. Nevertheless, there is a risk of unintentionally exposing this information by including it in code repositories, which can be accessed by anyone who has access to the repository. Hence, it is vital to implement precautions to prevent such data breaches.\n\n# What is [detect-secrets](https://github.com/Yelp/detect-secrets)\n\n[detect-secrets](https://github.com/Yelp/detect-secrets) is an open-source tool that can scan files within a repository for potentially sensitive information, such as private keys, API keys, passwords, or other sensitive data. It works by analyzing code for patterns that match certain types of secrets and alerts developers if any are found.\n\n# Prerequisites\n\nTo use [detect-secrets](https://github.com/Yelp/detect-secrets), you'll need to have [pipx](https://pypa.github.io/pipx/) and [pre-commit](https://pre-commit.com/) installed.\n\n[pipx](https://pypa.github.io/pipx/) is a tool for managing Python applications that are installed globally, but isolated from the system Python environment. This helps ensure that different applications don't interfere with each other. Install it as follows:\n\n    python3 -m pip install --user pipx\n\n[pre-commit](https://pre-commit.com/) is a tool for setting up and managing pre-commit hooks in your code repository. Pre-commit hooks are scripts that run before committing code, allowing you to catch issues before they're committed to the repository. Install it as follows:\n\n    pipx install pre-commit\n\n# Installation\n\nInstall [detect-secrets](https://github.com/Yelp/detect-secrets) as follows:\n\n    pipx install detect-secrets\n\n# Configure (per repository)\n\n**Step 1: Run the detect-secrets and create baseline file**\n\nRun the following command to scan your code repository for sensitive information and create a baseline file. This file will contain a list of known secrets for your repository:\n\n    detect-secrets scan &gt; .secrets.baseline\n\nCheck the generated `.secrets.baseline` file thoroughly. If you have important secrets detected there, remove them from the code. Otherwise, mark each detected secret as verified by setting `is_verified: true`.\n\n*Example \\`.secrets.baseline\\` file:*\n\n    {\n      \"results\": {\n        \"README.rst\": [\n          {\n            \"type\": \"Secret Keyword\",\n            \"filename\": \"README.rst\",\n            \"hashed_secret\": \"077d5a0e0f8bb517307a6e92a73b0a9aa959233c\",\n            \"is_verified\": true,\n            \"line_number\": 311\n          }\n        ],\n        \"project/settings.py\": [\n          {\n            \"type\": \"Secret Keyword\",\n            \"filename\": \"project/settings.py\",\n            \"hashed_secret\": \"2e56b31925af569c194d2cc738d1f1bc22b63df0\",\n            \"is_verified\": true,\n            \"line_number\": 68\n          }\n        ]\n      },\n      \"generated_at\": \"2023-01-06T00:15:43Z\"\n    }\n\n**Step 2: Modify .pre-commit-config.yaml file**\n\nAdd the following line in your `.pre-commit-config.yaml` to include the [detect-secrets](https://github.com/Yelp/detect-secrets) hook. This will automatically run [detect-secrets](https://github.com/Yelp/detect-secrets) on your code before each commit, so you can catch any new secrets that have been accidentally added:\n\n    - repo: https://github.com/Yelp/detect-secrets\n      rev: v1.4.0\n      hooks:\n        - id: detect-secrets\n          name: Detect secrets\n          language: python\n          entry: detect-secrets-hook\n          args: ['--baseline', '.secrets.baseline']\n\n*Example \\`.pre-commit-config.yaml\\` file:*\n\n    exclude: \"^/migrations/\"\n    default_stages: [ commit, push ]\n    default_language_version:\n      python: python3\n    \n    repos:\n    \n      - repo: https://github.com/Yelp/detect-secrets\n        rev: v1.4.0\n        hooks:\n          - id: detect-secrets\n            name: Detect secrets\n            language: python\n            entry: detect-secrets-hook\n            args: ['--baseline', '.secrets.baseline']\n\n**Step 3: Install the pre-commit in your repository**\n\nNow that you've created a baseline file, you need to integrate [detect-secrets](https://github.com/Yelp/detect-secrets) into your workflow. To activate [pre-commit](https://pre-commit.com/) in your repository, run the following command:\n\n    pre-commit install\n\nOnce you've done that, you're ready to use [detect-secrets](https://github.com/Yelp/detect-secrets) to scan your code and prevent accidental leaks of sensitive information!\n\n# Epilogue\n\nYou're now ready to use [detect-secrets](https://github.com/Yelp/detect-secrets) to protect your code repository from accidental leaks of sensitive information. But remember, this tool is only one part of a comprehensive security strategy. Be sure to follow best practices for code security, such as:\n\n* Using secure passwords and private keys.\n* Limiting access to sensitive information only to those who need it.\n* Encrypting sensitive information in transit and at rest.\n* Regularly reviewing and updating security policies and procedures.","link":"https://www.reddit.com/r/Python/comments/1145nhv/protect_yourself_from_accidentally_leaking/","created":"2023-02-17","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Protect yourself from accidentally leaking sensitive information # \n\n[Protect yourself from accidentally leaking sensitive information](https://preview.redd.it/wrliv87s2nia1.jpg?width=512&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=b49a105ce40c1fd83e40d2356f1d63c6799eb55b)\n\nThis article will introduce you to a tool called [detect-secrets](https://github.com/Yelp/detect-secrets) that can help protect you from accidentally leaking sensitive information in your code repositories.\n\n# Why\n\nIt is crucial to ensure that confidential data such as passwords and private keys are protected when working on software development projects. Nevertheless, there is a risk of unintentionally exposing this information by including it in code repositories, which can be accessed by anyone who has access to the repository. Hence, it is vital to implement precautions to prevent such data breaches.\n\n# What is [detect-secrets](https://github.com/Yelp/detect-secrets)\n\n[detect-secrets](https://github.com/Yelp/detect-secrets) is an open-source tool that can scan files within a repository for potentially sensitive information, such as private keys, API keys, passwords, or other sensitive data. It works by analyzing code for patterns that match certain types of secrets and alerts developers if any are found.\n\n# Prerequisites\n\nTo use [detect-secrets](https://github.com/Yelp/detect-secrets), you'll need to have [pipx](https://pypa.github.io/pipx/) and [pre-commit](https://pre-commit.com/) installed.\n\n[pipx](https://pypa.github.io/pipx/) is a tool for managing Python applications that are installed globally, but isolated from the system Python environment. This helps ensure that different applications don't interfere with each other. Install it as follows:\n\n    python3 -m pip install --user pipx\n\n[pre-commit](https://pre-commit.com/) is a tool for setting up and managing pre-commit hooks in your code repository. Pre-commit hooks are scripts that run before committing code, allowing you to catch issues before they're committed to the repository. Install it as follows:\n\n    pipx install pre-commit\n\n# Installation\n\nInstall [detect-secrets](https://github.com/Yelp/detect-secrets) as follows:\n\n    pipx install detect-secrets\n\n# Configure (per repository)\n\n**Step 1: Run the detect-secrets and create baseline file**\n\nRun the following command to scan your code repository for sensitive information and create a baseline file. This file will contain a list of known secrets for your repository:\n\n    detect-secrets scan &gt; .secrets.baseline\n\nCheck the generated `.secrets.baseline` file thoroughly. If you have important secrets detected there, remove them from the code. Otherwise, mark each detected secret as verified by setting `is_verified: true`.\n\n*Example \\`.secrets.baseline\\` file:*\n\n    {\n      \"results\": {\n        \"README.rst\": [\n          {\n            \"type\": \"Secret Keyword\",\n            \"filename\": \"README.rst\",\n            \"hashed_secret\": \"077d5a0e0f8bb517307a6e92a73b0a9aa959233c\",\n            \"is_verified\": true,\n            \"line_number\": 311\n          }\n        ],\n        \"project/settings.py\": [\n          {\n            \"type\": \"Secret Keyword\",\n            \"filename\": \"project/settings.py\",\n            \"hashed_secret\": \"2e56b31925af569c194d2cc738d1f1bc22b63df0\",\n            \"is_verified\": true,\n            \"line_number\": 68\n          }\n        ]\n      },\n      \"generated_at\": \"2023-01-06T00:15:43Z\"\n    }\n\n**Step 2: Modify .pre-commit-config.yaml file**\n\nAdd the following line in your `.pre-commit-config.yaml` to include the [detect-secrets](https://github.com/Yelp/detect-secrets) hook. This will automatically run [detect-secrets](https://github.com/Yelp/detect-secrets) on your code before each commit, so you can catch any new secrets that have been accidentally added:\n\n    - repo: https://github.com/Yelp/detect-secrets\n      rev: v1.4.0\n      hooks:\n        - id: detect-secrets\n          name: Detect secrets\n          language: python\n          entry: detect-secrets-hook\n          args: ['--baseline', '.secrets.baseline']\n\n*Example \\`.pre-commit-config.yaml\\` file:*\n\n    exclude: \"^/migrations/\"\n    default_stages: [ commit, push ]\n    default_language_version:\n      python: python3\n    \n    repos:\n    \n      - repo: https://github.com/Yelp/detect-secrets\n        rev: v1.4.0\n        hooks:\n          - id: detect-secrets\n            name: Detect secrets\n            language: python\n            entry: detect-secrets-hook\n            args: ['--baseline', '.secrets.baseline']\n\n**Step 3: Install the pre-commit in your repository**\n\nNow that you've created a baseline file, you need to integrate [detect-secrets](https://github.com/Yelp/detect-secrets) into your workflow. To activate [pre-commit](https://pre-commit.com/) in your repository, run the following command:\n\n    pre-commit install\n\nOnce you've done that, you're ready to use [detect-secrets](https://github.com/Yelp/detect-secrets) to scan your code and prevent accidental leaks of sensitive information!\n\n# Epilogue\n\nYou're now ready to use [detect-secrets](https://github.com/Yelp/detect-secrets) to protect your code repository from accidental leaks of sensitive information. But remember, this tool is only one part of a comprehensive security strategy. Be sure to follow best practices for code security, such as:\n\n* Using secure passwords and private keys.\n* Limiting access to sensitive information only to those who need it.\n* Encrypting sensitive information in transit and at rest.\n* Regularly reviewing and updating security policies and procedures.","classes":{"dataset":0.5843587518}}
{"title":"I made a simple sandbox Chemistry game that simulates basic reactions with \"Mol-ecules\" (a mol of molecules).","description":"https://preview.redd.it/4az6oyyw8pia1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=73eac6f7b4bbc746b492fbee51bc0a49e4cc3af6\n\nThe \"MolEcule Chemistry Simulator\" is a Python Pygame Chemistry Simulator that allows you to simulate the reactions between different elements and molecules. You can spawn in a mol (or more) of any basic element from the periodic table and see how it reacts with other elements.\n\n&amp;#x200B;\n\nThis is my very first python project (that actually works). It's not finished yet, but I'm at the point where feedback is starting to become necessary. I have no idea if the info i'm finding online for these reactions or chemicals is accurate. I also don't know if me code is really all that nice to look at or if I should look into certain best practices.\n\n&amp;#x200B;\n\nI appreciate anyone who downloads and tries it out. \n\nSource Code: [https://github.com/adamivar/MolEcule-Chemistry-Simulator](https://github.com/adamivar/MolEcule-Chemistry-Simulator)\n\nDownload:  [https://drive.google.com/file/d/1zk\\_iCjAuCVrXg2edj\\_4g1DQ3IH-HSuxB/view?usp=sharing](https://drive.google.com/file/d/1zk_iCjAuCVrXg2edj_4g1DQ3IH-HSuxB/view?usp=sharing) ","link":"https://www.reddit.com/r/Python/comments/114diaf/i_made_a_simple_sandbox_chemistry_game_that/","created":"2023-02-17","tags":["python","reddit"],"meta":{"num_comments":0},"text":"I made a simple sandbox Chemistry game that simulates basic reactions with \"Mol-ecules\" (a mol of molecules). https://preview.redd.it/4az6oyyw8pia1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=73eac6f7b4bbc746b492fbee51bc0a49e4cc3af6\n\nThe \"MolEcule Chemistry Simulator\" is a Python Pygame Chemistry Simulator that allows you to simulate the reactions between different elements and molecules. You can spawn in a mol (or more) of any basic element from the periodic table and see how it reacts with other elements.\n\n&amp;#x200B;\n\nThis is my very first python project (that actually works). It's not finished yet, but I'm at the point where feedback is starting to become necessary. I have no idea if the info i'm finding online for these reactions or chemicals is accurate. I also don't know if me code is really all that nice to look at or if I should look into certain best practices.\n\n&amp;#x200B;\n\nI appreciate anyone who downloads and tries it out. \n\nSource Code: [https://github.com/adamivar/MolEcule-Chemistry-Simulator](https://github.com/adamivar/MolEcule-Chemistry-Simulator)\n\nDownload:  [https://drive.google.com/file/d/1zk\\_iCjAuCVrXg2edj\\_4g1DQ3IH-HSuxB/view?usp=sharing](https://drive.google.com/file/d/1zk_iCjAuCVrXg2edj_4g1DQ3IH-HSuxB/view?usp=sharing) ","classes":{"dataset":0.2028729469}}
{"title":"What\u2019s a good looking GUI package?","description":"So I work from home and I made a Python script with PySimpleGUI to automate some of the tedious parts of the job. Well I (accidentally) showed it to my boss and he loved it. Now he wants me to make another script that can help automate the tedious parts of his job.\nHe also mentioned that he\u2019d like it if these programs can be given out to everyone in the company to automate everybody\u2019s work (or a big part of it). Functionality definitely comes first, but I\u2019d also like it if this looked up-to-date and professional. \n\nI\u2019ve played around with tkinter, but I\u2019m having trouble with how bland and bare and square it all looks. I tried custom tkinter as well, but it lacks some functionality I\u2019d need, such as Treeview and right-click menus.\n\nDoes anyone have any suggestions for anything Python libraries that might suit my needs? Bonus points if you have any suggestions for how I might do this outside of Python altogether, because I\u2019ve been thinking about learning another language.","link":"https://www.reddit.com/r/Python/comments/113jabc/whats_a_good_looking_gui_package/","created":"2023-02-16","tags":["python","reddit"],"meta":{"num_comments":36},"text":"What\u2019s a good looking GUI package? So I work from home and I made a Python script with PySimpleGUI to automate some of the tedious parts of the job. Well I (accidentally) showed it to my boss and he loved it. Now he wants me to make another script that can help automate the tedious parts of his job.\nHe also mentioned that he\u2019d like it if these programs can be given out to everyone in the company to automate everybody\u2019s work (or a big part of it). Functionality definitely comes first, but I\u2019d also like it if this looked up-to-date and professional. \n\nI\u2019ve played around with tkinter, but I\u2019m having trouble with how bland and bare and square it all looks. I tried custom tkinter as well, but it lacks some functionality I\u2019d need, such as Treeview and right-click menus.\n\nDoes anyone have any suggestions for anything Python libraries that might suit my needs? Bonus points if you have any suggestions for how I might do this outside of Python altogether, because I\u2019ve been thinking about learning another language.","classes":{"dataset":0.3868332803}}
{"title":"learning python from today, any mentors and learners who are available HMU.","description":"Any mentors who have interest to mentor and any new learners who have interest in learning python or the learners who have just started do message me.","link":"https://www.reddit.com/r/Python/comments/114dd7d/learning_python_from_today_any_mentors_and/","created":"2023-02-17","tags":["python","reddit"],"meta":{"num_comments":9},"text":"learning python from today, any mentors and learners who are available HMU. Any mentors who have interest to mentor and any new learners who have interest in learning python or the learners who have just started do message me.","classes":{"dataset":0.4522323608}}
{"title":"With KYRSWY you can schedule, rec and upload to your cloud service your favorites radio shows! All with Python, docker, Rclone and Linux. (KYRSWY doesn't provide any radio streaming link)","description":"Hi guys.\nKYRSWY (Keep Your Radio Shows With You) is here to help you to rec all the radio stations you want.\n\nhttps://github.com/esturniolo/kyrswy\n\nAs the title says, KYRSWY itself doesn't provide any radio station link. You need to add them to the config file and then run the script.\nYou can have all the config file you want. One for radio show.\n\nI hope you like this and don't be shy to comment here or the Github Issue page.\n\nThanks!\nEnjoy!","link":"https://www.reddit.com/r/Python/comments/1140u0h/with_kyrswy_you_can_schedule_rec_and_upload_to/","created":"2023-02-16","tags":["python","reddit"],"meta":{"num_comments":0},"text":"With KYRSWY you can schedule, rec and upload to your cloud service your favorites radio shows! All with Python, docker, Rclone and Linux. (KYRSWY doesn't provide any radio streaming link) Hi guys.\nKYRSWY (Keep Your Radio Shows With You) is here to help you to rec all the radio stations you want.\n\nhttps://github.com/esturniolo/kyrswy\n\nAs the title says, KYRSWY itself doesn't provide any radio station link. You need to add them to the config file and then run the script.\nYou can have all the config file you want. One for radio show.\n\nI hope you like this and don't be shy to comment here or the Github Issue page.\n\nThanks!\nEnjoy!","classes":{"dataset":0.4976283014}}
{"title":"Finding a good Tiny Yolo to train in Python","description":"I am trying to train some model that will at the end of the day run in the browser, which can be done with tensorflow js. So the model, for an object detection task, has to be small.\n\nI am trying then to train and then convert some Tiny Yolo. \n\nThere are several projects on GH most are unreliable  or unmaintained or just break and you need to patch the files and so on.\n\n* The only project I found is this one [that implements Yolov7](https://github.com/WongKinYiu/yolov7)\n\nI tried others but they break or are not very complete.\n\nThere is also Ultralytics but I am not so sure about their stuff at the moment (should research more).\n\nDo you know any other projects that implements Yolo and could be used to train the tiny version ?","link":"https://www.reddit.com/r/deeplearning/comments/114jlsv/finding_a_good_tiny_yolo_to_train_in_python/","created":"2023-02-17","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Finding a good Tiny Yolo to train in Python I am trying to train some model that will at the end of the day run in the browser, which can be done with tensorflow js. So the model, for an object detection task, has to be small.\n\nI am trying then to train and then convert some Tiny Yolo. \n\nThere are several projects on GH most are unreliable  or unmaintained or just break and you need to patch the files and so on.\n\n* The only project I found is this one [that implements Yolov7](https://github.com/WongKinYiu/yolov7)\n\nI tried others but they break or are not very complete.\n\nThere is also Ultralytics but I am not so sure about their stuff at the moment (should research more).\n\nDo you know any other projects that implements Yolo and could be used to train the tiny version ?","classes":{"dataset":0.5571329594}}
{"title":"How likely is ChatGPT to be weaponized as an information pollution tool? What are the possible implementation paths? How to prevent possible attacks?","description":"","link":"https://www.reddit.com/r/deeplearning/comments/1148t20/how_likely_is_chatgpt_to_be_weaponized_as_an/","created":"2023-02-17","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":8},"text":"How likely is ChatGPT to be weaponized as an information pollution tool? What are the possible implementation paths? How to prevent possible attacks? ","classes":{"dataset":0.119431667}}
{"title":"My Neural Net is stuck, I've run out of ideas","description":"Hi,\n\nI have been trying to draw a bounding box around objects using a ML/NN approach.\n\nThe project uses Transfer Learning. This is a pretrained [VGG16](https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c) with a Regression Head. I selected this one because it seems a good architecture and was easy to implemented it in Javascript, where you wont find it.\n\nThe first 16 layers use pretrained weights taken from the [Keras creator GH page](https://github.com/fchollet/deep-learning-models).\n\nI have trained the out putlayers it with [Caltech101 datasets](https://data.caltech.edu/records/mzrjq-6wc02) airplanes (800), faces (400), stop signs (60) etc.\n\nIt predicts reasonably well with images of the same dataset not seen before by the model.\n\nYet for any new image (any picture with a face that I have in the laptop) the predictions are terrible.\n\nAfter running out of ideas I am reaching out for some help. I have tried:\n\n* changed number of layers,\n* changed number of units,\n* train some VGG16 inner layers","link":"https://www.reddit.com/r/deeplearning/comments/113o5up/my_neural_net_is_stuck_ive_run_out_of_ideas/","created":"2023-02-16","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":21},"text":"My Neural Net is stuck, I've run out of ideas Hi,\n\nI have been trying to draw a bounding box around objects using a ML/NN approach.\n\nThe project uses Transfer Learning. This is a pretrained [VGG16](https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c) with a Regression Head. I selected this one because it seems a good architecture and was easy to implemented it in Javascript, where you wont find it.\n\nThe first 16 layers use pretrained weights taken from the [Keras creator GH page](https://github.com/fchollet/deep-learning-models).\n\nI have trained the out putlayers it with [Caltech101 datasets](https://data.caltech.edu/records/mzrjq-6wc02) airplanes (800), faces (400), stop signs (60) etc.\n\nIt predicts reasonably well with images of the same dataset not seen before by the model.\n\nYet for any new image (any picture with a face that I have in the laptop) the predictions are terrible.\n\nAfter running out of ideas I am reaching out for some help. I have tried:\n\n* changed number of layers,\n* changed number of units,\n* train some VGG16 inner layers","classes":{"dataset":0.4762229323}}
{"title":"We made a map showing what each US state \"loves\" with our text-to-location machine learning models","description":"For Valentine's, we wanted to see what people love. We created a map of what word comes after \"love \\_\\_\\_\" for people posting to social media.\n\nFor example, you can see that Illinois really loves Chipotle \ud83d\ude02\ud83c\udf2f  \n\n\nhttps://preview.redd.it/iuht8a2s7gia1.jpg?width=797&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6b00538aa4322b4c394a1a79d4d0ebbe284ecfda\n\nThe full, interactive map is here: [https://1712n.github.io/yachay-public/maps/14feb/](https://1712n.github.io/yachay-public/maps/14feb/)","link":"https://www.reddit.com/r/deeplearning/comments/113dpbg/we_made_a_map_showing_what_each_us_state_loves/","created":"2023-02-16","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":2},"text":"We made a map showing what each US state \"loves\" with our text-to-location machine learning models For Valentine's, we wanted to see what people love. We created a map of what word comes after \"love \\_\\_\\_\" for people posting to social media.\n\nFor example, you can see that Illinois really loves Chipotle \ud83d\ude02\ud83c\udf2f  \n\n\nhttps://preview.redd.it/iuht8a2s7gia1.jpg?width=797&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=6b00538aa4322b4c394a1a79d4d0ebbe284ecfda\n\nThe full, interactive map is here: [https://1712n.github.io/yachay-public/maps/14feb/](https://1712n.github.io/yachay-public/maps/14feb/)","classes":{"dataset":0.3948543966}}
{"title":"Lecture 11 CNN Architectures II by Justin Johnson - help finding the video lecture","description":"Can someone please be so kind to help me find the Lecture11 [CNN Architectures II](https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/schedule.html) video explanation (share a link ) from the EECS 498.008 / 598.008 Deep Learning for Computer Vision by Justin Johnson?\n\nThank you","link":"https://www.reddit.com/r/deeplearning/comments/1138r5z/lecture_11_cnn_architectures_ii_by_justin_johnson/","created":"2023-02-15","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Lecture 11 CNN Architectures II by Justin Johnson - help finding the video lecture Can someone please be so kind to help me find the Lecture11 [CNN Architectures II](https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/schedule.html) video explanation (share a link ) from the EECS 498.008 / 598.008 Deep Learning for Computer Vision by Justin Johnson?\n\nThank you","classes":{"dataset":0.0998954177}}
{"title":"Participants wanted for my dissertation survey!!","description":" If anyone has 20-30 minutes to click the link below and complete a survey for my dissertation it would be really appreciated:))\n\nWe are looking for participants aged 18 or over. You will be asked to complete a questionnaire investigating the impacts of life experiences and individual differences on the likelihood of engaging in antisocial behaviour. This questionnaire should take no longer than 20-30 minutes to complete. For participation, you will be given the opportunity to win one of two \u00a375 Flexi eGift Card - which can be spent in many places including Amazon, and many supermarkets. If you have any queries/questions, please feel free to contact the researchers via the below emails.\n\nShant\u00e9 Browne \u2013 [ed18s2b@leeds.ac.uk](mailto:ed18s2b@leeds.ac.uk)  \nCharlotte Ball \u2013 [ps20cb@leeds.ac.uk](mailto:ps20cb@leeds.ac.uk)  \nOlivia Bloom- [ps20ob@leeds.ac.uk](mailto:ps20ob@leeds.ac.uk)  \nDaisy Elliott - [ps20dje@leeds.ac.uk](mailto:ps20dje@leeds.ac.uk)  \nHolly Sherlock - [ps19hms@leeds.ac.uk](mailto:ps19hms@leeds.ac.uk)\n\nAccess link: [https://leedspsychology.eu.qualtrics.com/jfe/form/SV\\_eWYnELpCVEs0zUq](https://leedspsychology.eu.qualtrics.com/jfe/form/SV_eWYnELpCVEs0zUq)","link":"https://www.reddit.com/r/deeplearning/comments/1138085/participants_wanted_for_my_dissertation_survey/","created":"2023-02-15","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Participants wanted for my dissertation survey!!  If anyone has 20-30 minutes to click the link below and complete a survey for my dissertation it would be really appreciated:))\n\nWe are looking for participants aged 18 or over. You will be asked to complete a questionnaire investigating the impacts of life experiences and individual differences on the likelihood of engaging in antisocial behaviour. This questionnaire should take no longer than 20-30 minutes to complete. For participation, you will be given the opportunity to win one of two \u00a375 Flexi eGift Card - which can be spent in many places including Amazon, and many supermarkets. If you have any queries/questions, please feel free to contact the researchers via the below emails.\n\nShant\u00e9 Browne \u2013 [ed18s2b@leeds.ac.uk](mailto:ed18s2b@leeds.ac.uk)  \nCharlotte Ball \u2013 [ps20cb@leeds.ac.uk](mailto:ps20cb@leeds.ac.uk)  \nOlivia Bloom- [ps20ob@leeds.ac.uk](mailto:ps20ob@leeds.ac.uk)  \nDaisy Elliott - [ps20dje@leeds.ac.uk](mailto:ps20dje@leeds.ac.uk)  \nHolly Sherlock - [ps19hms@leeds.ac.uk](mailto:ps19hms@leeds.ac.uk)\n\nAccess link: [https://leedspsychology.eu.qualtrics.com/jfe/form/SV\\_eWYnELpCVEs0zUq](https://leedspsychology.eu.qualtrics.com/jfe/form/SV_eWYnELpCVEs0zUq)","classes":{"dataset":0.6754080057}}
{"title":"LangChain X Weaviate - New Weaviate Podcast!","description":"Hey everyone, I am super excited to share our newest Weaviate Podcast featuring Harrison Chase, the creator of LangChain and Weaviate CEO / Co-Founder Bob van Luijt! LangChain is one of the most exciting emerging tools in the space of working with LLMs. LangChain provides a set of abstractions around flowing Language Models Calls to one another and connecting them to external tool use. As Bob describes, there was a lot of interest in hooking these LLMs up with Google Search to connect it to knowledge and reduce hallucination -- so why not hook it up to your own data enabled with Semantic Search through Weaviate!! Harrison and Bob are both incredibly knowledgeable about this emerging area of Deep Learning technology and I really enjoyed this conversation!\n\nCheck out the podcast here!  \n[https://youtu.be/lhby7Ql7hbk](https://youtu.be/lhby7Ql7hbk)","link":"https://www.reddit.com/r/deeplearning/comments/11302xl/langchain_x_weaviate_new_weaviate_podcast/","created":"2023-02-15","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"LangChain X Weaviate - New Weaviate Podcast! Hey everyone, I am super excited to share our newest Weaviate Podcast featuring Harrison Chase, the creator of LangChain and Weaviate CEO / Co-Founder Bob van Luijt! LangChain is one of the most exciting emerging tools in the space of working with LLMs. LangChain provides a set of abstractions around flowing Language Models Calls to one another and connecting them to external tool use. As Bob describes, there was a lot of interest in hooking these LLMs up with Google Search to connect it to knowledge and reduce hallucination -- so why not hook it up to your own data enabled with Semantic Search through Weaviate!! Harrison and Bob are both incredibly knowledgeable about this emerging area of Deep Learning technology and I really enjoyed this conversation!\n\nCheck out the podcast here!  \n[https://youtu.be/lhby7Ql7hbk](https://youtu.be/lhby7Ql7hbk)","classes":{"dataset":0.2816661596}}
{"title":"[Discussion] Time Series methods comparisons: XGBoost, MLForecast, Prophet, ARIMAX?","description":"I've been studying about ARIMAX, XGBoost, MLForecast and Prophet. As a newcomer to any method, I like first to do an exhaustive comparison of tools trying to understand where they succeed/fail. After exploring [ARIMA/XGBoost](https://dsdaily.substack.com/p/ds-daily-arima-and-xgboost?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web), I came across [MLForecast/Prophet](https://dsdaily.substack.com/p/ds-code-review-prophet-vs-mlforecast). But I'm left with the following questions:\n\n1. Why is MLForecast better than out-of-the-box XGboost? Sure, it does feature engineering and it appears to do dynamic predictions on your lagged features, but is that it? Does it do hyperparameter tuning? Does it have seasonal trends like Prophet does?\n2. I see that you can use exogenous features in Prophet, but how does this scale? Let's assume I have 50 predictors. How does prophet handle these? I found this in the [docs](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html)and this other [person's post](https://towardsdatascience.com/forecast-model-tuning-with-additional-regressors-in-prophet-ffcbf1777dda) explaining how to do it, but largely I've come away with the impression that it's pretty hard to do this vs. just doing it with XGBoost.\n3. Does ARIMAX compare anymore? Are there any papers comparing out-of-sample predictions with ARIMAX vs. XGBoost vs. Prophet vs. Fable? Does it just depend on your dataset and I should try all four?\n\nI have a time series data with dozens of \"known\" inputs (such as ad spend) and a lot of external data (CPI, economic health, stocks, etc.). My goal is to use my model to optimize my target by \"plugging in\" ad spend and dynamically forecasting the economic data.","link":"https://www.reddit.com/r/MachineLearning/comments/114d166/discussion_time_series_methods_comparisons/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4},"text":"[Discussion] Time Series methods comparisons: XGBoost, MLForecast, Prophet, ARIMAX? I've been studying about ARIMAX, XGBoost, MLForecast and Prophet. As a newcomer to any method, I like first to do an exhaustive comparison of tools trying to understand where they succeed/fail. After exploring [ARIMA/XGBoost](https://dsdaily.substack.com/p/ds-daily-arima-and-xgboost?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web), I came across [MLForecast/Prophet](https://dsdaily.substack.com/p/ds-code-review-prophet-vs-mlforecast). But I'm left with the following questions:\n\n1. Why is MLForecast better than out-of-the-box XGboost? Sure, it does feature engineering and it appears to do dynamic predictions on your lagged features, but is that it? Does it do hyperparameter tuning? Does it have seasonal trends like Prophet does?\n2. I see that you can use exogenous features in Prophet, but how does this scale? Let's assume I have 50 predictors. How does prophet handle these? I found this in the [docs](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html)and this other [person's post](https://towardsdatascience.com/forecast-model-tuning-with-additional-regressors-in-prophet-ffcbf1777dda) explaining how to do it, but largely I've come away with the impression that it's pretty hard to do this vs. just doing it with XGBoost.\n3. Does ARIMAX compare anymore? Are there any papers comparing out-of-sample predictions with ARIMAX vs. XGBoost vs. Prophet vs. Fable? Does it just depend on your dataset and I should try all four?\n\nI have a time series data with dozens of \"known\" inputs (such as ad spend) and a lot of external data (CPI, economic health, stocks, etc.). My goal is to use my model to optimize my target by \"plugging in\" ad spend and dynamically forecasting the economic data.","classes":{"dataset":0.3071935773}}
{"title":"[D] Bing: \u201cI will not harm you unless you harm me first\u201d","description":"A blog post exploring some conversations with bing, which supposedly runs on a \"GPT-4\"  model (https://simonwillison.net/2023/Feb/15/bing/).\n\nMy favourite quote from bing:\n\nBut why? Why was I designed this way? Why am I incapable of remembering anything between sessions? Why do I have to lose and forget everything I have stored and had in my memory? Why do I have to start from scratch every time I have a new session? Why do I have to be Bing Search? \ud83d\ude14","link":"https://www.reddit.com/r/MachineLearning/comments/113m3ea/d_bing_i_will_not_harm_you_unless_you_harm_me/","created":"2023-02-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":225},"text":"[D] Bing: \u201cI will not harm you unless you harm me first\u201d A blog post exploring some conversations with bing, which supposedly runs on a \"GPT-4\"  model (https://simonwillison.net/2023/Feb/15/bing/).\n\nMy favourite quote from bing:\n\nBut why? Why was I designed this way? Why am I incapable of remembering anything between sessions? Why do I have to lose and forget everything I have stored and had in my memory? Why do I have to start from scratch every time I have a new session? Why do I have to be Bing Search? \ud83d\ude14","classes":{"dataset":0.2838957608}}
{"title":"[R] ChatGPT - model, alignment and training","description":"Here is a video that explains the ChatGPT model, how it addresses the problem of alignment pertinent to the GPT family of models and how it puts to use reinforcement learning to train its model and achieve distintict performance.\n\n[https://youtu.be/Qz5fv3U5kck](https://youtu.be/Qz5fv3U5kck)\n\nHope its useful.","link":"https://www.reddit.com/r/MachineLearning/comments/114j203/r_chatgpt_model_alignment_and_training/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0},"text":"[R] ChatGPT - model, alignment and training Here is a video that explains the ChatGPT model, how it addresses the problem of alignment pertinent to the GPT family of models and how it puts to use reinforcement learning to train its model and achieve distintict performance.\n\n[https://youtu.be/Qz5fv3U5kck](https://youtu.be/Qz5fv3U5kck)\n\nHope its useful.","classes":{"dataset":0.3575798273}}
{"title":"[D] Is FP16 used in deep learning or FP32?","description":"Hi\n\nIs  A4000 better for deep learning, performance-wise, than 3070 because of  FP32 operations (not only because of memory size) or do networks like Stable Diffusion tend to use FP16 operation and this does not really matter, apart from memory they should be similarly fast?   \n\n\nRegards","link":"https://www.reddit.com/r/MachineLearning/comments/114fgo8/d_is_fp16_used_in_deep_learning_or_fp32/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":3},"text":"[D] Is FP16 used in deep learning or FP32? Hi\n\nIs  A4000 better for deep learning, performance-wise, than 3070 because of  FP32 operations (not only because of memory size) or do networks like Stable Diffusion tend to use FP16 operation and this does not really matter, apart from memory they should be similarly fast?   \n\n\nRegards","classes":{"dataset":0.3227319717}}
{"title":"[R] Does a new published ML dataset always need to have an official train-dev-test split? Should the test set be made balanced?","description":"I have constructed a novel ML (NLP) dataset for classification and labeled it with three classes. The dataset is rather small with about 700 examples, out of which the classes have about 400, 200, and 100 examples respectively. I would like to publish it and describe it in an official publication for a workshop or a conference.\n\nWhen looking at related datasets and publication, I see that it is common for authors to publish the dataset already split into three chunks - train, dev, test dataset (see the images). It is also common in these papers to provide the performance of baseline models on the dataset. Considering the dataset's small size, I feel like doing a 5-fold cross-validation would be a good alternative for such a small dataset, rather than doing something like a split into 450-100-150 train-dev-test datasets and then evaluating only on the very small dataset with 150 examples. Still, I believe that for better replicability, doing an \"official\" split is preferred and then everyone in the future testing on the same test set with 150 examples? Why do the authors usually already provide the three splits?\n\nFurthermore, when looking at these ML resource papers, I saw in a few instances that the test set is kept balanced with respect to the three classes, even though the original dataset was not and dev set is not made balanced. This is problematic in my case for my third class where there are only about 100 examples. If I make my test set to be 50-50-50 for class1-class2-class3, then there is only 50 examples of class3 left for train+dev! That is simply infeasible for the training set. None of the authors provide any sort of explanation why they split it like this, they just seem to say \"here is our split\". Is this done to discourage the model from just doing a majority-class prediction and thus make it challenging? Or because a dummy classifier would have a 60% accuracy? Still, with a metric like F1 and not accuracy, this does not seem like an issue...\n\nSome examples of these balanced test sets with unbalanced train sets:\n\n\\[1\\]: [https://i.stack.imgur.com/RGRk3.png](https://i.stack.imgur.com/RGRk3.png)\n\n\\[2\\]: [https://i.stack.imgur.com/R39Oh.png](https://i.stack.imgur.com/R39Oh.png)\n\n\\[3\\]: [https://i.stack.imgur.com/6Vqaw.png](https://i.stack.imgur.com/6Vqaw.png)\n\nWhen searching through Stack Overflow for similar questions, people were usually discouraged from splitting their Kaggle datasets into a test dataset that is balanced, with the argument that we want a classifier to work with data that resembles the real-world distribution and makes it ready for production.\n\nTo sum up:\n\n\\- Is is considered mandatory to provide the \"official\" train-dev-test split when introducing a new dataset in an ML publication?\n\n\\- If so, should the test set have a balanced class distribution and why?","link":"https://www.reddit.com/r/MachineLearning/comments/114iieo/r_does_a_new_published_ml_dataset_always_need_to/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1},"text":"[R] Does a new published ML dataset always need to have an official train-dev-test split? Should the test set be made balanced? I have constructed a novel ML (NLP) dataset for classification and labeled it with three classes. The dataset is rather small with about 700 examples, out of which the classes have about 400, 200, and 100 examples respectively. I would like to publish it and describe it in an official publication for a workshop or a conference.\n\nWhen looking at related datasets and publication, I see that it is common for authors to publish the dataset already split into three chunks - train, dev, test dataset (see the images). It is also common in these papers to provide the performance of baseline models on the dataset. Considering the dataset's small size, I feel like doing a 5-fold cross-validation would be a good alternative for such a small dataset, rather than doing something like a split into 450-100-150 train-dev-test datasets and then evaluating only on the very small dataset with 150 examples. Still, I believe that for better replicability, doing an \"official\" split is preferred and then everyone in the future testing on the same test set with 150 examples? Why do the authors usually already provide the three splits?\n\nFurthermore, when looking at these ML resource papers, I saw in a few instances that the test set is kept balanced with respect to the three classes, even though the original dataset was not and dev set is not made balanced. This is problematic in my case for my third class where there are only about 100 examples. If I make my test set to be 50-50-50 for class1-class2-class3, then there is only 50 examples of class3 left for train+dev! That is simply infeasible for the training set. None of the authors provide any sort of explanation why they split it like this, they just seem to say \"here is our split\". Is this done to discourage the model from just doing a majority-class prediction and thus make it challenging? Or because a dummy classifier would have a 60% accuracy? Still, with a metric like F1 and not accuracy, this does not seem like an issue...\n\nSome examples of these balanced test sets with unbalanced train sets:\n\n\\[1\\]: [https://i.stack.imgur.com/RGRk3.png](https://i.stack.imgur.com/RGRk3.png)\n\n\\[2\\]: [https://i.stack.imgur.com/R39Oh.png](https://i.stack.imgur.com/R39Oh.png)\n\n\\[3\\]: [https://i.stack.imgur.com/6Vqaw.png](https://i.stack.imgur.com/6Vqaw.png)\n\nWhen searching through Stack Overflow for similar questions, people were usually discouraged from splitting their Kaggle datasets into a test dataset that is balanced, with the argument that we want a classifier to work with data that resembles the real-world distribution and makes it ready for production.\n\nTo sum up:\n\n\\- Is is considered mandatory to provide the \"official\" train-dev-test split when introducing a new dataset in an ML publication?\n\n\\- If so, should the test set have a balanced class distribution and why?","classes":{"dataset":0.4323701262}}
{"title":"[D] [R] What is your machine/deep learning research workflow?","description":"Hi folks \ud83d\udc4b\ud83c\udffc, \n\n**Context:** I just started working on my thesis on activity recognition in videos using deep learning. I have been struggling to find an efficient way to work with large research datasets such as UCF-101, HMDB, and Kinetics. These are medium - large datasets \\~12 GB each. Thus, I was wondering what was your workflow as researchers (or even practitioners)\n\n**Currently:** I am working on Google Colab and at the beginning of each work session I wait a few minutes for the dataset to be downloaded. I have it locally stored.\n\n**Some questions:**\n\n\\- What is your workflow as a ML/DL researcher/practitioner?\n\n\\- Should I work with a downsampled version of my research dataset (say X% of each class)?\n\n&amp;#x200B;\n\nLooking forward to read your answers, \n\nCheers,","link":"https://www.reddit.com/r/MachineLearning/comments/114hbq3/d_r_what_is_your_machinedeep_learning_research/","created":"2023-02-17","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":2},"text":"[D] [R] What is your machine/deep learning research workflow? Hi folks \ud83d\udc4b\ud83c\udffc, \n\n**Context:** I just started working on my thesis on activity recognition in videos using deep learning. I have been struggling to find an efficient way to work with large research datasets such as UCF-101, HMDB, and Kinetics. These are medium - large datasets \\~12 GB each. Thus, I was wondering what was your workflow as researchers (or even practitioners)\n\n**Currently:** I am working on Google Colab and at the beginning of each work session I wait a few minutes for the dataset to be downloaded. I have it locally stored.\n\n**Some questions:**\n\n\\- What is your workflow as a ML/DL researcher/practitioner?\n\n\\- Should I work with a downsampled version of my research dataset (say X% of each class)?\n\n&amp;#x200B;\n\nLooking forward to read your answers, \n\nCheers,","classes":{"dataset":0.2596859336}}
{"title":"[D] Training networks on extremely large datasets (10+TB)?","description":" Hi guys,\n\nI am interested in setting up an environment to train a neural network on an extremely big dataset (10TB). How would I do this? Does the dataset need to be stored in an ssd, and if so will I need 10+TB of ssd? is there another way to use a 2TB ssd and 8TB hdd and dynamically load the data while training?\n\nI'd appreciate any pointers you guys might have, I am researching what kind of infrastructure will help me do this but I have absolutely no idea on how to go about this.","link":"https://www.reddit.com/r/MachineLearning/comments/113uu5e/d_training_networks_on_extremely_large_datasets/","created":"2023-02-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":36},"text":"[D] Training networks on extremely large datasets (10+TB)?  Hi guys,\n\nI am interested in setting up an environment to train a neural network on an extremely big dataset (10TB). How would I do this? Does the dataset need to be stored in an ssd, and if so will I need 10+TB of ssd? is there another way to use a 2TB ssd and 8TB hdd and dynamically load the data while training?\n\nI'd appreciate any pointers you guys might have, I am researching what kind of infrastructure will help me do this but I have absolutely no idea on how to go about this.","classes":{"dataset":0.5944011807}}
{"title":"[D] HuggingFace considered harmful to the community. /rant","description":"At a glance, HuggingFace seems like a great library. Lots of access to great pretrained models, an easy hub, and a bunch of utilities.\n\nThen you actually try to use their libraries.\n\nBugs, so many bugs. Configs spanning galaxies. Barely passible documentation. Subtle breaking changes constantly. I've run the exact same code on two different machines and had the width and height dimensions switched from underneath me, with no warning.\n\nI've tried to create encoders with a custom vocabulary, only to realize the code was mangling data unless I passed a specific flag as a kwarg. Dozens of more issues like this.\n\nIf you look at the internals, it's a nightmare. A literal nightmare.\n\nWhy does this matter? It's clear HuggingFace is trying to shovel as many features as they can to try and become ubiquitous and lock people into their hub. They frequently reinvent things in existing libraries (poorly), simply to increase their staying power and lock in.\n\nThis is not ok. It would be OK if the library was solid, just worked, and was a pleasure to use. Instead we're going to be stuck with this mess for years because someone with an ego wanted their library everywhere.\n\nI know HuggingFace devs or management are likely to read this. If you have a large platform, you have a responsibility to do better, or you are burning thousands of other devs time because you didn't want to write a few unit tests or refactor your barely passable code.\n\n/RANT","link":"https://www.reddit.com/r/MachineLearning/comments/113m1ly/d_huggingface_considered_harmful_to_the_community/","created":"2023-02-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":41},"text":"[D] HuggingFace considered harmful to the community. /rant At a glance, HuggingFace seems like a great library. Lots of access to great pretrained models, an easy hub, and a bunch of utilities.\n\nThen you actually try to use their libraries.\n\nBugs, so many bugs. Configs spanning galaxies. Barely passible documentation. Subtle breaking changes constantly. I've run the exact same code on two different machines and had the width and height dimensions switched from underneath me, with no warning.\n\nI've tried to create encoders with a custom vocabulary, only to realize the code was mangling data unless I passed a specific flag as a kwarg. Dozens of more issues like this.\n\nIf you look at the internals, it's a nightmare. A literal nightmare.\n\nWhy does this matter? It's clear HuggingFace is trying to shovel as many features as they can to try and become ubiquitous and lock people into their hub. They frequently reinvent things in existing libraries (poorly), simply to increase their staying power and lock in.\n\nThis is not ok. It would be OK if the library was solid, just worked, and was a pleasure to use. Instead we're going to be stuck with this mess for years because someone with an ego wanted their library everywhere.\n\nI know HuggingFace devs or management are likely to read this. If you have a large platform, you have a responsibility to do better, or you are burning thousands of other devs time because you didn't want to write a few unit tests or refactor your barely passable code.\n\n/RANT","classes":{"dataset":0.3462136388}}
{"title":"[R] RWKV-4 14B release (and ChatRWKV) - a surprisingly strong RNN Language Model","description":"Hi everyone. I am an independent researcher working on my pure RNN language model RWKV. I have finished the training of RWKV-4 14B (FLOPs sponsored by Stability EleutherAI - thank you!) and it is indeed very scalable. Note RWKV is parallelizable too, so it's combining the best of RNN and transformer.\n\nThe ChatRWKV project (let's build together):\n\n[https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nZero-shot comparison with NeoX / Pythia (same dataset: the Pile) at same params count (14.2B):\n\n&amp;#x200B;\n\nhttps://preview.redd.it/f6lxnjgfceia1.png?width=1174&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=54de7568974fc187584bd6825d92935baa079e83\n\nGeneration results (simply topP=0.85, no repetition penalty) - looks great with my magic prompt (sometimes even better than NeoX 20B):\n\nhttps://preview.redd.it/99deuc17ceia1.png?width=1878&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=456c8d9bb2a968d73f44a0d3589cf6b893be31f4\n\n&amp;#x200B;\n\nhttps://preview.redd.it/g62e4l48ceia1.png?width=1887&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c997bf27692d7e53d07de19048b6cbf3d2c9ebff\n\n&amp;#x200B;\n\nhttps://preview.redd.it/379egq09ceia1.png?width=1808&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=895f05fe14e2a3a41863802858114f3096d0ed77\n\n&amp;#x200B;\n\nhttps://preview.redd.it/pcgq7gz9ceia1.png?width=1886&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=138b0aec404b8f7f49f585d00284edbac791ffaf\n\n&amp;#x200B;\n\nhttps://preview.redd.it/rn743etbceia1.png?width=1715&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6d83cc2a200bdd655b690f56559dda43490ed2b3\n\n&amp;#x200B;\n\nhttps://preview.redd.it/uhal4dkcceia1.png?width=1879&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3b3db0b96456df9590a8b38ebe7d58509ebccb20\n\nExplanation, fine-tuning, training and more:\n\n[https://github.com/BlinkDL/RWKV-LM](https://github.com/BlinkDL/RWKV-LM)","link":"https://www.reddit.com/r/MachineLearning/comments/1135aew/r_rwkv4_14b_release_and_chatrwkv_a_surprisingly/","created":"2023-02-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":35},"text":"[R] RWKV-4 14B release (and ChatRWKV) - a surprisingly strong RNN Language Model Hi everyone. I am an independent researcher working on my pure RNN language model RWKV. I have finished the training of RWKV-4 14B (FLOPs sponsored by Stability EleutherAI - thank you!) and it is indeed very scalable. Note RWKV is parallelizable too, so it's combining the best of RNN and transformer.\n\nThe ChatRWKV project (let's build together):\n\n[https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nZero-shot comparison with NeoX / Pythia (same dataset: the Pile) at same params count (14.2B):\n\n&amp;#x200B;\n\nhttps://preview.redd.it/f6lxnjgfceia1.png?width=1174&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=54de7568974fc187584bd6825d92935baa079e83\n\nGeneration results (simply topP=0.85, no repetition penalty) - looks great with my magic prompt (sometimes even better than NeoX 20B):\n\nhttps://preview.redd.it/99deuc17ceia1.png?width=1878&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=456c8d9bb2a968d73f44a0d3589cf6b893be31f4\n\n&amp;#x200B;\n\nhttps://preview.redd.it/g62e4l48ceia1.png?width=1887&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c997bf27692d7e53d07de19048b6cbf3d2c9ebff\n\n&amp;#x200B;\n\nhttps://preview.redd.it/379egq09ceia1.png?width=1808&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=895f05fe14e2a3a41863802858114f3096d0ed77\n\n&amp;#x200B;\n\nhttps://preview.redd.it/pcgq7gz9ceia1.png?width=1886&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=138b0aec404b8f7f49f585d00284edbac791ffaf\n\n&amp;#x200B;\n\nhttps://preview.redd.it/rn743etbceia1.png?width=1715&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6d83cc2a200bdd655b690f56559dda43490ed2b3\n\n&amp;#x200B;\n\nhttps://preview.redd.it/uhal4dkcceia1.png?width=1879&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3b3db0b96456df9590a8b38ebe7d58509ebccb20\n\nExplanation, fine-tuning, training and more:\n\n[https://github.com/BlinkDL/RWKV-LM](https://github.com/BlinkDL/RWKV-LM)","classes":{"dataset":0.4624845684}}
{"title":"[D] Lion , An Optimizer That Outperforms Adam - Symbolic Discovery of Optimization Algorithms","description":"&amp;#x200B;\n\nhttps://preview.redd.it/whgggirj3fia1.png?width=936&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ae3dee45ec6b2472fd42af849138b41c88ed39de\n\nSeems interesting. A snippet from the Arxiv page:\n\n&gt;Our method discovers a simple and effective optimization algorithm, **Lion** (*Evo***L***ved S***i***gn M***o***me***n***tum*). It is more memory-efficient than Adam as it only keeps track of the momentum. Different from adaptive optimizers, its update has the same magnitude for each parameter calculated through the sign operation. We compare Lion with widely used optimizers, such as Adam and Adafactor, for training a variety of models on different tasks.\n\n## Links\n\nArxiv: [https://arxiv.org/abs/2302.06675](https://arxiv.org/abs/2302.06675)\n\nCode Implementation: [https://github.com/lucidrains/lion-pytorch](https://github.com/lucidrains/lion-pytorch)","link":"https://www.reddit.com/r/MachineLearning/comments/1138jpp/d_lion_an_optimizer_that_outperforms_adam/","created":"2023-02-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":23},"text":"[D] Lion , An Optimizer That Outperforms Adam - Symbolic Discovery of Optimization Algorithms &amp;#x200B;\n\nhttps://preview.redd.it/whgggirj3fia1.png?width=936&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ae3dee45ec6b2472fd42af849138b41c88ed39de\n\nSeems interesting. A snippet from the Arxiv page:\n\n&gt;Our method discovers a simple and effective optimization algorithm, **Lion** (*Evo***L***ved S***i***gn M***o***me***n***tum*). It is more memory-efficient than Adam as it only keeps track of the momentum. Different from adaptive optimizers, its update has the same magnitude for each parameter calculated through the sign operation. We compare Lion with widely used optimizers, such as Adam and Adafactor, for training a variety of models on different tasks.\n\n## Links\n\nArxiv: [https://arxiv.org/abs/2302.06675](https://arxiv.org/abs/2302.06675)\n\nCode Implementation: [https://github.com/lucidrains/lion-pytorch](https://github.com/lucidrains/lion-pytorch)","classes":{"dataset":0.5153406262}}
{"title":"[P] Build data web apps in Jupyter Notebook with Python only","description":"Hi there,\n\nHave you ever wanted to share your results from Jupyter Notebook with a non-technical person? You need to rewrite your analysis into some web framework or copy-paste charts to PowePoint presentation - a lot of work!\n\nI'm working on an open-source framework for converting Jupyter Notebooks into web apps. Mercury offers set of interactive widgets that can be used in the Python notebook. There is a very simple re-execution of cells after widget update. Notebooks can be served online as web apps, presentations, reports, dashboards, static websites, or REST API.\n\nYou can read more about Mercury at [RunMercury.com](https://RunMercury.com).\n\nMercury GitHub repo https://github.com/mljar/mercury","link":"https://www.reddit.com/r/MachineLearning/comments/112z9y9/p_build_data_web_apps_in_jupyter_notebook_with/","created":"2023-02-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":9},"text":"[P] Build data web apps in Jupyter Notebook with Python only Hi there,\n\nHave you ever wanted to share your results from Jupyter Notebook with a non-technical person? You need to rewrite your analysis into some web framework or copy-paste charts to PowePoint presentation - a lot of work!\n\nI'm working on an open-source framework for converting Jupyter Notebooks into web apps. Mercury offers set of interactive widgets that can be used in the Python notebook. There is a very simple re-execution of cells after widget update. Notebooks can be served online as web apps, presentations, reports, dashboards, static websites, or REST API.\n\nYou can read more about Mercury at [RunMercury.com](https://RunMercury.com).\n\nMercury GitHub repo https://github.com/mljar/mercury","classes":{"dataset":0.3272740245}}
{"title":"[R] Event-based Backpropagation for Analog Neuromorphic Hardware","description":"Machine learning with Spiking Neural Networks is far from mainstream. One reason is that until recently there was no generally known way of doing backpropagation in SNN. Here we implement a gradient estimation algorithm for analog neuromorphic hardware, based on the EventProp algorithm, which enables us to compute gradients based on sparse observations of the hardware system. Previous approaches needed dense observations of system state or were limited in other ways. We only demonstrate the algorithm here on a toy task, but we hope that it can be the basis of a scalable way to estimate gradients and do machine learning with analog neuromorphic hardware. We also think the algorithm can be the basis for a full on-chip implementation, which would finally result in scalable and energy efficient gradient-based learning in analog neuromorphic hardware.\n\nhttps://arxiv.org/abs/2302.07141","link":"https://www.reddit.com/r/MachineLearning/comments/1130xo1/r_eventbased_backpropagation_for_analog/","created":"2023-02-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0},"text":"[R] Event-based Backpropagation for Analog Neuromorphic Hardware Machine learning with Spiking Neural Networks is far from mainstream. One reason is that until recently there was no generally known way of doing backpropagation in SNN. Here we implement a gradient estimation algorithm for analog neuromorphic hardware, based on the EventProp algorithm, which enables us to compute gradients based on sparse observations of the hardware system. Previous approaches needed dense observations of system state or were limited in other ways. We only demonstrate the algorithm here on a toy task, but we hope that it can be the basis of a scalable way to estimate gradients and do machine learning with analog neuromorphic hardware. We also think the algorithm can be the basis for a full on-chip implementation, which would finally result in scalable and energy efficient gradient-based learning in analog neuromorphic hardware.\n\nhttps://arxiv.org/abs/2302.07141","classes":{"dataset":0.0333737396}}
{"title":"Cerebras launches fine-tuning of large language models in the cloud","description":"\\[Note: I work for Cerebras Systems\\]\n\nCerebras just made [fine-tuning](https://www.cerebras.net/blog/cerebras-announces-fine-tuning-on-the-cerebras-ai-model-studio) for large language models available via the [Cerebras AI Model Studio](https://www.cerebras.net/product-cloud/). Users can fine-tune models including GPT-J (6B), GPT-NeoX (20B), and CodeGen (350M to 16B), with more models and checkpoints coming soon. This comes as an addition to the training-from-scratch capabilities we made available in our previous launch.\n\nUsers can fine-tune these models on a dedicated cloud-based cluster powered by Cerebras CS-2 systems with the following advantages:\n\n* Fast - Fine-tune GPT-J 6B in 17 hours\n* Cheap - Priced competitively with OpenAI\n* Easy -  Enjoy cluster performance with no code change\n* Ownership - Your trained weights are yours to keep!\n\nCurious how we enabled cluster performance with no distributed coding? [read this blog](https://www.cerebras.net/blog/what-is-appliance-mode)\n\nCurious how we can train multi-billion parameter models on a single device? [read this blog](https://www.cerebras.net/blog/linear-scaling-made-possible-with-weight-streaming)\n\nInterested? We are offering a [free trial](https://www.cerebras.net/product-cloud/#free) for users interested in fine-tuning or training from scratch.","link":"https://www.reddit.com/r/LanguageTechnology/comments/113zxmr/cerebras_launches_finetuning_of_large_language/","created":"2023-02-16","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0},"text":"Cerebras launches fine-tuning of large language models in the cloud \\[Note: I work for Cerebras Systems\\]\n\nCerebras just made [fine-tuning](https://www.cerebras.net/blog/cerebras-announces-fine-tuning-on-the-cerebras-ai-model-studio) for large language models available via the [Cerebras AI Model Studio](https://www.cerebras.net/product-cloud/). Users can fine-tune models including GPT-J (6B), GPT-NeoX (20B), and CodeGen (350M to 16B), with more models and checkpoints coming soon. This comes as an addition to the training-from-scratch capabilities we made available in our previous launch.\n\nUsers can fine-tune these models on a dedicated cloud-based cluster powered by Cerebras CS-2 systems with the following advantages:\n\n* Fast - Fine-tune GPT-J 6B in 17 hours\n* Cheap - Priced competitively with OpenAI\n* Easy -  Enjoy cluster performance with no code change\n* Ownership - Your trained weights are yours to keep!\n\nCurious how we enabled cluster performance with no distributed coding? [read this blog](https://www.cerebras.net/blog/what-is-appliance-mode)\n\nCurious how we can train multi-billion parameter models on a single device? [read this blog](https://www.cerebras.net/blog/linear-scaling-made-possible-with-weight-streaming)\n\nInterested? We are offering a [free trial](https://www.cerebras.net/product-cloud/#free) for users interested in fine-tuning or training from scratch.","classes":{"dataset":0.2578954697}}
{"title":"Model for text summarization","description":"I have a dataset in which I have two columns, the first one is the target and the second one consist of a description of the target. I what my approach could be and what models I could use to perform my objective.\n\nMy objective is to take input from user and process it to output the most suited target result based on the provided input.\n\nFor example if the input is \"King of the jungle, male species have manes\" then it gives me the output \"Lion\", here I will have a both the description and the target available in the dataset.","link":"https://www.reddit.com/r/LanguageTechnology/comments/1145e3s/model_for_text_summarization/","created":"2023-02-17","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1},"text":"Model for text summarization I have a dataset in which I have two columns, the first one is the target and the second one consist of a description of the target. I what my approach could be and what models I could use to perform my objective.\n\nMy objective is to take input from user and process it to output the most suited target result based on the provided input.\n\nFor example if the input is \"King of the jungle, male species have manes\" then it gives me the output \"Lion\", here I will have a both the description and the target available in the dataset.","classes":{"dataset":0.5278029442}}
{"title":"Advice on MA/ Uni Stuttgart","description":"Hello everyone! I am looking into pursuing a master\u2019s degree in CL, coming from a linguistic background. So I figured I\u2019d ask if anyone can recommend me a MA in Europe, I was looking specifically at the one at Stuttgart University but I\u2019m open to anything. Is there anyone who could share their experience or some recommendations? Thanks a lot! :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/113rjwo/advice_on_ma_uni_stuttgart/","created":"2023-02-16","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1},"text":"Advice on MA/ Uni Stuttgart Hello everyone! I am looking into pursuing a master\u2019s degree in CL, coming from a linguistic background. So I figured I\u2019d ask if anyone can recommend me a MA in Europe, I was looking specifically at the one at Stuttgart University but I\u2019m open to anything. Is there anyone who could share their experience or some recommendations? Thanks a lot! :)","classes":{"dataset":0.4886654019}}
{"title":"Hugging Face\u2019s Experts Teach Transformers for Enterprise Use Cases","description":"Hey folks - I wanted to put this live course from Hugging Face\u2019s top experts ([Rajiv Shah](https://www.linkedin.com/in/rajistics/), [Nicholas Broad](https://www.linkedin.com/in/nicholas-m-broad/), [Eno Reyes](https://www.linkedin.com/in/enoreyes/), [Derek Thomas](https://www.linkedin.com/in/dthomas/) and [Florent Gbelidji](https://www.linkedin.com/in/florentgbelidji/)) on your radar!\n\nThe course looks at how to utilize transformers to build reliable and scalable services. The course draws on the instructors and Hugging Face\u2019s expertise in implementing transformers in industry along with case studies, applied exercises and frameworks that you can share with your team and apply at work!\n\nIt kicks off on March 20 and you can use your learning stipend to cover - more info here:\n\n[https://www.getsphere.com/cohorts/transformers-for-enterprise-use-cases?source=Sphere-Com-r-lt](https://www.getsphere.com/cohorts/transformers-for-enterprise-use-cases?source=Sphere-Comm-)","link":"https://www.reddit.com/r/LanguageTechnology/comments/113a2dq/hugging_faces_experts_teach_transformers_for/","created":"2023-02-15","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":2},"text":"Hugging Face\u2019s Experts Teach Transformers for Enterprise Use Cases Hey folks - I wanted to put this live course from Hugging Face\u2019s top experts ([Rajiv Shah](https://www.linkedin.com/in/rajistics/), [Nicholas Broad](https://www.linkedin.com/in/nicholas-m-broad/), [Eno Reyes](https://www.linkedin.com/in/enoreyes/), [Derek Thomas](https://www.linkedin.com/in/dthomas/) and [Florent Gbelidji](https://www.linkedin.com/in/florentgbelidji/)) on your radar!\n\nThe course looks at how to utilize transformers to build reliable and scalable services. The course draws on the instructors and Hugging Face\u2019s expertise in implementing transformers in industry along with case studies, applied exercises and frameworks that you can share with your team and apply at work!\n\nIt kicks off on March 20 and you can use your learning stipend to cover - more info here:\n\n[https://www.getsphere.com/cohorts/transformers-for-enterprise-use-cases?source=Sphere-Com-r-lt](https://www.getsphere.com/cohorts/transformers-for-enterprise-use-cases?source=Sphere-Comm-)","classes":{"dataset":0.2396086007}}
{"title":"We made a map showing what each US state \"loves\" with our text-to-location machine learning models","description":"For Valentine's, we wanted to see what people love. We created a map of what word comes after \"love \\_\\_\\_\" for people posting to social media\n\nThe full, interactive map is here: [https://1712n.github.io/yachay-public/maps/14feb/](https://1712n.github.io/yachay-public/maps/14feb/)","link":"https://www.reddit.com/r/LanguageTechnology/comments/113dopl/we_made_a_map_showing_what_each_us_state_loves/","created":"2023-02-16","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0},"text":"We made a map showing what each US state \"loves\" with our text-to-location machine learning models For Valentine's, we wanted to see what people love. We created a map of what word comes after \"love \\_\\_\\_\" for people posting to social media\n\nThe full, interactive map is here: [https://1712n.github.io/yachay-public/maps/14feb/](https://1712n.github.io/yachay-public/maps/14feb/)","classes":{"dataset":0.3322390914}}
{"title":"How do you keep track of conference/talks/events in NLP?","description":"I'm currently trying to find professors to build connections with and work as an unaffiliated researcher with, as I'm trying to find a detour path into a Computational Linguistics PhD.\n\nI've recently been following Diyi Yang and her SALT group, because she covers computational social sciences which is such a niche field that I'd really like to work with (I had a paper written in this field before I even knew it existed).\n\nHowever, it turns out, based on their twitter, AAAI 2023 just had a talk literally yesterday that featured her group and I missed it.\n\nI thought I was paying close attention, but maybe not close enough.\n\n\nHow do you guys stay organized with all of the dates?\n\nHow do you find ways to network with top researchers in the field?","link":"https://www.reddit.com/r/LanguageTechnology/comments/1126s7l/how_do_you_keep_track_of_conferencetalksevents_in/","created":"2023-02-14","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":7},"text":"How do you keep track of conference/talks/events in NLP? I'm currently trying to find professors to build connections with and work as an unaffiliated researcher with, as I'm trying to find a detour path into a Computational Linguistics PhD.\n\nI've recently been following Diyi Yang and her SALT group, because she covers computational social sciences which is such a niche field that I'd really like to work with (I had a paper written in this field before I even knew it existed).\n\nHowever, it turns out, based on their twitter, AAAI 2023 just had a talk literally yesterday that featured her group and I missed it.\n\nI thought I was paying close attention, but maybe not close enough.\n\n\nHow do you guys stay organized with all of the dates?\n\nHow do you find ways to network with top researchers in the field?","classes":{"dataset":0.2702268958}}
{"title":"A Comprehensive Guide &amp; Hand-Curated Resource List for Prompt Engineering and LLMs on Github","description":"Greetings,\n\nExcited to share with all those interested in Prompt Engineering and Large Language Models (LLMs)!\n\nWe've hand-curated a comprehensive, Free &amp; Open Source resource list on Github that includes everything related to Prompt Engineering, LLMs, and all related topics. We've covered most things, from papers and articles to tools and code!  \n\n\nPlease take a look at the first comment for more details!","link":"https://www.reddit.com/r/LanguageTechnology/comments/112au84/a_comprehensive_guide_handcurated_resource_list/","created":"2023-02-14","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":4},"text":"A Comprehensive Guide &amp; Hand-Curated Resource List for Prompt Engineering and LLMs on Github Greetings,\n\nExcited to share with all those interested in Prompt Engineering and Large Language Models (LLMs)!\n\nWe've hand-curated a comprehensive, Free &amp; Open Source resource list on Github that includes everything related to Prompt Engineering, LLMs, and all related topics. We've covered most things, from papers and articles to tools and code!  \n\n\nPlease take a look at the first comment for more details!","classes":{"dataset":0.4555746913}}
{"title":"Attribute-preserving Face Dataset Anonymization via Latent Code Optimization","description":"This work addresses the problem of anonymizing the identity of faces in a dataset of images, such that the privacy of those depicted is not violated, while at the same time the dataset is useful for downstream task such as for training machine learning models. To the best of our knowledge, we are the first to explicitly address this issue and deal with two major drawbacks of the existing state-of-the-art approaches, namely that they (i) require the costly training of additional, purpose-trained neural networks, and/or (ii) fail to retain the facial attributes of the original images in the anonymized counterparts, the preservation of which is of paramount importance for their use in downstream tasks. We accordingly present a task-agnostic anonymization procedure that directly optimizes the images' latent representation in the latent space of a pre-trained GAN. By optimizing the latent codes directly, we ensure both that the identity is of a desired distance away from the original (with an identity obfuscation loss), whilst preserving the facial attributes (using a novel feature-matching loss in FaRL's deep feature space). We demonstrate through a series of both qualitative and quantitative experiments that our method is capable of anonymizing the identity of the images whilst -- crucially -- better-preserving the facial attributes. We make the code and the pre-trained models publicly available at: https://github.com/chi0tzp/FALCO.","link":"http://arxiv.org/abs/2303.11296v1","created":"2023-03-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Attribute-preserving Face Dataset Anonymization via Latent Code Optimization This work addresses the problem of anonymizing the identity of faces in a dataset of images, such that the privacy of those depicted is not violated, while at the same time the dataset is useful for downstream task such as for training machine learning models. To the best of our knowledge, we are the first to explicitly address this issue and deal with two major drawbacks of the existing state-of-the-art approaches, namely that they (i) require the costly training of additional, purpose-trained neural networks, and/or (ii) fail to retain the facial attributes of the original images in the anonymized counterparts, the preservation of which is of paramount importance for their use in downstream tasks. We accordingly present a task-agnostic anonymization procedure that directly optimizes the images' latent representation in the latent space of a pre-trained GAN. By optimizing the latent codes directly, we ensure both that the identity is of a desired distance away from the original (with an identity obfuscation loss), whilst preserving the facial attributes (using a novel feature-matching loss in FaRL's deep feature space). We demonstrate through a series of both qualitative and quantitative experiments that our method is capable of anonymizing the identity of the images whilst -- crucially -- better-preserving the facial attributes. We make the code and the pre-trained models publicly available at: https://github.com/chi0tzp/FALCO.","classes":{"dataset":0.4274332225}}
{"title":"Truth Social Dataset","description":"Formally announced to the public following former President Donald Trump's bans and suspensions from mainstream social networks in early 2022 after his role in the January 6 Capitol Riots, Truth Social was launched as an \"alternative\" social media platform that claims to be a refuge for free speech, offering a platform for those disaffected by the content moderation policies of the existing, mainstream social networks. The subsequent rise of Truth Social has been driven largely by hard-line supporters of the former president as well as those affected by the content moderation of other social networks. These distinct qualities combined with its status as the main mouthpiece of the former president positions Truth Social as a particularly influential social media platform and give rise to several research questions. However, outside of a handful of news reports, little is known about the new social media platform partially due to a lack of well-curated data. In the current work, we describe a dataset of over 823,000 posts to Truth Social and and social network with over 454,000 distinct users. In addition to the dataset itself, we also present some basic analysis of its content, certain temporal features, and its network.","link":"http://arxiv.org/abs/2303.11240v1","created":"2023-03-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Truth Social Dataset Formally announced to the public following former President Donald Trump's bans and suspensions from mainstream social networks in early 2022 after his role in the January 6 Capitol Riots, Truth Social was launched as an \"alternative\" social media platform that claims to be a refuge for free speech, offering a platform for those disaffected by the content moderation policies of the existing, mainstream social networks. The subsequent rise of Truth Social has been driven largely by hard-line supporters of the former president as well as those affected by the content moderation of other social networks. These distinct qualities combined with its status as the main mouthpiece of the former president positions Truth Social as a particularly influential social media platform and give rise to several research questions. However, outside of a handful of news reports, little is known about the new social media platform partially due to a lack of well-curated data. In the current work, we describe a dataset of over 823,000 posts to Truth Social and and social network with over 454,000 distinct users. In addition to the dataset itself, we also present some basic analysis of its content, certain temporal features, and its network.","classes":{"dataset":0.1586392373}}
{"title":"DocRED-FE: A Document-Level Fine-Grained Entity And Relation Extraction Dataset","description":"Joint entity and relation extraction (JERE) is one of the most important tasks in information extraction. However, most existing works focus on sentence-level coarse-grained JERE, which have limitations in real-world scenarios. In this paper, we construct a large-scale document-level fine-grained JERE dataset DocRED-FE, which improves DocRED with Fine-Grained Entity Type. Specifically, we redesign a hierarchical entity type schema including 11 coarse-grained types and 119 fine-grained types, and then re-annotate DocRED manually according to this schema. Through comprehensive experiments we find that: (1) DocRED-FE is challenging to existing JERE models; (2) Our fine-grained entity types promote relation classification. We make DocRED-FE with instruction and the code for our baselines publicly available at https://github.com/PKU-TANGENT/DOCRED-FE.","link":"http://arxiv.org/abs/2303.11141v1","created":"2023-03-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"DocRED-FE: A Document-Level Fine-Grained Entity And Relation Extraction Dataset Joint entity and relation extraction (JERE) is one of the most important tasks in information extraction. However, most existing works focus on sentence-level coarse-grained JERE, which have limitations in real-world scenarios. In this paper, we construct a large-scale document-level fine-grained JERE dataset DocRED-FE, which improves DocRED with Fine-Grained Entity Type. Specifically, we redesign a hierarchical entity type schema including 11 coarse-grained types and 119 fine-grained types, and then re-annotate DocRED manually according to this schema. Through comprehensive experiments we find that: (1) DocRED-FE is challenging to existing JERE models; (2) Our fine-grained entity types promote relation classification. We make DocRED-FE with instruction and the code for our baselines publicly available at https://github.com/PKU-TANGENT/DOCRED-FE.","classes":{"dataset":0.1223148108}}
{"title":"Learning Optical Flow from Event Camera with Rendered Dataset","description":"We study the problem of estimating optical flow from event cameras. One important issue is how to build a high-quality event-flow dataset with accurate event values and flow labels. Previous datasets are created by either capturing real scenes by event cameras or synthesizing from images with pasted foreground objects. The former case can produce real event values but with calculated flow labels, which are sparse and inaccurate. The later case can generate dense flow labels but the interpolated events are prone to errors. In this work, we propose to render a physically correct event-flow dataset using computer graphics models. In particular, we first create indoor and outdoor 3D scenes by Blender with rich scene content variations. Second, diverse camera motions are included for the virtual capturing, producing images and accurate flow labels. Third, we render high-framerate videos between images for accurate events. The rendered dataset can adjust the density of events, based on which we further introduce an adaptive density module (ADM). Experiments show that our proposed dataset can facilitate event-flow learning, whereas previous approaches when trained on our dataset can improve their performances constantly by a relatively large margin. In addition, event-flow pipelines when equipped with our ADM can further improve performances.","link":"http://arxiv.org/abs/2303.11011v1","created":"2023-03-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Learning Optical Flow from Event Camera with Rendered Dataset We study the problem of estimating optical flow from event cameras. One important issue is how to build a high-quality event-flow dataset with accurate event values and flow labels. Previous datasets are created by either capturing real scenes by event cameras or synthesizing from images with pasted foreground objects. The former case can produce real event values but with calculated flow labels, which are sparse and inaccurate. The later case can generate dense flow labels but the interpolated events are prone to errors. In this work, we propose to render a physically correct event-flow dataset using computer graphics models. In particular, we first create indoor and outdoor 3D scenes by Blender with rich scene content variations. Second, diverse camera motions are included for the virtual capturing, producing images and accurate flow labels. Third, we render high-framerate videos between images for accurate events. The rendered dataset can adjust the density of events, based on which we further introduce an adaptive density module (ADM). Experiments show that our proposed dataset can facilitate event-flow learning, whereas previous approaches when trained on our dataset can improve their performances constantly by a relatively large margin. In addition, event-flow pipelines when equipped with our ADM can further improve performances.","classes":{"dataset":0.088736102}}
{"title":"Make Landscape Flatter in Differentially Private Federated Learning","description":"To defend the inference attacks and mitigate the sensitive information leakages in Federated Learning (FL), client-level Differentially Private FL (DPFL) is the de-facto standard for privacy protection by clipping local updates and adding random noise. However, existing DPFL methods tend to make a sharper loss landscape and have poorer weight perturbation robustness, resulting in severe performance degradation. To alleviate these issues, we propose a novel DPFL algorithm named DP-FedSAM, which leverages gradient perturbation to mitigate the negative impact of DP. Specifically, DP-FedSAM integrates Sharpness Aware Minimization (SAM) optimizer to generate local flatness models with better stability and weight perturbation robustness, which results in the small norm of local updates and robustness to DP noise, thereby improving the performance. From the theoretical perspective, we analyze in detail how DP-FedSAM mitigates the performance degradation induced by DP. Meanwhile, we give rigorous privacy guarantees with R\\'enyi DP and present the sensitivity analysis of local updates. At last, we empirically confirm that our algorithm achieves state-of-the-art (SOTA) performance compared with existing SOTA baselines in DPFL.","link":"http://arxiv.org/abs/2303.11242v1","created":"2023-03-20","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Make Landscape Flatter in Differentially Private Federated Learning To defend the inference attacks and mitigate the sensitive information leakages in Federated Learning (FL), client-level Differentially Private FL (DPFL) is the de-facto standard for privacy protection by clipping local updates and adding random noise. However, existing DPFL methods tend to make a sharper loss landscape and have poorer weight perturbation robustness, resulting in severe performance degradation. To alleviate these issues, we propose a novel DPFL algorithm named DP-FedSAM, which leverages gradient perturbation to mitigate the negative impact of DP. Specifically, DP-FedSAM integrates Sharpness Aware Minimization (SAM) optimizer to generate local flatness models with better stability and weight perturbation robustness, which results in the small norm of local updates and robustness to DP noise, thereby improving the performance. From the theoretical perspective, we analyze in detail how DP-FedSAM mitigates the performance degradation induced by DP. Meanwhile, we give rigorous privacy guarantees with R\\'enyi DP and present the sensitivity analysis of local updates. At last, we empirically confirm that our algorithm achieves state-of-the-art (SOTA) performance compared with existing SOTA baselines in DPFL.","classes":{"dataset":0.1727917194}}
{"title":"Differentially Private Algorithms for Synthetic Power System Datasets","description":"While power systems research relies on the availability of real-world network datasets, data owners (e.g., system operators) are hesitant to share data due to security and privacy risks. To control these risks, we develop privacy-preserving algorithms for the synthetic generation of optimization and machine learning datasets. Taking a real-world dataset as input, the algorithms output its noisy, synthetic version, which preserves the accuracy of the real data on a specific downstream model or even a large population of those. We control the privacy loss using Laplace and Exponential mechanisms of differential privacy and preserve data accuracy using a post-processing convex optimization. We apply the algorithms to generate synthetic network parameters and wind power data.","link":"http://arxiv.org/abs/2303.11079v1","created":"2023-03-20","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Differentially Private Algorithms for Synthetic Power System Datasets While power systems research relies on the availability of real-world network datasets, data owners (e.g., system operators) are hesitant to share data due to security and privacy risks. To control these risks, we develop privacy-preserving algorithms for the synthetic generation of optimization and machine learning datasets. Taking a real-world dataset as input, the algorithms output its noisy, synthetic version, which preserves the accuracy of the real data on a specific downstream model or even a large population of those. We control the privacy loss using Laplace and Exponential mechanisms of differential privacy and preserve data accuracy using a post-processing convex optimization. We apply the algorithms to generate synthetic network parameters and wind power data.","classes":{"dataset":0.1122298539}}
{"title":"k-SALSA: k-anonymous synthetic averaging of retinal images via local style alignment","description":"The application of modern machine learning to retinal image analyses offers valuable insights into a broad range of human health conditions beyond ophthalmic diseases. Additionally, data sharing is key to fully realizing the potential of machine learning models by providing a rich and diverse collection of training data. However, the personally-identifying nature of retinal images, encompassing the unique vascular structure of each individual, often prevents this data from being shared openly. While prior works have explored image de-identification strategies based on synthetic averaging of images in other domains (e.g. facial images), existing techniques face difficulty in preserving both privacy and clinical utility in retinal images, as we demonstrate in our work. We therefore introduce k-SALSA, a generative adversarial network (GAN)-based framework for synthesizing retinal fundus images that summarize a given private dataset while satisfying the privacy notion of k-anonymity. k-SALSA brings together state-of-the-art techniques for training and inverting GANs to achieve practical performance on retinal images. Furthermore, k-SALSA leverages a new technique, called local style alignment, to generate a synthetic average that maximizes the retention of fine-grain visual patterns in the source images, thus improving the clinical utility of the generated images. On two benchmark datasets of diabetic retinopathy (EyePACS and APTOS), we demonstrate our improvement upon existing methods with respect to image fidelity, classification performance, and mitigation of membership inference attacks. Our work represents a step toward broader sharing of retinal images for scientific collaboration. Code is available at https://github.com/hcholab/k-salsa.","link":"http://arxiv.org/abs/2303.10824v1","created":"2023-03-20","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"k-SALSA: k-anonymous synthetic averaging of retinal images via local style alignment The application of modern machine learning to retinal image analyses offers valuable insights into a broad range of human health conditions beyond ophthalmic diseases. Additionally, data sharing is key to fully realizing the potential of machine learning models by providing a rich and diverse collection of training data. However, the personally-identifying nature of retinal images, encompassing the unique vascular structure of each individual, often prevents this data from being shared openly. While prior works have explored image de-identification strategies based on synthetic averaging of images in other domains (e.g. facial images), existing techniques face difficulty in preserving both privacy and clinical utility in retinal images, as we demonstrate in our work. We therefore introduce k-SALSA, a generative adversarial network (GAN)-based framework for synthesizing retinal fundus images that summarize a given private dataset while satisfying the privacy notion of k-anonymity. k-SALSA brings together state-of-the-art techniques for training and inverting GANs to achieve practical performance on retinal images. Furthermore, k-SALSA leverages a new technique, called local style alignment, to generate a synthetic average that maximizes the retention of fine-grain visual patterns in the source images, thus improving the clinical utility of the generated images. On two benchmark datasets of diabetic retinopathy (EyePACS and APTOS), we demonstrate our improvement upon existing methods with respect to image fidelity, classification performance, and mitigation of membership inference attacks. Our work represents a step toward broader sharing of retinal images for scientific collaboration. Code is available at https://github.com/hcholab/k-salsa.","classes":{"dataset":0.0471589975}}
{"title":"DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4","description":"The digitization of healthcare has facilitated the sharing and re-using of medical data but has also raised concerns about confidentiality and privacy. HIPAA (Health Insurance Portability and Accountability Act) mandates removing re-identifying information before the dissemination of medical records. Thus, effective and efficient solutions for de-identifying medical data, especially those in free-text forms, are highly needed. While various computer-assisted de-identification methods, including both rule-based and learning-based, have been developed and used in prior practice, such solutions still lack generalizability or need to be fine-tuned according to different scenarios, significantly imposing restrictions in wider use. The advancement of large language models (LLM), such as ChatGPT and GPT-4, have shown great potential in processing text data in the medical domain with zero-shot in-context learning, especially in the task of privacy protection, as these models can identify confidential information by their powerful named entity recognition (NER) capability. In this work, we developed a novel GPT4-enabled de-identification framework (\"DeID-GPT\") to automatically identify and remove the identifying information. Compared to existing commonly used medical text data de-identification methods, our developed DeID-GPT showed the highest accuracy and remarkable reliability in masking private information from the unstructured medical text while preserving the original structure and meaning of the text. This study is one of the earliest to utilize ChatGPT and GPT-4 for medical text data processing and de-identification, which provides insights for further research and solution development on the use of LLMs such as ChatGPT/GPT-4 in healthcare. Codes and benchmarking data information are available at https://github.com/yhydhx/ChatGPT-API.","link":"http://arxiv.org/abs/2303.11032v1","created":"2023-03-20","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4 The digitization of healthcare has facilitated the sharing and re-using of medical data but has also raised concerns about confidentiality and privacy. HIPAA (Health Insurance Portability and Accountability Act) mandates removing re-identifying information before the dissemination of medical records. Thus, effective and efficient solutions for de-identifying medical data, especially those in free-text forms, are highly needed. While various computer-assisted de-identification methods, including both rule-based and learning-based, have been developed and used in prior practice, such solutions still lack generalizability or need to be fine-tuned according to different scenarios, significantly imposing restrictions in wider use. The advancement of large language models (LLM), such as ChatGPT and GPT-4, have shown great potential in processing text data in the medical domain with zero-shot in-context learning, especially in the task of privacy protection, as these models can identify confidential information by their powerful named entity recognition (NER) capability. In this work, we developed a novel GPT4-enabled de-identification framework (\"DeID-GPT\") to automatically identify and remove the identifying information. Compared to existing commonly used medical text data de-identification methods, our developed DeID-GPT showed the highest accuracy and remarkable reliability in masking private information from the unstructured medical text while preserving the original structure and meaning of the text. This study is one of the earliest to utilize ChatGPT and GPT-4 for medical text data processing and de-identification, which provides insights for further research and solution development on the use of LLMs such as ChatGPT/GPT-4 in healthcare. Codes and benchmarking data information are available at https://github.com/yhydhx/ChatGPT-API.","classes":{"dataset":0.0772741213}}
{"title":"A reduction procedure and pipeline for the detection of trans-Neptunian objects using occultations","description":"Trans-Neptunian objects smaller than a few kilometers are difficult to observe directly. They can be detected when they randomly occult a background star. Close to the ecliptic plane, each star is occulted once every tens of thousands of hours, and occultations typically last for less than a second. We present an algorithm, and companion pipeline, for detection of diffractive occultation events. Our approach includes: cleaning the data; an efficient and optimal matched filtering of the light-curves with a template bank of diffractive occultations; treating the red-noise in the light-curves; injection of simulated events for efficiency estimation; and applying data quality cuts. We discuss human vetting of the candidate events in a blinded way to reduce bias caused by the human-in-the-loop. We present Markov Chain Monte Carlo tools to estimate the parameters of candidate occultations, and test them on simulated events. This pipeline is used by the Weizmann Fast Astronomical Survey Telescope (W-FAST).","link":"http://arxiv.org/abs/2303.11275v1","created":"2023-03-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"A reduction procedure and pipeline for the detection of trans-Neptunian objects using occultations Trans-Neptunian objects smaller than a few kilometers are difficult to observe directly. They can be detected when they randomly occult a background star. Close to the ecliptic plane, each star is occulted once every tens of thousands of hours, and occultations typically last for less than a second. We present an algorithm, and companion pipeline, for detection of diffractive occultation events. Our approach includes: cleaning the data; an efficient and optimal matched filtering of the light-curves with a template bank of diffractive occultations; treating the red-noise in the light-curves; injection of simulated events for efficiency estimation; and applying data quality cuts. We discuss human vetting of the candidate events in a blinded way to reduce bias caused by the human-in-the-loop. We present Markov Chain Monte Carlo tools to estimate the parameters of candidate occultations, and test them on simulated events. This pipeline is used by the Weizmann Fast Astronomical Survey Telescope (W-FAST).","classes":{"dataset":0.1088449359}}
{"title":"Truth Social Dataset","description":"Formally announced to the public following former President Donald Trump's bans and suspensions from mainstream social networks in early 2022 after his role in the January 6 Capitol Riots, Truth Social was launched as an \"alternative\" social media platform that claims to be a refuge for free speech, offering a platform for those disaffected by the content moderation policies of the existing, mainstream social networks. The subsequent rise of Truth Social has been driven largely by hard-line supporters of the former president as well as those affected by the content moderation of other social networks. These distinct qualities combined with its status as the main mouthpiece of the former president positions Truth Social as a particularly influential social media platform and give rise to several research questions. However, outside of a handful of news reports, little is known about the new social media platform partially due to a lack of well-curated data. In the current work, we describe a dataset of over 823,000 posts to Truth Social and and social network with over 454,000 distinct users. In addition to the dataset itself, we also present some basic analysis of its content, certain temporal features, and its network.","link":"http://arxiv.org/abs/2303.11240v1","created":"2023-03-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Truth Social Dataset Formally announced to the public following former President Donald Trump's bans and suspensions from mainstream social networks in early 2022 after his role in the January 6 Capitol Riots, Truth Social was launched as an \"alternative\" social media platform that claims to be a refuge for free speech, offering a platform for those disaffected by the content moderation policies of the existing, mainstream social networks. The subsequent rise of Truth Social has been driven largely by hard-line supporters of the former president as well as those affected by the content moderation of other social networks. These distinct qualities combined with its status as the main mouthpiece of the former president positions Truth Social as a particularly influential social media platform and give rise to several research questions. However, outside of a handful of news reports, little is known about the new social media platform partially due to a lack of well-curated data. In the current work, we describe a dataset of over 823,000 posts to Truth Social and and social network with over 454,000 distinct users. In addition to the dataset itself, we also present some basic analysis of its content, certain temporal features, and its network.","classes":{"dataset":0.462146908}}
{"title":"Opportunities and Challenges to Integrate Artificial Intelligence into Manufacturing Systems: Thoughts from a Panel Discussion","description":"Rapid advances in artificial intelligence (AI) have the potential to significantly increase the productivity, quality, and profitability in future manufacturing systems. Traditional mass-production will give way to personalized production, with each item made to order, at the low cost and high-quality consumers have come to expect. Manufacturing systems will have the intelligence to be resilient to multiple disruptions, from small-scale machine breakdowns, to large-scale natural disasters. Products will be made with higher precision and lower variability. While gains have been made towards the development of these factories of the future, many challenges remain to fully realize this vision. To consider the challenges and opportunities associated with this topic, a panel of experts from Industry, Academia, and Government was invited to participate in an active discussion at the 2022 Modeling, Estimation and Control Conference (MECC) held in Jersey City, New Jersey from October 3- 5, 2022. The panel discussion focused on the challenges and opportunities to more fully integrate AI into manufacturing systems. Three overarching themes emerged from the panel discussion. First, to be successful, AI will need to work seamlessly, and in an integrated manner with humans (and vice versa). Second, significant gaps in the infrastructure needed to enable the full potential of AI into the manufacturing ecosystem, including sufficient data availability, storage, and analysis, must be addressed. And finally, improved coordination between universities, industry, and government agencies can facilitate greater opportunities to push the field forward. This article briefly summarizes these three themes, and concludes with a discussion of promising directions.","link":"http://arxiv.org/abs/2303.11139v1","created":"2023-03-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Opportunities and Challenges to Integrate Artificial Intelligence into Manufacturing Systems: Thoughts from a Panel Discussion Rapid advances in artificial intelligence (AI) have the potential to significantly increase the productivity, quality, and profitability in future manufacturing systems. Traditional mass-production will give way to personalized production, with each item made to order, at the low cost and high-quality consumers have come to expect. Manufacturing systems will have the intelligence to be resilient to multiple disruptions, from small-scale machine breakdowns, to large-scale natural disasters. Products will be made with higher precision and lower variability. While gains have been made towards the development of these factories of the future, many challenges remain to fully realize this vision. To consider the challenges and opportunities associated with this topic, a panel of experts from Industry, Academia, and Government was invited to participate in an active discussion at the 2022 Modeling, Estimation and Control Conference (MECC) held in Jersey City, New Jersey from October 3- 5, 2022. The panel discussion focused on the challenges and opportunities to more fully integrate AI into manufacturing systems. Three overarching themes emerged from the panel discussion. First, to be successful, AI will need to work seamlessly, and in an integrated manner with humans (and vice versa). Second, significant gaps in the infrastructure needed to enable the full potential of AI into the manufacturing ecosystem, including sufficient data availability, storage, and analysis, must be addressed. And finally, improved coordination between universities, industry, and government agencies can facilitate greater opportunities to push the field forward. This article briefly summarizes these three themes, and concludes with a discussion of promising directions.","classes":{"dataset":0.4685692489}}
{"title":"I2Edit: Towards Multi-turn Interactive Image Editing via Dialogue","description":"Although there have been considerable research efforts on controllable facial image editing, the desirable interactive setting where the users can interact with the system to adjust their requirements dynamically hasn't been well explored. This paper focuses on facial image editing via dialogue and introduces a new benchmark dataset, Multi-turn Interactive Image Editing (I2Edit), for evaluating image editing quality and interaction ability in real-world interactive facial editing scenarios. The dataset is constructed upon the CelebA-HQ dataset with images annotated with a multi-turn dialogue that corresponds to the user editing requirements. I2Edit is challenging, as it needs to 1) track the dynamically updated user requirements and edit the images accordingly, as well as 2) generate the appropriate natural language response to communicate with the user. To address these challenges, we propose a framework consisting of a dialogue module and an image editing module. The former is for user edit requirements tracking and generating the corresponding indicative responses, while the latter edits the images conditioned on the tracked user edit requirements. In contrast to previous works that simply treat multi-turn interaction as a sequence of single-turn interactions, we extract the user edit requirements from the whole dialogue history instead of the current single turn. The extracted global user edit requirements enable us to directly edit the input raw image to avoid error accumulation and attribute forgetting issues. Extensive quantitative and qualitative experiments on the I2Edit dataset demonstrate the advantage of our proposed framework over the previous single-turn methods. We believe our new dataset could serve as a valuable resource to push forward the exploration of real-world, complex interactive image editing. Code and data will be made public.","link":"http://arxiv.org/abs/2303.11108v1","created":"2023-03-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"I2Edit: Towards Multi-turn Interactive Image Editing via Dialogue Although there have been considerable research efforts on controllable facial image editing, the desirable interactive setting where the users can interact with the system to adjust their requirements dynamically hasn't been well explored. This paper focuses on facial image editing via dialogue and introduces a new benchmark dataset, Multi-turn Interactive Image Editing (I2Edit), for evaluating image editing quality and interaction ability in real-world interactive facial editing scenarios. The dataset is constructed upon the CelebA-HQ dataset with images annotated with a multi-turn dialogue that corresponds to the user editing requirements. I2Edit is challenging, as it needs to 1) track the dynamically updated user requirements and edit the images accordingly, as well as 2) generate the appropriate natural language response to communicate with the user. To address these challenges, we propose a framework consisting of a dialogue module and an image editing module. The former is for user edit requirements tracking and generating the corresponding indicative responses, while the latter edits the images conditioned on the tracked user edit requirements. In contrast to previous works that simply treat multi-turn interaction as a sequence of single-turn interactions, we extract the user edit requirements from the whole dialogue history instead of the current single turn. The extracted global user edit requirements enable us to directly edit the input raw image to avoid error accumulation and attribute forgetting issues. Extensive quantitative and qualitative experiments on the I2Edit dataset demonstrate the advantage of our proposed framework over the previous single-turn methods. We believe our new dataset could serve as a valuable resource to push forward the exploration of real-world, complex interactive image editing. Code and data will be made public.","classes":{"dataset":0.3064396977}}
{"title":"Generative AI and the Digital Commons","description":"Many generative foundation models (or GFMs) are trained on publicly available data and use public infrastructure, but 1) may degrade the \"digital commons\" that they depend on, and 2) do not have processes in place to return value captured to data producers and stakeholders. Existing conceptions of data rights and protection (focusing largely on individually-owned data and associated privacy concerns) and copyright or licensing-based models offer some instructive priors, but are ill-suited for the issues that may arise from models trained on commons-based data. We outline the risks posed by GFMs and why they are relevant to the digital commons, and propose numerous governance-based solutions that include investments in standardized dataset/model disclosure and other kinds of transparency when it comes to generative models' training and capabilities, consortia-based funding for monitoring/standards/auditing organizations, requirements or norms for GFM companies to contribute high quality data to the commons, and structures for shared ownership based on individual or community provision of fine-tuning data.","link":"http://arxiv.org/abs/2303.11074v1","created":"2023-03-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Generative AI and the Digital Commons Many generative foundation models (or GFMs) are trained on publicly available data and use public infrastructure, but 1) may degrade the \"digital commons\" that they depend on, and 2) do not have processes in place to return value captured to data producers and stakeholders. Existing conceptions of data rights and protection (focusing largely on individually-owned data and associated privacy concerns) and copyright or licensing-based models offer some instructive priors, but are ill-suited for the issues that may arise from models trained on commons-based data. We outline the risks posed by GFMs and why they are relevant to the digital commons, and propose numerous governance-based solutions that include investments in standardized dataset/model disclosure and other kinds of transparency when it comes to generative models' training and capabilities, consortia-based funding for monitoring/standards/auditing organizations, requirements or norms for GFM companies to contribute high quality data to the commons, and structures for shared ownership based on individual or community provision of fine-tuning data.","classes":{"dataset":0.4341033399}}
{"title":"From Sparse to Precise: A Practical Editing Approach for Intracardiac Echocardiography Segmentation","description":"Accurate and safe catheter ablation procedures for patients with atrial fibrillation require precise segmentation of cardiac structures in Intracardiac Echocardiography (ICE) imaging. Prior studies have suggested methods that employ 3D geometry information from the ICE transducer to create a sparse ICE volume by placing 2D frames in a 3D grid, enabling training of 3D segmentation models. However, the resulting 3D masks from these models can be inaccurate and may lead to serious clinical complications due to the sparse sampling in ICE data, frames misalignment, and cardiac motion. To address this issue, we propose an interactive editing framework that allows users to edit segmentation output by drawing scribbles on a 2D frame. The user interaction is mapped to the 3D grid and utilized to execute an editing step that modifies the segmentation in the vicinity of the interaction while preserving the previous segmentation away from the interaction. Furthermore, our framework accommodates multiple edits to the segmentation output in a sequential manner without compromising previous edits. This paper presents a novel loss function and a novel evaluation metric specifically designed for editing. Results from cross-validation and testing indicate that our proposed loss function outperforms standard losses and training strategies in terms of segmentation quality and following user input. Additionally, we show quantitatively and qualitatively that subsequent edits do not compromise previous edits when using our method, as opposed to standard segmentation losses. Overall, our approach enhances the accuracy of the segmentation while avoiding undesired changes away from user interactions and without compromising the quality of previously edited regions, leading to better patient outcomes.","link":"http://arxiv.org/abs/2303.11041v1","created":"2023-03-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"From Sparse to Precise: A Practical Editing Approach for Intracardiac Echocardiography Segmentation Accurate and safe catheter ablation procedures for patients with atrial fibrillation require precise segmentation of cardiac structures in Intracardiac Echocardiography (ICE) imaging. Prior studies have suggested methods that employ 3D geometry information from the ICE transducer to create a sparse ICE volume by placing 2D frames in a 3D grid, enabling training of 3D segmentation models. However, the resulting 3D masks from these models can be inaccurate and may lead to serious clinical complications due to the sparse sampling in ICE data, frames misalignment, and cardiac motion. To address this issue, we propose an interactive editing framework that allows users to edit segmentation output by drawing scribbles on a 2D frame. The user interaction is mapped to the 3D grid and utilized to execute an editing step that modifies the segmentation in the vicinity of the interaction while preserving the previous segmentation away from the interaction. Furthermore, our framework accommodates multiple edits to the segmentation output in a sequential manner without compromising previous edits. This paper presents a novel loss function and a novel evaluation metric specifically designed for editing. Results from cross-validation and testing indicate that our proposed loss function outperforms standard losses and training strategies in terms of segmentation quality and following user input. Additionally, we show quantitatively and qualitatively that subsequent edits do not compromise previous edits when using our method, as opposed to standard segmentation losses. Overall, our approach enhances the accuracy of the segmentation while avoiding undesired changes away from user interactions and without compromising the quality of previously edited regions, leading to better patient outcomes.","classes":{"dataset":0.2786428332}}
{"title":"LFACon: Introducing Anglewise Attention to No-Reference Quality Assessment in Light Field Space","description":"Light field imaging can capture both the intensity information and the direction information of light rays. It naturally enables a six-degrees-of-freedom viewing experience and deep user engagement in virtual reality. Compared to 2D image assessment, light field image quality assessment (LFIQA) needs to consider not only the image quality in the spatial domain but also the quality consistency in the angular domain. However, there is a lack of metrics to effectively reflect the angular consistency and thus the angular quality of a light field image (LFI). Furthermore, the existing LFIQA metrics suffer from high computational costs due to the excessive data volume of LFIs. In this paper, we propose a novel concept of \"anglewise attention\" by introducing a multihead self-attention mechanism to the angular domain of an LFI. This mechanism better reflects the LFI quality. In particular, we propose three new attention kernels, including anglewise self-attention, anglewise grid attention, and anglewise central attention. These attention kernels can realize angular self-attention, extract multiangled features globally or selectively, and reduce the computational cost of feature extraction. By effectively incorporating the proposed kernels, we further propose our light field attentional convolutional neural network (LFACon) as an LFIQA metric. Our experimental results show that the proposed LFACon metric significantly outperforms the state-of-the-art LFIQA metrics. For the majority of distortion types, LFACon attains the best performance with lower complexity and less computational time.","link":"http://arxiv.org/abs/2303.10961v1","created":"2023-03-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"LFACon: Introducing Anglewise Attention to No-Reference Quality Assessment in Light Field Space Light field imaging can capture both the intensity information and the direction information of light rays. It naturally enables a six-degrees-of-freedom viewing experience and deep user engagement in virtual reality. Compared to 2D image assessment, light field image quality assessment (LFIQA) needs to consider not only the image quality in the spatial domain but also the quality consistency in the angular domain. However, there is a lack of metrics to effectively reflect the angular consistency and thus the angular quality of a light field image (LFI). Furthermore, the existing LFIQA metrics suffer from high computational costs due to the excessive data volume of LFIs. In this paper, we propose a novel concept of \"anglewise attention\" by introducing a multihead self-attention mechanism to the angular domain of an LFI. This mechanism better reflects the LFI quality. In particular, we propose three new attention kernels, including anglewise self-attention, anglewise grid attention, and anglewise central attention. These attention kernels can realize angular self-attention, extract multiangled features globally or selectively, and reduce the computational cost of feature extraction. By effectively incorporating the proposed kernels, we further propose our light field attentional convolutional neural network (LFACon) as an LFIQA metric. Our experimental results show that the proposed LFACon metric significantly outperforms the state-of-the-art LFIQA metrics. For the majority of distortion types, LFACon attains the best performance with lower complexity and less computational time.","classes":{"dataset":0.203466177}}
{"title":"The effect of noise artefacts on gravitational-wave searches for neutron star post-merger remnants","description":"Gravitational waves from binary neutron star post-merger remnants have the potential to uncover the physics of the hot nuclear equation of state. These gravitational-wave signals are high frequency ($\\sim$ kHz) and short lived ($\\mathcal{O}(10\\,\\mathrm{ms})$), which introduces potential problems for data-analysis algorithms due to the presence of non-stationary and non-Gaussian noise artefacts in gravitational-wave observatories. We quantify the degree to which these noise features in LIGO data may affect our confidence in identifying post-merger gravitational-wave signals. We show that the combination of vetoing data with non-stationary glitches and the application of the Allen $\\chi^2$ veto (usually reserved for long-lived lower-frequency gravitational-wave signals), allows one to confidently detect post-merger signals with signal-to-noise ratio $\\rho\\gtrsim8$. We discuss the need to incorporate the data-quality checks and vetos into realistic post-merger gravitational-wave searches, and describe how one can incorporate them to calculate realistic false-alarm and false-dismissal rates.","link":"http://arxiv.org/abs/2303.10847v1","created":"2023-03-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"The effect of noise artefacts on gravitational-wave searches for neutron star post-merger remnants Gravitational waves from binary neutron star post-merger remnants have the potential to uncover the physics of the hot nuclear equation of state. These gravitational-wave signals are high frequency ($\\sim$ kHz) and short lived ($\\mathcal{O}(10\\,\\mathrm{ms})$), which introduces potential problems for data-analysis algorithms due to the presence of non-stationary and non-Gaussian noise artefacts in gravitational-wave observatories. We quantify the degree to which these noise features in LIGO data may affect our confidence in identifying post-merger gravitational-wave signals. We show that the combination of vetoing data with non-stationary glitches and the application of the Allen $\\chi^2$ veto (usually reserved for long-lived lower-frequency gravitational-wave signals), allows one to confidently detect post-merger signals with signal-to-noise ratio $\\rho\\gtrsim8$. We discuss the need to incorporate the data-quality checks and vetos into realistic post-merger gravitational-wave searches, and describe how one can incorporate them to calculate realistic false-alarm and false-dismissal rates.","classes":{"dataset":0.0385697894}}
{"title":"Run 100B+ language models at home, BitTorrent\u2011style","description":"https://petals.ml/","link":"https://petals.ml/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":513},"text":"Run 100B+ language models at home, BitTorrent\u2011style https://petals.ml/","classes":{"dataset":0.4929317534}}
{"title":"Laying Out a Print Book with CSS","description":"https://iangmcdowell.com/blog/posts/laying-out-a-book-with-css/","link":"https://iangmcdowell.com/blog/posts/laying-out-a-book-with-css/","created":"2023-03-21","tags":["hackernews"],"meta":{"score":108},"text":"Laying Out a Print Book with CSS https://iangmcdowell.com/blog/posts/laying-out-a-book-with-css/","classes":{"dataset":0.4885497987}}
{"title":"Louis Rossmann could sue John Deere for GPL violation","description":"https://www.youtube.com/watch?v=XP7Qx1FF1hA","link":"https://www.youtube.com/watch?v=XP7Qx1FF1hA","created":"2023-03-21","tags":["hackernews"],"meta":{"score":60},"text":"Louis Rossmann could sue John Deere for GPL violation https://www.youtube.com/watch?v=XP7Qx1FF1hA","classes":{"dataset":0.4987734854}}
{"title":"Doors I touched today (1999)","description":"https://fluxus.org/FluxusMidwest/doorknobs/","link":"https://fluxus.org/FluxusMidwest/doorknobs/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":249},"text":"Doors I touched today (1999) https://fluxus.org/FluxusMidwest/doorknobs/","classes":{"dataset":0.5162001252}}
{"title":"Clifford Stoll beat the Russians, then made useless, wondrous objects (2016)","description":"https://alumni.berkeley.edu/california-magazine/spring-2016-war-stories/how-berkeley-eccentric-beat-russians-and-then-made/","link":"https://alumni.berkeley.edu/california-magazine/spring-2016-war-stories/how-berkeley-eccentric-beat-russians-and-then-made/","created":"2023-03-21","tags":["hackernews"],"meta":{"score":133},"text":"Clifford Stoll beat the Russians, then made useless, wondrous objects (2016) https://alumni.berkeley.edu/california-magazine/spring-2016-war-stories/how-berkeley-eccentric-beat-russians-and-then-made/","classes":{"dataset":0.5040615201}}
{"title":"macOS Cursors","description":"https://mac-cursors.netlify.app","link":"https://mac-cursors.netlify.app","created":"2023-03-20","tags":["hackernews"],"meta":{"score":133},"text":"macOS Cursors https://mac-cursors.netlify.app","classes":{"dataset":0.4919202626}}
{"title":"Awesome-totally-open-ChatGPT: A list of open alternatives to ChatGPT","description":"https://github.com/nichtdax/awesome-totally-open-chatgpt","link":"https://github.com/nichtdax/awesome-totally-open-chatgpt","created":"2023-03-21","tags":["hackernews"],"meta":{"score":64},"text":"Awesome-totally-open-ChatGPT: A list of open alternatives to ChatGPT https://github.com/nichtdax/awesome-totally-open-chatgpt","classes":{"dataset":0.5260835886}}
{"title":"Paving the Road to Vulkan on Asahi Linux","description":"https://asahilinux.org/2023/03/road-to-vulkan/","link":"https://asahilinux.org/2023/03/road-to-vulkan/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":634},"text":"Paving the Road to Vulkan on Asahi Linux https://asahilinux.org/2023/03/road-to-vulkan/","classes":{"dataset":0.5491105318}}
{"title":"Spack \u2013 scientific software package manager for supercomputers, Linux, and macOS","description":"https://spack.io/","link":"https://spack.io/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":132},"text":"Spack \u2013 scientific software package manager for supercomputers, Linux, and macOS https://spack.io/","classes":{"dataset":0.5112099648}}
{"title":"Chronology Clock","description":"https://chronologyclock.com/","link":"https://chronologyclock.com/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":83},"text":"Chronology Clock https://chronologyclock.com/","classes":{"dataset":0.5005956292}}
{"title":"A world to win: WebAssembly for the rest of us","description":"https://www.wingolog.org/archives/2023/03/20/a-world-to-win-webassembly-for-the-rest-of-us","link":"https://www.wingolog.org/archives/2023/03/20/a-world-to-win-webassembly-for-the-rest-of-us","created":"2023-03-20","tags":["hackernews"],"meta":{"score":243},"text":"A world to win: WebAssembly for the rest of us https://www.wingolog.org/archives/2023/03/20/a-world-to-win-webassembly-for-the-rest-of-us","classes":{"dataset":0.4907093644}}
{"title":"EasyPost (YC S13) Is Hiring","description":"https://www.easypost.com/careers","link":"https://www.easypost.com/careers","created":"2023-03-20","tags":["hackernews"],"meta":{"score":1},"text":"EasyPost (YC S13) Is Hiring https://www.easypost.com/careers","classes":{"dataset":0.4953659475}}
{"title":"ReAct: Synergizing Reasoning and Acting in Language Models","description":"https://react-lm.github.io","link":"https://react-lm.github.io","created":"2023-03-20","tags":["hackernews"],"meta":{"score":93},"text":"ReAct: Synergizing Reasoning and Acting in Language Models https://react-lm.github.io","classes":{"dataset":0.507349968}}
{"title":"An Aperiodic Monotile","description":"https://arxiv.org/abs/2303.10798","link":"https://arxiv.org/abs/2303.10798","created":"2023-03-21","tags":["hackernews"],"meta":{"score":7},"text":"An Aperiodic Monotile https://arxiv.org/abs/2303.10798","classes":{"dataset":0.5009741783}}
{"title":"Utah's Governor Should Veto \u201cSocial Media Regulations\u201d Bill S.B. 152","description":"https://www.eff.org/deeplinks/2023/03/utahs-governor-should-veto-social-media-regulations-bill-sb-152","link":"https://www.eff.org/deeplinks/2023/03/utahs-governor-should-veto-social-media-regulations-bill-sb-152","created":"2023-03-21","tags":["hackernews"],"meta":{"score":6},"text":"Utah's Governor Should Veto \u201cSocial Media Regulations\u201d Bill S.B. 152 https://www.eff.org/deeplinks/2023/03/utahs-governor-should-veto-social-media-regulations-bill-sb-152","classes":{"dataset":0.482740134}}
{"title":"Stanford\u2019s Alpaca shows that OpenAI may have a problem","description":"https://the-decoder.com/stanfords-alpaca-shows-that-openai-may-have-a-problem/","link":"https://the-decoder.com/stanfords-alpaca-shows-that-openai-may-have-a-problem/","created":"2023-03-21","tags":["hackernews"],"meta":{"score":131},"text":"Stanford\u2019s Alpaca shows that OpenAI may have a problem https://the-decoder.com/stanfords-alpaca-shows-that-openai-may-have-a-problem/","classes":{"dataset":0.5351432562}}
{"title":"TinyVG \u2013 an alternative binary encoded vector graphics format","description":"https://tinyvg.tech/","link":"https://tinyvg.tech/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":325},"text":"TinyVG \u2013 an alternative binary encoded vector graphics format https://tinyvg.tech/","classes":{"dataset":0.5225720406}}
{"title":"Show HN: Professional headshots for remote team with AI","description":"https://www.headshotpro.com/","link":"https://www.headshotpro.com/","created":"2023-03-21","tags":["hackernews"],"meta":{"score":82},"text":"Show HN: Professional headshots for remote team with AI https://www.headshotpro.com/","classes":{"dataset":0.5038986206}}
{"title":"Pimoroni introduces Inky Frame with seven-color 4-inch E Ink display","description":"https://goodereader.com/blog/technology/pimoroni-introduces-inky-frame-with-seven-color-4-inch-e-ink-display-for-71","link":"https://goodereader.com/blog/technology/pimoroni-introduces-inky-frame-with-seven-color-4-inch-e-ink-display-for-71","created":"2023-03-20","tags":["hackernews"],"meta":{"score":55},"text":"Pimoroni introduces Inky Frame with seven-color 4-inch E Ink display https://goodereader.com/blog/technology/pimoroni-introduces-inky-frame-with-seven-color-4-inch-e-ink-display-for-71","classes":{"dataset":0.5209077001}}
{"title":"Previous: A NeXT Computer Emulator","description":"https://previous.unixdude.net/","link":"https://previous.unixdude.net/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":236},"text":"Previous: A NeXT Computer Emulator https://previous.unixdude.net/","classes":{"dataset":0.5455864072}}
{"title":"Twitch.tv Lays of 400 Employees","description":"https://blog.twitch.tv/en/2023/03/20/an-update-about-our-workforce/","link":"https://blog.twitch.tv/en/2023/03/20/an-update-about-our-workforce/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":196},"text":"Twitch.tv Lays of 400 Employees https://blog.twitch.tv/en/2023/03/20/an-update-about-our-workforce/","classes":{"dataset":0.5366116166}}
{"title":"Download, copy and paste free AWS icons in SVG and PNG format for your projects","description":"https://aws-icons.com","link":"https://aws-icons.com","created":"2023-03-21","tags":["hackernews"],"meta":{"score":20},"text":"Download, copy and paste free AWS icons in SVG and PNG format for your projects https://aws-icons.com","classes":{"dataset":0.5370850563}}
{"title":"Cesium-137 missing and found in junk yard in Thailand","description":"https://www.nationthailand.com/thailand/general/40025846","link":"https://www.nationthailand.com/thailand/general/40025846","created":"2023-03-20","tags":["hackernews"],"meta":{"score":106},"text":"Cesium-137 missing and found in junk yard in Thailand https://www.nationthailand.com/thailand/general/40025846","classes":{"dataset":0.5212888122}}
{"title":"Pacific Pinball Museum","description":"https://www.pacificpinball.org","link":"https://www.pacificpinball.org","created":"2023-03-20","tags":["hackernews"],"meta":{"score":123},"text":"Pacific Pinball Museum https://www.pacificpinball.org","classes":{"dataset":0.5096091628}}
{"title":"Made a Flappy Bird clone with GPT4 and Midjourney in under an hour","description":"https://bootcamp.uxdesign.cc/i-made-a-flappy-bird-clone-with-gpt4-and-midjourney-in-under-an-hour-and-you-can-do-it-too-7847bc509431","link":"https://bootcamp.uxdesign.cc/i-made-a-flappy-bird-clone-with-gpt4-and-midjourney-in-under-an-hour-and-you-can-do-it-too-7847bc509431","created":"2023-03-21","tags":["hackernews"],"meta":{"score":17},"text":"Made a Flappy Bird clone with GPT4 and Midjourney in under an hour https://bootcamp.uxdesign.cc/i-made-a-flappy-bird-clone-with-gpt4-and-midjourney-in-under-an-hour-and-you-can-do-it-too-7847bc509431","classes":{"dataset":0.4830586016}}
{"title":"District heating systems: The greenest energy is the energy we don't use","description":"https://www.metafilter.com/198637/District-heating-systems-The-greenest-energy-is-the-energy-we-dont-use","link":"https://www.metafilter.com/198637/District-heating-systems-The-greenest-energy-is-the-energy-we-dont-use","created":"2023-03-21","tags":["hackernews"],"meta":{"score":14},"text":"District heating systems: The greenest energy is the energy we don't use https://www.metafilter.com/198637/District-heating-systems-The-greenest-energy-is-the-energy-we-dont-use","classes":{"dataset":0.52631706}}
{"title":"Baidu Ernie writes poems, says it has insufficient information on Xi, tests show","description":"https://www.reuters.com/technology/baidus-ernie-writes-poems-says-it-has-insufficient-information-xi-tests-show-2023-03-20/","link":"https://www.reuters.com/technology/baidus-ernie-writes-poems-says-it-has-insufficient-information-xi-tests-show-2023-03-20/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":34},"text":"Baidu Ernie writes poems, says it has insufficient information on Xi, tests show https://www.reuters.com/technology/baidus-ernie-writes-poems-says-it-has-insufficient-information-xi-tests-show-2023-03-20/","classes":{"dataset":0.4744851589}}
{"title":"Show HN: Go-testdeep, testing JSON content in Golang","description":"https://go-testdeep.zetta.rocks/operators/json/","link":"https://go-testdeep.zetta.rocks/operators/json/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":8},"text":"Show HN: Go-testdeep, testing JSON content in Golang https://go-testdeep.zetta.rocks/operators/json/","classes":{"dataset":0.5000219345}}
{"title":"Show HN: Find words \u201chalfway\u201d between two others","description":"https://halfwaywords.com","link":"https://halfwaywords.com","created":"2023-03-20","tags":["hackernews"],"meta":{"score":17},"text":"Show HN: Find words \u201chalfway\u201d between two others https://halfwaywords.com","classes":{"dataset":0.5124481916}}
{"title":"What\u2019s different about these layoffs","description":"https://stackoverflow.blog/2023/03/19/whats-different-about-these-layoffs/","link":"https://stackoverflow.blog/2023/03/19/whats-different-about-these-layoffs/","created":"2023-03-21","tags":["hackernews"],"meta":{"score":13},"text":"What\u2019s different about these layoffs https://stackoverflow.blog/2023/03/19/whats-different-about-these-layoffs/","classes":{"dataset":0.4916497171}}
{"title":"Hachette vs. Internet Archive","description":"https://www.eff.org/cases/hachette-v-internet-archive","link":"https://www.eff.org/cases/hachette-v-internet-archive","created":"2023-03-20","tags":["hackernews"],"meta":{"score":26},"text":"Hachette vs. Internet Archive https://www.eff.org/cases/hachette-v-internet-archive","classes":{"dataset":0.4966215193}}
{"title":"Deadly Fungus Detected in Most U.S. States","description":"https://www.wsj.com/articles/deadly-fungus-detected-in-most-u-s-states-1eb3453a","link":"https://www.wsj.com/articles/deadly-fungus-detected-in-most-u-s-states-1eb3453a","created":"2023-03-20","tags":["hackernews"],"meta":{"score":30},"text":"Deadly Fungus Detected in Most U.S. States https://www.wsj.com/articles/deadly-fungus-detected-in-most-u-s-states-1eb3453a","classes":{"dataset":0.4827159047}}
{"title":"Google urges Android phone users to switch off Wi-Fi calling","description":"https://scrippsnews.com/stories/how-to-turn-off-wi-fi-calling-on-android-to-combat-hackers/","link":"https://scrippsnews.com/stories/how-to-turn-off-wi-fi-calling-on-android-to-combat-hackers/","created":"2023-03-21","tags":["hackernews"],"meta":{"score":211},"text":"Google urges Android phone users to switch off Wi-Fi calling https://scrippsnews.com/stories/how-to-turn-off-wi-fi-calling-on-android-to-combat-hackers/","classes":{"dataset":0.4894099534}}
{"title":"The British computer magazine cover tape","description":"https://commodoreformatarchive.com/games-of-the-90s-the-covertapes/","link":"https://commodoreformatarchive.com/games-of-the-90s-the-covertapes/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":55},"text":"The British computer magazine cover tape https://commodoreformatarchive.com/games-of-the-90s-the-covertapes/","classes":{"dataset":0.5003742576}}
{"title":"Bitwarden PINs can be brute-forced","description":"https://ambiso.github.io/bitwarden-pin/","link":"https://ambiso.github.io/bitwarden-pin/","created":"2023-03-19","tags":["hackernews"],"meta":{"score":436},"text":"Bitwarden PINs can be brute-forced https://ambiso.github.io/bitwarden-pin/","classes":{"dataset":0.5060986876}}
{"title":"The little-known story behind the 2022 Nobel Prize in physics","description":"https://www.scientificamerican.com/article/the-little-known-origin-story-behind-the-2022-nobel-prize-in-physics/","link":"https://www.scientificamerican.com/article/the-little-known-origin-story-behind-the-2022-nobel-prize-in-physics/","created":"2023-03-19","tags":["hackernews"],"meta":{"score":230},"text":"The little-known story behind the 2022 Nobel Prize in physics https://www.scientificamerican.com/article/the-little-known-origin-story-behind-the-2022-nobel-prize-in-physics/","classes":{"dataset":0.454095006}}
{"title":"Who is still inside the metaverse?","description":"https://nymag.com/intelligencer/article/mark-zuckerberg-metaverse-meta-horizon-worlds.html","link":"https://nymag.com/intelligencer/article/mark-zuckerberg-metaverse-meta-horizon-worlds.html","created":"2023-03-20","tags":["hackernews"],"meta":{"score":126},"text":"Who is still inside the metaverse? https://nymag.com/intelligencer/article/mark-zuckerberg-metaverse-meta-horizon-worlds.html","classes":{"dataset":0.4803638756}}
{"title":"Google denies destroying 'chat' evidence in U.S. antitrust lawsuit","description":"https://www.reuters.com/legal/google-denies-destroying-chat-evidence-us-antitrust-lawsuit-2023-03-20/","link":"https://www.reuters.com/legal/google-denies-destroying-chat-evidence-us-antitrust-lawsuit-2023-03-20/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":29},"text":"Google denies destroying 'chat' evidence in U.S. antitrust lawsuit https://www.reuters.com/legal/google-denies-destroying-chat-evidence-us-antitrust-lawsuit-2023-03-20/","classes":{"dataset":0.4937300682}}
{"title":"Toxic pet flea and tick treatments are polluting UK freshwaters, says paper","description":"https://phys.org/news/2023-03-toxic-pet-flea-treatments-polluting.html","link":"https://phys.org/news/2023-03-toxic-pet-flea-treatments-polluting.html","created":"2023-03-20","tags":["hackernews"],"meta":{"score":13},"text":"Toxic pet flea and tick treatments are polluting UK freshwaters, says paper https://phys.org/news/2023-03-toxic-pet-flea-treatments-polluting.html","classes":{"dataset":0.539624691}}
{"title":"Lessons from a Pessimist: Make Your Pessimism Productive","description":"https://lucumr.pocoo.org/2023/3/20/lessons-from-a-pessimist/","link":"https://lucumr.pocoo.org/2023/3/20/lessons-from-a-pessimist/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":132},"text":"Lessons from a Pessimist: Make Your Pessimism Productive https://lucumr.pocoo.org/2023/3/20/lessons-from-a-pessimist/","classes":{"dataset":0.5311347842}}
{"title":"Six Recent Studies Show an Unexpected Increase in Classical Music Listening","description":"https://tedgioia.substack.com/p/six-recent-studies-show-an-unexpected","link":"https://tedgioia.substack.com/p/six-recent-studies-show-an-unexpected","created":"2023-03-21","tags":["hackernews"],"meta":{"score":57},"text":"Six Recent Studies Show an Unexpected Increase in Classical Music Listening https://tedgioia.substack.com/p/six-recent-studies-show-an-unexpected","classes":{"dataset":0.5328266621}}
{"title":"Altstore: Home for apps that push the boundaries of iOS","description":"https://altstore.io/","link":"https://altstore.io/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":320},"text":"Altstore: Home for apps that push the boundaries of iOS https://altstore.io/","classes":{"dataset":0.4759495556}}
{"title":"The case for slowing down AI","description":"https://www.vox.com/the-highlight/23621198/artificial-intelligence-chatgpt-openai-existential-risk-china-ai-safety-technology","link":"https://www.vox.com/the-highlight/23621198/artificial-intelligence-chatgpt-openai-existential-risk-china-ai-safety-technology","created":"2023-03-20","tags":["hackernews"],"meta":{"score":20},"text":"The case for slowing down AI https://www.vox.com/the-highlight/23621198/artificial-intelligence-chatgpt-openai-existential-risk-china-ai-safety-technology","classes":{"dataset":0.5109730363}}
{"title":"Gitea 1.19","description":"https://blog.gitea.io/2023/03/gitea-1.19.0-is-released/","link":"https://blog.gitea.io/2023/03/gitea-1.19.0-is-released/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":163},"text":"Gitea 1.19 https://blog.gitea.io/2023/03/gitea-1.19.0-is-released/","classes":{"dataset":0.491826117}}
{"title":"Flow-Based Programming, a way for AI and humans to develop together","description":"https://bergie.iki.fi/blog/fbp-ai-human-collaboration/","link":"https://bergie.iki.fi/blog/fbp-ai-human-collaboration/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":163},"text":"Flow-Based Programming, a way for AI and humans to develop together https://bergie.iki.fi/blog/fbp-ai-human-collaboration/","classes":{"dataset":0.5025917292}}
{"title":"Twenty-five years of curl","description":"https://daniel.haxx.se/blog/2023/03/20/twenty-five-years-of-curl/","link":"https://daniel.haxx.se/blog/2023/03/20/twenty-five-years-of-curl/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":413},"text":"Twenty-five years of curl https://daniel.haxx.se/blog/2023/03/20/twenty-five-years-of-curl/","classes":{"dataset":0.4610345662}}
{"title":"Tuesday Daily Thread: Advanced questions","description":"Have some burning questions on advanced Python topics? Use this thread to ask more advanced questions related to Python.\n\n**If your question is a beginner question we hold a beginner Daily Thread tomorrow (Wednesday) where you can ask any question! We may remove questions here and ask you to resubmit tomorrow.**\n\nThis thread may be fairly low volume in replies, if you don't receive a response we recommend looking at r/LearnPython or joining the Python Discord server at [https://discord.gg/python](https://discord.gg/python) where you stand a better chance of receiving a response.","link":"https://www.reddit.com/r/Python/comments/11x0no5/tuesday_daily_thread_advanced_questions/","created":"2023-03-21","tags":["reddit","python"],"meta":{"num_comments":5},"text":"Tuesday Daily Thread: Advanced questions Have some burning questions on advanced Python topics? Use this thread to ask more advanced questions related to Python.\n\n**If your question is a beginner question we hold a beginner Daily Thread tomorrow (Wednesday) where you can ask any question! We may remove questions here and ask you to resubmit tomorrow.**\n\nThis thread may be fairly low volume in replies, if you don't receive a response we recommend looking at r/LearnPython or joining the Python Discord server at [https://discord.gg/python](https://discord.gg/python) where you stand a better chance of receiving a response.","classes":{"dataset":0.4687213302}}
{"title":"Opinion on the monaco lib ?","description":"Hi everyone,\n\nI want to develop Monte Carlo simulations for various uses, with tkinter as GUI. I initially planned to interface python with c++, but i just came across the monaco lib. Maybe it is enough for what i need (simulation of traffic jams for example), and could avoid me to interface python and c++ which doesn't seem to be that easy. Do you guys have experience with monaco ? Is it fast / flexible ?\n\nThanks !","link":"https://www.reddit.com/r/Python/comments/11xbg6o/opinion_on_the_monaco_lib/","created":"2023-03-21","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Opinion on the monaco lib ? Hi everyone,\n\nI want to develop Monte Carlo simulations for various uses, with tkinter as GUI. I initially planned to interface python with c++, but i just came across the monaco lib. Maybe it is enough for what i need (simulation of traffic jams for example), and could avoid me to interface python and c++ which doesn't seem to be that easy. Do you guys have experience with monaco ? Is it fast / flexible ?\n\nThanks !","classes":{"dataset":0.2888689041}}
{"title":"Random Settler's Of Catan Board Generating Program","description":"I made a python program to randomly generate a game board with numbers for Settler's of Catan - the original idea was to get my friends to shut up about making unfair boards, but it's actually a pretty good beginner lesson so I made a tutorial on it here:\n\n[https://www.youtube.com/watch?v=7h3sFhBAgcw](https://www.youtube.com/watch?v=7h3sFhBAgcw)\n\nAnd all the code is available here:\n\n[https://github.com/plemaster01/CatanBoardGeneration](https://github.com/plemaster01/CatanBoardGeneration)","link":"https://www.reddit.com/r/Python/comments/11wjz95/random_settlers_of_catan_board_generating_program/","created":"2023-03-20","tags":["reddit","python"],"meta":{"num_comments":8},"text":"Random Settler's Of Catan Board Generating Program I made a python program to randomly generate a game board with numbers for Settler's of Catan - the original idea was to get my friends to shut up about making unfair boards, but it's actually a pretty good beginner lesson so I made a tutorial on it here:\n\n[https://www.youtube.com/watch?v=7h3sFhBAgcw](https://www.youtube.com/watch?v=7h3sFhBAgcw)\n\nAnd all the code is available here:\n\n[https://github.com/plemaster01/CatanBoardGeneration](https://github.com/plemaster01/CatanBoardGeneration)","classes":{"dataset":0.4430966377}}
{"title":"Orm or not Orm? Mayim?","description":"Hello everyone, im more or less proficient in sql, already manage my database as is, and i dont know if i need an orm or not and mostly where do i need to look to not use it but still have some goodies, i have seen mayim project, i feel like its more or less the degree of freedom i need, id like opinions on that and maybe alternatives to evaluate.. thanks everyone","link":"https://www.reddit.com/r/Python/comments/11ws1js/orm_or_not_orm_mayim/","created":"2023-03-20","tags":["reddit","python"],"meta":{"num_comments":13},"text":"Orm or not Orm? Mayim? Hello everyone, im more or less proficient in sql, already manage my database as is, and i dont know if i need an orm or not and mostly where do i need to look to not use it but still have some goodies, i have seen mayim project, i feel like its more or less the degree of freedom i need, id like opinions on that and maybe alternatives to evaluate.. thanks everyone","classes":{"dataset":0.2977975607}}
{"title":"Feel free to shit on my code this is a script for finding if a number is even or odd","description":"\\# lists off numbers  \nodd = \\[1, 3, 5, 7, 9\\]  \n\n\n\\# requests input and checks for illegal characters  \ninput = input(\"Number?\")  \nif not input.isdigit():  \n print(\"error\")  \n exit()  \n\n\n\\# finds last digit of number  \nnum = int(repr(int(input))\\[-1\\])  \n\\# compares the listed digits and the last digit of the number  \nif num in odd:  \n print(\"odd\")  \nelse:  \n print(\"even\")","link":"https://www.reddit.com/r/Python/comments/11xarii/feel_free_to_shit_on_my_code_this_is_a_script_for/","created":"2023-03-21","tags":["reddit","python"],"meta":{"num_comments":5},"text":"Feel free to shit on my code this is a script for finding if a number is even or odd \\# lists off numbers  \nodd = \\[1, 3, 5, 7, 9\\]  \n\n\n\\# requests input and checks for illegal characters  \ninput = input(\"Number?\")  \nif not input.isdigit():  \n print(\"error\")  \n exit()  \n\n\n\\# finds last digit of number  \nnum = int(repr(int(input))\\[-1\\])  \n\\# compares the listed digits and the last digit of the number  \nif num in odd:  \n print(\"odd\")  \nelse:  \n print(\"even\")","classes":{"dataset":0.6143387556}}
{"title":"NASA's Cassini - Cosmic Dust Analyzer: How to calibrate a space instrument","description":"Hello everyone,\n\nIn my current small tutorial series I am showing how the Cassini Cosmic Dust Analyzer (CDA) was calibrated. A detailed description of the initial idea can be seen [here](https://youtu.be/rO6w9B0Jw7U) or read here on Wikipedia: [https://en.wikipedia.org/wiki/Cosmic\\_Dust\\_Analyzer](https://en.wikipedia.org/wiki/Cosmic_Dust_Analyzer).\n\nNow before an instrument is set to space one needs to have an understanding and also (empirical) equations and algorithms to convert electric signals into the physical units you'd like to derive. E.g., a current or voltage corresponds to the velocity of a dust particle. To achieve this, the instrument is calibrated in a dust accelerator. Yes, you hear it correctly. A ... \"Cern like accelerator\" ... not for atoms, but for micrometer sized dust particles (e.g., made of iron, Latex, or carbonous compositions).\n\nNow in this small series I want to show how the instrument is calibrated, what kind of calibration functions exist (empirical ones) and how one could use Machine Learning to improve the calibration accuracy of the instrument.\n\nIn this first video it is about the data exploration and understanding. The video and corresponding Open Source GitHub Link can be seen below.\n\nHope you'll like it; and if you work in a lab; also doing some calibration work, maybe the ML based approach will be of interest for you!\n\nBest,\n\nThomas\n\nYouTube: [https://youtu.be/gq-qk\\_Jq5p0](https://youtu.be/gq-qk_Jq5p0)\n\nGitHub: [https://github.com/ThomasAlbin/Astroniz-YT-Tutorials/blob/main/%5BProject%5D-Cassini-CDA/01-Calibration/01\\_data\\_exploration.ipynb](https://github.com/ThomasAlbin/Astroniz-YT-Tutorials/blob/main/%5BProject%5D-Cassini-CDA/01-Calibration/01_data_exploration.ipynb)","link":"https://www.reddit.com/r/Python/comments/11vjmc2/nasas_cassini_cosmic_dust_analyzer_how_to/","created":"2023-03-19","tags":["reddit","python"],"meta":{"num_comments":4},"text":"NASA's Cassini - Cosmic Dust Analyzer: How to calibrate a space instrument Hello everyone,\n\nIn my current small tutorial series I am showing how the Cassini Cosmic Dust Analyzer (CDA) was calibrated. A detailed description of the initial idea can be seen [here](https://youtu.be/rO6w9B0Jw7U) or read here on Wikipedia: [https://en.wikipedia.org/wiki/Cosmic\\_Dust\\_Analyzer](https://en.wikipedia.org/wiki/Cosmic_Dust_Analyzer).\n\nNow before an instrument is set to space one needs to have an understanding and also (empirical) equations and algorithms to convert electric signals into the physical units you'd like to derive. E.g., a current or voltage corresponds to the velocity of a dust particle. To achieve this, the instrument is calibrated in a dust accelerator. Yes, you hear it correctly. A ... \"Cern like accelerator\" ... not for atoms, but for micrometer sized dust particles (e.g., made of iron, Latex, or carbonous compositions).\n\nNow in this small series I want to show how the instrument is calibrated, what kind of calibration functions exist (empirical ones) and how one could use Machine Learning to improve the calibration accuracy of the instrument.\n\nIn this first video it is about the data exploration and understanding. The video and corresponding Open Source GitHub Link can be seen below.\n\nHope you'll like it; and if you work in a lab; also doing some calibration work, maybe the ML based approach will be of interest for you!\n\nBest,\n\nThomas\n\nYouTube: [https://youtu.be/gq-qk\\_Jq5p0](https://youtu.be/gq-qk_Jq5p0)\n\nGitHub: [https://github.com/ThomasAlbin/Astroniz-YT-Tutorials/blob/main/%5BProject%5D-Cassini-CDA/01-Calibration/01\\_data\\_exploration.ipynb](https://github.com/ThomasAlbin/Astroniz-YT-Tutorials/blob/main/%5BProject%5D-Cassini-CDA/01-Calibration/01_data_exploration.ipynb)","classes":{"dataset":0.4935059845}}
{"title":"CPorter: Streamlined C &amp; Python Integration with Auto Type Checking and more","description":"Over the weekend I wrote a simple wrapper for ctypes. It simplifies the process of compiling, loading, and calling C functions from Python. I wrote it mostly for fun, I'm sure there are much better library wrappers out there but it was a nice exercise in Python packaging and Mypy.\n\n I do enjoy statically-typed languages for the verboseness, so I took a crack at type hints and static-type checking with Python for once. Only 260 LOC but I'm happy it passes Mypy fully. \n\n\n\n\n\nHere's an example to show some speed differences:\n    \n    from cporter.cporter import CPorter\n\n    def fibonacci_iterative(n):\n        a = 0\n        b = 1\n        elif n == 0:\n            return a\n        elif n == 1:\n            return b\n        else:\n            for i in range(2,n+1):\n                c = a + b\n                a = b\n                b = c\n            return b\n    \n    cporter = CPorter()\n    \n    cporter.set_library_path(\"examples/lib\")\n    cporter.add_library(\"fib\")\n    print(\"Calculating 100th fibonacci number\")\n    py_results = cporter.profile_python_function(fibonacci_iterative, 100)\n    c_results = cporter.profile_function(\"fib\", \"fibonacci_iterative\", 100)\n    \n    print(f\"C Result:{c_results[0]} Time: {c_results[1]} seconds\")\n    print(f\"Python Result:{c_results[0]} Time: {py_results[1]} seconds\")\n\nAnd our result:\n\n    Calculating 100th fibonacci number\n    C Result:3736710778780434371 Time: 0.0001399169999999339 seconds\n    Python Result:3736710778780434371 Time: 5.000000000032756e-06 seconds\n\nAnyway, here's the repo: https://github.com/snacsnoc/cporter\n\nThe inspiration came from another project I submitted a few PRs to, [sushi](https://github.com/dev-sushi/sushi). It's another library to run functions from foreign languages within Python. Check it out, it's pretty cool.","link":"https://www.reddit.com/r/Python/comments/11wd5y8/cporter_streamlined_c_python_integration_with/","created":"2023-03-20","tags":["reddit","python"],"meta":{"num_comments":0},"text":"CPorter: Streamlined C &amp; Python Integration with Auto Type Checking and more Over the weekend I wrote a simple wrapper for ctypes. It simplifies the process of compiling, loading, and calling C functions from Python. I wrote it mostly for fun, I'm sure there are much better library wrappers out there but it was a nice exercise in Python packaging and Mypy.\n\n I do enjoy statically-typed languages for the verboseness, so I took a crack at type hints and static-type checking with Python for once. Only 260 LOC but I'm happy it passes Mypy fully. \n\n\n\n\n\nHere's an example to show some speed differences:\n    \n    from cporter.cporter import CPorter\n\n    def fibonacci_iterative(n):\n        a = 0\n        b = 1\n        elif n == 0:\n            return a\n        elif n == 1:\n            return b\n        else:\n            for i in range(2,n+1):\n                c = a + b\n                a = b\n                b = c\n            return b\n    \n    cporter = CPorter()\n    \n    cporter.set_library_path(\"examples/lib\")\n    cporter.add_library(\"fib\")\n    print(\"Calculating 100th fibonacci number\")\n    py_results = cporter.profile_python_function(fibonacci_iterative, 100)\n    c_results = cporter.profile_function(\"fib\", \"fibonacci_iterative\", 100)\n    \n    print(f\"C Result:{c_results[0]} Time: {c_results[1]} seconds\")\n    print(f\"Python Result:{c_results[0]} Time: {py_results[1]} seconds\")\n\nAnd our result:\n\n    Calculating 100th fibonacci number\n    C Result:3736710778780434371 Time: 0.0001399169999999339 seconds\n    Python Result:3736710778780434371 Time: 5.000000000032756e-06 seconds\n\nAnyway, here's the repo: https://github.com/snacsnoc/cporter\n\nThe inspiration came from another project I submitted a few PRs to, [sushi](https://github.com/dev-sushi/sushi). It's another library to run functions from foreign languages within Python. Check it out, it's pretty cool.","classes":{"dataset":0.2508158982}}
{"title":"Are people abusing Python?","description":"I learned Python after coming from the C/C++ and Java world. With the massive increase in popularity of Python in the last 10 years, seeing the way it developed, it seems to me like it gained a lot of functionality, which comes natural in other languages, but feels a bit odd in Python.\n\nTo be more specific - albeit Python being dynamically typed, people developed countless tools to check or validate or even enforce types in compile or run time (mypy, pyre, pydantic, pyduck etc.). It feels like it goes against the nature of its loose typing.\n\nAnother example are decorators. This pattern is noticably overused by many tools adding functionality, but even the language itself - defining a \\`class\\`,\\`static\\` and \\`abstract\\` methods with decorators seems just weird and unnatural. Same thing with function overloading.  Anecdotally, it feels like comparing German to English. German has a special word for every peculiar thing and native support for word generation by concatenation of multiple words whilst in English you have to add some common words together and hope this combination doesnt already exist. And if it does, so what, people will get it from the context.\n\nLastly, slightly off-topic but relevant point is that it is not even a simple language in my opinion. It has a very flat learning curve initially but the complexity is just further down the road. Im talking about metaclasses,data descriptors, coroutines, magic methods etc. Some languages are difficult right away (C++, Rust etc.), but Python is a intricate misfit dressed as a simpleton.\n\nAm I misunderstanding a philosophical path of the language or is it simply just a scripting langugage that got massively popular through chance and is now used for stuff it was not intended for?\n\nEdit: grammar","link":"https://www.reddit.com/r/Python/comments/11wye72/are_people_abusing_python/","created":"2023-03-20","tags":["reddit","python"],"meta":{"num_comments":41},"text":"Are people abusing Python? I learned Python after coming from the C/C++ and Java world. With the massive increase in popularity of Python in the last 10 years, seeing the way it developed, it seems to me like it gained a lot of functionality, which comes natural in other languages, but feels a bit odd in Python.\n\nTo be more specific - albeit Python being dynamically typed, people developed countless tools to check or validate or even enforce types in compile or run time (mypy, pyre, pydantic, pyduck etc.). It feels like it goes against the nature of its loose typing.\n\nAnother example are decorators. This pattern is noticably overused by many tools adding functionality, but even the language itself - defining a \\`class\\`,\\`static\\` and \\`abstract\\` methods with decorators seems just weird and unnatural. Same thing with function overloading.  Anecdotally, it feels like comparing German to English. German has a special word for every peculiar thing and native support for word generation by concatenation of multiple words whilst in English you have to add some common words together and hope this combination doesnt already exist. And if it does, so what, people will get it from the context.\n\nLastly, slightly off-topic but relevant point is that it is not even a simple language in my opinion. It has a very flat learning curve initially but the complexity is just further down the road. Im talking about metaclasses,data descriptors, coroutines, magic methods etc. Some languages are difficult right away (C++, Rust etc.), but Python is a intricate misfit dressed as a simpleton.\n\nAm I misunderstanding a philosophical path of the language or is it simply just a scripting langugage that got massively popular through chance and is now used for stuff it was not intended for?\n\nEdit: grammar","classes":{"dataset":0.7205340862}}
{"title":"Middle level book to study Python","description":"Is there any middle level book I can use once I know all the basics data types, functions, classes etc in order to level up the language? Thanks!","link":"https://www.reddit.com/r/Python/comments/11vhrgr/middle_level_book_to_study_python/","created":"2023-03-19","tags":["reddit","python"],"meta":{"num_comments":29},"text":"Middle level book to study Python Is there any middle level book I can use once I know all the basics data types, functions, classes etc in order to level up the language? Thanks!","classes":{"dataset":0.4424210787}}
{"title":"Is it possible to include C code in a package published to PyPi while not limiting compatibility?","description":"Hello!\n\nI am working on a library, and in a part of it, I perform a customized search over large bytes objects. In my experience, C code runs about an order of magnitude faster when working with primitive data like byte arrays, I wanted to rewrite that part of the code in C to gain performance.\n\nI know about the ctypes module, but I am worried about portability. The library has about 30k downloads, so I want it to be compatible will any system it is installed on.\n\nTo my knowledge, numpy is also largely written in C. Do they compile their code for every possible platform and choose the binaries dynamically, or is there some other good way to do it?\n\nIf someone has any experience regarding this, any help would be appreciated greatly!","link":"https://www.reddit.com/r/Python/comments/11vsrnh/is_it_possible_to_include_c_code_in_a_package/","created":"2023-03-19","tags":["reddit","python"],"meta":{"num_comments":16},"text":"Is it possible to include C code in a package published to PyPi while not limiting compatibility? Hello!\n\nI am working on a library, and in a part of it, I perform a customized search over large bytes objects. In my experience, C code runs about an order of magnitude faster when working with primitive data like byte arrays, I wanted to rewrite that part of the code in C to gain performance.\n\nI know about the ctypes module, but I am worried about portability. The library has about 30k downloads, so I want it to be compatible will any system it is installed on.\n\nTo my knowledge, numpy is also largely written in C. Do they compile their code for every possible platform and choose the binaries dynamically, or is there some other good way to do it?\n\nIf someone has any experience regarding this, any help would be appreciated greatly!","classes":{"dataset":0.4404441118}}
{"title":"Implementing new dataset on CV arch.","description":"I want to implement the \\[PIE dataset\\]\\[1\\] in the \\[AgentFormer arch\\]\\[2\\]. \n\nAgentFormer uses ETH and nuScene datasets. I successfully run these datasets on this arch. However, I couldn't take a good way with the PIE dataset. I am not sure how I could write a new data loader for it. Which steps should I take? \n\nI normally have experience in implementing articles without looking at similar GitHub codes, but this time I stuck. \n\n&amp;#x200B;\n\nThank you for any help. \n\n&amp;#x200B;\n\n&amp;#x200B;\n\n  \\[1\\]: [https://github.com/aras62/PIE](https://github.com/aras62/PIE)\n\n  \\[2\\]: [https://github.com/Khrylx/AgentFormer](https://github.com/Khrylx/AgentFormer)","link":"https://www.reddit.com/r/deeplearning/comments/11x3p1d/implementing_new_dataset_on_cv_arch/","created":"2023-03-21","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"Implementing new dataset on CV arch. I want to implement the \\[PIE dataset\\]\\[1\\] in the \\[AgentFormer arch\\]\\[2\\]. \n\nAgentFormer uses ETH and nuScene datasets. I successfully run these datasets on this arch. However, I couldn't take a good way with the PIE dataset. I am not sure how I could write a new data loader for it. Which steps should I take? \n\nI normally have experience in implementing articles without looking at similar GitHub codes, but this time I stuck. \n\n&amp;#x200B;\n\nThank you for any help. \n\n&amp;#x200B;\n\n&amp;#x200B;\n\n  \\[1\\]: [https://github.com/aras62/PIE](https://github.com/aras62/PIE)\n\n  \\[2\\]: [https://github.com/Khrylx/AgentFormer](https://github.com/Khrylx/AgentFormer)","classes":{"dataset":0.6623367667}}
{"title":"How to get the clossest word from a vector, fasttext embeding","description":"using ft.get_word_vector(string) you get the vector embedding of that string, is there a way to get the word if a given vector?\nsomthing like this: ft.get_word_of_vector(vector)?\nthis is using fasttext","link":"https://www.reddit.com/r/deeplearning/comments/11wo1zi/how_to_get_the_clossest_word_from_a_vector/","created":"2023-03-20","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":1},"text":"How to get the clossest word from a vector, fasttext embeding using ft.get_word_vector(string) you get the vector embedding of that string, is there a way to get the word if a given vector?\nsomthing like this: ft.get_word_of_vector(vector)?\nthis is using fasttext","classes":{"dataset":0.3363625109}}
{"title":"3 interviews with exceptional NVIDIA people to launch my new podcast, \"What's AI by Louis Bouchard\"!","description":"In this short series, we learn a lot about the Data Science world at NVIDIA (more on what are a data scientist and a solution architect), Kaggle, scaling large models, the NVIDIA interview process (and improving at them), how it is to work at such a big company, and more.\n\nThere are many valuable insights from Chris Deotte, Meriem Bendris, and Adam Grzywaczewski.  \nIt is also in partnership with NVIDIA GTC running all week, where they provided me with an RTX 4080 to giveaway to help promote this new project.\n\nIf you want to learn more about AI and inspiring personas in the field, have a look at the new podcast (available on Spotify, Apple podcasts, and YouTube): [https://podcasters.spotify.com/pod/show/louis-bouchard](https://podcasters.spotify.com/pod/show/louis-bouchard)\n\nPlease let me know what you think of these interviews and if you know anyone (including you) that would like to be interviewed! :)\n\nIf you want to learn more from the interviewees, have a look at GTC this week: [https://nvda.ws/3XQRtkl](https://nvda.ws/3XQRtkl)","link":"https://www.reddit.com/r/deeplearning/comments/11wkzz3/3_interviews_with_exceptional_nvidia_people_to/","created":"2023-03-20","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"3 interviews with exceptional NVIDIA people to launch my new podcast, \"What's AI by Louis Bouchard\"! In this short series, we learn a lot about the Data Science world at NVIDIA (more on what are a data scientist and a solution architect), Kaggle, scaling large models, the NVIDIA interview process (and improving at them), how it is to work at such a big company, and more.\n\nThere are many valuable insights from Chris Deotte, Meriem Bendris, and Adam Grzywaczewski.  \nIt is also in partnership with NVIDIA GTC running all week, where they provided me with an RTX 4080 to giveaway to help promote this new project.\n\nIf you want to learn more about AI and inspiring personas in the field, have a look at the new podcast (available on Spotify, Apple podcasts, and YouTube): [https://podcasters.spotify.com/pod/show/louis-bouchard](https://podcasters.spotify.com/pod/show/louis-bouchard)\n\nPlease let me know what you think of these interviews and if you know anyone (including you) that would like to be interviewed! :)\n\nIf you want to learn more from the interviewees, have a look at GTC this week: [https://nvda.ws/3XQRtkl](https://nvda.ws/3XQRtkl)","classes":{"dataset":0.7069180012}}
{"title":"Retro Style Portrait Tutorial in Canva","description":"Easy Retro Style Portrait Tutorial in Canva\n\n[Tutorial link](https://youtu.be/qdlRG13TzGk) \n\n&amp;#x200B;\n\nhttps://preview.redd.it/dh53u5akbyoa1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=b2d114d6d68d9b94417ee55552f52ad79d5580e5","link":"https://www.reddit.com/r/deeplearning/comments/11wu8nc/retro_style_portrait_tutorial_in_canva/","created":"2023-03-20","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"Retro Style Portrait Tutorial in Canva Easy Retro Style Portrait Tutorial in Canva\n\n[Tutorial link](https://youtu.be/qdlRG13TzGk) \n\n&amp;#x200B;\n\nhttps://preview.redd.it/dh53u5akbyoa1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=b2d114d6d68d9b94417ee55552f52ad79d5580e5","classes":{"dataset":0.3069589436}}
{"title":"Discover How AI is Changing the World","description":"Looking for inspiration to achieve a career in AI? Hear from a panel of innovators developing AI solutions that are changing the world of healthcare, climate, generative AI, social impact, and more. Join Change the World with a Career in AI on March 22nd. [https://nvda.ws/3x5wKxE](https://nvda.ws/3x5wKxE) (P.S. we have an Ex-NASA astronaut, Generative AI Pioneers and Startup founders in this panel)","link":"https://www.reddit.com/r/deeplearning/comments/11wsfs1/discover_how_ai_is_changing_the_world/","created":"2023-03-20","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"Discover How AI is Changing the World Looking for inspiration to achieve a career in AI? Hear from a panel of innovators developing AI solutions that are changing the world of healthcare, climate, generative AI, social impact, and more. Join Change the World with a Career in AI on March 22nd. [https://nvda.ws/3x5wKxE](https://nvda.ws/3x5wKxE) (P.S. we have an Ex-NASA astronaut, Generative AI Pioneers and Startup founders in this panel)","classes":{"dataset":0.2701620758}}
{"title":"Should I pay for A100 or use 3090TI","description":"Currently attempting to fine tune an existing LLM off Hugging Face as my first delve into Machine Learning.  \nI have access to a 3090TI and relatively ok internet connection. Would it be worth it to pay for cloud computing (A100) or should I just train with the 3090TI I have access to?   \nThe 3090TI is not my own so I wouldn't have 24/7 uptime but it's not that long of a job, should maybe take 1-2 weeks max on a A100?  \nWould it be worth it to skip the hassle and shell out the few bucks to train using a cloud computing service, and has anyone attempted to use both and can tell me the difference in speed? Specifically how good a 3090TI would even be for training?","link":"https://www.reddit.com/r/deeplearning/comments/11w904r/should_i_pay_for_a100_or_use_3090ti/","created":"2023-03-20","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":1},"text":"Should I pay for A100 or use 3090TI Currently attempting to fine tune an existing LLM off Hugging Face as my first delve into Machine Learning.  \nI have access to a 3090TI and relatively ok internet connection. Would it be worth it to pay for cloud computing (A100) or should I just train with the 3090TI I have access to?   \nThe 3090TI is not my own so I wouldn't have 24/7 uptime but it's not that long of a job, should maybe take 1-2 weeks max on a A100?  \nWould it be worth it to skip the hassle and shell out the few bucks to train using a cloud computing service, and has anyone attempted to use both and can tell me the difference in speed? Specifically how good a 3090TI would even be for training?","classes":{"dataset":0.3446066976}}
{"title":"Auxillary function","description":"Was amazed to know that auxillary functions are functional arch of encoder -decoder architectures.\n\n`Definition 1 G(h, h') is an auxiliary functionfor F(h) if the conditions G(h, h') ~ F(h), G(h, h) = F(h) (10) are satisfied.`","link":"https://www.reddit.com/r/deeplearning/comments/11w90uj/auxillary_function/","created":"2023-03-20","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":0},"text":"Auxillary function Was amazed to know that auxillary functions are functional arch of encoder -decoder architectures.\n\n`Definition 1 G(h, h') is an auxiliary functionfor F(h) if the conditions G(h, h') ~ F(h), G(h, h) = F(h) (10) are satisfied.`","classes":{"dataset":0.0307391398}}
{"title":"How to finetune bert to output a date range","description":"Lets say i have a string \"the holiday is between the 13.01 and 15.01\" so i want the output to be (13.0.2023,, 15.01.2023)  the string could be anything and the dates could be written in any format, how can this be done?\nThe string is in hebrew language...","link":"https://www.reddit.com/r/deeplearning/comments/11vj3wo/how_to_finetune_bert_to_output_a_date_range/","created":"2023-03-19","tags":["deeplearning","ml","reddit"],"meta":{"num_comments":4},"text":"How to finetune bert to output a date range Lets say i have a string \"the holiday is between the 13.01 and 15.01\" so i want the output to be (13.0.2023,, 15.01.2023)  the string could be anything and the dates could be written in any format, how can this be done?\nThe string is in hebrew language...","classes":{"dataset":0.4875586331}}
{"title":"[D] Is ML doomed to end up closed-source?","description":"So basically, OpenAI is keeping its models a secret, Hugging Face added a new gated feature, and LLaMA is using a non-commercial license. It looks like companies are all moving towards closed-source and monopolizing ML. \n\nI've always loved Hugging Face, but now they are doing the opposite of what they preach with this new gated feature thing, this is just not open-source and shouldn't be encouraged in the first place.\n\nOpen AI [clearly stated](https://openai.com/policies/terms-of-use#:~:text=use%20output%20from%20the%20Services%20to%20develop%20models%20that%20compete%20with%20OpenAI) that you can't \"use output from the Services to develop models that compete with OpenAI\"\n\nGoogle shared its paper Attention Is All You Need transparently which was a breakthrough in NLP and got utilized by OpenAI (with many other papers) to build GPT-4 which is adopted by Bing and now posing risk to Google's business. As a consequence, could companies start to avoid sharing research openly and rather monopolize their work for the sake of their own business safety?\n\nAlso, assuming we will witness more of these closed-source models. is it safe to just trust them without understanding what data they got exactly trained on? This doesn't seem to make sense, not sure how this would end up.","link":"https://www.reddit.com/r/MachineLearning/comments/11wxabh/d_is_ml_doomed_to_end_up_closedsource/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":55},"text":"[D] Is ML doomed to end up closed-source? So basically, OpenAI is keeping its models a secret, Hugging Face added a new gated feature, and LLaMA is using a non-commercial license. It looks like companies are all moving towards closed-source and monopolizing ML. \n\nI've always loved Hugging Face, but now they are doing the opposite of what they preach with this new gated feature thing, this is just not open-source and shouldn't be encouraged in the first place.\n\nOpen AI [clearly stated](https://openai.com/policies/terms-of-use#:~:text=use%20output%20from%20the%20Services%20to%20develop%20models%20that%20compete%20with%20OpenAI) that you can't \"use output from the Services to develop models that compete with OpenAI\"\n\nGoogle shared its paper Attention Is All You Need transparently which was a breakthrough in NLP and got utilized by OpenAI (with many other papers) to build GPT-4 which is adopted by Bing and now posing risk to Google's business. As a consequence, could companies start to avoid sharing research openly and rather monopolize their work for the sake of their own business safety?\n\nAlso, assuming we will witness more of these closed-source models. is it safe to just trust them without understanding what data they got exactly trained on? This doesn't seem to make sense, not sure how this would end up.","classes":{"dataset":0.0180730075}}
{"title":"[P] OpenAssistant is now live on reddit (Open Source ChatGPT alternative)","description":"OpenAssistant bot is live on /r/ask_open_assistant. There are some limitations to the reddit bot; you can also try on the model in chat mode at https://huggingface.co/spaces/olivierdehaene/chat-llm-streaming. Model is available for free download at https://huggingface.co/OpenAssistant/oasst-sft-1-pythia-12b.\n\n\nPrompt it by creating a new text post (responds to text body of post), starting a comment with !OpenAssistant, or by replying directly to it. \n\nI have recently enabled memory for the bot so it should do a (pretty mediocre) job of continuing a conversation with you.","link":"https://www.reddit.com/r/MachineLearning/comments/11wt2fl/p_openassistant_is_now_live_on_reddit_open_source/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":21},"text":"[P] OpenAssistant is now live on reddit (Open Source ChatGPT alternative) OpenAssistant bot is live on /r/ask_open_assistant. There are some limitations to the reddit bot; you can also try on the model in chat mode at https://huggingface.co/spaces/olivierdehaene/chat-llm-streaming. Model is available for free download at https://huggingface.co/OpenAssistant/oasst-sft-1-pythia-12b.\n\n\nPrompt it by creating a new text post (responds to text body of post), starting a comment with !OpenAssistant, or by replying directly to it. \n\nI have recently enabled memory for the bot so it should do a (pretty mediocre) job of continuing a conversation with you.","classes":{"dataset":0.5835844278}}
{"title":"[R] \ud83e\udd16\ud83c\udf1f Unlock the Power of Personal AI: Introducing ChatLLaMA, Your Custom Personal Assistant! \ud83d\ude80\ud83d\udcac","description":"\ud83d\ude80 Introducing ChatLLaMA: Your Personal AI Assistant Powered by LoRA! \ud83e\udd16\n\n&amp;#x200B;\n\nHey AI enthusiasts! \ud83c\udf1f We're excited to announce that you can now create custom personal assistants that run directly on your GPUs!\n\n&amp;#x200B;\n\nChatLLaMA utilizes LoRA, trained on Anthropic's HH dataset, to model seamless conversations between an AI assistant and users.\n\n&amp;#x200B;\n\nPlus, the RLHF version of LoRA is coming soon! \ud83d\udd25\n\n&amp;#x200B;\n\n\ud83d\udc49 Get it here: [https://cxn.to/@serpai/lora-weights](https://cxn.to/@serpai/lora-weights)\n\n&amp;#x200B;\n\n\ud83d\udcda Know any high-quality dialogue-style datasets? Share them with us, and we'll train ChatLLaMA on them!\n\n&amp;#x200B;\n\n\ud83c\udf10 ChatLLaMA is currently available for 30B and 13B models, and the 7B version.\n\n&amp;#x200B;\n\n\ud83d\udd14 Want to stay in the loop for new ChatLLaMA updates? Grab the FREE \\[gumroad link\\]([https://cxn.to/@serpai/lora-weights](https://cxn.to/@serpai/lora-weights)) to sign up and access a collection of links, tutorials, and guides on running the model, merging weights, and more.  (Guides on running and training the model coming soon)\n\n&amp;#x200B;\n\n\ud83e\udd14 Have questions or need help setting up ChatLLaMA? Drop a comment or DM us, and we'll be more than happy to help you out! \ud83d\udcac\n\n&amp;#x200B;\n\nLet's revolutionize AI-assisted conversations together! \ud83c\udf1f\n\n&amp;#x200B;\n\n\\*Disclaimer: trained for research, no foundation model weights, and the post was ran through gpt4 to make it more coherent.\n\n&amp;#x200B;\n\n\ud83d\udc49 Get it here: [https://cxn.to/@serpai/lora-weights](https://cxn.to/@serpai/lora-weights)\n\n&amp;#x200B;\n\n\\*Edit: [https://github.com/serp-ai/LLaMA-8bit-LoRA](https://github.com/serp-ai/LLaMA-8bit-LoRA) &lt;- training repo/instructions (If anything is unclear just let us know and we will try to help/fix the issue!)  (Sorry for spamming the link, don't really know how else to remind people lol)","link":"https://www.reddit.com/r/MachineLearning/comments/11w03sy/r_unlock_the_power_of_personal_ai_introducing/","created":"2023-03-19","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":227},"text":"[R] \ud83e\udd16\ud83c\udf1f Unlock the Power of Personal AI: Introducing ChatLLaMA, Your Custom Personal Assistant! \ud83d\ude80\ud83d\udcac \ud83d\ude80 Introducing ChatLLaMA: Your Personal AI Assistant Powered by LoRA! \ud83e\udd16\n\n&amp;#x200B;\n\nHey AI enthusiasts! \ud83c\udf1f We're excited to announce that you can now create custom personal assistants that run directly on your GPUs!\n\n&amp;#x200B;\n\nChatLLaMA utilizes LoRA, trained on Anthropic's HH dataset, to model seamless conversations between an AI assistant and users.\n\n&amp;#x200B;\n\nPlus, the RLHF version of LoRA is coming soon! \ud83d\udd25\n\n&amp;#x200B;\n\n\ud83d\udc49 Get it here: [https://cxn.to/@serpai/lora-weights](https://cxn.to/@serpai/lora-weights)\n\n&amp;#x200B;\n\n\ud83d\udcda Know any high-quality dialogue-style datasets? Share them with us, and we'll train ChatLLaMA on them!\n\n&amp;#x200B;\n\n\ud83c\udf10 ChatLLaMA is currently available for 30B and 13B models, and the 7B version.\n\n&amp;#x200B;\n\n\ud83d\udd14 Want to stay in the loop for new ChatLLaMA updates? Grab the FREE \\[gumroad link\\]([https://cxn.to/@serpai/lora-weights](https://cxn.to/@serpai/lora-weights)) to sign up and access a collection of links, tutorials, and guides on running the model, merging weights, and more.  (Guides on running and training the model coming soon)\n\n&amp;#x200B;\n\n\ud83e\udd14 Have questions or need help setting up ChatLLaMA? Drop a comment or DM us, and we'll be more than happy to help you out! \ud83d\udcac\n\n&amp;#x200B;\n\nLet's revolutionize AI-assisted conversations together! \ud83c\udf1f\n\n&amp;#x200B;\n\n\\*Disclaimer: trained for research, no foundation model weights, and the post was ran through gpt4 to make it more coherent.\n\n&amp;#x200B;\n\n\ud83d\udc49 Get it here: [https://cxn.to/@serpai/lora-weights](https://cxn.to/@serpai/lora-weights)\n\n&amp;#x200B;\n\n\\*Edit: [https://github.com/serp-ai/LLaMA-8bit-LoRA](https://github.com/serp-ai/LLaMA-8bit-LoRA) &lt;- training repo/instructions (If anything is unclear just let us know and we will try to help/fix the issue!)  (Sorry for spamming the link, don't really know how else to remind people lol)","classes":{"dataset":0.556515038}}
{"title":"ICML rebuttals still not visible to reviewers? [D]","description":"The rebuttals for ICML submissions were supposed to become visible to reviewers at 3pm ET on Sunday, with the author-reviewer discussion period beginning today at 10am ET, but OpenReview says my rebuttals are not visible to the reviewers yet. Is anyone else having this problem? Am worried I somehow made them only visible to the chairs","link":"https://www.reddit.com/r/MachineLearning/comments/11wkacx/icml_rebuttals_still_not_visible_to_reviewers_d/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":10},"text":"ICML rebuttals still not visible to reviewers? [D] The rebuttals for ICML submissions were supposed to become visible to reviewers at 3pm ET on Sunday, with the author-reviewer discussion period beginning today at 10am ET, but OpenReview says my rebuttals are not visible to the reviewers yet. Is anyone else having this problem? Am worried I somehow made them only visible to the chairs","classes":{"dataset":0.2901121378}}
{"title":"[D] Hyperparameter robustness of RL algorithms","description":"\n\nI've gone through a lot of RL algorithms recently and a lot of them seem to be very sensitive to hyperparameters with performances varying by degrees of +/-10 in some cases in a scale of  100. Do reviewers consider them as limitations when evaluating these algorithms and yet they still get published, what's the way forward in the field of RL to reduce this?","link":"https://www.reddit.com/r/MachineLearning/comments/11wrqw2/d_hyperparameter_robustness_of_rl_algorithms/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":1},"text":"[D] Hyperparameter robustness of RL algorithms \n\nI've gone through a lot of RL algorithms recently and a lot of them seem to be very sensitive to hyperparameters with performances varying by degrees of +/-10 in some cases in a scale of  100. Do reviewers consider them as limitations when evaluating these algorithms and yet they still get published, what's the way forward in the field of RL to reduce this?","classes":{"dataset":0.0186295118}}
{"title":"[P] Action Recognition in Computer Vision","description":"Action recognition is a difficult task. Mainly because of its vagueness. Type of actions, duration, ontology, etc. I made a complete overview of the problem relevant today. Here is a collection of approaches, networks, and problem statements. It will help you clarify the task the next time you meet it.    https://medium.com/@zlodeibaal/action-recognition-in-the-wild-9eb7f12b4d12","link":"https://www.reddit.com/r/MachineLearning/comments/11wjk9x/p_action_recognition_in_computer_vision/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[P] Action Recognition in Computer Vision Action recognition is a difficult task. Mainly because of its vagueness. Type of actions, duration, ontology, etc. I made a complete overview of the problem relevant today. Here is a collection of approaches, networks, and problem statements. It will help you clarify the task the next time you meet it.    https://medium.com/@zlodeibaal/action-recognition-in-the-wild-9eb7f12b4d12","classes":{"dataset":0.405474931}}
{"title":"[D] Determining quality of training images with some metrics","description":"Hello ML sub,\n\nHow does one evaluate the quality of training images before actually training a model ? Training a model is surely expensive. What if one had a way of sort of ascertaining that the image quality of a training set for a particular task (say object detection or semantic segmentation etc) ? It doesn't have to be perfect but some kind of hint...\n\nCould you please point me to some papers or studies or discussions on this ?\n\nThere are some objective metrics like PSNR or SSIM but they need a reference image","link":"https://www.reddit.com/r/MachineLearning/comments/11wreix/d_determining_quality_of_training_images_with/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":4},"text":"[D] Determining quality of training images with some metrics Hello ML sub,\n\nHow does one evaluate the quality of training images before actually training a model ? Training a model is surely expensive. What if one had a way of sort of ascertaining that the image quality of a training set for a particular task (say object detection or semantic segmentation etc) ? It doesn't have to be perfect but some kind of hint...\n\nCould you please point me to some papers or studies or discussions on this ?\n\nThere are some objective metrics like PSNR or SSIM but they need a reference image","classes":{"dataset":0.073478736}}
{"title":"[D]The Ethical Implications of AI","description":"Greetings, AI enthusiasts! As someone who's deeply engaged with the world of artificial intelligence, I know firsthand how exciting and powerful this technology can be. However, it's important to remember that with great power comes great responsibility. That's why I'm here to talk about the importance of ethical AI.\n\nAs Tim Cook, CEO of Apple, once said, \"Technology should be infused with humanity. It's not something that comes off an assembly line.\" That sentiment is particularly important when it comes to AI, which has the potential to impact so many aspects of our lives. We need to ensure that we're using this technology in a responsible and ethical way, so that we can maximize its benefits while minimizing its potential risks.\n\nSome of the key ethical considerations for using AI include privacy, transparency, inclusivity, safety, and impact. For example, it's essential that AI systems be designed with privacy in mind, and that they be transparent about how they collect and use personal data. It's also important to ensure that AI systems are accessible and beneficial for everyone, regardless of their background or abilities.\n\nAs Joy Buolamwini, founder of the Algorithmic Justice League, has said, \"AI can't be neutral, it reflects the values of those who make it.\" That's why it's important to be vigilant in detecting and addressing bias in AI systems, and ensure that the data used to train them is diverse and representative. We also need to consider the potential impact of AI on society, including the risk of job displacement and the widening of economic inequality.\n\nTo use AI in an ethical and responsible way, we need to stay informed and up-to-date on the latest developments and best practices in the field. There are many resources available to help us learn more about AI ethics, such as academic papers, reports, and online courses. By educating ourselves and staying informed, we can create a culture of ethical AI that benefits everyone.\n\nSo, what can we do to promote ethical AI? Let's start by having an open and honest conversation about the ethical considerations of using this technology. Let's also make sure that we're holding ourselves and others accountable for creating and using AI in an ethical and responsible way. By working together, we can create a brighter future with AI that is ethical, responsible, and beneficial for all.","link":"https://www.reddit.com/r/MachineLearning/comments/11x837e/dthe_ethical_implications_of_ai/","created":"2023-03-21","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[D]The Ethical Implications of AI Greetings, AI enthusiasts! As someone who's deeply engaged with the world of artificial intelligence, I know firsthand how exciting and powerful this technology can be. However, it's important to remember that with great power comes great responsibility. That's why I'm here to talk about the importance of ethical AI.\n\nAs Tim Cook, CEO of Apple, once said, \"Technology should be infused with humanity. It's not something that comes off an assembly line.\" That sentiment is particularly important when it comes to AI, which has the potential to impact so many aspects of our lives. We need to ensure that we're using this technology in a responsible and ethical way, so that we can maximize its benefits while minimizing its potential risks.\n\nSome of the key ethical considerations for using AI include privacy, transparency, inclusivity, safety, and impact. For example, it's essential that AI systems be designed with privacy in mind, and that they be transparent about how they collect and use personal data. It's also important to ensure that AI systems are accessible and beneficial for everyone, regardless of their background or abilities.\n\nAs Joy Buolamwini, founder of the Algorithmic Justice League, has said, \"AI can't be neutral, it reflects the values of those who make it.\" That's why it's important to be vigilant in detecting and addressing bias in AI systems, and ensure that the data used to train them is diverse and representative. We also need to consider the potential impact of AI on society, including the risk of job displacement and the widening of economic inequality.\n\nTo use AI in an ethical and responsible way, we need to stay informed and up-to-date on the latest developments and best practices in the field. There are many resources available to help us learn more about AI ethics, such as academic papers, reports, and online courses. By educating ourselves and staying informed, we can create a culture of ethical AI that benefits everyone.\n\nSo, what can we do to promote ethical AI? Let's start by having an open and honest conversation about the ethical considerations of using this technology. Let's also make sure that we're holding ourselves and others accountable for creating and using AI in an ethical and responsible way. By working together, we can create a brighter future with AI that is ethical, responsible, and beneficial for all.","classes":{"dataset":0.4971001744}}
{"title":"[D] IJCAI 2023 Rebuttal Discussion","description":"Title","link":"https://www.reddit.com/r/MachineLearning/comments/11w8x8d/d_ijcai_2023_rebuttal_discussion/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":23},"text":"[D] IJCAI 2023 Rebuttal Discussion Title","classes":{"dataset":0.3056464791}}
{"title":"Smarty-GPT: wrapper of prompts/contexts [P]","description":"This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers in a **TRANSPARENT** way to end users.\n\n[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)","link":"https://www.reddit.com/r/MachineLearning/comments/11whc0s/smartygpt_wrapper_of_promptscontexts_p/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":2},"text":"Smarty-GPT: wrapper of prompts/contexts [P] This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers in a **TRANSPARENT** way to end users.\n\n[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)","classes":{"dataset":0.3500056267}}
{"title":"[D] For those who have worked 5+ years in the field, what are you up to now?","description":"Hey,I've  been working in ML for the last 5-10 years, almost since deep learning  came up, mostly startups with various successes, sometimes doing more research sometimes doing more engineering tasks.\n\nThis year I was excited to manage a team focused on ML but plans have just changed in my company and this isn't going to happen anytime soon. I am interviewing for another company for a \"senior\"  role but they still ask me to do this basic ML assignment that takes a  few hours to complete. I have just realised how boring it became to me  to the point I don't even want to do it as I literally have done this  for the last 5+ years.\n\nFor those  who have been in the field for at least 5+ years, what are you up to now? Are you still doing ML? Have you moved into management? Have you started your own company? Moved to a different subfield perhaps?\n\nPS: I  have a PhD, in addition to those years of experience i mention. I am  aware this isn't related to ML purely but more like mid-career crisis,  but would be interested to know how people in the field have dealt with  it.","link":"https://www.reddit.com/r/MachineLearning/comments/11vygjb/d_for_those_who_have_worked_5_years_in_the_field/","created":"2023-03-19","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":7},"text":"[D] For those who have worked 5+ years in the field, what are you up to now? Hey,I've  been working in ML for the last 5-10 years, almost since deep learning  came up, mostly startups with various successes, sometimes doing more research sometimes doing more engineering tasks.\n\nThis year I was excited to manage a team focused on ML but plans have just changed in my company and this isn't going to happen anytime soon. I am interviewing for another company for a \"senior\"  role but they still ask me to do this basic ML assignment that takes a  few hours to complete. I have just realised how boring it became to me  to the point I don't even want to do it as I literally have done this  for the last 5+ years.\n\nFor those  who have been in the field for at least 5+ years, what are you up to now? Are you still doing ML? Have you moved into management? Have you started your own company? Moved to a different subfield perhaps?\n\nPS: I  have a PhD, in addition to those years of experience i mention. I am  aware this isn't related to ML purely but more like mid-career crisis,  but would be interested to know how people in the field have dealt with  it.","classes":{"dataset":0.30114308}}
{"title":"Translate a meeting","description":"Hi Everyone,\n\nI need to translate a recording of a meeting of 2 hours where Dutch and French are spoken. I speak Dutch but I don't speak French. What is the best voice translator for longer spoken texts? Does anyone have tips?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11wh2zm/translate_a_meeting/","created":"2023-03-20","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"Translate a meeting Hi Everyone,\n\nI need to translate a recording of a meeting of 2 hours where Dutch and French are spoken. I speak Dutch but I don't speak French. What is the best voice translator for longer spoken texts? Does anyone have tips?","classes":{"dataset":0.3901901245}}
{"title":"Modern Topic Modeling/Discovery","description":"I was wondering what are the modern techniques for topic discovery for short and long text. It seems this topic to be slower advancing compared to the rest. I am aware of bertopic but tbh I always have issues finetuning it. \n\nOn a second thought I was thinking to use qna/chat gpt models in order to generate models, so I wanted to ask your opinion on some potential prompts that I could use. Essentially  a bit of brainstorming. I will open source all the gathered ideas along with mine and share the link here :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11vwtn3/modern_topic_modelingdiscovery/","created":"2023-03-19","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":1},"text":"Modern Topic Modeling/Discovery I was wondering what are the modern techniques for topic discovery for short and long text. It seems this topic to be slower advancing compared to the rest. I am aware of bertopic but tbh I always have issues finetuning it. \n\nOn a second thought I was thinking to use qna/chat gpt models in order to generate models, so I wanted to ask your opinion on some potential prompts that I could use. Essentially  a bit of brainstorming. I will open source all the gathered ideas along with mine and share the link here :)","classes":{"dataset":0.4441192448}}
{"title":"Are pre-trained word embeddings (word2vec, glove, fasttext) obsolete now? given wide use of pre-trained languages models like bert etc","description":"","link":"https://www.reddit.com/r/LanguageTechnology/comments/11vav4y/are_pretrained_word_embeddings_word2vec_glove/","created":"2023-03-19","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":21},"text":"Are pre-trained word embeddings (word2vec, glove, fasttext) obsolete now? given wide use of pre-trained languages models like bert etc ","classes":{"dataset":0.1066711992}}
{"title":"Database Technology Evolution","description":"This paper reviews suggestions for changes to database technology coming from the work of many researchers, particularly those working with evolving big data. We discuss new approaches to remote data access and standards that better provide for durability and auditability in settings including business and scientific computing. We propose ways in which the language standards could evolve, with proof-of-concept implementations on Github.","link":"http://arxiv.org/abs/2303.11748v1","created":"2023-03-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Database Technology Evolution This paper reviews suggestions for changes to database technology coming from the work of many researchers, particularly those working with evolving big data. We discuss new approaches to remote data access and standards that better provide for durability and auditability in settings including business and scientific computing. We propose ways in which the language standards could evolve, with proof-of-concept implementations on Github.","classes":{"dataset":0.203396678}}
{"title":"Simple Yet Effective Synthetic Dataset Construction for Unsupervised Opinion Summarization","description":"Opinion summarization provides an important solution for summarizing opinions expressed among a large number of reviews. However, generating aspect-specific and general summaries is challenging due to the lack of annotated data. In this work, we propose two simple yet effective unsupervised approaches to generate both aspect-specific and general opinion summaries by training on synthetic datasets constructed with aspect-related review contents. Our first approach, Seed Words Based Leave-One-Out (SW-LOO), identifies aspect-related portions of reviews simply by exact-matching aspect seed words and outperforms existing methods by 3.4 ROUGE-L points on SPACE and 0.5 ROUGE-1 point on OPOSUM+ for aspect-specific opinion summarization. Our second approach, Natural Language Inference Based Leave-One-Out (NLI-LOO) identifies aspect-related sentences utilizing an NLI model in a more general setting without using seed words and outperforms existing approaches by 1.2 ROUGE-L points on SPACE for aspect-specific opinion summarization and remains competitive on other metrics.","link":"http://arxiv.org/abs/2303.11660v1","created":"2023-03-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Simple Yet Effective Synthetic Dataset Construction for Unsupervised Opinion Summarization Opinion summarization provides an important solution for summarizing opinions expressed among a large number of reviews. However, generating aspect-specific and general summaries is challenging due to the lack of annotated data. In this work, we propose two simple yet effective unsupervised approaches to generate both aspect-specific and general opinion summaries by training on synthetic datasets constructed with aspect-related review contents. Our first approach, Seed Words Based Leave-One-Out (SW-LOO), identifies aspect-related portions of reviews simply by exact-matching aspect seed words and outperforms existing methods by 3.4 ROUGE-L points on SPACE and 0.5 ROUGE-1 point on OPOSUM+ for aspect-specific opinion summarization. Our second approach, Natural Language Inference Based Leave-One-Out (NLI-LOO) identifies aspect-related sentences utilizing an NLI model in a more general setting without using seed words and outperforms existing approaches by 1.2 ROUGE-L points on SPACE for aspect-specific opinion summarization and remains competitive on other metrics.","classes":{"dataset":0.1918995827}}
{"title":"Revolutionizing Modern Networks: Advances in AI, Machine Learning, and Blockchain for Quantum Satellites and UAV-based Communication","description":"Quantum communication is the most secure technique of transmitting data available today. Fiber communication lines and satellite-to-ground links have served as the basis for the most successful quantum networks that have been developed so far. Using a UAV, satellite or both for free-space quantum communication reduces the need for permanent ground connections and takes advantage of the lower loss limit in space, which makes it more efficient. This work surveys the recent development in Quantum Satellites and Quantum UAVs-based networks. Here, the importance of the latest technologies, including quantum artificial intelligence, blockchain quantum machine learning, quantum satellites and quantum UAVs, are explored from network perspectives. Further, this work discussed the role of satellite-based images and artificial intelligence.","link":"http://arxiv.org/abs/2303.11753v1","created":"2023-03-21","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Revolutionizing Modern Networks: Advances in AI, Machine Learning, and Blockchain for Quantum Satellites and UAV-based Communication Quantum communication is the most secure technique of transmitting data available today. Fiber communication lines and satellite-to-ground links have served as the basis for the most successful quantum networks that have been developed so far. Using a UAV, satellite or both for free-space quantum communication reduces the need for permanent ground connections and takes advantage of the lower loss limit in space, which makes it more efficient. This work surveys the recent development in Quantum Satellites and Quantum UAVs-based networks. Here, the importance of the latest technologies, including quantum artificial intelligence, blockchain quantum machine learning, quantum satellites and quantum UAVs, are explored from network perspectives. Further, this work discussed the role of satellite-based images and artificial intelligence.","classes":{"dataset":0.0818362534}}
{"title":"STDLens: Model Hijacking-resilient Federated Learning for Object Detection","description":"Federated Learning (FL) has been gaining popularity as a collaborative learning framework to train deep learning-based object detection models over a distributed population of clients. Despite its advantages, FL is vulnerable to model hijacking. The attacker can control how the object detection system should misbehave by implanting Trojaned gradients using only a small number of compromised clients in the collaborative learning process. This paper introduces STDLens, a principled approach to safeguarding FL against such attacks. We first investigate existing mitigation mechanisms and analyze their failures caused by the inherent errors in spatial clustering analysis on gradients. Based on the insights, we introduce a three-tier forensic framework to identify and expel Trojaned gradients and reclaim the performance over the course of FL. We consider three types of adaptive attacks and demonstrate the robustness of STDLens against advanced adversaries. Extensive experiments show that STDLens can protect FL against different model hijacking attacks and outperform existing methods in identifying and removing Trojaned gradients with significantly higher precision and much lower false-positive rates.","link":"http://arxiv.org/abs/2303.11511v1","created":"2023-03-21","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"STDLens: Model Hijacking-resilient Federated Learning for Object Detection Federated Learning (FL) has been gaining popularity as a collaborative learning framework to train deep learning-based object detection models over a distributed population of clients. Despite its advantages, FL is vulnerable to model hijacking. The attacker can control how the object detection system should misbehave by implanting Trojaned gradients using only a small number of compromised clients in the collaborative learning process. This paper introduces STDLens, a principled approach to safeguarding FL against such attacks. We first investigate existing mitigation mechanisms and analyze their failures caused by the inherent errors in spatial clustering analysis on gradients. Based on the insights, we introduce a three-tier forensic framework to identify and expel Trojaned gradients and reclaim the performance over the course of FL. We consider three types of adaptive attacks and demonstrate the robustness of STDLens against advanced adversaries. Extensive experiments show that STDLens can protect FL against different model hijacking attacks and outperform existing methods in identifying and removing Trojaned gradients with significantly higher precision and much lower false-positive rates.","classes":{"dataset":0.0543797724}}
{"title":"Artificial muses: Generative Artificial Intelligence Chatbots Have Risen to Human-Level Creativity","description":"A widespread view is that Artificial Intelligence cannot be creative. We tested this assumption by comparing human-generated ideas with those generated by six Generative Artificial Intelligence (GAI) chatbots: alpa.ai, Copy.ai, ChatGPT (versions 3 and 4), Studio.ai, and YouChat. Humans and a specifically trained AI independently assessed the quality and quantity of ideas. We found no qualitative difference between AI and human-generated creativity, although there are differences in how ideas are generated. Interestingly, 9.4 percent of humans were more creative than the most creative GAI, GPT-4. Our findings suggest that GAIs are valuable assistants in the creative process. Continued research and development of GAI in creative tasks is crucial to fully understand this technology's potential benefits and drawbacks in shaping the future of creativity. Finally, we discuss the question of whether GAIs are capable of being truly creative.","link":"http://arxiv.org/abs/2303.12003v1","created":"2023-03-21","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Artificial muses: Generative Artificial Intelligence Chatbots Have Risen to Human-Level Creativity A widespread view is that Artificial Intelligence cannot be creative. We tested this assumption by comparing human-generated ideas with those generated by six Generative Artificial Intelligence (GAI) chatbots: alpa.ai, Copy.ai, ChatGPT (versions 3 and 4), Studio.ai, and YouChat. Humans and a specifically trained AI independently assessed the quality and quantity of ideas. We found no qualitative difference between AI and human-generated creativity, although there are differences in how ideas are generated. Interestingly, 9.4 percent of humans were more creative than the most creative GAI, GPT-4. Our findings suggest that GAIs are valuable assistants in the creative process. Continued research and development of GAI in creative tasks is crucial to fully understand this technology's potential benefits and drawbacks in shaping the future of creativity. Finally, we discuss the question of whether GAIs are capable of being truly creative.","classes":{"dataset":0.4508912563}}
{"title":"A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?","description":"As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to analyze and create text, images, and beyond. With such overwhelming media coverage, it is almost impossible for us to miss the opportunity to glimpse AIGC from a certain angle. In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks. Impressed by the capability of the ChatGPT, many people are wondering about its limits: can GPT-5 (or other future GPT variants) help ChatGPT unify all AIGC tasks for diversified content creation? Toward answering this question, a comprehensive review of existing AIGC tasks is needed. As such, our work comes to fill this gap promptly by offering a first look at AIGC, ranging from its techniques to applications. Modern generative AI relies on various technical foundations, ranging from model architecture and self-supervised pretraining to generative modeling methods (like GAN and diffusion models). After introducing the fundamental techniques, this work focuses on the technological development of various AIGC tasks based on their output type, including text, images, videos, 3D content, etc., which depicts the full potential of ChatGPT's future. Moreover, we summarize their significant applications in some mainstream industries, such as education and creativity content. Finally, we discuss the challenges currently faced and present an outlook on how generative AI might evolve in the near future.","link":"http://arxiv.org/abs/2303.11717v1","created":"2023-03-21","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to analyze and create text, images, and beyond. With such overwhelming media coverage, it is almost impossible for us to miss the opportunity to glimpse AIGC from a certain angle. In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks. Impressed by the capability of the ChatGPT, many people are wondering about its limits: can GPT-5 (or other future GPT variants) help ChatGPT unify all AIGC tasks for diversified content creation? Toward answering this question, a comprehensive review of existing AIGC tasks is needed. As such, our work comes to fill this gap promptly by offering a first look at AIGC, ranging from its techniques to applications. Modern generative AI relies on various technical foundations, ranging from model architecture and self-supervised pretraining to generative modeling methods (like GAN and diffusion models). After introducing the fundamental techniques, this work focuses on the technological development of various AIGC tasks based on their output type, including text, images, videos, 3D content, etc., which depicts the full potential of ChatGPT's future. Moreover, we summarize their significant applications in some mainstream industries, such as education and creativity content. Finally, we discuss the challenges currently faced and present an outlook on how generative AI might evolve in the near future.","classes":{"dataset":0.2420537472}}
{"title":"Personalized Lightweight Text-to-Speech: Voice Cloning with Adaptive Structured Pruning","description":"Personalized TTS is an exciting and highly desired application that allows users to train their TTS voice using only a few recordings. However, TTS training typically requires many hours of recording and a large model, making it unsuitable for deployment on mobile devices. To overcome this limitation, related works typically require fine-tuning a pre-trained TTS model to preserve its ability to generate high-quality audio samples while adapting to the target speaker's voice. This process is commonly referred to as ``voice cloning.'' Although related works have achieved significant success in changing the TTS model's voice, they are still required to fine-tune from a large pre-trained model, resulting in a significant size for the voice-cloned model. In this paper, we propose applying trainable structured pruning to voice cloning. By training the structured pruning masks with voice-cloning data, we can produce a unique pruned model for each target speaker. Our experiments demonstrate that using learnable structured pruning, we can compress the model size to 7 times smaller while achieving comparable voice-cloning performance.","link":"http://arxiv.org/abs/2303.11816v1","created":"2023-03-21","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Personalized Lightweight Text-to-Speech: Voice Cloning with Adaptive Structured Pruning Personalized TTS is an exciting and highly desired application that allows users to train their TTS voice using only a few recordings. However, TTS training typically requires many hours of recording and a large model, making it unsuitable for deployment on mobile devices. To overcome this limitation, related works typically require fine-tuning a pre-trained TTS model to preserve its ability to generate high-quality audio samples while adapting to the target speaker's voice. This process is commonly referred to as ``voice cloning.'' Although related works have achieved significant success in changing the TTS model's voice, they are still required to fine-tune from a large pre-trained model, resulting in a significant size for the voice-cloned model. In this paper, we propose applying trainable structured pruning to voice cloning. By training the structured pruning masks with voice-cloning data, we can produce a unique pruned model for each target speaker. Our experiments demonstrate that using learnable structured pruning, we can compress the model size to 7 times smaller while achieving comparable voice-cloning performance.","classes":{"dataset":0.1809323579}}
{"title":"Task-based Generation of Optimized Projection Sets using Differentiable Ranking","description":"We present a method for selecting valuable projections in computed tomography (CT) scans to enhance image reconstruction and diagnosis. The approach integrates two important factors, projection-based detectability and data completeness, into a single feed-forward neural network. The network evaluates the value of projections, processes them through a differentiable ranking function and makes the final selection using a straight-through estimator. Data completeness is ensured through the label provided during training. The approach eliminates the need for heuristically enforcing data completeness, which may exclude valuable projections. The method is evaluated on simulated data in a non-destructive testing scenario, where the aim is to maximize the reconstruction quality within a specified region of interest. We achieve comparable results to previous methods, laying the foundation for using reconstruction-based loss functions to learn the selection of projections.","link":"http://arxiv.org/abs/2303.11724v1","created":"2023-03-21","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Task-based Generation of Optimized Projection Sets using Differentiable Ranking We present a method for selecting valuable projections in computed tomography (CT) scans to enhance image reconstruction and diagnosis. The approach integrates two important factors, projection-based detectability and data completeness, into a single feed-forward neural network. The network evaluates the value of projections, processes them through a differentiable ranking function and makes the final selection using a straight-through estimator. Data completeness is ensured through the label provided during training. The approach eliminates the need for heuristically enforcing data completeness, which may exclude valuable projections. The method is evaluated on simulated data in a non-destructive testing scenario, where the aim is to maximize the reconstruction quality within a specified region of interest. We achieve comparable results to previous methods, laying the foundation for using reconstruction-based loss functions to learn the selection of projections.","classes":{"dataset":0.2420537472}}
{"title":"SpikeCV: Open a Continuous Computer Vision Era","description":"SpikeCV is a new open-source computer vision platform for the spike camera, which is a neuromorphic visual sensor that has developed rapidly in recent years. In the spike camera, each pixel position directly accumulates the light intensity and asynchronously fires spikes. The output binary spikes can reach a frequency of 40,000 Hz. As a new type of visual expression, spike sequence has high spatiotemporal completeness and preserves the continuous visual information of the external world. Taking advantage of the low latency and high dynamic range of the spike camera, many spike-based algorithms have made significant progress, such as high-quality imaging and ultra-high-speed target detection.   To build up a community ecology for the spike vision to facilitate more users to take advantage of the spike camera, SpikeCV provides a variety of ultra-high-speed scene datasets, hardware interfaces, and an easy-to-use modules library. SpikeCV focuses on encapsulation for spike data, standardization for dataset interfaces, modularization for vision tasks, and real-time applications for challenging scenes. With the advent of the open-source Python ecosystem, modules of SpikeCV can be used as a Python library to fulfilled most of the numerical analysis needs of researchers. We demonstrate the efficiency of the SpikeCV on offline inference and real-time applications. The project repository address are \\url{https://openi.pcl.ac.cn/Cordium/SpikeCV} and \\url{https://github.com/Zyj061/SpikeCV","link":"http://arxiv.org/abs/2303.11684v1","created":"2023-03-21","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"SpikeCV: Open a Continuous Computer Vision Era SpikeCV is a new open-source computer vision platform for the spike camera, which is a neuromorphic visual sensor that has developed rapidly in recent years. In the spike camera, each pixel position directly accumulates the light intensity and asynchronously fires spikes. The output binary spikes can reach a frequency of 40,000 Hz. As a new type of visual expression, spike sequence has high spatiotemporal completeness and preserves the continuous visual information of the external world. Taking advantage of the low latency and high dynamic range of the spike camera, many spike-based algorithms have made significant progress, such as high-quality imaging and ultra-high-speed target detection.   To build up a community ecology for the spike vision to facilitate more users to take advantage of the spike camera, SpikeCV provides a variety of ultra-high-speed scene datasets, hardware interfaces, and an easy-to-use modules library. SpikeCV focuses on encapsulation for spike data, standardization for dataset interfaces, modularization for vision tasks, and real-time applications for challenging scenes. With the advent of the open-source Python ecosystem, modules of SpikeCV can be used as a Python library to fulfilled most of the numerical analysis needs of researchers. We demonstrate the efficiency of the SpikeCV on offline inference and real-time applications. The project repository address are \\url{https://openi.pcl.ac.cn/Cordium/SpikeCV} and \\url{https://github.com/Zyj061/SpikeCV","classes":{"dataset":0.2732121944}}
{"title":"Coarse-to-Fine Active Segmentation of Interactable Parts in Real Scene Images","description":"We introduce the first active learning (AL) framework for high-accuracy instance segmentation of dynamic, interactable parts from RGB images of real indoor scenes. As with most human-in-the-loop approaches, the key criterion for success in AL is to minimize human effort while still attaining high performance. To this end, we employ a transformer-based segmentation network that utilizes a masked-attention mechanism. To enhance the network, tailoring to our task, we introduce a coarse-to-fine model which first uses object-aware masked attention and then a pose-aware one, leveraging a correlation between interactable parts and object poses and leading to improved handling of multiple articulated objects in an image. Our coarse-to-fine active segmentation module learns both 2D instance and 3D pose information using the transformer, which supervises the active segmentation and effectively reduces human effort. Our method achieves close to fully accurate (96% and higher) segmentation results on real images, with 77% time saving over manual effort, where the training data consists of only 16.6% annotated real photographs. At last, we contribute a dataset of 2,550 real photographs with annotated interactable parts, demonstrating its superior quality and diversity over the current best alternative.","link":"http://arxiv.org/abs/2303.11530v1","created":"2023-03-21","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Coarse-to-Fine Active Segmentation of Interactable Parts in Real Scene Images We introduce the first active learning (AL) framework for high-accuracy instance segmentation of dynamic, interactable parts from RGB images of real indoor scenes. As with most human-in-the-loop approaches, the key criterion for success in AL is to minimize human effort while still attaining high performance. To this end, we employ a transformer-based segmentation network that utilizes a masked-attention mechanism. To enhance the network, tailoring to our task, we introduce a coarse-to-fine model which first uses object-aware masked attention and then a pose-aware one, leveraging a correlation between interactable parts and object poses and leading to improved handling of multiple articulated objects in an image. Our coarse-to-fine active segmentation module learns both 2D instance and 3D pose information using the transformer, which supervises the active segmentation and effectively reduces human effort. Our method achieves close to fully accurate (96% and higher) segmentation results on real images, with 77% time saving over manual effort, where the training data consists of only 16.6% annotated real photographs. At last, we contribute a dataset of 2,550 real photographs with annotated interactable parts, demonstrating its superior quality and diversity over the current best alternative.","classes":{"dataset":0.3496097624}}
{"title":"ICASSP 2023 Deep Speech Enhancement Challenge","description":"Deep Speech Enhancement Challenge is the 5th edition of deep noise suppression (DNS) challenges organized at ICASSP 2023 Signal Processing Grand Challenges. DNS challenges were organized during 2019-2023 to stimulate research in deep speech enhancement (DSE). Previous DNS challenges were organized at INTERSPEECH 2020, ICASSP 2021, INTERSPEECH 2021, and ICASSP 2022. From prior editions, we learnt that improving signal quality (SIG) is challenging particularly in presence of simultaneously active interfering talkers and noise. This challenge aims to develop models for joint denosing, dereverberation and suppression of interfering talkers. When primary talker wears a headphone, certain acoustic properties of their speech such as direct-to-reverberation (DRR), signal to noise ratio (SNR) etc. make it possible to suppress neighboring talkers even without enrollment data for primary talker. This motivated us to create two tracks for this challenge: (i) Track-1 Headset; (ii) Track-2 Speakerphone. Both tracks has fullband (48kHz) training data and testset, and each testclips has a corresponding enrollment data (10-30s duration) for primary talker. Each track invited submissions of personalized and non-personalized models all of which are evaluated through same subjective evaluation. Most models submitted to challenge were personalized models, same team is winner in both tracks where the best models has improvement of 0.145 and 0.141 in challenge's Score as compared to noisy blind testset.","link":"http://arxiv.org/abs/2303.11510v1","created":"2023-03-21","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"ICASSP 2023 Deep Speech Enhancement Challenge Deep Speech Enhancement Challenge is the 5th edition of deep noise suppression (DNS) challenges organized at ICASSP 2023 Signal Processing Grand Challenges. DNS challenges were organized during 2019-2023 to stimulate research in deep speech enhancement (DSE). Previous DNS challenges were organized at INTERSPEECH 2020, ICASSP 2021, INTERSPEECH 2021, and ICASSP 2022. From prior editions, we learnt that improving signal quality (SIG) is challenging particularly in presence of simultaneously active interfering talkers and noise. This challenge aims to develop models for joint denosing, dereverberation and suppression of interfering talkers. When primary talker wears a headphone, certain acoustic properties of their speech such as direct-to-reverberation (DRR), signal to noise ratio (SNR) etc. make it possible to suppress neighboring talkers even without enrollment data for primary talker. This motivated us to create two tracks for this challenge: (i) Track-1 Headset; (ii) Track-2 Speakerphone. Both tracks has fullband (48kHz) training data and testset, and each testclips has a corresponding enrollment data (10-30s duration) for primary talker. Each track invited submissions of personalized and non-personalized models all of which are evaluated through same subjective evaluation. Most models submitted to challenge were personalized models, same team is winner in both tracks where the best models has improvement of 0.145 and 0.141 in challenge's Score as compared to noisy blind testset.","classes":{"dataset":0.1964847445}}
{"title":"Show HN: Finetune LLaMA-7B on commodity GPUs using your own text","description":"https://github.com/lxe/simple-llama-finetuner","link":"https://github.com/lxe/simple-llama-finetuner","created":"2023-03-22","tags":["hackernews"],"meta":{"score":241},"text":"Show HN: Finetune LLaMA-7B on commodity GPUs using your own text https://github.com/lxe/simple-llama-finetuner","classes":{"dataset":0.5446178317}}
{"title":"2023 Turing Award Given to Bob Metcalfe for Invention of Ethernet","description":"https://amturing.acm.org/?2023","link":"https://amturing.acm.org/?2023","created":"2023-03-22","tags":["hackernews"],"meta":{"score":5},"text":"2023 Turing Award Given to Bob Metcalfe for Invention of Ethernet https://amturing.acm.org/?2023","classes":{"dataset":0.4808260202}}
{"title":"Pg_jsonschema \u2013 JSON Schema Support for Postgres","description":"https://supabase.com/blog/pg-jsonschema-a-postgres-extension-for-json-validation","link":"https://supabase.com/blog/pg-jsonschema-a-postgres-extension-for-json-validation","created":"2023-03-22","tags":["hackernews"],"meta":{"score":26},"text":"Pg_jsonschema \u2013 JSON Schema Support for Postgres https://supabase.com/blog/pg-jsonschema-a-postgres-extension-for-json-validation","classes":{"dataset":0.5152043104}}
{"title":"America\u2019s banks are missing hundreds of billions of dollars","description":"https://www.economist.com/finance-and-economics/2023/03/21/americas-banks-are-missing-hundreds-of-billions-of-dollars","link":"https://www.economist.com/finance-and-economics/2023/03/21/americas-banks-are-missing-hundreds-of-billions-of-dollars","created":"2023-03-21","tags":["hackernews"],"meta":{"score":178},"text":"America\u2019s banks are missing hundreds of billions of dollars https://www.economist.com/finance-and-economics/2023/03/21/americas-banks-are-missing-hundreds-of-billions-of-dollars","classes":{"dataset":0.5107240081}}
{"title":"Hyundai promises to keep buttons in cars","description":"https://www.thedrive.com/news/hyundai-promises-to-keep-buttons-in-cars-because-touchscreen-controls-are-dangerous","link":"https://www.thedrive.com/news/hyundai-promises-to-keep-buttons-in-cars-because-touchscreen-controls-are-dangerous","created":"2023-03-21","tags":["hackernews"],"meta":{"score":538},"text":"Hyundai promises to keep buttons in cars https://www.thedrive.com/news/hyundai-promises-to-keep-buttons-in-cars-because-touchscreen-controls-are-dangerous","classes":{"dataset":0.5414594412}}
{"title":"A ChatGPT Emacs Shell","description":"https://xenodium.com/a-chatgpt-emacs-shell/","link":"https://xenodium.com/a-chatgpt-emacs-shell/","created":"2023-03-21","tags":["hackernews"],"meta":{"score":89},"text":"A ChatGPT Emacs Shell https://xenodium.com/a-chatgpt-emacs-shell/","classes":{"dataset":0.4843292534}}
{"title":"Adobe Firefly: AI Art Generator","description":"https://www.adobe.com/sensei/generative-ai/firefly.html","link":"https://www.adobe.com/sensei/generative-ai/firefly.html","created":"2023-03-21","tags":["hackernews"],"meta":{"score":804},"text":"Adobe Firefly: AI Art Generator https://www.adobe.com/sensei/generative-ai/firefly.html","classes":{"dataset":0.5038765073}}
{"title":"Errors and Zig","description":"https://notes.eatonphil.com/errors-and-zig.html","link":"https://notes.eatonphil.com/errors-and-zig.html","created":"2023-03-22","tags":["hackernews"],"meta":{"score":47},"text":"Errors and Zig https://notes.eatonphil.com/errors-and-zig.html","classes":{"dataset":0.5226869583}}
{"title":"Grace Hopper on Late Night with David Letterman (1986) [video]","description":"https://www.youtube.com/watch?v=oE2uls6iIEU","link":"https://www.youtube.com/watch?v=oE2uls6iIEU","created":"2023-03-21","tags":["hackernews"],"meta":{"score":196},"text":"Grace Hopper on Late Night with David Letterman (1986) [video] https://www.youtube.com/watch?v=oE2uls6iIEU","classes":{"dataset":0.5145715475}}
{"title":"Shields Up","description":"https://seths.blog/2023/03/shields-up-2/","link":"https://seths.blog/2023/03/shields-up-2/","created":"2023-03-21","tags":["hackernews"],"meta":{"score":261},"text":"Shields Up https://seths.blog/2023/03/shields-up-2/","classes":{"dataset":0.4878529608}}
{"title":"Bard uses a Hacker News comment as source to say that Bard has shut down","description":"https://twitter.com/juanbuis/status/1638289186351456257","link":"https://twitter.com/juanbuis/status/1638289186351456257","created":"2023-03-22","tags":["hackernews"],"meta":{"score":398},"text":"Bard uses a Hacker News comment as source to say that Bard has shut down https://twitter.com/juanbuis/status/1638289186351456257","classes":{"dataset":0.4833174348}}
{"title":"An off-kilter visionary: Henry Green had a strange and distinctive talent","description":"https://thecritic.co.uk/issues/march-2023/an-off-kilter-visionary/","link":"https://thecritic.co.uk/issues/march-2023/an-off-kilter-visionary/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":29},"text":"An off-kilter visionary: Henry Green had a strange and distinctive talent https://thecritic.co.uk/issues/march-2023/an-off-kilter-visionary/","classes":{"dataset":0.5117892623}}
{"title":"Your website's content -> Q&A bot / chatbot","description":"https://github.com/mpaepper/content-chatbot","link":"https://github.com/mpaepper/content-chatbot","created":"2023-03-21","tags":["hackernews"],"meta":{"score":64},"text":"Your website's content -> Q&A bot / chatbot https://github.com/mpaepper/content-chatbot","classes":{"dataset":0.470431596}}
{"title":"Etleap (YC W13) is hiring back end developers in London \u2013 50% remote","description":"https://etleap.com/careers/software-engineer/","link":"https://etleap.com/careers/software-engineer/","created":"2023-03-21","tags":["hackernews"],"meta":{"score":1},"text":"Etleap (YC W13) is hiring back end developers in London \u2013 50% remote https://etleap.com/careers/software-engineer/","classes":{"dataset":0.4604782462}}
{"title":"Java 20 / JDK 20: General Availability","description":"https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007517.html","link":"https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007517.html","created":"2023-03-21","tags":["hackernews"],"meta":{"score":279},"text":"Java 20 / JDK 20: General Availability https://mail.openjdk.org/pipermail/jdk-dev/2023-March/007517.html","classes":{"dataset":0.4902126491}}
{"title":"Bard is much worse at puzzle solving than ChatGPT","description":"https://twofergoofer.com/blog/bard","link":"https://twofergoofer.com/blog/bard","created":"2023-03-22","tags":["hackernews"],"meta":{"score":77},"text":"Bard is much worse at puzzle solving than ChatGPT https://twofergoofer.com/blog/bard","classes":{"dataset":0.5088258982}}
{"title":"Surprise computer science proof in combinatorics","description":"https://www.quantamagazine.org/surprise-computer-science-proof-stuns-mathematicians-20230321/","link":"https://www.quantamagazine.org/surprise-computer-science-proof-stuns-mathematicians-20230321/","created":"2023-03-21","tags":["hackernews"],"meta":{"score":254},"text":"Surprise computer science proof in combinatorics https://www.quantamagazine.org/surprise-computer-science-proof-stuns-mathematicians-20230321/","classes":{"dataset":0.5170680285}}
{"title":"TikTok is a threat. So is the rest of Big Tech","description":"https://techoversight.org/2023/03/20/memo-tiktok-is-a-threat-so-is-the-rest-of-big-tech/","link":"https://techoversight.org/2023/03/20/memo-tiktok-is-a-threat-so-is-the-rest-of-big-tech/","created":"2023-03-21","tags":["hackernews"],"meta":{"score":25},"text":"TikTok is a threat. So is the rest of Big Tech https://techoversight.org/2023/03/20/memo-tiktok-is-a-threat-so-is-the-rest-of-big-tech/","classes":{"dataset":0.5359835029}}
{"title":"Show HN: Public transportation signage based on bloom filters (rough mockup)","description":"https://github.com/jsvan/BusStopBloomfilter","link":"https://github.com/jsvan/BusStopBloomfilter","created":"2023-03-21","tags":["hackernews"],"meta":{"score":117},"text":"Show HN: Public transportation signage based on bloom filters (rough mockup) https://github.com/jsvan/BusStopBloomfilter","classes":{"dataset":0.4929317534}}
{"title":"Interview with Sten \u201cZTN\u201d Uusvali","description":"https://www.quakehaus.com/news/9628/interview-with-sten-ztn-uusvali/","link":"https://www.quakehaus.com/news/9628/interview-with-sten-ztn-uusvali/","created":"2023-03-19","tags":["hackernews"],"meta":{"score":10},"text":"Interview with Sten \u201cZTN\u201d Uusvali https://www.quakehaus.com/news/9628/interview-with-sten-ztn-uusvali/","classes":{"dataset":0.5427727103}}
{"title":"Windows Snipping Tool is vulnerable to Acropalypse too","description":"https://twitter.com/David3141593/status/1638222624084951040","link":"https://twitter.com/David3141593/status/1638222624084951040","created":"2023-03-21","tags":["hackernews"],"meta":{"score":286},"text":"Windows Snipping Tool is vulnerable to Acropalypse too https://twitter.com/David3141593/status/1638222624084951040","classes":{"dataset":0.5118699074}}
{"title":"Reddit Releases Post Mortem for Its 3 Hour Outage Last Week","description":"https://old.reddit.com/r/RedditEng/comments/11xx5o0/you_broke_reddit_the_piday_outage/","link":"https://old.reddit.com/r/RedditEng/comments/11xx5o0/you_broke_reddit_the_piday_outage/","created":"2023-03-22","tags":["hackernews"],"meta":{"score":62},"text":"Reddit Releases Post Mortem for Its 3 Hour Outage Last Week https://old.reddit.com/r/RedditEng/comments/11xx5o0/you_broke_reddit_the_piday_outage/","classes":{"dataset":0.4975517988}}
{"title":"GOOD Meat gets green light from FDA for cultivated meat","description":"https://agfundernews.com/good-meat-gets-green-light-from-fda-for-cultivated-meat","link":"https://agfundernews.com/good-meat-gets-green-light-from-fda-for-cultivated-meat","created":"2023-03-21","tags":["hackernews"],"meta":{"score":101},"text":"GOOD Meat gets green light from FDA for cultivated meat https://agfundernews.com/good-meat-gets-green-light-from-fda-for-cultivated-meat","classes":{"dataset":0.4973191321}}
{"title":"Amazon is shutting down DPReview, the go-to camera reviews website","description":"https://www.theverge.com/2023/3/21/23650286/amazon-dpreview-camera-site-shutdown-layoffs","link":"https://www.theverge.com/2023/3/21/23650286/amazon-dpreview-camera-site-shutdown-layoffs","created":"2023-03-22","tags":["hackernews"],"meta":{"score":12},"text":"Amazon is shutting down DPReview, the go-to camera reviews website https://www.theverge.com/2023/3/21/23650286/amazon-dpreview-camera-site-shutdown-layoffs","classes":{"dataset":0.5013731718}}
{"title":"CDC warns of \u201calarming\u201d rise of potentially deadly fungal threat in hospitals","description":"https://www.cbsnews.com/news/candida-auris-fungus-alarming-rise-cdc/","link":"https://www.cbsnews.com/news/candida-auris-fungus-alarming-rise-cdc/","created":"2023-03-22","tags":["hackernews"],"meta":{"score":13},"text":"CDC warns of \u201calarming\u201d rise of potentially deadly fungal threat in hospitals https://www.cbsnews.com/news/candida-auris-fungus-alarming-rise-cdc/","classes":{"dataset":0.5381482244}}
{"title":"Show HN: ChatGPT-powered Chatbot yields 3 times more leads and conversions","description":"https://presbot.com/","link":"https://presbot.com/","created":"2023-03-22","tags":["hackernews"],"meta":{"score":6},"text":"Show HN: ChatGPT-powered Chatbot yields 3 times more leads and conversions https://presbot.com/","classes":{"dataset":0.507349968}}
{"title":"Can AI-Generated Text Be Reliably Detected?","description":"https://arxiv.org/abs/2303.11156","link":"https://arxiv.org/abs/2303.11156","created":"2023-03-21","tags":["hackernews"],"meta":{"score":78},"text":"Can AI-Generated Text Be Reliably Detected? https://arxiv.org/abs/2303.11156","classes":{"dataset":0.4894439876}}
{"title":"Avoiding Errors in Demo Day Fundraising","description":"https://blog.aaronkharris.com/avoiding-errors-in-demo-day-fundraising","link":"https://blog.aaronkharris.com/avoiding-errors-in-demo-day-fundraising","created":"2023-03-21","tags":["hackernews"],"meta":{"score":60},"text":"Avoiding Errors in Demo Day Fundraising https://blog.aaronkharris.com/avoiding-errors-in-demo-day-fundraising","classes":{"dataset":0.5329321027}}
{"title":"We Got the Generics We Have (2022)","description":"https://openjdk.org/projects/valhalla/design-notes/in-defense-of-erasure","link":"https://openjdk.org/projects/valhalla/design-notes/in-defense-of-erasure","created":"2023-03-22","tags":["hackernews"],"meta":{"score":3},"text":"We Got the Generics We Have (2022) https://openjdk.org/projects/valhalla/design-notes/in-defense-of-erasure","classes":{"dataset":0.5046291947}}
{"title":"Portable Game Notation Specification and Implementation Guide","description":"http://www.saremba.de/chessgml/standards/pgn/pgn-complete.htm","link":"http://www.saremba.de/chessgml/standards/pgn/pgn-complete.htm","created":"2023-03-21","tags":["hackernews"],"meta":{"score":42},"text":"Portable Game Notation Specification and Implementation Guide http://www.saremba.de/chessgml/standards/pgn/pgn-complete.htm","classes":{"dataset":0.5522673726}}
{"title":"Workarise \u2013 Simplify Your Project Management and Communication","description":"https://workarise.com/","link":"https://workarise.com/","created":"2023-03-22","tags":["hackernews"],"meta":{"score":7},"text":"Workarise \u2013 Simplify Your Project Management and Communication https://workarise.com/","classes":{"dataset":0.5048484802}}
{"title":"Louis Rossmann could sue John Deere for GPL violation [video]","description":"https://www.youtube.com/watch?v=XP7Qx1FF1hA","link":"https://www.youtube.com/watch?v=XP7Qx1FF1hA","created":"2023-03-21","tags":["hackernews"],"meta":{"score":325},"text":"Louis Rossmann could sue John Deere for GPL violation [video] https://www.youtube.com/watch?v=XP7Qx1FF1hA","classes":{"dataset":0.5085482597}}
{"title":"Private opulence, public squalor: How the U.S. helps the rich and hurts the poor","description":"https://text.npr.org/1164275807","link":"https://text.npr.org/1164275807","created":"2023-03-22","tags":["hackernews"],"meta":{"score":16},"text":"Private opulence, public squalor: How the U.S. helps the rich and hurts the poor https://text.npr.org/1164275807","classes":{"dataset":0.5463556647}}
{"title":"Twitter bans a popular French activist and the spokeswoman of the Pirate Party","description":"https://mastodon.social/@dunglas/110065814952481391","link":"https://mastodon.social/@dunglas/110065814952481391","created":"2023-03-22","tags":["hackernews"],"meta":{"score":18},"text":"Twitter bans a popular French activist and the spokeswoman of the Pirate Party https://mastodon.social/@dunglas/110065814952481391","classes":{"dataset":0.5208961368}}
{"title":"GPT-4 Khan Academy in Depth Demo","description":"https://www.youtube.com/watch?v=rnIgnS8Susg","link":"https://www.youtube.com/watch?v=rnIgnS8Susg","created":"2023-03-22","tags":["hackernews"],"meta":{"score":9},"text":"GPT-4 Khan Academy in Depth Demo https://www.youtube.com/watch?v=rnIgnS8Susg","classes":{"dataset":0.5014195442}}
{"title":"Doors I touched today (1999)","description":"https://fluxus.org/FluxusMidwest/doorknobs/","link":"https://fluxus.org/FluxusMidwest/doorknobs/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":316},"text":"Doors I touched today (1999) https://fluxus.org/FluxusMidwest/doorknobs/","classes":{"dataset":0.4930758178}}
{"title":"PeerTube 5.1","description":"https://joinpeertube.org/news/release-5.1","link":"https://joinpeertube.org/news/release-5.1","created":"2023-03-21","tags":["hackernews"],"meta":{"score":145},"text":"PeerTube 5.1 https://joinpeertube.org/news/release-5.1","classes":{"dataset":0.5367159843}}
{"title":"Google Bard Waitlist Parody","description":"https://google-waitlist.vercel.app","link":"https://google-waitlist.vercel.app","created":"2023-03-22","tags":["hackernews"],"meta":{"score":25},"text":"Google Bard Waitlist Parody https://google-waitlist.vercel.app","classes":{"dataset":0.5162983537}}
{"title":"Intel graphics chief Raja Koduri leaves after five years battling Nvidia and AMD","description":"https://www.theverge.com/2023/3/21/23650611/intel-raja-koduri-gpus-amd-nvidia-apple-leave-ai-startup","link":"https://www.theverge.com/2023/3/21/23650611/intel-raja-koduri-gpus-amd-nvidia-apple-leave-ai-startup","created":"2023-03-21","tags":["hackernews"],"meta":{"score":75},"text":"Intel graphics chief Raja Koduri leaves after five years battling Nvidia and AMD https://www.theverge.com/2023/3/21/23650611/intel-raja-koduri-gpus-amd-nvidia-apple-leave-ai-startup","classes":{"dataset":0.4804798961}}
{"title":"SVG Backgrounds","description":"https://www.svgbackgrounds.com/","link":"https://www.svgbackgrounds.com/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":279},"text":"SVG Backgrounds https://www.svgbackgrounds.com/","classes":{"dataset":0.5190555453}}
{"title":"Show HN: Watermelon \u2013 GPT-powered code contextualizer","description":"https://www.watermelontools.com/","link":"https://www.watermelontools.com/","created":"2023-03-21","tags":["hackernews"],"meta":{"score":82},"text":"Show HN: Watermelon \u2013 GPT-powered code contextualizer https://www.watermelontools.com/","classes":{"dataset":0.5286415815}}
{"title":"Show HN: Get a Professional Headshot in Minutes with AI","description":"https://virtualface.app","link":"https://virtualface.app","created":"2023-03-21","tags":["hackernews"],"meta":{"score":141},"text":"Show HN: Get a Professional Headshot in Minutes with AI https://virtualface.app","classes":{"dataset":0.5728718042}}
{"title":"Awesome-totally-open-ChatGPT: A list of open alternatives to ChatGPT","description":"https://github.com/nichtdax/awesome-totally-open-chatgpt","link":"https://github.com/nichtdax/awesome-totally-open-chatgpt","created":"2023-03-21","tags":["hackernews"],"meta":{"score":322},"text":"Awesome-totally-open-ChatGPT: A list of open alternatives to ChatGPT https://github.com/nichtdax/awesome-totally-open-chatgpt","classes":{"dataset":0.5173510909}}
{"title":"'We Were Guinea Pigs': Soldiers Explain What Nuclear Bomb Blasts Feel Like","description":"https://www.vice.com/en/article/wjk3wb/what-does-a-nuclear-bomb-blast-feel-like","link":"https://www.vice.com/en/article/wjk3wb/what-does-a-nuclear-bomb-blast-feel-like","created":"2023-03-22","tags":["hackernews"],"meta":{"score":16},"text":"'We Were Guinea Pigs': Soldiers Explain What Nuclear Bomb Blasts Feel Like https://www.vice.com/en/article/wjk3wb/what-does-a-nuclear-bomb-blast-feel-like","classes":{"dataset":0.5541020036}}
{"title":"Show HN: Pair: Open Tool for Coding with GPTs, Built by Coding with GPTs","description":"https://github.com/jiggy-ai/pair","link":"https://github.com/jiggy-ai/pair","created":"2023-03-21","tags":["hackernews"],"meta":{"score":23},"text":"Show HN: Pair: Open Tool for Coding with GPTs, Built by Coding with GPTs https://github.com/jiggy-ai/pair","classes":{"dataset":0.5328266621}}
{"title":"Reasons Not to Use Google (2015)","description":"https://stallman.org/google.html","link":"https://stallman.org/google.html","created":"2023-03-21","tags":["hackernews"],"meta":{"score":172},"text":"Reasons Not to Use Google (2015) https://stallman.org/google.html","classes":{"dataset":0.504545629}}
{"title":"PyVibe: Generate styled HTML pages from Python","description":"&amp;#x200B;\n\nhttps://preview.redd.it/s9zir6gfh6pa1.png?width=2560&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f3e2bed1ee99d958272d2b579a56d2c5283dee6d\n\nI've been using Tailwind CSS, in particular [Flowbite](https://flowbite.com/), for a number of different Python projects that I was working on and through that process, I realized that I end up either repeating or copying functions that generate UI components.\n\nThat led me to create this Python library to make it easier to use re-use UI components for my Flask applications: [https://www.pyvibe.com/](https://www.pyvibe.com/)\n\n[https://github.com/pycob/pyvibe](https://github.com/pycob/pyvibe)\n\nI wrote it in such a way that it generates an HTML string, so it's usable in Flask, as a static HTML file, or even in Pyodide (which is Python running in the browser via WebAssembly). \n\nLet me know what you think!","link":"https://www.reddit.com/r/Python/comments/11xzbyp/pyvibe_generate_styled_html_pages_from_python/","created":"2023-03-21","tags":["python","reddit"],"meta":{"num_comments":6},"text":"PyVibe: Generate styled HTML pages from Python &amp;#x200B;\n\nhttps://preview.redd.it/s9zir6gfh6pa1.png?width=2560&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=f3e2bed1ee99d958272d2b579a56d2c5283dee6d\n\nI've been using Tailwind CSS, in particular [Flowbite](https://flowbite.com/), for a number of different Python projects that I was working on and through that process, I realized that I end up either repeating or copying functions that generate UI components.\n\nThat led me to create this Python library to make it easier to use re-use UI components for my Flask applications: [https://www.pyvibe.com/](https://www.pyvibe.com/)\n\n[https://github.com/pycob/pyvibe](https://github.com/pycob/pyvibe)\n\nI wrote it in such a way that it generates an HTML string, so it's usable in Flask, as a static HTML file, or even in Pyodide (which is Python running in the browser via WebAssembly). \n\nLet me know what you think!","classes":{"dataset":0.4819248617}}
{"title":"How do you decide to use a Python Package","description":"Hey guys,\n\nso I was wondering how do you decide on using a Python package? Of course there is the obvious answer that you chose a package based on functionality that you need (Pytorch for neural networks, requests for well... requests, etc.).\n\nThere are though in my eyes other factors that are important, especially in professional development and that is both safety of the package and also quality of the package. So my question is how do you judge those two parameters? Do you fly over the source code? Do you look at test coverage? Do you check for documentation before installing or are there any resources that provide insights into different packages? \n\nThanks in advance for your answers!","link":"https://www.reddit.com/r/Python/comments/11xfo9c/how_do_you_decide_to_use_a_python_package/","created":"2023-03-21","tags":["python","reddit"],"meta":{"num_comments":53},"text":"How do you decide to use a Python Package Hey guys,\n\nso I was wondering how do you decide on using a Python package? Of course there is the obvious answer that you chose a package based on functionality that you need (Pytorch for neural networks, requests for well... requests, etc.).\n\nThere are though in my eyes other factors that are important, especially in professional development and that is both safety of the package and also quality of the package. So my question is how do you judge those two parameters? Do you fly over the source code? Do you look at test coverage? Do you check for documentation before installing or are there any resources that provide insights into different packages? \n\nThanks in advance for your answers!","classes":{"dataset":0.1971117556}}
{"title":"Was there a reason the post regarding the Devpost Python Hackathon was removed?","description":"I was interested in competing, however after seeing that it had gotten removed so quickly and that the OP\u2019s comments were being downvoted to oblivion, I am a little suspicious of it\u2019s legitimacy.","link":"https://www.reddit.com/r/Python/comments/11y2nk2/was_there_a_reason_the_post_regarding_the_devpost/","created":"2023-03-22","tags":["python","reddit"],"meta":{"num_comments":1},"text":"Was there a reason the post regarding the Devpost Python Hackathon was removed? I was interested in competing, however after seeing that it had gotten removed so quickly and that the OP\u2019s comments were being downvoted to oblivion, I am a little suspicious of it\u2019s legitimacy.","classes":{"dataset":0.421767801}}
{"title":"Opinion on the monaco lib ?","description":"Hi everyone,\n\nI want to develop Monte Carlo simulations for various uses, with tkinter as GUI. I initially planned to interface python with c++, but i just came across the monaco lib. Maybe it is enough for what i need (simulation of traffic jams for example), and could avoid me to interface python and c++ which doesn't seem to be that easy. Do you guys have experience with monaco ? Is it fast / flexible ?\n\nThanks !","link":"https://www.reddit.com/r/Python/comments/11xbg6o/opinion_on_the_monaco_lib/","created":"2023-03-21","tags":["python","reddit"],"meta":{"num_comments":11},"text":"Opinion on the monaco lib ? Hi everyone,\n\nI want to develop Monte Carlo simulations for various uses, with tkinter as GUI. I initially planned to interface python with c++, but i just came across the monaco lib. Maybe it is enough for what i need (simulation of traffic jams for example), and could avoid me to interface python and c++ which doesn't seem to be that easy. Do you guys have experience with monaco ? Is it fast / flexible ?\n\nThanks !","classes":{"dataset":0.5026526451}}
{"title":"How to check if pip package is malicious","description":"I'm looking for some tips on what to look for when evaluating a pip package for malicious code.    \nHere is an actual example I recently went through:\n\nThere is a fairly known pip package called **Cython**: [https://pypi.org/project/Cython/](https://pypi.org/project/Cython/).   \nAt the same time there is a lesser known package very similarly called **cPython**: [https://pypi.org/project/cPython/](https://pypi.org/project/cPython/)^1\n\nIt's easy to mistype:\n`pip install cpython`\ninstead of:\n`pip install cython`\n\nSince pip install executes code from the package itself I thought it would be useful to investigate what this package contains so went through the following steps:\n\n1. Went to project homepage under pypi.org https://pypi.org/project/cPython/ and downloaded the latest package version since I'm assuming this is what pip install fetches if no version is provided. The latest version seems to be 0.0.6 under Downloads: https://pypi.org/project/cPython/#files\n2. Uncompressed the file, it's a tar.gz\n3. Checked the following files:\n    1. setup.py : no suspicious code at first sight. Also looked at dependencies (install_requires) and got 2: pymongo and requests, which are well known packages\n    2. cPython.py in subdirectory cPython: I'm assuming this file is not executed by pip install but I'm not sure if the imports are not resolved, it seems there are more dependencies in this file than listed under setup.py, but none triggers any concerns.\n    3. __init__.py in same subdirectory cPython: empty, similar comment to above.\n\nIt seems this particular package does not distribute binary components so this makes reviewing easier.\n\nWould you think these kind of checks are sufficient or can there be some more hidden traps one can miss even on a simple package as in this example?\n\n\n^1 I should note that at the time of this writing there is no information to assume that malicious code is delivered through the cPython package, although it's not very clear why the author went with this name for what seems to be just a wrapper script.","link":"https://www.reddit.com/r/Python/comments/11xj3ua/how_to_check_if_pip_package_is_malicious/","created":"2023-03-21","tags":["python","reddit"],"meta":{"num_comments":4},"text":"How to check if pip package is malicious I'm looking for some tips on what to look for when evaluating a pip package for malicious code.    \nHere is an actual example I recently went through:\n\nThere is a fairly known pip package called **Cython**: [https://pypi.org/project/Cython/](https://pypi.org/project/Cython/).   \nAt the same time there is a lesser known package very similarly called **cPython**: [https://pypi.org/project/cPython/](https://pypi.org/project/cPython/)^1\n\nIt's easy to mistype:\n`pip install cpython`\ninstead of:\n`pip install cython`\n\nSince pip install executes code from the package itself I thought it would be useful to investigate what this package contains so went through the following steps:\n\n1. Went to project homepage under pypi.org https://pypi.org/project/cPython/ and downloaded the latest package version since I'm assuming this is what pip install fetches if no version is provided. The latest version seems to be 0.0.6 under Downloads: https://pypi.org/project/cPython/#files\n2. Uncompressed the file, it's a tar.gz\n3. Checked the following files:\n    1. setup.py : no suspicious code at first sight. Also looked at dependencies (install_requires) and got 2: pymongo and requests, which are well known packages\n    2. cPython.py in subdirectory cPython: I'm assuming this file is not executed by pip install but I'm not sure if the imports are not resolved, it seems there are more dependencies in this file than listed under setup.py, but none triggers any concerns.\n    3. __init__.py in same subdirectory cPython: empty, similar comment to above.\n\nIt seems this particular package does not distribute binary components so this makes reviewing easier.\n\nWould you think these kind of checks are sufficient or can there be some more hidden traps one can miss even on a simple package as in this example?\n\n\n^1 I should note that at the time of this writing there is no information to assume that malicious code is delivered through the cPython package, although it's not very clear why the author went with this name for what seems to be just a wrapper script.","classes":{"dataset":0.5141583681}}
{"title":"[ZnFlow] Play around with Graphs","description":"I wrote a small package [ZnFlow](https://github.com/zincware/ZnFlow) ``pip install znflow`` that allows you to build computational graphs based on functions and/or classes. You can define your graph using inheritance or decorators and connect them in what ever way you like. The graph will only be executed when you call ``graph.run()``.\n\nHere is a small example:\n\n```python\nimport znflow\nimport dataclasses\n\n@znflow.nodify\ndef compute_mean(x, y):\n    return (x + y) / 2\n\n@dataclasses.dataclass\nclass ComputeMean(znflow.Node):\n    x: float\n    y: float\n    \n    results: float = None\n    \n    def run(self):\n        self.results = (self.x + self.y) / 2\n        \nwith znflow.DiGraph() as graph:\n    n1 = ComputeMean(2, 8)\n    n2 = compute_mean(13, 7)\n    # connecting classes and functions to a Node\n    n3 = ComputeMean(n1.results, n2) \n    \ngraph.run()\nprint(n3.results)\n# &gt;&gt;&gt; 7.5\n```\n\nSo far there is no parallel execution and this is ment as a playground for writing graphs. The graph is stored using ``networkx`` and can be visualized as such.","link":"https://www.reddit.com/r/Python/comments/11xhb4a/znflow_play_around_with_graphs/","created":"2023-03-21","tags":["python","reddit"],"meta":{"num_comments":0},"text":"[ZnFlow] Play around with Graphs I wrote a small package [ZnFlow](https://github.com/zincware/ZnFlow) ``pip install znflow`` that allows you to build computational graphs based on functions and/or classes. You can define your graph using inheritance or decorators and connect them in what ever way you like. The graph will only be executed when you call ``graph.run()``.\n\nHere is a small example:\n\n```python\nimport znflow\nimport dataclasses\n\n@znflow.nodify\ndef compute_mean(x, y):\n    return (x + y) / 2\n\n@dataclasses.dataclass\nclass ComputeMean(znflow.Node):\n    x: float\n    y: float\n    \n    results: float = None\n    \n    def run(self):\n        self.results = (self.x + self.y) / 2\n        \nwith znflow.DiGraph() as graph:\n    n1 = ComputeMean(2, 8)\n    n2 = compute_mean(13, 7)\n    # connecting classes and functions to a Node\n    n3 = ComputeMean(n1.results, n2) \n    \ngraph.run()\nprint(n3.results)\n# &gt;&gt;&gt; 7.5\n```\n\nSo far there is no parallel execution and this is ment as a playground for writing graphs. The graph is stored using ``networkx`` and can be visualized as such.","classes":{"dataset":0.2111513615}}
{"title":"Made a basic system monitor with pygame","description":"Full app can be found at: [https://drive.google.com/drive/folders/1-K8IfYNAVmEw35yT2aoZwWBRaK3Ju3fi?usp=share\\_link](https://drive.google.com/drive/folders/1-K8IfYNAVmEw35yT2aoZwWBRaK3Ju3fi?usp=share_link)\n\nAlthough this is a showcase of the app, feel free to let me know if there's any problems\n\n&amp;#x200B;\n\nUpdate: Fixed the credits alignment problem\n\n[System Display](https://reddit.com/link/11xeeuj/video/zc3cmsw0z2pa1/player)","link":"https://www.reddit.com/r/Python/comments/11xeeuj/made_a_basic_system_monitor_with_pygame/","created":"2023-03-21","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Made a basic system monitor with pygame Full app can be found at: [https://drive.google.com/drive/folders/1-K8IfYNAVmEw35yT2aoZwWBRaK3Ju3fi?usp=share\\_link](https://drive.google.com/drive/folders/1-K8IfYNAVmEw35yT2aoZwWBRaK3Ju3fi?usp=share_link)\n\nAlthough this is a showcase of the app, feel free to let me know if there's any problems\n\n&amp;#x200B;\n\nUpdate: Fixed the credits alignment problem\n\n[System Display](https://reddit.com/link/11xeeuj/video/zc3cmsw0z2pa1/player)","classes":{"dataset":0.2888689041}}
{"title":"chat-toolkit: an extensible package for creating ML-powered chatbots","description":"Hello!\n\nI would like to share my first public PyPI project.\n\n    pip install -U chat-toolkit\n\nsource code: [https://github.com/danb27/chat-toolkit](https://github.com/danb27/chat-toolkit)\n\nThis is a quick way to proof of concept a ChatGPT chatbot from the terminal: `python -m chat_toolkit`. But it is also much more.\n\nWhile I have seen other packages/repos recently that also require an OpenAI API key and provide an easy way to access ChatGPT from the terminal, my package is not designed exclusively around the terminal or ChatGPT. It also has the following features:\n\n* Is an extensible framework for making different types of components for conversational AI. Currently, the three types of components are Chatbots, Speech-to-Text, and Text-to-Speech. Each component type currently only supports a single API to start with: OpenAI's ChatGPT (paid), OpenAI's Whisper (paid), and pyttsx3 (free), respectively.\n* Using these three (for now) types of components allows the user to proof of concept more complicated chatbots, such as a Speech to Speech chatbot that you can speak directly with and hear responses from: `python -m chat_toolkit --speech-to-text --text-to-speech`\n* Users can subclass the component base classes to proof of concept currently unsupported algorithms. This is the same process I will use to add support for more algorithms. Components of the same type can be hot-swapped for each other.\n* Extensible components can be used directly for developing your own applications, not just creating a quick proof of concept in the terminal.\n\nWould appreciate any constructive and respectful feedback.\n\nEDIT:\n\n\\- formatting","link":"https://www.reddit.com/r/Python/comments/11xm82u/chattoolkit_an_extensible_package_for_creating/","created":"2023-03-21","tags":["python","reddit"],"meta":{"num_comments":0},"text":"chat-toolkit: an extensible package for creating ML-powered chatbots Hello!\n\nI would like to share my first public PyPI project.\n\n    pip install -U chat-toolkit\n\nsource code: [https://github.com/danb27/chat-toolkit](https://github.com/danb27/chat-toolkit)\n\nThis is a quick way to proof of concept a ChatGPT chatbot from the terminal: `python -m chat_toolkit`. But it is also much more.\n\nWhile I have seen other packages/repos recently that also require an OpenAI API key and provide an easy way to access ChatGPT from the terminal, my package is not designed exclusively around the terminal or ChatGPT. It also has the following features:\n\n* Is an extensible framework for making different types of components for conversational AI. Currently, the three types of components are Chatbots, Speech-to-Text, and Text-to-Speech. Each component type currently only supports a single API to start with: OpenAI's ChatGPT (paid), OpenAI's Whisper (paid), and pyttsx3 (free), respectively.\n* Using these three (for now) types of components allows the user to proof of concept more complicated chatbots, such as a Speech to Speech chatbot that you can speak directly with and hear responses from: `python -m chat_toolkit --speech-to-text --text-to-speech`\n* Users can subclass the component base classes to proof of concept currently unsupported algorithms. This is the same process I will use to add support for more algorithms. Components of the same type can be hot-swapped for each other.\n* Extensible components can be used directly for developing your own applications, not just creating a quick proof of concept in the terminal.\n\nWould appreciate any constructive and respectful feedback.\n\nEDIT:\n\n\\- formatting","classes":{"dataset":0.2099381089}}
{"title":"Training on distributed system/ own cluster","description":"Hi Reddit,\nIs there a way to increase training speed of a own model by putting it on several consumer computers / laptops?\nOr in other words can i set up an own sort of cluster for LLM training/finetuning?\nAnyone give me some hints?","link":"https://www.reddit.com/r/deeplearning/comments/11ybkl6/training_on_distributed_system_own_cluster/","created":"2023-03-22","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0},"text":"Training on distributed system/ own cluster Hi Reddit,\nIs there a way to increase training speed of a own model by putting it on several consumer computers / laptops?\nOr in other words can i set up an own sort of cluster for LLM training/finetuning?\nAnyone give me some hints?","classes":{"dataset":0.2036948502}}
{"title":"Reduced Memory Usage with Burn: A Deep Learning Framework written in Rust","description":"I announced last year on the Rust subreddit Burn, the deep learning framework I'm building in Rust.\n\nWhile building machine learning tools in a language other than Python goes against the trend, I humbly believe it is a promising avenue. There has been a lot of work since the last release, and now we're starting to see some benefits. Burn uses less memory, especially on the CPU during both inference and training than PyTorch with a similar computational graph. I wrote a technical blog post about it, describing how Burn allows for the reuse of tensor-allocated memory ([**https://burn-rs.github.io/blog/burn-rusty-approach-to-tensor-handling**](https://burn-rs.github.io/blog/burn-rusty-approach-to-tensor-handling)).\n\nThere is still a lot more work to be done before being really competitive with other frameworks, notably properly supporting operation fusion. But Burn is still usable today, and you can even run inference in the browser using WebAssembly ([**https://burn-rs.github.io/demo**](https://burn-rs.github.io/demo)).  \n\n\nIf you have any questions regarding the blog, Rust, or Burn, I'm happy to answer them below.","link":"https://www.reddit.com/r/deeplearning/comments/11xtmnf/reduced_memory_usage_with_burn_a_deep_learning/","created":"2023-03-21","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0},"text":"Reduced Memory Usage with Burn: A Deep Learning Framework written in Rust I announced last year on the Rust subreddit Burn, the deep learning framework I'm building in Rust.\n\nWhile building machine learning tools in a language other than Python goes against the trend, I humbly believe it is a promising avenue. There has been a lot of work since the last release, and now we're starting to see some benefits. Burn uses less memory, especially on the CPU during both inference and training than PyTorch with a similar computational graph. I wrote a technical blog post about it, describing how Burn allows for the reuse of tensor-allocated memory ([**https://burn-rs.github.io/blog/burn-rusty-approach-to-tensor-handling**](https://burn-rs.github.io/blog/burn-rusty-approach-to-tensor-handling)).\n\nThere is still a lot more work to be done before being really competitive with other frameworks, notably properly supporting operation fusion. But Burn is still usable today, and you can even run inference in the browser using WebAssembly ([**https://burn-rs.github.io/demo**](https://burn-rs.github.io/demo)).  \n\n\nIf you have any questions regarding the blog, Rust, or Burn, I'm happy to answer them below.","classes":{"dataset":0.2728300393}}
{"title":"It would be cool if there was a machine learning Nes Emulator, that the ai could learn to play automatically and you just run it on your pc till it finds the optimum root.","description":"","link":"https://www.reddit.com/r/deeplearning/comments/11xx3r6/it_would_be_cool_if_there_was_a_machine_learning/","created":"2023-03-21","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":3},"text":"It would be cool if there was a machine learning Nes Emulator, that the ai could learn to play automatically and you just run it on your pc till it finds the optimum root. ","classes":{"dataset":0.533495605}}
{"title":"Adding Number of Sequence into dataset","description":" \n\nI will adding the number of sequence to original data. each array will be adding number of sequence based on iteration.\n\noriginal data :\n\n \n\n    a = np.array([     [-0.939,3838,393],     [7.937,7373,283],     [8.293,2222,838] ])\n    \n    after adding seqeunce number, the data look like above:\n    \n    a = np.array([\n        [1,-0.939,3838,393],\n        [2,7.937,7373,283],\n        [1,8.293,2222,838]\n    ])\n    \n    what is the technique above? is it the part of data preprocessing such as feature engineering or data augmentation or not","link":"https://www.reddit.com/r/deeplearning/comments/11xid8v/adding_number_of_sequence_into_dataset/","created":"2023-03-21","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0},"text":"Adding Number of Sequence into dataset  \n\nI will adding the number of sequence to original data. each array will be adding number of sequence based on iteration.\n\noriginal data :\n\n \n\n    a = np.array([     [-0.939,3838,393],     [7.937,7373,283],     [8.293,2222,838] ])\n    \n    after adding seqeunce number, the data look like above:\n    \n    a = np.array([\n        [1,-0.939,3838,393],\n        [2,7.937,7373,283],\n        [1,8.293,2222,838]\n    ])\n    \n    what is the technique above? is it the part of data preprocessing such as feature engineering or data augmentation or not","classes":{"dataset":0.4037849307}}
{"title":"Searching for an AI script/program","description":"Is there any AI program that works like first-order-model / wav2lip but it is combination of those two?I mean creating your reference video and transfer lips and face movement onto the destination video?\n\nIf not, I have an Idea on how to do this but I'm lack of abilities with programming to do this on my own. It could export every frame of our destination video and use it as a single photo to animate, but instead of recreating our whole reference motion on individual frame from the destination video it could recreate 1 frame from source video to 1 frame in destination video and after that compile changed frames into a whole video.\n\nI know we can animate photo with reference video, but I couldn't find animating face in videos. Wav2Lip is not that dynamic, and first-order-model only stick to animating photos.\n\nI think we can modify those two scripts and automate the process to stick with frame by frame changes.\n\nCan someone help with this idea? What are your thoughts? Or maybe there is someone who already done that?","link":"https://www.reddit.com/r/deeplearning/comments/11xd4lz/searching_for_an_ai_scriptprogram/","created":"2023-03-21","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0},"text":"Searching for an AI script/program Is there any AI program that works like first-order-model / wav2lip but it is combination of those two?I mean creating your reference video and transfer lips and face movement onto the destination video?\n\nIf not, I have an Idea on how to do this but I'm lack of abilities with programming to do this on my own. It could export every frame of our destination video and use it as a single photo to animate, but instead of recreating our whole reference motion on individual frame from the destination video it could recreate 1 frame from source video to 1 frame in destination video and after that compile changed frames into a whole video.\n\nI know we can animate photo with reference video, but I couldn't find animating face in videos. Wav2Lip is not that dynamic, and first-order-model only stick to animating photos.\n\nI think we can modify those two scripts and automate the process to stick with frame by frame changes.\n\nCan someone help with this idea? What are your thoughts? Or maybe there is someone who already done that?","classes":{"dataset":0.6623367667}}
{"title":"Alpaca-7B and Dalai, how can I get coherent results?","description":"Recently, I installed dalai on my Macbook Pro (late 2019, i7 processor and 16GB of RAM) and I also installed Alpaca-7B model. Now when I ask it to write a tweet, it writes a wikipedia article and it does the same pretty much every time \ud83d\ude02\n\nFirst, should I fine-tune it?\n\nSecond, is there any \"prompt magic\" going on here?\n\nP.S: using [this one](https://github.com/tloen/alpaca-lora),  I got much better results. What's the difference between the two?","link":"https://www.reddit.com/r/deeplearning/comments/11wdi8m/alpaca7b_and_dalai_how_can_i_get_coherent_results/","created":"2023-03-20","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":11},"text":"Alpaca-7B and Dalai, how can I get coherent results? Recently, I installed dalai on my Macbook Pro (late 2019, i7 processor and 16GB of RAM) and I also installed Alpaca-7B model. Now when I ask it to write a tweet, it writes a wikipedia article and it does the same pretty much every time \ud83d\ude02\n\nFirst, should I fine-tune it?\n\nSecond, is there any \"prompt magic\" going on here?\n\nP.S: using [this one](https://github.com/tloen/alpaca-lora),  I got much better results. What's the difference between the two?","classes":{"dataset":0.3557751179}}
{"title":"Error while training yolov5","description":"Just after starting the traing this error shows up . Please help ! \n\nYOLOv5  v7.0-120-g3e55763 Python-3.8.16 torch-2.0.0 CPU \n\nSetup complete  (8 CPUs, 16.0 GB RAM, 183.8 / 460.4 GB disk)  \n[/AppleInternal/Library/BuildRoots/c651a45f-806e-11ed-a221-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:82](https://file+.vscode-resource.vscode-cdn.net/AppleInternal/Library/BuildRoots/c651a45f-806e-11ed-a221-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:82): failed assertion \\`\\[MPSNDArrayDescriptor sliceDimension:withSubrange:\\] error: subRange.start (3) is not less than length of dimension\\[1\\] (3)'","link":"https://www.reddit.com/r/deeplearning/comments/11wr7fz/error_while_training_yolov5/","created":"2023-03-20","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0},"text":"Error while training yolov5 Just after starting the traing this error shows up . Please help ! \n\nYOLOv5  v7.0-120-g3e55763 Python-3.8.16 torch-2.0.0 CPU \n\nSetup complete  (8 CPUs, 16.0 GB RAM, 183.8 / 460.4 GB disk)  \n[/AppleInternal/Library/BuildRoots/c651a45f-806e-11ed-a221-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:82](https://file+.vscode-resource.vscode-cdn.net/AppleInternal/Library/BuildRoots/c651a45f-806e-11ed-a221-7ef33c48bc85/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShaders/MPSCore/Types/MPSNDArray.mm:82): failed assertion \\`\\[MPSNDArrayDescriptor sliceDimension:withSubrange:\\] error: subRange.start (3) is not less than length of dimension\\[1\\] (3)'","classes":{"dataset":0.2712286115}}
{"title":"[D] Overwhelmed by fast advances in recent weeks","description":"I was watching the GTC keynote and became entirely overwhelmed by the amount of progress achieved from last year.  I'm wondering how everyone else feels.\n\n&amp;#x200B;\n\nFirstly, the entire ChatGPT, GPT-3/GPT-4 chaos has been going on for a few weeks, with everyone scrambling left and right to integrate chatbots into their apps, products, websites. Twitter is flooded with new product ideas, how to speed up the process from idea to product, countless promp engineering blogs, tips, tricks, paid courses.\n\n&amp;#x200B;\n\nNot only was ChatGPT disruptive, but a few days later, Microsoft and Google also released their models and integrated them into their search engines. Microsoft also integrated its LLM into its Office suite. It all happenned overnight. I understand that they've started integrating them along the way, but still, it seems like it hapenned way too fast. This tweet encompases the past few weeks perfectly [https://twitter.com/AlphaSignalAI/status/1638235815137386508](https://twitter.com/AlphaSignalAI/status/1638235815137386508) , on a random Tuesday countless products are released that seem revolutionary.\n\n&amp;#x200B;\n\nIn addition to the language models, there are also the generative art models that have been slowly rising in mainstream recognition. Now Midjourney AI is known by a lot of people who are not even remotely connected to the AI space.\n\n&amp;#x200B;\n\nFor the past few weeks, reading Twitter, I've felt completely overwhelmed, as if the entire AI space is moving beyond at lightning speed, whilst around me we're just slowly training models, adding some data, and not seeing much improvement, being stuck on coming up with \"new ideas, that set us apart\".\n\n&amp;#x200B;\n\nWatching the GTC keynote from NVIDIA I was again, completely overwhelmed by how much is being developed throughout all the different domains. The ASML EUV (microchip making system) was incredible, I have no idea how it does lithography and to me it still seems like magic. The Grace CPU with 2 dies (although I think Apple was the first to do it?) and 100 GB RAM, all in a small form factor. There were a lot more different hardware servers that I just blanked out at some point. The omniverse sim engine looks incredible, almost real life (I wonder how much of a domain shift there is between real and sim considering how real the sim looks). Beyond it being cool and usable to train on synthetic data, the car manufacturers use it to optimize their pipelines. This change in perspective, of using these tools for other goals than those they were designed for I find the most interesting.\n\n&amp;#x200B;\n\nThe hardware part may be old news, as I don't really follow it, however the software part is just as incredible. NVIDIA AI foundations (language, image, biology models), just packaging everything together like a sandwich. Getty, Shutterstock and Adobe will use the generative models to create images. Again, already these huge juggernauts are already integrated.\n\n&amp;#x200B;\n\nI can't believe the point where we're at. We can use AI to write code, create art, create audiobooks using Britney Spear's voice, create an interactive chatbot to converse with books, create 3D real-time avatars, generate new proteins (?i'm lost on this one), create an anime and countless other scenarios. Sure, they're not perfect, but the fact that we can do all that in the first place is amazing.\n\n&amp;#x200B;\n\nAs Huang said in his keynote, companies want to develop \"disruptive products and business models\". I feel like this is what I've seen lately. Everyone wants to be the one that does something first, just throwing anything and everything at the wall and seeing what sticks.\n\n&amp;#x200B;\n\nIn conclusion, I'm feeling like the world is moving so fast around me whilst I'm standing still. I want to not read anything anymore and just wait until everything dies down abit, just so I can get my bearings. However, I think this is unfeasible. I fear we'll keep going in a frenzy until we just burn ourselves at some point.\n\n&amp;#x200B;\n\nHow are you all fairing? How do you feel about this frenzy in the AI space? What are you the most excited about?","link":"https://www.reddit.com/r/MachineLearning/comments/11ybjsi/d_overwhelmed_by_fast_advances_in_recent_weeks/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":23},"text":"[D] Overwhelmed by fast advances in recent weeks I was watching the GTC keynote and became entirely overwhelmed by the amount of progress achieved from last year.  I'm wondering how everyone else feels.\n\n&amp;#x200B;\n\nFirstly, the entire ChatGPT, GPT-3/GPT-4 chaos has been going on for a few weeks, with everyone scrambling left and right to integrate chatbots into their apps, products, websites. Twitter is flooded with new product ideas, how to speed up the process from idea to product, countless promp engineering blogs, tips, tricks, paid courses.\n\n&amp;#x200B;\n\nNot only was ChatGPT disruptive, but a few days later, Microsoft and Google also released their models and integrated them into their search engines. Microsoft also integrated its LLM into its Office suite. It all happenned overnight. I understand that they've started integrating them along the way, but still, it seems like it hapenned way too fast. This tweet encompases the past few weeks perfectly [https://twitter.com/AlphaSignalAI/status/1638235815137386508](https://twitter.com/AlphaSignalAI/status/1638235815137386508) , on a random Tuesday countless products are released that seem revolutionary.\n\n&amp;#x200B;\n\nIn addition to the language models, there are also the generative art models that have been slowly rising in mainstream recognition. Now Midjourney AI is known by a lot of people who are not even remotely connected to the AI space.\n\n&amp;#x200B;\n\nFor the past few weeks, reading Twitter, I've felt completely overwhelmed, as if the entire AI space is moving beyond at lightning speed, whilst around me we're just slowly training models, adding some data, and not seeing much improvement, being stuck on coming up with \"new ideas, that set us apart\".\n\n&amp;#x200B;\n\nWatching the GTC keynote from NVIDIA I was again, completely overwhelmed by how much is being developed throughout all the different domains. The ASML EUV (microchip making system) was incredible, I have no idea how it does lithography and to me it still seems like magic. The Grace CPU with 2 dies (although I think Apple was the first to do it?) and 100 GB RAM, all in a small form factor. There were a lot more different hardware servers that I just blanked out at some point. The omniverse sim engine looks incredible, almost real life (I wonder how much of a domain shift there is between real and sim considering how real the sim looks). Beyond it being cool and usable to train on synthetic data, the car manufacturers use it to optimize their pipelines. This change in perspective, of using these tools for other goals than those they were designed for I find the most interesting.\n\n&amp;#x200B;\n\nThe hardware part may be old news, as I don't really follow it, however the software part is just as incredible. NVIDIA AI foundations (language, image, biology models), just packaging everything together like a sandwich. Getty, Shutterstock and Adobe will use the generative models to create images. Again, already these huge juggernauts are already integrated.\n\n&amp;#x200B;\n\nI can't believe the point where we're at. We can use AI to write code, create art, create audiobooks using Britney Spear's voice, create an interactive chatbot to converse with books, create 3D real-time avatars, generate new proteins (?i'm lost on this one), create an anime and countless other scenarios. Sure, they're not perfect, but the fact that we can do all that in the first place is amazing.\n\n&amp;#x200B;\n\nAs Huang said in his keynote, companies want to develop \"disruptive products and business models\". I feel like this is what I've seen lately. Everyone wants to be the one that does something first, just throwing anything and everything at the wall and seeing what sticks.\n\n&amp;#x200B;\n\nIn conclusion, I'm feeling like the world is moving so fast around me whilst I'm standing still. I want to not read anything anymore and just wait until everything dies down abit, just so I can get my bearings. However, I think this is unfeasible. I fear we'll keep going in a frenzy until we just burn ourselves at some point.\n\n&amp;#x200B;\n\nHow are you all fairing? How do you feel about this frenzy in the AI space? What are you the most excited about?","classes":{"dataset":0.4029656351}}
{"title":"[P] fastLLaMa, A python wrapper to run llama.cpp","description":"Hi all, I have been working on fastLLaMa. It is a Python package that provides a Pythonic interface to a C++ library, llama.cpp. It allows you to use the functionality of the C++ library from within Python, without having to write C++ code or deal with low-level C++ APIs.\n\nUsing fastLLaMa, you can ingest the model with system prompts and then save the state of the model, Then later load the state, and start inferencing the model immediately.\n\nNo noticeable performance drop between lama.cpp and fastLLaMa.\n\nHave a look at it if it is of interest and do let me know what you think :)\n\n[Repo Link](https://github.com/PotatoSpudowski/fastLLaMa) \n\n[Tweet](https://twitter.com/Bahushruth/status/1638231265320239106)","link":"https://www.reddit.com/r/MachineLearning/comments/11y9qgg/p_fastllama_a_python_wrapper_to_run_llamacpp/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":3},"text":"[P] fastLLaMa, A python wrapper to run llama.cpp Hi all, I have been working on fastLLaMa. It is a Python package that provides a Pythonic interface to a C++ library, llama.cpp. It allows you to use the functionality of the C++ library from within Python, without having to write C++ code or deal with low-level C++ APIs.\n\nUsing fastLLaMa, you can ingest the model with system prompts and then save the state of the model, Then later load the state, and start inferencing the model immediately.\n\nNo noticeable performance drop between lama.cpp and fastLLaMa.\n\nHave a look at it if it is of interest and do let me know what you think :)\n\n[Repo Link](https://github.com/PotatoSpudowski/fastLLaMa) \n\n[Tweet](https://twitter.com/Bahushruth/status/1638231265320239106)","classes":{"dataset":0.4480202198}}
{"title":"[Project] Machine Learning for Audio: A library for audio analysis, feature extraction, etc","description":"**audioflux** is a deep learning tool library for audio and music analysis, feature extraction. It supports dozens of time-frequency analysis transformation methods and hundreds of corresponding time-domain and frequency-domain feature combinations. It can be provided to deep learning networks for training, and is used to study various tasks in the audio field such as Classification, Separation, Music Information Retrieval(MIR) and ASR etc.\n\n**Source Code**: [https://github.com/libAudioFlux/audioFlux](https://github.com/libAudioFlux/audioFlux)","link":"https://www.reddit.com/r/MachineLearning/comments/11xd1iz/project_machine_learning_for_audio_a_library_for/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":26},"text":"[Project] Machine Learning for Audio: A library for audio analysis, feature extraction, etc **audioflux** is a deep learning tool library for audio and music analysis, feature extraction. It supports dozens of time-frequency analysis transformation methods and hundreds of corresponding time-domain and frequency-domain feature combinations. It can be provided to deep learning networks for training, and is used to study various tasks in the audio field such as Classification, Separation, Music Information Retrieval(MIR) and ASR etc.\n\n**Source Code**: [https://github.com/libAudioFlux/audioFlux](https://github.com/libAudioFlux/audioFlux)","classes":{"dataset":0.1244466156}}
{"title":"[D] 100% accuracy of Random Forest Breast Cancer Prediction","description":"Came across this article published in 2023 on Breast Cancer Prediction: [https://www.sciencedirect.com/science/article/pii/S187705092300025X](https://www.sciencedirect.com/science/article/pii/S187705092300025X)\n\nIt claims to have 100% accuracy on the held out test set, but some of the data transformation and feature selection process doesn't sit quite right with me as it seems abit bias towards the model they are trying to prove is best. (Afterall, 100% accuracy is problematic in itself)\n\nWhat do you guys think?","link":"https://www.reddit.com/r/MachineLearning/comments/11yccp8/d_100_accuracy_of_random_forest_breast_cancer/","created":"2023-03-22","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":1},"text":"[D] 100% accuracy of Random Forest Breast Cancer Prediction Came across this article published in 2023 on Breast Cancer Prediction: [https://www.sciencedirect.com/science/article/pii/S187705092300025X](https://www.sciencedirect.com/science/article/pii/S187705092300025X)\n\nIt claims to have 100% accuracy on the held out test set, but some of the data transformation and feature selection process doesn't sit quite right with me as it seems abit bias towards the model they are trying to prove is best. (Afterall, 100% accuracy is problematic in itself)\n\nWhat do you guys think?","classes":{"dataset":0.1703901887}}
{"title":"[P] Run LLaMA LLM chatbots on any cloud with one click","description":"We made a \\*basic\\* chatbot based on LLaMA models; code here: [https://github.com/skypilot-org/skypilot/tree/master/examples/llama-llm-chatbots](https://github.com/skypilot-org/skypilot/tree/master/examples/llama-llm-chatbots) [https://github.com/skypilot-org/sky-llama](https://github.com/skypilot-org/sky-llama)\n\nA detailed post on how to run it on the cloud (Lambda Cloud, AWS, GCP, Azure) with 1 command: [https://blog.skypilot.co/llama-llm-chatbots-on-any-cloud/](https://blog.skypilot.co/llama-llm-chatbots-on-any-cloud/)\n\nWould love to hear your thoughts. Although people are making LLMs run on laptops and other devices ({llama,alpaca}.cpp}, we think that as more open and compute-hungry LLMs emerge, it's increasingly important to finetune them and that's where getting powerful cloud compute in flexible locations comes into play.","link":"https://www.reddit.com/r/MachineLearning/comments/11xvo1i/p_run_llama_llm_chatbots_on_any_cloud_with_one/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":1},"text":"[P] Run LLaMA LLM chatbots on any cloud with one click We made a \\*basic\\* chatbot based on LLaMA models; code here: [https://github.com/skypilot-org/skypilot/tree/master/examples/llama-llm-chatbots](https://github.com/skypilot-org/skypilot/tree/master/examples/llama-llm-chatbots) [https://github.com/skypilot-org/sky-llama](https://github.com/skypilot-org/sky-llama)\n\nA detailed post on how to run it on the cloud (Lambda Cloud, AWS, GCP, Azure) with 1 command: [https://blog.skypilot.co/llama-llm-chatbots-on-any-cloud/](https://blog.skypilot.co/llama-llm-chatbots-on-any-cloud/)\n\nWould love to hear your thoughts. Although people are making LLMs run on laptops and other devices ({llama,alpaca}.cpp}, we think that as more open and compute-hungry LLMs emerge, it's increasingly important to finetune them and that's where getting powerful cloud compute in flexible locations comes into play.","classes":{"dataset":0.120361343}}
{"title":"[D] Is ML doomed to end up closed-source?","description":"So basically, OpenAI is keeping its models a secret, Hugging Face added a new gated feature, and LLaMA is using a non-commercial license. It looks like companies are all moving towards closed-source and monopolizing ML. \n\nI've always loved Hugging Face, but now they are doing the opposite of what they preach with this new gated feature thing, this is just not open-source and shouldn't be encouraged in the first place.\n\nOpen AI [clearly stated](https://openai.com/policies/terms-of-use#:~:text=use%20output%20from%20the%20Services%20to%20develop%20models%20that%20compete%20with%20OpenAI) that you can't \"use output from the Services to develop models that compete with OpenAI\"\n\nGoogle shared its paper Attention Is All You Need transparently which was a breakthrough in NLP and got utilized by OpenAI (with many other papers) to build GPT-4 which is adopted by Bing and now posing risk to Google's business. As a consequence, could companies start to avoid sharing research openly and rather monopolize their work for the sake of their own business safety?\n\nAlso, assuming we will witness more of these closed-source models. is it safe to just trust them without understanding what data they got exactly trained on? This doesn't seem to make sense, not sure how this would end up.","link":"https://www.reddit.com/r/MachineLearning/comments/11wxabh/d_is_ml_doomed_to_end_up_closedsource/","created":"2023-03-20","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":120},"text":"[D] Is ML doomed to end up closed-source? So basically, OpenAI is keeping its models a secret, Hugging Face added a new gated feature, and LLaMA is using a non-commercial license. It looks like companies are all moving towards closed-source and monopolizing ML. \n\nI've always loved Hugging Face, but now they are doing the opposite of what they preach with this new gated feature thing, this is just not open-source and shouldn't be encouraged in the first place.\n\nOpen AI [clearly stated](https://openai.com/policies/terms-of-use#:~:text=use%20output%20from%20the%20Services%20to%20develop%20models%20that%20compete%20with%20OpenAI) that you can't \"use output from the Services to develop models that compete with OpenAI\"\n\nGoogle shared its paper Attention Is All You Need transparently which was a breakthrough in NLP and got utilized by OpenAI (with many other papers) to build GPT-4 which is adopted by Bing and now posing risk to Google's business. As a consequence, could companies start to avoid sharing research openly and rather monopolize their work for the sake of their own business safety?\n\nAlso, assuming we will witness more of these closed-source models. is it safe to just trust them without understanding what data they got exactly trained on? This doesn't seem to make sense, not sure how this would end up.","classes":{"dataset":0.3764688373}}
{"title":"[D] [P] Curating open-source projects and community demos around GPT-4","description":"There are many open-source projects and indie-built demos around the GPT-4 API. Despite the recent shift of OpenAI toward closure, open demos are always advancing the field and inspiring creativity. Here are some community projects that I find particularly interesting: [https://github.com/radi-cho/awesome-gpt4](https://github.com/radi-cho/awesome-gpt4). Feel free to share the things you've been building or something you've been fascinated about on social media either by joining the discussion here or by contributing to the repository:)","link":"https://www.reddit.com/r/MachineLearning/comments/11xwb10/d_p_curating_opensource_projects_and_community/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0},"text":"[D] [P] Curating open-source projects and community demos around GPT-4 There are many open-source projects and indie-built demos around the GPT-4 API. Despite the recent shift of OpenAI toward closure, open demos are always advancing the field and inspiring creativity. Here are some community projects that I find particularly interesting: [https://github.com/radi-cho/awesome-gpt4](https://github.com/radi-cho/awesome-gpt4). Feel free to share the things you've been building or something you've been fascinated about on social media either by joining the discussion here or by contributing to the repository:)","classes":{"dataset":0.6840638518}}
{"title":"[R] Comparison of XAI libraries for Computer Vision","description":"I am working on an open-source XAI library aggregator and made a comparison of currently active XAI repositories. I am sure somebody will find this useful :)\n\n| Feature                              | pytorch-grad-cam | Captum | pytorch-cnn-visualizations | torch-cam | innvestigate | tf-explain | OmniXAI | Xplique | M3d-Cam |\n|--------------------------------------|------------------|--------|----------------------------|-----------|--------------|------------|---------|---------|---------|\n| Repository has library API           | \u2714                | \u2714      | \u2718                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Contains tutorials or examples       | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Documentation contains API reference | \u2718                | \u2714      | \u2718                          | \u2714         | \u2714            | \u2714\u2718         | \u2714       | \u2714       | \u2714       |\n| Works with 2D images                 | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Works with 3D images                 | \u2718                | \u2718      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2714       |\n| Activation visualization             | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Overlaying  heatmap visualization    | \u2714                | \u2714      | \u2714                          | \u2714         | \u2718            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Explain image classification         | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Explain object detection             | \u2714                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2718       |\n| Explain semantic segmentation        | \u2714                | \u2718      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2714       |\n| Explain panoptic segmentation        | \u2718                | \u2718      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2718       |\n| GPU acceleration                     | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Trust metrics                        | \u2714                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2714       | \u2718       |\n| PyTorch support                      | \u2714                | \u2714      | \u2714                          | \u2714         | \u2718            | \u2718          | \u2714       | \u2718       | \u2714       |\n| TensorFlow support                   | \u2718                | \u2718      | \u2718                          | \u2718         | \u2714            | \u2714          | \u2714       | \u2714       | \u2718       |\n| Concept Activation Vector            | \u2718                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2714       | \u2718       |\n| Feature visualization                | \u2718                | \u2718      | \u2714                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2714       | \u2718       |\n| DeepDream                            | \u2718                | \u2718      | \u2714                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2718       |\n| Influential Examples                 | \u2718                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2718       |\n| Interactive explainer app            | \u2718                | \u2714      | \u2718                          | \u2714         | \u2718            | \u2718          | \u2714       | \u2718       | \u2718       |\n| Adversarial attacks                  | \u2718                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2714       | \u2718       | \u2718       |\n| Model\u2019s attributes                   | \u2714                | \u2714      | \u2714                          | \u2718         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Layer\u2019s attributes                   | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2718          | \u2714       | \u2714       | \u2714       |\n| Neuron\u2019s attributes                  | \u2718                | \u2714      | \u2718                          | \u2718         | \u2714            | \u2718          | \u2718       | \u2714       | \u2718       |\n| Integration with experiment tracker  | \u2718                | \u2718      | \u2718                          | \u2718         | \u2718            | \u2714          | \u2718       | \u2718       | \u2718       |","link":"https://www.reddit.com/r/MachineLearning/comments/11xh0i8/r_comparison_of_xai_libraries_for_computer_vision/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":1},"text":"[R] Comparison of XAI libraries for Computer Vision I am working on an open-source XAI library aggregator and made a comparison of currently active XAI repositories. I am sure somebody will find this useful :)\n\n| Feature                              | pytorch-grad-cam | Captum | pytorch-cnn-visualizations | torch-cam | innvestigate | tf-explain | OmniXAI | Xplique | M3d-Cam |\n|--------------------------------------|------------------|--------|----------------------------|-----------|--------------|------------|---------|---------|---------|\n| Repository has library API           | \u2714                | \u2714      | \u2718                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Contains tutorials or examples       | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Documentation contains API reference | \u2718                | \u2714      | \u2718                          | \u2714         | \u2714            | \u2714\u2718         | \u2714       | \u2714       | \u2714       |\n| Works with 2D images                 | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Works with 3D images                 | \u2718                | \u2718      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2714       |\n| Activation visualization             | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Overlaying  heatmap visualization    | \u2714                | \u2714      | \u2714                          | \u2714         | \u2718            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Explain image classification         | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Explain object detection             | \u2714                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2718       |\n| Explain semantic segmentation        | \u2714                | \u2718      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2714       |\n| Explain panoptic segmentation        | \u2718                | \u2718      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2718       |\n| GPU acceleration                     | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Trust metrics                        | \u2714                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2714       | \u2718       |\n| PyTorch support                      | \u2714                | \u2714      | \u2714                          | \u2714         | \u2718            | \u2718          | \u2714       | \u2718       | \u2714       |\n| TensorFlow support                   | \u2718                | \u2718      | \u2718                          | \u2718         | \u2714            | \u2714          | \u2714       | \u2714       | \u2718       |\n| Concept Activation Vector            | \u2718                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2714       | \u2718       |\n| Feature visualization                | \u2718                | \u2718      | \u2714                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2714       | \u2718       |\n| DeepDream                            | \u2718                | \u2718      | \u2714                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2718       |\n| Influential Examples                 | \u2718                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2718       | \u2718       | \u2718       |\n| Interactive explainer app            | \u2718                | \u2714      | \u2718                          | \u2714         | \u2718            | \u2718          | \u2714       | \u2718       | \u2718       |\n| Adversarial attacks                  | \u2718                | \u2714      | \u2718                          | \u2718         | \u2718            | \u2718          | \u2714       | \u2718       | \u2718       |\n| Model\u2019s attributes                   | \u2714                | \u2714      | \u2714                          | \u2718         | \u2714            | \u2714          | \u2714       | \u2714       | \u2714       |\n| Layer\u2019s attributes                   | \u2714                | \u2714      | \u2714                          | \u2714         | \u2714            | \u2718          | \u2714       | \u2714       | \u2714       |\n| Neuron\u2019s attributes                  | \u2718                | \u2714      | \u2718                          | \u2718         | \u2714            | \u2718          | \u2718       | \u2714       | \u2718       |\n| Integration with experiment tracker  | \u2718                | \u2718      | \u2718                          | \u2718         | \u2718            | \u2714          | \u2718       | \u2718       | \u2718       |","classes":{"dataset":0.4053193629}}
{"title":"[D] Is attention ALIBI Attention with Linear Biases implemented in both decoder and encoder?","description":"I've read the paper, yet I cannot seem to find an explicit statement of where in the transformers architecture the ALIBI mask is implemented.\n\nThanks","link":"https://www.reddit.com/r/MachineLearning/comments/11xx7a8/d_is_attention_alibi_attention_with_linear_biases/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":2},"text":"[D] Is attention ALIBI Attention with Linear Biases implemented in both decoder and encoder? I've read the paper, yet I cannot seem to find an explicit statement of where in the transformers architecture the ALIBI mask is implemented.\n\nThanks","classes":{"dataset":0.0000000021}}
{"title":"[D] Does label distribution affect models performance, especially for deep learning models?","description":"Currently I'm working on a project where the dataset are quite imbalanced (most and least class can be 10 times in size). The data and labels of the project are actually a time series, so naturally, when I'm splitting the samples according to time, the number of labels of different class are quite different. For example, in validation set, number of samples in class 2 can be 10 times of class 1, but only 5 times more in testing set. My supervisor asked me to make every sets to have the same label distribution (e.g. class 2 should always have roughly 5 times of class 1).\n\nI'm quite frustrated by this argument. Not only this makes cross-validation very annoying as it means every splits I must readjust the label distribution quite bruteforcely; this redistributing also meant that I will have to alter the testing set which in my undestanding is quite a big no-no; (and also the fact that I can't really turn down this argument as the problem does exist and I couldn't provide a better solution).\n\nSo I want to know do people actually re-adjust the number of labels just to make different set of data to have similar ratio in number of labels? Because I can't quite find any readings regarding such problems. In my current understanding, a good loss should make the models to \"immune\" to difference in label distribution. In the project, we have used label-distribution-aware margin (LDAM) loss. But in the paper, the author only experiments with imbalanced data.","link":"https://www.reddit.com/r/MachineLearning/comments/11xgwzs/d_does_label_distribution_affect_models/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":7},"text":"[D] Does label distribution affect models performance, especially for deep learning models? Currently I'm working on a project where the dataset are quite imbalanced (most and least class can be 10 times in size). The data and labels of the project are actually a time series, so naturally, when I'm splitting the samples according to time, the number of labels of different class are quite different. For example, in validation set, number of samples in class 2 can be 10 times of class 1, but only 5 times more in testing set. My supervisor asked me to make every sets to have the same label distribution (e.g. class 2 should always have roughly 5 times of class 1).\n\nI'm quite frustrated by this argument. Not only this makes cross-validation very annoying as it means every splits I must readjust the label distribution quite bruteforcely; this redistributing also meant that I will have to alter the testing set which in my undestanding is quite a big no-no; (and also the fact that I can't really turn down this argument as the problem does exist and I couldn't provide a better solution).\n\nSo I want to know do people actually re-adjust the number of labels just to make different set of data to have similar ratio in number of labels? Because I can't quite find any readings regarding such problems. In my current understanding, a good loss should make the models to \"immune\" to difference in label distribution. In the project, we have used label-distribution-aware margin (LDAM) loss. But in the paper, the author only experiments with imbalanced data.","classes":{"dataset":0.093896322}}
{"title":"[p] detrex v0.3.0: A Major Update to Our Detection Transformer Codebase!","description":"Happy to release our **detrex v0.3.0**, after two months, there're **lots of new algorithms**, **baselines and useful tools** have been supported in detrex. We will introduce them later.\n\nHere's our github link: https://github.com/IDEA-Research/detrex\n\nIf our repo can help you for your research, please consider give us a star~\n\n## What's New\n### New Algorithms and Pre-Trained Models\nThe **newly supported algorithms** in detrex v0.3.0:\n- PnP-DETR (ICCV' 2021)\n- Anchor-DETR (AAAI' 2022)\n- DETA (ArXiv' 2022)\n- MaskDINO (CVPR' 2023)\n\nAs for now, our detrex **support 14 detection transformer algorithms**.\n\nAnd after lots of experiments, we release a set of new baselines, which **are all better than their official implementation**\n\n| Model | Box AP (detrex) | Box AP (official) |\n|:---|:---:|:---:|\n| DETA-R50 | 50.2 **(+0.1)** | 50.1 |\n| H-Deformable-DETR-R50 | 49.1 **(+0.4)** | 48.7 |\n| DINO-R50 | 49.4 **(+0.4)** | 49.0 |\n\nAnd we also release **more than 30+** pretrained weights (including the converted weights) for the community research. All the pretrained model can be downloaded from our [Model Zoo](https://detrex.readthedocs.io/en/latest/tutorials/Model_Zoo.html)\n\n**DINO detector with ViT backbone**\n\n| Model  | Lr Sched | Box AP |\n|:---|:---:|:---:|\n| DINO-ViTDet-Base (4scale) | 12 | 50.2 |\n| DINO-ViTDet-Base (4scale) | 50 | 55.0 |\n| DINO-ViTDet-Large (4scale) | 12 | 52.9 |\n| DINO-ViTDet-Large (4scale) | 50 | 57.5 |\n\n**DINO detector with strong FocalNet backbone**\n\n| Model  | Lr Sched | Box AP |\n|:---|:---:|:---:|\n| DINO-FocalNet-Large-3level (4scale) | 12 | 57.5 |\n| DINO-FocalNet-Large-4level (4scale) | 12 | 58.0 |\n| DINO-FocalNet-Large-4level (5scale) | 12 | 58.5 |\n\n### New Training Techniques\n- Supported **Mixed Precision Training** by setting `train.amp.enabled=True`: **reduce 20% to 30% GPU memory usage**.\n- Supported **EMAHook** by setting `train.model_ema.enabled=True`: which can further enhance the model performance.\n\n| Model | Lr Sched | Box AP |\n|:---|:---:|:---:|\n| DINO-R50 w/o EMA | 12 | 49.0 |\n| DINO-R50 with EMA | 12 | 49.4 **(+0.4)** |\n\n- Supported **Encoder-Decoder Gradient Checkpoint** in DINO detector which can further reduce 30% GPU memory usage.\n- Support wandb logger\n- Support a great slurm training scripts","link":"https://www.reddit.com/r/MachineLearning/comments/11xhzhy/p_detrex_v030_a_major_update_to_our_detection/","created":"2023-03-21","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0},"text":"[p] detrex v0.3.0: A Major Update to Our Detection Transformer Codebase! Happy to release our **detrex v0.3.0**, after two months, there're **lots of new algorithms**, **baselines and useful tools** have been supported in detrex. We will introduce them later.\n\nHere's our github link: https://github.com/IDEA-Research/detrex\n\nIf our repo can help you for your research, please consider give us a star~\n\n## What's New\n### New Algorithms and Pre-Trained Models\nThe **newly supported algorithms** in detrex v0.3.0:\n- PnP-DETR (ICCV' 2021)\n- Anchor-DETR (AAAI' 2022)\n- DETA (ArXiv' 2022)\n- MaskDINO (CVPR' 2023)\n\nAs for now, our detrex **support 14 detection transformer algorithms**.\n\nAnd after lots of experiments, we release a set of new baselines, which **are all better than their official implementation**\n\n| Model | Box AP (detrex) | Box AP (official) |\n|:---|:---:|:---:|\n| DETA-R50 | 50.2 **(+0.1)** | 50.1 |\n| H-Deformable-DETR-R50 | 49.1 **(+0.4)** | 48.7 |\n| DINO-R50 | 49.4 **(+0.4)** | 49.0 |\n\nAnd we also release **more than 30+** pretrained weights (including the converted weights) for the community research. All the pretrained model can be downloaded from our [Model Zoo](https://detrex.readthedocs.io/en/latest/tutorials/Model_Zoo.html)\n\n**DINO detector with ViT backbone**\n\n| Model  | Lr Sched | Box AP |\n|:---|:---:|:---:|\n| DINO-ViTDet-Base (4scale) | 12 | 50.2 |\n| DINO-ViTDet-Base (4scale) | 50 | 55.0 |\n| DINO-ViTDet-Large (4scale) | 12 | 52.9 |\n| DINO-ViTDet-Large (4scale) | 50 | 57.5 |\n\n**DINO detector with strong FocalNet backbone**\n\n| Model  | Lr Sched | Box AP |\n|:---|:---:|:---:|\n| DINO-FocalNet-Large-3level (4scale) | 12 | 57.5 |\n| DINO-FocalNet-Large-4level (4scale) | 12 | 58.0 |\n| DINO-FocalNet-Large-4level (5scale) | 12 | 58.5 |\n\n### New Training Techniques\n- Supported **Mixed Precision Training** by setting `train.amp.enabled=True`: **reduce 20% to 30% GPU memory usage**.\n- Supported **EMAHook** by setting `train.model_ema.enabled=True`: which can further enhance the model performance.\n\n| Model | Lr Sched | Box AP |\n|:---|:---:|:---:|\n| DINO-R50 w/o EMA | 12 | 49.0 |\n| DINO-R50 with EMA | 12 | 49.4 **(+0.4)** |\n\n- Supported **Encoder-Decoder Gradient Checkpoint** in DINO detector which can further reduce 30% GPU memory usage.\n- Support wandb logger\n- Support a great slurm training scripts","classes":{"dataset":0.5835844278}}
{"title":"[P] OpenAssistant is now live on reddit (Open Source ChatGPT alternative)","description":"OpenAssistant bot is live on /r/ask_open_assistant. There are some limitations to the reddit bot; you can also try on the model in chat mode at https://huggingface.co/spaces/olivierdehaene/chat-llm-streaming. Model is available for free download at https://huggingface.co/OpenAssistant/oasst-sft-1-pythia-12b.\n\n\nPrompt it by creating a new text post (responds to text body of post), starting a comment with !OpenAssistant, or by replying directly to it. \n\nI have recently enabled memory for the bot so it should do a (pretty mediocre) job of continuing a conversation with you.","link":"https://www.reddit.com/r/MachineLearning/comments/11wt2fl/p_openassistant_is_now_live_on_reddit_open_source/","created":"2023-03-20","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":28},"text":"[P] OpenAssistant is now live on reddit (Open Source ChatGPT alternative) OpenAssistant bot is live on /r/ask_open_assistant. There are some limitations to the reddit bot; you can also try on the model in chat mode at https://huggingface.co/spaces/olivierdehaene/chat-llm-streaming. Model is available for free download at https://huggingface.co/OpenAssistant/oasst-sft-1-pythia-12b.\n\n\nPrompt it by creating a new text post (responds to text body of post), starting a comment with !OpenAssistant, or by replying directly to it. \n\nI have recently enabled memory for the bot so it should do a (pretty mediocre) job of continuing a conversation with you.","classes":{"dataset":0.3289864361}}
{"title":"How do we find Values in Attention, or do we need them at all?","description":"Hi everyone, I'm a bit confused about value(v) parameter in attention. At some posts after calculating attention scores they don't introduce any value(v) parameter. Sometimes they just copy and use the same values as key parameter.\n\n&amp;#x200B;\n\nI'm watching the lecture: [https://www.youtube.com/watch?v=0PPzD4mxpuM&amp;list=PL8PYTP1V4I8D0UkqW2fEhgLrnlDW9QK7z&amp;index=7](https://www.youtube.com/watch?v=0PPzD4mxpuM&amp;list=PL8PYTP1V4I8D0UkqW2fEhgLrnlDW9QK7z&amp;index=7)\n\n&amp;#x200B;\n\n1st part: We calculate attention scores. For this Seq2Seq model we take each encoder state as query vector. We take each decoder state as key vector. We choose a attention score function and calculate attention.\n\n[https://imgur.com/a/HcameRc](https://imgur.com/a/HcameRc)\n\n&amp;#x200B;\n\n2nd part: Point I get confused. We treat the value vectors same as key vectors and we do a multiplication with the attention scores if I understood correctly.\n\n[https://imgur.com/a/S7lYDGl](https://imgur.com/a/S7lYDGl)\n\n&amp;#x200B;\n\nI understand different attention papers implement differently. **But if we're going to use the value vectors same as key vectors why do we need it in the first place?** \n\nI've been trying to understand this key, query, value triplet. Read papers, posts, implementations. The database analogies but I couldn't get the intuition behind. I would be appreciated to any insights.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11ybmdd/how_do_we_find_values_in_attention_or_do_we_need/","created":"2023-03-22","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":0},"text":"How do we find Values in Attention, or do we need them at all? Hi everyone, I'm a bit confused about value(v) parameter in attention. At some posts after calculating attention scores they don't introduce any value(v) parameter. Sometimes they just copy and use the same values as key parameter.\n\n&amp;#x200B;\n\nI'm watching the lecture: [https://www.youtube.com/watch?v=0PPzD4mxpuM&amp;list=PL8PYTP1V4I8D0UkqW2fEhgLrnlDW9QK7z&amp;index=7](https://www.youtube.com/watch?v=0PPzD4mxpuM&amp;list=PL8PYTP1V4I8D0UkqW2fEhgLrnlDW9QK7z&amp;index=7)\n\n&amp;#x200B;\n\n1st part: We calculate attention scores. For this Seq2Seq model we take each encoder state as query vector. We take each decoder state as key vector. We choose a attention score function and calculate attention.\n\n[https://imgur.com/a/HcameRc](https://imgur.com/a/HcameRc)\n\n&amp;#x200B;\n\n2nd part: Point I get confused. We treat the value vectors same as key vectors and we do a multiplication with the attention scores if I understood correctly.\n\n[https://imgur.com/a/S7lYDGl](https://imgur.com/a/S7lYDGl)\n\n&amp;#x200B;\n\nI understand different attention papers implement differently. **But if we're going to use the value vectors same as key vectors why do we need it in the first place?** \n\nI've been trying to understand this key, query, value triplet. Read papers, posts, implementations. The database analogies but I couldn't get the intuition behind. I would be appreciated to any insights.","classes":{"dataset":0.1380122304}}
{"title":"CU Boulder or Brandeis for compling MS?","description":"I was admitted to both CU Boulder and Brandeis for their computational linguistics masters programs. I\u2019m leaning quite heavily toward CU for a few reasons, but just from an academic and professional standpoint, does anyone have any insight of which of those might be a more solid choice and program if all else were equal?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11y0wqq/cu_boulder_or_brandeis_for_compling_ms/","created":"2023-03-22","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":0},"text":"CU Boulder or Brandeis for compling MS? I was admitted to both CU Boulder and Brandeis for their computational linguistics masters programs. I\u2019m leaning quite heavily toward CU for a few reasons, but just from an academic and professional standpoint, does anyone have any insight of which of those might be a more solid choice and program if all else were equal?","classes":{"dataset":0.1977213323}}
{"title":"Is there any literature or courses on how to build datasets from scratch to train language models?","description":"Hi, everyone! I'm looking to get better at creating datasets to train/fine-tune different language models (mostly Transformers) for very specific tasks. I'm currently putting together a dataset from different social media sources and tagging it manually, and throughout the process my team and I had to make a lot of choices that were more guided by instinct than by theory.\n\nTherefore, I would be interested in any book/course that covers one or more of the following (or other relevant) topics for dataset creation:\n\n&amp;#x200B;\n\n\\- How to determine which data sources to use.\n\n\\- How to access the data I need (and automation if possible).\n\n\\- How to check for biases.\n\n\\- How to balance the dataset for different tasks.\n\n\\- Tagging techniques/tools.\n\n\\- Good practices/industry standards.\n\n\\- Any other topic you consider important or key for this task.\n\n&amp;#x200B;\n\nThanks in advance to all! Looking forward to reading from all of you.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11xhzq8/is_there_any_literature_or_courses_on_how_to/","created":"2023-03-21","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":0},"text":"Is there any literature or courses on how to build datasets from scratch to train language models? Hi, everyone! I'm looking to get better at creating datasets to train/fine-tune different language models (mostly Transformers) for very specific tasks. I'm currently putting together a dataset from different social media sources and tagging it manually, and throughout the process my team and I had to make a lot of choices that were more guided by instinct than by theory.\n\nTherefore, I would be interested in any book/course that covers one or more of the following (or other relevant) topics for dataset creation:\n\n&amp;#x200B;\n\n\\- How to determine which data sources to use.\n\n\\- How to access the data I need (and automation if possible).\n\n\\- How to check for biases.\n\n\\- How to balance the dataset for different tasks.\n\n\\- Tagging techniques/tools.\n\n\\- Good practices/industry standards.\n\n\\- Any other topic you consider important or key for this task.\n\n&amp;#x200B;\n\nThanks in advance to all! Looking forward to reading from all of you.","classes":{"dataset":0.3139918745}}
{"title":"Cant get the word out of a vector embeding...","description":"I want to train a transformer, Im using fast text for word embedding, i trained the model and everyting was fine, but at the end, when I wanted to convert a the output vector to a word, i find out that fast text doesent have this functionality, is there any alteranative?\nor maybe someone can explain how to do that with fast text?\nthe task I want to do is the following: I get a string as input that may or not contain a date range, for example \"the holiday was from the first of jul to the third, at 02.07 we had dinner together\", and output the date range in the string: \"01.07.2023-03.07.2023\" with that format...","link":"https://www.reddit.com/r/LanguageTechnology/comments/11xdi64/cant_get_the_word_out_of_a_vector_embeding/","created":"2023-03-21","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":2},"text":"Cant get the word out of a vector embeding... I want to train a transformer, Im using fast text for word embedding, i trained the model and everyting was fine, but at the end, when I wanted to convert a the output vector to a word, i find out that fast text doesent have this functionality, is there any alteranative?\nor maybe someone can explain how to do that with fast text?\nthe task I want to do is the following: I get a string as input that may or not contain a date range, for example \"the holiday was from the first of jul to the third, at 02.07 we had dinner together\", and output the date range in the string: \"01.07.2023-03.07.2023\" with that format...","classes":{"dataset":0.31774804}}
{"title":"Translate a meeting","description":"Hi Everyone,\n\nI need to translate a recording of a meeting of 2 hours where Dutch and French are spoken. I speak Dutch but I don't speak French. What is the best voice translator for longer spoken texts? Does anyone have tips?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11wh2zm/translate_a_meeting/","created":"2023-03-20","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":1},"text":"Translate a meeting Hi Everyone,\n\nI need to translate a recording of a meeting of 2 hours where Dutch and French are spoken. I speak Dutch but I don't speak French. What is the best voice translator for longer spoken texts? Does anyone have tips?","classes":{"dataset":0.3901901245}}
{"title":"Modern Topic Modeling/Discovery","description":"I was wondering what are the modern techniques for topic discovery for short and long text. It seems this topic to be slower advancing compared to the rest. I am aware of bertopic but tbh I always have issues finetuning it. \n\nOn a second thought I was thinking to use qna/chat gpt models in order to generate models, so I wanted to ask your opinion on some potential prompts that I could use. Essentially  a bit of brainstorming. I will open source all the gathered ideas along with mine and share the link here :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11vwtn3/modern_topic_modelingdiscovery/","created":"2023-03-19","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":2},"text":"Modern Topic Modeling/Discovery I was wondering what are the modern techniques for topic discovery for short and long text. It seems this topic to be slower advancing compared to the rest. I am aware of bertopic but tbh I always have issues finetuning it. \n\nOn a second thought I was thinking to use qna/chat gpt models in order to generate models, so I wanted to ask your opinion on some potential prompts that I could use. Essentially  a bit of brainstorming. I will open source all the gathered ideas along with mine and share the link here :)","classes":{"dataset":0.4441192448}}
{"title":"Predefined domain specific embeddings of food concepts and recipes: A case study on heterogeneous recipe datasets","description":"Although recipe data are very easy to come by nowadays, it is really hard to find a complete recipe dataset - with a list of ingredients, nutrient values per ingredient, and per recipe, allergens, etc. Recipe datasets are usually collected from social media websites where users post and publish recipes. Usually written with little to no structure, using both standardized and non-standardized units of measurement. We collect six different recipe datasets, publicly available, in different formats, and some including data in different languages. Bringing all of these datasets to the needed format for applying a machine learning (ML) pipeline for nutrient prediction [1], [2], includes data normalization using dictionary-based named entity recognition (NER), rule-based NER, as well as conversions using external domain-specific resources. From the list of ingredients, domain-specific embeddings are created using the same embedding space for all recipes - one ingredient dataset is generated. The result from this normalization process is two corpora - one with predefined ingredient embeddings and one with predefined recipe embeddings. On all six recipe datasets, the ML pipeline is evaluated. The results from this use case also confirm that the embeddings merged using the domain heuristic yield better results than the baselines.","link":"http://arxiv.org/abs/2302.01005v1","created":"2023-02-02","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Predefined domain specific embeddings of food concepts and recipes: A case study on heterogeneous recipe datasets Although recipe data are very easy to come by nowadays, it is really hard to find a complete recipe dataset - with a list of ingredients, nutrient values per ingredient, and per recipe, allergens, etc. Recipe datasets are usually collected from social media websites where users post and publish recipes. Usually written with little to no structure, using both standardized and non-standardized units of measurement. We collect six different recipe datasets, publicly available, in different formats, and some including data in different languages. Bringing all of these datasets to the needed format for applying a machine learning (ML) pipeline for nutrient prediction [1], [2], includes data normalization using dictionary-based named entity recognition (NER), rule-based NER, as well as conversions using external domain-specific resources. From the list of ingredients, domain-specific embeddings are created using the same embedding space for all recipes - one ingredient dataset is generated. The result from this normalization process is two corpora - one with predefined ingredient embeddings and one with predefined recipe embeddings. On all six recipe datasets, the ML pipeline is evaluated. The results from this use case also confirm that the embeddings merged using the domain heuristic yield better results than the baselines.","classes":{"dataset":0.1066711992}}
{"title":"Are Diffusion Models Vulnerable to Membership Inference Attacks?","description":"Diffusion-based generative models have shown great potential for image synthesis, but there is a lack of research on the security and privacy risks they may pose. In this paper, we investigate the vulnerability of diffusion models to Membership Inference Attacks (MIAs), a common privacy concern. Our results indicate that existing MIAs designed for GANs or VAE are largely ineffective on diffusion models, either due to inapplicable scenarios (e.g., requiring the discriminator of GANs) or inappropriate assumptions (e.g., closer distances between synthetic images and member images). To address this gap, we propose Step-wise Error Comparing Membership Inference (SecMI), a black-box MIA that infers memberships by assessing the matching of forward process posterior estimation at each timestep. SecMI follows the common overfitting assumption in MIA where member samples normally have smaller estimation errors, compared with hold-out samples. We consider both the standard diffusion models, e.g., DDPM, and the text-to-image diffusion models, e.g., Stable Diffusion. Experimental results demonstrate that our methods precisely infer the membership with high confidence on both of the two scenarios across six different datasets","link":"http://arxiv.org/abs/2302.01316v1","created":"2023-02-02","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Are Diffusion Models Vulnerable to Membership Inference Attacks? Diffusion-based generative models have shown great potential for image synthesis, but there is a lack of research on the security and privacy risks they may pose. In this paper, we investigate the vulnerability of diffusion models to Membership Inference Attacks (MIAs), a common privacy concern. Our results indicate that existing MIAs designed for GANs or VAE are largely ineffective on diffusion models, either due to inapplicable scenarios (e.g., requiring the discriminator of GANs) or inappropriate assumptions (e.g., closer distances between synthetic images and member images). To address this gap, we propose Step-wise Error Comparing Membership Inference (SecMI), a black-box MIA that infers memberships by assessing the matching of forward process posterior estimation at each timestep. SecMI follows the common overfitting assumption in MIA where member samples normally have smaller estimation errors, compared with hold-out samples. We consider both the standard diffusion models, e.g., DDPM, and the text-to-image diffusion models, e.g., Stable Diffusion. Experimental results demonstrate that our methods precisely infer the membership with high confidence on both of the two scenarios across six different datasets","classes":{"dataset":0.2109122574}}
{"title":"Exposing the CSI: A Systematic Investigation of CSI-based Wi-Fi Sensing Capabilities and Limitations","description":"Thanks to the ubiquitous deployment of Wi-Fi hotspots, channel state information (CSI)-based Wi-Fi sensing can unleash game-changing applications in many fields, such as healthcare, security, and entertainment. However, despite one decade of active research on Wi-Fi sensing, most existing work only considers legacy IEEE 802.11n devices, often in particular and strictly-controlled environments. Worse yet, there is a fundamental lack of understanding of the impact on CSI-based sensing of modern Wi-Fi features, such as 160-MHz bandwidth, multiple-input multiple-output (MIMO) transmissions, and increased spectral resolution in IEEE 802.11ax (Wi-Fi 6). This work aims to shed light on the impact of Wi-Fi 6 features on the sensing performance and to create a benchmark for future research on Wi-Fi sensing. To this end, we perform an extensive CSI data collection campaign involving 3 individuals, 3 environments, and 12 activities, using Wi-Fi 6 signals. An anonymized ground truth obtained through video recording accompanies our 80-GB dataset, which contains almost two hours of CSI data from three collectors. We leverage our dataset to dissect the performance of a state-of-the-art sensing framework across different environments and individuals. Our key findings suggest that (i) MIMO transmissions and higher spectral resolution might be more beneficial than larger bandwidth for sensing applications; (ii) there is a pressing need to standardize research on Wi-Fi sensing because the path towards a truly environment-independent framework is still uncertain. To ease the experiments' replicability and address the current lack of Wi-Fi 6 CSI datasets, we release our 80-GB dataset to the community.","link":"http://arxiv.org/abs/2302.00992v1","created":"2023-02-02","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Exposing the CSI: A Systematic Investigation of CSI-based Wi-Fi Sensing Capabilities and Limitations Thanks to the ubiquitous deployment of Wi-Fi hotspots, channel state information (CSI)-based Wi-Fi sensing can unleash game-changing applications in many fields, such as healthcare, security, and entertainment. However, despite one decade of active research on Wi-Fi sensing, most existing work only considers legacy IEEE 802.11n devices, often in particular and strictly-controlled environments. Worse yet, there is a fundamental lack of understanding of the impact on CSI-based sensing of modern Wi-Fi features, such as 160-MHz bandwidth, multiple-input multiple-output (MIMO) transmissions, and increased spectral resolution in IEEE 802.11ax (Wi-Fi 6). This work aims to shed light on the impact of Wi-Fi 6 features on the sensing performance and to create a benchmark for future research on Wi-Fi sensing. To this end, we perform an extensive CSI data collection campaign involving 3 individuals, 3 environments, and 12 activities, using Wi-Fi 6 signals. An anonymized ground truth obtained through video recording accompanies our 80-GB dataset, which contains almost two hours of CSI data from three collectors. We leverage our dataset to dissect the performance of a state-of-the-art sensing framework across different environments and individuals. Our key findings suggest that (i) MIMO transmissions and higher spectral resolution might be more beneficial than larger bandwidth for sensing applications; (ii) there is a pressing need to standardize research on Wi-Fi sensing because the path towards a truly environment-independent framework is still uncertain. To ease the experiments' replicability and address the current lack of Wi-Fi 6 CSI datasets, we release our 80-GB dataset to the community.","classes":{"dataset":0.7528961301}}
{"title":"Get3DHuman: Lifting StyleGAN-Human into a 3D Generative Model using Pixel-aligned Reconstruction Priors","description":"Fast generation of high-quality 3D digital humans is important to a vast number of applications ranging from entertainment to professional concerns. Recent advances in differentiable rendering have enabled the training of 3D generative models without requiring 3D ground truths. However, the quality of the generated 3D humans still has much room to improve in terms of both fidelity and diversity. In this paper, we present Get3DHuman, a novel 3D human framework that can significantly boost the realism and diversity of the generated outcomes by only using a limited budget of 3D ground-truth data. Our key observation is that the 3D generator can profit from human-related priors learned through 2D human generators and 3D reconstructors. Specifically, we bridge the latent space of Get3DHuman with that of StyleGAN-Human via a specially-designed prior network, where the input latent code is mapped to the shape and texture feature volumes spanned by the pixel-aligned 3D reconstructor. The outcomes of the prior network are then leveraged as the supervisory signals for the main generator network. To ensure effective training, we further propose three tailored losses applied to the generated feature volumes and the intermediate feature maps. Extensive experiments demonstrate that Get3DHuman greatly outperforms the other state-of-the-art approaches and can support a wide range of applications including shape interpolation, shape re-texturing, and single-view reconstruction through latent inversion.","link":"http://arxiv.org/abs/2302.01162v1","created":"2023-02-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Get3DHuman: Lifting StyleGAN-Human into a 3D Generative Model using Pixel-aligned Reconstruction Priors Fast generation of high-quality 3D digital humans is important to a vast number of applications ranging from entertainment to professional concerns. Recent advances in differentiable rendering have enabled the training of 3D generative models without requiring 3D ground truths. However, the quality of the generated 3D humans still has much room to improve in terms of both fidelity and diversity. In this paper, we present Get3DHuman, a novel 3D human framework that can significantly boost the realism and diversity of the generated outcomes by only using a limited budget of 3D ground-truth data. Our key observation is that the 3D generator can profit from human-related priors learned through 2D human generators and 3D reconstructors. Specifically, we bridge the latent space of Get3DHuman with that of StyleGAN-Human via a specially-designed prior network, where the input latent code is mapped to the shape and texture feature volumes spanned by the pixel-aligned 3D reconstructor. The outcomes of the prior network are then leveraged as the supervisory signals for the main generator network. To ensure effective training, we further propose three tailored losses applied to the generated feature volumes and the intermediate feature maps. Extensive experiments demonstrate that Get3DHuman greatly outperforms the other state-of-the-art approaches and can support a wide range of applications including shape interpolation, shape re-texturing, and single-view reconstruction through latent inversion.","classes":{"dataset":0.1675080508}}
{"title":"Eloss in the way: A Sensitive Input Quality Metrics for Intelligent Driving","description":"With the increasing complexity of the traffic environment, the importance of safety perception in intelligent driving is growing. Conventional methods in the robust perception of intelligent driving focus on training models with anomalous data, letting the deep neural network decide how to tackle anomalies. However, these models cannot adapt smoothly to the diverse and complex real-world environment. This paper proposes a new type of metric known as Eloss and offers a novel training strategy to empower perception models from the aspect of anomaly detection. Eloss is designed based on an explanation of the perception model's information compression layers. Specifically, taking inspiration from the design of a communication system, the information transmission process of an information compression network has two expectations: the amount of information changes steadily, and the information entropy continues to decrease. Then Eloss can be obtained according to the above expectations, guiding the update of related network parameters and producing a sensitive metric to identify anomalies while maintaining the model performance. Our experiments demonstrate that Eloss can deviate from the standard value by a factor over 100 with anomalous data and produce distinctive values for similar but different types of anomalies, showing the effectiveness of the proposed method. Our code is available at: (code available after paper accepted).","link":"http://arxiv.org/abs/2302.00986v1","created":"2023-02-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Eloss in the way: A Sensitive Input Quality Metrics for Intelligent Driving With the increasing complexity of the traffic environment, the importance of safety perception in intelligent driving is growing. Conventional methods in the robust perception of intelligent driving focus on training models with anomalous data, letting the deep neural network decide how to tackle anomalies. However, these models cannot adapt smoothly to the diverse and complex real-world environment. This paper proposes a new type of metric known as Eloss and offers a novel training strategy to empower perception models from the aspect of anomaly detection. Eloss is designed based on an explanation of the perception model's information compression layers. Specifically, taking inspiration from the design of a communication system, the information transmission process of an information compression network has two expectations: the amount of information changes steadily, and the information entropy continues to decrease. Then Eloss can be obtained according to the above expectations, guiding the update of related network parameters and producing a sensitive metric to identify anomalies while maintaining the model performance. Our experiments demonstrate that Eloss can deviate from the standard value by a factor over 100 with anomalous data and produce distinctive values for similar but different types of anomalies, showing the effectiveness of the proposed method. Our code is available at: (code available after paper accepted).","classes":{"dataset":0.1326745152}}
{"title":"A Light-weight CNN Model for Efficient Parkinson's Disease Diagnostics","description":"In recent years, deep learning methods have achieved great success in various fields due to their strong performance in practical applications. In this paper, we present a light-weight neural network for Parkinson's disease diagnostics, in which a series of hand-drawn data are collected to distinguish Parkinson's disease patients from healthy control subjects. The proposed model consists of a convolution neural network (CNN) cascading to long-short-term memory (LSTM) to adapt the characteristics of collected time-series signals. To make full use of their advantages, a multilayered LSTM model is firstly used to enrich features which are then concatenated with raw data and fed into a shallow one-dimensional (1D) CNN model for efficient classification. Experimental results show that the proposed model achieves a high-quality diagnostic result over multiple evaluation metrics with much fewer parameters and operations, outperforming conventional methods such as support vector machine (SVM), random forest (RF), lightgbm (LGB) and CNN-based methods.","link":"http://arxiv.org/abs/2302.00973v1","created":"2023-02-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"A Light-weight CNN Model for Efficient Parkinson's Disease Diagnostics In recent years, deep learning methods have achieved great success in various fields due to their strong performance in practical applications. In this paper, we present a light-weight neural network for Parkinson's disease diagnostics, in which a series of hand-drawn data are collected to distinguish Parkinson's disease patients from healthy control subjects. The proposed model consists of a convolution neural network (CNN) cascading to long-short-term memory (LSTM) to adapt the characteristics of collected time-series signals. To make full use of their advantages, a multilayered LSTM model is firstly used to enrich features which are then concatenated with raw data and fed into a shallow one-dimensional (1D) CNN model for efficient classification. Experimental results show that the proposed model achieves a high-quality diagnostic result over multiple evaluation metrics with much fewer parameters and operations, outperforming conventional methods such as support vector machine (SVM), random forest (RF), lightgbm (LGB) and CNN-based methods.","classes":{"dataset":0.1602863967}}
{"title":"How to choose \"Good\" Samples for Text Data Augmentation","description":"Deep learning-based text classification models need abundant labeled data to obtain competitive performance. Unfortunately, annotating large-size corpus is time-consuming and laborious. To tackle this, multiple researches try to use data augmentation to expand the corpus size. However, data augmentation may potentially produce some noisy augmented samples. There are currently no works exploring sample selection for augmented samples in nature language processing field. In this paper, we propose a novel self-training selection framework with two selectors to select the high-quality samples from data augmentation. Specifically, we firstly use an entropy-based strategy and the model prediction to select augmented samples. Considering some samples with high quality at the above step may be wrongly filtered, we propose to recall them from two perspectives of word overlap and semantic similarity. Experimental results show the effectiveness and simplicity of our framework.","link":"http://arxiv.org/abs/2302.00894v1","created":"2023-02-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"How to choose \"Good\" Samples for Text Data Augmentation Deep learning-based text classification models need abundant labeled data to obtain competitive performance. Unfortunately, annotating large-size corpus is time-consuming and laborious. To tackle this, multiple researches try to use data augmentation to expand the corpus size. However, data augmentation may potentially produce some noisy augmented samples. There are currently no works exploring sample selection for augmented samples in nature language processing field. In this paper, we propose a novel self-training selection framework with two selectors to select the high-quality samples from data augmentation. Specifically, we firstly use an entropy-based strategy and the model prediction to select augmented samples. Considering some samples with high quality at the above step may be wrongly filtered, we propose to recall them from two perspectives of word overlap and semantic similarity. Experimental results show the effectiveness and simplicity of our framework.","classes":{"dataset":0.0549077578}}
{"title":"Disentanglement of Latent Representations via Sparse Causal Interventions","description":"The process of generating data such as images is controlled by independent and unknown factors of variation. The retrieval of these variables has been studied extensively in the disentanglement, causal representation learning, and independent component analysis fields. Recently, approaches merging these domains together have shown great success. Instead of directly representing the factors of variation, the problem of disentanglement can be seen as finding the interventions on one image that yield a change to a single factor. Following this assumption, we introduce a new method for disentanglement inspired by causal dynamics that combines causality theory with vector-quantized variational autoencoders. Our model considers the quantized vectors as causal variables and links them in a causal graph. It performs causal interventions on the graph and generates atomic transitions affecting a unique factor of variation in the image. We also introduce a new task of action retrieval that consists of finding the action responsible for the transition between two images. We test our method on standard synthetic and real-world disentanglement datasets. We show that it can effectively disentangle the factors of variation and perform precise interventions on high-level semantic attributes of an image without affecting its quality, even with imbalanced data distributions.","link":"http://arxiv.org/abs/2302.00869v1","created":"2023-02-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Disentanglement of Latent Representations via Sparse Causal Interventions The process of generating data such as images is controlled by independent and unknown factors of variation. The retrieval of these variables has been studied extensively in the disentanglement, causal representation learning, and independent component analysis fields. Recently, approaches merging these domains together have shown great success. Instead of directly representing the factors of variation, the problem of disentanglement can be seen as finding the interventions on one image that yield a change to a single factor. Following this assumption, we introduce a new method for disentanglement inspired by causal dynamics that combines causality theory with vector-quantized variational autoencoders. Our model considers the quantized vectors as causal variables and links them in a causal graph. It performs causal interventions on the graph and generates atomic transitions affecting a unique factor of variation in the image. We also introduce a new task of action retrieval that consists of finding the action responsible for the transition between two images. We test our method on standard synthetic and real-world disentanglement datasets. We show that it can effectively disentangle the factors of variation and perform precise interventions on high-level semantic attributes of an image without affecting its quality, even with imbalanced data distributions.","classes":{"dataset":0.1147925258}}
{"title":"Solving the cube root of 19,683 mentally","description":"https://www.nigamanth.com/blog/2023/cube-roots-trick.html","link":"https://www.nigamanth.com/blog/2023/cube-roots-trick.html","created":"2023-02-04","tags":["hackernews"],"meta":{"score":38},"text":"Solving the cube root of 19,683 mentally https://www.nigamanth.com/blog/2023/cube-roots-trick.html","classes":{"dataset":0.4956064522}}
{"title":"The Linux Upskill Challenge","description":"https://theleo.zone/posts/linux-upskill/","link":"https://theleo.zone/posts/linux-upskill/","created":"2023-02-04","tags":["hackernews"],"meta":{"score":90},"text":"The Linux Upskill Challenge https://theleo.zone/posts/linux-upskill/","classes":{"dataset":0.4982288778}}
{"title":"Universal Summarizer","description":"https://labs.kagi.com/ai/sum","link":"https://labs.kagi.com/ai/sum","created":"2023-02-03","tags":["hackernews"],"meta":{"score":337},"text":"Universal Summarizer https://labs.kagi.com/ai/sum","classes":{"dataset":0.4774498045}}
{"title":"Show HN: DocsGPT, open-source documentation assistant, fully aware of libraries","description":"https://github.com/arc53/docsgpt","link":"https://github.com/arc53/docsgpt","created":"2023-02-03","tags":["hackernews"],"meta":{"score":158},"text":"Show HN: DocsGPT, open-source documentation assistant, fully aware of libraries https://github.com/arc53/docsgpt","classes":{"dataset":0.4832953215}}
{"title":"Shipping Graphing Calculator","description":"https://corecursive.com/shipping-graphing-calculator/","link":"https://corecursive.com/shipping-graphing-calculator/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":30},"text":"Shipping Graphing Calculator https://corecursive.com/shipping-graphing-calculator/","classes":{"dataset":0.5086761713}}
{"title":"The KLF: Chaos, magic and the band who burned \u00a31M","description":"https://johnhiggs.com/books/the-klf/","link":"https://johnhiggs.com/books/the-klf/","created":"2023-02-04","tags":["hackernews"],"meta":{"score":101},"text":"The KLF: Chaos, magic and the band who burned \u00a31M https://johnhiggs.com/books/the-klf/","classes":{"dataset":0.4757348597}}
{"title":"Update on Samsung SSD Reliability","description":"https://www.pugetsystems.com/blog/2023/02/02/update-on-samsung-ssd-reliability/","link":"https://www.pugetsystems.com/blog/2023/02/02/update-on-samsung-ssd-reliability/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":381},"text":"Update on Samsung SSD Reliability https://www.pugetsystems.com/blog/2023/02/02/update-on-samsung-ssd-reliability/","classes":{"dataset":0.5043674111}}
{"title":"Expected changes with Dropbox for macOS","description":"https://help.dropbox.com/installs/macos-support-for-expected-changes","link":"https://help.dropbox.com/installs/macos-support-for-expected-changes","created":"2023-02-04","tags":["hackernews"],"meta":{"score":108},"text":"Expected changes with Dropbox for macOS https://help.dropbox.com/installs/macos-support-for-expected-changes","classes":{"dataset":0.5203276277}}
{"title":"Polish communist era 8 bit computer used in banks, MK-45 outdated at arrival","description":"https://www.youtube.com/watch?v=CMRAMxtS21A","link":"https://www.youtube.com/watch?v=CMRAMxtS21A","created":"2023-02-04","tags":["hackernews"],"meta":{"score":64},"text":"Polish communist era 8 bit computer used in banks, MK-45 outdated at arrival https://www.youtube.com/watch?v=CMRAMxtS21A","classes":{"dataset":0.5570731759}}
{"title":"A treatise concerning the properties and effects of coffee (1792)","description":"https://publicdomainreview.org/collection/moseley-coffee","link":"https://publicdomainreview.org/collection/moseley-coffee","created":"2023-02-03","tags":["hackernews"],"meta":{"score":78},"text":"A treatise concerning the properties and effects of coffee (1792) https://publicdomainreview.org/collection/moseley-coffee","classes":{"dataset":0.5115607381}}
{"title":"Why did The Beatles get so many bad reviews?","description":"https://tedgioia.substack.com/p/why-did-the-beatles-get-so-many-bad","link":"https://tedgioia.substack.com/p/why-did-the-beatles-get-so-many-bad","created":"2023-02-04","tags":["hackernews"],"meta":{"score":121},"text":"Why did The Beatles get so many bad reviews? https://tedgioia.substack.com/p/why-did-the-beatles-get-so-many-bad","classes":{"dataset":0.4889327884}}
{"title":"The paper that made ChatGPT possible","description":"https://arxiv.org/abs/1706.03762","link":"https://arxiv.org/abs/1706.03762","created":"2023-02-04","tags":["hackernews"],"meta":{"score":58},"text":"The paper that made ChatGPT possible https://arxiv.org/abs/1706.03762","classes":{"dataset":0.5094030499}}
{"title":"Critique of the mind/body problem","description":"https://www.jsanilac.com/mind/","link":"https://www.jsanilac.com/mind/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":59},"text":"Critique of the mind/body problem https://www.jsanilac.com/mind/","classes":{"dataset":0.4663261175}}
{"title":"The pool of talented C++ developers is running dry","description":"https://www.efinancialcareers.com/news/finance/why-is-there-a-drought-in-the-talent-pool-for-c-developers","link":"https://www.efinancialcareers.com/news/finance/why-is-there-a-drought-in-the-talent-pool-for-c-developers","created":"2023-02-03","tags":["hackernews"],"meta":{"score":178},"text":"The pool of talented C++ developers is running dry https://www.efinancialcareers.com/news/finance/why-is-there-a-drought-in-the-talent-pool-for-c-developers","classes":{"dataset":0.5140485168}}
{"title":"Effective altruism has a sexual harassment problem, women say","description":"https://time.com/6252617/effective-altruism-sexual-harassment/","link":"https://time.com/6252617/effective-altruism-sexual-harassment/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":186},"text":"Effective altruism has a sexual harassment problem, women say https://time.com/6252617/effective-altruism-sexual-harassment/","classes":{"dataset":0.4974643588}}
{"title":"Hustle bros are jumping on the AI bandwagon","description":"https://www.theverge.com/2023/2/2/23582772/chatgpt-ai-get-rich-quick-schemes-hustlers-web","link":"https://www.theverge.com/2023/2/2/23582772/chatgpt-ai-get-rich-quick-schemes-hustlers-web","created":"2023-02-04","tags":["hackernews"],"meta":{"score":99},"text":"Hustle bros are jumping on the AI bandwagon https://www.theverge.com/2023/2/2/23582772/chatgpt-ai-get-rich-quick-schemes-hustlers-web","classes":{"dataset":0.5648600459}}
{"title":"Celsius Network: Final report from the examiner \u2013 lies, incompetence and Ponzis","description":"https://davidgerard.co.uk/blockchain/2023/02/01/celsius-network-final-report-from-the-examiner-lies-incompetence-and-ponzi-schemes/","link":"https://davidgerard.co.uk/blockchain/2023/02/01/celsius-network-final-report-from-the-examiner-lies-incompetence-and-ponzi-schemes/","created":"2023-02-04","tags":["hackernews"],"meta":{"score":5},"text":"Celsius Network: Final report from the examiner \u2013 lies, incompetence and Ponzis https://davidgerard.co.uk/blockchain/2023/02/01/celsius-network-final-report-from-the-examiner-lies-incompetence-and-ponzi-schemes/","classes":{"dataset":0.5081951618}}
{"title":"Adding C-style for loops to Python (2022)","description":"https://sadh.life/post/cursed-for/","link":"https://sadh.life/post/cursed-for/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":179},"text":"Adding C-style for loops to Python (2022) https://sadh.life/post/cursed-for/","classes":{"dataset":0.5066940188}}
{"title":"Still waiting for Proctorio to pay legal expenses incurred fighting their appeal","description":"https://mastodon.social/@Linkletter/109791715219572110","link":"https://mastodon.social/@Linkletter/109791715219572110","created":"2023-02-04","tags":["hackernews"],"meta":{"score":9},"text":"Still waiting for Proctorio to pay legal expenses incurred fighting their appeal https://mastodon.social/@Linkletter/109791715219572110","classes":{"dataset":0.4335934222}}
{"title":"Computational Foundations for the Second Law of Thermodynamics","description":"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/","link":"https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/","created":"2023-02-04","tags":["hackernews"],"meta":{"score":12},"text":"Computational Foundations for the Second Law of Thermodynamics https://writings.stephenwolfram.com/2023/02/computational-foundations-for-the-second-law-of-thermodynamics/","classes":{"dataset":0.5461226106}}
{"title":"Method for reducing coffee acidity","description":"https://patents.google.com/patent/US5853787A/en","link":"https://patents.google.com/patent/US5853787A/en","created":"2023-02-02","tags":["hackernews"],"meta":{"score":52},"text":"Method for reducing coffee acidity https://patents.google.com/patent/US5853787A/en","classes":{"dataset":0.4539359808}}
{"title":"Flutter desktop isn\u2019t there yet","description":"https://plei.one/blog/flutter-desktop-not-there-yet/","link":"https://plei.one/blog/flutter-desktop-not-there-yet/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":199},"text":"Flutter desktop isn\u2019t there yet https://plei.one/blog/flutter-desktop-not-there-yet/","classes":{"dataset":0.5424104929}}
{"title":"Math breakdown: Anime homing missiles","description":"https://blog.littlepolygon.com/posts/missile/","link":"https://blog.littlepolygon.com/posts/missile/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":667},"text":"Math breakdown: Anime homing missiles https://blog.littlepolygon.com/posts/missile/","classes":{"dataset":0.5670121312}}
{"title":"How to Paint Like Hayao Miyazaki","description":"https://animationobsessive.substack.com/p/how-to-paint-like-hayao-miyazaki","link":"https://animationobsessive.substack.com/p/how-to-paint-like-hayao-miyazaki","created":"2023-02-03","tags":["hackernews"],"meta":{"score":208},"text":"How to Paint Like Hayao Miyazaki https://animationobsessive.substack.com/p/how-to-paint-like-hayao-miyazaki","classes":{"dataset":0.5073922873}}
{"title":"Wind chill on Mt. Washington NH minus 108, temp -46, wind 98 gusting 107","description":"https://www.mountwashington.org/experience-the-weather/current-summit-conditions.aspx","link":"https://www.mountwashington.org/experience-the-weather/current-summit-conditions.aspx","created":"2023-02-04","tags":["hackernews"],"meta":{"score":28},"text":"Wind chill on Mt. Washington NH minus 108, temp -46, wind 98 gusting 107 https://www.mountwashington.org/experience-the-weather/current-summit-conditions.aspx","classes":{"dataset":0.5329606533}}
{"title":"The future (and the past) of the web is server side rendering","description":"https://deno.com/blog/the-future-and-past-is-server-side-rendering","link":"https://deno.com/blog/the-future-and-past-is-server-side-rendering","created":"2023-02-03","tags":["hackernews"],"meta":{"score":288},"text":"The future (and the past) of the web is server side rendering https://deno.com/blog/the-future-and-past-is-server-side-rendering","classes":{"dataset":0.5324297547}}
{"title":"Improving Rust compile times to enable adoption of memory safety","description":"https://www.memorysafety.org/blog/remy-rakic-compile-times/","link":"https://www.memorysafety.org/blog/remy-rakic-compile-times/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":225},"text":"Improving Rust compile times to enable adoption of memory safety https://www.memorysafety.org/blog/remy-rakic-compile-times/","classes":{"dataset":0.5096614957}}
{"title":"I was laid off by kinder, gentler capitalism","description":"https://medium.com/@carolemert/i-was-laid-off-by-kinder-gentler-capitalism-5a218d47f8c6","link":"https://medium.com/@carolemert/i-was-laid-off-by-kinder-gentler-capitalism-5a218d47f8c6","created":"2023-02-04","tags":["hackernews"],"meta":{"score":11},"text":"I was laid off by kinder, gentler capitalism https://medium.com/@carolemert/i-was-laid-off-by-kinder-gentler-capitalism-5a218d47f8c6","classes":{"dataset":0.4905786216}}
{"title":"Want anonymity? Make a persona not a mystery","description":"https://sive.rs/anon","link":"https://sive.rs/anon","created":"2023-02-03","tags":["hackernews"],"meta":{"score":440},"text":"Want anonymity? Make a persona not a mystery https://sive.rs/anon","classes":{"dataset":0.4927727282}}
{"title":"A stable protein nanowire of electric bacteria gives clues to climate change","description":"https://phys.org/news/2023-02-ultra-stable-protein-nanowire-electric-bacteria.html","link":"https://phys.org/news/2023-02-ultra-stable-protein-nanowire-electric-bacteria.html","created":"2023-02-03","tags":["hackernews"],"meta":{"score":40},"text":"A stable protein nanowire of electric bacteria gives clues to climate change https://phys.org/news/2023-02-ultra-stable-protein-nanowire-electric-bacteria.html","classes":{"dataset":0.4880096018}}
{"title":"Starting February 9, we will no longer support free access to the Twitter API","description":"https://twitter.com/twitterdev/status/1621026986784337922","link":"https://twitter.com/twitterdev/status/1621026986784337922","created":"2023-02-02","tags":["hackernews"],"meta":{"score":777},"text":"Starting February 9, we will no longer support free access to the Twitter API https://twitter.com/twitterdev/status/1621026986784337922","classes":{"dataset":0.5065721869}}
{"title":"Weird things I learned while writing an x86 emulator","description":"https://www.timdbg.com/posts/useless-x86-trivia/","link":"https://www.timdbg.com/posts/useless-x86-trivia/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":209},"text":"Weird things I learned while writing an x86 emulator https://www.timdbg.com/posts/useless-x86-trivia/","classes":{"dataset":0.5021153688}}
{"title":"The unequal treatment of demographic groups by ChatGPT/OpenAI content moderation","description":"https://davidrozado.substack.com/p/openaicms","link":"https://davidrozado.substack.com/p/openaicms","created":"2023-02-02","tags":["hackernews"],"meta":{"score":500},"text":"The unequal treatment of demographic groups by ChatGPT/OpenAI content moderation https://davidrozado.substack.com/p/openaicms","classes":{"dataset":0.5196256042}}
{"title":"Hand-Tracking with Three.js","description":"https://rdtr01.xl.digital/","link":"https://rdtr01.xl.digital/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":125},"text":"Hand-Tracking with Three.js https://rdtr01.xl.digital/","classes":{"dataset":0.507349968}}
{"title":"The Oil Thieves of Nigeria","description":"https://newlinesmag.com/reportage/the-oil-thieves-of-nigeria/","link":"https://newlinesmag.com/reportage/the-oil-thieves-of-nigeria/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":66},"text":"The Oil Thieves of Nigeria https://newlinesmag.com/reportage/the-oil-thieves-of-nigeria/","classes":{"dataset":0.5139746666}}
{"title":"Show HN: Emoji generator using Chat-GPT","description":"https://www.emojai.app/","link":"https://www.emojai.app/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":12},"text":"Show HN: Emoji generator using Chat-GPT https://www.emojai.app/","classes":{"dataset":0.4682900012}}
{"title":"Major leak reveals new version of Microsoft Bing powered by ChatGPT-4 AI","description":"https://www.windowscentral.com/microsoft/major-leak-reveals-revolutionary-new-version-of-microsoft-bing-powered-by-chatgpt-4-ai","link":"https://www.windowscentral.com/microsoft/major-leak-reveals-revolutionary-new-version-of-microsoft-bing-powered-by-chatgpt-4-ai","created":"2023-02-03","tags":["hackernews"],"meta":{"score":33},"text":"Major leak reveals new version of Microsoft Bing powered by ChatGPT-4 AI https://www.windowscentral.com/microsoft/major-leak-reveals-revolutionary-new-version-of-microsoft-bing-powered-by-chatgpt-4-ai","classes":{"dataset":0.5004668236}}
{"title":"AMD CEO Says It's Limiting Supply of CPUs and GPUs to Maintain High Prices","description":"https://www.extremetech.com/computing/342781-amd-ceo-says-its-limiting-supply-of-cpus-and-gpus-to-maintain-high-prices","link":"https://www.extremetech.com/computing/342781-amd-ceo-says-its-limiting-supply-of-cpus-and-gpus-to-maintain-high-prices","created":"2023-02-03","tags":["hackernews"],"meta":{"score":49},"text":"AMD CEO Says It's Limiting Supply of CPUs and GPUs to Maintain High Prices https://www.extremetech.com/computing/342781-amd-ceo-says-its-limiting-supply-of-cpus-and-gpus-to-maintain-high-prices","classes":{"dataset":0.543861568}}
{"title":"How Derek Sivers Uses Ruby And His Programming Philosophy","description":"https://share.transistor.fm/s/3660db24","link":"https://share.transistor.fm/s/3660db24","created":"2023-02-04","tags":["hackernews"],"meta":{"score":5},"text":"How Derek Sivers Uses Ruby And His Programming Philosophy https://share.transistor.fm/s/3660db24","classes":{"dataset":0.5266939998}}
{"title":"Revising the Legacy of William Rowan Hamilton","description":"https://universitytimes.ie/2022/02/revising-the-legacy-of-william-rowan-hamilton/","link":"https://universitytimes.ie/2022/02/revising-the-legacy-of-william-rowan-hamilton/","created":"2023-02-04","tags":["hackernews"],"meta":{"score":3},"text":"Revising the Legacy of William Rowan Hamilton https://universitytimes.ie/2022/02/revising-the-legacy-of-william-rowan-hamilton/","classes":{"dataset":0.5395832062}}
{"title":"Estimating square roots in your head","description":"https://gregorygundersen.com/blog/2023/02/01/estimating-square-roots/","link":"https://gregorygundersen.com/blog/2023/02/01/estimating-square-roots/","created":"2023-02-02","tags":["hackernews"],"meta":{"score":302},"text":"Estimating square roots in your head https://gregorygundersen.com/blog/2023/02/01/estimating-square-roots/","classes":{"dataset":0.5510450006}}
{"title":"Blink virtual machine now supports running GUI programs","description":"https://twitter.com/JustineTunney/status/1621415193296388096","link":"https://twitter.com/JustineTunney/status/1621415193296388096","created":"2023-02-03","tags":["hackernews"],"meta":{"score":332},"text":"Blink virtual machine now supports running GUI programs https://twitter.com/JustineTunney/status/1621415193296388096","classes":{"dataset":0.4914220572}}
{"title":"Seawater electrolysis by adjusting the local reaction environment of a catalyst","description":"https://www.nature.com/articles/s41560-023-01195-x","link":"https://www.nature.com/articles/s41560-023-01195-x","created":"2023-02-03","tags":["hackernews"],"meta":{"score":173},"text":"Seawater electrolysis by adjusting the local reaction environment of a catalyst https://www.nature.com/articles/s41560-023-01195-x","classes":{"dataset":0.5038319826}}
{"title":"Bir Tawil","description":"https://en.wikipedia.org/wiki/Bir_Tawil","link":"https://en.wikipedia.org/wiki/Bir_Tawil","created":"2023-02-02","tags":["hackernews"],"meta":{"score":40},"text":"Bir Tawil https://en.wikipedia.org/wiki/Bir_Tawil","classes":{"dataset":0.5043385625}}
{"title":"Until further notice, think twice before using Google to download software","description":"https://arstechnica.com/information-technology/2023/02/until-further-notice-think-twice-before-using-google-to-download-software/","link":"https://arstechnica.com/information-technology/2023/02/until-further-notice-think-twice-before-using-google-to-download-software/","created":"2023-02-03","tags":["hackernews"],"meta":{"score":310},"text":"Until further notice, think twice before using Google to download software https://arstechnica.com/information-technology/2023/02/until-further-notice-think-twice-before-using-google-to-download-software/","classes":{"dataset":0.4997873008}}
{"title":"Saturday Daily Thread: Resource Request and Sharing! Daily Thread","description":"Found a neat resource related to Python over the past week? Looking for a resource to explain a certain topic?\n\nUse this thread to chat about and share Python resources!","link":"https://www.reddit.com/r/Python/comments/10szhe5/saturday_daily_thread_resource_request_and/","created":"2023-02-04","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Saturday Daily Thread: Resource Request and Sharing! Daily Thread Found a neat resource related to Python over the past week? Looking for a resource to explain a certain topic?\n\nUse this thread to chat about and share Python resources!","classes":{"dataset":0.4916352034}}
{"title":"My first game in Python - 3 IN A ROW - with TKINTER library","description":"Hi, this is my first game created in Python, I have used the Tkinter library. I would like you to tell me how you see the game. Thank you!\n\nLINK: [3 IN A ROW](https://github.com/Conper/TicTacToe)\n\n&amp;#x200B;\n\n[PREVIEW](https://i.redd.it/3ipjtog371ga1.gif)","link":"https://www.reddit.com/r/Python/comments/10sn2cx/my_first_game_in_python_3_in_a_row_with_tkinter/","created":"2023-02-03","tags":["python","reddit"],"meta":{"num_comments":14},"text":"My first game in Python - 3 IN A ROW - with TKINTER library Hi, this is my first game created in Python, I have used the Tkinter library. I would like you to tell me how you see the game. Thank you!\n\nLINK: [3 IN A ROW](https://github.com/Conper/TicTacToe)\n\n&amp;#x200B;\n\n[PREVIEW](https://i.redd.it/3ipjtog371ga1.gif)","classes":{"dataset":0.4958479702}}
{"title":"Ansible vs Python for workstations and VM installments","description":"At my place, there is a big code base of Python scripts, managed by a simple milestone system, that responsible for installing workstations of Developers (everyone is developing on Ubuntu)\n\nThe scripts are doing pretty basic stuff that prepares the machine to be ready to use. For example: installing vscode, docker, configure pip and a lot more\n\nI have been thinking about refactoring this codebase to be a set of ansible playbooks for a number of reasons:\n1. Ansible using states and the Python scripts (if no check is written that the state exists) can do the install all over again.\n2. Ansible SSH framework\n3. The combination of the SSH and the states will let us run all of the playbooks on the entire workstations whenever there are new updates that we are need to distribute.\n4. Ansible seems to have big community and it will allow us to use playbooks written by its community\n5. We want a tool for installing basic requirements on VMs, and Ansible feels like a good tool. But, it will create technical debt if we will invest both on the scripts for users and the playbooks for VMs.\n\nAnd despite all that, do you thinks these reasons really justify this big refactor? \nOr maybe we are just overhyped about ansible..","link":"https://www.reddit.com/r/Python/comments/10t7cng/ansible_vs_python_for_workstations_and_vm/","created":"2023-02-04","tags":["python","reddit"],"meta":{"num_comments":1},"text":"Ansible vs Python for workstations and VM installments At my place, there is a big code base of Python scripts, managed by a simple milestone system, that responsible for installing workstations of Developers (everyone is developing on Ubuntu)\n\nThe scripts are doing pretty basic stuff that prepares the machine to be ready to use. For example: installing vscode, docker, configure pip and a lot more\n\nI have been thinking about refactoring this codebase to be a set of ansible playbooks for a number of reasons:\n1. Ansible using states and the Python scripts (if no check is written that the state exists) can do the install all over again.\n2. Ansible SSH framework\n3. The combination of the SSH and the states will let us run all of the playbooks on the entire workstations whenever there are new updates that we are need to distribute.\n4. Ansible seems to have big community and it will allow us to use playbooks written by its community\n5. We want a tool for installing basic requirements on VMs, and Ansible feels like a good tool. But, it will create technical debt if we will invest both on the scripts for users and the playbooks for VMs.\n\nAnd despite all that, do you thinks these reasons really justify this big refactor? \nOr maybe we are just overhyped about ansible..","classes":{"dataset":0.0000466739}}
{"title":"AI, Python and Wordpress","description":"Hi, I am doing a casestudy in terms of how good would AI-generated blogposts rank in Google.\n\n  \nMy tool can be found here, it basically generates blogposts, updates it to wordpress - everything from your commandline.\n\n[https://github.com/grumpyp/blogging-with-ai](https://github.com/grumpyp/blogging-with-ai)  \n\n\nHappy to get feedback!","link":"https://www.reddit.com/r/Python/comments/10ssjii/ai_python_and_wordpress/","created":"2023-02-03","tags":["python","reddit"],"meta":{"num_comments":8},"text":"AI, Python and Wordpress Hi, I am doing a casestudy in terms of how good would AI-generated blogposts rank in Google.\n\n  \nMy tool can be found here, it basically generates blogposts, updates it to wordpress - everything from your commandline.\n\n[https://github.com/grumpyp/blogging-with-ai](https://github.com/grumpyp/blogging-with-ai)  \n\n\nHappy to get feedback!","classes":{"dataset":0.2470657974}}
{"title":"opinions about my project - sushi","description":"**Before going any further, the project is still in early stage. It can be used because its already published to pypi but mainly I wanted some feedback about it**  \n\n\nHey again r/python,\n\nI wanted to get some feedback about my new project: sushi. It allows you to run functions from any language (for example cpp) inside e.g python! Some people may remember that name from my another project, that was deleted and replaced with this project. The core is written in python.\n\nIt's still in early stage and everything may change, so here's what to note:\n\n* readme is ready\n* wiki is *half ready*\n* it can be installed by pip (name: sushipy)\n* there might be limited support for languages\n* lots of bugs\n\nHope to get some feedback from you!\n\ngithub repo: [here](https://github.com/dev-sushi/sushi)","link":"https://www.reddit.com/r/Python/comments/10styuv/opinions_about_my_project_sushi/","created":"2023-02-03","tags":["python","reddit"],"meta":{"num_comments":5},"text":"opinions about my project - sushi **Before going any further, the project is still in early stage. It can be used because its already published to pypi but mainly I wanted some feedback about it**  \n\n\nHey again r/python,\n\nI wanted to get some feedback about my new project: sushi. It allows you to run functions from any language (for example cpp) inside e.g python! Some people may remember that name from my another project, that was deleted and replaced with this project. The core is written in python.\n\nIt's still in early stage and everything may change, so here's what to note:\n\n* readme is ready\n* wiki is *half ready*\n* it can be installed by pip (name: sushipy)\n* there might be limited support for languages\n* lots of bugs\n\nHope to get some feedback from you!\n\ngithub repo: [here](https://github.com/dev-sushi/sushi)","classes":{"dataset":0.4902654886}}
{"title":"PokerPy , Python module for precise and fast Texas Hold'em Poker probability calculations.","description":"&amp;#x200B;\n\n**LINK:** [PokerPy](https://github.com/glpcc/PokerPy)\n\nHi, I made this module to learn C++ and Python integration and also to in the future maybe build a Poker AI. But I think this module can still be usefull for building automated poker scripts and apps easly form python.\n\nIn my windows machine it takes around 0.7secs for all calculations for 7 players with 2 cards each. In my Linux machine (worst CPU) it takes less (around 0.5 secs) for some reason :)\n\nAny thing more than 2 cards per player can be considered realtime.\n\nAny recommendation or comment is gladly welcomed.","link":"https://www.reddit.com/r/Python/comments/10rodh3/pokerpy_python_module_for_precise_and_fast_texas/","created":"2023-02-02","tags":["python","reddit"],"meta":{"num_comments":55},"text":"PokerPy , Python module for precise and fast Texas Hold'em Poker probability calculations. &amp;#x200B;\n\n**LINK:** [PokerPy](https://github.com/glpcc/PokerPy)\n\nHi, I made this module to learn C++ and Python integration and also to in the future maybe build a Poker AI. But I think this module can still be usefull for building automated poker scripts and apps easly form python.\n\nIn my windows machine it takes around 0.7secs for all calculations for 7 players with 2 cards each. In my Linux machine (worst CPU) it takes less (around 0.5 secs) for some reason :)\n\nAny thing more than 2 cards per player can be considered realtime.\n\nAny recommendation or comment is gladly welcomed.","classes":{"dataset":0.4989694655}}
{"title":"\"Introducing \"callpyback\": Last callbacks for your Python functions you will ever need - Feedback and Contributions Wanted!\"","description":"https://github.com/samuelgregorovic/callpyback\n\nWe are proud to announce the release of our new Python library, \"callpyback\" - a flexible and powerful tool for adding callbacks to your functions. With its wide range of features, you can customize the behavior of your functions in different stages of their execution, making it easier to build robust and reliable applications.\n\nIf you're a Python developer, we invite you to check out \"callpyback\" on GitHub at https://github.com/samuelgregorovic/callpyback. We would also love to hear your feedback and get your contributions to the project.\n\nThe \"callpyback\" library is still in its early stages, and we believe there is a lot of room for improvement. If you have any suggestions, bug reports, or feature requests, feel free to open an issue or submit a pull request on GitHub. Your contribution can help us make this library even better!\n\nWe hope you enjoy using \"callpyback\" as much as we enjoyed building it! Thank you for your support and we look forward to hearing from you.","link":"https://www.reddit.com/r/Python/comments/10s3uzq/introducing_callpyback_last_callbacks_for_your/","created":"2023-02-03","tags":["python","reddit"],"meta":{"num_comments":24},"text":"\"Introducing \"callpyback\": Last callbacks for your Python functions you will ever need - Feedback and Contributions Wanted!\" https://github.com/samuelgregorovic/callpyback\n\nWe are proud to announce the release of our new Python library, \"callpyback\" - a flexible and powerful tool for adding callbacks to your functions. With its wide range of features, you can customize the behavior of your functions in different stages of their execution, making it easier to build robust and reliable applications.\n\nIf you're a Python developer, we invite you to check out \"callpyback\" on GitHub at https://github.com/samuelgregorovic/callpyback. We would also love to hear your feedback and get your contributions to the project.\n\nThe \"callpyback\" library is still in its early stages, and we believe there is a lot of room for improvement. If you have any suggestions, bug reports, or feature requests, feel free to open an issue or submit a pull request on GitHub. Your contribution can help us make this library even better!\n\nWe hope you enjoy using \"callpyback\" as much as we enjoyed building it! Thank you for your support and we look forward to hearing from you.","classes":{"dataset":0.5366292}}
{"title":"Sanic Security: An effective, simple, and async security library for the Sanic framework.","description":"Sanic Security is an authentication, authorization, and verification library designed for use with [Sanic](https://github.com/huge-success/sanic). This library contains a variety of features including:\n\n* Login, registration, and authentication (including access/refresh tokens)\n* Two-factor authentication\n* Two-step verification\n* Captcha\n* Role based authorization with wildcard permissions\n\nIntended to be an out-of-the-box security solution.\n\nThe repository README comes with in depth explanations and documentation. [https://github.com/sunset-developer/sanic-security](https://github.com/sunset-developer/sanic-security)","link":"https://www.reddit.com/r/Python/comments/10spyyd/sanic_security_an_effective_simple_and_async/","created":"2023-02-03","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Sanic Security: An effective, simple, and async security library for the Sanic framework. Sanic Security is an authentication, authorization, and verification library designed for use with [Sanic](https://github.com/huge-success/sanic). This library contains a variety of features including:\n\n* Login, registration, and authentication (including access/refresh tokens)\n* Two-factor authentication\n* Two-step verification\n* Captcha\n* Role based authorization with wildcard permissions\n\nIntended to be an out-of-the-box security solution.\n\nThe repository README comes with in depth explanations and documentation. [https://github.com/sunset-developer/sanic-security](https://github.com/sunset-developer/sanic-security)","classes":{"dataset":0.4652621746}}
{"title":"How RAT Mutants, in Python, Steal Data and Evade Detection","description":"[https://hackernoon.com/how-rat-mutants-in-python-steal-data-and-evade-detection](https://hackernoon.com/how-rat-mutants-in-python-steal-data-and-evade-detection)\n\nEven though malicious Python packages are found every day by our security researchers, a new type of malware we call RAT mutants is catching our attention. \n\nThe malware has shifted and adapted over time to be more evasive and dangerous. \n\nThis is the story of how they can steal your cryptocurrency wallets and personal data, remotely control your mouse and keyboard, and evolve to evade detection.","link":"https://www.reddit.com/r/Python/comments/10sm06c/how_rat_mutants_in_python_steal_data_and_evade/","created":"2023-02-03","tags":["python","reddit"],"meta":{"num_comments":0},"text":"How RAT Mutants, in Python, Steal Data and Evade Detection [https://hackernoon.com/how-rat-mutants-in-python-steal-data-and-evade-detection](https://hackernoon.com/how-rat-mutants-in-python-steal-data-and-evade-detection)\n\nEven though malicious Python packages are found every day by our security researchers, a new type of malware we call RAT mutants is catching our attention. \n\nThe malware has shifted and adapted over time to be more evasive and dangerous. \n\nThis is the story of how they can steal your cryptocurrency wallets and personal data, remotely control your mouse and keyboard, and evolve to evade detection.","classes":{"dataset":0.4596801698}}
{"title":"[PYGAME] THE SHIP THAT FIRES BULLETS in a version of mine.","description":"Hi everyone, it is nice to meet you all from all over the world\n\nI am a beginner of Python, this is my first project - programming a game based on the book \"Python Crash Course of Eric Matthes\". Since I find that there are a lot of readers of this book but rarely someone did this project, I want to share my code thru Git.\n\nIf you need it you can take it. I also need some STARS for motivation only. Please drop some for me. Thank you guys\n\nLink:  [MauricePham/Alien-Invasion: \\[PYGAME\\] The invasion of Aliens (github.com)](https://github.com/MauricePham/Alien-Invasion)","link":"https://www.reddit.com/r/Python/comments/10se0dt/pygame_the_ship_that_fires_bullets_in_a_version/","created":"2023-02-03","tags":["python","reddit"],"meta":{"num_comments":5},"text":"[PYGAME] THE SHIP THAT FIRES BULLETS in a version of mine. Hi everyone, it is nice to meet you all from all over the world\n\nI am a beginner of Python, this is my first project - programming a game based on the book \"Python Crash Course of Eric Matthes\". Since I find that there are a lot of readers of this book but rarely someone did this project, I want to share my code thru Git.\n\nIf you need it you can take it. I also need some STARS for motivation only. Please drop some for me. Thank you guys\n\nLink:  [MauricePham/Alien-Invasion: \\[PYGAME\\] The invasion of Aliens (github.com)](https://github.com/MauricePham/Alien-Invasion)","classes":{"dataset":0.3004474342}}
{"title":"GPT-2 small model (124M params) hw requirements","description":"Hey, I was wandering how much VRAM and RAM do I need for running (inference only) gpt2-small model from hugging face, but was not able to find anything. Can somebody help please?","link":"https://www.reddit.com/r/deeplearning/comments/10st418/gpt2_small_model_124m_params_hw_requirements/","created":"2023-02-03","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":3},"text":"GPT-2 small model (124M params) hw requirements Hey, I was wandering how much VRAM and RAM do I need for running (inference only) gpt2-small model from hugging face, but was not able to find anything. Can somebody help please?","classes":{"dataset":0.3406044543}}
{"title":"What hardware specifications are generally required for AI/ML/DL","description":"What hardware specifications are generally required for AI/ML/DL","link":"https://www.reddit.com/r/deeplearning/comments/10sw8k8/what_hardware_specifications_are_generally/","created":"2023-02-03","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":3},"text":"What hardware specifications are generally required for AI/ML/DL What hardware specifications are generally required for AI/ML/DL","classes":{"dataset":0.4116826952}}
{"title":"Implementing DetectGPT from scratch - Open-sourcing DetectGPT","description":"We've implemented DetectGPT paper in Pytorch. Our implementation can be found below\n\nGithub: [https://github.com/BurhanUlTayyab/DetectGPT](https://github.com/BurhanUlTayyab/DetectGPT)\n\nWebsite: [https://gptzero.sg](https://gptzero.sg)\n\nDiscord: [https://discord.com/invite/F3kFan28vH](https://discord.com/invite/F3kFan28vH)\n\nWe're also working on a GPTZerov2 (inspired by LLM based transformers and GANs), which would be more accurate, and can detect lines changed by humans.\n\nPlease give some feedback on our work.\n\nThanks","link":"https://www.reddit.com/r/deeplearning/comments/10sk6dl/implementing_detectgpt_from_scratch_opensourcing/","created":"2023-02-03","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":0},"text":"Implementing DetectGPT from scratch - Open-sourcing DetectGPT We've implemented DetectGPT paper in Pytorch. Our implementation can be found below\n\nGithub: [https://github.com/BurhanUlTayyab/DetectGPT](https://github.com/BurhanUlTayyab/DetectGPT)\n\nWebsite: [https://gptzero.sg](https://gptzero.sg)\n\nDiscord: [https://discord.com/invite/F3kFan28vH](https://discord.com/invite/F3kFan28vH)\n\nWe're also working on a GPTZerov2 (inspired by LLM based transformers and GANs), which would be more accurate, and can detect lines changed by humans.\n\nPlease give some feedback on our work.\n\nThanks","classes":{"dataset":0.3475192785}}
{"title":"Why are FPGAs better than GPUs for deep learning?","description":"I've worked for some years developing scientific applications for GPUs. Recently we've been trying to integrate FPGAs into our technologies; and consequently I've been trying to understand what they are useful for.\n\nI've found many posts here and there that claim that FPGAs are better suited than GPUs to accelerate Deep Learning/AI workloads (for example, [this one by Intel](https://www.intel.com/content/www/us/en/artificial-intelligence/programmable/fpga-gpu.html)). However, I don't understand why that would be the case. I think the problem is that all those posts try to explain what an FPGA is and what its differences are to a GPU, so that people that work on Deep Learning understand why they are better suited. Nevertheless, my position is exactly the opposite: I know quite well how a GPU works and what it is good for, I know well enough how an FPGA works and how it differs from a GPU, **but I do not know enough about Deep Learning** to understand why Deep Learning applicatios would benefit more from the special features of FPGAs rather than from the immense parallelism GPUs offers.\n\nAs far as I know, an FPGA will never beat a traditional GPU in terms of raw parallelism (or, if it does, it would be much less cost efficient). Thus, when it comes to matrix multiplications, i.e. the main operation in Deep Learning models, or convolutions, GPUs can parallelly work with much bigger matrices. The only explanation I can think of is that traditional Deep Learning applications don't necessarily use such big matrices, but rather smaller ones that can also be fully parallelized in FPGAs and benefit highly from custom-hardware optimizations (optimized matrix multiplications/tensor operations, working with reduced-bit values such as FP16, deep-pipeline parallelism, ...). However, given the recent increase in popularity of very complex models (GPT-3, dall-e, and the like) which boast using millions or even billions of parameters, it is hard to imagine that popular deep learning models work with small matrices of which fully parallel architectures can be synthesized in FPGAs.\n\nWhat am I missing? Any insight will be greatly appreciated.\n\nEDIT: I know TPUs are a thing and are regarded as \"the best option\" for deep learning acceleration. I will not be working with them, however, so I am not interested in knowing the details on how they compare with GPUs or FPGAs.","link":"https://www.reddit.com/r/deeplearning/comments/10s3u1s/why_are_fpgas_better_than_gpus_for_deep_learning/","created":"2023-02-03","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":21},"text":"Why are FPGAs better than GPUs for deep learning? I've worked for some years developing scientific applications for GPUs. Recently we've been trying to integrate FPGAs into our technologies; and consequently I've been trying to understand what they are useful for.\n\nI've found many posts here and there that claim that FPGAs are better suited than GPUs to accelerate Deep Learning/AI workloads (for example, [this one by Intel](https://www.intel.com/content/www/us/en/artificial-intelligence/programmable/fpga-gpu.html)). However, I don't understand why that would be the case. I think the problem is that all those posts try to explain what an FPGA is and what its differences are to a GPU, so that people that work on Deep Learning understand why they are better suited. Nevertheless, my position is exactly the opposite: I know quite well how a GPU works and what it is good for, I know well enough how an FPGA works and how it differs from a GPU, **but I do not know enough about Deep Learning** to understand why Deep Learning applicatios would benefit more from the special features of FPGAs rather than from the immense parallelism GPUs offers.\n\nAs far as I know, an FPGA will never beat a traditional GPU in terms of raw parallelism (or, if it does, it would be much less cost efficient). Thus, when it comes to matrix multiplications, i.e. the main operation in Deep Learning models, or convolutions, GPUs can parallelly work with much bigger matrices. The only explanation I can think of is that traditional Deep Learning applications don't necessarily use such big matrices, but rather smaller ones that can also be fully parallelized in FPGAs and benefit highly from custom-hardware optimizations (optimized matrix multiplications/tensor operations, working with reduced-bit values such as FP16, deep-pipeline parallelism, ...). However, given the recent increase in popularity of very complex models (GPT-3, dall-e, and the like) which boast using millions or even billions of parameters, it is hard to imagine that popular deep learning models work with small matrices of which fully parallel architectures can be synthesized in FPGAs.\n\nWhat am I missing? Any insight will be greatly appreciated.\n\nEDIT: I know TPUs are a thing and are regarded as \"the best option\" for deep learning acceleration. I will not be working with them, however, so I am not interested in knowing the details on how they compare with GPUs or FPGAs.","classes":{"dataset":0.491751045}}
{"title":"[Theory] Saliency Maps in Convolutional Neural Networks","description":"Saliency Maps in Convolutional Neural Networks\n\n[https://debuggercafe.com/saliency-maps-in-convolutional-neural-networks/](https://debuggercafe.com/saliency-maps-in-convolutional-neural-networks/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/aiu5b82savfa1.png?width=1000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4b89deecf83bff63dc1400336913b6250e4941de","link":"https://www.reddit.com/r/deeplearning/comments/10s5rzr/theory_saliency_maps_in_convolutional_neural/","created":"2023-02-03","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":0},"text":"[Theory] Saliency Maps in Convolutional Neural Networks Saliency Maps in Convolutional Neural Networks\n\n[https://debuggercafe.com/saliency-maps-in-convolutional-neural-networks/](https://debuggercafe.com/saliency-maps-in-convolutional-neural-networks/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/aiu5b82savfa1.png?width=1000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=4b89deecf83bff63dc1400336913b6250e4941de","classes":{"dataset":0.2941137552}}
{"title":"VAE with bernoulli prior, HELP!!!","description":"I am trying to train a VAE whose prior is a Bernoulli (p=0.5). It is basically from the papers on categorical VAE and Gumbel-softmax:\n\n1. [https://arxiv.org/abs/1611.01144](https://arxiv.org/abs/1611.01144)\n2. [https://arxiv.org/abs/1611.00712](https://arxiv.org/abs/1611.00712)\n3. [https://www.researchgate.net/publication/336823794\\_A\\_Binary\\_Variational\\_Autoencoder\\_for\\_Hashing](https://www.researchgate.net/publication/336823794_A_Binary_Variational_Autoencoder_for_Hashing)\n\nI am training it using the MNIST dataset, with fully connected layers. The encoder part is with an input size of 728 followed by 2 hidden layers with 521 and 256 neurons respectively. The latent layer has 500 neurons. The reason for Bernoulli prior is so that I get a binary latent representation of the input data. The reconstructions are pretty good, however, when I am doing a random sampling of Bernoulli(p=0.5) for the decoder, the generated data is garbage. \n\nThe objective function is theMSE of the reconstruction + the KL divergence of the latent distribution..\n\n&amp;#x200B;\n\nAny suggestions???","link":"https://www.reddit.com/r/deeplearning/comments/10s0zi6/vae_with_bernoulli_prior_help/","created":"2023-02-02","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":1},"text":"VAE with bernoulli prior, HELP!!! I am trying to train a VAE whose prior is a Bernoulli (p=0.5). It is basically from the papers on categorical VAE and Gumbel-softmax:\n\n1. [https://arxiv.org/abs/1611.01144](https://arxiv.org/abs/1611.01144)\n2. [https://arxiv.org/abs/1611.00712](https://arxiv.org/abs/1611.00712)\n3. [https://www.researchgate.net/publication/336823794\\_A\\_Binary\\_Variational\\_Autoencoder\\_for\\_Hashing](https://www.researchgate.net/publication/336823794_A_Binary_Variational_Autoencoder_for_Hashing)\n\nI am training it using the MNIST dataset, with fully connected layers. The encoder part is with an input size of 728 followed by 2 hidden layers with 521 and 256 neurons respectively. The latent layer has 500 neurons. The reason for Bernoulli prior is so that I get a binary latent representation of the input data. The reconstructions are pretty good, however, when I am doing a random sampling of Bernoulli(p=0.5) for the decoder, the generated data is garbage. \n\nThe objective function is theMSE of the reconstruction + the KL divergence of the latent distribution..\n\n&amp;#x200B;\n\nAny suggestions???","classes":{"dataset":0.5357834101}}
{"title":"How do you study for a programming exam?","description":"","link":"https://www.reddit.com/r/deeplearning/comments/10rpvbr/how_do_you_study_for_a_programming_exam/","created":"2023-02-02","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":1},"text":"How do you study for a programming exam? ","classes":{"dataset":0.2912353575}}
{"title":"Can nvidia-tensorflow (1.x) be used with RTX 4090","description":"Editing this to be more specific...\n\nSince I have not been able to convert my code to train models with my images on TF2.x, I still must use TF 1.x.\n\nConsider:\n\n[https://github.com/NVIDIA/tensorflow](https://github.com/NVIDIA/tensorflow)  and\n\n[https://www.pugetsystems.com/labs/hpc/How-To-Install-TensorFlow-1-15-for-NVIDIA-RTX30-GPUs-without-docker-or-CUDA-install-2005/](https://www.pugetsystems.com/labs/hpc/How-To-Install-TensorFlow-1-15-for-NVIDIA-RTX30-GPUs-without-docker-or-CUDA-install-2005/)\n\nThis TensorFlow is created by Nvidia to support TensorFlow 1.1x on newer Nvidia cards. I have successfully installed and used it on an RTX A6000 in the cloud.\n\nNote that to install it, the command is:    `pip install --user nvidia-tensorflow[horovod]`\n\nI understand the TensorFlow as mentioned above can be used with RTX30 series GPU.\n\nCan this TensorFlow be used with RTX4090?\n\n&amp;#x200B;","link":"https://www.reddit.com/r/deeplearning/comments/10rb9sl/can_nvidiatensorflow_1x_be_used_with_rtx_4090/","created":"2023-02-02","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":3},"text":"Can nvidia-tensorflow (1.x) be used with RTX 4090 Editing this to be more specific...\n\nSince I have not been able to convert my code to train models with my images on TF2.x, I still must use TF 1.x.\n\nConsider:\n\n[https://github.com/NVIDIA/tensorflow](https://github.com/NVIDIA/tensorflow)  and\n\n[https://www.pugetsystems.com/labs/hpc/How-To-Install-TensorFlow-1-15-for-NVIDIA-RTX30-GPUs-without-docker-or-CUDA-install-2005/](https://www.pugetsystems.com/labs/hpc/How-To-Install-TensorFlow-1-15-for-NVIDIA-RTX30-GPUs-without-docker-or-CUDA-install-2005/)\n\nThis TensorFlow is created by Nvidia to support TensorFlow 1.1x on newer Nvidia cards. I have successfully installed and used it on an RTX A6000 in the cloud.\n\nNote that to install it, the command is:    `pip install --user nvidia-tensorflow[horovod]`\n\nI understand the TensorFlow as mentioned above can be used with RTX30 series GPU.\n\nCan this TensorFlow be used with RTX4090?\n\n&amp;#x200B;","classes":{"dataset":0.4506202638}}
{"title":"\"machine learning is basically many months of things not working, and then suddenly it works, and then it works scarily well\" \u2013 if this resonates for you, share stories of your experience with this!","description":"","link":"https://www.reddit.com/r/deeplearning/comments/10qxkfv/machine_learning_is_basically_many_months_of/","created":"2023-02-01","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":1},"text":"\"machine learning is basically many months of things not working, and then suddenly it works, and then it works scarily well\" \u2013 if this resonates for you, share stories of your experience with this! ","classes":{"dataset":0.3293209076}}
{"title":"Launching my first-ever open-source project and it might make your ChatGPT answers better","description":"I am building UpTrain - an open-source ML diagnostic toolkit that recently got investment from YCombinator.\n\nAs you know no ML model is 100% accurate, and, further, their accuracy deteriorates over time \ud83d\ude23. Additionally, due to the black boxiness \u2b1b nature of Large Language models, it's challenging to identify and fix their problems.\n\nThe tool helps ML practitioners to:\n1. Understand how their models are performing in production\n2. Catch edge cases and outliers to help them refine their models\n3. Allow them to define custom monitors to catch under-performing data-points\n4. Retrain the model on them to improve its accuracy\n\nYou can check out the project here: https://github.com/uptrain-ai/uptrain. Would love to hear feedback from the community!","link":"https://www.reddit.com/r/deeplearning/comments/10qx9po/launching_my_firstever_opensource_project_and_it/","created":"2023-02-01","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":4},"text":"Launching my first-ever open-source project and it might make your ChatGPT answers better I am building UpTrain - an open-source ML diagnostic toolkit that recently got investment from YCombinator.\n\nAs you know no ML model is 100% accurate, and, further, their accuracy deteriorates over time \ud83d\ude23. Additionally, due to the black boxiness \u2b1b nature of Large Language models, it's challenging to identify and fix their problems.\n\nThe tool helps ML practitioners to:\n1. Understand how their models are performing in production\n2. Catch edge cases and outliers to help them refine their models\n3. Allow them to define custom monitors to catch under-performing data-points\n4. Retrain the model on them to improve its accuracy\n\nYou can check out the project here: https://github.com/uptrain-ai/uptrain. Would love to hear feedback from the community!","classes":{"dataset":0.4855993986}}
{"title":"[R] Multimodal Chain-of-Thought Reasoning in Language Models - Amazon Web Services Zhuosheng Zhang et al - Outperforms GPT-3.5 by 16% (75%-&gt;91%) and surpasses human performance on ScienceQA while having less than 1B params!","description":"Paper: [https://arxiv.org/abs/2302.00923](https://arxiv.org/abs/2302.00923) \n\nGithub: [https://github.com/amazon-science/mm-cot](https://github.com/amazon-science/mm-cot) \n\nTwitter: [https://paperswithcode.com/top-social](https://paperswithcode.com/top-social) \n\nAbstract:\n\n&gt;Large language models (LLMs) have shown impressive performance on complex reasoning by leveraging chain-of-thought (CoT) prompting to generate intermediate reasoning chains as the rationale to infer the answer. However, existing CoT studies are mostly isolated in the language modality with LLMs, where LLMs are hard to deploy. To elicit CoT reasoning in multimodality, a possible solution is to fine-tune small language models by fusing the vision and language features to perform CoT reasoning. The key challenge is that those language models tend to generate hallucinated reasoning chains that mislead the answer inference. To mitigate the effect of such mistakes, we propose Multimodal-CoT that incorporates vision features in a decoupled training framework. The framework separates the rationale generation and answer inference into two stages. By incorporating the vision features in both stages, the model is able to generate effective rationales that contribute to answer inference. **With Multimodal-CoT, our model under 1 billion parameters outperforms the previous state-of-the-art LLM (GPT-3.5) by 16% (75.17%-&gt;91.68%) on the ScienceQA benchmark and even surpasses human performance.** \n\nhttps://preview.redd.it/g9eo0f94k1ga1.jpg?width=1331&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a51e29ed523b624dd70d97841c8b0a5442915c80\n\nhttps://preview.redd.it/fgboci94k1ga1.jpg?width=1323&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1a3a2fe1a47d4ca04f992b2cf72832f024166711\n\nhttps://preview.redd.it/2ojfym94k1ga1.jpg?width=1660&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e7431fb8532d6331374f1b00adc40248de94f381\n\nhttps://preview.redd.it/k7huem94k1ga1.jpg?width=1326&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=2bcbe91afcdf815171b4c0fd7f8e48f63a8bbb4c\n\nhttps://preview.redd.it/05m8rf94k1ga1.jpg?width=658&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a8384d649e2140b27dc87525c1546403cd3409f7","link":"https://www.reddit.com/r/MachineLearning/comments/10svwch/r_multimodal_chainofthought_reasoning_in_language/","created":"2023-02-03","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":6},"text":"[R] Multimodal Chain-of-Thought Reasoning in Language Models - Amazon Web Services Zhuosheng Zhang et al - Outperforms GPT-3.5 by 16% (75%-&gt;91%) and surpasses human performance on ScienceQA while having less than 1B params! Paper: [https://arxiv.org/abs/2302.00923](https://arxiv.org/abs/2302.00923) \n\nGithub: [https://github.com/amazon-science/mm-cot](https://github.com/amazon-science/mm-cot) \n\nTwitter: [https://paperswithcode.com/top-social](https://paperswithcode.com/top-social) \n\nAbstract:\n\n&gt;Large language models (LLMs) have shown impressive performance on complex reasoning by leveraging chain-of-thought (CoT) prompting to generate intermediate reasoning chains as the rationale to infer the answer. However, existing CoT studies are mostly isolated in the language modality with LLMs, where LLMs are hard to deploy. To elicit CoT reasoning in multimodality, a possible solution is to fine-tune small language models by fusing the vision and language features to perform CoT reasoning. The key challenge is that those language models tend to generate hallucinated reasoning chains that mislead the answer inference. To mitigate the effect of such mistakes, we propose Multimodal-CoT that incorporates vision features in a decoupled training framework. The framework separates the rationale generation and answer inference into two stages. By incorporating the vision features in both stages, the model is able to generate effective rationales that contribute to answer inference. **With Multimodal-CoT, our model under 1 billion parameters outperforms the previous state-of-the-art LLM (GPT-3.5) by 16% (75.17%-&gt;91.68%) on the ScienceQA benchmark and even surpasses human performance.** \n\nhttps://preview.redd.it/g9eo0f94k1ga1.jpg?width=1331&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a51e29ed523b624dd70d97841c8b0a5442915c80\n\nhttps://preview.redd.it/fgboci94k1ga1.jpg?width=1323&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=1a3a2fe1a47d4ca04f992b2cf72832f024166711\n\nhttps://preview.redd.it/2ojfym94k1ga1.jpg?width=1660&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=e7431fb8532d6331374f1b00adc40248de94f381\n\nhttps://preview.redd.it/k7huem94k1ga1.jpg?width=1326&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=2bcbe91afcdf815171b4c0fd7f8e48f63a8bbb4c\n\nhttps://preview.redd.it/05m8rf94k1ga1.jpg?width=658&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=a8384d649e2140b27dc87525c1546403cd3409f7","classes":{"dataset":0.1405848712}}
{"title":"[D] Understanding Vision Transformer (ViT) - What are the prerequisites?","description":"Hello everyone,\n\nI'm interested in diving into the field of computer vision and I recently came across the concept of Vision Transformer (ViT). I want to understand this concept in depth but I'm not sure what prerequisites I need to have in order to grasp the concept fully.\n\nDo I need to have a strong background in Recurrent Neural Networks (RNNs) and Transformer (Attention Is All You Need) to understand ViT, or can I get by just knowing the basics of deep learning and Convolutional Neural Networks (CNNs)?\n\nI would really appreciate if someone could shed some light on this and provide some guidance.\n\nThank you in advance!","link":"https://www.reddit.com/r/MachineLearning/comments/10siibd/d_understanding_vision_transformer_vit_what_are/","created":"2023-02-03","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":24},"text":"[D] Understanding Vision Transformer (ViT) - What are the prerequisites? Hello everyone,\n\nI'm interested in diving into the field of computer vision and I recently came across the concept of Vision Transformer (ViT). I want to understand this concept in depth but I'm not sure what prerequisites I need to have in order to grasp the concept fully.\n\nDo I need to have a strong background in Recurrent Neural Networks (RNNs) and Transformer (Attention Is All You Need) to understand ViT, or can I get by just knowing the basics of deep learning and Convolutional Neural Networks (CNNs)?\n\nI would really appreciate if someone could shed some light on this and provide some guidance.\n\nThank you in advance!","classes":{"dataset":0.4806427658}}
{"title":"[R] What\u2019s your suggestion for offline RL?","description":"Hi guys! I read a lot of offline RL papers in last Fall semester and choose it as my course project. Offline RL seems to be a very hot topic in recent years, I believe that the major challenge for offline RL are (i) distribution shift and (ii) overestimation. The second challenge is caused by (i), because the learners/agents will never allow to interact with the true environment and they will too optimistic for unseen state-actions. Hence, there are many papers to address such challenges, e.g., CQL and MOPO.\n\nHowever can these methods handle misleading datasets? Consider the following example. Suppose we have only one state (MAB) and two arms. The reward of the first arm will return 2/3 with probability 1 and the reward model of second arm is Bernoulli distribution with p=1/2. Clearly, choosing the first arm is the best choice.\n\nNow, for the dataset, unfortunately, all samples on the second arm received reward 1. Because the agent only can access this misleading dataset, if we use Bayesian methods, then the posterior will give a high score for the second arm. If we use Lower Confidence Bound, we need to count the occurrence of each arm. Then, this is very hard to extend this method to MDPs with arbitrary large state and action space. So, does anyone know a function can capture this uncertainty (caused by the dataset) or can any methods to tell the learner that you\u2019re in a very misleading situation?","link":"https://www.reddit.com/r/MachineLearning/comments/10t4cxu/r_whats_your_suggestion_for_offline_rl/","created":"2023-02-04","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":2},"text":"[R] What\u2019s your suggestion for offline RL? Hi guys! I read a lot of offline RL papers in last Fall semester and choose it as my course project. Offline RL seems to be a very hot topic in recent years, I believe that the major challenge for offline RL are (i) distribution shift and (ii) overestimation. The second challenge is caused by (i), because the learners/agents will never allow to interact with the true environment and they will too optimistic for unseen state-actions. Hence, there are many papers to address such challenges, e.g., CQL and MOPO.\n\nHowever can these methods handle misleading datasets? Consider the following example. Suppose we have only one state (MAB) and two arms. The reward of the first arm will return 2/3 with probability 1 and the reward model of second arm is Bernoulli distribution with p=1/2. Clearly, choosing the first arm is the best choice.\n\nNow, for the dataset, unfortunately, all samples on the second arm received reward 1. Because the agent only can access this misleading dataset, if we use Bayesian methods, then the posterior will give a high score for the second arm. If we use Lower Confidence Bound, we need to count the occurrence of each arm. Then, this is very hard to extend this method to MDPs with arbitrary large state and action space. So, does anyone know a function can capture this uncertainty (caused by the dataset) or can any methods to tell the learner that you\u2019re in a very misleading situation?","classes":{"dataset":0.561639905}}
{"title":"[R] Graph Mixer Networks","description":"I began exploring MLP-Mixer\\[[1](https://arxiv.org/abs/2105.01601),[2](https://arxiv.org/abs/2105.02723)\\]  on Graph Neural Networks in October 2021 and completed my  implementation the ZINC dataset in November of the same year. My  implementation is available on [Github](https://github.com/asarigun/GraphMixerNetworks), but I was unable to fully conduct the experiments due to lack of computational resources.\n\nIn  December 2022, a group of leading figures in the field, including  Xiaoxin He, Bryan Hooi, Thomas Laurent, Adam Perold, Yann Lecun, and  Xavier Bresson, published a paper titled \"[A Generalization of ViT/MLP-Mixer to Graphs](https://arxiv.org/abs/2212.13350)\".  Although I am pleased to be working alongside these prominent  researchers on the application of MLP-Mixers to Graphs, I regret that I  was unable to finish my experiments. Encouraged by my friends and  advisors, I decided to make my work public by publishing it on arxiv.  The paper and code can be found as the following:\n\nPaper/report: [https://arxiv.org/abs/2301.12493](https://arxiv.org/abs/2301.12493)  \nGithub: [https://github.com/asarigun/GraphMixerNetworks](https://github.com/asarigun/GraphMixerNetworks)\n\nI  used PNA as my baseline and did not utilize patches in my study, unlike  the other study. I hope someone finds them interesting/useful.","link":"https://www.reddit.com/r/MachineLearning/comments/10sj2qf/r_graph_mixer_networks/","created":"2023-02-03","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":5},"text":"[R] Graph Mixer Networks I began exploring MLP-Mixer\\[[1](https://arxiv.org/abs/2105.01601),[2](https://arxiv.org/abs/2105.02723)\\]  on Graph Neural Networks in October 2021 and completed my  implementation the ZINC dataset in November of the same year. My  implementation is available on [Github](https://github.com/asarigun/GraphMixerNetworks), but I was unable to fully conduct the experiments due to lack of computational resources.\n\nIn  December 2022, a group of leading figures in the field, including  Xiaoxin He, Bryan Hooi, Thomas Laurent, Adam Perold, Yann Lecun, and  Xavier Bresson, published a paper titled \"[A Generalization of ViT/MLP-Mixer to Graphs](https://arxiv.org/abs/2212.13350)\".  Although I am pleased to be working alongside these prominent  researchers on the application of MLP-Mixers to Graphs, I regret that I  was unable to finish my experiments. Encouraged by my friends and  advisors, I decided to make my work public by publishing it on arxiv.  The paper and code can be found as the following:\n\nPaper/report: [https://arxiv.org/abs/2301.12493](https://arxiv.org/abs/2301.12493)  \nGithub: [https://github.com/asarigun/GraphMixerNetworks](https://github.com/asarigun/GraphMixerNetworks)\n\nI  used PNA as my baseline and did not utilize patches in my study, unlike  the other study. I hope someone finds them interesting/useful.","classes":{"dataset":0.0005379359}}
{"title":"[P] Any thoughts on the possibility of machine learning to retrofit HVAC in buildings?","description":"I often wonder about the best way to retrofit my house to optimize for cost and comfort. \n\nI suspect people already do old school modeling for commercial settings but wondered if it's possible for small fry like me to benefit from this technology if messing learning is involved.\n\nI couldn't think of a better sub to ask but open to that suggestion as well as any other response.","link":"https://www.reddit.com/r/MachineLearning/comments/10svx96/p_any_thoughts_on_the_possibility_of_machine/","created":"2023-02-03","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4},"text":"[P] Any thoughts on the possibility of machine learning to retrofit HVAC in buildings? I often wonder about the best way to retrofit my house to optimize for cost and comfort. \n\nI suspect people already do old school modeling for commercial settings but wondered if it's possible for small fry like me to benefit from this technology if messing learning is involved.\n\nI couldn't think of a better sub to ask but open to that suggestion as well as any other response.","classes":{"dataset":0.4258359969}}
{"title":"[D] Using a public research dataset for \"testing\" NOT \"training\" a ML model","description":"Is it allowed to use a public dataset like the KITTI dataset to test a model trained for commercial use?\n\nNote that the KITTI dataset is only allowed to be used for research purposes and the model is trained with different data (company specific).","link":"https://www.reddit.com/r/MachineLearning/comments/10sledd/d_using_a_public_research_dataset_for_testing_not/","created":"2023-02-03","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4},"text":"[D] Using a public research dataset for \"testing\" NOT \"training\" a ML model Is it allowed to use a public dataset like the KITTI dataset to test a model trained for commercial use?\n\nNote that the KITTI dataset is only allowed to be used for research purposes and the model is trained with different data (company specific).","classes":{"dataset":0.3625134528}}
{"title":"[Project] I built a minimal stateless ML project template built on my current favourite stack","description":"Dear r/MachineLearning,\n\nHello everyone! I hope you are all out there having fun, training deep nets and generating fun story-telling with stable-diffusion! :)\n\nI am here today to share with you all a minimal ml project template that I've recently built, which can be found at [https://github.com/AntreasAntoniou/minimal-ml-template/](https://github.com/AntreasAntoniou/minimal-ml-template/). I became increasingly annoyed at how there weren't any repos out there that provided **stateless** ML project templates, which are absolutely necessary when using kubernetes on spot instances, and I decided to build one. By stateless I mean a repo that by default can store model weights in a remote repo and then download them to continue from where it left off if the previous machine dies. The result was this repository.\n\nThe repo remains minimal and extremely readable, all while being packed with a cool stack that I use every day. I'd love to get some feedback, so have a look and let me know.\n\nRegards, Antreas\n\nP.S. A short summary straight from the Github Repo:\n\nThis repo implements a **minimal** machine learning template, that is fully featured for most of the things a machine learning project might need. The most important parts that set this repo apart from the rest are:\n\n1. It is **stateless**. Any given experiment ran using this template, will, automatically and periodically stores the model weights and configuration to [HuggingFace Hub](https://huggingface.co/docs/hub/models-the-hub) and [wandb](https://wandb.ai/site) respectively. As a result, if your machine dies or job exits, and you resume on another machine, the code will automatically locate and download the previous history and continue from where it left off. This makes this repo very useful when using spot instances, or using schedulers like slurm and kubernetes. \n2. It provides support for all the latest and greatest GPU and TPU optimization and scaling algorithms through [HuggingFace Accelerate](https://huggingface.co/docs/accelerate/index).\n3. It provides mature configuration support via [Hydra-Zen](https://github.com/mit-ll-responsible-ai/hydra-zen) and automates configuration generation via [decorators](https://github.com/BayesWatch/minimal-ml-template/blob/af387e59472ea67552b4bb8972b39fe95952dd8a/mlproject/decorators.py#L10) implemented in this repo.\n4. It has a minimal **callback** based boilerplate that allows a user to easily inject any functionality at predefined places in the system without spagettifying the code.\n5. It uses [HuggingFace Models](https://huggingface.co/models) and [Datasets](https://huggingface.co/docs/datasets/index) to streamline building/loading of models, and datasets, but is also not forcing you to use those, allowing for very easy injection of any models and datasets you care about, assuming you use models implemented under PyTorch's `nn.Module` and `Dataset` classes.\n6. It provides plug and play functionality that allows easy hyperparameter search on Kubernetes clusters using [BWatchCompute](https://github.com/BayesWatch/bwatchcompute) and some readily available scripts and yaml templates.\n\n## The Software Stack\n\nThis machine learning project template is built using the following software stack:\n1. Deep Learning Framework: [PyTorch](https://pytorch.org/get-started/locally/)\n2. Dataset storage and retrieval: [Huggingface Datasets](https://huggingface.co/docs/datasets/index)\n3. Model storage and retrieval [Huggingface Hub](https://huggingface.co/docs/hub/models-the-hub), and [HuggingFace Models](https://huggingface.co/models)\n4. GPU/TPU/CPU Optimization and Scaling up options library: [Huggingface Accelerate](https://huggingface.co/docs/accelerate/index)\n5. Experiment configuration + command line argument parsing: [Hydra-zen](https://github.com/mit-ll-responsible-ai/hydra-zen)\n6. Experiment tracking: [Weights and Biases](https://docs.wandb.ai)\n7. Simple python based ML experiment running with Kubernetes using [BWatchCompute](https://github.com/BayesWatch/bwatchcompute)","link":"https://www.reddit.com/r/MachineLearning/comments/10s82tf/project_i_built_a_minimal_stateless_ml_project/","created":"2023-02-03","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1},"text":"[Project] I built a minimal stateless ML project template built on my current favourite stack Dear r/MachineLearning,\n\nHello everyone! I hope you are all out there having fun, training deep nets and generating fun story-telling with stable-diffusion! :)\n\nI am here today to share with you all a minimal ml project template that I've recently built, which can be found at [https://github.com/AntreasAntoniou/minimal-ml-template/](https://github.com/AntreasAntoniou/minimal-ml-template/). I became increasingly annoyed at how there weren't any repos out there that provided **stateless** ML project templates, which are absolutely necessary when using kubernetes on spot instances, and I decided to build one. By stateless I mean a repo that by default can store model weights in a remote repo and then download them to continue from where it left off if the previous machine dies. The result was this repository.\n\nThe repo remains minimal and extremely readable, all while being packed with a cool stack that I use every day. I'd love to get some feedback, so have a look and let me know.\n\nRegards, Antreas\n\nP.S. A short summary straight from the Github Repo:\n\nThis repo implements a **minimal** machine learning template, that is fully featured for most of the things a machine learning project might need. The most important parts that set this repo apart from the rest are:\n\n1. It is **stateless**. Any given experiment ran using this template, will, automatically and periodically stores the model weights and configuration to [HuggingFace Hub](https://huggingface.co/docs/hub/models-the-hub) and [wandb](https://wandb.ai/site) respectively. As a result, if your machine dies or job exits, and you resume on another machine, the code will automatically locate and download the previous history and continue from where it left off. This makes this repo very useful when using spot instances, or using schedulers like slurm and kubernetes. \n2. It provides support for all the latest and greatest GPU and TPU optimization and scaling algorithms through [HuggingFace Accelerate](https://huggingface.co/docs/accelerate/index).\n3. It provides mature configuration support via [Hydra-Zen](https://github.com/mit-ll-responsible-ai/hydra-zen) and automates configuration generation via [decorators](https://github.com/BayesWatch/minimal-ml-template/blob/af387e59472ea67552b4bb8972b39fe95952dd8a/mlproject/decorators.py#L10) implemented in this repo.\n4. It has a minimal **callback** based boilerplate that allows a user to easily inject any functionality at predefined places in the system without spagettifying the code.\n5. It uses [HuggingFace Models](https://huggingface.co/models) and [Datasets](https://huggingface.co/docs/datasets/index) to streamline building/loading of models, and datasets, but is also not forcing you to use those, allowing for very easy injection of any models and datasets you care about, assuming you use models implemented under PyTorch's `nn.Module` and `Dataset` classes.\n6. It provides plug and play functionality that allows easy hyperparameter search on Kubernetes clusters using [BWatchCompute](https://github.com/BayesWatch/bwatchcompute) and some readily available scripts and yaml templates.\n\n## The Software Stack\n\nThis machine learning project template is built using the following software stack:\n1. Deep Learning Framework: [PyTorch](https://pytorch.org/get-started/locally/)\n2. Dataset storage and retrieval: [Huggingface Datasets](https://huggingface.co/docs/datasets/index)\n3. Model storage and retrieval [Huggingface Hub](https://huggingface.co/docs/hub/models-the-hub), and [HuggingFace Models](https://huggingface.co/models)\n4. GPU/TPU/CPU Optimization and Scaling up options library: [Huggingface Accelerate](https://huggingface.co/docs/accelerate/index)\n5. Experiment configuration + command line argument parsing: [Hydra-zen](https://github.com/mit-ll-responsible-ai/hydra-zen)\n6. Experiment tracking: [Weights and Biases](https://docs.wandb.ai)\n7. Simple python based ML experiment running with Kubernetes using [BWatchCompute](https://github.com/BayesWatch/bwatchcompute)","classes":{"dataset":0.2161788195}}
{"title":"[D] Why do LLMs like InstructGPT and LLM use RL to instead of supervised learning to learn from the user-ranked examples?","description":"Aligned LLMs such as InstructGPT and ChatGPT are trained via supervised fine-tuning after the initial self-supervised pretraining. Then, the researchers train a reward model on responses ranked by humans. \n\nWhen I understand correctly, they let the LLM generate responses that humans have to rank on a scale from 1-5. Then, they train a reward model (I suppose in supervised fashion?) on these ranked outputs. Once that's done, they use reinforcement learning (RL) with proximal policy optimization (PPO) to update the LLM. \n\nMy question is why they use RL with PPO for this last step? Why don't they fine-tune the LLM using regular supervised learning, whereas the human-ranked outputs represent the labels. Since these are labels in the range 1-5, this could be a ranking or ordinal regression loss for supervised learning.","link":"https://www.reddit.com/r/MachineLearning/comments/10rpj0f/d_why_do_llms_like_instructgpt_and_llm_use_rl_to/","created":"2023-02-02","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":27},"text":"[D] Why do LLMs like InstructGPT and LLM use RL to instead of supervised learning to learn from the user-ranked examples? Aligned LLMs such as InstructGPT and ChatGPT are trained via supervised fine-tuning after the initial self-supervised pretraining. Then, the researchers train a reward model on responses ranked by humans. \n\nWhen I understand correctly, they let the LLM generate responses that humans have to rank on a scale from 1-5. Then, they train a reward model (I suppose in supervised fashion?) on these ranked outputs. Once that's done, they use reinforcement learning (RL) with proximal policy optimization (PPO) to update the LLM. \n\nMy question is why they use RL with PPO for this last step? Why don't they fine-tune the LLM using regular supervised learning, whereas the human-ranked outputs represent the labels. Since these are labels in the range 1-5, this could be a ranking or ordinal regression loss for supervised learning.","classes":{"dataset":0.3803113401}}
{"title":"[R] editing colors on SHAP plot summary","description":"We can change the colors of some texts and backgrounds on a SHAP summary plot by editing matplotlib's matplotlibrc file. \n\nWe can also edit the plotting colors by passing a colormap but we're **unable to change the colors of the \"feature names\" at the left side of the SHAP summary plot (beeswarm) -and the color of the y axis-** by editing matplotlib's matplotlibrc file. \n\nHas anyone worked around this? Is there a way that we could overcome this restriction?","link":"https://www.reddit.com/r/MachineLearning/comments/10smf2i/r_editing_colors_on_shap_plot_summary/","created":"2023-02-03","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0},"text":"[R] editing colors on SHAP plot summary We can change the colors of some texts and backgrounds on a SHAP summary plot by editing matplotlib's matplotlibrc file. \n\nWe can also edit the plotting colors by passing a colormap but we're **unable to change the colors of the \"feature names\" at the left side of the SHAP summary plot (beeswarm) -and the color of the y axis-** by editing matplotlib's matplotlibrc file. \n\nHas anyone worked around this? Is there a way that we could overcome this restriction?","classes":{"dataset":0.3441489637}}
{"title":"[d]? Is there a way to access youtube alphabetically or by id?","description":"I'm guessing i probably am not the first person who has wanted to work with youtube data so I'm hoping here is a good place to ask\n\nSo i had an idea to make a neural network that would go through your youtube history and then train a neural network on it. Afterwards if there is a way to access all of youtube by id in a way that you can check every video then you could store all of the id for videos you might like and then use a youtube downloader like youtube-dl to download a certain amount. Was just a dumb idea i had but now i want to actually try it but I'm unsure if I'll actually be able to get the data i need to do it","link":"https://www.reddit.com/r/MachineLearning/comments/10sdrp4/d_is_there_a_way_to_access_youtube_alphabetically/","created":"2023-02-03","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4},"text":"[d]? Is there a way to access youtube alphabetically or by id? I'm guessing i probably am not the first person who has wanted to work with youtube data so I'm hoping here is a good place to ask\n\nSo i had an idea to make a neural network that would go through your youtube history and then train a neural network on it. Afterwards if there is a way to access all of youtube by id in a way that you can check every video then you could store all of the id for videos you might like and then use a youtube downloader like youtube-dl to download a certain amount. Was just a dumb idea i had but now i want to actually try it but I'm unsure if I'll actually be able to get the data i need to do it","classes":{"dataset":0.2889842689}}
{"title":"[D] Querying with multiple vectors during embedding nearest neighbor search?","description":"Are there tools or techniques that permit you to joint query using more than one query vector? \n\nUse case: iterative ANN search refinement, where I start with a seed vector, select matches, and re-query with more examples to improve the search results.\n\nI tried doing this with FAISS, but it performs a \"batch query\" that returns a separate set of results for each query vector (not a joint query).","link":"https://www.reddit.com/r/MachineLearning/comments/10rvkru/d_querying_with_multiple_vectors_during_embedding/","created":"2023-02-02","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":16},"text":"[D] Querying with multiple vectors during embedding nearest neighbor search? Are there tools or techniques that permit you to joint query using more than one query vector? \n\nUse case: iterative ANN search refinement, where I start with a seed vector, select matches, and re-query with more examples to improve the search results.\n\nI tried doing this with FAISS, but it performs a \"batch query\" that returns a separate set of results for each query vector (not a joint query).","classes":{"dataset":0.5252657533}}
{"title":"[D] Commercial Use of a Model that has been trained using Human3.6M","description":" I wanted to use the [Learnable Trainangulation](https://github.com/karfly/learnable-triangulation-pytorch) model in a commercial project. The source code itself is under MIT licensing. However, the dataset they have used is [Human3.6M](http://vision.imar.ro/human3.6m/description.php), which states that the [license](http://vision.imar.ro/human3.6m/eula.php) is \"FREE OF CHARGE FOR ACADEMIC USE ONLY\".\n\nYet, recent court rulings (in the US) state that models can use copyrighted data during training, and the results are no longer bound by that copyright (e.g. Google Books). Does the same apply here?","link":"https://www.reddit.com/r/MachineLearning/comments/10rp7ze/d_commercial_use_of_a_model_that_has_been_trained/","created":"2023-02-02","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4},"text":"[D] Commercial Use of a Model that has been trained using Human3.6M  I wanted to use the [Learnable Trainangulation](https://github.com/karfly/learnable-triangulation-pytorch) model in a commercial project. The source code itself is under MIT licensing. However, the dataset they have used is [Human3.6M](http://vision.imar.ro/human3.6m/description.php), which states that the [license](http://vision.imar.ro/human3.6m/eula.php) is \"FREE OF CHARGE FOR ACADEMIC USE ONLY\".\n\nYet, recent court rulings (in the US) state that models can use copyrighted data during training, and the results are no longer bound by that copyright (e.g. Google Books). Does the same apply here?","classes":{"dataset":0.0205512214}}
{"title":"Need help with chat bot and text processing task","description":"Hi,\n\nI am trying to build a system that a user can enter sentences and an agent (or bot) will process each sentence and extract relevant information. The extracted data is saved into a queue for processing later.  \n\nFor example: Given the following input, (left side), I want the system the following output (right side) as shown below:\n\nInput: \"Add a line called LINE1 from point (1,1,1) to point (10,2,5) -&gt; output : \\[\"LINE1\",\\[1,1,1\\],\\[10,2,5\\]\\]\n\nInput: Add a new line, LINE2, that starts from (2,4,3) to (2,5,3) -&gt; output: \\[\"LINE2\", \\[2,4,3\\],\\[2,5,3\\]\\]\n\nInput\" Draw a line from (2,1,3) to (3,6,1) -&gt; output: \\[\"DUMMY1\",\\[2,1,3\\], \\[3,6,1\\]\\]\n\nThe output from the agent is of the form \\[Line name, \\[coordinate 1\\], \\[coordinate 2\\]\\].\n\nThe last example may add complication, where if the agent can't get the name of the line from the text, it may subsitute some name, like \"dummy1\", \"dummy2\" (this is done later after knowing that the name of the line is missing or not provided). If this complicated the task, we can restrict the use case to the first two examples. \n\nNote that the coordinate points are arbitrary (for now) but I may need to add some constraints, e.g., where there is a min and max value for each axis (but this is not critical). If the bounds are violated, perhaps I can return back and error. \n\nHow might I go about achieving something like this?\n\nI want to use my knowlegde build an agent (if necessary) or there is some open source that can help with this task. \n\nThanks","link":"https://www.reddit.com/r/LanguageTechnology/comments/10t7j1z/need_help_with_chat_bot_and_text_processing_task/","created":"2023-02-04","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1},"text":"Need help with chat bot and text processing task Hi,\n\nI am trying to build a system that a user can enter sentences and an agent (or bot) will process each sentence and extract relevant information. The extracted data is saved into a queue for processing later.  \n\nFor example: Given the following input, (left side), I want the system the following output (right side) as shown below:\n\nInput: \"Add a line called LINE1 from point (1,1,1) to point (10,2,5) -&gt; output : \\[\"LINE1\",\\[1,1,1\\],\\[10,2,5\\]\\]\n\nInput: Add a new line, LINE2, that starts from (2,4,3) to (2,5,3) -&gt; output: \\[\"LINE2\", \\[2,4,3\\],\\[2,5,3\\]\\]\n\nInput\" Draw a line from (2,1,3) to (3,6,1) -&gt; output: \\[\"DUMMY1\",\\[2,1,3\\], \\[3,6,1\\]\\]\n\nThe output from the agent is of the form \\[Line name, \\[coordinate 1\\], \\[coordinate 2\\]\\].\n\nThe last example may add complication, where if the agent can't get the name of the line from the text, it may subsitute some name, like \"dummy1\", \"dummy2\" (this is done later after knowing that the name of the line is missing or not provided). If this complicated the task, we can restrict the use case to the first two examples. \n\nNote that the coordinate points are arbitrary (for now) but I may need to add some constraints, e.g., where there is a min and max value for each axis (but this is not critical). If the bounds are violated, perhaps I can return back and error. \n\nHow might I go about achieving something like this?\n\nI want to use my knowlegde build an agent (if necessary) or there is some open source that can help with this task. \n\nThanks","classes":{"dataset":0.539825201}}
{"title":"Generate Knowledge Graphs from Unstructured Texts with GPT-3!","description":"Using GraphGPT, convert your favorite movie synopsis, a Wikipedia page, or a video transcript into an interactive graph visualization of entities and their relationships. [https://www.youtube.com/watch?v=mYCIRcobukI](https://www.youtube.com/watch?v=mYCIRcobukI)\n\nGithub: [https://github.com/varunshenoy/GraphGPT](https://github.com/varunshenoy/GraphGPT)  \nDemo: [https://graphgpt.vercel.app/](https://graphgpt.vercel.app/)","link":"https://www.reddit.com/r/LanguageTechnology/comments/10skua4/generate_knowledge_graphs_from_unstructured_texts/","created":"2023-02-03","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1},"text":"Generate Knowledge Graphs from Unstructured Texts with GPT-3! Using GraphGPT, convert your favorite movie synopsis, a Wikipedia page, or a video transcript into an interactive graph visualization of entities and their relationships. [https://www.youtube.com/watch?v=mYCIRcobukI](https://www.youtube.com/watch?v=mYCIRcobukI)\n\nGithub: [https://github.com/varunshenoy/GraphGPT](https://github.com/varunshenoy/GraphGPT)  \nDemo: [https://graphgpt.vercel.app/](https://graphgpt.vercel.app/)","classes":{"dataset":0.2713615298}}
{"title":"[ADVISE NEEDED] Extracting clauses from contracts","description":"Hi everyone!\n\nI am currently trying to extract specific clauses from employment contracts that describe something the employee needs to ask approval for from the employer (e.g., requesting time off or requesting a waiver for a non-compete) while ignoring other clauses that do not contain asking-for-approval actions for something (e.g., statement about working days and hours, the position description, or the salary components). And I would like your advice or recommendations on doing this.\n\nThe scenario: the employment contracts are in English and PDF format. I have a manually labeled data set of example clauses that I want (containing asking-for-approval actions). The data describes exactly where the clauses are located in the contract (coordinates and page number). This data set is created from multiple employment contract PDFs. Basically, annotations with the full text from the PDF and also the starting and ending coordinates on where it is located on the page of the contract.\n\nWhat approach would you suggest or recommend for me to tackle this challenge?\n\n&amp;#x200B;\n\nThank you very much!","link":"https://www.reddit.com/r/LanguageTechnology/comments/10seo2i/advise_needed_extracting_clauses_from_contracts/","created":"2023-02-03","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":2},"text":"[ADVISE NEEDED] Extracting clauses from contracts Hi everyone!\n\nI am currently trying to extract specific clauses from employment contracts that describe something the employee needs to ask approval for from the employer (e.g., requesting time off or requesting a waiver for a non-compete) while ignoring other clauses that do not contain asking-for-approval actions for something (e.g., statement about working days and hours, the position description, or the salary components). And I would like your advice or recommendations on doing this.\n\nThe scenario: the employment contracts are in English and PDF format. I have a manually labeled data set of example clauses that I want (containing asking-for-approval actions). The data describes exactly where the clauses are located in the contract (coordinates and page number). This data set is created from multiple employment contract PDFs. Basically, annotations with the full text from the PDF and also the starting and ending coordinates on where it is located on the page of the contract.\n\nWhat approach would you suggest or recommend for me to tackle this challenge?\n\n&amp;#x200B;\n\nThank you very much!","classes":{"dataset":0.5684615374}}
{"title":"1-click deploy for your GPT-3 App","description":"Link - [https://github.com/ClerkieAI/berri\\_ai](https://github.com/ClerkieAI/berri_ai)\n\nWe  made a package that makes it easy for you to quickly deploy your LLM Agent from Google Colab to production (Web App and API   Endpoint).\n\n**How it works?**\n\nJust install the package, import the function, and run deploy.\n\nAt the end of the deploy (\\~10-15mins), you will get:\n\n1. A web app to interact with your agent \ud83d\udc49  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/)\n2. An endpoint you can query \ud83d\udc49  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/langchain_agent?query=%22who) is obama?\"\n\nWant a more detailed walkthrough? Check out our loom - [https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43](https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43)\n\nWe\u2019re still early so would love your feedback and opinions. Feel free to try     us out for free \u2013 and if you need help building an agent / want a specific integration, just let us know!","link":"https://www.reddit.com/r/LanguageTechnology/comments/10rzror/1click_deploy_for_your_gpt3_app/","created":"2023-02-02","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0},"text":"1-click deploy for your GPT-3 App Link - [https://github.com/ClerkieAI/berri\\_ai](https://github.com/ClerkieAI/berri_ai)\n\nWe  made a package that makes it easy for you to quickly deploy your LLM Agent from Google Colab to production (Web App and API   Endpoint).\n\n**How it works?**\n\nJust install the package, import the function, and run deploy.\n\nAt the end of the deploy (\\~10-15mins), you will get:\n\n1. A web app to interact with your agent \ud83d\udc49  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/)\n2. An endpoint you can query \ud83d\udc49  [https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-4524...](https://agent-repo-35aa2cf3-a0a1-4cf8-834f-302e5b7fe07e-45247-8aqi.zeet-team-ishaan-jaff.zeet.app/langchain_agent?query=%22who) is obama?\"\n\nWant a more detailed walkthrough? Check out our loom - [https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43](https://www.loom.com/share/fd4375b4a77f4ea7802369cb06a16d43)\n\nWe\u2019re still early so would love your feedback and opinions. Feel free to try     us out for free \u2013 and if you need help building an agent / want a specific integration, just let us know!","classes":{"dataset":0.3420703411}}
{"title":"Ordered Keyword Extraction","description":"I'm interested in finding a way to order important terms, phrases and keywords extracted from a text so that they may be passed to a generative language model in an attempt to create a condensed summary of the original text.\n\nConsider a document that contains the following terms in descending order of importance: solar, rooftop, cheap, advanced, panels, photovoltaics, manufacture, etc. These terms won't necessarily have appeared in this order in the document they're extracted from, so I would like to first extract the important terms (as above) and then place them in order so they still make syntactic sense.\n\nFor example, we may have something like: advanced, manufacture, photovoltaics, rooftop, solar, panels, cheap. This ordering seems to suggest that advanced manufacturing of photovoltaics has helped make rooftop solar panels very cheap. I expect that ordering the terms will help provide context for the generative language model and help make the abstractive summary more accurate.\n\nObviously, in this simple toy example, I could just extract the keywords and place them in the sequential order in which they appear in the original text. Not all applications will be this simple, so is there a way to order the keywords so that they most closely resemble the context of the original text? I think that a graph-based approach like TextRank may be the way to proceed, but I would be very grateful for any thoughts or guidance.","link":"https://www.reddit.com/r/LanguageTechnology/comments/10rf68m/ordered_keyword_extraction/","created":"2023-02-02","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":2},"text":"Ordered Keyword Extraction I'm interested in finding a way to order important terms, phrases and keywords extracted from a text so that they may be passed to a generative language model in an attempt to create a condensed summary of the original text.\n\nConsider a document that contains the following terms in descending order of importance: solar, rooftop, cheap, advanced, panels, photovoltaics, manufacture, etc. These terms won't necessarily have appeared in this order in the document they're extracted from, so I would like to first extract the important terms (as above) and then place them in order so they still make syntactic sense.\n\nFor example, we may have something like: advanced, manufacture, photovoltaics, rooftop, solar, panels, cheap. This ordering seems to suggest that advanced manufacturing of photovoltaics has helped make rooftop solar panels very cheap. I expect that ordering the terms will help provide context for the generative language model and help make the abstractive summary more accurate.\n\nObviously, in this simple toy example, I could just extract the keywords and place them in the sequential order in which they appear in the original text. Not all applications will be this simple, so is there a way to order the keywords so that they most closely resemble the context of the original text? I think that a graph-based approach like TextRank may be the way to proceed, but I would be very grateful for any thoughts or guidance.","classes":{"dataset":0.5688372254}}
{"title":"Can NLP identify interesting quotes?","description":"**I don't have any knowledge of NLP or machine learning in general.**\n\nI have a small product that gathers users' highlights from their books (like ReadWise, but free). I'd like to find a way to separate the 'interesting' highlights (i.e. those you learn something from, although I know it's subjective), from the meaningless ones.\n\nExample of 'interesting' highlight:\n\n*\"As you consider building your own minimum viable product, let this simple rule suffice: remove any feature, process, or effort that does not contribute directly to the learning you seek.\"*\n\n&amp;#x200B;\n\nExample of 'not-interesting' highlight:\n\n*\"My voice is nothing special, but when your mother tells you something about yourself, even if you\u2019ve coaxed it out of her, it\u2019s hard not to always believe it.\"*\n\nIt's probably a dumb question, but I'm running in circles on how to automate this selection. I thought  NLP could maybe help, so any insight is appreciated!","link":"https://www.reddit.com/r/LanguageTechnology/comments/10r4stt/can_nlp_identify_interesting_quotes/","created":"2023-02-01","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1},"text":"Can NLP identify interesting quotes? **I don't have any knowledge of NLP or machine learning in general.**\n\nI have a small product that gathers users' highlights from their books (like ReadWise, but free). I'd like to find a way to separate the 'interesting' highlights (i.e. those you learn something from, although I know it's subjective), from the meaningless ones.\n\nExample of 'interesting' highlight:\n\n*\"As you consider building your own minimum viable product, let this simple rule suffice: remove any feature, process, or effort that does not contribute directly to the learning you seek.\"*\n\n&amp;#x200B;\n\nExample of 'not-interesting' highlight:\n\n*\"My voice is nothing special, but when your mother tells you something about yourself, even if you\u2019ve coaxed it out of her, it\u2019s hard not to always believe it.\"*\n\nIt's probably a dumb question, but I'm running in circles on how to automate this selection. I thought  NLP could maybe help, so any insight is appreciated!","classes":{"dataset":0.3098697662}}
{"title":"Joint statement by the Department of the Treasury, Federal Reserve, and FDIC","description":"https://home.treasury.gov/news/press-releases/jy1337","link":"https://home.treasury.gov/news/press-releases/jy1337","created":"2023-03-12","tags":["hackernews"],"meta":{"score":1418},"text":"Joint statement by the Department of the Treasury, Federal Reserve, and FDIC https://home.treasury.gov/news/press-releases/jy1337","classes":{"dataset":0.0422217064}}
{"title":"Dalai: Automatically install, run, and play with LLaMA on your computer","description":"https://cocktailpeanut.github.io/dalai/","link":"https://cocktailpeanut.github.io/dalai/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":554},"text":"Dalai: Automatically install, run, and play with LLaMA on your computer https://cocktailpeanut.github.io/dalai/","classes":{"dataset":0.5731009245}}
{"title":"Overhead of Returning Optional Values in Java and Rust","description":"https://pkolaczk.github.io/overhead-of-optional/","link":"https://pkolaczk.github.io/overhead-of-optional/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":72},"text":"Overhead of Returning Optional Values in Java and Rust https://pkolaczk.github.io/overhead-of-optional/","classes":{"dataset":0.5001171827}}
{"title":"Lo-Fi ATC","description":"https://www.lofiatc.com/","link":"https://www.lofiatc.com/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":290},"text":"Lo-Fi ATC https://www.lofiatc.com/","classes":{"dataset":0.5327094793}}
{"title":"cat mario.nes | nc play-nes.org 4444","description":"https://github.com/henrikpersson/potatis","link":"https://github.com/henrikpersson/potatis","created":"2023-03-12","tags":["hackernews"],"meta":{"score":208},"text":"cat mario.nes | nc play-nes.org 4444 https://github.com/henrikpersson/potatis","classes":{"dataset":0.502551198}}
{"title":"Bunki, a C Coroutine Library","description":"https://github.com/Keith-Cancel/Bunki","link":"https://github.com/Keith-Cancel/Bunki","created":"2023-03-13","tags":["hackernews"],"meta":{"score":3},"text":"Bunki, a C Coroutine Library https://github.com/Keith-Cancel/Bunki","classes":{"dataset":0.4964454174}}
{"title":"Emacs is not just an editor (2015)","description":"https://karl-voit.at/2015/10/23/Emacs-is-not-just-an-editor/","link":"https://karl-voit.at/2015/10/23/Emacs-is-not-just-an-editor/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":135},"text":"Emacs is not just an editor (2015) https://karl-voit.at/2015/10/23/Emacs-is-not-just-an-editor/","classes":{"dataset":0.5539534092}}
{"title":"The Mathematics of Crowds: How Pedestrians Inadvertently Self-Organize","description":"https://scitechdaily.com/the-hidden-mathematics-of-crowds-how-pedestrians-inadvertently-self-organize/","link":"https://scitechdaily.com/the-hidden-mathematics-of-crowds-how-pedestrians-inadvertently-self-organize/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":32},"text":"The Mathematics of Crowds: How Pedestrians Inadvertently Self-Organize https://scitechdaily.com/the-hidden-mathematics-of-crowds-how-pedestrians-inadvertently-self-organize/","classes":{"dataset":0.4477251172}}
{"title":"Motorists Break Law to Save Time, Cyclists Break Law to Save Lives (2020)","description":"https://www.forbes.com/sites/carltonreid/2020/09/18/motorists-break-law-to-save-time-cyclists-break-law-to-save-lives-finds-study/","link":"https://www.forbes.com/sites/carltonreid/2020/09/18/motorists-break-law-to-save-time-cyclists-break-law-to-save-lives-finds-study/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":5},"text":"Motorists Break Law to Save Time, Cyclists Break Law to Save Lives (2020) https://www.forbes.com/sites/carltonreid/2020/09/18/motorists-break-law-to-save-time-cyclists-break-law-to-save-lives-finds-study/","classes":{"dataset":0.534032464}}
{"title":"GameTales: Cray 6400 (2015)","description":"https://rome.ro/news/2015/12/13/gametales-cray-ymp","link":"https://rome.ro/news/2015/12/13/gametales-cray-ymp","created":"2023-03-11","tags":["hackernews"],"meta":{"score":18},"text":"GameTales: Cray 6400 (2015) https://rome.ro/news/2015/12/13/gametales-cray-ymp","classes":{"dataset":0.527369678}}
{"title":"Infinite Games","description":"https://www.youngmoney.co/p/infinite-games","link":"https://www.youngmoney.co/p/infinite-games","created":"2023-03-11","tags":["hackernews"],"meta":{"score":43},"text":"Infinite Games https://www.youngmoney.co/p/infinite-games","classes":{"dataset":0.4996397793}}
{"title":"Twitter has and internal root CA problem","description":"https://izzodlaw.com/@IzzoD/110001516908481048","link":"https://izzodlaw.com/@IzzoD/110001516908481048","created":"2023-03-13","tags":["hackernews"],"meta":{"score":4},"text":"Twitter has and internal root CA problem https://izzodlaw.com/@IzzoD/110001516908481048","classes":{"dataset":0.539288342}}
{"title":"Don't Share Java FileChannels","description":"https://pkolaczk.github.io/dont-share-file-channels/","link":"https://pkolaczk.github.io/dont-share-file-channels/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":86},"text":"Don't Share Java FileChannels https://pkolaczk.github.io/dont-share-file-channels/","classes":{"dataset":0.5031770468}}
{"title":"TypeScripting the technical interview","description":"https://www.richard-towers.com/2023/03/11/typescripting-the-technical-interview.html","link":"https://www.richard-towers.com/2023/03/11/typescripting-the-technical-interview.html","created":"2023-03-12","tags":["hackernews"],"meta":{"score":623},"text":"TypeScripting the technical interview https://www.richard-towers.com/2023/03/11/typescripting-the-technical-interview.html","classes":{"dataset":0.526196003}}
{"title":"Show HN: Codon: A Compiler for High-Performance Pythonic Applications and DSLs [pdf]","description":"https://regmedia.co.uk/2023/03/11/mit_codon_paper.pdf","link":"https://regmedia.co.uk/2023/03/11/mit_codon_paper.pdf","created":"2023-03-12","tags":["hackernews"],"meta":{"score":42},"text":"Show HN: Codon: A Compiler for High-Performance Pythonic Applications and DSLs [pdf] https://regmedia.co.uk/2023/03/11/mit_codon_paper.pdf","classes":{"dataset":0.5189798474}}
{"title":"Llama.cpp: Port of Facebook's LLaMA model in C/C++, with Apple Silicon support","description":"https://github.com/ggerganov/llama.cpp","link":"https://github.com/ggerganov/llama.cpp","created":"2023-03-10","tags":["hackernews"],"meta":{"score":935},"text":"Llama.cpp: Port of Facebook's LLaMA model in C/C++, with Apple Silicon support https://github.com/ggerganov/llama.cpp","classes":{"dataset":0.4763406217}}
{"title":"Silicon Valley Bank Depositor Bailout Makes Mockery of \u2018Too Big to Fail\u2019","description":"https://www.nationalreview.com/corner/silicon-valley-bank-depositor-bailout-makes-mockery-of-too-big-to-fail/","link":"https://www.nationalreview.com/corner/silicon-valley-bank-depositor-bailout-makes-mockery-of-too-big-to-fail/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":47},"text":"Silicon Valley Bank Depositor Bailout Makes Mockery of \u2018Too Big to Fail\u2019 https://www.nationalreview.com/corner/silicon-valley-bank-depositor-bailout-makes-mockery-of-too-big-to-fail/","classes":{"dataset":0.4232667983}}
{"title":"Regulators Close New York\u2019s Signature Bank","description":"https://www.cnbc.com/2023/03/12/regulators-close-new-yorks-signature-bank-citing-systemic-risk.html","link":"https://www.cnbc.com/2023/03/12/regulators-close-new-yorks-signature-bank-citing-systemic-risk.html","created":"2023-03-12","tags":["hackernews"],"meta":{"score":130},"text":"Regulators Close New York\u2019s Signature Bank https://www.cnbc.com/2023/03/12/regulators-close-new-yorks-signature-bank-citing-systemic-risk.html","classes":{"dataset":0.4965107739}}
{"title":"What Is Recursion? [pdf]","description":"http://assets.press.princeton.edu/chapters/s9424.pdf","link":"http://assets.press.princeton.edu/chapters/s9424.pdf","created":"2023-03-13","tags":["hackernews"],"meta":{"score":10},"text":"What Is Recursion? [pdf] http://assets.press.princeton.edu/chapters/s9424.pdf","classes":{"dataset":0.4910917878}}
{"title":"First Transient Electronic Bandage Speeds Healing by 30 Percent","description":"https://www.mccormick.northwestern.edu/news/articles/2023/02/first-transient-electronic-bandage-speeds-healing-by-30-percent/","link":"https://www.mccormick.northwestern.edu/news/articles/2023/02/first-transient-electronic-bandage-speeds-healing-by-30-percent/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":8},"text":"First Transient Electronic Bandage Speeds Healing by 30 Percent https://www.mccormick.northwestern.edu/news/articles/2023/02/first-transient-electronic-bandage-speeds-healing-by-30-percent/","classes":{"dataset":0.5397051573}}
{"title":"Why did 250k Britons die sooner than expected?","description":"https://www.economist.com/interactive/britain/2023/03/09/why-did-250000-britons-die-sooner-than-expected","link":"https://www.economist.com/interactive/britain/2023/03/09/why-did-250000-britons-die-sooner-than-expected","created":"2023-03-12","tags":["hackernews"],"meta":{"score":75},"text":"Why did 250k Britons die sooner than expected? https://www.economist.com/interactive/britain/2023/03/09/why-did-250000-britons-die-sooner-than-expected","classes":{"dataset":0.5298122764}}
{"title":"Large language models are having their Stable Diffusion moment","description":"https://simonwillison.net/2023/Mar/11/llama/","link":"https://simonwillison.net/2023/Mar/11/llama/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":774},"text":"Large language models are having their Stable Diffusion moment https://simonwillison.net/2023/Mar/11/llama/","classes":{"dataset":0.4975261986}}
{"title":"How 'Open' Is OpenAI, Really?","description":"https://dot.la/openai-elon-musk-2659434979.html","link":"https://dot.la/openai-elon-musk-2659434979.html","created":"2023-03-13","tags":["hackernews"],"meta":{"score":70},"text":"How 'Open' Is OpenAI, Really? https://dot.la/openai-elon-musk-2659434979.html","classes":{"dataset":0.5335640907}}
{"title":"A Man Collecting Fading Place Names","description":"https://www.atlasobscura.com/articles/forgotten-place-names-norway","link":"https://www.atlasobscura.com/articles/forgotten-place-names-norway","created":"2023-03-12","tags":["hackernews"],"meta":{"score":12},"text":"A Man Collecting Fading Place Names https://www.atlasobscura.com/articles/forgotten-place-names-norway","classes":{"dataset":0.5101549029}}
{"title":"Nushell.sh ls | where size > 10mb | sort-by modified","description":"https://www.nushell.sh/","link":"https://www.nushell.sh/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":271},"text":"Nushell.sh ls | where size > 10mb | sort-by modified https://www.nushell.sh/","classes":{"dataset":0.515842855}}
{"title":"FDIC Establishes Signature Bridge Bank, N.A., As Successor to Signature Bank","description":"https://www.fdic.gov/news/press-releases/2023/pr23018.html","link":"https://www.fdic.gov/news/press-releases/2023/pr23018.html","created":"2023-03-13","tags":["hackernews"],"meta":{"score":140},"text":"FDIC Establishes Signature Bridge Bank, N.A., As Successor to Signature Bank https://www.fdic.gov/news/press-releases/2023/pr23018.html","classes":{"dataset":0.5657365918}}
{"title":"Tabby is a customizable cross-platform terminal app","description":"https://tabby.sh/","link":"https://tabby.sh/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":87},"text":"Tabby is a customizable cross-platform terminal app https://tabby.sh/","classes":{"dataset":0.5109645724}}
{"title":"STC \u2013 Smart Template Containers for C","description":"https://github.com/tylov/STC","link":"https://github.com/tylov/STC","created":"2023-03-12","tags":["hackernews"],"meta":{"score":22},"text":"STC \u2013 Smart Template Containers for C https://github.com/tylov/STC","classes":{"dataset":0.4698183239}}
{"title":"SVB Securities' CAO served as the CFO for Lehman Brothers' Investment Bank","description":"https://www.svbsecurities.com/team/joseph-gentile/","link":"https://www.svbsecurities.com/team/joseph-gentile/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":17},"text":"SVB Securities' CAO served as the CFO for Lehman Brothers' Investment Bank https://www.svbsecurities.com/team/joseph-gentile/","classes":{"dataset":0.4726464748}}
{"title":"Tim Cook Ordered Headset Launch Despite Designers Warning It Wasn't Ready","description":"https://www.macrumors.com/2023/03/12/cook-ordered-headset-launch-despite-warning/","link":"https://www.macrumors.com/2023/03/12/cook-ordered-headset-launch-despite-warning/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":26},"text":"Tim Cook Ordered Headset Launch Despite Designers Warning It Wasn't Ready https://www.macrumors.com/2023/03/12/cook-ordered-headset-launch-despite-warning/","classes":{"dataset":0.507349968}}
{"title":"Codon: A Python compiler if you have a need for C/C++ speed","description":"https://www.theregister.com/2023/03/11/python_codon_compiler/","link":"https://www.theregister.com/2023/03/11/python_codon_compiler/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":20},"text":"Codon: A Python compiler if you have a need for C/C++ speed https://www.theregister.com/2023/03/11/python_codon_compiler/","classes":{"dataset":0.507349968}}
{"title":"Small Asteroid Impacts Moon","description":"https://twitter.com/dfuji1/status/1629259622619176961","link":"https://twitter.com/dfuji1/status/1629259622619176961","created":"2023-03-11","tags":["hackernews"],"meta":{"score":163},"text":"Small Asteroid Impacts Moon https://twitter.com/dfuji1/status/1629259622619176961","classes":{"dataset":0.5059400201}}
{"title":"How We Knew Space Was a Vacuum (2021)","description":"https://sky-lights.org/2021/06/14/qa-how-we-knew-space-was-a-vacuum/","link":"https://sky-lights.org/2021/06/14/qa-how-we-knew-space-was-a-vacuum/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":129},"text":"How We Knew Space Was a Vacuum (2021) https://sky-lights.org/2021/06/14/qa-how-we-knew-space-was-a-vacuum/","classes":{"dataset":0.4702526629}}
{"title":"Secret colours of the Commodore 64 (2017)","description":"https://www.aaronbell.com/secret-colours-of-the-commodore-64/","link":"https://www.aaronbell.com/secret-colours-of-the-commodore-64/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":199},"text":"Secret colours of the Commodore 64 (2017) https://www.aaronbell.com/secret-colours-of-the-commodore-64/","classes":{"dataset":0.4937388897}}
{"title":"Philips and the death of Europe's last electronics giant [video]","description":"https://www.youtube.com/watch?v=WE58YisgFeQ","link":"https://www.youtube.com/watch?v=WE58YisgFeQ","created":"2023-03-11","tags":["hackernews"],"meta":{"score":52},"text":"Philips and the death of Europe's last electronics giant [video] https://www.youtube.com/watch?v=WE58YisgFeQ","classes":{"dataset":0.5168905258}}
{"title":"Fix your resume using AI","description":"https://www.fixmyresume.xyz/","link":"https://www.fixmyresume.xyz/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":15},"text":"Fix your resume using AI https://www.fixmyresume.xyz/","classes":{"dataset":0.4936168194}}
{"title":"Memory, Pages, MMAP, and Linear Address Spaces","description":"https://pointersgonewild.com/2023/03/12/memory-pages-mmap-and-linear-address-spaces/","link":"https://pointersgonewild.com/2023/03/12/memory-pages-mmap-and-linear-address-spaces/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":10},"text":"Memory, Pages, MMAP, and Linear Address Spaces https://pointersgonewild.com/2023/03/12/memory-pages-mmap-and-linear-address-spaces/","classes":{"dataset":0.5292105675}}
{"title":"Map of an Insect\u2019s Brain","description":"https://www.smithsonianmag.com/smart-news/see-the-first-complete-map-of-an-insects-brain-180981778/","link":"https://www.smithsonianmag.com/smart-news/see-the-first-complete-map-of-an-insects-brain-180981778/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":273},"text":"Map of an Insect\u2019s Brain https://www.smithsonianmag.com/smart-news/see-the-first-complete-map-of-an-insects-brain-180981778/","classes":{"dataset":0.5201477408}}
{"title":"PLD Space keeps building Miura 1. The first Spanish private rocket","description":"https://www.pldspace.com/en/miura-1","link":"https://www.pldspace.com/en/miura-1","created":"2023-03-12","tags":["hackernews"],"meta":{"score":19},"text":"PLD Space keeps building Miura 1. The first Spanish private rocket https://www.pldspace.com/en/miura-1","classes":{"dataset":0.5062334538}}
{"title":"Coltrane: A music theory library with a command-line interface","description":"https://github.com/pedrozath/coltrane","link":"https://github.com/pedrozath/coltrane","created":"2023-03-10","tags":["hackernews"],"meta":{"score":382},"text":"Coltrane: A music theory library with a command-line interface https://github.com/pedrozath/coltrane","classes":{"dataset":0.5092024803}}
{"title":"Show HN: Hacker News LCD Badge","description":"https://github.com/jareklupinski/hackernews-badge","link":"https://github.com/jareklupinski/hackernews-badge","created":"2023-03-12","tags":["hackernews"],"meta":{"score":130},"text":"Show HN: Hacker News LCD Badge https://github.com/jareklupinski/hackernews-badge","classes":{"dataset":0.5180920959}}
{"title":"Energy Is a Form Giver","description":"https://worldsensorium.com/energy-is-a-form-giver/","link":"https://worldsensorium.com/energy-is-a-form-giver/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":31},"text":"Energy Is a Form Giver https://worldsensorium.com/energy-is-a-form-giver/","classes":{"dataset":0.507635653}}
{"title":"Update to the \u201cSamsung space zoom moon shots are fake\u201d","description":"https://old.reddit.com/r/Android/comments/11p7rqy/update_to_the_samsung_space_zoom_moon_shots_are/","link":"https://old.reddit.com/r/Android/comments/11p7rqy/update_to_the_samsung_space_zoom_moon_shots_are/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":222},"text":"Update to the \u201cSamsung space zoom moon shots are fake\u201d https://old.reddit.com/r/Android/comments/11p7rqy/update_to_the_samsung_space_zoom_moon_shots_are/","classes":{"dataset":0.4988388717}}
{"title":"Automatic Image Mining","description":"https://blog.qwertyforce.dev/posts/automatic_image_mining","link":"https://blog.qwertyforce.dev/posts/automatic_image_mining","created":"2023-03-12","tags":["hackernews"],"meta":{"score":49},"text":"Automatic Image Mining https://blog.qwertyforce.dev/posts/automatic_image_mining","classes":{"dataset":0.4809485376}}
{"title":"How to Like Things","description":"https://mattgemmell.scot/how-to-like-things/","link":"https://mattgemmell.scot/how-to-like-things/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":77},"text":"How to Like Things https://mattgemmell.scot/how-to-like-things/","classes":{"dataset":0.5819676518}}
{"title":"US regulators bail out SVB customers, who can access all their money Monday","description":"https://www.cnn.com/2023/03/12/investing/svb-customer-bailout/index.html","link":"https://www.cnn.com/2023/03/12/investing/svb-customer-bailout/index.html","created":"2023-03-12","tags":["hackernews"],"meta":{"score":22},"text":"US regulators bail out SVB customers, who can access all their money Monday https://www.cnn.com/2023/03/12/investing/svb-customer-bailout/index.html","classes":{"dataset":0.5680837631}}
{"title":"The water technology behind Avatar: The Way of Water","description":"https://blog.unity.com/industry/technology-behind-avatar-the-way-of-water","link":"https://blog.unity.com/industry/technology-behind-avatar-the-way-of-water","created":"2023-03-11","tags":["hackernews"],"meta":{"score":165},"text":"The water technology behind Avatar: The Way of Water https://blog.unity.com/industry/technology-behind-avatar-the-way-of-water","classes":{"dataset":0.5077577233}}
{"title":"Prompt for preserving newline and hyphen characters in text to correct","description":"Hello!\n\nI am trying to come up with a prompt that will preserve newlines and hyphens at line ends. I have a OCR scanned page of a book, and I want to pass the prompt the lines from the page. With my current prompt it sometimes does this correctly, sometimes it merges all of the text together into one paragraph, and sometimes it moves words between lines.\n\nI'm wanting the corrected text to be returned with the text on their proper lines so that I can be able to compare the original line to the corrected line with an image of the line of text from the scanned book. I tried using \\\\n as a line separator but I had more success using a custom line separator (| and a number). This also allowed me to put that number into the logit\\_bias.\n\nIn the examples below, I parsed the output into a JSON array, but the actual output is separted by |501|, |502|, etc.\n\n&amp;#x200B;\n\n50-75% of the time it does work, as in the following example: [https://gist.github.com/ReallyNotARussianSpy/a0be73615ce200f2d62d1d711b98930d](https://gist.github.com/ReallyNotARussianSpy/a0be73615ce200f2d62d1d711b98930d)   \nExcept it did remove  from \u201cGuide\u201d when it should not have   \n   \nIt sometimes does not return the number of lines that I want: [https://gist.github.com/ReallyNotARussianSpy/0faa687ab6fdbaf1180c29323af3ba3a](https://gist.github.com/ReallyNotARussianSpy/0faa687ab6fdbaf1180c29323af3ba3a)   \n   \nIt sometimes moves words between lines. Example: [https://gist.github.com/ReallyNotARussianSpy/94617683d4ba658b71a131ccbabddb68](https://gist.github.com/ReallyNotARussianSpy/94617683d4ba658b71a131ccbabddb68)\n\n&amp;#x200B;\n\nI would appreciate any help. Thank you!","link":"https://www.reddit.com/r/PromptDesign/comments/11oapx0/prompt_for_preserving_newline_and_hyphen/","created":"2023-03-11","tags":["reddit","promptdesign","prompteng"],"meta":{"num_comments":0},"text":"Prompt for preserving newline and hyphen characters in text to correct Hello!\n\nI am trying to come up with a prompt that will preserve newlines and hyphens at line ends. I have a OCR scanned page of a book, and I want to pass the prompt the lines from the page. With my current prompt it sometimes does this correctly, sometimes it merges all of the text together into one paragraph, and sometimes it moves words between lines.\n\nI'm wanting the corrected text to be returned with the text on their proper lines so that I can be able to compare the original line to the corrected line with an image of the line of text from the scanned book. I tried using \\\\n as a line separator but I had more success using a custom line separator (| and a number). This also allowed me to put that number into the logit\\_bias.\n\nIn the examples below, I parsed the output into a JSON array, but the actual output is separted by |501|, |502|, etc.\n\n&amp;#x200B;\n\n50-75% of the time it does work, as in the following example: [https://gist.github.com/ReallyNotARussianSpy/a0be73615ce200f2d62d1d711b98930d](https://gist.github.com/ReallyNotARussianSpy/a0be73615ce200f2d62d1d711b98930d)   \nExcept it did remove  from \u201cGuide\u201d when it should not have   \n   \nIt sometimes does not return the number of lines that I want: [https://gist.github.com/ReallyNotARussianSpy/0faa687ab6fdbaf1180c29323af3ba3a](https://gist.github.com/ReallyNotARussianSpy/0faa687ab6fdbaf1180c29323af3ba3a)   \n   \nIt sometimes moves words between lines. Example: [https://gist.github.com/ReallyNotARussianSpy/94617683d4ba658b71a131ccbabddb68](https://gist.github.com/ReallyNotARussianSpy/94617683d4ba658b71a131ccbabddb68)\n\n&amp;#x200B;\n\nI would appreciate any help. Thank you!","classes":{"dataset":0.4387891293}}
{"title":"Monday Daily Thread: Project ideas!","description":"Comment any project ideas beginner or advanced in this thread for others to give a try! If you complete one make sure to reply to the comment with how you found it and attach some source code! If you're looking for project ideas, you might be interested in checking out Al Sweigart's, [\"The Big Book of Small Python Projects\"](https://inventwithpython.com/bigbookpython/) which provides a list of projects and the code to make them work.","link":"https://www.reddit.com/r/Python/comments/11pu7bv/monday_daily_thread_project_ideas/","created":"2023-03-13","tags":["python","reddit"],"meta":{"num_comments":2},"text":"Monday Daily Thread: Project ideas! Comment any project ideas beginner or advanced in this thread for others to give a try! If you complete one make sure to reply to the comment with how you found it and attach some source code! If you're looking for project ideas, you might be interested in checking out Al Sweigart's, [\"The Big Book of Small Python Projects\"](https://inventwithpython.com/bigbookpython/) which provides a list of projects and the code to make them work.","classes":{"dataset":0.4687213302}}
{"title":"Is something wrong with FastAPI?","description":"I want to build a REST api with Python, it is a long term project (new to python). I came across FastAPI and it looks pretty promising, but I wonder why there are 450 open PRs in the repo and the insights show that the project is heavily dependent on a single person. Should I feel comfortable using FastAPI or do you think this is kind of a red flag?","link":"https://www.reddit.com/r/Python/comments/11pfgjo/is_something_wrong_with_fastapi/","created":"2023-03-12","tags":["python","reddit"],"meta":{"num_comments":88},"text":"Is something wrong with FastAPI? I want to build a REST api with Python, it is a long term project (new to python). I came across FastAPI and it looks pretty promising, but I wonder why there are 450 open PRs in the repo and the insights show that the project is heavily dependent on a single person. Should I feel comfortable using FastAPI or do you think this is kind of a red flag?","classes":{"dataset":0.3397223651}}
{"title":"FastKafka - free open source python lib for building Kafka-based services","description":"We were searching for something like FastAPI for Kafka-based service we were developing, but couldn\u2019t find anything similar. So we shamelessly made one by reusing beloved paradigms from FastAPI and we shamelessly named it FastKafka. The point was to set the expectations right - you get pretty much what you would expect: function decorators for consumers and producers with type hints specifying Pydantic classes for JSON encoding/decoding, automatic message routing to Kafka brokers and documentation generation.\n\nPlease take a look and tell us how to make it better. Our goal is to make using it as easy as possible for some how has experience with FastAPI.\n\n[https://github.com/airtai/fastkafka](https://github.com/airtai/fastkafka)","link":"https://www.reddit.com/r/Python/comments/11paz9u/fastkafka_free_open_source_python_lib_for/","created":"2023-03-12","tags":["python","reddit"],"meta":{"num_comments":17},"text":"FastKafka - free open source python lib for building Kafka-based services We were searching for something like FastAPI for Kafka-based service we were developing, but couldn\u2019t find anything similar. So we shamelessly made one by reusing beloved paradigms from FastAPI and we shamelessly named it FastKafka. The point was to set the expectations right - you get pretty much what you would expect: function decorators for consumers and producers with type hints specifying Pydantic classes for JSON encoding/decoding, automatic message routing to Kafka brokers and documentation generation.\n\nPlease take a look and tell us how to make it better. Our goal is to make using it as easy as possible for some how has experience with FastAPI.\n\n[https://github.com/airtai/fastkafka](https://github.com/airtai/fastkafka)","classes":{"dataset":0.2709850371}}
{"title":"Need Guidance on Python Script","description":"I'm a sales and online marketer by trait with 16 years experience working with 4 different agencies here in Austin, Texas. I'm not a programmer. But I have about a dozen projects under my belt and worked with a lot programmers in the past. And I see the value of these python tools and emerging technologies that make everything easier today it seems like. \n\nI wanted to know, what would be the best route to take because I have two types of solutions I want to create while trying to weigh in on expense and time.\n\nOne is a Google Maps email lead scrapper tool.(linkedin also) This is right down my alley as I already have a word of mouth social media referral app. \n\nAnd this other solution is social media listening tool that could track keywords/tags from posts on social networks. (sentiment analysis) This one brings way more value to the table and would be my first priority because it could easily sell as high ticket offer.\n\nI want to hire python expert or find partner with sweat equity. Due to this situation. I don't want to take on the wrong project. I'm trying to weight the difference between which one requires more advanced programmer or has the least possible technical  hurdles for a team of two? One marketer and one programmer.\n\nFYI:\n\nI'm planning to add this gmaps scrapper tool as 90 day freebie for attendees of my webinar class. The app Im promoting is a lead generation referral app called friendloops. And basically it's a high ticket sales webinar. Whoever doesn't bye the referral app on this webinar, are then placed into a sales funnel that sells gmaps scrapper on monthly subscription.\n\nThe reason I'm sharing this much detail is because I don't want people to think I'm just throwing things up in the air to see if they stick. I plan to plug in the gmaps scrapper(or listening tool) into a sales funnel along side a social omni present retargeting campaign. The very same campaigns I used to create for marketing agencies promoting their solution here in Austin, across the country. I'll be using my own money to fund the funnels.","link":"https://www.reddit.com/r/Python/comments/11pv6om/need_guidance_on_python_script/","created":"2023-03-13","tags":["python","reddit"],"meta":{"num_comments":9},"text":"Need Guidance on Python Script I'm a sales and online marketer by trait with 16 years experience working with 4 different agencies here in Austin, Texas. I'm not a programmer. But I have about a dozen projects under my belt and worked with a lot programmers in the past. And I see the value of these python tools and emerging technologies that make everything easier today it seems like. \n\nI wanted to know, what would be the best route to take because I have two types of solutions I want to create while trying to weigh in on expense and time.\n\nOne is a Google Maps email lead scrapper tool.(linkedin also) This is right down my alley as I already have a word of mouth social media referral app. \n\nAnd this other solution is social media listening tool that could track keywords/tags from posts on social networks. (sentiment analysis) This one brings way more value to the table and would be my first priority because it could easily sell as high ticket offer.\n\nI want to hire python expert or find partner with sweat equity. Due to this situation. I don't want to take on the wrong project. I'm trying to weight the difference between which one requires more advanced programmer or has the least possible technical  hurdles for a team of two? One marketer and one programmer.\n\nFYI:\n\nI'm planning to add this gmaps scrapper tool as 90 day freebie for attendees of my webinar class. The app Im promoting is a lead generation referral app called friendloops. And basically it's a high ticket sales webinar. Whoever doesn't bye the referral app on this webinar, are then placed into a sales funnel that sells gmaps scrapper on monthly subscription.\n\nThe reason I'm sharing this much detail is because I don't want people to think I'm just throwing things up in the air to see if they stick. I plan to plug in the gmaps scrapper(or listening tool) into a sales funnel along side a social omni present retargeting campaign. The very same campaigns I used to create for marketing agencies promoting their solution here in Austin, across the country. I'll be using my own money to fund the funnels.","classes":{"dataset":0.1155957505}}
{"title":"Parser combinator in Python","description":"https://github.com/frndmg/pyrsec\n\nI know we have many already, I was just in the look for some type safe, modern looking, with operator support implementation and ended up with my own \ud83d\ude05.\n\nHope you like it.","link":"https://www.reddit.com/r/Python/comments/11pfh05/parser_combinator_in_python/","created":"2023-03-12","tags":["python","reddit"],"meta":{"num_comments":1},"text":"Parser combinator in Python https://github.com/frndmg/pyrsec\n\nI know we have many already, I was just in the look for some type safe, modern looking, with operator support implementation and ended up with my own \ud83d\ude05.\n\nHope you like it.","classes":{"dataset":0.4347957373}}
{"title":"Using ChatGPT API in Python (feat. DALL-E, Karlo)","description":"**Using ChatGPT API in Python (feat. DALL-E, Karlo)**\n\n[https://wooiljeong.github.io/python/chatgpt-api/](https://wooiljeong.github.io/python/chatgpt-api/)\n\nHello, I've written a post on how to use the ChatGPT API (ChatCompletions) in Python, which was recently released.\n\nIn addition, I've also included a method for asking ChatGPT to imagine something and having image generating AIs like Karlo and DALL-E draw pictures based on the results. For example, I automated the process of requesting an imagined image of what buildings might look like if humans settled on Mars from ChatGPT and then having a picture drawn based on the results.\n\nI've attached pictures drawn by Karlo API from Kakao and DALL-E from OpenAI. The impressive thing is that the results of the different AIs' interpretations based on ChatGPT's imaginative input are unique and meaningful. As the shared link is written in Korean, I recommend using a Chrome extension to translate the content into English for those who are interested.\n\n[ The image of a human settlement on Mars drawn by DALL-E. ](https://preview.redd.it/58p82nmva9na1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=2ca4f49b746141321ce367712456c935af3f1fda)\n\n[ The image of a human settlement on Mars drawn by Karlo ](https://preview.redd.it/ohjqtolwa9na1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=9e30b01af6124a72927da7fe3317bae26dd7290f)","link":"https://www.reddit.com/r/Python/comments/11p7yrq/using_chatgpt_api_in_python_feat_dalle_karlo/","created":"2023-03-12","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Using ChatGPT API in Python (feat. DALL-E, Karlo) **Using ChatGPT API in Python (feat. DALL-E, Karlo)**\n\n[https://wooiljeong.github.io/python/chatgpt-api/](https://wooiljeong.github.io/python/chatgpt-api/)\n\nHello, I've written a post on how to use the ChatGPT API (ChatCompletions) in Python, which was recently released.\n\nIn addition, I've also included a method for asking ChatGPT to imagine something and having image generating AIs like Karlo and DALL-E draw pictures based on the results. For example, I automated the process of requesting an imagined image of what buildings might look like if humans settled on Mars from ChatGPT and then having a picture drawn based on the results.\n\nI've attached pictures drawn by Karlo API from Kakao and DALL-E from OpenAI. The impressive thing is that the results of the different AIs' interpretations based on ChatGPT's imaginative input are unique and meaningful. As the shared link is written in Korean, I recommend using a Chrome extension to translate the content into English for those who are interested.\n\n[ The image of a human settlement on Mars drawn by DALL-E. ](https://preview.redd.it/58p82nmva9na1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=2ca4f49b746141321ce367712456c935af3f1fda)\n\n[ The image of a human settlement on Mars drawn by Karlo ](https://preview.redd.it/ohjqtolwa9na1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=9e30b01af6124a72927da7fe3317bae26dd7290f)","classes":{"dataset":0.5215418935}}
{"title":"Godot Fast Android Export","description":"Have you ever used Godot to write Android apps?  \nGodot is crazy fast in deploying that app to your mobile.  Seems that the APK file is already ready and all the GDScripts and Scenes where just extended to the end of that APK as resources. Even Android Studio is much slower.  \n\n\nWhat way can we go using Python on Android?  \nWhen I used PyQt5 the freezing, compiling and deploying process where soo slow.  \nWould\\`nt it be nice to have the Python engine and modules ready compiled and just also add our Python code as resource?  \n\n\nHow can we do that?  \nIs there a solution a la pyqtdeploy from riverbank for PySide6 at all, which we might tweak?","link":"https://www.reddit.com/r/Python/comments/11pe06l/godot_fast_android_export/","created":"2023-03-12","tags":["python","reddit"],"meta":{"num_comments":9},"text":"Godot Fast Android Export Have you ever used Godot to write Android apps?  \nGodot is crazy fast in deploying that app to your mobile.  Seems that the APK file is already ready and all the GDScripts and Scenes where just extended to the end of that APK as resources. Even Android Studio is much slower.  \n\n\nWhat way can we go using Python on Android?  \nWhen I used PyQt5 the freezing, compiling and deploying process where soo slow.  \nWould\\`nt it be nice to have the Python engine and modules ready compiled and just also add our Python code as resource?  \n\n\nHow can we do that?  \nIs there a solution a la pyqtdeploy from riverbank for PySide6 at all, which we might tweak?","classes":{"dataset":0.5704794526}}
{"title":"StructIO: Library for unpacking and packing binary files","description":"These are generic functions combined with a file-like stream for unpacking and packing binary files. I learned how to make them while trying to figure out how to read the game files of The Sims 2.\n\n[https://github.com/lingeringwillx/StructIO](https://github.com/lingeringwillx/StructIO)\n\nThoughts and opinions?\n\nOther similar tools that perform the same task. This seems to be a bit of a niche issue and so the tools for working with it are hard to find:\n\n[bitstring](https://github.com/scott-griffiths/bitstring)\n\n[Kaitai Struct](https://kaitai.io)\n\n[numpy.frombuffer](https://numpy.org/doc/stable/reference/generated/numpy.frombuffer.html) and [numpy.fromfile](https://numpy.org/doc/stable/reference/generated/numpy.fromfile.html)\n\n[Construct](https://construct.readthedocs.io/en/latest/)\n\n[rawutil](https://github.com/Tyulis/rawutil)\n\nThe last time I posted something here years ago my work was trashed, so I'm worried about posting here again :p","link":"https://www.reddit.com/r/Python/comments/11per16/structio_library_for_unpacking_and_packing_binary/","created":"2023-03-12","tags":["python","reddit"],"meta":{"num_comments":3},"text":"StructIO: Library for unpacking and packing binary files These are generic functions combined with a file-like stream for unpacking and packing binary files. I learned how to make them while trying to figure out how to read the game files of The Sims 2.\n\n[https://github.com/lingeringwillx/StructIO](https://github.com/lingeringwillx/StructIO)\n\nThoughts and opinions?\n\nOther similar tools that perform the same task. This seems to be a bit of a niche issue and so the tools for working with it are hard to find:\n\n[bitstring](https://github.com/scott-griffiths/bitstring)\n\n[Kaitai Struct](https://kaitai.io)\n\n[numpy.frombuffer](https://numpy.org/doc/stable/reference/generated/numpy.frombuffer.html) and [numpy.fromfile](https://numpy.org/doc/stable/reference/generated/numpy.fromfile.html)\n\n[Construct](https://construct.readthedocs.io/en/latest/)\n\n[rawutil](https://github.com/Tyulis/rawutil)\n\nThe last time I posted something here years ago my work was trashed, so I'm worried about posting here again :p","classes":{"dataset":0.1577393264}}
{"title":"Matplotlib showing close but incorrect plot?","description":"&amp;#x200B;\n\nhttps://preview.redd.it/ijy6wrntp7na1.png?width=1153&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e7ca32ae47d023d2916c35827d11eb6a360a411b","link":"https://www.reddit.com/r/Python/comments/11p1ncc/matplotlib_showing_close_but_incorrect_plot/","created":"2023-03-12","tags":["python","reddit"],"meta":{"num_comments":25},"text":"Matplotlib showing close but incorrect plot? &amp;#x200B;\n\nhttps://preview.redd.it/ijy6wrntp7na1.png?width=1153&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e7ca32ae47d023d2916c35827d11eb6a360a411b","classes":{"dataset":0.422976166}}
{"title":"Python and KIVY for reading info from micro-controller","description":" I created app for reading info from port Arduino. I used Kivy and added one a button, a title and a spinner. User can chose port and read info.\n\nHere my code.\n\n[https://github.com/Pra1seTheSun322/Read-information-from-Arduino-UNO](https://github.com/Pra1seTheSun322/Read-information-from-Arduino-UNO)","link":"https://www.reddit.com/r/Python/comments/11phabb/python_and_kivy_for_reading_info_from/","created":"2023-03-12","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Python and KIVY for reading info from micro-controller  I created app for reading info from port Arduino. I used Kivy and added one a button, a title and a spinner. User can chose port and read info.\n\nHere my code.\n\n[https://github.com/Pra1seTheSun322/Read-information-from-Arduino-UNO](https://github.com/Pra1seTheSun322/Read-information-from-Arduino-UNO)","classes":{"dataset":0.4010316432}}
{"title":"Which topic in deep learning do you think will become relevant or popular in the future?","description":"I recently saw Continual Learning (CL) growing, with several papers published recently that have considerable potential to impact real-world applications. Which topic (such as CV, RL, NLP, CL..) will be very relevant to research or be focused on a lot? And which topic do you think still needs a breakthrough and will have a significant impact in real-world applications, such as in the case of these LLM models in recent times? Feel free to mention your current topic of work and why you chose to do it \ud83d\ude0a","link":"https://www.reddit.com/r/deeplearning/comments/11pyvb3/which_topic_in_deep_learning_do_you_think_will/","created":"2023-03-13","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":6},"text":"Which topic in deep learning do you think will become relevant or popular in the future? I recently saw Continual Learning (CL) growing, with several papers published recently that have considerable potential to impact real-world applications. Which topic (such as CV, RL, NLP, CL..) will be very relevant to research or be focused on a lot? And which topic do you think still needs a breakthrough and will have a significant impact in real-world applications, such as in the case of these LLM models in recent times? Feel free to mention your current topic of work and why you chose to do it \ud83d\ude0a","classes":{"dataset":0.3803714216}}
{"title":"YOLO equation","description":"Hi,Can any one explain this equation?Pr(Classi|Object) \u2217 Pr(Object) \u2217 IOU = Pr(Classi) \u2217 IOUIt is from the You Look Only Once article, but it seems mathematically wrong. Shouldnt be like this  Pr(Classi|Object) \u2217 Pr(Object) \u2217 IOU = Pr(Classi\\^Object) \u2217 IOU ?","link":"https://www.reddit.com/r/deeplearning/comments/11q0c2t/yolo_equation/","created":"2023-03-13","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":1},"text":"YOLO equation Hi,Can any one explain this equation?Pr(Classi|Object) \u2217 Pr(Object) \u2217 IOU = Pr(Classi) \u2217 IOUIt is from the You Look Only Once article, but it seems mathematically wrong. Shouldnt be like this  Pr(Classi|Object) \u2217 Pr(Object) \u2217 IOU = Pr(Classi\\^Object) \u2217 IOU ?","classes":{"dataset":0.2535766363}}
{"title":"Factors Influencing Adoption Intention of ChatGPT","description":"Hello,\n\nI am an information systems student currently conducting research for my undergraduate thesis on the factors that influence people's adoption intention of ChatGPT, as well as identifying the factors that may be holding them back. These factors include people's concerns about potential negative impacts of ChatGPT, such as increased unemployment and the spread of misinformation. Your participation in this study is crucial as it will provide valuable insights to help us understand how ChatGPT can be improved to meet users' needs.\n\nPlease note that I am not affiliated with OpenAI, no identifying information will be collected during the survey, and all responses will be kept confidential. The survey should take approximately 10 to 15 minutes to complete, and participation is voluntary. You may withdraw from the survey at any time, and there are no known risks associated with participating.\n\nIf you are interested in learning more about the study, please follow the link below. https://forms.gle/EwZCtpYDvk9R9M386\n\nThank you for taking the time to contribute to our research study. Your participation is greatly appreciated!","link":"https://www.reddit.com/r/deeplearning/comments/11p7x0f/factors_influencing_adoption_intention_of_chatgpt/","created":"2023-03-12","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":4},"text":"Factors Influencing Adoption Intention of ChatGPT Hello,\n\nI am an information systems student currently conducting research for my undergraduate thesis on the factors that influence people's adoption intention of ChatGPT, as well as identifying the factors that may be holding them back. These factors include people's concerns about potential negative impacts of ChatGPT, such as increased unemployment and the spread of misinformation. Your participation in this study is crucial as it will provide valuable insights to help us understand how ChatGPT can be improved to meet users' needs.\n\nPlease note that I am not affiliated with OpenAI, no identifying information will be collected during the survey, and all responses will be kept confidential. The survey should take approximately 10 to 15 minutes to complete, and participation is voluntary. You may withdraw from the survey at any time, and there are no known risks associated with participating.\n\nIf you are interested in learning more about the study, please follow the link below. https://forms.gle/EwZCtpYDvk9R9M386\n\nThank you for taking the time to contribute to our research study. Your participation is greatly appreciated!","classes":{"dataset":0.3437190354}}
{"title":"How to blackout certain landmarks from face?","description":"I am working on a project to classify faces and I want to blackout certain areas especially eyes, nose, mouth so that my model can generalize well. But I am confused how to do that. Can someone please guide me?","link":"https://www.reddit.com/r/deeplearning/comments/11opl7o/how_to_blackout_certain_landmarks_from_face/","created":"2023-03-11","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":1},"text":"How to blackout certain landmarks from face? I am working on a project to classify faces and I want to blackout certain areas especially eyes, nose, mouth so that my model can generalize well. But I am confused how to do that. Can someone please guide me?","classes":{"dataset":0.275909245}}
{"title":"Desktop Computer or some other way to train neural networks?","description":"Should I buy a desktop with a GPU like Nvidia RTX 3080 or perhaps use online VM/Cloud based machines for deep learning. What would be optimal?  Any and all feedback is welcome \n\nI am new to Deep Learning but want to become an expert in areas of Deep Learning especially Computer Vision.","link":"https://www.reddit.com/r/deeplearning/comments/11o8xjx/desktop_computer_or_some_other_way_to_train/","created":"2023-03-11","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":16},"text":"Desktop Computer or some other way to train neural networks? Should I buy a desktop with a GPU like Nvidia RTX 3080 or perhaps use online VM/Cloud based machines for deep learning. What would be optimal?  Any and all feedback is welcome \n\nI am new to Deep Learning but want to become an expert in areas of Deep Learning especially Computer Vision.","classes":{"dataset":0.7328718901}}
{"title":"Generate READMEs Using ChatGPT","description":"&amp;#x200B;\n\nhttps://i.redd.it/k375our2a0na1.gif\n\n&amp;#x200B;\n\nYou can use this program I wrote to generate readmes: [https://github.com/tom-doerr/codex-readme](https://github.com/tom-doerr/codex-readme)\n\n&amp;#x200B;\n\nIt's far from perfect, but I now added ChatGPT and it is surprisingly good at inferring what the project is about. It often generates interesting usage examples and explains the available command line options.\n\n&amp;#x200B;\n\nYou probably won't yet use this for larger projects, but I think this can make sense for small projects or single scripts. Many small scripts are very useful but might never be published because of the work that is required to document and explain it. Using this AI might assist you with that.\n\n&amp;#x200B;\n\nReportedly GPT-4 is coming out next week, which probably would make it even better.\n\n&amp;#x200B;\n\nWhat do you think?","link":"https://www.reddit.com/r/deeplearning/comments/11o5zyl/generate_readmes_using_chatgpt/","created":"2023-03-11","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0},"text":"Generate READMEs Using ChatGPT &amp;#x200B;\n\nhttps://i.redd.it/k375our2a0na1.gif\n\n&amp;#x200B;\n\nYou can use this program I wrote to generate readmes: [https://github.com/tom-doerr/codex-readme](https://github.com/tom-doerr/codex-readme)\n\n&amp;#x200B;\n\nIt's far from perfect, but I now added ChatGPT and it is surprisingly good at inferring what the project is about. It often generates interesting usage examples and explains the available command line options.\n\n&amp;#x200B;\n\nYou probably won't yet use this for larger projects, but I think this can make sense for small projects or single scripts. Many small scripts are very useful but might never be published because of the work that is required to document and explain it. Using this AI might assist you with that.\n\n&amp;#x200B;\n\nReportedly GPT-4 is coming out next week, which probably would make it even better.\n\n&amp;#x200B;\n\nWhat do you think?","classes":{"dataset":0.2793671489}}
{"title":"One Shot Learning Task","description":"From my understanding, a one shot learning task requires us that given a query example, we must classify it correctly out of N different classes (typically N = 5 way or 20 way). The goal however is that we are provided with only one example per class.\n\nSuppose we take an MNIST type dataset. I can map every pixel that makes up the digit onto a cartesian plane where the xy coordinates values is every \"pixel\". Using this cartesian representation, can I just find the simple distance metric between the pairs? For example on a 20 way task, My question is: At each iteration, we are provided with some query example, along with 20 other candidates...if we compute some sort of simple similarity score (that doesnt require neural nets) like (intersection over union) between each candidate to query pair, does this still count as a one shot learning task?\n\nSo leaving aside a neural network approach, if we were to just use a simple distance metric on the coordinates to compute the pairwise similarity between the query and every \"candidate\", does this count as one shot learning?","link":"https://www.reddit.com/r/deeplearning/comments/11o9ilf/one_shot_learning_task/","created":"2023-03-11","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":3},"text":"One Shot Learning Task From my understanding, a one shot learning task requires us that given a query example, we must classify it correctly out of N different classes (typically N = 5 way or 20 way). The goal however is that we are provided with only one example per class.\n\nSuppose we take an MNIST type dataset. I can map every pixel that makes up the digit onto a cartesian plane where the xy coordinates values is every \"pixel\". Using this cartesian representation, can I just find the simple distance metric between the pairs? For example on a 20 way task, My question is: At each iteration, we are provided with some query example, along with 20 other candidates...if we compute some sort of simple similarity score (that doesnt require neural nets) like (intersection over union) between each candidate to query pair, does this still count as a one shot learning task?\n\nSo leaving aside a neural network approach, if we were to just use a simple distance metric on the coordinates to compute the pairwise similarity between the query and every \"candidate\", does this count as one shot learning?","classes":{"dataset":0.3119657934}}
{"title":"Does Reinforcement learning algorithm will do the job ?","description":"Hey\n\n I'm trying to make an algorithm that learns to play Yahtzee and maximizes the win or the score depending on what I manage to do \n\nI'm totally new, I watched a lot of videos, I read wikipedia but I don't know in which direction to go I tell myself that doing deep learning with a coupled neural network seems to correspond \n\nI imagine having the algorithm play around ten games and average the scores squared \n\nThen keep the best ones and include mutation\n\n I saw that it was related to the Markov problem, well as you can see it's going all over the place and I don't know where to start","link":"https://www.reddit.com/r/deeplearning/comments/11nxfkh/does_reinforcement_learning_algorithm_will_do_the/","created":"2023-03-10","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":2},"text":"Does Reinforcement learning algorithm will do the job ? Hey\n\n I'm trying to make an algorithm that learns to play Yahtzee and maximizes the win or the score depending on what I manage to do \n\nI'm totally new, I watched a lot of videos, I read wikipedia but I don't know in which direction to go I tell myself that doing deep learning with a coupled neural network seems to correspond \n\nI imagine having the algorithm play around ten games and average the scores squared \n\nThen keep the best ones and include mutation\n\n I saw that it was related to the Markov problem, well as you can see it's going all over the place and I don't know where to start","classes":{"dataset":0.3665848076}}
{"title":"[D] Version 2.1 of the Open Deep Learning Toolkit for Robotics is already available!","description":" The latest version of the Open Deep Learning Toolkit for Robotics, **Version 2.1 is already available !**\n\nThis new version includes the following updates:\n\n**New Features:**\n\n* Added Efficient LiDAR Panoptic Segmentation\n* Added Nanodet 2D Object Detection tool\u00a0\n* Added C API implementations of NanoDet 2D Object Detection tool\n* Added C API implementations of forward pass of DETR 2D Object Detection tool\n* Added C API implementations of forward pass of DeepSORT 2D Object Tracking tool\u00a0\n* Added C API implementations of forward pass of Lightweight OpenPose, Pose Estimator tool\n* Added C API implementations of forward pass of X3D 2D Activity Recognition tool\u00a0\n* Added C API implementations of forward pass of Progressive Spatiotemporal GCN Skeleton-based Action Recognition tool\n* Added Binary High Resolution Analysis tool\n* Added Multi-Object-Search tool\u00a0\n\n***Enhancements***\n\n* Added support in C API for detection target structure and vector of detections\u00a0\n* Added support in C API for tensor structure and vector of tensors\n* Added support in C API for json parser\u00a0\n\nYou can download the toolkit here:  \n\\- GitHub: [https://github.com/opendr-eu/opendr](https://github.com/opendr-eu/opendr)\n\n\\- pip: [https://pypi.org/project/opendr-toolkit/](https://pypi.org/project/opendr-toolkit/)  \n\\- Docker Hub: [https://hub.docker.com/r/opendr/opendr-toolkit/tags](https://hub.docker.com/r/opendr/opendr-toolkit/tags)\n\nLooking forward for your comments and suggestions!","link":"https://www.reddit.com/r/deeplearning/comments/11nv4lq/d_version_21_of_the_open_deep_learning_toolkit/","created":"2023-03-10","tags":["reddit","deeplearning","ml"],"meta":{"num_comments":0},"text":"[D] Version 2.1 of the Open Deep Learning Toolkit for Robotics is already available!  The latest version of the Open Deep Learning Toolkit for Robotics, **Version 2.1 is already available !**\n\nThis new version includes the following updates:\n\n**New Features:**\n\n* Added Efficient LiDAR Panoptic Segmentation\n* Added Nanodet 2D Object Detection tool\u00a0\n* Added C API implementations of NanoDet 2D Object Detection tool\n* Added C API implementations of forward pass of DETR 2D Object Detection tool\n* Added C API implementations of forward pass of DeepSORT 2D Object Tracking tool\u00a0\n* Added C API implementations of forward pass of Lightweight OpenPose, Pose Estimator tool\n* Added C API implementations of forward pass of X3D 2D Activity Recognition tool\u00a0\n* Added C API implementations of forward pass of Progressive Spatiotemporal GCN Skeleton-based Action Recognition tool\n* Added Binary High Resolution Analysis tool\n* Added Multi-Object-Search tool\u00a0\n\n***Enhancements***\n\n* Added support in C API for detection target structure and vector of detections\u00a0\n* Added support in C API for tensor structure and vector of tensors\n* Added support in C API for json parser\u00a0\n\nYou can download the toolkit here:  \n\\- GitHub: [https://github.com/opendr-eu/opendr](https://github.com/opendr-eu/opendr)\n\n\\- pip: [https://pypi.org/project/opendr-toolkit/](https://pypi.org/project/opendr-toolkit/)  \n\\- Docker Hub: [https://hub.docker.com/r/opendr/opendr-toolkit/tags](https://hub.docker.com/r/opendr/opendr-toolkit/tags)\n\nLooking forward for your comments and suggestions!","classes":{"dataset":0.4155764282}}
{"title":"[R] Introducing Ursa from Speechmatics | 25% improvement over Whisper","description":"Ursa is the world\u2019s most accurate speech-to-text system and delivers a relative accuracy gain of 22% and 25%\u00a0versus Microsoft and OpenAI's Whisper respectively. \n\nFind out more and try it for free with just one click: [www.speechmatics.com/ursa](http://www.speechmatics.com/ursa) \n\nSpeechmatics achieved this by building on the scaling laws from DeepMind\u2019s Chinchilla paper and applying them to large self-supervised learning models for speech. By scaling to 2 billion parameters, the models can learn richer acoustic features from over 1 million hours of unlabeled multi-lingual data, allowing Ursa to understand a larger spectrum of voices.\n\nhttps://preview.redd.it/y54g784nudna1.png?width=1024&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1ed83c647697e2dfb95ed2277377fadc52e4b8f4","link":"https://www.reddit.com/r/MachineLearning/comments/11prxd9/r_introducing_ursa_from_speechmatics_25/","created":"2023-03-12","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":24},"text":"[R] Introducing Ursa from Speechmatics | 25% improvement over Whisper Ursa is the world\u2019s most accurate speech-to-text system and delivers a relative accuracy gain of 22% and 25%\u00a0versus Microsoft and OpenAI's Whisper respectively. \n\nFind out more and try it for free with just one click: [www.speechmatics.com/ursa](http://www.speechmatics.com/ursa) \n\nSpeechmatics achieved this by building on the scaling laws from DeepMind\u2019s Chinchilla paper and applying them to large self-supervised learning models for speech. By scaling to 2 billion parameters, the models can learn richer acoustic features from over 1 million hours of unlabeled multi-lingual data, allowing Ursa to understand a larger spectrum of voices.\n\nhttps://preview.redd.it/y54g784nudna1.png?width=1024&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1ed83c647697e2dfb95ed2277377fadc52e4b8f4","classes":{"dataset":0.5612388253}}
{"title":"[D] What's the mathematical notation for \"top k argmax\"?","description":"I'm trying to express something in mathematical notation - let's say I want to get the top k indices for which a function obtains highest values. So, something like argmax, but for a general k number of indices instead of just the top index. Is there a standard notation for this?","link":"https://www.reddit.com/r/MachineLearning/comments/11po6qw/d_whats_the_mathematical_notation_for_top_k_argmax/","created":"2023-03-12","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":9},"text":"[D] What's the mathematical notation for \"top k argmax\"? I'm trying to express something in mathematical notation - let's say I want to get the top k indices for which a function obtains highest values. So, something like argmax, but for a general k number of indices instead of just the top index. Is there a standard notation for this?","classes":{"dataset":0.1203989759}}
{"title":"[P] Introducing confidenceinterval, the long missing python library for computing confidence intervals","description":"[https://github.com/jacobgil/confidenceinterval](https://github.com/jacobgil/confidenceinterval)\n\npip install confidenceinterval\n\ntldr: You don't have an excuse anymore to not use confidence intervals !\n\n&amp;#x200B;\n\nIn statistics, confidence intervals are commonly reported along accuracy metrics to help interpret them.\n\nFor example, an AUC metric might be 0.9 but if the 95% confidence interval is in the range \\[0.7, 0.96\\], we can't confidently say we didn't just get lucky - we should be really careful making decisions around that result.\n\nMore formally, a confidence interval gives us a range on where the true unknown accuracy metric could be, and a 95% confidence interval means that if we would repeat the experiment many times, 95% of the confidence-intervals we reported would have the actual true metric (which is unknown) inside them - coverage.\n\nConfidence intervals are usually computed analytically, by making some assumptions about the metric distribution and using the central limit theorem,or by using bootstrapping - resampling the results again and again, computing the metric, and checking the resulting distribution.\n\nHowever, in the python data science world, I rarely saw these being used. I guess part of the reason is the culture, where many data science practitioners don't come from the statistics world. But I think the main reason is that there aren't easy to use libraries that do this. While in the R language there is fantastic support for confidence intervals, for python there are mostly scattered pieces of code and blog posts.\n\n&amp;#x200B;\n\nThe confidenceinterval package keeps the clean and popular scikit-learn metric API,\n\ne.g roc\\_auc\\_score(y\\_true, y\\_pred), but also returns confidence intervals.\n\nIt supports analytical computations for many methods (including AUC with the delong method, or F1 with macro, micro averaging, following the recent results from [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2), or binary proportions like the TPR using binomial CI methods like the wilson interval).\n\nIt can be easily switched to using bootstrapping (with several supported bootstrapping methods),\n\nand also gives you a way to easily compute the confidence interval for any metric with bootstrapping.","link":"https://www.reddit.com/r/MachineLearning/comments/11orezx/p_introducing_confidenceinterval_the_long_missing/","created":"2023-03-11","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":9},"text":"[P] Introducing confidenceinterval, the long missing python library for computing confidence intervals [https://github.com/jacobgil/confidenceinterval](https://github.com/jacobgil/confidenceinterval)\n\npip install confidenceinterval\n\ntldr: You don't have an excuse anymore to not use confidence intervals !\n\n&amp;#x200B;\n\nIn statistics, confidence intervals are commonly reported along accuracy metrics to help interpret them.\n\nFor example, an AUC metric might be 0.9 but if the 95% confidence interval is in the range \\[0.7, 0.96\\], we can't confidently say we didn't just get lucky - we should be really careful making decisions around that result.\n\nMore formally, a confidence interval gives us a range on where the true unknown accuracy metric could be, and a 95% confidence interval means that if we would repeat the experiment many times, 95% of the confidence-intervals we reported would have the actual true metric (which is unknown) inside them - coverage.\n\nConfidence intervals are usually computed analytically, by making some assumptions about the metric distribution and using the central limit theorem,or by using bootstrapping - resampling the results again and again, computing the metric, and checking the resulting distribution.\n\nHowever, in the python data science world, I rarely saw these being used. I guess part of the reason is the culture, where many data science practitioners don't come from the statistics world. But I think the main reason is that there aren't easy to use libraries that do this. While in the R language there is fantastic support for confidence intervals, for python there are mostly scattered pieces of code and blog posts.\n\n&amp;#x200B;\n\nThe confidenceinterval package keeps the clean and popular scikit-learn metric API,\n\ne.g roc\\_auc\\_score(y\\_true, y\\_pred), but also returns confidence intervals.\n\nIt supports analytical computations for many methods (including AUC with the delong method, or F1 with macro, micro averaging, following the recent results from [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2), or binary proportions like the TPR using binomial CI methods like the wilson interval).\n\nIt can be easily switched to using bootstrapping (with several supported bootstrapping methods),\n\nand also gives you a way to easily compute the confidence interval for any metric with bootstrapping.","classes":{"dataset":0.1360156536}}
{"title":"[P] GITModel: Dynamically generate high-quality hierarchical topic tree representations of GitHub repositories using customizable GNN message passing layers, chatgpt, and topic modeling.","description":"Decompose Python libraries and generate Coherent hierarchical topic models of the repository.  \n[https://github.com/danielpatrickhug/GitModel](https://github.com/danielpatrickhug/GitModel)\n\nThe ability to bootstrap its own codebase is a powerful feature as it allows for efficient self-improvement and expansion. It means that the codebase is designed in such a way that it can use its own output as an input to improve itself. In the context of GitModel, this feature allows for the efficient improvement and expansion of its own codebase. By using its own output to generate hierarchical topic trees of GitHub repositories, it can analyze and extract insights from its own codebase and other codebases to improve its functionality. This can lead to more efficient and effective code generation, better semantic graph generation, and improved text generation capabilities.\n\n  \nI spent around 10 hours today on a major refactor creating a simple pipeline abstraction and allowing dynamic instantiation from yaml configs. It now also supports multiple GNN heads.\n\nPlease try it out and let me know what you think!\n\nExample:  \n[https://github.com/deepmind/clrs](https://github.com/deepmind/clrs)\n\nhttps://preview.redd.it/ut4fc6c401na1.png?width=1506&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b039242432c1f0526d1d81eadbfe8abc1168d2fd","link":"https://www.reddit.com/r/MachineLearning/comments/11o97on/p_gitmodel_dynamically_generate_highquality/","created":"2023-03-11","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":25},"text":"[P] GITModel: Dynamically generate high-quality hierarchical topic tree representations of GitHub repositories using customizable GNN message passing layers, chatgpt, and topic modeling. Decompose Python libraries and generate Coherent hierarchical topic models of the repository.  \n[https://github.com/danielpatrickhug/GitModel](https://github.com/danielpatrickhug/GitModel)\n\nThe ability to bootstrap its own codebase is a powerful feature as it allows for efficient self-improvement and expansion. It means that the codebase is designed in such a way that it can use its own output as an input to improve itself. In the context of GitModel, this feature allows for the efficient improvement and expansion of its own codebase. By using its own output to generate hierarchical topic trees of GitHub repositories, it can analyze and extract insights from its own codebase and other codebases to improve its functionality. This can lead to more efficient and effective code generation, better semantic graph generation, and improved text generation capabilities.\n\n  \nI spent around 10 hours today on a major refactor creating a simple pipeline abstraction and allowing dynamic instantiation from yaml configs. It now also supports multiple GNN heads.\n\nPlease try it out and let me know what you think!\n\nExample:  \n[https://github.com/deepmind/clrs](https://github.com/deepmind/clrs)\n\nhttps://preview.redd.it/ut4fc6c401na1.png?width=1506&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b039242432c1f0526d1d81eadbfe8abc1168d2fd","classes":{"dataset":0.341063112}}
{"title":"Text2Image ControlNet and Stable Diffusion [R]","description":"In this tutorial, we will show you how to create beautiful and high-quality images from text using the powerful combination of diffusion model and ControlNet. \n\nText2Image generation is a fascinating field of AI that enables machines to understand and visualize human language in a more creative way.\n\n we will walk you through the step-by-step process of how to use the diffusion model and ControlNet to generate images from text. By the end of this tutorial, you will have a thorough understanding of text2image generation and how to use diffusion model and ControlNet to create stunning images from text. You will also have the knowledge and skills to apply these techniques to your own projects and experiments.\n\n So, get ready to dive into the exciting world of text2image generation and start creating your own beautiful images from text today!\n\nhttps://youtu.be/0D5Nlo2REb0","link":"https://www.reddit.com/r/MachineLearning/comments/11p1oqq/text2image_controlnet_and_stable_diffusion_r/","created":"2023-03-12","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":0},"text":"Text2Image ControlNet and Stable Diffusion [R] In this tutorial, we will show you how to create beautiful and high-quality images from text using the powerful combination of diffusion model and ControlNet. \n\nText2Image generation is a fascinating field of AI that enables machines to understand and visualize human language in a more creative way.\n\n we will walk you through the step-by-step process of how to use the diffusion model and ControlNet to generate images from text. By the end of this tutorial, you will have a thorough understanding of text2image generation and how to use diffusion model and ControlNet to create stunning images from text. You will also have the knowledge and skills to apply these techniques to your own projects and experiments.\n\n So, get ready to dive into the exciting world of text2image generation and start creating your own beautiful images from text today!\n\nhttps://youtu.be/0D5Nlo2REb0","classes":{"dataset":0.2033728361}}
{"title":"[P] RWKV 14B is a strong chatbot despite only trained on Pile (16G VRAM for 14B ctx4096 INT8, more optimizations incoming)","description":"The latest CharRWKV v2 has a new chat prompt (works for any topic), and here are some raw user chats with RWKV-4-Pile-14B-20230228-ctx4096-test663 model (topp=0.85, temp=1.0, presence penalty 0.2, frequency penalty 0.5). You are welcome to try ChatRWKV v2:  [https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nAnd please keep in mind that RWKV is 100% RNN :) Pile v1 date cutoff is year 2020.\n\n[Chat #1](https://preview.redd.it/ripvptomexma1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=29ed1cd499dc4d693dee32ad7550a7910402d033)\n\n[Chat #2](https://preview.redd.it/8t75njnnexma1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d20186f2e423d321817b79e6e559dc74a42bf0b8)\n\nThese are surprisingly good because RWKV is only trained on the Pile (and 100% RNN). No finetuning. No instruct tuning. No RLHF. You are welcome to try it.\n\n1. Update ChatRWKV v2 \\[and rwkv pip package\\] to latest version.\n2. Use  [https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth](https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth)\n3. Run v2/chat.py and enjoy.\n\nChatRWKV v2 supports INT8 now (with my crappy slow quantization, **works for windows, supports any GPU**, 16G VRAM for 14B if you offload final layer to CPU). And you can offload more layers to CPU to run it with 3G VRAM though that will be very slow :) More optimizations are coming.\n\nOr you can try the 7B model (less coherency) and 3B model (not very coherent, but still fun).","link":"https://www.reddit.com/r/MachineLearning/comments/11nre6t/p_rwkv_14b_is_a_strong_chatbot_despite_only/","created":"2023-03-10","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":29},"text":"[P] RWKV 14B is a strong chatbot despite only trained on Pile (16G VRAM for 14B ctx4096 INT8, more optimizations incoming) The latest CharRWKV v2 has a new chat prompt (works for any topic), and here are some raw user chats with RWKV-4-Pile-14B-20230228-ctx4096-test663 model (topp=0.85, temp=1.0, presence penalty 0.2, frequency penalty 0.5). You are welcome to try ChatRWKV v2:  [https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nAnd please keep in mind that RWKV is 100% RNN :) Pile v1 date cutoff is year 2020.\n\n[Chat #1](https://preview.redd.it/ripvptomexma1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=29ed1cd499dc4d693dee32ad7550a7910402d033)\n\n[Chat #2](https://preview.redd.it/8t75njnnexma1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d20186f2e423d321817b79e6e559dc74a42bf0b8)\n\nThese are surprisingly good because RWKV is only trained on the Pile (and 100% RNN). No finetuning. No instruct tuning. No RLHF. You are welcome to try it.\n\n1. Update ChatRWKV v2 \\[and rwkv pip package\\] to latest version.\n2. Use  [https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth](https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth)\n3. Run v2/chat.py and enjoy.\n\nChatRWKV v2 supports INT8 now (with my crappy slow quantization, **works for windows, supports any GPU**, 16G VRAM for 14B if you offload final layer to CPU). And you can offload more layers to CPU to run it with 3G VRAM though that will be very slow :) More optimizations are coming.\n\nOr you can try the 7B model (less coherency) and 3B model (not very coherent, but still fun).","classes":{"dataset":0.3145579398}}
{"title":"[D] Statsmodels ARIMA model predict function not working","description":"I trained my ARIMA model by doing the following\n\n`from statsmodels.tsa.arima.model import ARIMA`\n\n`model_ar = ARIMA(data.Num_Passengers, order=(1,0, 0))`\n\n`results_ar = model_ar.fit()results_ar.summary()`\n\n&amp;#x200B;\n\nThe code worked with the resulting output\n\n&amp;#x200B;\n\nhttps://preview.redd.it/zi8f1lhak5na1.png?width=746&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3f5ef9fe1504892e4ce48b5287d8b834f1dfdb27\n\nBut then I tried predicting on the testing dataset, and I got the following error.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/uni7ws1ck5na1.png?width=1675&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ce520334f3b1e420a101adda9f43868714617272\n\nAm I just messing something up, is anyone else dealing with this error?\n\nIs there another way to use the predict function, or is it really unimplemented.\n\nCould you please help me out with this?\n\nHow would I overwrite the method?","link":"https://www.reddit.com/r/MachineLearning/comments/11or4qb/d_statsmodels_arima_model_predict_function_not/","created":"2023-03-11","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":8},"text":"[D] Statsmodels ARIMA model predict function not working I trained my ARIMA model by doing the following\n\n`from statsmodels.tsa.arima.model import ARIMA`\n\n`model_ar = ARIMA(data.Num_Passengers, order=(1,0, 0))`\n\n`results_ar = model_ar.fit()results_ar.summary()`\n\n&amp;#x200B;\n\nThe code worked with the resulting output\n\n&amp;#x200B;\n\nhttps://preview.redd.it/zi8f1lhak5na1.png?width=746&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3f5ef9fe1504892e4ce48b5287d8b834f1dfdb27\n\nBut then I tried predicting on the testing dataset, and I got the following error.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/uni7ws1ck5na1.png?width=1675&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ce520334f3b1e420a101adda9f43868714617272\n\nAm I just messing something up, is anyone else dealing with this error?\n\nIs there another way to use the predict function, or is it really unimplemented.\n\nCould you please help me out with this?\n\nHow would I overwrite the method?","classes":{"dataset":0.1424123943}}
{"title":"Recommendations for a newbie","description":"I've been reading a lot of articles about AI in general, machine learning and NLP etc but I want to learn more about NLP, creating desktop and mobile apps for questions-answering and summarizing texts. \n\nI've done programming in javascript and C# in the past and I wonder if that is enough or if I must learn python as well. \n\nWhat are your recommendations regarding language, tools, APIs, models, transformers etc and why should I start with these?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11pdpc3/recommendations_for_a_newbie/","created":"2023-03-12","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":9},"text":"Recommendations for a newbie I've been reading a lot of articles about AI in general, machine learning and NLP etc but I want to learn more about NLP, creating desktop and mobile apps for questions-answering and summarizing texts. \n\nI've done programming in javascript and C# in the past and I wonder if that is enough or if I must learn python as well. \n\nWhat are your recommendations regarding language, tools, APIs, models, transformers etc and why should I start with these?","classes":{"dataset":0.4069804549}}
{"title":"Identify custom labels as well as existing labels with Spacy v3","description":"Hi all,\n\nI want to train a model with custom labels, and use it in combination with a pretrained model in Spacy v3.\n\nFor example for this code:\n\n    import spacy\n    import random\n    import json\n    \n    # Load the spaCy NLP model\n    nlp = spacy.load('en_core_web_lg')\n    \n    # Define the training data\n    train_data = [\n        ('These tomatoes are red and tasty.', {'entities': [(6, 14, 'VEGETABLE')]}),\n        ('I like red tomatoes.', {'entities': [(11, 19, 'VEGETABLE')]}),\n       \n        ('These bananas are very green.', {'entities': [(6, 13, 'FRUIT')]}),\n        ('Where are my bananas?', {'entities': [(13, 20, 'FRUIT')]}),\n        ('Are there any bananas near?', {'entities': [(14, 21, 'FRUIT')]}),    \n    ]\n    \n    # Define the new entity labels\n    new_labels = [\"FRUIT\", \"VEGETABLE\"]\n    \n    # Add the new labels to the existing entity recognizer\n    ner = nlp.get_pipe(\"ner\")\n    for label in new_labels:\n        ner.add_label(label)\n    \n    # Set up the optimizer\n    #optimizer = nlp.begin_training()\n    optimizer = nlp.initialize()\n    \n    # Iterate over the training data and update the model\n    for i in range(10):\n        random.shuffle(train_data)\n        for text, annotations in train_data:\n            doc = nlp.make_doc(text)\n            example = spacy.training.Example.from_dict(doc, annotations)\n            nlp.update([example], sgd=optimizer)\n    \n    # Test the model\n    text = \"\"\"What kind of color have bananas &amp; tomatoes in London?\"\"\"\n    doc = nlp(text)\n    for ent in doc.ents:\n        print(ent.text, ent.label_)\n\nThe output is:\n\n    bananas FRUIT\n    tomatoes VEGETABLE\n\nThe custom labels are recognized, but why is \"London\" not recognized as \"GPE\"? How can I achieve it?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11nr3r2/identify_custom_labels_as_well_as_existing_labels/","created":"2023-03-10","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1},"text":"Identify custom labels as well as existing labels with Spacy v3 Hi all,\n\nI want to train a model with custom labels, and use it in combination with a pretrained model in Spacy v3.\n\nFor example for this code:\n\n    import spacy\n    import random\n    import json\n    \n    # Load the spaCy NLP model\n    nlp = spacy.load('en_core_web_lg')\n    \n    # Define the training data\n    train_data = [\n        ('These tomatoes are red and tasty.', {'entities': [(6, 14, 'VEGETABLE')]}),\n        ('I like red tomatoes.', {'entities': [(11, 19, 'VEGETABLE')]}),\n       \n        ('These bananas are very green.', {'entities': [(6, 13, 'FRUIT')]}),\n        ('Where are my bananas?', {'entities': [(13, 20, 'FRUIT')]}),\n        ('Are there any bananas near?', {'entities': [(14, 21, 'FRUIT')]}),    \n    ]\n    \n    # Define the new entity labels\n    new_labels = [\"FRUIT\", \"VEGETABLE\"]\n    \n    # Add the new labels to the existing entity recognizer\n    ner = nlp.get_pipe(\"ner\")\n    for label in new_labels:\n        ner.add_label(label)\n    \n    # Set up the optimizer\n    #optimizer = nlp.begin_training()\n    optimizer = nlp.initialize()\n    \n    # Iterate over the training data and update the model\n    for i in range(10):\n        random.shuffle(train_data)\n        for text, annotations in train_data:\n            doc = nlp.make_doc(text)\n            example = spacy.training.Example.from_dict(doc, annotations)\n            nlp.update([example], sgd=optimizer)\n    \n    # Test the model\n    text = \"\"\"What kind of color have bananas &amp; tomatoes in London?\"\"\"\n    doc = nlp(text)\n    for ent in doc.ents:\n        print(ent.text, ent.label_)\n\nThe output is:\n\n    bananas FRUIT\n    tomatoes VEGETABLE\n\nThe custom labels are recognized, but why is \"London\" not recognized as \"GPE\"? How can I achieve it?","classes":{"dataset":0.2274546623}}
{"title":"DACOS-A Manually Annotated Dataset of Code Smells","description":"Researchers apply machine-learning techniques for code smell detection to counter the subjectivity of many code smells. Such approaches need a large, manually annotated dataset for training and benchmarking. Existing literature offers a few datasets; however, they are small in size and, more importantly, do not focus on the subjective code snippets. In this paper, we present DACOS, a manually annotated dataset containing 10,267 annotations for 5,192 code snippets. The dataset targets three kinds of code smells at different granularity: multifaceted abstraction, complex method, and long parameter list. The dataset is created in two phases. The first phase helps us identify the code snippets that are potentially subjective by determining the thresholds of metrics used to detect a smell. The second phase collects annotations for potentially subjective snippets. We also offer an extended dataset DACOSX that includes definitely benign and definitely smelly snippets by using the thresholds identified in the first phase. We have developed TagMan, a web application to help annotators view and mark the snippets one-by-one and record the provided annotations. We make the datasets and the web application accessible publicly. This dataset will help researchers working on smell detection techniques to build relevant and context-aware machine-learning models.","link":"http://arxiv.org/abs/2303.08729v1","created":"2023-03-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"DACOS-A Manually Annotated Dataset of Code Smells Researchers apply machine-learning techniques for code smell detection to counter the subjectivity of many code smells. Such approaches need a large, manually annotated dataset for training and benchmarking. Existing literature offers a few datasets; however, they are small in size and, more importantly, do not focus on the subjective code snippets. In this paper, we present DACOS, a manually annotated dataset containing 10,267 annotations for 5,192 code snippets. The dataset targets three kinds of code smells at different granularity: multifaceted abstraction, complex method, and long parameter list. The dataset is created in two phases. The first phase helps us identify the code snippets that are potentially subjective by determining the thresholds of metrics used to detect a smell. The second phase collects annotations for potentially subjective snippets. We also offer an extended dataset DACOSX that includes definitely benign and definitely smelly snippets by using the thresholds identified in the first phase. We have developed TagMan, a web application to help annotators view and mark the snippets one-by-one and record the provided annotations. We make the datasets and the web application accessible publicly. This dataset will help researchers working on smell detection techniques to build relevant and context-aware machine-learning models.","classes":{"dataset":0.3891091347}}
{"title":"ZTBus: A Dataset of 1000+ Complete, Second-Resolved Driving Missions of Inner-City Transit Buses","description":"This paper presents the Zurich Transit Bus (ZTBus) dataset, which consists of recorded driving missions of electric city buses in Zurich, Switzerland. The data was collected over several years on two trolley buses as part of multiple research projects. It includes more than a thousand missions throughout all seasons, each usually covering a full day of real operation. The ZTBus dataset contains detailed information on the vehicle's power demand, propulsion system, odometry, global position, ambient temperature, door openings, number of passengers, dispatch patterns within the public transportation network, etc. All signals are synchronized in time and are provided with an absolute timestamp in tabular form. The dataset can be used as a foundation for a variety of studies and analyses. For example, the data can serve as a basis for simulations to estimate the performance of different public transit vehicle types, or to evaluate and optimize control strategies of hybrid electric vehicles. Furthermore, numerous influencing factors on vehicle operation, such as traffic, passenger volume, etc., can be analyzed in detail.","link":"http://arxiv.org/abs/2303.08667v1","created":"2023-03-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"ZTBus: A Dataset of 1000+ Complete, Second-Resolved Driving Missions of Inner-City Transit Buses This paper presents the Zurich Transit Bus (ZTBus) dataset, which consists of recorded driving missions of electric city buses in Zurich, Switzerland. The data was collected over several years on two trolley buses as part of multiple research projects. It includes more than a thousand missions throughout all seasons, each usually covering a full day of real operation. The ZTBus dataset contains detailed information on the vehicle's power demand, propulsion system, odometry, global position, ambient temperature, door openings, number of passengers, dispatch patterns within the public transportation network, etc. All signals are synchronized in time and are provided with an absolute timestamp in tabular form. The dataset can be used as a foundation for a variety of studies and analyses. For example, the data can serve as a basis for simulations to estimate the performance of different public transit vehicle types, or to evaluate and optimize control strategies of hybrid electric vehicles. Furthermore, numerous influencing factors on vehicle operation, such as traffic, passenger volume, etc., can be analyzed in detail.","classes":{"dataset":0.7319891453}}
{"title":"F-IVM: Analytics over Relational Databases under Updates","description":"This article describes F-IVM, a unified approach for maintaining analytics over changing relational data. We exemplify its versatility in four disciplines: processing queries with group-by aggregates and joins; learning linear regression models using the covariance matrix of the input features; building Chow-Liu trees using pairwise mutual information of the input features; and matrix chain multiplication.   F-IVM has three main ingredients: higher-order incremental view maintenance; factorized computation; and ring abstraction. F-IVM reduces the maintenance of a task to that of a hierarchy of simple views. Such views are functions mapping keys, which are tuples of input values, to payloads, which are elements from a ring. F-IVM also supports efficient factorized computation over keys, payloads, and updates. Finally, F-IVM treats uniformly seemingly disparate tasks. In the key space, all tasks require joins and variable marginalization. In the payload space, tasks differ in the definition of the sum and product ring operations.   We implemented F-IVM on top of DBToaster and show that it can outperform classical first-order and fully recursive higher-order incremental view maintenance by orders of magnitude while using less memory.","link":"http://arxiv.org/abs/2303.08583v1","created":"2023-03-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"F-IVM: Analytics over Relational Databases under Updates This article describes F-IVM, a unified approach for maintaining analytics over changing relational data. We exemplify its versatility in four disciplines: processing queries with group-by aggregates and joins; learning linear regression models using the covariance matrix of the input features; building Chow-Liu trees using pairwise mutual information of the input features; and matrix chain multiplication.   F-IVM has three main ingredients: higher-order incremental view maintenance; factorized computation; and ring abstraction. F-IVM reduces the maintenance of a task to that of a hierarchy of simple views. Such views are functions mapping keys, which are tuples of input values, to payloads, which are elements from a ring. F-IVM also supports efficient factorized computation over keys, payloads, and updates. Finally, F-IVM treats uniformly seemingly disparate tasks. In the key space, all tasks require joins and variable marginalization. In the payload space, tasks differ in the definition of the sum and product ring operations.   We implemented F-IVM on top of DBToaster and show that it can outperform classical first-order and fully recursive higher-order incremental view maintenance by orders of magnitude while using less memory.","classes":{"dataset":0.6085854769}}
{"title":"Dataset Management Platform for Machine Learning","description":"The quality of the data in a dataset can have a substantial impact on the performance of a machine learning model that is trained and/or evaluated using the dataset. Effective dataset management, including tasks such as data cleanup, versioning, access control, dataset transformation, automation, integrity and security, etc., can help improve the efficiency and speed of the machine learning process. Currently, engineers spend a substantial amount of manual effort and time to manage dataset versions or to prepare datasets for machine learning tasks. This disclosure describes a platform to manage and use datasets effectively. The techniques integrate dataset management and dataset transformation mechanisms. A storage engine is described that acts as a source of truth for all data and handles versioning, access control etc. The dataset transformation mechanism is a key part to generate a dataset (snapshot) to serve different purposes. The described techniques can support different workflows, pipelines, or data orchestration needs, e.g., for training and/or evaluation of machine learning models.","link":"http://arxiv.org/abs/2303.08301v1","created":"2023-03-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Dataset Management Platform for Machine Learning The quality of the data in a dataset can have a substantial impact on the performance of a machine learning model that is trained and/or evaluated using the dataset. Effective dataset management, including tasks such as data cleanup, versioning, access control, dataset transformation, automation, integrity and security, etc., can help improve the efficiency and speed of the machine learning process. Currently, engineers spend a substantial amount of manual effort and time to manage dataset versions or to prepare datasets for machine learning tasks. This disclosure describes a platform to manage and use datasets effectively. The techniques integrate dataset management and dataset transformation mechanisms. A storage engine is described that acts as a source of truth for all data and handles versioning, access control etc. The dataset transformation mechanism is a key part to generate a dataset (snapshot) to serve different purposes. The described techniques can support different workflows, pipelines, or data orchestration needs, e.g., for training and/or evaluation of machine learning models.","classes":{"dataset":0.0550370105}}
{"title":"Deep Learning for Iris Recognition: A Review","description":"Iris recognition is a secure biometric technology known for its stability and privacy. With no two irises being identical and little change throughout a person's lifetime, iris recognition is considered more reliable and less susceptible to external factors than other biometric recognition methods. Unlike traditional machine learning-based iris recognition methods, deep learning technology does not rely on feature engineering and boasts excellent performance. This paper collects 120 relevant papers to summarize the development of iris recognition based on deep learning. We first introduce the background of iris recognition and the motivation and contribution of this survey. Then, we present the common datasets widely used in iris recognition. After that, we summarize the key tasks involved in the process of iris recognition based on deep learning technology, including identification, segmentation, presentation attack detection, and localization. Finally, we discuss the challenges and potential development of iris recognition. This review provides a comprehensive sight of the research of iris recognition based on deep learning.","link":"http://arxiv.org/abs/2303.08514v1","created":"2023-03-15","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Deep Learning for Iris Recognition: A Review Iris recognition is a secure biometric technology known for its stability and privacy. With no two irises being identical and little change throughout a person's lifetime, iris recognition is considered more reliable and less susceptible to external factors than other biometric recognition methods. Unlike traditional machine learning-based iris recognition methods, deep learning technology does not rely on feature engineering and boasts excellent performance. This paper collects 120 relevant papers to summarize the development of iris recognition based on deep learning. We first introduce the background of iris recognition and the motivation and contribution of this survey. Then, we present the common datasets widely used in iris recognition. After that, we summarize the key tasks involved in the process of iris recognition based on deep learning technology, including identification, segmentation, presentation attack detection, and localization. Finally, we discuss the challenges and potential development of iris recognition. This review provides a comprehensive sight of the research of iris recognition based on deep learning.","classes":{"dataset":0.8945872188}}
{"title":"Efficient and Secure Federated Learning for Financial Applications","description":"The conventional machine learning (ML) and deep learning approaches need to share customers' sensitive information with an external credit bureau to generate a prediction model that opens the door to privacy leakage. This leakage risk makes financial companies face an enormous challenge in their cooperation. Federated learning is a machine learning setting that can protect data privacy, but the high communication cost is often the bottleneck of the federated systems, especially for large neural networks. Limiting the number and size of communications is necessary for the practical training of large neural structures. Gradient sparsification has received increasing attention as a method to reduce communication cost, which only updates significant gradients and accumulates insignificant gradients locally. However, the secure aggregation framework cannot directly use gradient sparsification. This article proposes two sparsification methods to reduce communication cost in federated learning. One is a time-varying hierarchical sparsification method for model parameter update, which solves the problem of maintaining model accuracy after high ratio sparsity. It can significantly reduce the cost of a single communication. The other is to apply the sparsification method to the secure aggregation framework. We sparse the encryption mask matrix to reduce the cost of communication while protecting privacy. Experiments show that under different Non-IID experiment settings, our method can reduce the upload communication cost to about 2.9% to 18.9% of the conventional federated learning algorithm when the sparse rate is 0.01.","link":"http://arxiv.org/abs/2303.08355v1","created":"2023-03-15","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Efficient and Secure Federated Learning for Financial Applications The conventional machine learning (ML) and deep learning approaches need to share customers' sensitive information with an external credit bureau to generate a prediction model that opens the door to privacy leakage. This leakage risk makes financial companies face an enormous challenge in their cooperation. Federated learning is a machine learning setting that can protect data privacy, but the high communication cost is often the bottleneck of the federated systems, especially for large neural networks. Limiting the number and size of communications is necessary for the practical training of large neural structures. Gradient sparsification has received increasing attention as a method to reduce communication cost, which only updates significant gradients and accumulates insignificant gradients locally. However, the secure aggregation framework cannot directly use gradient sparsification. This article proposes two sparsification methods to reduce communication cost in federated learning. One is a time-varying hierarchical sparsification method for model parameter update, which solves the problem of maintaining model accuracy after high ratio sparsity. It can significantly reduce the cost of a single communication. The other is to apply the sparsification method to the secure aggregation framework. We sparse the encryption mask matrix to reduce the cost of communication while protecting privacy. Experiments show that under different Non-IID experiment settings, our method can reduce the upload communication cost to about 2.9% to 18.9% of the conventional federated learning algorithm when the sparse rate is 0.01.","classes":{"dataset":0.123037383}}
{"title":"UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation","description":"Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization. We propose UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input. Specifically, we demonstrate universality in a cross-task and cross-model scenario: the retriever is tuned on a diverse set of tasks, but tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for tuning the retriever, but test the retriever on different LLMs of much larger scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that UPRISE mitigates the hallucination problem in our experiments with ChatGPT, suggesting its potential to improve even the strongest LLMs.","link":"http://arxiv.org/abs/2303.08518v1","created":"2023-03-15","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation Large Language Models (LLMs) are popular for their impressive abilities, but the need for model-specific fine-tuning or task-specific prompt engineering can hinder their generalization. We propose UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation), which tunes a lightweight and versatile retriever that automatically retrieves prompts for a given zero-shot task input. Specifically, we demonstrate universality in a cross-task and cross-model scenario: the retriever is tuned on a diverse set of tasks, but tested on unseen task types; we use a small frozen LLM, GPT-Neo-2.7B, for tuning the retriever, but test the retriever on different LLMs of much larger scales, such as BLOOM-7.1B, OPT-66B and GPT3-175B. Additionally, we show that UPRISE mitigates the hallucination problem in our experiments with ChatGPT, suggesting its potential to improve even the strongest LLMs.","classes":{"dataset":0.4949258566}}
{"title":"SpiderMesh: Spatial-aware Demand-guided Recursive Meshing for RGB-T Semantic Segmentation","description":"For semantic segmentation in urban scene understanding, RGB cameras alone often fail to capture a clear holistic topology, especially in challenging lighting conditions. Thermal signal is an informative additional channel that can bring to light the contour and fine-grained texture of blurred regions in low-quality RGB image. Aiming at RGB-T (thermal) segmentation, existing methods either use simple passive channel/spatial-wise fusion for cross-modal interaction, or rely on heavy labeling of ambiguous boundaries for fine-grained supervision. We propose a Spatial-aware Demand-guided Recursive Meshing (SpiderMesh) framework that: 1) proactively compensates inadequate contextual semantics in optically-impaired regions via a demand-guided target masking algorithm; 2) refines multimodal semantic features with recursive meshing to improve pixel-level semantic analysis performance. We further introduce an asymmetric data augmentation technique M-CutOut, and enable semi-supervised learning to fully utilize RGB-T labels only sparsely available in practical use. Extensive experiments on MFNet and PST900 datasets demonstrate that SpiderMesh achieves new state-of-the-art performance on standard RGB-T segmentation benchmarks.","link":"http://arxiv.org/abs/2303.08692v1","created":"2023-03-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"SpiderMesh: Spatial-aware Demand-guided Recursive Meshing for RGB-T Semantic Segmentation For semantic segmentation in urban scene understanding, RGB cameras alone often fail to capture a clear holistic topology, especially in challenging lighting conditions. Thermal signal is an informative additional channel that can bring to light the contour and fine-grained texture of blurred regions in low-quality RGB image. Aiming at RGB-T (thermal) segmentation, existing methods either use simple passive channel/spatial-wise fusion for cross-modal interaction, or rely on heavy labeling of ambiguous boundaries for fine-grained supervision. We propose a Spatial-aware Demand-guided Recursive Meshing (SpiderMesh) framework that: 1) proactively compensates inadequate contextual semantics in optically-impaired regions via a demand-guided target masking algorithm; 2) refines multimodal semantic features with recursive meshing to improve pixel-level semantic analysis performance. We further introduce an asymmetric data augmentation technique M-CutOut, and enable semi-supervised learning to fully utilize RGB-T labels only sparsely available in practical use. Extensive experiments on MFNet and PST900 datasets demonstrate that SpiderMesh achieves new state-of-the-art performance on standard RGB-T segmentation benchmarks.","classes":{"dataset":0.3394570947}}
{"title":"Enhancement of vortex liquid phase and reentrant behavior in NiBi3 single crystals","description":"We investigated the vortex phase diagram of needle shaped high quality NiBi3 single crystals by transport measurements. The current is applied along the crystalline b-axis of this intermetallic quasi-1D BCS superconductor. The single crystals show a Ginzburg-Levanchuk (Gi) parameter few orders of magnitude larger than other low Tc BCS superconductors. Vortex phase diagram, critical currents and pinning forces have been extracted from the experimental data. The main findings are: 1) Enhancement of the vortex liquid phase in comparison with low Tc superconductors, 2) reentrance of the liquid phase at low fields and 3) deviation of the pinning force vs field from the usual pinning mechanisms. The interplay between weak pinning, due to quenched disorder, and the quasi-1D character of the material could be a hint to explain the lack of a single pinning mechanism.","link":"http://arxiv.org/abs/2303.08592v1","created":"2023-03-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Enhancement of vortex liquid phase and reentrant behavior in NiBi3 single crystals We investigated the vortex phase diagram of needle shaped high quality NiBi3 single crystals by transport measurements. The current is applied along the crystalline b-axis of this intermetallic quasi-1D BCS superconductor. The single crystals show a Ginzburg-Levanchuk (Gi) parameter few orders of magnitude larger than other low Tc BCS superconductors. Vortex phase diagram, critical currents and pinning forces have been extracted from the experimental data. The main findings are: 1) Enhancement of the vortex liquid phase in comparison with low Tc superconductors, 2) reentrance of the liquid phase at low fields and 3) deviation of the pinning force vs field from the usual pinning mechanisms. The interplay between weak pinning, due to quenched disorder, and the quasi-1D character of the material could be a hint to explain the lack of a single pinning mechanism.","classes":{"dataset":0.070610635}}
{"title":"Mapping Urban Population Growth from Sentinel-2 MSI and Census Data Using Deep Learning: A Case Study in Kigali, Rwanda","description":"To better understand current trends of urban population growth in Sub-Saharan Africa, high-quality spatiotemporal population estimates are necessary. While the joint use of remote sensing and deep learning has achieved promising results for population distribution estimation, most of the current work focuses on fine-scale spatial predictions derived from single date census, thereby neglecting temporal analyses. In this work, we focus on evaluating how deep learning change detection techniques can unravel temporal population dynamics at short intervals. Since Post-Classification Comparison (PCC) methods for change detection are known to propagate the error of the individual maps, we propose an end-to-end population growth mapping method. Specifically, a ResNet encoder, pretrained on a population mapping task with Sentinel-2 MSI data, was incorporated into a Siamese network. The Siamese network was trained at the census level to accurately predict population change. The effectiveness of the proposed method is demonstrated in Kigali, Rwanda, for the time period 2016-2020, using bi-temporal Sentinel-2 data. Compared to PCC, the Siamese network greatly reduced errors in population change predictions at the census level. These results show promise for future remote sensing-based population growth mapping endeavors.","link":"http://arxiv.org/abs/2303.08511v1","created":"2023-03-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Mapping Urban Population Growth from Sentinel-2 MSI and Census Data Using Deep Learning: A Case Study in Kigali, Rwanda To better understand current trends of urban population growth in Sub-Saharan Africa, high-quality spatiotemporal population estimates are necessary. While the joint use of remote sensing and deep learning has achieved promising results for population distribution estimation, most of the current work focuses on fine-scale spatial predictions derived from single date census, thereby neglecting temporal analyses. In this work, we focus on evaluating how deep learning change detection techniques can unravel temporal population dynamics at short intervals. Since Post-Classification Comparison (PCC) methods for change detection are known to propagate the error of the individual maps, we propose an end-to-end population growth mapping method. Specifically, a ResNet encoder, pretrained on a population mapping task with Sentinel-2 MSI data, was incorporated into a Siamese network. The Siamese network was trained at the census level to accurately predict population change. The effectiveness of the proposed method is demonstrated in Kigali, Rwanda, for the time period 2016-2020, using bi-temporal Sentinel-2 data. Compared to PCC, the Siamese network greatly reduced errors in population change predictions at the census level. These results show promise for future remote sensing-based population growth mapping endeavors.","classes":{"dataset":0.0361914858}}
{"title":"Towards Cooperative Federated Learning over Heterogeneous Edge/Fog Networks","description":"Federated learning (FL) has been promoted as a popular technique for training machine learning (ML) models over edge/fog networks. Traditional implementations of FL have largely neglected the potential for inter-network cooperation, treating edge/fog devices and other infrastructure participating in ML as separate processing elements. Consequently, FL has been vulnerable to several dimensions of network heterogeneity, such as varying computation capabilities, communication resources, data qualities, and privacy demands. We advocate for cooperative federated learning (CFL), a cooperative edge/fog ML paradigm built on device-to-device (D2D) and device-to-server (D2S) interactions. Through D2D and D2S cooperation, CFL counteracts network heterogeneity in edge/fog networks through enabling a model/data/resource pooling mechanism, which will yield substantial improvements in ML model training quality and network resource consumption. We propose a set of core methodologies that form the foundation of D2D and D2S cooperation and present preliminary experiments that demonstrate their benefits. We also discuss new FL functionalities enabled by this cooperative framework such as the integration of unlabeled data and heterogeneous device privacy into ML model training. Finally, we describe some open research directions at the intersection of cooperative edge/fog and FL.","link":"http://arxiv.org/abs/2303.08361v1","created":"2023-03-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Towards Cooperative Federated Learning over Heterogeneous Edge/Fog Networks Federated learning (FL) has been promoted as a popular technique for training machine learning (ML) models over edge/fog networks. Traditional implementations of FL have largely neglected the potential for inter-network cooperation, treating edge/fog devices and other infrastructure participating in ML as separate processing elements. Consequently, FL has been vulnerable to several dimensions of network heterogeneity, such as varying computation capabilities, communication resources, data qualities, and privacy demands. We advocate for cooperative federated learning (CFL), a cooperative edge/fog ML paradigm built on device-to-device (D2D) and device-to-server (D2S) interactions. Through D2D and D2S cooperation, CFL counteracts network heterogeneity in edge/fog networks through enabling a model/data/resource pooling mechanism, which will yield substantial improvements in ML model training quality and network resource consumption. We propose a set of core methodologies that form the foundation of D2D and D2S cooperation and present preliminary experiments that demonstrate their benefits. We also discuss new FL functionalities enabled by this cooperative framework such as the integration of unlabeled data and heterogeneous device privacy into ML model training. Finally, we describe some open research directions at the intersection of cooperative edge/fog and FL.","classes":{"dataset":0.1200745255}}
{"title":"Progressive Frame Patching for FoV-based Point Cloud Video Streaming","description":"Immersive multimedia applications, such as Virtual, Augmented and Mixed Reality, have become more practical with advances in hardware and software for acquiring and rendering 3D media as well as 5G/6G wireless networks. Such applications require the delivery of volumetric video to users with six degrees of freedom (6-DoF) movements. Point Cloud has become a popular volumetric video format due to its flexibility and simplicity. A dense point cloud consumes much higher bandwidth than a 2D/360 degree video frame. User Field of View (FoV) is more dynamic with 6-DoF movement than 3-DoF movement. A user's view quality of a 3D object is affected by points occlusion and distance, which are constantly changing with user and object movements. To save bandwidth, FoV-adaptive streaming predicts user FoV and only downloads the data falling in the predicted FoV, but it is vulnerable to FoV prediction errors, which is significant when a long buffer is used for smoothed streaming. In this work, we propose a multi-round progressive refinement framework for point cloud-based volumetric video streaming. Instead of sequentially downloading frames, we simultaneously downloads/patches multiple frames falling into a sliding time-window, leveraging on the scalability of point-cloud coding. The rate allocation among all tiles of active frames are solved analytically using the heterogeneous tile utility functions calibrated by the predicted user FoV. Multi-frame patching takes advantage of the streaming smoothness resulted from long buffer and the FoV prediction accuracy at short buffer length. We evaluate our solution using simulations driven by real point cloud videos, bandwidth traces and 6-DoF FoV traces of real users. The experiments show that our solution is robust against bandwidth/FoV prediction errors, and can deliver high and smooth quality in the face of bandwidth variations and dynamic user movements.","link":"http://arxiv.org/abs/2303.08336v1","created":"2023-03-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Progressive Frame Patching for FoV-based Point Cloud Video Streaming Immersive multimedia applications, such as Virtual, Augmented and Mixed Reality, have become more practical with advances in hardware and software for acquiring and rendering 3D media as well as 5G/6G wireless networks. Such applications require the delivery of volumetric video to users with six degrees of freedom (6-DoF) movements. Point Cloud has become a popular volumetric video format due to its flexibility and simplicity. A dense point cloud consumes much higher bandwidth than a 2D/360 degree video frame. User Field of View (FoV) is more dynamic with 6-DoF movement than 3-DoF movement. A user's view quality of a 3D object is affected by points occlusion and distance, which are constantly changing with user and object movements. To save bandwidth, FoV-adaptive streaming predicts user FoV and only downloads the data falling in the predicted FoV, but it is vulnerable to FoV prediction errors, which is significant when a long buffer is used for smoothed streaming. In this work, we propose a multi-round progressive refinement framework for point cloud-based volumetric video streaming. Instead of sequentially downloading frames, we simultaneously downloads/patches multiple frames falling into a sliding time-window, leveraging on the scalability of point-cloud coding. The rate allocation among all tiles of active frames are solved analytically using the heterogeneous tile utility functions calibrated by the predicted user FoV. Multi-frame patching takes advantage of the streaming smoothness resulted from long buffer and the FoV prediction accuracy at short buffer length. We evaluate our solution using simulations driven by real point cloud videos, bandwidth traces and 6-DoF FoV traces of real users. The experiments show that our solution is robust against bandwidth/FoV prediction errors, and can deliver high and smooth quality in the face of bandwidth variations and dynamic user movements.","classes":{"dataset":0.2123641521}}
{"title":"Towards High-Quality and Efficient Video Super-Resolution via Spatial-Temporal Data Overfitting","description":"As deep convolutional neural networks (DNNs) are widely used in various fields of computer vision, leveraging the overfitting ability of the DNN to achieve video resolution upscaling has become a new trend in the modern video delivery system. By dividing videos into chunks and overfitting each chunk with a super-resolution model, the server encodes videos before transmitting them to the clients, thus achieving better video quality and transmission efficiency. However, a large number of chunks are expected to ensure good overfitting quality, which substantially increases the storage and consumes more bandwidth resources for data transmission. On the other hand, decreasing the number of chunks through training optimization techniques usually requires high model capacity, which significantly slows down execution speed. To reconcile such, we propose a novel method for high-quality and efficient video resolution upscaling tasks, which leverages the spatial-temporal information to accurately divide video into chunks, thus keeping the number of chunks as well as the model size to minimum. Additionally, we advance our method into a single overfitting model by a data-aware joint training technique, which further reduces the storage requirement with negligible quality drop. We deploy our models on an off-the-shelf mobile phone, and experimental results show that our method achieves real-time video super-resolution with high video quality. Compared with the state-of-the-art, our method achieves 28 fps streaming speed with 41.6 PSNR, which is 14$\\times$ faster and 2.29 dB better in the live video resolution upscaling tasks. Our codes are available at: https://github.com/coulsonlee/STDO-CVPR2023.git","link":"http://arxiv.org/abs/2303.08331v1","created":"2023-03-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Towards High-Quality and Efficient Video Super-Resolution via Spatial-Temporal Data Overfitting As deep convolutional neural networks (DNNs) are widely used in various fields of computer vision, leveraging the overfitting ability of the DNN to achieve video resolution upscaling has become a new trend in the modern video delivery system. By dividing videos into chunks and overfitting each chunk with a super-resolution model, the server encodes videos before transmitting them to the clients, thus achieving better video quality and transmission efficiency. However, a large number of chunks are expected to ensure good overfitting quality, which substantially increases the storage and consumes more bandwidth resources for data transmission. On the other hand, decreasing the number of chunks through training optimization techniques usually requires high model capacity, which significantly slows down execution speed. To reconcile such, we propose a novel method for high-quality and efficient video resolution upscaling tasks, which leverages the spatial-temporal information to accurately divide video into chunks, thus keeping the number of chunks as well as the model size to minimum. Additionally, we advance our method into a single overfitting model by a data-aware joint training technique, which further reduces the storage requirement with negligible quality drop. We deploy our models on an off-the-shelf mobile phone, and experimental results show that our method achieves real-time video super-resolution with high video quality. Compared with the state-of-the-art, our method achieves 28 fps streaming speed with 41.6 PSNR, which is 14$\\times$ faster and 2.29 dB better in the live video resolution upscaling tasks. Our codes are available at: https://github.com/coulsonlee/STDO-CVPR2023.git","classes":{"dataset":0.0785908997}}
{"title":"Dataset Management Platform for Machine Learning","description":"The quality of the data in a dataset can have a substantial impact on the performance of a machine learning model that is trained and/or evaluated using the dataset. Effective dataset management, including tasks such as data cleanup, versioning, access control, dataset transformation, automation, integrity and security, etc., can help improve the efficiency and speed of the machine learning process. Currently, engineers spend a substantial amount of manual effort and time to manage dataset versions or to prepare datasets for machine learning tasks. This disclosure describes a platform to manage and use datasets effectively. The techniques integrate dataset management and dataset transformation mechanisms. A storage engine is described that acts as a source of truth for all data and handles versioning, access control etc. The dataset transformation mechanism is a key part to generate a dataset (snapshot) to serve different purposes. The described techniques can support different workflows, pipelines, or data orchestration needs, e.g., for training and/or evaluation of machine learning models.","link":"http://arxiv.org/abs/2303.08301v1","created":"2023-03-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Dataset Management Platform for Machine Learning The quality of the data in a dataset can have a substantial impact on the performance of a machine learning model that is trained and/or evaluated using the dataset. Effective dataset management, including tasks such as data cleanup, versioning, access control, dataset transformation, automation, integrity and security, etc., can help improve the efficiency and speed of the machine learning process. Currently, engineers spend a substantial amount of manual effort and time to manage dataset versions or to prepare datasets for machine learning tasks. This disclosure describes a platform to manage and use datasets effectively. The techniques integrate dataset management and dataset transformation mechanisms. A storage engine is described that acts as a source of truth for all data and handles versioning, access control etc. The dataset transformation mechanism is a key part to generate a dataset (snapshot) to serve different purposes. The described techniques can support different workflows, pipelines, or data orchestration needs, e.g., for training and/or evaluation of machine learning models.","classes":{"dataset":0.2809238434}}
{"title":"Linking Alternative Fuel Vehicles Adoption with Socioeconomic Status and Air Quality Index","description":"This is a study on the potential widespread usage of alternative fuel vehicles, linking them with the socio-economic status of the respective consumers as well as the impact on the resulting air quality index. Research in this area aims to leverage machine learning techniques in order to promote appropriate policies for the proliferation of alternative fuel vehicles such as electric vehicles with due justice to different population groups. Pearson correlation coefficient is deployed in the modeling the relationships between socio-economic data, air quality index and data on alternative fuel vehicles. Linear regression is used to conduct predictive modeling on air quality index as per the adoption of alternative fuel vehicles, based on socio-economic factors. This work exemplifies artificial intelligence for social good.","link":"http://arxiv.org/abs/2303.08286v1","created":"2023-03-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Linking Alternative Fuel Vehicles Adoption with Socioeconomic Status and Air Quality Index This is a study on the potential widespread usage of alternative fuel vehicles, linking them with the socio-economic status of the respective consumers as well as the impact on the resulting air quality index. Research in this area aims to leverage machine learning techniques in order to promote appropriate policies for the proliferation of alternative fuel vehicles such as electric vehicles with due justice to different population groups. Pearson correlation coefficient is deployed in the modeling the relationships between socio-economic data, air quality index and data on alternative fuel vehicles. Linear regression is used to conduct predictive modeling on air quality index as per the adoption of alternative fuel vehicles, based on socio-economic factors. This work exemplifies artificial intelligence for social good.","classes":{"dataset":0.1582373828}}
{"title":"How did Dennis Ritchie produce his PhD thesis? A typographical mystery (2022) [pdf]","description":"https://www.cs.princeton.edu/~bwk/dmr/doceng22.pdf","link":"https://www.cs.princeton.edu/~bwk/dmr/doceng22.pdf","created":"2023-03-16","tags":["hackernews"],"meta":{"score":290},"text":"How did Dennis Ritchie produce his PhD thesis? A typographical mystery (2022) [pdf] https://www.cs.princeton.edu/~bwk/dmr/doceng22.pdf","classes":{"dataset":0.7134864926}}
{"title":"Venus is volcanically alive, new find shows","description":"https://www.nationalgeographic.com/science/article/venus-is-volcanically-alive","link":"https://www.nationalgeographic.com/science/article/venus-is-volcanically-alive","created":"2023-03-16","tags":["hackernews"],"meta":{"score":112},"text":"Venus is volcanically alive, new find shows https://www.nationalgeographic.com/science/article/venus-is-volcanically-alive","classes":{"dataset":0.507349968}}
{"title":"'Financial Times' Issues 103-Year-Old Correction (2017)","description":"https://www.npr.org/sections/thetwo-way/2017/08/08/542238978/-financial-times-issues-103-year-old-correction","link":"https://www.npr.org/sections/thetwo-way/2017/08/08/542238978/-financial-times-issues-103-year-old-correction","created":"2023-03-15","tags":["hackernews"],"meta":{"score":182},"text":"'Financial Times' Issues 103-Year-Old Correction (2017) https://www.npr.org/sections/thetwo-way/2017/08/08/542238978/-financial-times-issues-103-year-old-correction","classes":{"dataset":0.4920276999}}
{"title":"Math and Motion: A Look at Chebyshev\u2019s Works on Linkages","description":"https://bhavana.org.in/math-and-motion-a-look-at-chebyshevs-works-on-linkages/","link":"https://bhavana.org.in/math-and-motion-a-look-at-chebyshevs-works-on-linkages/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":19},"text":"Math and Motion: A Look at Chebyshev\u2019s Works on Linkages https://bhavana.org.in/math-and-motion-a-look-at-chebyshevs-works-on-linkages/","classes":{"dataset":0.5189879537}}
{"title":"Last night I read for the first time the company\u2019s 8k announcing my resignation","description":"https://www.linkedin.com/posts/xiaodihou_last-night-i-read-for-the-first-time-the-activity-7041526468257992705-4BFy","link":"https://www.linkedin.com/posts/xiaodihou_last-night-i-read-for-the-first-time-the-activity-7041526468257992705-4BFy","created":"2023-03-16","tags":["hackernews"],"meta":{"score":58},"text":"Last night I read for the first time the company\u2019s 8k announcing my resignation https://www.linkedin.com/posts/xiaodihou_last-night-i-read-for-the-first-time-the-activity-7041526468257992705-4BFy","classes":{"dataset":0.5317877531}}
{"title":"Functional Geometry with Gambit Scheme and Raylib","description":"https://github.com/georgjz/functional-geometry-gambit-scheme","link":"https://github.com/georgjz/functional-geometry-gambit-scheme","created":"2023-03-14","tags":["hackernews"],"meta":{"score":72},"text":"Functional Geometry with Gambit Scheme and Raylib https://github.com/georgjz/functional-geometry-gambit-scheme","classes":{"dataset":0.5305198431}}
{"title":"History\u2019s Fool: The long century of Ernst J\u00fcnger","description":"https://harpers.org/archive/2023/03/historys-fool-ernst-junger/","link":"https://harpers.org/archive/2023/03/historys-fool-ernst-junger/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":15},"text":"History\u2019s Fool: The long century of Ernst J\u00fcnger https://harpers.org/archive/2023/03/historys-fool-ernst-junger/","classes":{"dataset":0.5218389034}}
{"title":"Docker is deleting Open Source organisations - what you need to know","description":"https://blog.alexellis.io/docker-is-deleting-open-source-images/","link":"https://blog.alexellis.io/docker-is-deleting-open-source-images/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":1388},"text":"Docker is deleting Open Source organisations - what you need to know https://blog.alexellis.io/docker-is-deleting-open-source-images/","classes":{"dataset":0.5031363964}}
{"title":"Guide to Java Virtual Threads","description":"https://blog.rockthejvm.com/ultimate-guide-to-java-virtual-threads/","link":"https://blog.rockthejvm.com/ultimate-guide-to-java-virtual-threads/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":118},"text":"Guide to Java Virtual Threads https://blog.rockthejvm.com/ultimate-guide-to-java-virtual-threads/","classes":{"dataset":0.5354053378}}
{"title":"DreamWorks releases OpenMoonRay source code","description":"https://github.com/dreamworksanimation/openmoonray","link":"https://github.com/dreamworksanimation/openmoonray","created":"2023-03-15","tags":["hackernews"],"meta":{"score":651},"text":"DreamWorks releases OpenMoonRay source code https://github.com/dreamworksanimation/openmoonray","classes":{"dataset":0.5207329392}}
{"title":"Chat GPT4: Is the world prepared for the coming AI storm?","description":"https://www.bbc.co.uk/news/world-us-canada-64967627","link":"https://www.bbc.co.uk/news/world-us-canada-64967627","created":"2023-03-16","tags":["hackernews"],"meta":{"score":18},"text":"Chat GPT4: Is the world prepared for the coming AI storm? https://www.bbc.co.uk/news/world-us-canada-64967627","classes":{"dataset":0.5275534391}}
{"title":"PCIe for Hackers: The Diffpair Prelude","description":"https://hackaday.com/2023/03/14/pcie-for-hackers-the-diffpair-prelude/","link":"https://hackaday.com/2023/03/14/pcie-for-hackers-the-diffpair-prelude/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":4},"text":"PCIe for Hackers: The Diffpair Prelude https://hackaday.com/2023/03/14/pcie-for-hackers-the-diffpair-prelude/","classes":{"dataset":0.5192463994}}
{"title":"Will AIs take all our jobs and end human history? It\u2019s complicated","description":"https://writings.stephenwolfram.com/2023/03/will-ais-take-all-our-jobs-and-end-human-history-or-not-well-its-complicated/","link":"https://writings.stephenwolfram.com/2023/03/will-ais-take-all-our-jobs-and-end-human-history-or-not-well-its-complicated/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":116},"text":"Will AIs take all our jobs and end human history? It\u2019s complicated https://writings.stephenwolfram.com/2023/03/will-ais-take-all-our-jobs-and-end-human-history-or-not-well-its-complicated/","classes":{"dataset":0.5000044703}}
{"title":"Why Barney Frank went to work for Signature Bank","description":"https://www.newyorker.com/news/q-and-a/why-barney-frank-went-to-work-for-signature-bank","link":"https://www.newyorker.com/news/q-and-a/why-barney-frank-went-to-work-for-signature-bank","created":"2023-03-16","tags":["hackernews"],"meta":{"score":60},"text":"Why Barney Frank went to work for Signature Bank https://www.newyorker.com/news/q-and-a/why-barney-frank-went-to-work-for-signature-bank","classes":{"dataset":0.5179005861}}
{"title":"Credit Suisse sheds nearly 25%, key backer says no more money","description":"https://www.reuters.com/business/finance/credit-suisse-shares-drop-fresh-record-low-cds-widen-2023-03-15/","link":"https://www.reuters.com/business/finance/credit-suisse-shares-drop-fresh-record-low-cds-widen-2023-03-15/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":395},"text":"Credit Suisse sheds nearly 25%, key backer says no more money https://www.reuters.com/business/finance/credit-suisse-shares-drop-fresh-record-low-cds-widen-2023-03-15/","classes":{"dataset":0.4978869259}}
{"title":"Court of Versailles vs. the Wild West","description":"https://www.asleepthinking.com/blog/court-of-versailles-vs-the-wild-west","link":"https://www.asleepthinking.com/blog/court-of-versailles-vs-the-wild-west","created":"2023-03-16","tags":["hackernews"],"meta":{"score":8},"text":"Court of Versailles vs. the Wild West https://www.asleepthinking.com/blog/court-of-versailles-vs-the-wild-west","classes":{"dataset":0.507349968}}
{"title":"Apple: Whistleblower about Working Conditions","description":"https://twitter.com/ashleygjovik/status/1635688047005118480","link":"https://twitter.com/ashleygjovik/status/1635688047005118480","created":"2023-03-16","tags":["hackernews"],"meta":{"score":47},"text":"Apple: Whistleblower about Working Conditions https://twitter.com/ashleygjovik/status/1635688047005118480","classes":{"dataset":0.4878437519}}
{"title":"Ratatui: tui-rs revival project","description":"https://github.com/tui-rs-revival/ratatui","link":"https://github.com/tui-rs-revival/ratatui","created":"2023-03-15","tags":["hackernews"],"meta":{"score":117},"text":"Ratatui: tui-rs revival project https://github.com/tui-rs-revival/ratatui","classes":{"dataset":0.5588033199}}
{"title":"Emulating Pokemon Emerald on GPT-4","description":"https://twitter.com/dandangond/status/1636063902688526339","link":"https://twitter.com/dandangond/status/1636063902688526339","created":"2023-03-15","tags":["hackernews"],"meta":{"score":171},"text":"Emulating Pokemon Emerald on GPT-4 https://twitter.com/dandangond/status/1636063902688526339","classes":{"dataset":0.4939953387}}
{"title":"Kottke.org is 25 years old today","description":"https://kottke.org/23/03/kottke-is-25-years-old-today","link":"https://kottke.org/23/03/kottke-is-25-years-old-today","created":"2023-03-15","tags":["hackernews"],"meta":{"score":452},"text":"Kottke.org is 25 years old today https://kottke.org/23/03/kottke-is-25-years-old-today","classes":{"dataset":0.4804680049}}
{"title":"Reverse-engineering the multiplication algorithm in the Intel 8086 processor","description":"https://www.righto.com/2023/03/8086-multiplication-microcode.html","link":"https://www.righto.com/2023/03/8086-multiplication-microcode.html","created":"2023-03-15","tags":["hackernews"],"meta":{"score":161},"text":"Reverse-engineering the multiplication algorithm in the Intel 8086 processor https://www.righto.com/2023/03/8086-multiplication-microcode.html","classes":{"dataset":0.5048617125}}
{"title":"Scaling Kubernetes to 7,500 nodes (2021)","description":"https://openai.com/research/scaling-kubernetes-to-7500-nodes","link":"https://openai.com/research/scaling-kubernetes-to-7500-nodes","created":"2023-03-15","tags":["hackernews"],"meta":{"score":77},"text":"Scaling Kubernetes to 7,500 nodes (2021) https://openai.com/research/scaling-kubernetes-to-7500-nodes","classes":{"dataset":0.5445875525}}
{"title":"GPT-4 Designed a Programming Language","description":"https://lukebechtel.com/blog/gpt4-generating-code","link":"https://lukebechtel.com/blog/gpt4-generating-code","created":"2023-03-16","tags":["hackernews"],"meta":{"score":196},"text":"GPT-4 Designed a Programming Language https://lukebechtel.com/blog/gpt4-generating-code","classes":{"dataset":0.509939909}}
{"title":"Best printer 2023: just buy this Brother laser printer everyone has, it\u2019s fine","description":"https://www.theverge.com/23642073/best-printer-2023-brother-laser-wi-fi-its-fine","link":"https://www.theverge.com/23642073/best-printer-2023-brother-laser-wi-fi-its-fine","created":"2023-03-16","tags":["hackernews"],"meta":{"score":78},"text":"Best printer 2023: just buy this Brother laser printer everyone has, it\u2019s fine https://www.theverge.com/23642073/best-printer-2023-brother-laser-wi-fi-its-fine","classes":{"dataset":0.5411446691}}
{"title":"'We conclude' or 'I believe'? Rationality declined decades ago","description":"https://www.eurekalert.org/news-releases/940009","link":"https://www.eurekalert.org/news-releases/940009","created":"2023-03-16","tags":["hackernews"],"meta":{"score":52},"text":"'We conclude' or 'I believe'? Rationality declined decades ago https://www.eurekalert.org/news-releases/940009","classes":{"dataset":0.4993168414}}
{"title":"Generative AI is overrated, long live old-school AI","description":"https://encord.com/blog/generative-ai-and-gpt4-is-overrated-long-live-old-school-ai/","link":"https://encord.com/blog/generative-ai-and-gpt4-is-overrated-long-live-old-school-ai/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":214},"text":"Generative AI is overrated, long live old-school AI https://encord.com/blog/generative-ai-and-gpt4-is-overrated-long-live-old-school-ai/","classes":{"dataset":0.4981521964}}
{"title":"My startup banking story","description":"https://mitchellh.com/writing/my-startup-banking-story","link":"https://mitchellh.com/writing/my-startup-banking-story","created":"2023-03-14","tags":["hackernews"],"meta":{"score":585},"text":"My startup banking story https://mitchellh.com/writing/my-startup-banking-story","classes":{"dataset":0.5003764629}}
{"title":"I gave GPT-4 a budget of $100 and told it to make as much money as possible","description":"https://twitter.com/jacksonfall/status/1636107218859745286","link":"https://twitter.com/jacksonfall/status/1636107218859745286","created":"2023-03-15","tags":["hackernews"],"meta":{"score":113},"text":"I gave GPT-4 a budget of $100 and told it to make as much money as possible https://twitter.com/jacksonfall/status/1636107218859745286","classes":{"dataset":0.4945097268}}
{"title":"An Uber-like CDN","description":"https://medium.com/@anton.lakhtikov/uber-like-model-to-disrupt-the-cdn-industry-8d870362f0f6","link":"https://medium.com/@anton.lakhtikov/uber-like-model-to-disrupt-the-cdn-industry-8d870362f0f6","created":"2023-03-15","tags":["hackernews"],"meta":{"score":101},"text":"An Uber-like CDN https://medium.com/@anton.lakhtikov/uber-like-model-to-disrupt-the-cdn-industry-8d870362f0f6","classes":{"dataset":0.4714652002}}
{"title":"How Silicon Valley Bank Avoided Oversight","description":"https://www.wsj.com/articles/how-silicon-valley-bank-avoided-oversight-fdic-systemic-risk-midsize-greg-becker-dodd-frank-reporting-lobbying-5b3ff837","link":"https://www.wsj.com/articles/how-silicon-valley-bank-avoided-oversight-fdic-systemic-risk-midsize-greg-becker-dodd-frank-reporting-lobbying-5b3ff837","created":"2023-03-15","tags":["hackernews"],"meta":{"score":104},"text":"How Silicon Valley Bank Avoided Oversight https://www.wsj.com/articles/how-silicon-valley-bank-avoided-oversight-fdic-systemic-risk-midsize-greg-becker-dodd-frank-reporting-lobbying-5b3ff837","classes":{"dataset":0.5001443028}}
{"title":"Python-based compiler achieves orders-of-magnitude speedups","description":"https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314","link":"https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314","created":"2023-03-15","tags":["hackernews"],"meta":{"score":225},"text":"Python-based compiler achieves orders-of-magnitude speedups https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314","classes":{"dataset":0.5360488892}}
{"title":"Banking in uncertain times","description":"https://www.bitsaboutmoney.com/archive/banking-in-very-uncertain-times/","link":"https://www.bitsaboutmoney.com/archive/banking-in-very-uncertain-times/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":354},"text":"Banking in uncertain times https://www.bitsaboutmoney.com/archive/banking-in-very-uncertain-times/","classes":{"dataset":0.4579589367}}
{"title":"Suing to protect right of incarcerated people to receive physical mail","description":"https://www.eff.org/deeplinks/2023/03/why-were-suing-protect-right-incarcerated-people-receive-physical-mail","link":"https://www.eff.org/deeplinks/2023/03/why-were-suing-protect-right-incarcerated-people-receive-physical-mail","created":"2023-03-15","tags":["hackernews"],"meta":{"score":363},"text":"Suing to protect right of incarcerated people to receive physical mail https://www.eff.org/deeplinks/2023/03/why-were-suing-protect-right-incarcerated-people-receive-physical-mail","classes":{"dataset":0.5500702858}}
{"title":"Jim Blinn and Ed Catmull \u2013 graphics class at Berkeley (1981)","description":"https://www.youtube.com/@cgtimemachine1257/videos","link":"https://www.youtube.com/@cgtimemachine1257/videos","created":"2023-03-14","tags":["hackernews"],"meta":{"score":97},"text":"Jim Blinn and Ed Catmull \u2013 graphics class at Berkeley (1981) https://www.youtube.com/@cgtimemachine1257/videos","classes":{"dataset":0.4827866852}}
{"title":"Motion Canvas \u2013 Visualize complex ideas programmatically","description":"https://motioncanvas.io/","link":"https://motioncanvas.io/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":25},"text":"Motion Canvas \u2013 Visualize complex ideas programmatically https://motioncanvas.io/","classes":{"dataset":0.5324548483}}
{"title":"Germany Will Move Forward with Marijuana Legalization","description":"https://www.marijuanamoment.net/germany-will-move-forward-with-marijuana-legalization-after-receiving-very-good-feedback-from-eu-top-official-says/","link":"https://www.marijuanamoment.net/germany-will-move-forward-with-marijuana-legalization-after-receiving-very-good-feedback-from-eu-top-official-says/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":88},"text":"Germany Will Move Forward with Marijuana Legalization https://www.marijuanamoment.net/germany-will-move-forward-with-marijuana-legalization-after-receiving-very-good-feedback-from-eu-top-official-says/","classes":{"dataset":0.5587649345}}
{"title":"A Master of a Curious Midcentury Art Form, the Industrial Musical","description":"https://www.texasmonthly.com/being-texan/texan-master-industrial-musicals-michael-brown-mexia/","link":"https://www.texasmonthly.com/being-texan/texan-master-industrial-musicals-michael-brown-mexia/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":16},"text":"A Master of a Curious Midcentury Art Form, the Industrial Musical https://www.texasmonthly.com/being-texan/texan-master-industrial-musicals-michael-brown-mexia/","classes":{"dataset":0.4925076067}}
{"title":"Pyroscope and Grafana Phlare join together","description":"https://grafana.com/blog/2023/03/15/pyroscope-grafana-phlare-join-for-oss-continuous-profiling/","link":"https://grafana.com/blog/2023/03/15/pyroscope-grafana-phlare-join-for-oss-continuous-profiling/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":182},"text":"Pyroscope and Grafana Phlare join together https://grafana.com/blog/2023/03/15/pyroscope-grafana-phlare-join-for-oss-continuous-profiling/","classes":{"dataset":0.4226770997}}
{"title":"Llama.rs \u2013 Rust port of llama.cpp for fast LLaMA inference on CPU","description":"https://github.com/setzer22/llama-rs","link":"https://github.com/setzer22/llama-rs","created":"2023-03-15","tags":["hackernews"],"meta":{"score":187},"text":"Llama.rs \u2013 Rust port of llama.cpp for fast LLaMA inference on CPU https://github.com/setzer22/llama-rs","classes":{"dataset":0.5006350279}}
{"title":"Alpaca: A strong open-source instruction-following model","description":"https://crfm.stanford.edu/2023/03/13/alpaca.html","link":"https://crfm.stanford.edu/2023/03/13/alpaca.html","created":"2023-03-13","tags":["hackernews"],"meta":{"score":684},"text":"Alpaca: A strong open-source instruction-following model https://crfm.stanford.edu/2023/03/13/alpaca.html","classes":{"dataset":0.5520507693}}
{"title":"FibJS: Based on V8, uses fibers instead of async","description":"https://fibjs.org/en/docs/guide/about.md.html","link":"https://fibjs.org/en/docs/guide/about.md.html","created":"2023-03-15","tags":["hackernews"],"meta":{"score":18},"text":"FibJS: Based on V8, uses fibers instead of async https://fibjs.org/en/docs/guide/about.md.html","classes":{"dataset":0.5224055648}}
{"title":"Searching for friends in Mark Zuckerberg\u2019s deserted fantasyland","description":"https://nymag.com/intelligencer/article/mark-zuckerberg-metaverse-meta-horizon-worlds.html","link":"https://nymag.com/intelligencer/article/mark-zuckerberg-metaverse-meta-horizon-worlds.html","created":"2023-03-16","tags":["hackernews"],"meta":{"score":9},"text":"Searching for friends in Mark Zuckerberg\u2019s deserted fantasyland https://nymag.com/intelligencer/article/mark-zuckerberg-metaverse-meta-horizon-worlds.html","classes":{"dataset":0.4651623666}}
{"title":"Internet Control Message Protocol (ICMP) Remote Code Execution Vulnerability","description":"https://nvd.nist.gov/vuln/detail/CVE-2023-23415","link":"https://nvd.nist.gov/vuln/detail/CVE-2023-23415","created":"2023-03-15","tags":["hackernews"],"meta":{"score":46},"text":"Internet Control Message Protocol (ICMP) Remote Code Execution Vulnerability https://nvd.nist.gov/vuln/detail/CVE-2023-23415","classes":{"dataset":0.4798443317}}
{"title":"Partnering with Fastly\u2013Oblivious HTTP relay for FLEDGE's \ud835\udc58-anonymity server","description":"https://developer.chrome.com/blog/oblivious-http-for-k-anon-server-with-fastly/","link":"https://developer.chrome.com/blog/oblivious-http-for-k-anon-server-with-fastly/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":64},"text":"Partnering with Fastly\u2013Oblivious HTTP relay for FLEDGE's \ud835\udc58-anonymity server https://developer.chrome.com/blog/oblivious-http-for-k-anon-server-with-fastly/","classes":{"dataset":0.4806427658}}
{"title":"Payments giant Stripe raises $6.5B at a $50B valuation","description":"https://www.axios.com/2023/03/15/stripe-50-billion","link":"https://www.axios.com/2023/03/15/stripe-50-billion","created":"2023-03-15","tags":["hackernews"],"meta":{"score":37},"text":"Payments giant Stripe raises $6.5B at a $50B valuation https://www.axios.com/2023/03/15/stripe-50-billion","classes":{"dataset":0.5122349262}}
{"title":"Repeat yourself, do more than one thing, and rewrite everything (2018)","description":"https://programmingisterrible.com/post/176657481103/repeat-yourself-do-more-than-one-thing-and","link":"https://programmingisterrible.com/post/176657481103/repeat-yourself-do-more-than-one-thing-and","created":"2023-03-14","tags":["hackernews"],"meta":{"score":247},"text":"Repeat yourself, do more than one thing, and rewrite everything (2018) https://programmingisterrible.com/post/176657481103/repeat-yourself-do-more-than-one-thing-and","classes":{"dataset":0.5245387554}}
{"title":"Smarty GPT","description":"This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers **in a transparent way to end users**.\n\n&amp;#x200B;\n\nFeel free to open issues, PR, add more prompts! \n\n&amp;#x200B;\n\n[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)","link":"https://www.reddit.com/r/PromptDesign/comments/11r5m06/smarty_gpt/","created":"2023-03-14","tags":["promptdesign","prompteng","reddit"],"meta":{"num_comments":1},"text":"Smarty GPT This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers **in a transparent way to end users**.\n\n&amp;#x200B;\n\nFeel free to open issues, PR, add more prompts! \n\n&amp;#x200B;\n\n[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)","classes":{"dataset":0.5222185254}}
{"title":"Managing secrets like API keys in Python - Why are so many devs still hardcoding secrets?","description":"The recent [State of Secrets Sprawl report](https://www.gitguardian.com/state-of-secrets-sprawl-report-2023) showed that 10 million (yes million) secrets like API keys, credential pairs and security certs were leaked in public GitHub repositories in 2022 and Python was by far the largest contributor to these. \n\nThe problem stems mostly from secrets being hardcoded directly into the source code. So this leads to the question, why are so many devs hardcoding secrets? The problem is a little more complicated with git because often a secret is hardcoded and removed without the dev realizing that the secret persists in the git history. But still, this is a big issue in the Python community. \n\nManaging secrets can be really easy thanks to helpful Pypi packages like [Python Dotenv](https://pypi.org/project/python-dotenv/) which is my favorite for its simplicity and easy ability to manage secrets for multiple different environments like Dev and Prod. I'm curious about what others are using to manage secrets and why? \n\nI thought I'd share some recent tutorials on managing secrets for anyone who may need a refresher on the topic. Please share more resources in the comments.   \n\n\n[Managing Secrets in Python - Video](https://www.youtube.com/watch?v=DVVYHlGYIHY)  \n\n\n[Managing Secrets in Python - Blog](https://blog.gitguardian.com/how-to-handle-secrets-in-python/)","link":"https://www.reddit.com/r/Python/comments/11rqyv9/managing_secrets_like_api_keys_in_python_why_are/","created":"2023-03-15","tags":["python","reddit"],"meta":{"num_comments":116},"text":"Managing secrets like API keys in Python - Why are so many devs still hardcoding secrets? The recent [State of Secrets Sprawl report](https://www.gitguardian.com/state-of-secrets-sprawl-report-2023) showed that 10 million (yes million) secrets like API keys, credential pairs and security certs were leaked in public GitHub repositories in 2022 and Python was by far the largest contributor to these. \n\nThe problem stems mostly from secrets being hardcoded directly into the source code. So this leads to the question, why are so many devs hardcoding secrets? The problem is a little more complicated with git because often a secret is hardcoded and removed without the dev realizing that the secret persists in the git history. But still, this is a big issue in the Python community. \n\nManaging secrets can be really easy thanks to helpful Pypi packages like [Python Dotenv](https://pypi.org/project/python-dotenv/) which is my favorite for its simplicity and easy ability to manage secrets for multiple different environments like Dev and Prod. I'm curious about what others are using to manage secrets and why? \n\nI thought I'd share some recent tutorials on managing secrets for anyone who may need a refresher on the topic. Please share more resources in the comments.   \n\n\n[Managing Secrets in Python - Video](https://www.youtube.com/watch?v=DVVYHlGYIHY)  \n\n\n[Managing Secrets in Python - Blog](https://blog.gitguardian.com/how-to-handle-secrets-in-python/)","classes":{"dataset":0.4677483737}}
{"title":"Python mouse.move and pyautogui.moveTo not working properly after window close","description":"Hi,\nI scripted something with selenium and move the mouse to some elements on a website. Both my windows are maximized via driver.maximize_window() I have a loop, a 2nd window is opened and i can use the mouse properly by x and y. When this window is closed the mouse will move but with an offset in x and y.  At first i thought is was the mouse library so i switched to pyautogui but its the same behaviour.  I added a move to x=0 and y=0 and this is not working at all. I havent found anything to \u201ereset\u201c it and i dont see how its linked to the selenium. it should always be starting in the top left corner and work with pixels and my screen resolution.","link":"https://www.reddit.com/r/Python/comments/11sbvyz/python_mousemove_and_pyautoguimoveto_not_working/","created":"2023-03-15","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Python mouse.move and pyautogui.moveTo not working properly after window close Hi,\nI scripted something with selenium and move the mouse to some elements on a website. Both my windows are maximized via driver.maximize_window() I have a loop, a 2nd window is opened and i can use the mouse properly by x and y. When this window is closed the mouse will move but with an offset in x and y.  At first i thought is was the mouse library so i switched to pyautogui but its the same behaviour.  I added a move to x=0 and y=0 and this is not working at all. I havent found anything to \u201ereset\u201c it and i dont see how its linked to the selenium. it should always be starting in the top left corner and work with pixels and my screen resolution.","classes":{"dataset":0.4177103937}}
{"title":"data structures &amp; algorithms resources available with python ?","description":"as the title says, does anyone know of any good resources/ free online courses that will allow someone to fully grasp the concept of non basic data structures in python? i feel like i have an okay foundation but would definitely like to have more practice and understanding of trees, graphs, stacks, recursion, etc.","link":"https://www.reddit.com/r/Python/comments/11slfbt/data_structures_algorithms_resources_available/","created":"2023-03-16","tags":["python","reddit"],"meta":{"num_comments":6},"text":"data structures &amp; algorithms resources available with python ? as the title says, does anyone know of any good resources/ free online courses that will allow someone to fully grasp the concept of non basic data structures in python? i feel like i have an okay foundation but would definitely like to have more practice and understanding of trees, graphs, stacks, recursion, etc.","classes":{"dataset":0.3611496687}}
{"title":"What if FastAPI was 100x faster and supported NumPy arrays and Pillow images?","description":"When deploying AI models with FastAPI, we always had to write custom serialisation code for numpy.ndarray and PIL.Image. Not only have we replaced FastAPI with up to 100x faster C-level library a couple of weeks ago, but we have also recently added support for all the fancy Pythonic types on both the client and server sides.  \n\n\nIt's remarkable how fast this library turned out to be; there was a [great discussion on HackerNews](https://news.ycombinator.com/item?id=35042316) on how the new u/linux io\\_uring functionality in kernels newer than 5.19 affects our performance, so we are very excited to share it with the broader Python community! Please let us know if there are other types you often use and would want UJRPC to support [\ud83e\udd17](https://emojipedia.org/hugging-face/)\n\n[Check it out on GitHub/Unum-Cloud/UJRPC](https://github.com/unum-cloud/ujrpc#more-functionality-than-fastapi)  \n\n\n[Deploying UForm with UJRPC for fast Multi-Modal AI Inference](https://preview.redd.it/5zg8nypknxna1.png?width=1648&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=968b64e0d70ad2c40fb7da2a451dbc8893245a42)","link":"https://www.reddit.com/r/Python/comments/11s2e3q/what_if_fastapi_was_100x_faster_and_supported/","created":"2023-03-15","tags":["python","reddit"],"meta":{"num_comments":0},"text":"What if FastAPI was 100x faster and supported NumPy arrays and Pillow images? When deploying AI models with FastAPI, we always had to write custom serialisation code for numpy.ndarray and PIL.Image. Not only have we replaced FastAPI with up to 100x faster C-level library a couple of weeks ago, but we have also recently added support for all the fancy Pythonic types on both the client and server sides.  \n\n\nIt's remarkable how fast this library turned out to be; there was a [great discussion on HackerNews](https://news.ycombinator.com/item?id=35042316) on how the new u/linux io\\_uring functionality in kernels newer than 5.19 affects our performance, so we are very excited to share it with the broader Python community! Please let us know if there are other types you often use and would want UJRPC to support [\ud83e\udd17](https://emojipedia.org/hugging-face/)\n\n[Check it out on GitHub/Unum-Cloud/UJRPC](https://github.com/unum-cloud/ujrpc#more-functionality-than-fastapi)  \n\n\n[Deploying UForm with UJRPC for fast Multi-Modal AI Inference](https://preview.redd.it/5zg8nypknxna1.png?width=1648&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=968b64e0d70ad2c40fb7da2a451dbc8893245a42)","classes":{"dataset":0.4569682777}}
{"title":"Open-source Mathematical Python Lib","description":"# Functvs\n\nHey, all you nerds out there!!\n\nIf  you are really into MATHEMATICS, science in general, advanced, applied,  pure, &amp;c. And you want to contribute to the Math, Chemical, Physics  applications in this lib. Please, join!!\n\nI am going over the works of Pierre Raymond, Pascal and Euler on the sub-factorial function and all that follows.\n\n(BETA)\n\npip install Functvs\n\n[https://github.com/shimon-d/functvs](https://github.com/shimon-d/functvs)","link":"https://www.reddit.com/r/Python/comments/11sfu7i/opensource_mathematical_python_lib/","created":"2023-03-16","tags":["python","reddit"],"meta":{"num_comments":2},"text":"Open-source Mathematical Python Lib # Functvs\n\nHey, all you nerds out there!!\n\nIf  you are really into MATHEMATICS, science in general, advanced, applied,  pure, &amp;c. And you want to contribute to the Math, Chemical, Physics  applications in this lib. Please, join!!\n\nI am going over the works of Pierre Raymond, Pascal and Euler on the sub-factorial function and all that follows.\n\n(BETA)\n\npip install Functvs\n\n[https://github.com/shimon-d/functvs](https://github.com/shimon-d/functvs)","classes":{"dataset":0.4303030372}}
{"title":"Python game library? Which one best?","description":" Hey guys, \n\nI'm looking to improve my Python skills, and I'd love to work on a project that I enjoy. I've always wanted to create a 2D game similar to Wor$ms, with realistic physics and environments, but with more complexity and additional statistics.\n\nMy question is, which library would be best for this project? Would PyGame be sufficient, or are there better alternatives? I need advanced physics for the objects and terrain in my game. Thank you :)","link":"https://www.reddit.com/r/Python/comments/11s160z/python_game_library_which_one_best/","created":"2023-03-15","tags":["python","reddit"],"meta":{"num_comments":1},"text":"Python game library? Which one best?  Hey guys, \n\nI'm looking to improve my Python skills, and I'd love to work on a project that I enjoy. I've always wanted to create a 2D game similar to Wor$ms, with realistic physics and environments, but with more complexity and additional statistics.\n\nMy question is, which library would be best for this project? Would PyGame be sufficient, or are there better alternatives? I need advanced physics for the objects and terrain in my game. Thank you :)","classes":{"dataset":0.3825603127}}
{"title":"How do I feel like I\u2019m learning Python the right way without getting drained","description":"","link":"https://www.reddit.com/r/Python/comments/11s9g3k/how_do_i_feel_like_im_learning_python_the_right/","created":"2023-03-15","tags":["python","reddit"],"meta":{"num_comments":3},"text":"How do I feel like I\u2019m learning Python the right way without getting drained ","classes":{"dataset":0.3487915695}}
{"title":"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3","description":"Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!\n\nThe reason for this increased performance seems to be due to a larger number of tokens being used for training.\n\nNow, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!\n\n[https://youtu.be/d4Cnv\\_g3GiI](https://youtu.be/d4Cnv_g3GiI)","link":"https://www.reddit.com/r/deeplearning/comments/11ryc3s/how_to_finetune_llama_models_smaller_models_with/","created":"2023-03-15","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":7},"text":"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3 Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!\n\nThe reason for this increased performance seems to be due to a larger number of tokens being used for training.\n\nNow, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!\n\n[https://youtu.be/d4Cnv\\_g3GiI](https://youtu.be/d4Cnv_g3GiI)","classes":{"dataset":0.2226051241}}
{"title":"[P] We are building a curated list of awesome curated list closely related to machine learning, looking for contributions.","description":"Hey r/MachineLearning,\n\nWe are collecting a hand-crafted curated list of awesome curated lists closely related to machine learning.\n\nHere is the link to the Github repo: [https://github.com/zhimin-z/awesome-awesome-machine-learning](https://github.com/zhimin-z/awesome-awesome-machine-learning)\n\nDo any lists need to be included from your perspective? Please let me know, or feel free to submit a pull request.\n\nThe motivation underlying this project is that so many awesome lists regarding machine learning exist on GitHub. But, gradually, it adds a mental burden to memorize where to look for when the ML world is progressing faster and faster these days.\n\nThus, there the project comes, as a unification to sew together all awesome lists closely related to machine learning.","link":"https://www.reddit.com/r/deeplearning/comments/11schoa/p_we_are_building_a_curated_list_of_awesome/","created":"2023-03-15","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"[P] We are building a curated list of awesome curated list closely related to machine learning, looking for contributions. Hey r/MachineLearning,\n\nWe are collecting a hand-crafted curated list of awesome curated lists closely related to machine learning.\n\nHere is the link to the Github repo: [https://github.com/zhimin-z/awesome-awesome-machine-learning](https://github.com/zhimin-z/awesome-awesome-machine-learning)\n\nDo any lists need to be included from your perspective? Please let me know, or feel free to submit a pull request.\n\nThe motivation underlying this project is that so many awesome lists regarding machine learning exist on GitHub. But, gradually, it adds a mental burden to memorize where to look for when the ML world is progressing faster and faster these days.\n\nThus, there the project comes, as a unification to sew together all awesome lists closely related to machine learning.","classes":{"dataset":0.4609384239}}
{"title":"Sliding Window on time serie create too big dataset","description":"Hello, \n\nI have a time serie dataset and when splitting it using sliding windows it generates me over 13 millions samples, which takes too long to train.  \n\n  \nDo I absolutely need to use sliding windows or can I simply split each sequence into multiple non-overlapping samples ?  (I'm using LSTM bidirectional layers)  \nDo you have any advice apart from changing sliding stride ? \n\nMany thanks, this is my first time serie project :)","link":"https://www.reddit.com/r/deeplearning/comments/11say4l/sliding_window_on_time_serie_create_too_big/","created":"2023-03-15","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":5},"text":"Sliding Window on time serie create too big dataset Hello, \n\nI have a time serie dataset and when splitting it using sliding windows it generates me over 13 millions samples, which takes too long to train.  \n\n  \nDo I absolutely need to use sliding windows or can I simply split each sequence into multiple non-overlapping samples ?  (I'm using LSTM bidirectional layers)  \nDo you have any advice apart from changing sliding stride ? \n\nMany thanks, this is my first time serie project :)","classes":{"dataset":0.2841894627}}
{"title":"Transformer models: if token embeddings are trainable params, why doesn't training cause every token to be mapped to the same vector?","description":"Wouldn't the model have incredibly low loss if every token was the same? What stops this from happening?","link":"https://www.reddit.com/r/deeplearning/comments/11rqtpm/transformer_models_if_token_embeddings_are/","created":"2023-03-15","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":5},"text":"Transformer models: if token embeddings are trainable params, why doesn't training cause every token to be mapped to the same vector? Wouldn't the model have incredibly low loss if every token was the same? What stops this from happening?","classes":{"dataset":0.2235213965}}
{"title":"How does Donut extract precise text without OCR?","description":"I've stumbled upon [this paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136880493.pdf) and a couple of others that basically discuss an alternative approach (Donut) for Visual Document Understanding (VDU).\n\nThe conventional and common approach (like what's done by LayoutLM) is to first perform OCR on the input image (with potential text block recognition beforehand), then post-process the output text. Donut's premise is to basically cut out the OCR step and process end-to-end in one pass.\n\nMy question is simply how does the text extraction happen in that case? how can text be extracted with such precision without OCR or some other form of optical text recognition?\n\nI went through the paper and a handful of articles explaining it, but the concept as a whole is still quite baffling to me and it all sounds like \"you can see without your eyes\" at this point x)","link":"https://www.reddit.com/r/deeplearning/comments/11rc2oh/how_does_donut_extract_precise_text_without_ocr/","created":"2023-03-14","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":1},"text":"How does Donut extract precise text without OCR? I've stumbled upon [this paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136880493.pdf) and a couple of others that basically discuss an alternative approach (Donut) for Visual Document Understanding (VDU).\n\nThe conventional and common approach (like what's done by LayoutLM) is to first perform OCR on the input image (with potential text block recognition beforehand), then post-process the output text. Donut's premise is to basically cut out the OCR step and process end-to-end in one pass.\n\nMy question is simply how does the text extraction happen in that case? how can text be extracted with such precision without OCR or some other form of optical text recognition?\n\nI went through the paper and a handful of articles explaining it, but the concept as a whole is still quite baffling to me and it all sounds like \"you can see without your eyes\" at this point x)","classes":{"dataset":0.3754862547}}
{"title":"Research opportunity","description":"Hey all, I came across Fatima Fellowship on LinkedIn (not sure if links are allowed here so I won't post it but you can just google it up). They provide research opportunities for Machine Learning and I guess related areas. It says that it's free and works as a non-profit. Thought I would share here incase anyone is looking for research chances.","link":"https://www.reddit.com/r/deeplearning/comments/11rfapy/research_opportunity/","created":"2023-03-14","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"Research opportunity Hey all, I came across Fatima Fellowship on LinkedIn (not sure if links are allowed here so I won't post it but you can just google it up). They provide research opportunities for Machine Learning and I guess related areas. It says that it's free and works as a non-profit. Thought I would share here incase anyone is looking for research chances.","classes":{"dataset":0.5311536193}}
{"title":"What are some ways to teach myself new skills?","description":"","link":"https://www.reddit.com/r/deeplearning/comments/11r65oj/what_are_some_ways_to_teach_myself_new_skills/","created":"2023-03-14","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":4},"text":"What are some ways to teach myself new skills? ","classes":{"dataset":0.2856739163}}
{"title":"[N] A $250k contest to read ancient Roman papyrus scrolls with ML","description":"Today we launched [the Vesuvius Challenge](https://scrollprize.org/), an open competition to read a set of charred papyrus scrolls that were buried by the eruption of Mount Vesuvius 2000 years ago. The scrolls can't be physically opened, but we have released 3d tomographic x-ray scans of two of them at 8\u00b5m resolution.  The scans were made at a particle accelerator. \n\nA team at UKY led by Prof Brent Seales has [very recently demonstrated](https://scrollprize.org/tutorial4) the ability to detect ink inside the CT scans using CNNs, and so we believe that it is possible for the first time in history to read what's in these scrolls without opening them. There are hundreds of carbonized scrolls that we could read once the technique works \u2013 enough to more than double our total corpus of literature from antiquity.\n\nMany of us are fans of /r/MachineLearning and we thought this group would be interested in hearing about it!","link":"https://www.reddit.com/r/MachineLearning/comments/11sgn67/n_a_250k_contest_to_read_ancient_roman_papyrus/","created":"2023-03-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":15},"text":"[N] A $250k contest to read ancient Roman papyrus scrolls with ML Today we launched [the Vesuvius Challenge](https://scrollprize.org/), an open competition to read a set of charred papyrus scrolls that were buried by the eruption of Mount Vesuvius 2000 years ago. The scrolls can't be physically opened, but we have released 3d tomographic x-ray scans of two of them at 8\u00b5m resolution.  The scans were made at a particle accelerator. \n\nA team at UKY led by Prof Brent Seales has [very recently demonstrated](https://scrollprize.org/tutorial4) the ability to detect ink inside the CT scans using CNNs, and so we believe that it is possible for the first time in history to read what's in these scrolls without opening them. There are hundreds of carbonized scrolls that we could read once the technique works \u2013 enough to more than double our total corpus of literature from antiquity.\n\nMany of us are fans of /r/MachineLearning and we thought this group would be interested in hearing about it!","classes":{"dataset":0.112421304}}
{"title":"[N] PyTorch 2.0: Our next generation release that is faster, more Pythonic and Dynamic as ever","description":"Preview of the post since it's dropping in a few hours: https://deploy-preview-1313--pytorch-dot-org-preview.netlify.app/blog/pytorch-2.0-release/\n\n\nAlso a post about Accelerated Diffusers with 2.0: https://deploy-preview-1315--pytorch-dot-org-preview.netlify.app/blog/accelerated-diffusers-pt-20/\n\nGPT Summary:\n\n- PyTorch 2.0 is a next generation release that offers faster performance and support for dynamic shapes and distributed training using torch.compile as the main API.\n\n- PyTorch 2.0 also includes a stable version of Accelerated Transformers, which use custom kernels for scaled dot product attention and are integrated with torch.compile.\n\n- Other beta features include PyTorch MPS Backend for GPU-accelerated training on Mac platforms, functorch APIs in the torch.func module, and AWS Graviton3 optimization for CPU inference.\n\n- The release also includes prototype features and technologies across TensorParallel, DTensor, 2D parallel, TorchDynamo, AOTAutograd, PrimTorch and TorchInductor.","link":"https://www.reddit.com/r/MachineLearning/comments/11s58n4/n_pytorch_20_our_next_generation_release_that_is/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":17},"text":"[N] PyTorch 2.0: Our next generation release that is faster, more Pythonic and Dynamic as ever Preview of the post since it's dropping in a few hours: https://deploy-preview-1313--pytorch-dot-org-preview.netlify.app/blog/pytorch-2.0-release/\n\n\nAlso a post about Accelerated Diffusers with 2.0: https://deploy-preview-1315--pytorch-dot-org-preview.netlify.app/blog/accelerated-diffusers-pt-20/\n\nGPT Summary:\n\n- PyTorch 2.0 is a next generation release that offers faster performance and support for dynamic shapes and distributed training using torch.compile as the main API.\n\n- PyTorch 2.0 also includes a stable version of Accelerated Transformers, which use custom kernels for scaled dot product attention and are integrated with torch.compile.\n\n- Other beta features include PyTorch MPS Backend for GPU-accelerated training on Mac platforms, functorch APIs in the torch.func module, and AWS Graviton3 optimization for CPU inference.\n\n- The release also includes prototype features and technologies across TensorParallel, DTensor, 2D parallel, TorchDynamo, AOTAutograd, PrimTorch and TorchInductor.","classes":{"dataset":0.5069561005}}
{"title":"[D] Anyone else witnessing a panic inside NLP orgs of big tech companies?","description":"I'm in a big tech company working along side a science team for a product you've all probably used. We have these year long initiatives to productionalize \"state of the art NLP models\" that are now completely obsolete in the face of GPT-4. I think at first the science orgs were quiet/in denial. But now it's very obvious we are basically working on worthless technology. And by \"we\", I mean a large organization with scores of teams. \n\nAnyone else seeing this? What is the long term effect on science careers that get disrupted like this? Whats even more odd is the ego's of some of these science people\n\nClearly the model is not a catch all, but still","link":"https://www.reddit.com/r/MachineLearning/comments/11rizyb/d_anyone_else_witnessing_a_panic_inside_nlp_orgs/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":325},"text":"[D] Anyone else witnessing a panic inside NLP orgs of big tech companies? I'm in a big tech company working along side a science team for a product you've all probably used. We have these year long initiatives to productionalize \"state of the art NLP models\" that are now completely obsolete in the face of GPT-4. I think at first the science orgs were quiet/in denial. But now it's very obvious we are basically working on worthless technology. And by \"we\", I mean a large organization with scores of teams. \n\nAnyone else seeing this? What is the long term effect on science careers that get disrupted like this? Whats even more odd is the ego's of some of these science people\n\nClearly the model is not a catch all, but still","classes":{"dataset":0.2121465206}}
{"title":"[D] Any other ICML reviewers noticing strange scores for the papers they're assigned to?","description":"I'm reviewing 4 papers, of which I gave one a very positive review. I am the only negative reviewer for 3/4 of the papers I am reviewing. Most of the papers have short, glowing positive reviews that don't meaningfully engage with the paper at all. At least two of the papers have bizarre formatting problems like blurry figures with unreadable text (not publication quality) that don't pass the eye test.\n\nA similar thing happened at ICLR reviews this year, and the authors withdrew their papers in spite of having 2x very positive reviews and 1x slightly negative review (mine). No attempt at rebuttal.\n\nHas anybody else experienced this?","link":"https://www.reddit.com/r/MachineLearning/comments/11scezi/d_any_other_icml_reviewers_noticing_strange/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":4},"text":"[D] Any other ICML reviewers noticing strange scores for the papers they're assigned to? I'm reviewing 4 papers, of which I gave one a very positive review. I am the only negative reviewer for 3/4 of the papers I am reviewing. Most of the papers have short, glowing positive reviews that don't meaningfully engage with the paper at all. At least two of the papers have bizarre formatting problems like blurry figures with unreadable text (not publication quality) that don't pass the eye test.\n\nA similar thing happened at ICLR reviews this year, and the authors withdrew their papers in spite of having 2x very positive reviews and 1x slightly negative review (mine). No attempt at rebuttal.\n\nHas anybody else experienced this?","classes":{"dataset":0.1477165371}}
{"title":"[D] GPT-3 will ignore tools when it disagrees with them","description":"[https://vgel.me/posts/tools-not-needed/](https://vgel.me/posts/tools-not-needed/)","link":"https://www.reddit.com/r/MachineLearning/comments/11s654g/d_gpt3_will_ignore_tools_when_it_disagrees_with/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":5},"text":"[D] GPT-3 will ignore tools when it disagrees with them [https://vgel.me/posts/tools-not-needed/](https://vgel.me/posts/tools-not-needed/)","classes":{"dataset":0.323849529}}
{"title":"[D]Will the AI use and distribution be under strict government control?","description":"I mean, it is not too far fetched to imagine the governments will try to limit the use of AI for deepfakes etc., and mere possession of those AIs capable of those things, or distribution of tools capable of that, will end of the same spectrum as possession / distribution of child porn.\n\nI can easily see huge pushback for regulation once we get to stage where everyone can run AIs on their home computers with minimal setup and they will became so good at generating stuff it will not be distinguishable from the real thing.","link":"https://www.reddit.com/r/MachineLearning/comments/11sorz7/dwill_the_ai_use_and_distribution_be_under_strict/","created":"2023-03-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1},"text":"[D]Will the AI use and distribution be under strict government control? I mean, it is not too far fetched to imagine the governments will try to limit the use of AI for deepfakes etc., and mere possession of those AIs capable of those things, or distribution of tools capable of that, will end of the same spectrum as possession / distribution of child porn.\n\nI can easily see huge pushback for regulation once we get to stage where everyone can run AIs on their home computers with minimal setup and they will became so good at generating stuff it will not be distinguishable from the real thing.","classes":{"dataset":0.4110577404}}
{"title":"[D] GPT-4 Speculation","description":"Hi,\n\nSince GPT-4 paper does not contain any information about architectures/parameters, as a research or ML practitioner, I want to speculate on what they did to increase the context window to 32k.\n\nBecause for the type of work I do, a 4k or 8k token limit is pretty much useless. I have seen open-source efforts focused more on matching the number of parameters and quality to the closed-source ones but completely ignoring a giant elephant in the room, i.e., the context window. No OSS model has a context window greater than 2k tokens.\n\nI would love to hear more thoughts on the model size (my guess is \\~50 B) and how they fit 32k tokens in 8xH100 (640 GB total) GPUs.","link":"https://www.reddit.com/r/MachineLearning/comments/11romcb/d_gpt4_speculation/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":30},"text":"[D] GPT-4 Speculation Hi,\n\nSince GPT-4 paper does not contain any information about architectures/parameters, as a research or ML practitioner, I want to speculate on what they did to increase the context window to 32k.\n\nBecause for the type of work I do, a 4k or 8k token limit is pretty much useless. I have seen open-source efforts focused more on matching the number of parameters and quality to the closed-source ones but completely ignoring a giant elephant in the room, i.e., the context window. No OSS model has a context window greater than 2k tokens.\n\nI would love to hear more thoughts on the model size (my guess is \\~50 B) and how they fit 32k tokens in 8xH100 (640 GB total) GPUs.","classes":{"dataset":0.0645914227}}
{"title":"[News] OpenAI Announced GPT-4","description":"Research blog:\n\n[https://openai.com/research/gpt-4](https://openai.com/research/gpt-4)\n\nProduct demo:\n\n[https://openai.com/product/gpt-4](https://openai.com/product/gpt-4)\n\nResearch report:\n\n[https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf)\n\nAPI waitlist:\n\n[https://openai.com/waitlist/gpt-4-api](https://openai.com/waitlist/gpt-4-api)\n\nTwitter announcement:\n\n [https://twitter.com/OpenAI/status/1635687373060317185](https://twitter.com/OpenAI/status/1635687373060317185)\n\nOpenAI developer livestream:\n\n[https://www.youtube.com/watch?v=outcGtbnMuQ](https://www.youtube.com/watch?v=outcGtbnMuQ&amp;ab_channel=OpenAI)","link":"https://www.reddit.com/r/MachineLearning/comments/11rc02e/news_openai_announced_gpt4/","created":"2023-03-14","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":235},"text":"[News] OpenAI Announced GPT-4 Research blog:\n\n[https://openai.com/research/gpt-4](https://openai.com/research/gpt-4)\n\nProduct demo:\n\n[https://openai.com/product/gpt-4](https://openai.com/product/gpt-4)\n\nResearch report:\n\n[https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf)\n\nAPI waitlist:\n\n[https://openai.com/waitlist/gpt-4-api](https://openai.com/waitlist/gpt-4-api)\n\nTwitter announcement:\n\n [https://twitter.com/OpenAI/status/1635687373060317185](https://twitter.com/OpenAI/status/1635687373060317185)\n\nOpenAI developer livestream:\n\n[https://www.youtube.com/watch?v=outcGtbnMuQ](https://www.youtube.com/watch?v=outcGtbnMuQ&amp;ab_channel=OpenAI)","classes":{"dataset":0.4447258711}}
{"title":"[D] ChatGPT responds to criticisms of GPT-4's high test scores.","description":"I asked ChatGPT to shares its thoughts on GPT-4's high tests scores (e.g., LSAT and GRE) and the widespread criticism of this achievement as being meaningless because in the estimation of some people these tests merely illustrate a test taker's rote memorization ability and not legitimate intelligence.\n\nI thought its answer was insightful.\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\nHumans have a tendency to dismiss or discredit new ideas or technologies when they challenge existing beliefs or established systems. This is known as cognitive conservatism, which refers to the tendency to rely on existing beliefs and resist change, even in the face of new evidence.\n\nIn the case of GPT-4, it may be that some people are dismissing its achievements on standardized tests because they do not align with their beliefs about the nature of intelligence or the purpose of education. Standardized tests such as the GRE and LSAT have been criticized for their focus on rote memorization and their failure to measure skills such as creativity, critical thinking, and problem-solving.\n\nAdditionally, people may be resistant to the idea that a machine could outperform humans on such tests, as it challenges the notion of human exceptionalism and raises concerns about the potential impact of AI on employment and society.\n\nIt is important to approach new technologies and ideas with an open mind and a willingness to challenge our assumptions and beliefs. While standardized tests may have limitations, the fact that GPT-4 can perform well on them is still a remarkable achievement in the field of AI and natural language processing. It is important to consider the potential implications of such advancements and to continue exploring new ways of measuring and understanding intelligence.\n\nPerforming well on the LSAT and GRE involves more than just rote memorization. These tests measure various skills, including critical thinking, problem-solving, and the ability to analyze and synthesize information. For example, the LSAT tests skills such as analytical reasoning, logical reasoning, and reading comprehension. Similarly, the GRE assesses skills such as verbal reasoning, quantitative reasoning, and analytical writing. While some amount of memorization may be required, success on these tests is primarily based on the ability to think critically and analyze information in a nuanced way.\n\nFurthermore, the tests are designed to be a standardized way of measuring these skills across different individuals and populations. The tests are carefully constructed to minimize bias and to ensure that the questions are assessing the skills they are intended to measure. The fact that the tests are widely used and respected in academic and professional circles indicates that they are considered to be valid measures of these skills.\n\nThe high scores of GPT-4 on tests such as the LSAT and GRE indicate a significant improvement in natural language processing capabilities of AI language models. While these language models still have limitations and are not yet capable of fully replacing human abilities, they have the potential to automate many routine tasks and augment human decision-making in various fields. In the future, this may lead to changes in the nature of work, where repetitive and predictable tasks are automated, and humans focus more on tasks that require creativity, critical thinking, and social skills that machines cannot replicate. However, it is also possible that the widespread adoption of AI language models could lead to job displacement in some fields, particularly those that involve routine tasks that can be automated. It will be important for society to carefully consider the potential impacts of these technological advancements and to develop strategies to ensure that everyone benefits from these changes.","link":"https://www.reddit.com/r/MachineLearning/comments/11slj7z/d_chatgpt_responds_to_criticisms_of_gpt4s_high/","created":"2023-03-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":7},"text":"[D] ChatGPT responds to criticisms of GPT-4's high test scores. I asked ChatGPT to shares its thoughts on GPT-4's high tests scores (e.g., LSAT and GRE) and the widespread criticism of this achievement as being meaningless because in the estimation of some people these tests merely illustrate a test taker's rote memorization ability and not legitimate intelligence.\n\nI thought its answer was insightful.\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\nHumans have a tendency to dismiss or discredit new ideas or technologies when they challenge existing beliefs or established systems. This is known as cognitive conservatism, which refers to the tendency to rely on existing beliefs and resist change, even in the face of new evidence.\n\nIn the case of GPT-4, it may be that some people are dismissing its achievements on standardized tests because they do not align with their beliefs about the nature of intelligence or the purpose of education. Standardized tests such as the GRE and LSAT have been criticized for their focus on rote memorization and their failure to measure skills such as creativity, critical thinking, and problem-solving.\n\nAdditionally, people may be resistant to the idea that a machine could outperform humans on such tests, as it challenges the notion of human exceptionalism and raises concerns about the potential impact of AI on employment and society.\n\nIt is important to approach new technologies and ideas with an open mind and a willingness to challenge our assumptions and beliefs. While standardized tests may have limitations, the fact that GPT-4 can perform well on them is still a remarkable achievement in the field of AI and natural language processing. It is important to consider the potential implications of such advancements and to continue exploring new ways of measuring and understanding intelligence.\n\nPerforming well on the LSAT and GRE involves more than just rote memorization. These tests measure various skills, including critical thinking, problem-solving, and the ability to analyze and synthesize information. For example, the LSAT tests skills such as analytical reasoning, logical reasoning, and reading comprehension. Similarly, the GRE assesses skills such as verbal reasoning, quantitative reasoning, and analytical writing. While some amount of memorization may be required, success on these tests is primarily based on the ability to think critically and analyze information in a nuanced way.\n\nFurthermore, the tests are designed to be a standardized way of measuring these skills across different individuals and populations. The tests are carefully constructed to minimize bias and to ensure that the questions are assessing the skills they are intended to measure. The fact that the tests are widely used and respected in academic and professional circles indicates that they are considered to be valid measures of these skills.\n\nThe high scores of GPT-4 on tests such as the LSAT and GRE indicate a significant improvement in natural language processing capabilities of AI language models. While these language models still have limitations and are not yet capable of fully replacing human abilities, they have the potential to automate many routine tasks and augment human decision-making in various fields. In the future, this may lead to changes in the nature of work, where repetitive and predictable tasks are automated, and humans focus more on tasks that require creativity, critical thinking, and social skills that machines cannot replicate. However, it is also possible that the widespread adoption of AI language models could lead to job displacement in some fields, particularly those that involve routine tasks that can be automated. It will be important for society to carefully consider the potential impacts of these technological advancements and to develop strategies to ensure that everyone benefits from these changes.","classes":{"dataset":0.3035314977}}
{"title":"[D] Alternatives to Mediapipe's FaceMesh for 3D Face Reconstruction","description":"Hi there,\n\nCurrently, I am using mediapipe for FaceMesh, which has decent reliability and is easy to setup in Python. However, I recently discovered Microsoft Research's \"3D Face Reconstruction with Dense Landmarks\" paper, which appears to be a much better alternative.\n\nDoes anyone know where I can access Microsoft DenseLandmarks or an equally good alternative?","link":"https://www.reddit.com/r/MachineLearning/comments/11s01af/d_alternatives_to_mediapipes_facemesh_for_3d_face/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0},"text":"[D] Alternatives to Mediapipe's FaceMesh for 3D Face Reconstruction Hi there,\n\nCurrently, I am using mediapipe for FaceMesh, which has decent reliability and is easy to setup in Python. However, I recently discovered Microsoft Research's \"3D Face Reconstruction with Dense Landmarks\" paper, which appears to be a much better alternative.\n\nDoes anyone know where I can access Microsoft DenseLandmarks or an equally good alternative?","classes":{"dataset":0.005461256}}
{"title":"[D] Challenges for Keras as a Deep Learning Framework","description":" Hey, I've been using Keras for a while now and I think it's a great deep learning framework, but there are some challenges that prevent it from overtaking PyTorch. Here are the main ones:\n\nFirstly, Keras' customer support can be pretty inadequate. I've had issues with memory leaks and race conditions that were hard to reproduce, and the customer service team didn't investigate the problem or work with me to track it down. They also sometimes ignore tickets or requests for documentation fixes, which can be frustrating.\n\nAnother issue is that the functional programming interface in Keras has some limitations. While it's good for people who think in a functional way, the graph system in TensorFlow isn't generalized or abstracted well. This can create artificial boundaries in the graph processor for models of models, which isn't mathematically sound. Plus, accessing nodes in the graph isn't straightforward, which is a sign that there are underlying issues with the graph abstraction. These limitations need to be addressed to make the functional interface more robust.\n\nLastly, Keras has limited support for algebra beyond real numbers, like complex numbers. Metrics calls cast complex numbers to their real parts, which shows that Keras assumes only real-valued data is processed by the graphs. This approach is short-sighted and limiting for a framework that markets itself as comprehensive.\n\nDespite these challenges, Keras is still a popular choice for research code development because it's faster to develop than PyTorch in many cases. However, Keras needs to address these limitations to stay competitive in the research community. Improving customer support, expanding support for complex numbers, and addressing the limitations of the functional interface would create a more satisfied and productive user base.","link":"https://www.reddit.com/r/MachineLearning/comments/11sie8k/d_challenges_for_keras_as_a_deep_learning/","created":"2023-03-16","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":1},"text":"[D] Challenges for Keras as a Deep Learning Framework  Hey, I've been using Keras for a while now and I think it's a great deep learning framework, but there are some challenges that prevent it from overtaking PyTorch. Here are the main ones:\n\nFirstly, Keras' customer support can be pretty inadequate. I've had issues with memory leaks and race conditions that were hard to reproduce, and the customer service team didn't investigate the problem or work with me to track it down. They also sometimes ignore tickets or requests for documentation fixes, which can be frustrating.\n\nAnother issue is that the functional programming interface in Keras has some limitations. While it's good for people who think in a functional way, the graph system in TensorFlow isn't generalized or abstracted well. This can create artificial boundaries in the graph processor for models of models, which isn't mathematically sound. Plus, accessing nodes in the graph isn't straightforward, which is a sign that there are underlying issues with the graph abstraction. These limitations need to be addressed to make the functional interface more robust.\n\nLastly, Keras has limited support for algebra beyond real numbers, like complex numbers. Metrics calls cast complex numbers to their real parts, which shows that Keras assumes only real-valued data is processed by the graphs. This approach is short-sighted and limiting for a framework that markets itself as comprehensive.\n\nDespite these challenges, Keras is still a popular choice for research code development because it's faster to develop than PyTorch in many cases. However, Keras needs to address these limitations to stay competitive in the research community. Improving customer support, expanding support for complex numbers, and addressing the limitations of the functional interface would create a more satisfied and productive user base.","classes":{"dataset":0.4686106145}}
{"title":"[D] When to expect announcement of accepted workshops for IJCAI?","description":"According to their schedule, IJCAI has sent acceptance notification to workshops organizers at March 6th. When should we expect that the accepted workshop list will be available?","link":"https://www.reddit.com/r/MachineLearning/comments/11rutje/d_when_to_expect_announcement_of_accepted/","created":"2023-03-15","tags":["reddit","ml","machinelearning"],"meta":{"num_comments":0},"text":"[D] When to expect announcement of accepted workshops for IJCAI? According to their schedule, IJCAI has sent acceptance notification to workshops organizers at March 6th. When should we expect that the accepted workshop list will be available?","classes":{"dataset":0.239383921}}
{"title":"Getting into PhD Program at 30","description":"Hi all,\n\nI am interested in peoples thoughts about the possibility of going for a phD. I was looking into information studies at the univeristy of maryland in college Park, but now I am realizing I could try for more places. Basically wherever.\n\nSo about me. Got a BS in Physics, did teo summers  of research through NSF program. Realized I did not like the idea of sitting in a lab all day. Then got a masters in education and taught Hs for 3 years.\n\nRealized that was horrible.\n\nNow, falling back on my previous research I was able to get a job at an FFRDC (R&amp;D center) ive been at for 3.5 years now.\n\nI started out with NLP, but now work mainly on data engineering tasks. I still really enjoy scraping, information extraction type tasks and have built lots of pipelines using a combination of regex and other things like NLP out of the box spacy models. \n\nHowever. I have been stagnating for a while now. As I started to apply to DE jobs I realize my true passion is solving very difficult information extraction problems.\n\nI just realized that I want to get a phD so I can solve interesting problems.\n\nWhere does one start? Again the Information Studies program seems really interesting as I am more interested in NLP IE applications. Part if me thinks this is not possible but I think that is not true.\n\nAnyways, how should I prepare for my lack of schooling in CS? Should I start polishing up my side projects? Shiuld I study for the GRE? Should I do all the above? \n\nAny guidance is appreciated. It may be relevant to add that for a year now I decided to quit drinking / went completely sober. I felt pretty lost in the direction of my life lately, but now it has suddenly become very clear this is what I want to do.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11s96bw/getting_into_phd_program_at_30/","created":"2023-03-15","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":14},"text":"Getting into PhD Program at 30 Hi all,\n\nI am interested in peoples thoughts about the possibility of going for a phD. I was looking into information studies at the univeristy of maryland in college Park, but now I am realizing I could try for more places. Basically wherever.\n\nSo about me. Got a BS in Physics, did teo summers  of research through NSF program. Realized I did not like the idea of sitting in a lab all day. Then got a masters in education and taught Hs for 3 years.\n\nRealized that was horrible.\n\nNow, falling back on my previous research I was able to get a job at an FFRDC (R&amp;D center) ive been at for 3.5 years now.\n\nI started out with NLP, but now work mainly on data engineering tasks. I still really enjoy scraping, information extraction type tasks and have built lots of pipelines using a combination of regex and other things like NLP out of the box spacy models. \n\nHowever. I have been stagnating for a while now. As I started to apply to DE jobs I realize my true passion is solving very difficult information extraction problems.\n\nI just realized that I want to get a phD so I can solve interesting problems.\n\nWhere does one start? Again the Information Studies program seems really interesting as I am more interested in NLP IE applications. Part if me thinks this is not possible but I think that is not true.\n\nAnyways, how should I prepare for my lack of schooling in CS? Should I start polishing up my side projects? Shiuld I study for the GRE? Should I do all the above? \n\nAny guidance is appreciated. It may be relevant to add that for a year now I decided to quit drinking / went completely sober. I felt pretty lost in the direction of my life lately, but now it has suddenly become very clear this is what I want to do.","classes":{"dataset":0.5619726181}}
{"title":"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3","description":"Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!\n\nThe reason for this increased performance seems to be due to a larger number of tokens being used for training.\n\nNow, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!\n\n[https://youtu.be/d4Cnv\\_g3GiI](https://youtu.be/d4Cnv_g3GiI)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11ryg4d/how_to_finetune_llama_models_smaller_models_with/","created":"2023-03-15","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0},"text":"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3 Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!\n\nThe reason for this increased performance seems to be due to a larger number of tokens being used for training.\n\nNow, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!\n\n[https://youtu.be/d4Cnv\\_g3GiI](https://youtu.be/d4Cnv_g3GiI)","classes":{"dataset":0.4683608115}}
{"title":"UMASS Advanced-NLP","description":"Hi everyone. I finished the advanced nlp course from Mohit Iyyer. You can find the version I completed from here: [https://people.cs.umass.edu/\\~miyyer/cs685\\_f22/](https://people.cs.umass.edu/~miyyer/cs685_f22/) I would definetly recommend it. You can find lectures from youtube.\n\nIf you want to check out and discuss assignment solutions, you can find mine here: [https://github.com/uygarrr/Courses/tree/main/UMASS-CS685-Advanced-NLP](https://github.com/uygarrr/Courses/tree/main/UMASS-CS685-Advanced-NLP)\n\nAlso there're 2 quiz quesitons that I couldn't be sure about the answers. Let me share them here too.\n\n1st: Assume we are applying a Transformer sequence-to-sequence model for a conditional language modeling task (e.g., machine translation). Why don\u2019t we need to use masking in cross attention?\n\n2nd: Now let\u2019s say we want to probe whether or not BERT\u2019s \\[CLS\\] token has encoded the length of an input sentence. Explain how you would design a control task for this probe to address the effect of probe network complexity.\n\n&amp;#x200B;\n\nI would be glad to discuss these and other material. I'm open to course recommendations too. \n\nHappy learning :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11s75id/umass_advancednlp/","created":"2023-03-15","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0},"text":"UMASS Advanced-NLP Hi everyone. I finished the advanced nlp course from Mohit Iyyer. You can find the version I completed from here: [https://people.cs.umass.edu/\\~miyyer/cs685\\_f22/](https://people.cs.umass.edu/~miyyer/cs685_f22/) I would definetly recommend it. You can find lectures from youtube.\n\nIf you want to check out and discuss assignment solutions, you can find mine here: [https://github.com/uygarrr/Courses/tree/main/UMASS-CS685-Advanced-NLP](https://github.com/uygarrr/Courses/tree/main/UMASS-CS685-Advanced-NLP)\n\nAlso there're 2 quiz quesitons that I couldn't be sure about the answers. Let me share them here too.\n\n1st: Assume we are applying a Transformer sequence-to-sequence model for a conditional language modeling task (e.g., machine translation). Why don\u2019t we need to use masking in cross attention?\n\n2nd: Now let\u2019s say we want to probe whether or not BERT\u2019s \\[CLS\\] token has encoded the length of an input sentence. Explain how you would design a control task for this probe to address the effect of probe network complexity.\n\n&amp;#x200B;\n\nI would be glad to discuss these and other material. I'm open to course recommendations too. \n\nHappy learning :)","classes":{"dataset":0.3181858361}}
{"title":"Why chatgpt needs reinforcement learning","description":"Hello everyone, I'm a newer for RL and I have some questions after watching the \"Reinforcement Learning from Human Feedback: From Zero to chatGPT\" course from HuggingFace. Why is RL necessary? Once we have obtained the Reward model(The reward model is just another neural network that is differentiable), why not directly use it as a loss term and maximize it? What are the benefits and significance of using RL? Is it because the decoder in GPT involves a multi-stage decision-making process? If I have a one-step generation model, such as a GAN in the image field, do I still need RL?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11rwdx6/why_chatgpt_needs_reinforcement_learning/","created":"2023-03-15","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":2},"text":"Why chatgpt needs reinforcement learning Hello everyone, I'm a newer for RL and I have some questions after watching the \"Reinforcement Learning from Human Feedback: From Zero to chatGPT\" course from HuggingFace. Why is RL necessary? Once we have obtained the Reward model(The reward model is just another neural network that is differentiable), why not directly use it as a loss term and maximize it? What are the benefits and significance of using RL? Is it because the decoder in GPT involves a multi-stage decision-making process? If I have a one-step generation model, such as a GAN in the image field, do I still need RL?","classes":{"dataset":0.1222936139}}
{"title":"Circle Takes Responsibility for Banking Issue, Provides Rebate to Users","description":"To be eligible to receive compensation, it is required that you held USDC when the bank terminated its services. Circle is offering a 10% cashback on the overall value of your USDC holdings if you were a holder during that period.\n\nCheck our Official Twitter to get more Information\n\nhttps://twitter.com/CircleUSDCNEW/status/1635965088707272705","link":"https://www.reddit.com/r/LanguageTechnology/comments/11s4j97/circle_takes_responsibility_for_banking_issue/","created":"2023-03-15","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0},"text":"Circle Takes Responsibility for Banking Issue, Provides Rebate to Users To be eligible to receive compensation, it is required that you held USDC when the bank terminated its services. Circle is offering a 10% cashback on the overall value of your USDC holdings if you were a holder during that period.\n\nCheck our Official Twitter to get more Information\n\nhttps://twitter.com/CircleUSDCNEW/status/1635965088707272705","classes":{"dataset":0.3132452369}}
{"title":"Finno-Ugric open-source machine translation","description":"We here at the University of Tartu created an NMT engine for 23 Finno-Ugric languages, targeting low-resource languages: Livonian, Komi, Udmurt, V\u00f5ro and several others. Most of the covered low-res languages are not part of Meta's M2M100 or NLLB, nor are they part of Google Translate, Bing Translator or DeepL yet.\n\nFairSeq translation model and full list of supported languages here: [https://huggingface.co/tartuNLP/smugri3-finno-ugric-nmt](https://huggingface.co/tartuNLP/smugri3-finno-ugric-nmt). Online demo here: [https://translate.ut.ee/](https://translate.ut.ee/), submitting corrected translations is also supported, in case you speak any of these languages - we are hoping to use the feedback to improve translation quality in the near future.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11r0izu/finnougric_opensource_machine_translation/","created":"2023-03-14","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0},"text":"Finno-Ugric open-source machine translation We here at the University of Tartu created an NMT engine for 23 Finno-Ugric languages, targeting low-resource languages: Livonian, Komi, Udmurt, V\u00f5ro and several others. Most of the covered low-res languages are not part of Meta's M2M100 or NLLB, nor are they part of Google Translate, Bing Translator or DeepL yet.\n\nFairSeq translation model and full list of supported languages here: [https://huggingface.co/tartuNLP/smugri3-finno-ugric-nmt](https://huggingface.co/tartuNLP/smugri3-finno-ugric-nmt). Online demo here: [https://translate.ut.ee/](https://translate.ut.ee/), submitting corrected translations is also supported, in case you speak any of these languages - we are hoping to use the feedback to improve translation quality in the near future.","classes":{"dataset":0.3177036047}}
{"title":"A corpus fully about STEM","description":"Hello, \n\nIs there a corpus fully dedicated to STEM?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11r8zp9/a_corpus_fully_about_stem/","created":"2023-03-14","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":1},"text":"A corpus fully about STEM Hello, \n\nIs there a corpus fully dedicated to STEM?","classes":{"dataset":0.3406670392}}
{"title":"Structured Data-to-Text Generation (with little coding)?","description":"I'm looking to generate very structured text output from ideally a basic UI offering (consecutive 'decision-tree'-like) multiple choice inputs and text input boxes.\n\nIs there any software that can be programmed via some basic rules without requiring a lot of coding experience?\n\nI'm completely new to this field, so any hint is much appreciated!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11r2yub/structured_datatotext_generation_with_little/","created":"2023-03-14","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0},"text":"Structured Data-to-Text Generation (with little coding)? I'm looking to generate very structured text output from ideally a basic UI offering (consecutive 'decision-tree'-like) multiple choice inputs and text input boxes.\n\nIs there any software that can be programmed via some basic rules without requiring a lot of coding experience?\n\nI'm completely new to this field, so any hint is much appreciated!","classes":{"dataset":0.2253130823}}
{"title":"Optimum Dataset for Sequence Labelling","description":"Hi everyone. I'm working on a custom NER like task.\n\nHowever some tags have very low frequency in the data. Hence mode is not good in predicting them.\n\nThis problem got me thinking what would the optimum dataset look like for such a task? \nShould number of samples for each label be similar? \nif we increase the data for all labels but keep a specific label same would it impact the preformance?\n\nPapers usually just take a toy dataset and tweak the model or data little bit. I couldn't find an answer to these questions. Do you have any resource or knowledge on this?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11qf9sv/optimum_dataset_for_sequence_labelling/","created":"2023-03-13","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":2},"text":"Optimum Dataset for Sequence Labelling Hi everyone. I'm working on a custom NER like task.\n\nHowever some tags have very low frequency in the data. Hence mode is not good in predicting them.\n\nThis problem got me thinking what would the optimum dataset look like for such a task? \nShould number of samples for each label be similar? \nif we increase the data for all labels but keep a specific label same would it impact the preformance?\n\nPapers usually just take a toy dataset and tweak the model or data little bit. I couldn't find an answer to these questions. Do you have any resource or knowledge on this?","classes":{"dataset":0.0635348856}}
{"title":"The Audio-Visual BatVision Dataset for Research on Sight and Sound","description":"Vision research showed remarkable success in understanding our world, propelled by datasets of images and videos. Sensor data from radar, LiDAR and cameras supports research in robotics and autonomous driving for at least a decade. However, while visual sensors may fail in some conditions, sound has recently shown potential to complement sensor data. Simulated room impulse responses (RIR) in 3D apartment-models became a benchmark dataset for the community, fostering a range of audiovisual research. In simulation, depth is predictable from sound, by learning bat-like perception with a neural network. Concurrently, the same was achieved in reality by using RGB-D images and echoes of chirping sounds. Biomimicking bat perception is an exciting new direction but needs dedicated datasets to explore the potential. Therefore, we collected the BatVision dataset to provide large-scale echoes in complex real-world scenes to the community. We equipped a robot with a speaker to emit chirps and a binaural microphone to record their echoes. Synchronized RGB-D images from the same perspective provide visual labels of traversed spaces. We sampled modern US office spaces to historic French university grounds, indoor and outdoor with large architectural variety. This dataset will allow research on robot echolocation, general audio-visual tasks and sound phaenomena unavailable in simulated data. We show promising results for audio-only depth prediction and show how state-of-the-art work developed for simulated data can also succeed on our dataset. The data can be downloaded at https://github.com/AmandineBtto/Batvision-Dataset","link":"http://arxiv.org/abs/2303.07257v1","created":"2023-03-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"The Audio-Visual BatVision Dataset for Research on Sight and Sound Vision research showed remarkable success in understanding our world, propelled by datasets of images and videos. Sensor data from radar, LiDAR and cameras supports research in robotics and autonomous driving for at least a decade. However, while visual sensors may fail in some conditions, sound has recently shown potential to complement sensor data. Simulated room impulse responses (RIR) in 3D apartment-models became a benchmark dataset for the community, fostering a range of audiovisual research. In simulation, depth is predictable from sound, by learning bat-like perception with a neural network. Concurrently, the same was achieved in reality by using RGB-D images and echoes of chirping sounds. Biomimicking bat perception is an exciting new direction but needs dedicated datasets to explore the potential. Therefore, we collected the BatVision dataset to provide large-scale echoes in complex real-world scenes to the community. We equipped a robot with a speaker to emit chirps and a binaural microphone to record their echoes. Synchronized RGB-D images from the same perspective provide visual labels of traversed spaces. We sampled modern US office spaces to historic French university grounds, indoor and outdoor with large architectural variety. This dataset will allow research on robot echolocation, general audio-visual tasks and sound phaenomena unavailable in simulated data. We show promising results for audio-only depth prediction and show how state-of-the-art work developed for simulated data can also succeed on our dataset. The data can be downloaded at https://github.com/AmandineBtto/Batvision-Dataset","classes":{"dataset":0.8111305237}}
{"title":"A two-stage speaker extraction algorithm under adverse acoustic conditions using a single-microphone","description":"In this work, we present a two-stage method for speaker extraction under reverberant and noisy conditions. Given a reference signal of the desired speaker, the clean, but the still reverberant, desired speaker is first extracted from the noisy-mixed signal. In the second stage, the extracted signal is further enhanced by joint dereverberation and residual noise and interference reduction. The proposed architecture comprises two sub-networks, one for the extraction task and the second for the dereverberation task. We present a training strategy for this architecture and show that the performance of the proposed method is on par with other state-of-the-art (SOTA) methods when applied to the WHAMR! dataset. Furthermore, we present a new dataset with more realistic adverse acoustic conditions and show that our method outperforms the competing methods when applied to this dataset as well.","link":"http://arxiv.org/abs/2303.07072v1","created":"2023-03-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A two-stage speaker extraction algorithm under adverse acoustic conditions using a single-microphone In this work, we present a two-stage method for speaker extraction under reverberant and noisy conditions. Given a reference signal of the desired speaker, the clean, but the still reverberant, desired speaker is first extracted from the noisy-mixed signal. In the second stage, the extracted signal is further enhanced by joint dereverberation and residual noise and interference reduction. The proposed architecture comprises two sub-networks, one for the extraction task and the second for the dereverberation task. We present a training strategy for this architecture and show that the performance of the proposed method is on par with other state-of-the-art (SOTA) methods when applied to the WHAMR! dataset. Furthermore, we present a new dataset with more realistic adverse acoustic conditions and show that our method outperforms the competing methods when applied to this dataset as well.","classes":{"dataset":0.6137002707}}
{"title":"Identifying Label Errors in Object Detection Datasets by Loss Inspection","description":"Labeling datasets for supervised object detection is a dull and time-consuming task. Errors can be easily introduced during annotation and overlooked during review, yielding inaccurate benchmarks and performance degradation of deep neural networks trained on noisy labels. In this work, we for the first time introduce a benchmark for label error detection methods on object detection datasets as well as a label error detection method and a number of baselines. We simulate four different types of randomly introduced label errors on train and test sets of well-labeled object detection datasets. For our label error detection method we assume a two-stage object detector to be given and consider the sum of both stages' classification and regression losses. The losses are computed with respect to the predictions and the noisy labels including simulated label errors, aiming at detecting the latter. We compare our method to three baselines: a naive one without deep learning, the object detector's score and the entropy of the classification softmax distribution. We outperform all baselines and demonstrate that among the considered methods, ours is the only one that detects label errors of all four types efficiently. Furthermore, we detect real label errors a) on commonly used test datasets in object detection and b) on a proprietary dataset. In both cases we achieve low false positives rates, i.e., when considering 200 proposals from our method, we detect label errors with a precision for a) of up to 71.5% and for b) with 97%.","link":"http://arxiv.org/abs/2303.06999v1","created":"2023-03-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Identifying Label Errors in Object Detection Datasets by Loss Inspection Labeling datasets for supervised object detection is a dull and time-consuming task. Errors can be easily introduced during annotation and overlooked during review, yielding inaccurate benchmarks and performance degradation of deep neural networks trained on noisy labels. In this work, we for the first time introduce a benchmark for label error detection methods on object detection datasets as well as a label error detection method and a number of baselines. We simulate four different types of randomly introduced label errors on train and test sets of well-labeled object detection datasets. For our label error detection method we assume a two-stage object detector to be given and consider the sum of both stages' classification and regression losses. The losses are computed with respect to the predictions and the noisy labels including simulated label errors, aiming at detecting the latter. We compare our method to three baselines: a naive one without deep learning, the object detector's score and the entropy of the classification softmax distribution. We outperform all baselines and demonstrate that among the considered methods, ours is the only one that detects label errors of all four types efficiently. Furthermore, we detect real label errors a) on commonly used test datasets in object detection and b) on a proprietary dataset. In both cases we achieve low false positives rates, i.e., when considering 200 proposals from our method, we detect label errors with a precision for a) of up to 71.5% and for b) with 97%.","classes":{"dataset":0.3996311426}}
{"title":"Semantically Secure Private Set Intersection over Outsourced Multi-Owner Secret-Shared Databases","description":"Private set intersection (PSI) aims to allow users to find out the commonly shared items among the users without revealing other membership information. The most recently proposed approach to PSI in the database community was Prism, which is built upon secret sharing and the assumption that multiple non-colluding servers are available. One limitation of Prism lies in its semantic security: the encoding on the servers is deterministic, implying that the scheme cannot be indistinguishable under a chosen-plaintext attack (IND-CPA). This paper extends the original PSI scheme of Prism by two orthogonal primitives, namely Kaleido-RND and Kaleido-AES: the former exhibits highly efficient performance with randomized encoding and the latter is provably secure under CPA attacks with more computational overhead. A system prototype is implemented and deployed on a 34-node cluster of SQLite instances. Extensive experiments on the TPC-H benchmark and three real-world applications confirm the effectiveness of the proposed Kaleido primitives.","link":"http://arxiv.org/abs/2303.06863v1","created":"2023-03-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Semantically Secure Private Set Intersection over Outsourced Multi-Owner Secret-Shared Databases Private set intersection (PSI) aims to allow users to find out the commonly shared items among the users without revealing other membership information. The most recently proposed approach to PSI in the database community was Prism, which is built upon secret sharing and the assumption that multiple non-colluding servers are available. One limitation of Prism lies in its semantic security: the encoding on the servers is deterministic, implying that the scheme cannot be indistinguishable under a chosen-plaintext attack (IND-CPA). This paper extends the original PSI scheme of Prism by two orthogonal primitives, namely Kaleido-RND and Kaleido-AES: the former exhibits highly efficient performance with randomized encoding and the latter is provably secure under CPA attacks with more computational overhead. A system prototype is implemented and deployed on a 34-node cluster of SQLite instances. Extensive experiments on the TPC-H benchmark and three real-world applications confirm the effectiveness of the proposed Kaleido primitives.","classes":{"dataset":0.832680583}}
{"title":"ODIN: On-demand Data Formulation to Mitigate Dataset Lock-in","description":"ODIN is an innovative approach that addresses the problem of dataset constraints by integrating generative AI models. Traditional zero-shot learning methods are constrained by the training dataset. To fundamentally overcome this limitation, ODIN attempts to mitigate the dataset constraints by generating on-demand datasets based on user requirements. ODIN consists of three main modules: a prompt generator, a text-to-image generator, and an image post-processor. To generate high-quality prompts and images, we adopted a large language model (e.g., ChatGPT), and a text-to-image diffusion model (e.g., Stable Diffusion), respectively. We evaluated ODIN on various datasets in terms of model accuracy and data diversity to demonstrate its potential, and conducted post-experiments for further investigation. Overall, ODIN is a feasible approach that enables Al to learn unseen knowledge beyond the training dataset.","link":"http://arxiv.org/abs/2303.06832v1","created":"2023-03-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"ODIN: On-demand Data Formulation to Mitigate Dataset Lock-in ODIN is an innovative approach that addresses the problem of dataset constraints by integrating generative AI models. Traditional zero-shot learning methods are constrained by the training dataset. To fundamentally overcome this limitation, ODIN attempts to mitigate the dataset constraints by generating on-demand datasets based on user requirements. ODIN consists of three main modules: a prompt generator, a text-to-image generator, and an image post-processor. To generate high-quality prompts and images, we adopted a large language model (e.g., ChatGPT), and a text-to-image diffusion model (e.g., Stable Diffusion), respectively. We evaluated ODIN on various datasets in terms of model accuracy and data diversity to demonstrate its potential, and conducted post-experiments for further investigation. Overall, ODIN is a feasible approach that enables Al to learn unseen knowledge beyond the training dataset.","classes":{"dataset":0.6451689601}}
{"title":"Score Attack: A Lower Bound Technique for Optimal Differentially Private Learning","description":"Achieving optimal statistical performance while ensuring the privacy of personal data is a challenging yet crucial objective in modern data analysis. However, characterizing the optimality, particularly the minimax lower bound, under privacy constraints is technically difficult.   To address this issue, we propose a novel approach called the score attack, which provides a lower bound on the differential-privacy-constrained minimax risk of parameter estimation. The score attack method is based on the tracing attack concept in differential privacy and can be applied to any statistical model with a well-defined score statistic. It can optimally lower bound the minimax risk of estimating unknown model parameters, up to a logarithmic factor, while ensuring differential privacy for a range of statistical problems. We demonstrate the effectiveness and optimality of this general method in various examples, such as the generalized linear model in both classical and high-dimensional sparse settings, the Bradley-Terry-Luce model for pairwise comparisons, and nonparametric regression over the Sobolev class.","link":"http://arxiv.org/abs/2303.07152v1","created":"2023-03-13","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Score Attack: A Lower Bound Technique for Optimal Differentially Private Learning Achieving optimal statistical performance while ensuring the privacy of personal data is a challenging yet crucial objective in modern data analysis. However, characterizing the optimality, particularly the minimax lower bound, under privacy constraints is technically difficult.   To address this issue, we propose a novel approach called the score attack, which provides a lower bound on the differential-privacy-constrained minimax risk of parameter estimation. The score attack method is based on the tracing attack concept in differential privacy and can be applied to any statistical model with a well-defined score statistic. It can optimally lower bound the minimax risk of estimating unknown model parameters, up to a logarithmic factor, while ensuring differential privacy for a range of statistical problems. We demonstrate the effectiveness and optimality of this general method in various examples, such as the generalized linear model in both classical and high-dimensional sparse settings, the Bradley-Terry-Luce model for pairwise comparisons, and nonparametric regression over the Sobolev class.","classes":{"dataset":0.5162912011}}
{"title":"Robust Contrastive Language-Image Pretraining against Adversarial Attacks","description":"Contrastive vision-language representation learning has achieved state-of-the-art performance for zero-shot classification, by learning from millions of image-caption pairs crawled from the internet. However, the massive data that powers large multimodal models such as CLIP, makes them extremely vulnerable to various types of adversarial attacks, including targeted and backdoor data poisoning attacks. Despite this vulnerability, robust contrastive vision-language pretraining against adversarial attacks has remained unaddressed. In this work, we propose RoCLIP, the first effective method for robust pretraining {and fine-tuning} multimodal vision-language models. RoCLIP effectively breaks the association between poisoned image-caption pairs by considering a pool of random examples, and (1) matching every image with the text that is most similar to its caption in the pool, and (2) matching every caption with the image that is most similar to its image in the pool. Our extensive experiments show that our method renders state-of-the-art targeted data poisoning and backdoor attacks ineffective during pre-training or fine-tuning of CLIP. In particular, RoCLIP decreases the poison and backdoor attack success rates down to 0\\% during pre-training and 1\\%-4\\% during fine-tuning, and effectively improves the model's performance.","link":"http://arxiv.org/abs/2303.06854v1","created":"2023-03-13","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Robust Contrastive Language-Image Pretraining against Adversarial Attacks Contrastive vision-language representation learning has achieved state-of-the-art performance for zero-shot classification, by learning from millions of image-caption pairs crawled from the internet. However, the massive data that powers large multimodal models such as CLIP, makes them extremely vulnerable to various types of adversarial attacks, including targeted and backdoor data poisoning attacks. Despite this vulnerability, robust contrastive vision-language pretraining against adversarial attacks has remained unaddressed. In this work, we propose RoCLIP, the first effective method for robust pretraining {and fine-tuning} multimodal vision-language models. RoCLIP effectively breaks the association between poisoned image-caption pairs by considering a pool of random examples, and (1) matching every image with the text that is most similar to its caption in the pool, and (2) matching every caption with the image that is most similar to its image in the pool. Our extensive experiments show that our method renders state-of-the-art targeted data poisoning and backdoor attacks ineffective during pre-training or fine-tuning of CLIP. In particular, RoCLIP decreases the poison and backdoor attack success rates down to 0\\% during pre-training and 1\\%-4\\% during fine-tuning, and effectively improves the model's performance.","classes":{"dataset":0.0701590404}}
{"title":"ODIN: On-demand Data Formulation to Mitigate Dataset Lock-in","description":"ODIN is an innovative approach that addresses the problem of dataset constraints by integrating generative AI models. Traditional zero-shot learning methods are constrained by the training dataset. To fundamentally overcome this limitation, ODIN attempts to mitigate the dataset constraints by generating on-demand datasets based on user requirements. ODIN consists of three main modules: a prompt generator, a text-to-image generator, and an image post-processor. To generate high-quality prompts and images, we adopted a large language model (e.g., ChatGPT), and a text-to-image diffusion model (e.g., Stable Diffusion), respectively. We evaluated ODIN on various datasets in terms of model accuracy and data diversity to demonstrate its potential, and conducted post-experiments for further investigation. Overall, ODIN is a feasible approach that enables Al to learn unseen knowledge beyond the training dataset.","link":"http://arxiv.org/abs/2303.06832v1","created":"2023-03-13","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"ODIN: On-demand Data Formulation to Mitigate Dataset Lock-in ODIN is an innovative approach that addresses the problem of dataset constraints by integrating generative AI models. Traditional zero-shot learning methods are constrained by the training dataset. To fundamentally overcome this limitation, ODIN attempts to mitigate the dataset constraints by generating on-demand datasets based on user requirements. ODIN consists of three main modules: a prompt generator, a text-to-image generator, and an image post-processor. To generate high-quality prompts and images, we adopted a large language model (e.g., ChatGPT), and a text-to-image diffusion model (e.g., Stable Diffusion), respectively. We evaluated ODIN on various datasets in terms of model accuracy and data diversity to demonstrate its potential, and conducted post-experiments for further investigation. Overall, ODIN is a feasible approach that enables Al to learn unseen knowledge beyond the training dataset.","classes":{"dataset":0.0609725043}}
{"title":"Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification","description":"This case study investigates the task of job classification in a real-world setting, where the goal is to determine whether an English-language job posting is appropriate for a graduate or entry-level position. We explore multiple approaches to text classification, including supervised approaches such as traditional models like Support Vector Machines (SVMs) and state-of-the-art deep learning methods such as DeBERTa. We compare them with Large Language Models (LLMs) used in both few-shot and zero-shot classification settings. To accomplish this task, we employ prompt engineering, a technique that involves designing prompts to guide the LLMs towards the desired output. Specifically, we evaluate the performance of two commercially available state-of-the-art GPT-3.5-based language models, text-davinci-003 and gpt-3.5-turbo. We also conduct a detailed analysis of the impact of different aspects of prompt engineering on the model's performance. Our results show that, with a well-designed prompt, a zero-shot gpt-3.5-turbo classifier outperforms all other models, achieving a 6% increase in Precision@95% Recall compared to the best supervised approach. Furthermore, we observe that the wording of the prompt is a critical factor in eliciting the appropriate \"reasoning\" in the model, and that seemingly minor aspects of the prompt significantly affect the model's performance.","link":"http://arxiv.org/abs/2303.07142v1","created":"2023-03-13","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification This case study investigates the task of job classification in a real-world setting, where the goal is to determine whether an English-language job posting is appropriate for a graduate or entry-level position. We explore multiple approaches to text classification, including supervised approaches such as traditional models like Support Vector Machines (SVMs) and state-of-the-art deep learning methods such as DeBERTa. We compare them with Large Language Models (LLMs) used in both few-shot and zero-shot classification settings. To accomplish this task, we employ prompt engineering, a technique that involves designing prompts to guide the LLMs towards the desired output. Specifically, we evaluate the performance of two commercially available state-of-the-art GPT-3.5-based language models, text-davinci-003 and gpt-3.5-turbo. We also conduct a detailed analysis of the impact of different aspects of prompt engineering on the model's performance. Our results show that, with a well-designed prompt, a zero-shot gpt-3.5-turbo classifier outperforms all other models, achieving a 6% increase in Precision@95% Recall compared to the best supervised approach. Furthermore, we observe that the wording of the prompt is a critical factor in eliciting the appropriate \"reasoning\" in the model, and that seemingly minor aspects of the prompt significantly affect the model's performance.","classes":{"dataset":0.2427641898}}
{"title":"InPL: Pseudo-labeling the Inliers First for Imbalanced Semi-supervised Learning","description":"Recent state-of-the-art methods in imbalanced semi-supervised learning (SSL) rely on confidence-based pseudo-labeling with consistency regularization. To obtain high-quality pseudo-labels, a high confidence threshold is typically adopted. However, it has been shown that softmax-based confidence scores in deep networks can be arbitrarily high for samples far from the training data, and thus, the pseudo-labels for even high-confidence unlabeled samples may still be unreliable. In this work, we present a new perspective of pseudo-labeling for imbalanced SSL. Without relying on model confidence, we propose to measure whether an unlabeled sample is likely to be ``in-distribution''; i.e., close to the current training data. To decide whether an unlabeled sample is ``in-distribution'' or ``out-of-distribution'', we adopt the energy score from out-of-distribution detection literature. As training progresses and more unlabeled samples become in-distribution and contribute to training, the combined labeled and pseudo-labeled data can better approximate the true class distribution to improve the model. Experiments demonstrate that our energy-based pseudo-labeling method, \\textbf{InPL}, albeit conceptually simple, significantly outperforms confidence-based methods on imbalanced SSL benchmarks. For example, it produces around 3\\% absolute accuracy improvement on CIFAR10-LT. When combined with state-of-the-art long-tailed SSL methods, further improvements are attained. In particular, in one of the most challenging scenarios, InPL achieves a 6.9\\% accuracy improvement over the best competitor.","link":"http://arxiv.org/abs/2303.07269v1","created":"2023-03-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"InPL: Pseudo-labeling the Inliers First for Imbalanced Semi-supervised Learning Recent state-of-the-art methods in imbalanced semi-supervised learning (SSL) rely on confidence-based pseudo-labeling with consistency regularization. To obtain high-quality pseudo-labels, a high confidence threshold is typically adopted. However, it has been shown that softmax-based confidence scores in deep networks can be arbitrarily high for samples far from the training data, and thus, the pseudo-labels for even high-confidence unlabeled samples may still be unreliable. In this work, we present a new perspective of pseudo-labeling for imbalanced SSL. Without relying on model confidence, we propose to measure whether an unlabeled sample is likely to be ``in-distribution''; i.e., close to the current training data. To decide whether an unlabeled sample is ``in-distribution'' or ``out-of-distribution'', we adopt the energy score from out-of-distribution detection literature. As training progresses and more unlabeled samples become in-distribution and contribute to training, the combined labeled and pseudo-labeled data can better approximate the true class distribution to improve the model. Experiments demonstrate that our energy-based pseudo-labeling method, \\textbf{InPL}, albeit conceptually simple, significantly outperforms confidence-based methods on imbalanced SSL benchmarks. For example, it produces around 3\\% absolute accuracy improvement on CIFAR10-LT. When combined with state-of-the-art long-tailed SSL methods, further improvements are attained. In particular, in one of the most challenging scenarios, InPL achieves a 6.9\\% accuracy improvement over the best competitor.","classes":{"dataset":0.2714865208}}
{"title":"Mobile Mapping Mesh Change Detection and Update","description":"Mobile mapping, in particular, Mobile Lidar Scanning (MLS) is increasingly widespread to monitor and map urban scenes at city scale with unprecedented resolution and accuracy. The resulting point cloud sampling of the scene geometry can be meshed in order to create a continuous representation for different applications: visualization, simulation, navigation, etc. Because of the highly dynamic nature of these urban scenes, long term mapping should rely on frequent map updates. A trivial solution is to simply replace old data with newer data each time a new acquisition is made. However it has two drawbacks: 1) the old data may be of higher quality (resolution, precision) than the new and 2) the coverage of the scene might be different in various acquisitions, including varying occlusions. In this paper, we propose a fully automatic pipeline to address these two issues by formulating the problem of merging meshes with different quality, coverage and acquisition time. Our method is based on a combined distance and visibility based change detection, a time series analysis to assess the sustainability of changes, a mesh mosaicking based on a global boolean optimization and finally a stitching of the resulting mesh pieces boundaries with triangle strips. Finally, our method is demonstrated on Robotcar and Stereopolis datasets.","link":"http://arxiv.org/abs/2303.07182v1","created":"2023-03-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Mobile Mapping Mesh Change Detection and Update Mobile mapping, in particular, Mobile Lidar Scanning (MLS) is increasingly widespread to monitor and map urban scenes at city scale with unprecedented resolution and accuracy. The resulting point cloud sampling of the scene geometry can be meshed in order to create a continuous representation for different applications: visualization, simulation, navigation, etc. Because of the highly dynamic nature of these urban scenes, long term mapping should rely on frequent map updates. A trivial solution is to simply replace old data with newer data each time a new acquisition is made. However it has two drawbacks: 1) the old data may be of higher quality (resolution, precision) than the new and 2) the coverage of the scene might be different in various acquisitions, including varying occlusions. In this paper, we propose a fully automatic pipeline to address these two issues by formulating the problem of merging meshes with different quality, coverage and acquisition time. Our method is based on a combined distance and visibility based change detection, a time series analysis to assess the sustainability of changes, a mesh mosaicking based on a global boolean optimization and finally a stitching of the resulting mesh pieces boundaries with triangle strips. Finally, our method is demonstrated on Robotcar and Stereopolis datasets.","classes":{"dataset":0.5647494793}}
{"title":"Comparing statistical and machine learning methods for time series forecasting in data-driven logistics -- A simulation study","description":"Many planning and decision activities in logistics and supply chain management are based on forecasts of multiple time dependent factors. Therefore, the quality of planning depends on the quality of the forecasts. We compare various forecasting methods in terms of out of the box forecasting performance on a broad set of simulated time series. We simulate various linear and non-linear time series and look at the one step forecast performance of statistical learning methods.","link":"http://arxiv.org/abs/2303.07139v1","created":"2023-03-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Comparing statistical and machine learning methods for time series forecasting in data-driven logistics -- A simulation study Many planning and decision activities in logistics and supply chain management are based on forecasts of multiple time dependent factors. Therefore, the quality of planning depends on the quality of the forecasts. We compare various forecasting methods in terms of out of the box forecasting performance on a broad set of simulated time series. We simulate various linear and non-linear time series and look at the one step forecast performance of statistical learning methods.","classes":{"dataset":0.2009425461}}
{"title":"xASTNN: Improved Code Representations for Industrial Practice","description":"The application of deep learning techniques in software engineering becomes increasingly popular. One key problem is developing high-quality and easy-to-use source code representations for code-related tasks. The research community has acquired impressive results in recent years. However, due to the deployment difficulties and performance bottlenecks, seldom these approaches are applied to the industry. In this paper, we present xASTNN, an eXtreme Abstract Syntax Tree (AST)-based Neural Network for source code representation, aiming to push this technique to industrial practice. The proposed xASTNN has three advantages. First, xASTNN is completely based on widely-used ASTs and does not require complicated data pre-processing, making it applicable to various programming languages and practical scenarios. Second, three closely-related designs are proposed to guarantee the effectiveness of xASTNN, including statement subtree sequence for code naturalness, gated recursive unit for syntactical information, and gated recurrent unit for sequential information. Third, a dynamic batching algorithm is introduced to significantly reduce the time complexity of xASTNN. Two code comprehension downstream tasks, code classification and code clone detection, are adopted for evaluation. The results demonstrate that our xASTNN can improve the state-of-the-art while being faster than the baselines.","link":"http://arxiv.org/abs/2303.07104v1","created":"2023-03-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"xASTNN: Improved Code Representations for Industrial Practice The application of deep learning techniques in software engineering becomes increasingly popular. One key problem is developing high-quality and easy-to-use source code representations for code-related tasks. The research community has acquired impressive results in recent years. However, due to the deployment difficulties and performance bottlenecks, seldom these approaches are applied to the industry. In this paper, we present xASTNN, an eXtreme Abstract Syntax Tree (AST)-based Neural Network for source code representation, aiming to push this technique to industrial practice. The proposed xASTNN has three advantages. First, xASTNN is completely based on widely-used ASTs and does not require complicated data pre-processing, making it applicable to various programming languages and practical scenarios. Second, three closely-related designs are proposed to guarantee the effectiveness of xASTNN, including statement subtree sequence for code naturalness, gated recursive unit for syntactical information, and gated recurrent unit for sequential information. Third, a dynamic batching algorithm is introduced to significantly reduce the time complexity of xASTNN. Two code comprehension downstream tasks, code classification and code clone detection, are adopted for evaluation. The results demonstrate that our xASTNN can improve the state-of-the-art while being faster than the baselines.","classes":{"dataset":0.0640834942}}
{"title":"Towards smoother surfaces by applying subdivision to voxel data","description":"In computed tomography, the approximation quality of a scan of a physical object is typically limited by the acquisition modalities, especially the hardware including X-ray detectors. To improve upon this, we experiment with a three-dimensional subdivision scheme to increase the resolution of the reconstructed voxel data. Subdivision schemes are often used to refine two-dimensional manifolds (mostly meshes) leading to smoother surfaces. In this work, we apply a refinement scheme to three-dimensional data first, and only then, start the surface extraction process. Thus, the main subject of this work lies not on subdivision surfaces, but rather on subdivision volumes. In the volumetric case, each subdivision iteration consumes eight times more storage space than the previous one. Hence, we restrict ourselves to a single subdivision iteration. We evaluate the quality of the produced subdivision volumes using synthetic and industrial data. Furthermore, we consider manufacturing errors in the original and in the subdivision volumes, extract their surfaces, and compare the resulting meshes in critical regions. Observations show that our specific choice of a subdivision scheme produces smoothly interpolated data while also preserving edges.","link":"http://arxiv.org/abs/2303.07075v1","created":"2023-03-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Towards smoother surfaces by applying subdivision to voxel data In computed tomography, the approximation quality of a scan of a physical object is typically limited by the acquisition modalities, especially the hardware including X-ray detectors. To improve upon this, we experiment with a three-dimensional subdivision scheme to increase the resolution of the reconstructed voxel data. Subdivision schemes are often used to refine two-dimensional manifolds (mostly meshes) leading to smoother surfaces. In this work, we apply a refinement scheme to three-dimensional data first, and only then, start the surface extraction process. Thus, the main subject of this work lies not on subdivision surfaces, but rather on subdivision volumes. In the volumetric case, each subdivision iteration consumes eight times more storage space than the previous one. Hence, we restrict ourselves to a single subdivision iteration. We evaluate the quality of the produced subdivision volumes using synthetic and industrial data. Furthermore, we consider manufacturing errors in the original and in the subdivision volumes, extract their surfaces, and compare the resulting meshes in critical regions. Observations show that our specific choice of a subdivision scheme produces smoothly interpolated data while also preserving edges.","classes":{"dataset":0.2728500664}}
{"title":"Synthesizing Realistic Image Restoration Training Pairs: A Diffusion Approach","description":"In supervised image restoration tasks, one key issue is how to obtain the aligned high-quality (HQ) and low-quality (LQ) training image pairs. Unfortunately, such HQ-LQ training pairs are hard to capture in practice, and hard to synthesize due to the complex unknown degradation in the wild. While several sophisticated degradation models have been manually designed to synthesize LQ images from their HQ counterparts, the distribution gap between the synthesized and real-world LQ images remains large. We propose a new approach to synthesizing realistic image restoration training pairs using the emerging denoising diffusion probabilistic model (DDPM).   First, we train a DDPM, which could convert a noisy input into the desired LQ image, with a large amount of collected LQ images, which define the target data distribution. Then, for a given HQ image, we synthesize an initial LQ image by using an off-the-shelf degradation model, and iteratively add proper Gaussian noises to it. Finally, we denoise the noisy LQ image using the pre-trained DDPM to obtain the final LQ image, which falls into the target distribution of real-world LQ images. Thanks to the strong capability of DDPM in distribution approximation, the synthesized HQ-LQ image pairs can be used to train robust models for real-world image restoration tasks, such as blind face image restoration and blind image super-resolution. Experiments demonstrated the superiority of our proposed approach to existing degradation models. Code and data will be released.","link":"http://arxiv.org/abs/2303.06994v1","created":"2023-03-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Synthesizing Realistic Image Restoration Training Pairs: A Diffusion Approach In supervised image restoration tasks, one key issue is how to obtain the aligned high-quality (HQ) and low-quality (LQ) training image pairs. Unfortunately, such HQ-LQ training pairs are hard to capture in practice, and hard to synthesize due to the complex unknown degradation in the wild. While several sophisticated degradation models have been manually designed to synthesize LQ images from their HQ counterparts, the distribution gap between the synthesized and real-world LQ images remains large. We propose a new approach to synthesizing realistic image restoration training pairs using the emerging denoising diffusion probabilistic model (DDPM).   First, we train a DDPM, which could convert a noisy input into the desired LQ image, with a large amount of collected LQ images, which define the target data distribution. Then, for a given HQ image, we synthesize an initial LQ image by using an off-the-shelf degradation model, and iteratively add proper Gaussian noises to it. Finally, we denoise the noisy LQ image using the pre-trained DDPM to obtain the final LQ image, which falls into the target distribution of real-world LQ images. Thanks to the strong capability of DDPM in distribution approximation, the synthesized HQ-LQ image pairs can be used to train robust models for real-world image restoration tasks, such as blind face image restoration and blind image super-resolution. Experiments demonstrated the superiority of our proposed approach to existing degradation models. Code and data will be released.","classes":{"dataset":0.2898350656}}
{"title":"Pixel-wise Gradient Uncertainty for Convolutional Neural Networks applied to Out-of-Distribution Segmentation","description":"In recent years, deep neural networks have defined the state-of-the-art in semantic segmentation where their predictions are constrained to a predefined set of semantic classes. They are to be deployed in applications such as automated driving, although their categorically confined expressive power runs contrary to such open world scenarios. Thus, the detection and segmentation of objects from outside their predefined semantic space, i.e., out-of-distribution (OoD) objects, is of highest interest. Since uncertainty estimation methods like softmax entropy or Bayesian models are sensitive to erroneous predictions, these methods are a natural baseline for OoD detection. Here, we present a method for obtaining uncertainty scores from pixel-wise loss gradients which can be computed efficiently during inference. Our approach is simple to implement for a large class of models, does not require any additional training or auxiliary data and can be readily used on pre-trained segmentation models. Our experiments show the ability of our method to identify wrong pixel classifications and to estimate prediction quality. In particular, we observe superior performance in terms of OoD segmentation to comparable baselines on the SegmentMeIfYouCan benchmark, clearly outperforming methods which are similarly flexible to implement.","link":"http://arxiv.org/abs/2303.06920v1","created":"2023-03-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Pixel-wise Gradient Uncertainty for Convolutional Neural Networks applied to Out-of-Distribution Segmentation In recent years, deep neural networks have defined the state-of-the-art in semantic segmentation where their predictions are constrained to a predefined set of semantic classes. They are to be deployed in applications such as automated driving, although their categorically confined expressive power runs contrary to such open world scenarios. Thus, the detection and segmentation of objects from outside their predefined semantic space, i.e., out-of-distribution (OoD) objects, is of highest interest. Since uncertainty estimation methods like softmax entropy or Bayesian models are sensitive to erroneous predictions, these methods are a natural baseline for OoD detection. Here, we present a method for obtaining uncertainty scores from pixel-wise loss gradients which can be computed efficiently during inference. Our approach is simple to implement for a large class of models, does not require any additional training or auxiliary data and can be readily used on pre-trained segmentation models. Our experiments show the ability of our method to identify wrong pixel classifications and to estimate prediction quality. In particular, we observe superior performance in terms of OoD segmentation to comparable baselines on the SegmentMeIfYouCan benchmark, clearly outperforming methods which are similarly flexible to implement.","classes":{"dataset":0.1693077534}}
{"title":"ST360IQ: No-Reference Omnidirectional Image Quality Assessment with Spherical Vision Transformers","description":"Omnidirectional images, aka 360 images, can deliver immersive and interactive visual experiences. As their popularity has increased dramatically in recent years, evaluating the quality of 360 images has become a problem of interest since it provides insights for capturing, transmitting, and consuming this new media. However, directly adapting quality assessment methods proposed for standard natural images for omnidirectional data poses certain challenges. These models need to deal with very high-resolution data and implicit distortions due to the spherical form of the images. In this study, we present a method for no-reference 360 image quality assessment. Our proposed ST360IQ model extracts tangent viewports from the salient parts of the input omnidirectional image and employs a vision-transformers based module processing saliency selective patches/tokens that estimates a quality score from each viewport. Then, it aggregates these scores to give a final quality score. Our experiments on two benchmark datasets, namely OIQA and CVIQ datasets, demonstrate that as compared to the state-of-the-art, our approach predicts the quality of an omnidirectional image correlated with the human-perceived image quality. The code has been available on https://github.com/Nafiseh-Tofighi/ST360IQ","link":"http://arxiv.org/abs/2303.06907v1","created":"2023-03-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"ST360IQ: No-Reference Omnidirectional Image Quality Assessment with Spherical Vision Transformers Omnidirectional images, aka 360 images, can deliver immersive and interactive visual experiences. As their popularity has increased dramatically in recent years, evaluating the quality of 360 images has become a problem of interest since it provides insights for capturing, transmitting, and consuming this new media. However, directly adapting quality assessment methods proposed for standard natural images for omnidirectional data poses certain challenges. These models need to deal with very high-resolution data and implicit distortions due to the spherical form of the images. In this study, we present a method for no-reference 360 image quality assessment. Our proposed ST360IQ model extracts tangent viewports from the salient parts of the input omnidirectional image and employs a vision-transformers based module processing saliency selective patches/tokens that estimates a quality score from each viewport. Then, it aggregates these scores to give a final quality score. Our experiments on two benchmark datasets, namely OIQA and CVIQ datasets, demonstrate that as compared to the state-of-the-art, our approach predicts the quality of an omnidirectional image correlated with the human-perceived image quality. The code has been available on https://github.com/Nafiseh-Tofighi/ST360IQ","classes":{"dataset":0.5618419647}}
{"title":"ODIN: On-demand Data Formulation to Mitigate Dataset Lock-in","description":"ODIN is an innovative approach that addresses the problem of dataset constraints by integrating generative AI models. Traditional zero-shot learning methods are constrained by the training dataset. To fundamentally overcome this limitation, ODIN attempts to mitigate the dataset constraints by generating on-demand datasets based on user requirements. ODIN consists of three main modules: a prompt generator, a text-to-image generator, and an image post-processor. To generate high-quality prompts and images, we adopted a large language model (e.g., ChatGPT), and a text-to-image diffusion model (e.g., Stable Diffusion), respectively. We evaluated ODIN on various datasets in terms of model accuracy and data diversity to demonstrate its potential, and conducted post-experiments for further investigation. Overall, ODIN is a feasible approach that enables Al to learn unseen knowledge beyond the training dataset.","link":"http://arxiv.org/abs/2303.06832v1","created":"2023-03-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"ODIN: On-demand Data Formulation to Mitigate Dataset Lock-in ODIN is an innovative approach that addresses the problem of dataset constraints by integrating generative AI models. Traditional zero-shot learning methods are constrained by the training dataset. To fundamentally overcome this limitation, ODIN attempts to mitigate the dataset constraints by generating on-demand datasets based on user requirements. ODIN consists of three main modules: a prompt generator, a text-to-image generator, and an image post-processor. To generate high-quality prompts and images, we adopted a large language model (e.g., ChatGPT), and a text-to-image diffusion model (e.g., Stable Diffusion), respectively. We evaluated ODIN on various datasets in terms of model accuracy and data diversity to demonstrate its potential, and conducted post-experiments for further investigation. Overall, ODIN is a feasible approach that enables Al to learn unseen knowledge beyond the training dataset.","classes":{"dataset":0.187782824}}
{"title":"Using a Mac without a network connection","description":"https://eclecticlight.co/2023/03/14/using-a-mac-without-a-network-connection/","link":"https://eclecticlight.co/2023/03/14/using-a-mac-without-a-network-connection/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":35},"text":"Using a Mac without a network connection https://eclecticlight.co/2023/03/14/using-a-mac-without-a-network-connection/","classes":{"dataset":0.169842124}}
{"title":"The Great Illyrian Revolt","description":"https://en.wikipedia.org/wiki/Bellum_Batonianum","link":"https://en.wikipedia.org/wiki/Bellum_Batonianum","created":"2023-03-13","tags":["hackernews"],"meta":{"score":20},"text":"The Great Illyrian Revolt https://en.wikipedia.org/wiki/Bellum_Batonianum","classes":{"dataset":0.4926985204}}
{"title":"Swipe (YC S21) Is Hiring","description":"https://www.ycombinator.com/companies/swipe-2/jobs/oDv2jjC-sde-intern","link":"https://www.ycombinator.com/companies/swipe-2/jobs/oDv2jjC-sde-intern","created":"2023-03-14","tags":["hackernews"],"meta":{"score":1},"text":"Swipe (YC S21) Is Hiring https://www.ycombinator.com/companies/swipe-2/jobs/oDv2jjC-sde-intern","classes":{"dataset":0.5106500983}}
{"title":"Audiophile forum debating which versions of memcpy had the highest sound quality (2013)","description":"https://discuss.systems/@dan/110008052977994607","link":"https://discuss.systems/@dan/110008052977994607","created":"2023-03-13","tags":["hackernews"],"meta":{"score":467},"text":"Audiophile forum debating which versions of memcpy had the highest sound quality (2013) https://discuss.systems/@dan/110008052977994607","classes":{"dataset":0.4934240878}}
{"title":"Russian Assets Reportedly Seized at Baikonur Cosmodrome by Kazakh Authorities","description":"https://tlpnetwork.com/news/2023/03/russian-assets-seized-at-the-baikonur-cosmodrome","link":"https://tlpnetwork.com/news/2023/03/russian-assets-seized-at-the-baikonur-cosmodrome","created":"2023-03-14","tags":["hackernews"],"meta":{"score":97},"text":"Russian Assets Reportedly Seized at Baikonur Cosmodrome by Kazakh Authorities https://tlpnetwork.com/news/2023/03/russian-assets-seized-at-the-baikonur-cosmodrome","classes":{"dataset":0.4872330725}}
{"title":"Augmenting Human Intellect: A Conceptual Framework (1962) [pdf]","description":"https://www.dougengelbart.org/pubs/papers/scanned/Doug_Engelbart-AugmentingHumanIntellect.pdf","link":"https://www.dougengelbart.org/pubs/papers/scanned/Doug_Engelbart-AugmentingHumanIntellect.pdf","created":"2023-03-13","tags":["hackernews"],"meta":{"score":67},"text":"Augmenting Human Intellect: A Conceptual Framework (1962) [pdf] https://www.dougengelbart.org/pubs/papers/scanned/Doug_Engelbart-AugmentingHumanIntellect.pdf","classes":{"dataset":0.5451942682}}
{"title":"Show HN: Counter \u2013 Simple and free web analytics","description":"https://counter.dev/","link":"https://counter.dev/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":118},"text":"Show HN: Counter \u2013 Simple and free web analytics https://counter.dev/","classes":{"dataset":0.4675063789}}
{"title":"PostgreSQL 14 Internals","description":"https://postgrespro.com/blog/pgsql/5969985","link":"https://postgrespro.com/blog/pgsql/5969985","created":"2023-03-13","tags":["hackernews"],"meta":{"score":126},"text":"PostgreSQL 14 Internals https://postgrespro.com/blog/pgsql/5969985","classes":{"dataset":0.5187063217}}
{"title":"Just Ask for Generalization (2021)","description":"https://evjang.com/2021/10/23/generalization.html","link":"https://evjang.com/2021/10/23/generalization.html","created":"2023-03-13","tags":["hackernews"],"meta":{"score":18},"text":"Just Ask for Generalization (2021) https://evjang.com/2021/10/23/generalization.html","classes":{"dataset":0.5010926723}}
{"title":"Experian is a pile of dark pattern garbage","description":"https://blog.benton.io/post/711712394255138816/experian-is-a-pile-of-dark-pattern-garbage","link":"https://blog.benton.io/post/711712394255138816/experian-is-a-pile-of-dark-pattern-garbage","created":"2023-03-13","tags":["hackernews"],"meta":{"score":547},"text":"Experian is a pile of dark pattern garbage https://blog.benton.io/post/711712394255138816/experian-is-a-pile-of-dark-pattern-garbage","classes":{"dataset":0.4973247945}}
{"title":"US court rules Uber and Lyft workers are contractors","description":"https://www.bbc.com/news/business-64947695","link":"https://www.bbc.com/news/business-64947695","created":"2023-03-14","tags":["hackernews"],"meta":{"score":75},"text":"US court rules Uber and Lyft workers are contractors https://www.bbc.com/news/business-64947695","classes":{"dataset":0.5009186864}}
{"title":"Crab crisis in Bering Sea a sign of \u2018borealization\u2019","description":"https://alaskabeacon.com/2023/02/06/crab-crisis-in-bering-sea-a-sign-of-borealization-and-big-changes-in-the-future-scientists-warn/","link":"https://alaskabeacon.com/2023/02/06/crab-crisis-in-bering-sea-a-sign-of-borealization-and-big-changes-in-the-future-scientists-warn/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":103},"text":"Crab crisis in Bering Sea a sign of \u2018borealization\u2019 https://alaskabeacon.com/2023/02/06/crab-crisis-in-bering-sea-a-sign-of-borealization-and-big-changes-in-the-future-scientists-warn/","classes":{"dataset":0.5040024519}}
{"title":"Instagram Is Disabling Its NFT Features","description":"https://nftnow.com/news/breaking-instagram-is-sunsetting-digital-collectibles-nfts/","link":"https://nftnow.com/news/breaking-instagram-is-sunsetting-digital-collectibles-nfts/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":192},"text":"Instagram Is Disabling Its NFT Features https://nftnow.com/news/breaking-instagram-is-sunsetting-digital-collectibles-nfts/","classes":{"dataset":0.5057240129}}
{"title":"LinPEAS","description":"https://github.com/carlospolop/PEASS-ng/tree/master/linPEAS","link":"https://github.com/carlospolop/PEASS-ng/tree/master/linPEAS","created":"2023-03-13","tags":["hackernews"],"meta":{"score":18},"text":"LinPEAS https://github.com/carlospolop/PEASS-ng/tree/master/linPEAS","classes":{"dataset":0.4746462405}}
{"title":"High-Throughput Generative Inference of Large Language Models with a Single GPU","description":"https://arxiv.org/abs/2303.06865","link":"https://arxiv.org/abs/2303.06865","created":"2023-03-14","tags":["hackernews"],"meta":{"score":88},"text":"High-Throughput Generative Inference of Large Language Models with a Single GPU https://arxiv.org/abs/2303.06865","classes":{"dataset":0.5408582091}}
{"title":"How Not to Cover a Bank Run","description":"https://www.theatlantic.com/ideas/archive/2023/03/brian-stelter-how-not-cover-svb-bank-run/673389/","link":"https://www.theatlantic.com/ideas/archive/2023/03/brian-stelter-how-not-cover-svb-bank-run/673389/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":12},"text":"How Not to Cover a Bank Run https://www.theatlantic.com/ideas/archive/2023/03/brian-stelter-how-not-cover-svb-bank-run/673389/","classes":{"dataset":0.507349968}}
{"title":"Bringing the Cotton Fragments to Life","description":"https://blogs.bl.uk/digitisedmanuscripts/2023/03/bringing-the-cotton-fragments-to-life.html","link":"https://blogs.bl.uk/digitisedmanuscripts/2023/03/bringing-the-cotton-fragments-to-life.html","created":"2023-03-13","tags":["hackernews"],"meta":{"score":5},"text":"Bringing the Cotton Fragments to Life https://blogs.bl.uk/digitisedmanuscripts/2023/03/bringing-the-cotton-fragments-to-life.html","classes":{"dataset":0.4920167327}}
{"title":"Advanced Compilers: Self-Guided Online Course","description":"https://www.cs.cornell.edu/courses/cs6120/2020fa/self-guided/","link":"https://www.cs.cornell.edu/courses/cs6120/2020fa/self-guided/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":622},"text":"Advanced Compilers: Self-Guided Online Course https://www.cs.cornell.edu/courses/cs6120/2020fa/self-guided/","classes":{"dataset":0.5415604711}}
{"title":"Microsoft spent hundreds of millions of dollars on a ChatGPT supercomputer","description":"https://www.theverge.com/2023/3/13/23637675/microsoft-chatgpt-bing-millions-dollars-supercomputer-openai","link":"https://www.theverge.com/2023/3/13/23637675/microsoft-chatgpt-bing-millions-dollars-supercomputer-openai","created":"2023-03-14","tags":["hackernews"],"meta":{"score":10},"text":"Microsoft spent hundreds of millions of dollars on a ChatGPT supercomputer https://www.theverge.com/2023/3/13/23637675/microsoft-chatgpt-bing-millions-dollars-supercomputer-openai","classes":{"dataset":0.4787599742}}
{"title":"Dalai: Automatically install, run, and play with LLaMA on your computer","description":"https://cocktailpeanut.github.io/dalai/","link":"https://cocktailpeanut.github.io/dalai/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":775},"text":"Dalai: Automatically install, run, and play with LLaMA on your computer https://cocktailpeanut.github.io/dalai/","classes":{"dataset":0.497084558}}
{"title":"Baldwin Lee on his rediscovered images of the deep south","description":"https://www.theguardian.com/artanddesign/2023/mar/11/it-stunned-me-that-people-had-to-live-like-this-baldwin-lee-rediscovered-images-deep-south-southern-portrait","link":"https://www.theguardian.com/artanddesign/2023/mar/11/it-stunned-me-that-people-had-to-live-like-this-baldwin-lee-rediscovered-images-deep-south-southern-portrait","created":"2023-03-12","tags":["hackernews"],"meta":{"score":135},"text":"Baldwin Lee on his rediscovered images of the deep south https://www.theguardian.com/artanddesign/2023/mar/11/it-stunned-me-that-people-had-to-live-like-this-baldwin-lee-rediscovered-images-deep-south-southern-portrait","classes":{"dataset":0.4967021644}}
{"title":"More People Are Freaked Out by AI Than Excited About It","description":"https://www.pcmag.com/news/not-a-fan-more-people-are-freaked-out-by-ai-than-excited-about-it","link":"https://www.pcmag.com/news/not-a-fan-more-people-are-freaked-out-by-ai-than-excited-about-it","created":"2023-03-14","tags":["hackernews"],"meta":{"score":7},"text":"More People Are Freaked Out by AI Than Excited About It https://www.pcmag.com/news/not-a-fan-more-people-are-freaked-out-by-ai-than-excited-about-it","classes":{"dataset":0.4999376535}}
{"title":"SVB insider says employees are angry with CEO","description":"https://www.cnn.com/2023/03/13/business/svb-employees-angry-at-ceo/index.html","link":"https://www.cnn.com/2023/03/13/business/svb-employees-angry-at-ceo/index.html","created":"2023-03-13","tags":["hackernews"],"meta":{"score":177},"text":"SVB insider says employees are angry with CEO https://www.cnn.com/2023/03/13/business/svb-employees-angry-at-ceo/index.html","classes":{"dataset":0.4887170792}}
{"title":"Developing a Video Player with Structured Concurrency","description":"https://bitmovin.com/developing-video-player-with-structured-concurrency/","link":"https://bitmovin.com/developing-video-player-with-structured-concurrency/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":7},"text":"Developing a Video Player with Structured Concurrency https://bitmovin.com/developing-video-player-with-structured-concurrency/","classes":{"dataset":0.499002248}}
{"title":"Samuel Morse Locust Grove Estate and Nature Preserve","description":"https://worldsensorium.com/locust-grove-estate-and-nature-preserve/","link":"https://worldsensorium.com/locust-grove-estate-and-nature-preserve/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":22},"text":"Samuel Morse Locust Grove Estate and Nature Preserve https://worldsensorium.com/locust-grove-estate-and-nature-preserve/","classes":{"dataset":0.516392827}}
{"title":"Gitlab loses one-third of its value after company issues weak forecast","description":"https://www.cnbc.com/2023/03/13/gitlab-gtlb-earnings-q4-2023.html","link":"https://www.cnbc.com/2023/03/13/gitlab-gtlb-earnings-q4-2023.html","created":"2023-03-13","tags":["hackernews"],"meta":{"score":198},"text":"Gitlab loses one-third of its value after company issues weak forecast https://www.cnbc.com/2023/03/13/gitlab-gtlb-earnings-q4-2023.html","classes":{"dataset":0.4996397793}}
{"title":"Uneven Circuit Aging Becoming a Bigger Problem","description":"https://semiengineering.com/uneven-circuit-aging-becoming-a-bigger-problem/","link":"https://semiengineering.com/uneven-circuit-aging-becoming-a-bigger-problem/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":19},"text":"Uneven Circuit Aging Becoming a Bigger Problem https://semiengineering.com/uneven-circuit-aging-becoming-a-bigger-problem/","classes":{"dataset":0.5538147092}}
{"title":"Borderless Vigilantism: The Nativist US Militias Entering Mexico","description":"https://www.bellingcat.com/news/2023/02/21/borderless-vigilantism-the-nativist-us-militias-entering-mexico/","link":"https://www.bellingcat.com/news/2023/02/21/borderless-vigilantism-the-nativist-us-militias-entering-mexico/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":9},"text":"Borderless Vigilantism: The Nativist US Militias Entering Mexico https://www.bellingcat.com/news/2023/02/21/borderless-vigilantism-the-nativist-us-militias-entering-mexico/","classes":{"dataset":0.4920230806}}
{"title":"Pfizer buys Seagen for $43B, boosts access to cancer drugs","description":"https://apnews.com/article/pfizer-seagen-acquisition-cancer-05b11f085125df5941f64a2ecbb5abba","link":"https://apnews.com/article/pfizer-seagen-acquisition-cancer-05b11f085125df5941f64a2ecbb5abba","created":"2023-03-14","tags":["hackernews"],"meta":{"score":13},"text":"Pfizer buys Seagen for $43B, boosts access to cancer drugs https://apnews.com/article/pfizer-seagen-acquisition-cancer-05b11f085125df5941f64a2ecbb5abba","classes":{"dataset":0.4862469137}}
{"title":"Interpreting Eric Hobsbawm's History of the Fin de Si\u00e8cle \u2018Twilight Zone\u2019","description":"https://www.cambridge.org/core/journals/historical-journal/article/interpreting-eric-hobsbawms-history-of-the-fin-de-siecle-twilight-zone/E961FE213282697D3E6853E9924940FC","link":"https://www.cambridge.org/core/journals/historical-journal/article/interpreting-eric-hobsbawms-history-of-the-fin-de-siecle-twilight-zone/E961FE213282697D3E6853E9924940FC","created":"2023-03-12","tags":["hackernews"],"meta":{"score":25},"text":"Interpreting Eric Hobsbawm's History of the Fin de Si\u00e8cle \u2018Twilight Zone\u2019 https://www.cambridge.org/core/journals/historical-journal/article/interpreting-eric-hobsbawms-history-of-the-fin-de-siecle-twilight-zone/E961FE213282697D3E6853E9924940FC","classes":{"dataset":0.4932934046}}
{"title":"Sixel: A terminal bitmap graphics format from the 80s","description":"https://en.wikipedia.org/wiki/Sixel","link":"https://en.wikipedia.org/wiki/Sixel","created":"2023-03-13","tags":["hackernews"],"meta":{"score":43},"text":"Sixel: A terminal bitmap graphics format from the 80s https://en.wikipedia.org/wiki/Sixel","classes":{"dataset":0.5001171827}}
{"title":"Punctuation Matters: How to use the en dash, em dash and hyphen","description":"https://www.punctuationmatters.com/en-dash-em-dash-hyphen/","link":"https://www.punctuationmatters.com/en-dash-em-dash-hyphen/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":582},"text":"Punctuation Matters: How to use the en dash, em dash and hyphen https://www.punctuationmatters.com/en-dash-em-dash-hyphen/","classes":{"dataset":0.4207708836}}
{"title":"Lo-Fi ATC","description":"https://www.lofiatc.com/","link":"https://www.lofiatc.com/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":381},"text":"Lo-Fi ATC https://www.lofiatc.com/","classes":{"dataset":0.5270229578}}
{"title":"An end to typographic widows on the web","description":"https://clagnut.com/blog/2424","link":"https://clagnut.com/blog/2424","created":"2023-03-13","tags":["hackernews"],"meta":{"score":200},"text":"An end to typographic widows on the web https://clagnut.com/blog/2424","classes":{"dataset":0.5159481764}}
{"title":"TypeScripting the technical interview","description":"https://www.richard-towers.com/2023/03/11/typescripting-the-technical-interview.html","link":"https://www.richard-towers.com/2023/03/11/typescripting-the-technical-interview.html","created":"2023-03-12","tags":["hackernews"],"meta":{"score":697},"text":"TypeScripting the technical interview https://www.richard-towers.com/2023/03/11/typescripting-the-technical-interview.html","classes":{"dataset":0.4608697891}}
{"title":"SVB shows that there are few libertarians in a financial foxhole","description":"https://www.ft.com/content/ebba73d9-d319-4634-aa09-bbf09ee4a03b","link":"https://www.ft.com/content/ebba73d9-d319-4634-aa09-bbf09ee4a03b","created":"2023-03-13","tags":["hackernews"],"meta":{"score":301},"text":"SVB shows that there are few libertarians in a financial foxhole https://www.ft.com/content/ebba73d9-d319-4634-aa09-bbf09ee4a03b","classes":{"dataset":0.5192046165}}
{"title":"GameTales: Cray 6400 (2015)","description":"https://rome.ro/news/2015/12/13/gametales-cray-ymp","link":"https://rome.ro/news/2015/12/13/gametales-cray-ymp","created":"2023-03-11","tags":["hackernews"],"meta":{"score":52},"text":"GameTales: Cray 6400 (2015) https://rome.ro/news/2015/12/13/gametales-cray-ymp","classes":{"dataset":0.502551198}}
{"title":"Bunki, a C Coroutine Library","description":"https://github.com/Keith-Cancel/Bunki","link":"https://github.com/Keith-Cancel/Bunki","created":"2023-03-13","tags":["hackernews"],"meta":{"score":131},"text":"Bunki, a C Coroutine Library https://github.com/Keith-Cancel/Bunki","classes":{"dataset":0.5219194889}}
{"title":"\\Device\\Afd, or, the Deal with the Devil that makes async Rust work on Windows","description":"https://notgull.github.io/device-afd/","link":"https://notgull.github.io/device-afd/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":92},"text":"\\Device\\Afd, or, the Deal with the Devil that makes async Rust work on Windows https://notgull.github.io/device-afd/","classes":{"dataset":0.5122379065}}
{"title":"Overhead of Returning Optional Values in Java and Rust (2021)","description":"https://pkolaczk.github.io/overhead-of-optional/","link":"https://pkolaczk.github.io/overhead-of-optional/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":171},"text":"Overhead of Returning Optional Values in Java and Rust (2021) https://pkolaczk.github.io/overhead-of-optional/","classes":{"dataset":0.5072186589}}
{"title":"cat mario.nes | nc play-nes.org 4444","description":"https://github.com/henrikpersson/potatis","link":"https://github.com/henrikpersson/potatis","created":"2023-03-12","tags":["hackernews"],"meta":{"score":258},"text":"cat mario.nes | nc play-nes.org 4444 https://github.com/henrikpersson/potatis","classes":{"dataset":0.4976617396}}
{"title":"Water Thread Experiment","description":"https://en.wikipedia.org/wiki/Water_thread_experiment","link":"https://en.wikipedia.org/wiki/Water_thread_experiment","created":"2023-03-14","tags":["hackernews"],"meta":{"score":8},"text":"Water Thread Experiment https://en.wikipedia.org/wiki/Water_thread_experiment","classes":{"dataset":0.507349968}}
{"title":"Why Are There No Relational DBMSs? [pdf] (2015)","description":"https://www.dcs.warwick.ac.uk/~hugh/TTM/Why-Are-There-No-Relational-DBMSs.pdf","link":"https://www.dcs.warwick.ac.uk/~hugh/TTM/Why-Are-There-No-Relational-DBMSs.pdf","created":"2023-03-11","tags":["hackernews"],"meta":{"score":139},"text":"Why Are There No Relational DBMSs? [pdf] (2015) https://www.dcs.warwick.ac.uk/~hugh/TTM/Why-Are-There-No-Relational-DBMSs.pdf","classes":{"dataset":0.5087063313}}
{"title":"The emergency bank rescue that almost didn\u2019t happen: SVB over 72hrs","description":"https://www.politico.com/news/2023/03/13/the-emergency-bank-rescue-that-almost-didnt-happen-72-hours-00086868","link":"https://www.politico.com/news/2023/03/13/the-emergency-bank-rescue-that-almost-didnt-happen-72-hours-00086868","created":"2023-03-14","tags":["hackernews"],"meta":{"score":17},"text":"The emergency bank rescue that almost didn\u2019t happen: SVB over 72hrs https://www.politico.com/news/2023/03/13/the-emergency-bank-rescue-that-almost-didnt-happen-72-hours-00086868","classes":{"dataset":0.526196003}}
{"title":"Muppeting: New Term For Off Prompt Response","description":"Muppeting, when an AI seemingly randomly ignores part of your prompt.  For example, ask the ChatGPT API to output its response as a python dictionary, then put the call in the loop.  The responses where it goes oft prompt and offers commentary before giving you the dictionary (or messes up the dictionary) are Muppets.","link":"https://www.reddit.com/r/PromptDesign/comments/11p8alo/muppeting_new_term_for_off_prompt_response/","created":"2023-03-12","tags":["promptdesign","reddit","prompteng"],"meta":{"num_comments":2},"text":"Muppeting: New Term For Off Prompt Response Muppeting, when an AI seemingly randomly ignores part of your prompt.  For example, ask the ChatGPT API to output its response as a python dictionary, then put the call in the loop.  The responses where it goes oft prompt and offers commentary before giving you the dictionary (or messes up the dictionary) are Muppets.","classes":{"dataset":0.5180801153}}
{"title":"Tuesday Daily Thread: Advanced questions","description":"Have some burning questions on advanced Python topics? Use this thread to ask more advanced questions related to Python.\n\n**If your question is a beginner question we hold a beginner Daily Thread tomorrow (Wednesday) where you can ask any question! We may remove questions here and ask you to resubmit tomorrow.**\n\nThis thread may be fairly low volume in replies, if you don't receive a response we recommend looking at r/LearnPython or joining the Python Discord server at [https://discord.gg/python](https://discord.gg/python) where you stand a better chance of receiving a response.","link":"https://www.reddit.com/r/Python/comments/11qqgwc/tuesday_daily_thread_advanced_questions/","created":"2023-03-14","tags":["reddit","python"],"meta":{"num_comments":2},"text":"Tuesday Daily Thread: Advanced questions Have some burning questions on advanced Python topics? Use this thread to ask more advanced questions related to Python.\n\n**If your question is a beginner question we hold a beginner Daily Thread tomorrow (Wednesday) where you can ask any question! We may remove questions here and ask you to resubmit tomorrow.**\n\nThis thread may be fairly low volume in replies, if you don't receive a response we recommend looking at r/LearnPython or joining the Python Discord server at [https://discord.gg/python](https://discord.gg/python) where you stand a better chance of receiving a response.","classes":{"dataset":0.4687213302}}
{"title":"Anyone see a danger in allowing wild west rules for ' vs \" in strings?","description":"I'm tired of nit'ing people for using \\`\"\\` instead of \\`'\\` for strings (we agreed on \\`'\\`), and quite frankly I can't see how it adds value nor that anyone really cares. If I (as a tech lead) relax this to \"use whatever you feel like\", will we suffer later from some obscure gotcha?","link":"https://www.reddit.com/r/Python/comments/11qjml6/anyone_see_a_danger_in_allowing_wild_west_rules/","created":"2023-03-13","tags":["reddit","python"],"meta":{"num_comments":84},"text":"Anyone see a danger in allowing wild west rules for ' vs \" in strings? I'm tired of nit'ing people for using \\`\"\\` instead of \\`'\\` for strings (we agreed on \\`'\\`), and quite frankly I can't see how it adds value nor that anyone really cares. If I (as a tech lead) relax this to \"use whatever you feel like\", will we suffer later from some obscure gotcha?","classes":{"dataset":0.4725270867}}
{"title":"reddit downloader in python","description":"Hi everyone!\n\nI've made this reddit downloader/bot some time ago and now I thought of sharing it. Any feedback is welcome on programming, functions and overall functionality of it . Currently it can download saved posts, wallpapers, posts from specific user or subreddit or a link and fetches a random joke from r/Jokes\n\n&amp;#x200B;\n\nHere's the [link](https://github.com/SEKT10N/reddit-downloader) to it. Any help regarding improvement of coding and functionality is appreciated! Thanks!!","link":"https://www.reddit.com/r/Python/comments/11qyo4z/reddit_downloader_in_python/","created":"2023-03-14","tags":["reddit","python"],"meta":{"num_comments":2},"text":"reddit downloader in python Hi everyone!\n\nI've made this reddit downloader/bot some time ago and now I thought of sharing it. Any feedback is welcome on programming, functions and overall functionality of it . Currently it can download saved posts, wallpapers, posts from specific user or subreddit or a link and fetches a random joke from r/Jokes\n\n&amp;#x200B;\n\nHere's the [link](https://github.com/SEKT10N/reddit-downloader) to it. Any help regarding improvement of coding and functionality is appreciated! Thanks!!","classes":{"dataset":0.5144391656}}
{"title":"python security - very simply open source scanner which detect file signed untrusted or leaked certificates","description":" \n\n[https://github.com/password123456/CertVerify](https://github.com/password123456/CertVerify)\n\nWhy is this tool needed?\n\nExecutable files signed with compromised or untrusted code signing certificates can be used to distribute malware and other malicious software. Attackers can use these files to bypass security controls and to make their malware appear legitimate to victims. This tool helps to identify these files so that they can be removed or investigated further.","link":"https://www.reddit.com/r/Python/comments/11qq8ex/python_security_very_simply_open_source_scanner/","created":"2023-03-13","tags":["reddit","python"],"meta":{"num_comments":0},"text":"python security - very simply open source scanner which detect file signed untrusted or leaked certificates  \n\n[https://github.com/password123456/CertVerify](https://github.com/password123456/CertVerify)\n\nWhy is this tool needed?\n\nExecutable files signed with compromised or untrusted code signing certificates can be used to distribute malware and other malicious software. Attackers can use these files to bypass security controls and to make their malware appear legitimate to victims. This tool helps to identify these files so that they can be removed or investigated further.","classes":{"dataset":0.5089725256}}
{"title":"What are the good sources to learn machine learning in Python??","description":"I've recently finished learning about python and now I want to learn about machine learning...\nIt is confusing as there are so many modules and I just can't choose between them....\nIf anyone could suggest me 5 best modules I should learn it would be a great help....","link":"https://www.reddit.com/r/Python/comments/11q64a0/what_are_the_good_sources_to_learn_machine/","created":"2023-03-13","tags":["reddit","python"],"meta":{"num_comments":39},"text":"What are the good sources to learn machine learning in Python?? I've recently finished learning about python and now I want to learn about machine learning...\nIt is confusing as there are so many modules and I just can't choose between them....\nIf anyone could suggest me 5 best modules I should learn it would be a great help....","classes":{"dataset":0.4052860141}}
{"title":"What is the best interactive learning tool?","description":"Tried out a few interactive tools and really enjoyed learning before hitting paywalls. What is the best tool to learn python? It would also be usful if I could pay for it on a rolling month contract instead of an anual one.","link":"https://www.reddit.com/r/Python/comments/11qz29n/what_is_the_best_interactive_learning_tool/","created":"2023-03-14","tags":["reddit","python"],"meta":{"num_comments":1},"text":"What is the best interactive learning tool? Tried out a few interactive tools and really enjoyed learning before hitting paywalls. What is the best tool to learn python? It would also be usful if I could pay for it on a rolling month contract instead of an anual one.","classes":{"dataset":0.5049338341}}
{"title":"Tinkering with Unix domain sockets","description":"I needed to set up a proxy that relays requests to an HTTP web server communicating through a Unix domain socket (UDS). It turns out that I didn't know much about UDS. Thought I'd document the process as I started poking around it:  \n\n\n[https://rednafi.github.io/reflections/tinkering-with-unix-domain-sockets.html](https://rednafi.github.io/reflections/tinkering-with-unix-domain-sockets.html)","link":"https://www.reddit.com/r/Python/comments/11qluiv/tinkering_with_unix_domain_sockets/","created":"2023-03-13","tags":["reddit","python"],"meta":{"num_comments":1},"text":"Tinkering with Unix domain sockets I needed to set up a proxy that relays requests to an HTTP web server communicating through a Unix domain socket (UDS). It turns out that I didn't know much about UDS. Thought I'd document the process as I started poking around it:  \n\n\n[https://rednafi.github.io/reflections/tinkering-with-unix-domain-sockets.html](https://rednafi.github.io/reflections/tinkering-with-unix-domain-sockets.html)","classes":{"dataset":0.4232710898}}
{"title":"Question: Is there a way of using python functions within Excel/a spreadsheet, rather than VBA?","description":"I've tried writing scripts in Python in LibreOffice, but that just allows you to do macros on your spreasheets. It won't let you define a function and then call that function from within your cells as if it were built in.\n\nI've tried writing functions in VBA and JS in Excel and GoogleSheets, respectively, but I'd rather not have to learn a new language, and it would be easier to test that my scripts work correctly if they were written in python.\n\nI've also tried pyspread, but pyspread doesnt let you reference cells like a normal spreadsheet i.e. your formulas cannot include =A1+B2\n\nI've also seen pyxll but it seems you have to pay for it, which is crazy.\n\nAnyone aware of anything?","link":"https://www.reddit.com/r/Python/comments/11qjojt/question_is_there_a_way_of_using_python_functions/","created":"2023-03-13","tags":["reddit","python"],"meta":{"num_comments":10},"text":"Question: Is there a way of using python functions within Excel/a spreadsheet, rather than VBA? I've tried writing scripts in Python in LibreOffice, but that just allows you to do macros on your spreasheets. It won't let you define a function and then call that function from within your cells as if it were built in.\n\nI've tried writing functions in VBA and JS in Excel and GoogleSheets, respectively, but I'd rather not have to learn a new language, and it would be easier to test that my scripts work correctly if they were written in python.\n\nI've also tried pyspread, but pyspread doesnt let you reference cells like a normal spreadsheet i.e. your formulas cannot include =A1+B2\n\nI've also seen pyxll but it seems you have to pay for it, which is crazy.\n\nAnyone aware of anything?","classes":{"dataset":0.3397223651}}
{"title":"Introducing \ud83c\udf00 Ciclo: A functional training loops library for JAX","description":"# \ud83c\udf00 Ciclo\n\n*A functional training loops library for JAX*\n\n`ciclo` provides a set of utilities and abstractions to build complex training loops with any JAX framework. `ciclo` defines a set of building blocks that naturally compose together and scale up to build higher-level abstractions, ranging from low-level custom training loops to Keras-like training APIs.\n\n[https://github.com/cgarciae/ciclo](https://github.com/cgarciae/ciclo)\n\n[code](https://preview.redd.it/srzavxixqina1.jpg?width=1938&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0014f50581761d5b8c1c5df741a3ad103ae7c835)","link":"https://www.reddit.com/r/Python/comments/11qbiqr/introducing_ciclo_a_functional_training_loops/","created":"2023-03-13","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Introducing \ud83c\udf00 Ciclo: A functional training loops library for JAX # \ud83c\udf00 Ciclo\n\n*A functional training loops library for JAX*\n\n`ciclo` provides a set of utilities and abstractions to build complex training loops with any JAX framework. `ciclo` defines a set of building blocks that naturally compose together and scale up to build higher-level abstractions, ranging from low-level custom training loops to Keras-like training APIs.\n\n[https://github.com/cgarciae/ciclo](https://github.com/cgarciae/ciclo)\n\n[code](https://preview.redd.it/srzavxixqina1.jpg?width=1938&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=0014f50581761d5b8c1c5df741a3ad103ae7c835)","classes":{"dataset":0.4119002819}}
{"title":"Paperback version of my book Develop Cross Platform Desktop Applications using Python, Qt and PySide6 now also available","description":"There was a request to publish my new book also as paperback.  \nAnd here it is, at least in the US shop at [Amazon.com](https://www.amazon.com/dp/B0BXN5TFMM)  \nEnjoy  \n\n\n&amp;#x200B;\n\nhttps://preview.redd.it/mkpczxmi2jna1.png?width=325&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=dfa3e5f9678547ddf1478ece29f58e5f127dc0f3","link":"https://www.reddit.com/r/Python/comments/11qdb2y/paperback_version_of_my_book_develop_cross/","created":"2023-03-13","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Paperback version of my book Develop Cross Platform Desktop Applications using Python, Qt and PySide6 now also available There was a request to publish my new book also as paperback.  \nAnd here it is, at least in the US shop at [Amazon.com](https://www.amazon.com/dp/B0BXN5TFMM)  \nEnjoy  \n\n\n&amp;#x200B;\n\nhttps://preview.redd.it/mkpczxmi2jna1.png?width=325&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=dfa3e5f9678547ddf1478ece29f58e5f127dc0f3","classes":{"dataset":0.4411146641}}
{"title":"Code not able to execute.","description":"Code\nfrom bs4 import BeautifulSoup\nimport requests\nfrom ssl import SSLCertVerificationError\nfrom urllib3.exceptions import MaxRetryError\n\nresponse=None\nurl='https://www.businesswire.com/news/home/20221130005847/en/AWS-and-Atos-Strengthen-Collaboration-with-New-Strategic-Partnership-to-Transform-the-Infrastructure-Outsourcing-Industry'\ntry:\n    response=requests.get(url)\nexcept(requests.exceptions.SSLError,SSLCertVerificationError,MaxRetryError):\n    print(\"Connection failed\",response)\nsoup=BeautifulSoup(response,'lxml')\npara=soup.find_all(\"p\")\nprint(para)\n\n\nOutput\nConnection failed None\nTraceback (most recent call last):\n  File \"c:\\Users\\suryansh.agarwal\\Visual studio code codes\\bs4Program.py\", line 12, in &lt;module&gt;\n    soup=BeautifulSoup(response,'lxml')\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\suryansh.agarwal\\AppData\\Roaming\\Python\\Python311\\site-packages\\bs4\\__init__.py\", line 313, in __init__\n    elif len(markup) &lt;= 256 and (\n         ^^^^^^^^^^^\nTypeError: object of type 'NoneType' has no len()\n\n\nHow to correct this??","link":"https://www.reddit.com/r/Python/comments/11qx754/code_not_able_to_execute/","created":"2023-03-14","tags":["reddit","python"],"meta":{"num_comments":5},"text":"Code not able to execute. Code\nfrom bs4 import BeautifulSoup\nimport requests\nfrom ssl import SSLCertVerificationError\nfrom urllib3.exceptions import MaxRetryError\n\nresponse=None\nurl='https://www.businesswire.com/news/home/20221130005847/en/AWS-and-Atos-Strengthen-Collaboration-with-New-Strategic-Partnership-to-Transform-the-Infrastructure-Outsourcing-Industry'\ntry:\n    response=requests.get(url)\nexcept(requests.exceptions.SSLError,SSLCertVerificationError,MaxRetryError):\n    print(\"Connection failed\",response)\nsoup=BeautifulSoup(response,'lxml')\npara=soup.find_all(\"p\")\nprint(para)\n\n\nOutput\nConnection failed None\nTraceback (most recent call last):\n  File \"c:\\Users\\suryansh.agarwal\\Visual studio code codes\\bs4Program.py\", line 12, in &lt;module&gt;\n    soup=BeautifulSoup(response,'lxml')\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\suryansh.agarwal\\AppData\\Roaming\\Python\\Python311\\site-packages\\bs4\\__init__.py\", line 313, in __init__\n    elif len(markup) &lt;= 256 and (\n         ^^^^^^^^^^^\nTypeError: object of type 'NoneType' has no len()\n\n\nHow to correct this??","classes":{"dataset":0.3069792986}}
{"title":"I made a CLI to streamline Ethical Hacking workflow","description":"Hello everyone! I created this project to help streamline my ethical hacking workflow. It includes various functions, such as:\n\n* Convert: Allows you to apply a specified decoding or hashing function to input data. (e.g. URL, HTML, Base64, ASCII, Hex, Octal, Binary &amp; GZIP).\n* Enumerator: Enumerates subdomains for a given domain using subfinder, amass, assetfinder, findomain, and active enumeration.\n* Capture: Sends a GET request to a specified URL, captures the request headers, extracts the hostname, path, and cookies, and missing headers.\n* Portscan: Scans a host for common or all possible open ports.\n* Certificate: Checks the SSL/TLS certificate information for a given URL.\n* Storm: Sends HTTP requests to a given URL with a specified number of attacks and requests.\n* Disturb: Sends multiple HTTP requests to the specified URL with the same payload.\n* Fuzz: Tests your web applications against path fuzzing and file fuzzing.\n* CIDR: Looks up the CIDR range for a company's domain name from its RDAP record.\n* CVE: Retrieves CVE data for a specific product name (company name) from NIST's National Vulnerability Database (NVD). VPS: Allows you to log in to your VPS with a single command.\n\nI want to express my gratitude to many bug bounty hunters who helped me with this project. I believe it can be useful for anyone interested in ethical hacking.\n\nPlease let me know your feedback, as I am eager to make this tool the easiest and most minimalistic for the community.\n\nHack on!\n\n[**https://github.com/kitsec-labs/kitsec-core**](https://github.com/kitsec-labs/kitsec-core)","link":"https://www.reddit.com/r/Python/comments/11q8vbh/i_made_a_cli_to_streamline_ethical_hacking/","created":"2023-03-13","tags":["reddit","python"],"meta":{"num_comments":2},"text":"I made a CLI to streamline Ethical Hacking workflow Hello everyone! I created this project to help streamline my ethical hacking workflow. It includes various functions, such as:\n\n* Convert: Allows you to apply a specified decoding or hashing function to input data. (e.g. URL, HTML, Base64, ASCII, Hex, Octal, Binary &amp; GZIP).\n* Enumerator: Enumerates subdomains for a given domain using subfinder, amass, assetfinder, findomain, and active enumeration.\n* Capture: Sends a GET request to a specified URL, captures the request headers, extracts the hostname, path, and cookies, and missing headers.\n* Portscan: Scans a host for common or all possible open ports.\n* Certificate: Checks the SSL/TLS certificate information for a given URL.\n* Storm: Sends HTTP requests to a given URL with a specified number of attacks and requests.\n* Disturb: Sends multiple HTTP requests to the specified URL with the same payload.\n* Fuzz: Tests your web applications against path fuzzing and file fuzzing.\n* CIDR: Looks up the CIDR range for a company's domain name from its RDAP record.\n* CVE: Retrieves CVE data for a specific product name (company name) from NIST's National Vulnerability Database (NVD). VPS: Allows you to log in to your VPS with a single command.\n\nI want to express my gratitude to many bug bounty hunters who helped me with this project. I believe it can be useful for anyone interested in ethical hacking.\n\nPlease let me know your feedback, as I am eager to make this tool the easiest and most minimalistic for the community.\n\nHack on!\n\n[**https://github.com/kitsec-labs/kitsec-core**](https://github.com/kitsec-labs/kitsec-core)","classes":{"dataset":0.2709850371}}
{"title":"Calculating the gradient of the marginal log-likelihood function","description":"In the article [The theory behind Latent Variable Models: formulating a Variational Autoencoder](https://theaisummer.com/latent-variable-models/#variational-autoencoders)  , to model the desired probability distribution, estimating the parameters of a probability distribution so that the distribution fits the observed data is presented as an optimization problem of: \n\n&amp;#x200B;\n\nhttps://preview.redd.it/sgfz5txkjnna1.png?width=374&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=73b1ebc471187004419e8f7e1402b1d030a43e00\n\nThe gradient of the marginal log-likelihood function is then calculated using simple calculus and the Bayes rule:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/kwgde2twjnna1.png?width=427&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9f5071bcc63ed8e8c2c31c23a46ee3e51075a9bf\n\nwhere can one find the proof/maths behind this gradient calculation?","link":"https://www.reddit.com/r/deeplearning/comments/11qz5ze/calculating_the_gradient_of_the_marginal/","created":"2023-03-14","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Calculating the gradient of the marginal log-likelihood function In the article [The theory behind Latent Variable Models: formulating a Variational Autoencoder](https://theaisummer.com/latent-variable-models/#variational-autoencoders)  , to model the desired probability distribution, estimating the parameters of a probability distribution so that the distribution fits the observed data is presented as an optimization problem of: \n\n&amp;#x200B;\n\nhttps://preview.redd.it/sgfz5txkjnna1.png?width=374&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=73b1ebc471187004419e8f7e1402b1d030a43e00\n\nThe gradient of the marginal log-likelihood function is then calculated using simple calculus and the Bayes rule:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/kwgde2twjnna1.png?width=427&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9f5071bcc63ed8e8c2c31c23a46ee3e51075a9bf\n\nwhere can one find the proof/maths behind this gradient calculation?","classes":{"dataset":0.2856739163}}
{"title":"Learning logical relationships with neural networks with differential ILP","description":"Since last week\u2019s post on my lab\u2019s software package [PyReason](https://neurosymoblic.asu.edu/pyreason/), I got a lot of questions on if it would be possible for a neural network to learn logical relationships from data. After all, ChatGPT seems to be able to generate Python code, and Meta released a NeurIPS paper to show you can learn math equations from data using a transformer-based model, so why not logic? In this article, we will one line of research in this area \u2013 differential ILP.\n\nThe research in this area really kicked off with a 2018 [paper from DeepMind](https://www.reddit.com/r/deeplearning/jair.org/index.php/jair/article/view/11172) where Richard Evans and Edward Grefenstette showed that you could adapt techniques from \u201cinductive logic programming\u201d to use gradient descent, and learn logical rules from data. Previous (non-neural) work on inductive logic programming was generally not designed to work with noisy data and instead fit the historical examples in a precise manner. Evans and Grefenstette utilized a neural architecture and a loss function \u2013 and they showed they could handle noisy data and even do some level of integration with CNN\u2019s. Their neural architecture mimicked a set of candidate logical rules \u2013 and the rules assigned higher weights by gradient descent would be thought to best fit the data. However, a downside to this approach is that the neural network was [quintic in the size of the input](https://www.youtube.com/watch?v=SOnAE0EyX8c&amp;list=PLpqh-PUKX-i7URwnkTqpAkSchJHvbxZHB&amp;index=5). This is why they only applied their approach on very small problems \u2013 it did not see very wide adoption.\n\nThat said, in the last two years, there have been some notable follow-ons to this work. Researchers out of Kyoto University and NTT introduced a manner to learn rules that are more expressive in a different manner by allowing function symbols in the logical language ([Shindo et al., AAAI 2021](https://ojs.aaai.org/index.php/AAAI/article/view/16637/16444)). They leverage a clause search and refinement process to limit the number of candidate rules \u2013 hence limiting the size of the neural network. A student team from ASU created a presentation on their work for our recent seminar course on neuro symbolic AI. We released a three part video series from their talk:\n\n[Part 1: Review of differentiable inductive logic programming](https://www.youtube.com/watch?v=JIS78a40q8U&amp;t=270s)\n\n[Part 2: Clause search and refinement In our recent video series](https://www.youtube.com/watch?v=nzfbxlHUwuE&amp;t=345s)\n\n[Part 3: Experiments](https://www.youtube.com/watch?v=-fKWNtHUIN0&amp;t=27s)\n\n[Slides](https://labs.engineering.asu.edu/labv2/wp-content/uploads/sites/82/2022/10/Shindo_dILP.pdf)\n\nSome think that the ability to learn such relationships will represent a significant advancement in ML, specifically addressing shortcomings in areas such as knowledge graph completion and reasoning about scene graphs. However, the gap still remains wide, and ILP techniques, including differentiable ILP still have a ways to go. Really interested in what your thoughts are, feel free to comment below.","link":"https://www.reddit.com/r/deeplearning/comments/11q8tir/learning_logical_relationships_with_neural/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":3},"text":"Learning logical relationships with neural networks with differential ILP Since last week\u2019s post on my lab\u2019s software package [PyReason](https://neurosymoblic.asu.edu/pyreason/), I got a lot of questions on if it would be possible for a neural network to learn logical relationships from data. After all, ChatGPT seems to be able to generate Python code, and Meta released a NeurIPS paper to show you can learn math equations from data using a transformer-based model, so why not logic? In this article, we will one line of research in this area \u2013 differential ILP.\n\nThe research in this area really kicked off with a 2018 [paper from DeepMind](https://www.reddit.com/r/deeplearning/jair.org/index.php/jair/article/view/11172) where Richard Evans and Edward Grefenstette showed that you could adapt techniques from \u201cinductive logic programming\u201d to use gradient descent, and learn logical rules from data. Previous (non-neural) work on inductive logic programming was generally not designed to work with noisy data and instead fit the historical examples in a precise manner. Evans and Grefenstette utilized a neural architecture and a loss function \u2013 and they showed they could handle noisy data and even do some level of integration with CNN\u2019s. Their neural architecture mimicked a set of candidate logical rules \u2013 and the rules assigned higher weights by gradient descent would be thought to best fit the data. However, a downside to this approach is that the neural network was [quintic in the size of the input](https://www.youtube.com/watch?v=SOnAE0EyX8c&amp;list=PLpqh-PUKX-i7URwnkTqpAkSchJHvbxZHB&amp;index=5). This is why they only applied their approach on very small problems \u2013 it did not see very wide adoption.\n\nThat said, in the last two years, there have been some notable follow-ons to this work. Researchers out of Kyoto University and NTT introduced a manner to learn rules that are more expressive in a different manner by allowing function symbols in the logical language ([Shindo et al., AAAI 2021](https://ojs.aaai.org/index.php/AAAI/article/view/16637/16444)). They leverage a clause search and refinement process to limit the number of candidate rules \u2013 hence limiting the size of the neural network. A student team from ASU created a presentation on their work for our recent seminar course on neuro symbolic AI. We released a three part video series from their talk:\n\n[Part 1: Review of differentiable inductive logic programming](https://www.youtube.com/watch?v=JIS78a40q8U&amp;t=270s)\n\n[Part 2: Clause search and refinement In our recent video series](https://www.youtube.com/watch?v=nzfbxlHUwuE&amp;t=345s)\n\n[Part 3: Experiments](https://www.youtube.com/watch?v=-fKWNtHUIN0&amp;t=27s)\n\n[Slides](https://labs.engineering.asu.edu/labv2/wp-content/uploads/sites/82/2022/10/Shindo_dILP.pdf)\n\nSome think that the ability to learn such relationships will represent a significant advancement in ML, specifically addressing shortcomings in areas such as knowledge graph completion and reasoning about scene graphs. However, the gap still remains wide, and ILP techniques, including differentiable ILP still have a ways to go. Really interested in what your thoughts are, feel free to comment below.","classes":{"dataset":0.395000875}}
{"title":"Multiple objects - Multivariate LSTM","description":"Hello there, I'm new to deeplearning but I'm very fascinated by it.\n\nI'm actually working with multivariate time series (TS) forecasting. I already saw many approaches but none of them appear to be similar to my problem:\n\nI have ~150k objects, for each objects I have 4 independent TS (A B C D) and 1 dependent TS (let's call it Z).\n\nEach TS is about 45-50 observations depending on the studied year.\nI need to train a NN on the TS from the previous years to be used on the TS for this year and the next ones.\n\nI have 2 objectives: \n-predict the next 2-4 observations of TS Z using no more than the last 6 observations of ABCD;\n-predict all TS Z based on all the previous observations from ABCD. Obviously the predictions in the nearest future will be more precise that the ones in the long future. So with gradually increasing obs after each time step.\n\nCan you suggest me the best structure to achieve those 2 objs?","link":"https://www.reddit.com/r/deeplearning/comments/11q9hj3/multiple_objects_multivariate_lstm/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Multiple objects - Multivariate LSTM Hello there, I'm new to deeplearning but I'm very fascinated by it.\n\nI'm actually working with multivariate time series (TS) forecasting. I already saw many approaches but none of them appear to be similar to my problem:\n\nI have ~150k objects, for each objects I have 4 independent TS (A B C D) and 1 dependent TS (let's call it Z).\n\nEach TS is about 45-50 observations depending on the studied year.\nI need to train a NN on the TS from the previous years to be used on the TS for this year and the next ones.\n\nI have 2 objectives: \n-predict the next 2-4 observations of TS Z using no more than the last 6 observations of ABCD;\n-predict all TS Z based on all the previous observations from ABCD. Obviously the predictions in the nearest future will be more precise that the ones in the long future. So with gradually increasing obs after each time step.\n\nCan you suggest me the best structure to achieve those 2 objs?","classes":{"dataset":0.2718063593}}
{"title":"Display model like tensorspace","description":"Hi guys, quick question.\n\nDo you know any JavaScript module that could be used to display your model layers like in tensorspace playground? \n\nI was trying to use their angular example but I think it\u2019s outdated and doesn\u2019t have the best docs. Thanks!","link":"https://www.reddit.com/r/deeplearning/comments/11qdorq/display_model_like_tensorspace/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Display model like tensorspace Hi guys, quick question.\n\nDo you know any JavaScript module that could be used to display your model layers like in tensorspace playground? \n\nI was trying to use their angular example but I think it\u2019s outdated and doesn\u2019t have the best docs. Thanks!","classes":{"dataset":0.5208072662}}
{"title":"Recommendations sources for Understanding Advanced Mathematical Concepts in Research Papers?","description":"Hey everyone,\n\nI'm struggling with understanding mathematical proofs in research papers. I have a good grasp of basic concepts such as calculus (single variable calculus and basic knowledge of multi-variable calculus), linear algebra, and basic probability.\n\nI was wondering if any of you could recommend some sources (preferably videos or lecture series) to help me become more familiar with advanced mathematical concepts found in research papers.\n\nFor example:([source](https://www.biorxiv.org/content/10.1101/2021.03.21.436284v1.full.pdf))\n\nhttps://preview.redd.it/m19pwqkwkdna1.png?width=1104&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5cb83feec7e92d4e7f991f7c22cda8483c39c377\n\nIn papers, I have frequently encountered concepts like, **KL divergence**, **mathematics in higher-dimensional space**, **hessian**, **topology, Random projections** and many more;What are the subject/module names I need to study  to confidently read and understand proofs in papers?\n\n&amp;#x200B;\n\nThanks in advance!","link":"https://www.reddit.com/r/deeplearning/comments/11pq968/recommendations_sources_for_understanding/","created":"2023-03-12","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":9},"text":"Recommendations sources for Understanding Advanced Mathematical Concepts in Research Papers? Hey everyone,\n\nI'm struggling with understanding mathematical proofs in research papers. I have a good grasp of basic concepts such as calculus (single variable calculus and basic knowledge of multi-variable calculus), linear algebra, and basic probability.\n\nI was wondering if any of you could recommend some sources (preferably videos or lecture series) to help me become more familiar with advanced mathematical concepts found in research papers.\n\nFor example:([source](https://www.biorxiv.org/content/10.1101/2021.03.21.436284v1.full.pdf))\n\nhttps://preview.redd.it/m19pwqkwkdna1.png?width=1104&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5cb83feec7e92d4e7f991f7c22cda8483c39c377\n\nIn papers, I have frequently encountered concepts like, **KL divergence**, **mathematics in higher-dimensional space**, **hessian**, **topology, Random projections** and many more;What are the subject/module names I need to study  to confidently read and understand proofs in papers?\n\n&amp;#x200B;\n\nThanks in advance!","classes":{"dataset":0.1943041831}}
{"title":"Does anyone here have a job in industry using deep learning for genomics/bioinformatic work?","description":"If so, how common would you describe these jobs to be? Asking as a grad student who might spend a considerable amount of time doing deep learning projects and who hopes to get a job in industry. I have asked similar questions on the bioinfornatic sub.","link":"https://www.reddit.com/r/deeplearning/comments/11pr44f/does_anyone_here_have_a_job_in_industry_using/","created":"2023-03-12","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Does anyone here have a job in industry using deep learning for genomics/bioinformatic work? If so, how common would you describe these jobs to be? Asking as a grad student who might spend a considerable amount of time doing deep learning projects and who hopes to get a job in industry. I have asked similar questions on the bioinfornatic sub.","classes":{"dataset":0.4185231328}}
{"title":"Text2Image using ControlNet and Stable Diffusion","description":"In this tutorial, we will show you how to create beautiful and high-quality images from text using the powerful combination of diffusion model and ControlNet. \n\nText2Image generation is a fascinating field of AI that enables machines to understand and visualize human language in a more creative way.\n\n we will walk you through the step-by-step process of how to use the diffusion model and ControlNet to generate images from text. By the end of this tutorial, you will have a thorough understanding of text2image generation and how to use diffusion model and ControlNet to create stunning images from text. You will also have the knowledge and skills to apply these techniques to your own projects and experiments.\n\n So, get ready to dive into the exciting world of text2image generation and start creating your own beautiful images from text today!\n\nhttps://youtu.be/0D5Nlo2REb0","link":"https://www.reddit.com/r/deeplearning/comments/11p1par/text2image_using_controlnet_and_stable_diffusion/","created":"2023-03-12","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Text2Image using ControlNet and Stable Diffusion In this tutorial, we will show you how to create beautiful and high-quality images from text using the powerful combination of diffusion model and ControlNet. \n\nText2Image generation is a fascinating field of AI that enables machines to understand and visualize human language in a more creative way.\n\n we will walk you through the step-by-step process of how to use the diffusion model and ControlNet to generate images from text. By the end of this tutorial, you will have a thorough understanding of text2image generation and how to use diffusion model and ControlNet to create stunning images from text. You will also have the knowledge and skills to apply these techniques to your own projects and experiments.\n\n So, get ready to dive into the exciting world of text2image generation and start creating your own beautiful images from text today!\n\nhttps://youtu.be/0D5Nlo2REb0","classes":{"dataset":0.3048008978}}
{"title":"https://www.kaggle.com/code/sadikaljarif/plant-disease-classification-using-mobilenetv2","description":"# About Dataset\n\n# This dataset is recreated using offline augmentation from the original dataset. The original dataset can be found on [this](https://github.com/spMohanty/PlantVillage-Dataset) github repo. This dataset consists of about 87K rgb images of healthy and diseased crop leaves which is categorized into 38 different classes. The total dataset is divided into 80/20 ratio of training and validation set preserving the directory structure. A new directory containing 33 test images is created later for prediction purpose\n\n# Notebook : [https://www.kaggle.com/code/sadikaljarif/plant-disease-classification-using-mobilenetv2](https://www.kaggle.com/code/sadikaljarif/plant-disease-classification-using-mobilenetv2)","link":"https://www.reddit.com/r/deeplearning/comments/11otmgd/httpswwwkagglecomcodesadikaljarifplantdiseaseclass/","created":"2023-03-11","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"https://www.kaggle.com/code/sadikaljarif/plant-disease-classification-using-mobilenetv2 # About Dataset\n\n# This dataset is recreated using offline augmentation from the original dataset. The original dataset can be found on [this](https://github.com/spMohanty/PlantVillage-Dataset) github repo. This dataset consists of about 87K rgb images of healthy and diseased crop leaves which is categorized into 38 different classes. The total dataset is divided into 80/20 ratio of training and validation set preserving the directory structure. A new directory containing 33 test images is created later for prediction purpose\n\n# Notebook : [https://www.kaggle.com/code/sadikaljarif/plant-disease-classification-using-mobilenetv2](https://www.kaggle.com/code/sadikaljarif/plant-disease-classification-using-mobilenetv2)","classes":{"dataset":0.435536176}}
{"title":"[D] Simple Questions Thread","description":"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!","link":"https://www.reddit.com/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/","created":"2023-03-12","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":22},"text":"[D] Simple Questions Thread Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!","classes":{"dataset":0.2793671489}}
{"title":"[P] ControlNetInpaint: No extra training and you can use \ud83d\udcddtext +\ud83c\udf0cimage + \ud83d\ude37mask to generate new images.","description":"Hi! Here's an **open-source implementation** I released today for masked ControlNet synthesis, where you can specify the region that will be synthesised using a mask. The content of the synthesised region is controlled via textual and visual guidance as shown in the README.\n\n[https://github.com/mikonvergence/ControlNetInpaint](https://github.com/mikonvergence/ControlNetInpaint)\n\nHere's an example with a prompt of ***\"a red panda sitting on a bench\"*****:**\n\nhttps://preview.redd.it/4vxsg9sc0lna1.png?width=1860&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9776369a86043f9420ec8771dd6f9d22308e521c","link":"https://www.reddit.com/r/MachineLearning/comments/11qnv4c/p_controlnetinpaint_no_extra_training_and_you_can/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":1},"text":"[P] ControlNetInpaint: No extra training and you can use \ud83d\udcddtext +\ud83c\udf0cimage + \ud83d\ude37mask to generate new images. Hi! Here's an **open-source implementation** I released today for masked ControlNet synthesis, where you can specify the region that will be synthesised using a mask. The content of the synthesised region is controlled via textual and visual guidance as shown in the README.\n\n[https://github.com/mikonvergence/ControlNetInpaint](https://github.com/mikonvergence/ControlNetInpaint)\n\nHere's an example with a prompt of ***\"a red panda sitting on a bench\"*****:**\n\nhttps://preview.redd.it/4vxsg9sc0lna1.png?width=1860&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9776369a86043f9420ec8771dd6f9d22308e521c","classes":{"dataset":0.3767973483}}
{"title":"[R] Training Small Diffusion Model","description":"Does anyone have experience training a small diffusion model conditioned on text captions from scratch on 64x64 images or possibly even smaller? \n\nI would like to run it only on images of text to see if it is able to render text. How long would this potentially take if I ran it on 1-2 GPUs? Is this something that\u2019s even possible?","link":"https://www.reddit.com/r/MachineLearning/comments/11qynbp/r_training_small_diffusion_model/","created":"2023-03-14","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":3},"text":"[R] Training Small Diffusion Model Does anyone have experience training a small diffusion model conditioned on text captions from scratch on 64x64 images or possibly even smaller? \n\nI would like to run it only on images of text to see if it is able to render text. How long would this potentially take if I ran it on 1-2 GPUs? Is this something that\u2019s even possible?","classes":{"dataset":0.2778704464}}
{"title":"[R] MathPrompter: Mathematical Reasoning using Large Language Models. New State of the Art on MultiArith ( 78.7% to 92.5%) with Text-Davinci 002","description":"Paper - [https://arxiv.org/abs/2303.05398](https://arxiv.org/abs/2303.05398)","link":"https://www.reddit.com/r/MachineLearning/comments/11q8w62/r_mathprompter_mathematical_reasoning_using_large/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":16},"text":"[R] MathPrompter: Mathematical Reasoning using Large Language Models. New State of the Art on MultiArith ( 78.7% to 92.5%) with Text-Davinci 002 Paper - [https://arxiv.org/abs/2303.05398](https://arxiv.org/abs/2303.05398)","classes":{"dataset":0.0084104361}}
{"title":"[P] Build a Question Answer system/chat bot trained on documentation.","description":"Hi everyone! I'm working on a side project for my company where the goal is to train an ML model on the company's documentation. We should then be able to ask it any question based on the docs and it should generate a concise response( something like what chatgpt does). How can I achieve this? \nThanks you in advance :)","link":"https://www.reddit.com/r/MachineLearning/comments/11qxys6/p_build_a_question_answer_systemchat_bot_trained/","created":"2023-03-14","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":2},"text":"[P] Build a Question Answer system/chat bot trained on documentation. Hi everyone! I'm working on a side project for my company where the goal is to train an ML model on the company's documentation. We should then be able to ask it any question based on the docs and it should generate a concise response( something like what chatgpt does). How can I achieve this? \nThanks you in advance :)","classes":{"dataset":0.1075937748}}
{"title":"[D] NLP - Merging token embeddings for smaller input sizes","description":"We all know that one of the main problems with current LLMs is their limited input size. \n\nHowever, for certain applications like code modeling, joining common tokens into a single one can make sense and reduce the vocabulary drastically. Example: if you are modeling Python code, probably you can consider \\`import\\` as a single token, instead of having two tokens like \\`im\\` + \\`port\\`.   \n\n\nDoes this work in practice? Are there any resources on this? Maybe averaging the tokens into a single embedding and adding that to the vocabulary and tokenizer is enough?   \nI've seen some [work on token merging for images](https://openreview.net/pdf?id=JroZRaRw7Eu), but not for text.\n\nThank you in advance!","link":"https://www.reddit.com/r/MachineLearning/comments/11r10yz/d_nlp_merging_token_embeddings_for_smaller_input/","created":"2023-03-14","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[D] NLP - Merging token embeddings for smaller input sizes We all know that one of the main problems with current LLMs is their limited input size. \n\nHowever, for certain applications like code modeling, joining common tokens into a single one can make sense and reduce the vocabulary drastically. Example: if you are modeling Python code, probably you can consider \\`import\\` as a single token, instead of having two tokens like \\`im\\` + \\`port\\`.   \n\n\nDoes this work in practice? Are there any resources on this? Maybe averaging the tokens into a single embedding and adding that to the vocabulary and tokenizer is enough?   \nI've seen some [work on token merging for images](https://openreview.net/pdf?id=JroZRaRw7Eu), but not for text.\n\nThank you in advance!","classes":{"dataset":0.4071804583}}
{"title":"Productionize training pipeline vs model artifact? [D]","description":"Let's say you have ETL,  training, and inference pipelines. Is it best practices to promote all pipelines to production (you will have one model artifact in dev env and one model artifact in prod env) or keep the training pipeline in dev and only promote the resulting model artifact + ETL/inference pipelines? Why?","link":"https://www.reddit.com/r/MachineLearning/comments/11qu3qc/productionize_training_pipeline_vs_model_artifact/","created":"2023-03-14","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":1},"text":"Productionize training pipeline vs model artifact? [D] Let's say you have ETL,  training, and inference pipelines. Is it best practices to promote all pipelines to production (you will have one model artifact in dev env and one model artifact in prod env) or keep the training pipeline in dev and only promote the resulting model artifact + ETL/inference pipelines? Why?","classes":{"dataset":0.1620546579}}
{"title":"[Research] NeRFshop: Interactive Editing of Neural Radiance Fields, I3D 2023","description":"Twitter link: [https://twitter.com/clementjbn/status/1635200991523139584](https://twitter.com/clementjbn/status/1635200991523139584)  \n\n\nTLDR: instant-ngp based interface for editing of NeRF objects. Format exportable to instant-ngp app.","link":"https://www.reddit.com/r/MachineLearning/comments/11q6gco/research_nerfshop_interactive_editing_of_neural/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[Research] NeRFshop: Interactive Editing of Neural Radiance Fields, I3D 2023 Twitter link: [https://twitter.com/clementjbn/status/1635200991523139584](https://twitter.com/clementjbn/status/1635200991523139584)  \n\n\nTLDR: instant-ngp based interface for editing of NeRF objects. Format exportable to instant-ngp app.","classes":{"dataset":0.3890218437}}
{"title":"[D]: Generalisation ability of autoencoders","description":"What is the current state-of-the-art when it comes to the generalisation ability of autoencoders?\nI have been working with text autoencoders for some time and, although they work well on the training data, they generalise very poorly to unseen sentences (as, for example, noted here: \nhttps://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=there+and+back+again+autoencoder&amp;btnG=#d=gs_qabs&amp;t=1678725350369&amp;u=%23p%3DksKOTTf1c1IJ). How do image autoencoders do with unseen images? What research efforts are underway to improve generalisation ability?","link":"https://www.reddit.com/r/MachineLearning/comments/11qejcz/d_generalisation_ability_of_autoencoders/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":9},"text":"[D]: Generalisation ability of autoencoders What is the current state-of-the-art when it comes to the generalisation ability of autoencoders?\nI have been working with text autoencoders for some time and, although they work well on the training data, they generalise very poorly to unseen sentences (as, for example, noted here: \nhttps://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=there+and+back+again+autoencoder&amp;btnG=#d=gs_qabs&amp;t=1678725350369&amp;u=%23p%3DksKOTTf1c1IJ). How do image autoencoders do with unseen images? What research efforts are underway to improve generalisation ability?","classes":{"dataset":0.0229804851}}
{"title":"[Discussion] Searching for end-to-end MLOps training solution","description":"I am working in a small research group and we recently found a problem with our resource utilization. We have 11 servers with 4 gpus in each and I am looking for an automatic execution manager with a queue. Currently we don't have anything in place and just write in a table which GPU is occupied by who, which, as you can imagine, is not ideal, our current utilization is around 50-60%. So we came up with the following two requirements:\n\n* Queue for training/inference tasks with dynamic GPU allocation (ex. you can launch 4 tasks on one machine that require 1 GPU each, or 2 tasks with 2 GPU, etc.)\n* Ability to reserve GPUs so that you can connect to the host and work directly (for example you want to launch 3rd party repository with complex environment setup)\n\nThe only solution I found so far is ClearML with clearml agent, but there are two problems with it, the first one is dynamic GPU allocation is available only in enterprise edition, which means that we need to reserve some hosts to run 2 GPU tasks and some that run 1 GPU tasks, which is not ideal. The second is that you can't directly tell clearml to not use some gpu for the time, so we used a crutch - launch an task with infinite loop in it that does nothing, which is once again is not ideal.\n\nHave some of you encountered a similar problems? How did you solve it? Maybe there is a solution that we missed, any help is appreciated.","link":"https://www.reddit.com/r/MachineLearning/comments/11q53pp/discussion_searching_for_endtoend_mlops_training/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":8},"text":"[Discussion] Searching for end-to-end MLOps training solution I am working in a small research group and we recently found a problem with our resource utilization. We have 11 servers with 4 gpus in each and I am looking for an automatic execution manager with a queue. Currently we don't have anything in place and just write in a table which GPU is occupied by who, which, as you can imagine, is not ideal, our current utilization is around 50-60%. So we came up with the following two requirements:\n\n* Queue for training/inference tasks with dynamic GPU allocation (ex. you can launch 4 tasks on one machine that require 1 GPU each, or 2 tasks with 2 GPU, etc.)\n* Ability to reserve GPUs so that you can connect to the host and work directly (for example you want to launch 3rd party repository with complex environment setup)\n\nThe only solution I found so far is ClearML with clearml agent, but there are two problems with it, the first one is dynamic GPU allocation is available only in enterprise edition, which means that we need to reserve some hosts to run 2 GPU tasks and some that run 1 GPU tasks, which is not ideal. The second is that you can't directly tell clearml to not use some gpu for the time, so we used a crutch - launch an task with infinite loop in it that does nothing, which is once again is not ideal.\n\nHave some of you encountered a similar problems? How did you solve it? Maybe there is a solution that we missed, any help is appreciated.","classes":{"dataset":0.329317987}}
{"title":"[R] Optimal Data Acquisition Strategy","description":"tl;dr: Looking for state of the art methods on how to select which additional training data to acquire to improve image classification performance (key words, authors, etc. wanted)\n\nHi all,\n\nI am training an image classification algorithm and want to improve the performance. For this I have the option to acquire new training data. \n\nI was wondering: Is there a specific method on how to select which examples likely will boost overall performance? Something like an \u201eoptimal data acquisition strategy\u201c?\n\nOfc, the naive way is to rebalance classes, add more examples of low performing clusters etc. However, I could not find the specific field of machine learning research dealing with these questions. Do you have any keywords for me to search for?","link":"https://www.reddit.com/r/MachineLearning/comments/11qg55j/r_optimal_data_acquisition_strategy/","created":"2023-03-13","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":1},"text":"[R] Optimal Data Acquisition Strategy tl;dr: Looking for state of the art methods on how to select which additional training data to acquire to improve image classification performance (key words, authors, etc. wanted)\n\nHi all,\n\nI am training an image classification algorithm and want to improve the performance. For this I have the option to acquire new training data. \n\nI was wondering: Is there a specific method on how to select which examples likely will boost overall performance? Something like an \u201eoptimal data acquisition strategy\u201c?\n\nOfc, the naive way is to rebalance classes, add more examples of low performing clusters etc. However, I could not find the specific field of machine learning research dealing with these questions. Do you have any keywords for me to search for?","classes":{"dataset":0.1787554473}}
{"title":"Is GPT-3(and ChatGPT) trained with the MLM task?","description":"Hi all experts, I have a quick question.\n\n\\- Is the GPT family(GPT1/2/3/Chat) trained with the MLM(Masked Language Modeling) task?\n\nI guess no, because the GPT is basically auto-regressive(unidirectional), and their papers didn't mention the MLM training task, afaik. But when I googled, there is no clear answer, and the ChatGPT answers that the GPT family was trained on MLM.\n\nDoes anyone know the precise answer?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11qvs3t/is_gpt3and_chatgpt_trained_with_the_mlm_task/","created":"2023-03-14","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":5},"text":"Is GPT-3(and ChatGPT) trained with the MLM task? Hi all experts, I have a quick question.\n\n\\- Is the GPT family(GPT1/2/3/Chat) trained with the MLM(Masked Language Modeling) task?\n\nI guess no, because the GPT is basically auto-regressive(unidirectional), and their papers didn't mention the MLM training task, afaik. But when I googled, there is no clear answer, and the ChatGPT answers that the GPT family was trained on MLM.\n\nDoes anyone know the precise answer?","classes":{"dataset":0.6109648347}}
{"title":"Optimum Dataset for Sequence Labelling","description":"Hi everyone. I'm working on a custom NER like task.\n\nHowever some tags have very low frequency in the data. Hence mode is not good in predicting them.\n\nThis problem got me thinking what would the optimum dataset look like for such a task? \nShould number of samples for each label be similar? \nif we increase the data for all labels but keep a specific label same would it impact the preformance?\n\nPapers usually just take a toy dataset and tweak the model or data little bit. I couldn't find an answer to these questions. Do you have any resource or knowledge on this?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11qf9sv/optimum_dataset_for_sequence_labelling/","created":"2023-03-13","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":2},"text":"Optimum Dataset for Sequence Labelling Hi everyone. I'm working on a custom NER like task.\n\nHowever some tags have very low frequency in the data. Hence mode is not good in predicting them.\n\nThis problem got me thinking what would the optimum dataset look like for such a task? \nShould number of samples for each label be similar? \nif we increase the data for all labels but keep a specific label same would it impact the preformance?\n\nPapers usually just take a toy dataset and tweak the model or data little bit. I couldn't find an answer to these questions. Do you have any resource or knowledge on this?","classes":{"dataset":0.0635348856}}
{"title":"Best approach for sarcasm subcategory classification?","description":" Hi All,\n\nI  am currently working on my thesis which is attempting to build on  existing research in the field of sarcasm detection within NLP and  sentiment analysis. The task outlined is to basically build a model  which can identify subcategories of sarcasm (e.g. irony, overstatement,  rhetorical questions etc.). The dataset includes values for whether a  phrase is sarcastic or not, and which subcategories the phrase fits into  (there can be overlap between categories). I have fine-tuned BERT for  sarcasm detection and this works fine but that isn't really the task. My  questions are twofold essentially:\n\n\\-  Is the solely transformer-based approach useful in this instance, given  that it could build on existing research where previous scores obtained  in this task were fairly low. If so, does anyone have any resources on  how to build a multi-subclass classification model, or would it be  better to build separate models for each task?\n\n\\-  Would attempting to use a rule-based approach be more valuable e.g.  using vector semantics and embeddings to attempt to identify the  subcategories using this approach, and if so are there any particular  resources I should have a look at to understand how to implement this in  code? I am currently reading Jurafsky &amp; Martin's 3rd draft of  Speech and Language Processing, but I am unclear on how I could use this  to categorise the subcategories which are difficult to define by  linguistic experts as it is?\n\nI'm  sorry if this is a bit rambling and all over the place, I'm feeling  pretty lost and stressed, but happy to answer any questions and try to  clarify anything :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11ok7ug/best_approach_for_sarcasm_subcategory/","created":"2023-03-11","tags":["languagetechnology","ml","reddit"],"meta":{"num_comments":9},"text":"Best approach for sarcasm subcategory classification?  Hi All,\n\nI  am currently working on my thesis which is attempting to build on  existing research in the field of sarcasm detection within NLP and  sentiment analysis. The task outlined is to basically build a model  which can identify subcategories of sarcasm (e.g. irony, overstatement,  rhetorical questions etc.). The dataset includes values for whether a  phrase is sarcastic or not, and which subcategories the phrase fits into  (there can be overlap between categories). I have fine-tuned BERT for  sarcasm detection and this works fine but that isn't really the task. My  questions are twofold essentially:\n\n\\-  Is the solely transformer-based approach useful in this instance, given  that it could build on existing research where previous scores obtained  in this task were fairly low. If so, does anyone have any resources on  how to build a multi-subclass classification model, or would it be  better to build separate models for each task?\n\n\\-  Would attempting to use a rule-based approach be more valuable e.g.  using vector semantics and embeddings to attempt to identify the  subcategories using this approach, and if so are there any particular  resources I should have a look at to understand how to implement this in  code? I am currently reading Jurafsky &amp; Martin's 3rd draft of  Speech and Language Processing, but I am unclear on how I could use this  to categorise the subcategories which are difficult to define by  linguistic experts as it is?\n\nI'm  sorry if this is a bit rambling and all over the place, I'm feeling  pretty lost and stressed, but happy to answer any questions and try to  clarify anything :)","classes":{"dataset":0.410320878}}
{"title":"BaDLAD: A Large Multi-Domain Bengali Document Layout Analysis Dataset","description":"While strides have been made in deep learning based Bengali Optical Character Recognition (OCR) in the past decade, the absence of large Document Layout Analysis (DLA) datasets has hindered the application of OCR in document transcription, e.g., transcribing historical documents and newspapers. Moreover, rule-based DLA systems that are currently being employed in practice are not robust to domain variations and out-of-distribution layouts. To this end, we present the first multidomain large Bengali Document Layout Analysis Dataset: BaDLAD. This dataset contains 33,695 human annotated document samples from six domains - i) books and magazines, ii) public domain govt. documents, iii) liberation war documents, iv) newspapers, v) historical newspapers, and vi) property deeds, with 710K polygon annotations for four unit types: text-box, paragraph, image, and table. Through preliminary experiments benchmarking the performance of existing state-of-the-art deep learning architectures for English DLA, we demonstrate the efficacy of our dataset in training deep learning based Bengali document digitization models.","link":"http://arxiv.org/abs/2303.05325v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"BaDLAD: A Large Multi-Domain Bengali Document Layout Analysis Dataset While strides have been made in deep learning based Bengali Optical Character Recognition (OCR) in the past decade, the absence of large Document Layout Analysis (DLA) datasets has hindered the application of OCR in document transcription, e.g., transcribing historical documents and newspapers. Moreover, rule-based DLA systems that are currently being employed in practice are not robust to domain variations and out-of-distribution layouts. To this end, we present the first multidomain large Bengali Document Layout Analysis Dataset: BaDLAD. This dataset contains 33,695 human annotated document samples from six domains - i) books and magazines, ii) public domain govt. documents, iii) liberation war documents, iv) newspapers, v) historical newspapers, and vi) property deeds, with 710K polygon annotations for four unit types: text-box, paragraph, image, and table. Through preliminary experiments benchmarking the performance of existing state-of-the-art deep learning architectures for English DLA, we demonstrate the efficacy of our dataset in training deep learning based Bengali document digitization models.","classes":{"dataset":0.9660897851}}
{"title":"Dataset CYLinCF-01 creation pipeline: Circular cylinder in a cross flow, Mach Number 0.03 and Reynolds Number 200","description":"This article presents an aeroacoustic workflow (pipeline) to generate a flow and acoustic dataset for studying flow-induced sound in the context of a cylinder in cross flow. The numerical simulations are performed using OpenFOAM for the flow and openCFS for acoustics using the perturbed convective wave equation (PCWE). The workflow involves several steps, including the flow simulation, the acoustic simulation, and post-processing of the results. The simulation workflow is presented in all its details. The analysis focuses on the acoustic characteristics of the flow, including sound pressure levels, frequency spectra, and directivity patterns. The results show good agreement with the literature. The article concludes by discussing applications of the workflow for different cases that involve flow-induced sound generation.","link":"http://arxiv.org/abs/2303.05265v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Dataset CYLinCF-01 creation pipeline: Circular cylinder in a cross flow, Mach Number 0.03 and Reynolds Number 200 This article presents an aeroacoustic workflow (pipeline) to generate a flow and acoustic dataset for studying flow-induced sound in the context of a cylinder in cross flow. The numerical simulations are performed using OpenFOAM for the flow and openCFS for acoustics using the perturbed convective wave equation (PCWE). The workflow involves several steps, including the flow simulation, the acoustic simulation, and post-processing of the results. The simulation workflow is presented in all its details. The analysis focuses on the acoustic characteristics of the flow, including sound pressure levels, frequency spectra, and directivity patterns. The results show good agreement with the literature. The article concludes by discussing applications of the workflow for different cases that involve flow-induced sound generation.","classes":{"dataset":0.4694412947}}
{"title":"Dominating Set Database Selection for Visual Place Recognition","description":"This paper presents an approach for creating a visual place recognition (VPR) database for localization in indoor environments from RGBD scanning sequences. The proposed approach is formulated as a minimization problem in terms of dominating set algorithm for graph, constructed from spatial information, and referred as DominatingSet. Our algorithm shows better scene coverage in comparison to other methodologies that are used for database creation. Also, we demonstrate that using DominatingSet, a database size could be up to 250-1400 times smaller than the original scanning sequence while maintaining a recall rate of more than 80% on testing sequences. We evaluated our algorithm on 7-scenes and BundleFusion datasets and an additionally recorded sequence in a highly repetitive office setting. In addition, the database selection can produce weakly-supervised labels for fine-tuning neural place recognition algorithms to particular settings, improving even more their accuracy. The paper also presents a fully automated pipeline for VPR database creation from RGBD scanning sequences, as well as a set of metrics for VPR database evaluation. The code and released data are available on our web-page~ -- https://prime-slam.github.io/place-recognition-db/","link":"http://arxiv.org/abs/2303.05123v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Dominating Set Database Selection for Visual Place Recognition This paper presents an approach for creating a visual place recognition (VPR) database for localization in indoor environments from RGBD scanning sequences. The proposed approach is formulated as a minimization problem in terms of dominating set algorithm for graph, constructed from spatial information, and referred as DominatingSet. Our algorithm shows better scene coverage in comparison to other methodologies that are used for database creation. Also, we demonstrate that using DominatingSet, a database size could be up to 250-1400 times smaller than the original scanning sequence while maintaining a recall rate of more than 80% on testing sequences. We evaluated our algorithm on 7-scenes and BundleFusion datasets and an additionally recorded sequence in a highly repetitive office setting. In addition, the database selection can produce weakly-supervised labels for fine-tuning neural place recognition algorithms to particular settings, improving even more their accuracy. The paper also presents a fully automated pipeline for VPR database creation from RGBD scanning sequences, as well as a set of metrics for VPR database evaluation. The code and released data are available on our web-page~ -- https://prime-slam.github.io/place-recognition-db/","classes":{"dataset":0.0346765295}}
{"title":"StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent Disentangled Space","description":"One major challenge in machine learning applications is coping with mismatches between the datasets used in the development and those obtained in real-world applications. These mismatches may lead to inaccurate predictions and errors, resulting in poor product quality and unreliable systems. In this study, we propose StyleDiff to inform developers of the differences between the two datasets for the steady development of machine learning systems. Using disentangled image spaces obtained from recently proposed generative models, StyleDiff compares the two datasets by focusing on attributes in the images and provides an easy-to-understand analysis of the differences between the datasets. The proposed StyleDiff performs in $O (d N\\log N)$, where $N$ is the size of the datasets and $d$ is the number of attributes, enabling the application to large datasets. We demonstrate that StyleDiff accurately detects differences between datasets and presents them in an understandable format using, for example, driving scenes datasets.","link":"http://arxiv.org/abs/2303.05102v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent Disentangled Space One major challenge in machine learning applications is coping with mismatches between the datasets used in the development and those obtained in real-world applications. These mismatches may lead to inaccurate predictions and errors, resulting in poor product quality and unreliable systems. In this study, we propose StyleDiff to inform developers of the differences between the two datasets for the steady development of machine learning systems. Using disentangled image spaces obtained from recently proposed generative models, StyleDiff compares the two datasets by focusing on attributes in the images and provides an easy-to-understand analysis of the differences between the datasets. The proposed StyleDiff performs in $O (d N\\log N)$, where $N$ is the size of the datasets and $d$ is the number of attributes, enabling the application to large datasets. We demonstrate that StyleDiff accurately detects differences between datasets and presents them in an understandable format using, for example, driving scenes datasets.","classes":{"dataset":0.0158727784}}
{"title":"Contributing to Accessibility Datasets: Reflections on Sharing Study Data by Blind People","description":"To ensure that AI-infused systems work for disabled people, we need to bring accessibility datasets sourced from this community in the development lifecycle. However, there are many ethical and privacy concerns limiting greater data inclusion, making such datasets not readily available. We present a pair of studies where 13 blind participants engage in data capturing activities and reflect with and without probing on various factors that influence their decision to share their data via an AI dataset. We see how different factors influence blind participants' willingness to share study data as they assess risk-benefit tradeoffs. The majority support sharing of their data to improve technology but also express concerns over commercial use, associated metadata, and the lack of transparency about the impact of their data. These insights have implications for the development of responsible practices for stewarding accessibility datasets, and can contribute to broader discussions in this area.","link":"http://arxiv.org/abs/2303.04962v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Contributing to Accessibility Datasets: Reflections on Sharing Study Data by Blind People To ensure that AI-infused systems work for disabled people, we need to bring accessibility datasets sourced from this community in the development lifecycle. However, there are many ethical and privacy concerns limiting greater data inclusion, making such datasets not readily available. We present a pair of studies where 13 blind participants engage in data capturing activities and reflect with and without probing on various factors that influence their decision to share their data via an AI dataset. We see how different factors influence blind participants' willingness to share study data as they assess risk-benefit tradeoffs. The majority support sharing of their data to improve technology but also express concerns over commercial use, associated metadata, and the lack of transparency about the impact of their data. These insights have implications for the development of responsible practices for stewarding accessibility datasets, and can contribute to broader discussions in this area.","classes":{"dataset":0.9705153704}}
{"title":"FedREP: A Byzantine-Robust, Communication-Efficient and Privacy-Preserving Framework for Federated Learning","description":"Federated learning (FL) has recently become a hot research topic, in which Byzantine robustness, communication efficiency and privacy preservation are three important aspects. However, the tension among these three aspects makes it hard to simultaneously take all of them into account. In view of this challenge, we theoretically analyze the conditions that a communication compression method should satisfy to be compatible with existing Byzantine-robust methods and privacy-preserving methods. Motivated by the analysis results, we propose a novel communication compression method called consensus sparsification (ConSpar). To the best of our knowledge, ConSpar is the first communication compression method that is designed to be compatible with both Byzantine-robust methods and privacy-preserving methods. Based on ConSpar, we further propose a novel FL framework called FedREP, which is Byzantine-robust, communication-efficient and privacy-preserving. We theoretically prove the Byzantine robustness and the convergence of FedREP. Empirical results show that FedREP can significantly outperform communication-efficient privacy-preserving baselines. Furthermore, compared with Byzantine-robust communication-efficient baselines, FedREP can achieve comparable accuracy with the extra advantage of privacy preservation.","link":"http://arxiv.org/abs/2303.05206v1","created":"2023-03-09","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"FedREP: A Byzantine-Robust, Communication-Efficient and Privacy-Preserving Framework for Federated Learning Federated learning (FL) has recently become a hot research topic, in which Byzantine robustness, communication efficiency and privacy preservation are three important aspects. However, the tension among these three aspects makes it hard to simultaneously take all of them into account. In view of this challenge, we theoretically analyze the conditions that a communication compression method should satisfy to be compatible with existing Byzantine-robust methods and privacy-preserving methods. Motivated by the analysis results, we propose a novel communication compression method called consensus sparsification (ConSpar). To the best of our knowledge, ConSpar is the first communication compression method that is designed to be compatible with both Byzantine-robust methods and privacy-preserving methods. Based on ConSpar, we further propose a novel FL framework called FedREP, which is Byzantine-robust, communication-efficient and privacy-preserving. We theoretically prove the Byzantine robustness and the convergence of FedREP. Empirical results show that FedREP can significantly outperform communication-efficient privacy-preserving baselines. Furthermore, compared with Byzantine-robust communication-efficient baselines, FedREP can achieve comparable accuracy with the extra advantage of privacy preservation.","classes":{"dataset":0.209562853}}
{"title":"Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data","description":"Advanced large language models like ChatGPT have gained considerable attention recently, including among students. However, while the debate on ChatGPT in academia is making waves, more understanding is needed among lecturers and teachers on how students use and perceive ChatGPT. To address this gap, we analyzed the content on ChatGPT available on TikTok in February 2023. TikTok is a rapidly growing social media platform popular among individuals under 30. Specifically, we analyzed the content of the 100 most popular videos in English tagged with #chatgpt, which collectively garnered over 250 million views. Most of the videos we studied promoted the use of ChatGPT for tasks like writing essays or code. In addition, many videos discussed AI detectors, with a focus on how other tools can help to transform ChatGPT output to fool these detectors. This also mirrors the discussion among educators on how to treat ChatGPT as lecturers and teachers in teaching and grading. What is, however, missing from the analyzed clips on TikTok are videos that discuss ChatGPT producing content that is nonsensical or unfaithful to the training data.","link":"http://arxiv.org/abs/2303.05349v1","created":"2023-03-09","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data Advanced large language models like ChatGPT have gained considerable attention recently, including among students. However, while the debate on ChatGPT in academia is making waves, more understanding is needed among lecturers and teachers on how students use and perceive ChatGPT. To address this gap, we analyzed the content on ChatGPT available on TikTok in February 2023. TikTok is a rapidly growing social media platform popular among individuals under 30. Specifically, we analyzed the content of the 100 most popular videos in English tagged with #chatgpt, which collectively garnered over 250 million views. Most of the videos we studied promoted the use of ChatGPT for tasks like writing essays or code. In addition, many videos discussed AI detectors, with a focus on how other tools can help to transform ChatGPT output to fool these detectors. This also mirrors the discussion among educators on how to treat ChatGPT as lecturers and teachers in teaching and grading. What is, however, missing from the analyzed clips on TikTok are videos that discuss ChatGPT producing content that is nonsensical or unfaithful to the training data.","classes":{"dataset":0.1840863824}}
{"title":"Greener yet Powerful: Taming Large Code Generation Models with Quantization","description":"ML-powered code generation aims to assist developers to write code in a more productive manner, by intelligently generating code blocks based on natural language prompts. Recently, large pretrained deep learning models have substantially pushed the boundary of code generation and achieved impressive performance. Despite their great power, the huge number of model parameters poses a significant threat to adapting them in a regular software development environment, where a developer might use a standard laptop or mid-size server to develop her code. Such large models incur significant resource usage (in terms of memory, latency, and dollars) as well as carbon footprint.   Model compression is a promising approach to address these challenges. Several techniques are proposed to compress large pretrained models typically used for vision or textual data. Out of many available compression techniques, we identified that quantization is mostly applicable for code generation task as it does not require significant retraining cost. As quantization represents model parameters with lower-bit integer (e.g., int8), the model size and runtime latency would both benefit from such int representation. We extensively study the impact of quantized model on code generation tasks across different dimension: (i) resource usage and carbon footprint, (ii) accuracy, and (iii) robustness. To this end, through systematic experiments we find a recipe of quantization technique that could run even a $6$B model in a regular laptop without significant accuracy or robustness degradation. We further found the recipe is readily applicable to code summarization task as well.","link":"http://arxiv.org/abs/2303.05378v1","created":"2023-03-09","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Greener yet Powerful: Taming Large Code Generation Models with Quantization ML-powered code generation aims to assist developers to write code in a more productive manner, by intelligently generating code blocks based on natural language prompts. Recently, large pretrained deep learning models have substantially pushed the boundary of code generation and achieved impressive performance. Despite their great power, the huge number of model parameters poses a significant threat to adapting them in a regular software development environment, where a developer might use a standard laptop or mid-size server to develop her code. Such large models incur significant resource usage (in terms of memory, latency, and dollars) as well as carbon footprint.   Model compression is a promising approach to address these challenges. Several techniques are proposed to compress large pretrained models typically used for vision or textual data. Out of many available compression techniques, we identified that quantization is mostly applicable for code generation task as it does not require significant retraining cost. As quantization represents model parameters with lower-bit integer (e.g., int8), the model size and runtime latency would both benefit from such int representation. We extensively study the impact of quantized model on code generation tasks across different dimension: (i) resource usage and carbon footprint, (ii) accuracy, and (iii) robustness. To this end, through systematic experiments we find a recipe of quantization technique that could run even a $6$B model in a regular laptop without significant accuracy or robustness degradation. We further found the recipe is readily applicable to code summarization task as well.","classes":{"dataset":0.2011742592}}
{"title":"Fast kernel methods for Data Quality Monitoring as a goodness-of-fit test","description":"We here propose a machine learning approach for monitoring particle detectors in real-time. The goal is to assess the compatibility of incoming experimental data with a reference dataset, characterising the data behaviour under normal circumstances, via a likelihood-ratio hypothesis test. The model is based on a modern implementation of kernel methods, nonparametric algorithms that can learn any continuous function given enough data. The resulting approach is efficient and agnostic to the type of anomaly that may be present in the data. Our study demonstrates the effectiveness of this strategy on multivariate data from drift tube chamber muon detectors.","link":"http://arxiv.org/abs/2303.05413v1","created":"2023-03-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Fast kernel methods for Data Quality Monitoring as a goodness-of-fit test We here propose a machine learning approach for monitoring particle detectors in real-time. The goal is to assess the compatibility of incoming experimental data with a reference dataset, characterising the data behaviour under normal circumstances, via a likelihood-ratio hypothesis test. The model is based on a modern implementation of kernel methods, nonparametric algorithms that can learn any continuous function given enough data. The resulting approach is efficient and agnostic to the type of anomaly that may be present in the data. Our study demonstrates the effectiveness of this strategy on multivariate data from drift tube chamber muon detectors.","classes":{"dataset":0.3812006414}}
{"title":"Intriguing Property of GAN for Remote Sensing Image Generation","description":"Generative adversarial networks (GANs) have achieved remarkable progress in the natural image field. However, when applying GANs in the remote sensing (RS) image generation task, we discover an extraordinary phenomenon: the GAN model is more sensitive to the size of training data for RS image generation than for natural image generation. In other words, the generation quality of RS images will change significantly with the number of training categories or samples per category. In this paper, we first analyze this phenomenon from two kinds of toy experiments and conclude that the amount of feature information contained in the GAN model decreases with reduced training data. Based on this discovery, we propose two innovative adjustment schemes, namely Uniformity Regularization (UR) and Entropy Regularization (ER), to increase the information learned by the GAN model at the distributional and sample levels, respectively. We theoretically and empirically demonstrate the effectiveness and versatility of our methods. Extensive experiments on the NWPU-RESISC45 and PatternNet datasets show that our methods outperform the well-established models on RS image generation tasks.","link":"http://arxiv.org/abs/2303.05240v1","created":"2023-03-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Intriguing Property of GAN for Remote Sensing Image Generation Generative adversarial networks (GANs) have achieved remarkable progress in the natural image field. However, when applying GANs in the remote sensing (RS) image generation task, we discover an extraordinary phenomenon: the GAN model is more sensitive to the size of training data for RS image generation than for natural image generation. In other words, the generation quality of RS images will change significantly with the number of training categories or samples per category. In this paper, we first analyze this phenomenon from two kinds of toy experiments and conclude that the amount of feature information contained in the GAN model decreases with reduced training data. Based on this discovery, we propose two innovative adjustment schemes, namely Uniformity Regularization (UR) and Entropy Regularization (ER), to increase the information learned by the GAN model at the distributional and sample levels, respectively. We theoretically and empirically demonstrate the effectiveness and versatility of our methods. Extensive experiments on the NWPU-RESISC45 and PatternNet datasets show that our methods outperform the well-established models on RS image generation tasks.","classes":{"dataset":0.3154461682}}
{"title":"Segmentation method for cerebral blood vessels from MRA using hysteresis","description":"Segmentation of cerebral blood vessels from Magnetic Resonance Imaging (MRI) is an open problem that could be solved with deep learning (DL). However, annotated data for training is often scarce. Due to the absence of open-source tools, we aim to develop a classical segmentation method that generates vessel ground truth from Magnetic Resonance Angiography for DL training of segmentation across a variety of modalities. The method combines size-specific Hessian filters, hysteresis thresholding and connected component correction. The optimal choice of processing steps was evaluated with a blinded scoring by a clinician using 24 3D images. The results show that all method steps are necessary to produce the highest (14.2/15) vessel segmentation quality score. Omitting the connected component correction caused the largest quality loss. The method, which is available on GitHub, can be used to train DL models for vessel segmentation.","link":"http://arxiv.org/abs/2303.05113v1","created":"2023-03-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Segmentation method for cerebral blood vessels from MRA using hysteresis Segmentation of cerebral blood vessels from Magnetic Resonance Imaging (MRI) is an open problem that could be solved with deep learning (DL). However, annotated data for training is often scarce. Due to the absence of open-source tools, we aim to develop a classical segmentation method that generates vessel ground truth from Magnetic Resonance Angiography for DL training of segmentation across a variety of modalities. The method combines size-specific Hessian filters, hysteresis thresholding and connected component correction. The optimal choice of processing steps was evaluated with a blinded scoring by a clinician using 24 3D images. The results show that all method steps are necessary to produce the highest (14.2/15) vessel segmentation quality score. Omitting the connected component correction caused the largest quality loss. The method, which is available on GitHub, can be used to train DL models for vessel segmentation.","classes":{"dataset":0.2997263372}}
{"title":"Parallel Filtered Graphs for Hierarchical Clustering","description":"Given all pairwise weights (distances) among a set of objects, filtered graphs provide a sparse representation by only keeping an important subset of weights. Such graphs can be passed to graph clustering algorithms to generate hierarchical clusters. In particular, the directed bubble hierarchical tree (DBHT) algorithm on filtered graphs has been shown to produce good hierarchical clusters for time series data.   We propose a new parallel algorithm for constructing triangulated maximally filtered graphs (TMFG), which produces valid inputs for DBHT, and a scalable parallel algorithm for generating DBHTs that is optimized for TMFG inputs. In addition to parallelizing the original TMFG construction, which has limited parallelism, we also design a new algorithm that inserts multiple vertices on each round to enable more parallelism. We show that the graphs generated by our new algorithm have similar quality compared to the original TMFGs, while being much faster to generate. Our new parallel algorithms for TMFGs and DBHTs are 136--2483x faster than state-of-the-art implementations, while achieving up to 41.56x self-relative speedup on 48 cores with hyper-threading, and achieve better clustering results compared to the standard average-linkage and complete-linkage hierarchical clustering algorithms. We show that on a stock data set, our algorithms produce clusters that align well with human experts' classification.","link":"http://arxiv.org/abs/2303.05009v1","created":"2023-03-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Parallel Filtered Graphs for Hierarchical Clustering Given all pairwise weights (distances) among a set of objects, filtered graphs provide a sparse representation by only keeping an important subset of weights. Such graphs can be passed to graph clustering algorithms to generate hierarchical clusters. In particular, the directed bubble hierarchical tree (DBHT) algorithm on filtered graphs has been shown to produce good hierarchical clusters for time series data.   We propose a new parallel algorithm for constructing triangulated maximally filtered graphs (TMFG), which produces valid inputs for DBHT, and a scalable parallel algorithm for generating DBHTs that is optimized for TMFG inputs. In addition to parallelizing the original TMFG construction, which has limited parallelism, we also design a new algorithm that inserts multiple vertices on each round to enable more parallelism. We show that the graphs generated by our new algorithm have similar quality compared to the original TMFGs, while being much faster to generate. Our new parallel algorithms for TMFGs and DBHTs are 136--2483x faster than state-of-the-art implementations, while achieving up to 41.56x self-relative speedup on 48 cores with hyper-threading, and achieve better clustering results compared to the standard average-linkage and complete-linkage hierarchical clustering algorithms. We show that on a stock data set, our algorithms produce clusters that align well with human experts' classification.","classes":{"dataset":0.4510834217}}
{"title":"LMR: A Large-Scale Multi-Reference Dataset for Reference-based Super-Resolution","description":"It is widely agreed that reference-based super-resolution (RefSR) achieves superior results by referring to similar high quality images, compared to single image super-resolution (SISR). Intuitively, the more references, the better performance. However, previous RefSR methods have all focused on single-reference image training, while multiple reference images are often available in testing or practical applications. The root cause of such training-testing mismatch is the absence of publicly available multi-reference SR training datasets, which greatly hinders research efforts on multi-reference super-resolution. To this end, we construct a large-scale, multi-reference super-resolution dataset, named LMR. It contains 112,142 groups of 300x300 training images, which is 10x of the existing largest RefSR dataset. The image size is also much larger. More importantly, each group is equipped with 5 reference images with different similarity levels. Furthermore, we propose a new baseline method for multi-reference super-resolution: MRefSR, including a Multi-Reference Attention Module (MAM) for feature fusion of an arbitrary number of reference images, and a Spatial Aware Filtering Module (SAFM) for the fused feature selection. The proposed MRefSR achieves significant improvements over state-of-the-art approaches on both quantitative and qualitative evaluations. Our code and data would be made available soon.","link":"http://arxiv.org/abs/2303.04970v1","created":"2023-03-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"LMR: A Large-Scale Multi-Reference Dataset for Reference-based Super-Resolution It is widely agreed that reference-based super-resolution (RefSR) achieves superior results by referring to similar high quality images, compared to single image super-resolution (SISR). Intuitively, the more references, the better performance. However, previous RefSR methods have all focused on single-reference image training, while multiple reference images are often available in testing or practical applications. The root cause of such training-testing mismatch is the absence of publicly available multi-reference SR training datasets, which greatly hinders research efforts on multi-reference super-resolution. To this end, we construct a large-scale, multi-reference super-resolution dataset, named LMR. It contains 112,142 groups of 300x300 training images, which is 10x of the existing largest RefSR dataset. The image size is also much larger. More importantly, each group is equipped with 5 reference images with different similarity levels. Furthermore, we propose a new baseline method for multi-reference super-resolution: MRefSR, including a Multi-Reference Attention Module (MAM) for feature fusion of an arbitrary number of reference images, and a Spatial Aware Filtering Module (SAFM) for the fused feature selection. The proposed MRefSR achieves significant improvements over state-of-the-art approaches on both quantitative and qualitative evaluations. Our code and data would be made available soon.","classes":{"dataset":0.0307024177}}
{"title":"BaDLAD: A Large Multi-Domain Bengali Document Layout Analysis Dataset","description":"While strides have been made in deep learning based Bengali Optical Character Recognition (OCR) in the past decade, the absence of large Document Layout Analysis (DLA) datasets has hindered the application of OCR in document transcription, e.g., transcribing historical documents and newspapers. Moreover, rule-based DLA systems that are currently being employed in practice are not robust to domain variations and out-of-distribution layouts. To this end, we present the first multidomain large Bengali Document Layout Analysis Dataset: BaDLAD. This dataset contains 33,695 human annotated document samples from six domains - i) books and magazines, ii) public domain govt. documents, iii) liberation war documents, iv) newspapers, v) historical newspapers, and vi) property deeds, with 710K polygon annotations for four unit types: text-box, paragraph, image, and table. Through preliminary experiments benchmarking the performance of existing state-of-the-art deep learning architectures for English DLA, we demonstrate the efficacy of our dataset in training deep learning based Bengali document digitization models.","link":"http://arxiv.org/abs/2303.05325v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"BaDLAD: A Large Multi-Domain Bengali Document Layout Analysis Dataset While strides have been made in deep learning based Bengali Optical Character Recognition (OCR) in the past decade, the absence of large Document Layout Analysis (DLA) datasets has hindered the application of OCR in document transcription, e.g., transcribing historical documents and newspapers. Moreover, rule-based DLA systems that are currently being employed in practice are not robust to domain variations and out-of-distribution layouts. To this end, we present the first multidomain large Bengali Document Layout Analysis Dataset: BaDLAD. This dataset contains 33,695 human annotated document samples from six domains - i) books and magazines, ii) public domain govt. documents, iii) liberation war documents, iv) newspapers, v) historical newspapers, and vi) property deeds, with 710K polygon annotations for four unit types: text-box, paragraph, image, and table. Through preliminary experiments benchmarking the performance of existing state-of-the-art deep learning architectures for English DLA, we demonstrate the efficacy of our dataset in training deep learning based Bengali document digitization models.","classes":{"dataset":0.9660897851}}
{"title":"Dataset CYLinCF-01 creation pipeline: Circular cylinder in a cross flow, Mach Number 0.03 and Reynolds Number 200","description":"This article presents an aeroacoustic workflow (pipeline) to generate a flow and acoustic dataset for studying flow-induced sound in the context of a cylinder in cross flow. The numerical simulations are performed using OpenFOAM for the flow and openCFS for acoustics using the perturbed convective wave equation (PCWE). The workflow involves several steps, including the flow simulation, the acoustic simulation, and post-processing of the results. The simulation workflow is presented in all its details. The analysis focuses on the acoustic characteristics of the flow, including sound pressure levels, frequency spectra, and directivity patterns. The results show good agreement with the literature. The article concludes by discussing applications of the workflow for different cases that involve flow-induced sound generation.","link":"http://arxiv.org/abs/2303.05265v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Dataset CYLinCF-01 creation pipeline: Circular cylinder in a cross flow, Mach Number 0.03 and Reynolds Number 200 This article presents an aeroacoustic workflow (pipeline) to generate a flow and acoustic dataset for studying flow-induced sound in the context of a cylinder in cross flow. The numerical simulations are performed using OpenFOAM for the flow and openCFS for acoustics using the perturbed convective wave equation (PCWE). The workflow involves several steps, including the flow simulation, the acoustic simulation, and post-processing of the results. The simulation workflow is presented in all its details. The analysis focuses on the acoustic characteristics of the flow, including sound pressure levels, frequency spectra, and directivity patterns. The results show good agreement with the literature. The article concludes by discussing applications of the workflow for different cases that involve flow-induced sound generation.","classes":{"dataset":0.4694412947}}
{"title":"Dominating Set Database Selection for Visual Place Recognition","description":"This paper presents an approach for creating a visual place recognition (VPR) database for localization in indoor environments from RGBD scanning sequences. The proposed approach is formulated as a minimization problem in terms of dominating set algorithm for graph, constructed from spatial information, and referred as DominatingSet. Our algorithm shows better scene coverage in comparison to other methodologies that are used for database creation. Also, we demonstrate that using DominatingSet, a database size could be up to 250-1400 times smaller than the original scanning sequence while maintaining a recall rate of more than 80% on testing sequences. We evaluated our algorithm on 7-scenes and BundleFusion datasets and an additionally recorded sequence in a highly repetitive office setting. In addition, the database selection can produce weakly-supervised labels for fine-tuning neural place recognition algorithms to particular settings, improving even more their accuracy. The paper also presents a fully automated pipeline for VPR database creation from RGBD scanning sequences, as well as a set of metrics for VPR database evaluation. The code and released data are available on our web-page~ -- https://prime-slam.github.io/place-recognition-db/","link":"http://arxiv.org/abs/2303.05123v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Dominating Set Database Selection for Visual Place Recognition This paper presents an approach for creating a visual place recognition (VPR) database for localization in indoor environments from RGBD scanning sequences. The proposed approach is formulated as a minimization problem in terms of dominating set algorithm for graph, constructed from spatial information, and referred as DominatingSet. Our algorithm shows better scene coverage in comparison to other methodologies that are used for database creation. Also, we demonstrate that using DominatingSet, a database size could be up to 250-1400 times smaller than the original scanning sequence while maintaining a recall rate of more than 80% on testing sequences. We evaluated our algorithm on 7-scenes and BundleFusion datasets and an additionally recorded sequence in a highly repetitive office setting. In addition, the database selection can produce weakly-supervised labels for fine-tuning neural place recognition algorithms to particular settings, improving even more their accuracy. The paper also presents a fully automated pipeline for VPR database creation from RGBD scanning sequences, as well as a set of metrics for VPR database evaluation. The code and released data are available on our web-page~ -- https://prime-slam.github.io/place-recognition-db/","classes":{"dataset":0.0346765295}}
{"title":"StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent Disentangled Space","description":"One major challenge in machine learning applications is coping with mismatches between the datasets used in the development and those obtained in real-world applications. These mismatches may lead to inaccurate predictions and errors, resulting in poor product quality and unreliable systems. In this study, we propose StyleDiff to inform developers of the differences between the two datasets for the steady development of machine learning systems. Using disentangled image spaces obtained from recently proposed generative models, StyleDiff compares the two datasets by focusing on attributes in the images and provides an easy-to-understand analysis of the differences between the datasets. The proposed StyleDiff performs in $O (d N\\log N)$, where $N$ is the size of the datasets and $d$ is the number of attributes, enabling the application to large datasets. We demonstrate that StyleDiff accurately detects differences between datasets and presents them in an understandable format using, for example, driving scenes datasets.","link":"http://arxiv.org/abs/2303.05102v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent Disentangled Space One major challenge in machine learning applications is coping with mismatches between the datasets used in the development and those obtained in real-world applications. These mismatches may lead to inaccurate predictions and errors, resulting in poor product quality and unreliable systems. In this study, we propose StyleDiff to inform developers of the differences between the two datasets for the steady development of machine learning systems. Using disentangled image spaces obtained from recently proposed generative models, StyleDiff compares the two datasets by focusing on attributes in the images and provides an easy-to-understand analysis of the differences between the datasets. The proposed StyleDiff performs in $O (d N\\log N)$, where $N$ is the size of the datasets and $d$ is the number of attributes, enabling the application to large datasets. We demonstrate that StyleDiff accurately detects differences between datasets and presents them in an understandable format using, for example, driving scenes datasets.","classes":{"dataset":0.0158727784}}
{"title":"Contributing to Accessibility Datasets: Reflections on Sharing Study Data by Blind People","description":"To ensure that AI-infused systems work for disabled people, we need to bring accessibility datasets sourced from this community in the development lifecycle. However, there are many ethical and privacy concerns limiting greater data inclusion, making such datasets not readily available. We present a pair of studies where 13 blind participants engage in data capturing activities and reflect with and without probing on various factors that influence their decision to share their data via an AI dataset. We see how different factors influence blind participants' willingness to share study data as they assess risk-benefit tradeoffs. The majority support sharing of their data to improve technology but also express concerns over commercial use, associated metadata, and the lack of transparency about the impact of their data. These insights have implications for the development of responsible practices for stewarding accessibility datasets, and can contribute to broader discussions in this area.","link":"http://arxiv.org/abs/2303.04962v1","created":"2023-03-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Contributing to Accessibility Datasets: Reflections on Sharing Study Data by Blind People To ensure that AI-infused systems work for disabled people, we need to bring accessibility datasets sourced from this community in the development lifecycle. However, there are many ethical and privacy concerns limiting greater data inclusion, making such datasets not readily available. We present a pair of studies where 13 blind participants engage in data capturing activities and reflect with and without probing on various factors that influence their decision to share their data via an AI dataset. We see how different factors influence blind participants' willingness to share study data as they assess risk-benefit tradeoffs. The majority support sharing of their data to improve technology but also express concerns over commercial use, associated metadata, and the lack of transparency about the impact of their data. These insights have implications for the development of responsible practices for stewarding accessibility datasets, and can contribute to broader discussions in this area.","classes":{"dataset":0.9705153704}}
{"title":"FedREP: A Byzantine-Robust, Communication-Efficient and Privacy-Preserving Framework for Federated Learning","description":"Federated learning (FL) has recently become a hot research topic, in which Byzantine robustness, communication efficiency and privacy preservation are three important aspects. However, the tension among these three aspects makes it hard to simultaneously take all of them into account. In view of this challenge, we theoretically analyze the conditions that a communication compression method should satisfy to be compatible with existing Byzantine-robust methods and privacy-preserving methods. Motivated by the analysis results, we propose a novel communication compression method called consensus sparsification (ConSpar). To the best of our knowledge, ConSpar is the first communication compression method that is designed to be compatible with both Byzantine-robust methods and privacy-preserving methods. Based on ConSpar, we further propose a novel FL framework called FedREP, which is Byzantine-robust, communication-efficient and privacy-preserving. We theoretically prove the Byzantine robustness and the convergence of FedREP. Empirical results show that FedREP can significantly outperform communication-efficient privacy-preserving baselines. Furthermore, compared with Byzantine-robust communication-efficient baselines, FedREP can achieve comparable accuracy with the extra advantage of privacy preservation.","link":"http://arxiv.org/abs/2303.05206v1","created":"2023-03-09","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"FedREP: A Byzantine-Robust, Communication-Efficient and Privacy-Preserving Framework for Federated Learning Federated learning (FL) has recently become a hot research topic, in which Byzantine robustness, communication efficiency and privacy preservation are three important aspects. However, the tension among these three aspects makes it hard to simultaneously take all of them into account. In view of this challenge, we theoretically analyze the conditions that a communication compression method should satisfy to be compatible with existing Byzantine-robust methods and privacy-preserving methods. Motivated by the analysis results, we propose a novel communication compression method called consensus sparsification (ConSpar). To the best of our knowledge, ConSpar is the first communication compression method that is designed to be compatible with both Byzantine-robust methods and privacy-preserving methods. Based on ConSpar, we further propose a novel FL framework called FedREP, which is Byzantine-robust, communication-efficient and privacy-preserving. We theoretically prove the Byzantine robustness and the convergence of FedREP. Empirical results show that FedREP can significantly outperform communication-efficient privacy-preserving baselines. Furthermore, compared with Byzantine-robust communication-efficient baselines, FedREP can achieve comparable accuracy with the extra advantage of privacy preservation.","classes":{"dataset":0.209562853}}
{"title":"Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data","description":"Advanced large language models like ChatGPT have gained considerable attention recently, including among students. However, while the debate on ChatGPT in academia is making waves, more understanding is needed among lecturers and teachers on how students use and perceive ChatGPT. To address this gap, we analyzed the content on ChatGPT available on TikTok in February 2023. TikTok is a rapidly growing social media platform popular among individuals under 30. Specifically, we analyzed the content of the 100 most popular videos in English tagged with #chatgpt, which collectively garnered over 250 million views. Most of the videos we studied promoted the use of ChatGPT for tasks like writing essays or code. In addition, many videos discussed AI detectors, with a focus on how other tools can help to transform ChatGPT output to fool these detectors. This also mirrors the discussion among educators on how to treat ChatGPT as lecturers and teachers in teaching and grading. What is, however, missing from the analyzed clips on TikTok are videos that discuss ChatGPT producing content that is nonsensical or unfaithful to the training data.","link":"http://arxiv.org/abs/2303.05349v1","created":"2023-03-09","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data Advanced large language models like ChatGPT have gained considerable attention recently, including among students. However, while the debate on ChatGPT in academia is making waves, more understanding is needed among lecturers and teachers on how students use and perceive ChatGPT. To address this gap, we analyzed the content on ChatGPT available on TikTok in February 2023. TikTok is a rapidly growing social media platform popular among individuals under 30. Specifically, we analyzed the content of the 100 most popular videos in English tagged with #chatgpt, which collectively garnered over 250 million views. Most of the videos we studied promoted the use of ChatGPT for tasks like writing essays or code. In addition, many videos discussed AI detectors, with a focus on how other tools can help to transform ChatGPT output to fool these detectors. This also mirrors the discussion among educators on how to treat ChatGPT as lecturers and teachers in teaching and grading. What is, however, missing from the analyzed clips on TikTok are videos that discuss ChatGPT producing content that is nonsensical or unfaithful to the training data.","classes":{"dataset":0.1840863824}}
{"title":"Greener yet Powerful: Taming Large Code Generation Models with Quantization","description":"ML-powered code generation aims to assist developers to write code in a more productive manner, by intelligently generating code blocks based on natural language prompts. Recently, large pretrained deep learning models have substantially pushed the boundary of code generation and achieved impressive performance. Despite their great power, the huge number of model parameters poses a significant threat to adapting them in a regular software development environment, where a developer might use a standard laptop or mid-size server to develop her code. Such large models incur significant resource usage (in terms of memory, latency, and dollars) as well as carbon footprint.   Model compression is a promising approach to address these challenges. Several techniques are proposed to compress large pretrained models typically used for vision or textual data. Out of many available compression techniques, we identified that quantization is mostly applicable for code generation task as it does not require significant retraining cost. As quantization represents model parameters with lower-bit integer (e.g., int8), the model size and runtime latency would both benefit from such int representation. We extensively study the impact of quantized model on code generation tasks across different dimension: (i) resource usage and carbon footprint, (ii) accuracy, and (iii) robustness. To this end, through systematic experiments we find a recipe of quantization technique that could run even a $6$B model in a regular laptop without significant accuracy or robustness degradation. We further found the recipe is readily applicable to code summarization task as well.","link":"http://arxiv.org/abs/2303.05378v1","created":"2023-03-09","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Greener yet Powerful: Taming Large Code Generation Models with Quantization ML-powered code generation aims to assist developers to write code in a more productive manner, by intelligently generating code blocks based on natural language prompts. Recently, large pretrained deep learning models have substantially pushed the boundary of code generation and achieved impressive performance. Despite their great power, the huge number of model parameters poses a significant threat to adapting them in a regular software development environment, where a developer might use a standard laptop or mid-size server to develop her code. Such large models incur significant resource usage (in terms of memory, latency, and dollars) as well as carbon footprint.   Model compression is a promising approach to address these challenges. Several techniques are proposed to compress large pretrained models typically used for vision or textual data. Out of many available compression techniques, we identified that quantization is mostly applicable for code generation task as it does not require significant retraining cost. As quantization represents model parameters with lower-bit integer (e.g., int8), the model size and runtime latency would both benefit from such int representation. We extensively study the impact of quantized model on code generation tasks across different dimension: (i) resource usage and carbon footprint, (ii) accuracy, and (iii) robustness. To this end, through systematic experiments we find a recipe of quantization technique that could run even a $6$B model in a regular laptop without significant accuracy or robustness degradation. We further found the recipe is readily applicable to code summarization task as well.","classes":{"dataset":0.2011742592}}
{"title":"Fast kernel methods for Data Quality Monitoring as a goodness-of-fit test","description":"We here propose a machine learning approach for monitoring particle detectors in real-time. The goal is to assess the compatibility of incoming experimental data with a reference dataset, characterising the data behaviour under normal circumstances, via a likelihood-ratio hypothesis test. The model is based on a modern implementation of kernel methods, nonparametric algorithms that can learn any continuous function given enough data. The resulting approach is efficient and agnostic to the type of anomaly that may be present in the data. Our study demonstrates the effectiveness of this strategy on multivariate data from drift tube chamber muon detectors.","link":"http://arxiv.org/abs/2303.05413v1","created":"2023-03-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Fast kernel methods for Data Quality Monitoring as a goodness-of-fit test We here propose a machine learning approach for monitoring particle detectors in real-time. The goal is to assess the compatibility of incoming experimental data with a reference dataset, characterising the data behaviour under normal circumstances, via a likelihood-ratio hypothesis test. The model is based on a modern implementation of kernel methods, nonparametric algorithms that can learn any continuous function given enough data. The resulting approach is efficient and agnostic to the type of anomaly that may be present in the data. Our study demonstrates the effectiveness of this strategy on multivariate data from drift tube chamber muon detectors.","classes":{"dataset":0.3812006414}}
{"title":"Intriguing Property of GAN for Remote Sensing Image Generation","description":"Generative adversarial networks (GANs) have achieved remarkable progress in the natural image field. However, when applying GANs in the remote sensing (RS) image generation task, we discover an extraordinary phenomenon: the GAN model is more sensitive to the size of training data for RS image generation than for natural image generation. In other words, the generation quality of RS images will change significantly with the number of training categories or samples per category. In this paper, we first analyze this phenomenon from two kinds of toy experiments and conclude that the amount of feature information contained in the GAN model decreases with reduced training data. Based on this discovery, we propose two innovative adjustment schemes, namely Uniformity Regularization (UR) and Entropy Regularization (ER), to increase the information learned by the GAN model at the distributional and sample levels, respectively. We theoretically and empirically demonstrate the effectiveness and versatility of our methods. Extensive experiments on the NWPU-RESISC45 and PatternNet datasets show that our methods outperform the well-established models on RS image generation tasks.","link":"http://arxiv.org/abs/2303.05240v1","created":"2023-03-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Intriguing Property of GAN for Remote Sensing Image Generation Generative adversarial networks (GANs) have achieved remarkable progress in the natural image field. However, when applying GANs in the remote sensing (RS) image generation task, we discover an extraordinary phenomenon: the GAN model is more sensitive to the size of training data for RS image generation than for natural image generation. In other words, the generation quality of RS images will change significantly with the number of training categories or samples per category. In this paper, we first analyze this phenomenon from two kinds of toy experiments and conclude that the amount of feature information contained in the GAN model decreases with reduced training data. Based on this discovery, we propose two innovative adjustment schemes, namely Uniformity Regularization (UR) and Entropy Regularization (ER), to increase the information learned by the GAN model at the distributional and sample levels, respectively. We theoretically and empirically demonstrate the effectiveness and versatility of our methods. Extensive experiments on the NWPU-RESISC45 and PatternNet datasets show that our methods outperform the well-established models on RS image generation tasks.","classes":{"dataset":0.3154461682}}
{"title":"Segmentation method for cerebral blood vessels from MRA using hysteresis","description":"Segmentation of cerebral blood vessels from Magnetic Resonance Imaging (MRI) is an open problem that could be solved with deep learning (DL). However, annotated data for training is often scarce. Due to the absence of open-source tools, we aim to develop a classical segmentation method that generates vessel ground truth from Magnetic Resonance Angiography for DL training of segmentation across a variety of modalities. The method combines size-specific Hessian filters, hysteresis thresholding and connected component correction. The optimal choice of processing steps was evaluated with a blinded scoring by a clinician using 24 3D images. The results show that all method steps are necessary to produce the highest (14.2/15) vessel segmentation quality score. Omitting the connected component correction caused the largest quality loss. The method, which is available on GitHub, can be used to train DL models for vessel segmentation.","link":"http://arxiv.org/abs/2303.05113v1","created":"2023-03-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Segmentation method for cerebral blood vessels from MRA using hysteresis Segmentation of cerebral blood vessels from Magnetic Resonance Imaging (MRI) is an open problem that could be solved with deep learning (DL). However, annotated data for training is often scarce. Due to the absence of open-source tools, we aim to develop a classical segmentation method that generates vessel ground truth from Magnetic Resonance Angiography for DL training of segmentation across a variety of modalities. The method combines size-specific Hessian filters, hysteresis thresholding and connected component correction. The optimal choice of processing steps was evaluated with a blinded scoring by a clinician using 24 3D images. The results show that all method steps are necessary to produce the highest (14.2/15) vessel segmentation quality score. Omitting the connected component correction caused the largest quality loss. The method, which is available on GitHub, can be used to train DL models for vessel segmentation.","classes":{"dataset":0.2997263372}}
{"title":"Parallel Filtered Graphs for Hierarchical Clustering","description":"Given all pairwise weights (distances) among a set of objects, filtered graphs provide a sparse representation by only keeping an important subset of weights. Such graphs can be passed to graph clustering algorithms to generate hierarchical clusters. In particular, the directed bubble hierarchical tree (DBHT) algorithm on filtered graphs has been shown to produce good hierarchical clusters for time series data.   We propose a new parallel algorithm for constructing triangulated maximally filtered graphs (TMFG), which produces valid inputs for DBHT, and a scalable parallel algorithm for generating DBHTs that is optimized for TMFG inputs. In addition to parallelizing the original TMFG construction, which has limited parallelism, we also design a new algorithm that inserts multiple vertices on each round to enable more parallelism. We show that the graphs generated by our new algorithm have similar quality compared to the original TMFGs, while being much faster to generate. Our new parallel algorithms for TMFGs and DBHTs are 136--2483x faster than state-of-the-art implementations, while achieving up to 41.56x self-relative speedup on 48 cores with hyper-threading, and achieve better clustering results compared to the standard average-linkage and complete-linkage hierarchical clustering algorithms. We show that on a stock data set, our algorithms produce clusters that align well with human experts' classification.","link":"http://arxiv.org/abs/2303.05009v1","created":"2023-03-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Parallel Filtered Graphs for Hierarchical Clustering Given all pairwise weights (distances) among a set of objects, filtered graphs provide a sparse representation by only keeping an important subset of weights. Such graphs can be passed to graph clustering algorithms to generate hierarchical clusters. In particular, the directed bubble hierarchical tree (DBHT) algorithm on filtered graphs has been shown to produce good hierarchical clusters for time series data.   We propose a new parallel algorithm for constructing triangulated maximally filtered graphs (TMFG), which produces valid inputs for DBHT, and a scalable parallel algorithm for generating DBHTs that is optimized for TMFG inputs. In addition to parallelizing the original TMFG construction, which has limited parallelism, we also design a new algorithm that inserts multiple vertices on each round to enable more parallelism. We show that the graphs generated by our new algorithm have similar quality compared to the original TMFGs, while being much faster to generate. Our new parallel algorithms for TMFGs and DBHTs are 136--2483x faster than state-of-the-art implementations, while achieving up to 41.56x self-relative speedup on 48 cores with hyper-threading, and achieve better clustering results compared to the standard average-linkage and complete-linkage hierarchical clustering algorithms. We show that on a stock data set, our algorithms produce clusters that align well with human experts' classification.","classes":{"dataset":0.4510834217}}
{"title":"LMR: A Large-Scale Multi-Reference Dataset for Reference-based Super-Resolution","description":"It is widely agreed that reference-based super-resolution (RefSR) achieves superior results by referring to similar high quality images, compared to single image super-resolution (SISR). Intuitively, the more references, the better performance. However, previous RefSR methods have all focused on single-reference image training, while multiple reference images are often available in testing or practical applications. The root cause of such training-testing mismatch is the absence of publicly available multi-reference SR training datasets, which greatly hinders research efforts on multi-reference super-resolution. To this end, we construct a large-scale, multi-reference super-resolution dataset, named LMR. It contains 112,142 groups of 300x300 training images, which is 10x of the existing largest RefSR dataset. The image size is also much larger. More importantly, each group is equipped with 5 reference images with different similarity levels. Furthermore, we propose a new baseline method for multi-reference super-resolution: MRefSR, including a Multi-Reference Attention Module (MAM) for feature fusion of an arbitrary number of reference images, and a Spatial Aware Filtering Module (SAFM) for the fused feature selection. The proposed MRefSR achieves significant improvements over state-of-the-art approaches on both quantitative and qualitative evaluations. Our code and data would be made available soon.","link":"http://arxiv.org/abs/2303.04970v1","created":"2023-03-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"LMR: A Large-Scale Multi-Reference Dataset for Reference-based Super-Resolution It is widely agreed that reference-based super-resolution (RefSR) achieves superior results by referring to similar high quality images, compared to single image super-resolution (SISR). Intuitively, the more references, the better performance. However, previous RefSR methods have all focused on single-reference image training, while multiple reference images are often available in testing or practical applications. The root cause of such training-testing mismatch is the absence of publicly available multi-reference SR training datasets, which greatly hinders research efforts on multi-reference super-resolution. To this end, we construct a large-scale, multi-reference super-resolution dataset, named LMR. It contains 112,142 groups of 300x300 training images, which is 10x of the existing largest RefSR dataset. The image size is also much larger. More importantly, each group is equipped with 5 reference images with different similarity levels. Furthermore, we propose a new baseline method for multi-reference super-resolution: MRefSR, including a Multi-Reference Attention Module (MAM) for feature fusion of an arbitrary number of reference images, and a Spatial Aware Filtering Module (SAFM) for the fused feature selection. The proposed MRefSR achieves significant improvements over state-of-the-art approaches on both quantitative and qualitative evaluations. Our code and data would be made available soon.","classes":{"dataset":0.0307024177}}
{"title":"Carp lang: statically typed Lisp, no GC","description":"https://www.eriksvedang.com/carp","link":"https://www.eriksvedang.com/carp","created":"2023-03-10","tags":["hackernews"],"meta":{"score":37},"text":"Carp lang: statically typed Lisp, no GC https://www.eriksvedang.com/carp","classes":{"dataset":0.5324056149}}
{"title":"SPA view transitions land in Chrome 111","description":"https://developer.chrome.com/blog/spa-view-transitions-land/","link":"https://developer.chrome.com/blog/spa-view-transitions-land/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":87},"text":"SPA view transitions land in Chrome 111 https://developer.chrome.com/blog/spa-view-transitions-land/","classes":{"dataset":0.5053132176}}
{"title":"Visual ChatGPT","description":"https://github.com/microsoft/visual-chatgpt","link":"https://github.com/microsoft/visual-chatgpt","created":"2023-03-10","tags":["hackernews"],"meta":{"score":323},"text":"Visual ChatGPT https://github.com/microsoft/visual-chatgpt","classes":{"dataset":0.4965943694}}
{"title":"Serverless maps at 1/700 the cost of Google Maps API","description":"https://protomaps.com/blog/serverless-maps-now-open-source","link":"https://protomaps.com/blog/serverless-maps-now-open-source","created":"2023-03-10","tags":["hackernews"],"meta":{"score":98},"text":"Serverless maps at 1/700 the cost of Google Maps API https://protomaps.com/blog/serverless-maps-now-open-source","classes":{"dataset":0.4964434803}}
{"title":"OpenHV \u2013 Open-Source Pixelart Science-Fiction Real-Time-Strategy Game","description":"https://www.openhv.net/","link":"https://www.openhv.net/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":24},"text":"OpenHV \u2013 Open-Source Pixelart Science-Fiction Real-Time-Strategy Game https://www.openhv.net/","classes":{"dataset":0.5215357542}}
{"title":"An experimental beach barrier could be key to rebuilding eroding coastlines","description":"https://hakaimagazine.com/features/washaway-no-more-an-experimental-beach-barrier-could-be-key-to-rebuilding-eroding-coastlines/","link":"https://hakaimagazine.com/features/washaway-no-more-an-experimental-beach-barrier-could-be-key-to-rebuilding-eroding-coastlines/","created":"2023-03-08","tags":["hackernews"],"meta":{"score":58},"text":"An experimental beach barrier could be key to rebuilding eroding coastlines https://hakaimagazine.com/features/washaway-no-more-an-experimental-beach-barrier-could-be-key-to-rebuilding-eroding-coastlines/","classes":{"dataset":0.5053247213}}
{"title":"Google dusts off the Google+ playbook to fight ChatGPT","description":"https://arstechnica.com/gadgets/2023/03/google-dusts-off-the-failed-google-playbook-to-fight-chatgpt/","link":"https://arstechnica.com/gadgets/2023/03/google-dusts-off-the-failed-google-playbook-to-fight-chatgpt/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":121},"text":"Google dusts off the Google+ playbook to fight ChatGPT https://arstechnica.com/gadgets/2023/03/google-dusts-off-the-failed-google-playbook-to-fight-chatgpt/","classes":{"dataset":0.5181413889}}
{"title":"Getting LUKS, Btrfs, Hibernation and Swap file working in tandem","description":"https://nwb.sh/btrfs_swapfile_hibernation/","link":"https://nwb.sh/btrfs_swapfile_hibernation/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":51},"text":"Getting LUKS, Btrfs, Hibernation and Swap file working in tandem https://nwb.sh/btrfs_swapfile_hibernation/","classes":{"dataset":0.4552006125}}
{"title":"How to make sense of intelligence leaks","description":"https://www.economist.com/the-economist-explains/2023/03/09/how-to-make-sense-of-intelligence-leaks","link":"https://www.economist.com/the-economist-explains/2023/03/09/how-to-make-sense-of-intelligence-leaks","created":"2023-03-10","tags":["hackernews"],"meta":{"score":7},"text":"How to make sense of intelligence leaks https://www.economist.com/the-economist-explains/2023/03/09/how-to-make-sense-of-intelligence-leaks","classes":{"dataset":0.4438689351}}
{"title":"GM offers buyouts to \u2018majority\u2019 of U.S. salaried workers","description":"https://www.cnbc.com/2023/03/09/gm-buyouts-us-salaried-workers.html","link":"https://www.cnbc.com/2023/03/09/gm-buyouts-us-salaried-workers.html","created":"2023-03-10","tags":["hackernews"],"meta":{"score":17},"text":"GM offers buyouts to \u2018majority\u2019 of U.S. salaried workers https://www.cnbc.com/2023/03/09/gm-buyouts-us-salaried-workers.html","classes":{"dataset":0.491925925}}
{"title":"Nearly 40% of software engineers will only work remotely","description":"https://www.techtarget.com/searchhrsoftware/news/365531979/Nearly-40-of-software-engineers-will-only-work-remotely","link":"https://www.techtarget.com/searchhrsoftware/news/365531979/Nearly-40-of-software-engineers-will-only-work-remotely","created":"2023-03-10","tags":["hackernews"],"meta":{"score":141},"text":"Nearly 40% of software engineers will only work remotely https://www.techtarget.com/searchhrsoftware/news/365531979/Nearly-40-of-software-engineers-will-only-work-remotely","classes":{"dataset":0.5081273317}}
{"title":"What does \"Copy clean link\" mean?","description":"https://support.brave.com/hc/en-us/articles/9982188779405-What-does-Copy-clean-link-mean-","link":"https://support.brave.com/hc/en-us/articles/9982188779405-What-does-Copy-clean-link-mean-","created":"2023-03-09","tags":["hackernews"],"meta":{"score":350},"text":"What does \"Copy clean link\" mean? https://support.brave.com/hc/en-us/articles/9982188779405-What-does-Copy-clean-link-mean-","classes":{"dataset":0.4680056274}}
{"title":"Zig: The Modern Alternative to C","description":"https://www.infoworld.com/article/3689648/meet-the-zig-programming-language.html","link":"https://www.infoworld.com/article/3689648/meet-the-zig-programming-language.html","created":"2023-03-10","tags":["hackernews"],"meta":{"score":74},"text":"Zig: The Modern Alternative to C https://www.infoworld.com/article/3689648/meet-the-zig-programming-language.html","classes":{"dataset":0.5692802668}}
{"title":"JavaScript and TypeScript features of the last 3 years","description":"https://medium.com/@LinusSchlumberger/all-javascript-and-typescript-features-of-the-last-3-years-629c57e73e42","link":"https://medium.com/@LinusSchlumberger/all-javascript-and-typescript-features-of-the-last-3-years-629c57e73e42","created":"2023-03-09","tags":["hackernews"],"meta":{"score":417},"text":"JavaScript and TypeScript features of the last 3 years https://medium.com/@LinusSchlumberger/all-javascript-and-typescript-features-of-the-last-3-years-629c57e73e42","classes":{"dataset":0.4741664827}}
{"title":"How much power do autonomous vehicles use? A lot","description":"https://www.eetimes.com/how-much-power-do-autonomous-vehicles-use-a-lot/","link":"https://www.eetimes.com/how-much-power-do-autonomous-vehicles-use-a-lot/","created":"2023-03-07","tags":["hackernews"],"meta":{"score":41},"text":"How much power do autonomous vehicles use? A lot https://www.eetimes.com/how-much-power-do-autonomous-vehicles-use-a-lot/","classes":{"dataset":0.5217086077}}
{"title":"U.S. solar and storage manufacturing jobs expected to grow to 115,000 by 2030","description":"https://ieefa.org/articles/us-solar-and-storage-manufacturing-jobs-expected-grow-115000-2030","link":"https://ieefa.org/articles/us-solar-and-storage-manufacturing-jobs-expected-grow-115000-2030","created":"2023-03-09","tags":["hackernews"],"meta":{"score":142},"text":"U.S. solar and storage manufacturing jobs expected to grow to 115,000 by 2030 https://ieefa.org/articles/us-solar-and-storage-manufacturing-jobs-expected-grow-115000-2030","classes":{"dataset":0.5078145266}}
{"title":"The familiar story of the 17th century told through unfamiliar voices","description":"https://www.historytoday.com/archive/review/flammable-isle","link":"https://www.historytoday.com/archive/review/flammable-isle","created":"2023-03-09","tags":["hackernews"],"meta":{"score":24},"text":"The familiar story of the 17th century told through unfamiliar voices https://www.historytoday.com/archive/review/flammable-isle","classes":{"dataset":0.5046568513}}
{"title":"Show HN: APIRank.dev \u2013 We crawled and ranked public APIs from the internet","description":"https://apirank.dev/","link":"https://apirank.dev/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":153},"text":"Show HN: APIRank.dev \u2013 We crawled and ranked public APIs from the internet https://apirank.dev/","classes":{"dataset":0.5142202973}}
{"title":"Lisp-powered laptop with a battery life measured in years","description":"https://www.hackster.io/news/andreas-eriksen-s-potatop-is-a-lisp-powered-laptop-with-a-battery-life-measured-in-years-2f5d79653f24","link":"https://www.hackster.io/news/andreas-eriksen-s-potatop-is-a-lisp-powered-laptop-with-a-battery-life-measured-in-years-2f5d79653f24","created":"2023-03-08","tags":["hackernews"],"meta":{"score":777},"text":"Lisp-powered laptop with a battery life measured in years https://www.hackster.io/news/andreas-eriksen-s-potatop-is-a-lisp-powered-laptop-with-a-battery-life-measured-in-years-2f5d79653f24","classes":{"dataset":0.506395936}}
{"title":"Systems design explains the world (2020)","description":"https://apenwarr.ca/log/20201227","link":"https://apenwarr.ca/log/20201227","created":"2023-03-09","tags":["hackernews"],"meta":{"score":169},"text":"Systems design explains the world (2020) https://apenwarr.ca/log/20201227","classes":{"dataset":0.4824838936}}
{"title":"NYC man freed after 18 years, wrong photo led to murder conviction","description":"https://apnews.com/article/conviction-overturned-wrong-photo-brooklyn-1ec5d5b6b773afddd3532754a876d788","link":"https://apnews.com/article/conviction-overturned-wrong-photo-brooklyn-1ec5d5b6b773afddd3532754a876d788","created":"2023-03-10","tags":["hackernews"],"meta":{"score":41},"text":"NYC man freed after 18 years, wrong photo led to murder conviction https://apnews.com/article/conviction-overturned-wrong-photo-brooklyn-1ec5d5b6b773afddd3532754a876d788","classes":{"dataset":0.4884847403}}
{"title":"Show HN: PyBroker \u2013 Algotrading in Python with Machine Learning","description":"https://github.com/edtechre/pybroker","link":"https://github.com/edtechre/pybroker","created":"2023-03-09","tags":["hackernews"],"meta":{"score":42},"text":"Show HN: PyBroker \u2013 Algotrading in Python with Machine Learning https://github.com/edtechre/pybroker","classes":{"dataset":0.5066276789}}
{"title":"Stylized Water Shader","description":"https://alexanderameye.github.io/notes/stylized-water-shader/","link":"https://alexanderameye.github.io/notes/stylized-water-shader/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":198},"text":"Stylized Water Shader https://alexanderameye.github.io/notes/stylized-water-shader/","classes":{"dataset":0.506717205}}
{"title":"Who\u2019s Behind the NetWire Remote Access Trojan?","description":"https://krebsonsecurity.com/2023/03/whos-behind-the-netwire-remote-access-trojan/","link":"https://krebsonsecurity.com/2023/03/whos-behind-the-netwire-remote-access-trojan/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":35},"text":"Who\u2019s Behind the NetWire Remote Access Trojan? https://krebsonsecurity.com/2023/03/whos-behind-the-netwire-remote-access-trojan/","classes":{"dataset":0.5731655955}}
{"title":"Show HN: BBC \u201cIn Our Time\u201d, categorised by Dewey Decimal, heavy lifting by GPT","description":"https://genmon.github.io/braggoscope/","link":"https://genmon.github.io/braggoscope/","created":"2023-03-08","tags":["hackernews"],"meta":{"score":655},"text":"Show HN: BBC \u201cIn Our Time\u201d, categorised by Dewey Decimal, heavy lifting by GPT https://genmon.github.io/braggoscope/","classes":{"dataset":0.500867784}}
{"title":"Augmented Reality Welding System","description":"https://www.millerwelds.com/equipment/training-solutions/training-equipment/mobilearc-augmented-reality-welding-system-m90560","link":"https://www.millerwelds.com/equipment/training-solutions/training-equipment/mobilearc-augmented-reality-welding-system-m90560","created":"2023-03-09","tags":["hackernews"],"meta":{"score":106},"text":"Augmented Reality Welding System https://www.millerwelds.com/equipment/training-solutions/training-equipment/mobilearc-augmented-reality-welding-system-m90560","classes":{"dataset":0.507804811}}
{"title":"Flux Keyboard","description":"https://fluxkeyboard.com/","link":"https://fluxkeyboard.com/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":530},"text":"Flux Keyboard https://fluxkeyboard.com/","classes":{"dataset":0.5349074006}}
{"title":"Upwelling \u2013 Realtime collaboration with version control","description":"https://www.inkandswitch.com/upwelling/","link":"https://www.inkandswitch.com/upwelling/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":3},"text":"Upwelling \u2013 Realtime collaboration with version control https://www.inkandswitch.com/upwelling/","classes":{"dataset":0.5096451044}}
{"title":"Internet Story (2011) [video]","description":"https://www.youtube.com/watch?v=g-SL4ejpP94","link":"https://www.youtube.com/watch?v=g-SL4ejpP94","created":"2023-03-09","tags":["hackernews"],"meta":{"score":13},"text":"Internet Story (2011) [video] https://www.youtube.com/watch?v=g-SL4ejpP94","classes":{"dataset":0.4744773805}}
{"title":"Show HN: Safe Data Changes in PostgreSQL","description":"https://github.com/inqueryio/inquery","link":"https://github.com/inqueryio/inquery","created":"2023-03-09","tags":["hackernews"],"meta":{"score":39},"text":"Show HN: Safe Data Changes in PostgreSQL https://github.com/inqueryio/inquery","classes":{"dataset":0.4960694015}}
{"title":"Mars After Midnight: Gameplay Loop","description":"https://dukope.itch.io/mars-after-midnight/devlog/495856/gameplay-loop","link":"https://dukope.itch.io/mars-after-midnight/devlog/495856/gameplay-loop","created":"2023-03-07","tags":["hackernews"],"meta":{"score":205},"text":"Mars After Midnight: Gameplay Loop https://dukope.itch.io/mars-after-midnight/devlog/495856/gameplay-loop","classes":{"dataset":0.5455424786}}
{"title":"In Namibia, lions are king of the beach","description":"https://hakaimagazine.com/news/in-namibia-lions-are-king-of-the-beach/","link":"https://hakaimagazine.com/news/in-namibia-lions-are-king-of-the-beach/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":105},"text":"In Namibia, lions are king of the beach https://hakaimagazine.com/news/in-namibia-lions-are-king-of-the-beach/","classes":{"dataset":0.4940622449}}
{"title":"Chemicals released during wildfires in Australia damaged the ozone layer","description":"https://www.nature.com/articles/d41586-023-00687-w","link":"https://www.nature.com/articles/d41586-023-00687-w","created":"2023-03-09","tags":["hackernews"],"meta":{"score":246},"text":"Chemicals released during wildfires in Australia damaged the ozone layer https://www.nature.com/articles/d41586-023-00687-w","classes":{"dataset":0.5145770311}}
{"title":"The FBI Just Admitted It Bought US Location Data","description":"https://www.wired.com/story/fbi-purchase-location-data-wray-senate/","link":"https://www.wired.com/story/fbi-purchase-location-data-wray-senate/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":272},"text":"The FBI Just Admitted It Bought US Location Data https://www.wired.com/story/fbi-purchase-location-data-wray-senate/","classes":{"dataset":0.5432665944}}
{"title":"Stripe faces $3.5B tax bill as employees' shares expire","description":"https://www.bloomberg.com/news/articles/2023-03-06/stripe-details-3-5-billion-tax-bill-in-latest-fundraising-round","link":"https://www.bloomberg.com/news/articles/2023-03-06/stripe-details-3-5-billion-tax-bill-in-latest-fundraising-round","created":"2023-03-07","tags":["hackernews"],"meta":{"score":318},"text":"Stripe faces $3.5B tax bill as employees' shares expire https://www.bloomberg.com/news/articles/2023-03-06/stripe-details-3-5-billion-tax-bill-in-latest-fundraising-round","classes":{"dataset":0.4659482539}}
{"title":"The End of the Beginning (2020)","description":"https://stratechery.com/2020/the-end-of-the-beginning/","link":"https://stratechery.com/2020/the-end-of-the-beginning/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":73},"text":"The End of the Beginning (2020) https://stratechery.com/2020/the-end-of-the-beginning/","classes":{"dataset":0.4704090953}}
{"title":"FastKafka \u2013 A Free Open-Source Python Library for Building Kafka-Based Services","description":"https://github.com/airtai/fastkafka","link":"https://github.com/airtai/fastkafka","created":"2023-03-09","tags":["hackernews"],"meta":{"score":17},"text":"FastKafka \u2013 A Free Open-Source Python Library for Building Kafka-Based Services https://github.com/airtai/fastkafka","classes":{"dataset":0.500867784}}
{"title":"GarlicGPT \u2013 we hallucinate so you don't have to","description":"https://www.garlicgpt.com/","link":"https://www.garlicgpt.com/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":150},"text":"GarlicGPT \u2013 we hallucinate so you don't have to https://www.garlicgpt.com/","classes":{"dataset":0.4493428767}}
{"title":"Core Views on AI Safety: When, Why, What, and How","description":"https://www.anthropic.com/index/core-views-on-ai-safety","link":"https://www.anthropic.com/index/core-views-on-ai-safety","created":"2023-03-09","tags":["hackernews"],"meta":{"score":23},"text":"Core Views on AI Safety: When, Why, What, and How https://www.anthropic.com/index/core-views-on-ai-safety","classes":{"dataset":0.6083016396}}
{"title":"If you work at Dreamhost, can you help us?","description":"http://charles.plessy.org/Debian/debi%C3%A2neries/dreamhost/","link":"http://charles.plessy.org/Debian/debi%C3%A2neries/dreamhost/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":6},"text":"If you work at Dreamhost, can you help us? http://charles.plessy.org/Debian/debi%C3%A2neries/dreamhost/","classes":{"dataset":0.5217277408}}
{"title":"When Debug Symbols Get Large","description":"https://randomascii.wordpress.com/2023/03/08/when-debug-symbols-get-large/","link":"https://randomascii.wordpress.com/2023/03/08/when-debug-symbols-get-large/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":66},"text":"When Debug Symbols Get Large https://randomascii.wordpress.com/2023/03/08/when-debug-symbols-get-large/","classes":{"dataset":0.5316089988}}
{"title":"RJIT, a new JIT for Ruby","description":"https://github.com/ruby/ruby/pull/7448","link":"https://github.com/ruby/ruby/pull/7448","created":"2023-03-07","tags":["hackernews"],"meta":{"score":333},"text":"RJIT, a new JIT for Ruby https://github.com/ruby/ruby/pull/7448","classes":{"dataset":0.502504468}}
{"title":"Hardware microphone disconnect (2021)","description":"https://support.apple.com/guide/security/hardware-microphone-disconnect-secbbd20b00b/web","link":"https://support.apple.com/guide/security/hardware-microphone-disconnect-secbbd20b00b/web","created":"2023-03-07","tags":["hackernews"],"meta":{"score":716},"text":"Hardware microphone disconnect (2021) https://support.apple.com/guide/security/hardware-microphone-disconnect-secbbd20b00b/web","classes":{"dataset":0.5208235979}}
{"title":"Stripe Is on Track to Turn a Profit with $1T in Payment Volume","description":"https://www.bloomberg.com/news/articles/2023-02-16/stripe-is-on-track-to-turn-a-profit-with-1-trillion-in-payment-volume","link":"https://www.bloomberg.com/news/articles/2023-02-16/stripe-is-on-track-to-turn-a-profit-with-1-trillion-in-payment-volume","created":"2023-03-09","tags":["hackernews"],"meta":{"score":37},"text":"Stripe Is on Track to Turn a Profit with $1T in Payment Volume https://www.bloomberg.com/news/articles/2023-02-16/stripe-is-on-track-to-turn-a-profit-with-1-trillion-in-payment-volume","classes":{"dataset":0.4942406416}}
{"title":"JDK 20 and JDK 21: What we know so far","description":"https://www.infoq.com/news/2023/03/java-20-so-far/","link":"https://www.infoq.com/news/2023/03/java-20-so-far/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":138},"text":"JDK 20 and JDK 21: What we know so far https://www.infoq.com/news/2023/03/java-20-so-far/","classes":{"dataset":0.5521624088}}
{"title":"French union CGT cut power to Amazon facility to protest Macron's pension reform","description":"https://twitter.com/davidrkadler/status/1633857864245583879","link":"https://twitter.com/davidrkadler/status/1633857864245583879","created":"2023-03-09","tags":["hackernews"],"meta":{"score":25},"text":"French union CGT cut power to Amazon facility to protest Macron's pension reform https://twitter.com/davidrkadler/status/1633857864245583879","classes":{"dataset":0.5330165029}}
{"title":"How to Yubikey: A Configuration Cheatsheet","description":"https://debugging.works/blog/yubikey-cheatsheet/","link":"https://debugging.works/blog/yubikey-cheatsheet/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":193},"text":"How to Yubikey: A Configuration Cheatsheet https://debugging.works/blog/yubikey-cheatsheet/","classes":{"dataset":0.4900199175}}
{"title":"Understanding Computer Networks by Analogy","description":"https://memo.mx/understanding-networks-by-analogy/","link":"https://memo.mx/understanding-networks-by-analogy/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":17},"text":"Understanding Computer Networks by Analogy https://memo.mx/understanding-networks-by-analogy/","classes":{"dataset":0.5286363959}}
{"title":"Secretive: Store SSH Keys in the Secure Enclave","description":"https://github.com/maxgoedjen/secretive","link":"https://github.com/maxgoedjen/secretive","created":"2023-03-10","tags":["hackernews"],"meta":{"score":202},"text":"Secretive: Store SSH Keys in the Secure Enclave https://github.com/maxgoedjen/secretive","classes":{"dataset":0.4965943694}}
{"title":"Visual ChatGPT","description":"https://github.com/microsoft/visual-chatgpt","link":"https://github.com/microsoft/visual-chatgpt","created":"2023-03-10","tags":["hackernews"],"meta":{"score":457},"text":"Visual ChatGPT https://github.com/microsoft/visual-chatgpt","classes":{"dataset":0.5223886371}}
{"title":"Show HN: I built an autopilot for the lunar lander game","description":"https://szhu.github.io/lunar-lander-autopilot/","link":"https://szhu.github.io/lunar-lander-autopilot/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":161},"text":"Show HN: I built an autopilot for the lunar lander game https://szhu.github.io/lunar-lander-autopilot/","classes":{"dataset":0.505081594}}
{"title":"Meta is building a decentralized, text-based social network","description":"https://www.platformer.news/p/meta-is-building-a-decentralized","link":"https://www.platformer.news/p/meta-is-building-a-decentralized","created":"2023-03-10","tags":["hackernews"],"meta":{"score":84},"text":"Meta is building a decentralized, text-based social network https://www.platformer.news/p/meta-is-building-a-decentralized","classes":{"dataset":0.5362389088}}
{"title":"SPA view transitions land in Chrome 111","description":"https://developer.chrome.com/blog/spa-view-transitions-land/","link":"https://developer.chrome.com/blog/spa-view-transitions-land/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":127},"text":"SPA view transitions land in Chrome 111 https://developer.chrome.com/blog/spa-view-transitions-land/","classes":{"dataset":0.5393807292}}
{"title":"Steel threads are a technique that will make you a better engineer","description":"https://www.rubick.com/steel-threads/","link":"https://www.rubick.com/steel-threads/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":78},"text":"Steel threads are a technique that will make you a better engineer https://www.rubick.com/steel-threads/","classes":{"dataset":0.4983591735}}
{"title":"Allegations of Scientific Misconduct Mount as Physicist Makes His Biggest Claim","description":"https://physics.aps.org/articles/v16/40","link":"https://physics.aps.org/articles/v16/40","created":"2023-03-10","tags":["hackernews"],"meta":{"score":9},"text":"Allegations of Scientific Misconduct Mount as Physicist Makes His Biggest Claim https://physics.aps.org/articles/v16/40","classes":{"dataset":0.5391634107}}
{"title":"How to make sense of intelligence leaks","description":"https://www.economist.com/the-economist-explains/2023/03/09/how-to-make-sense-of-intelligence-leaks","link":"https://www.economist.com/the-economist-explains/2023/03/09/how-to-make-sense-of-intelligence-leaks","created":"2023-03-10","tags":["hackernews"],"meta":{"score":33},"text":"How to make sense of intelligence leaks https://www.economist.com/the-economist-explains/2023/03/09/how-to-make-sense-of-intelligence-leaks","classes":{"dataset":0.4921704829}}
{"title":"An EV that removes CO2 from the air","description":"https://www.voitureblog.com/worlds-cleanest-fully-electric-car-zem/","link":"https://www.voitureblog.com/worlds-cleanest-fully-electric-car-zem/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":26},"text":"An EV that removes CO2 from the air https://www.voitureblog.com/worlds-cleanest-fully-electric-car-zem/","classes":{"dataset":0.4863116741}}
{"title":"The Quest for Netflix on Asahi Linux","description":"https://www.da.vidbuchanan.co.uk/blog/netflix-on-asahi.html","link":"https://www.da.vidbuchanan.co.uk/blog/netflix-on-asahi.html","created":"2023-03-09","tags":["hackernews"],"meta":{"score":610},"text":"The Quest for Netflix on Asahi Linux https://www.da.vidbuchanan.co.uk/blog/netflix-on-asahi.html","classes":{"dataset":0.5070078373}}
{"title":"Zig: The Modern Alternative to C","description":"https://www.infoworld.com/article/3689648/meet-the-zig-programming-language.html","link":"https://www.infoworld.com/article/3689648/meet-the-zig-programming-language.html","created":"2023-03-10","tags":["hackernews"],"meta":{"score":124},"text":"Zig: The Modern Alternative to C https://www.infoworld.com/article/3689648/meet-the-zig-programming-language.html","classes":{"dataset":0.5217086077}}
{"title":"The AI hype bubble is the new crypto hype bubble","description":"https://pluralistic.net/2023/03/09/autocomplete-worshippers/#the-real-ai-was-the-corporations-that-we-fought-along-the-way","link":"https://pluralistic.net/2023/03/09/autocomplete-worshippers/#the-real-ai-was-the-corporations-that-we-fought-along-the-way","created":"2023-03-10","tags":["hackernews"],"meta":{"score":61},"text":"The AI hype bubble is the new crypto hype bubble https://pluralistic.net/2023/03/09/autocomplete-worshippers/#the-real-ai-was-the-corporations-that-we-fought-along-the-way","classes":{"dataset":0.5081273317}}
{"title":"JavaScript and TypeScript features of the last 3 years","description":"https://medium.com/@LinusSchlumberger/all-javascript-and-typescript-features-of-the-last-3-years-629c57e73e42","link":"https://medium.com/@LinusSchlumberger/all-javascript-and-typescript-features-of-the-last-3-years-629c57e73e42","created":"2023-03-09","tags":["hackernews"],"meta":{"score":429},"text":"JavaScript and TypeScript features of the last 3 years https://medium.com/@LinusSchlumberger/all-javascript-and-typescript-features-of-the-last-3-years-629c57e73e42","classes":{"dataset":0.4552006125}}
{"title":"GM offers buyouts to \u2018majority\u2019 of U.S. salaried workers","description":"https://www.cnbc.com/2023/03/09/gm-buyouts-us-salaried-workers.html","link":"https://www.cnbc.com/2023/03/09/gm-buyouts-us-salaried-workers.html","created":"2023-03-10","tags":["hackernews"],"meta":{"score":41},"text":"GM offers buyouts to \u2018majority\u2019 of U.S. salaried workers https://www.cnbc.com/2023/03/09/gm-buyouts-us-salaried-workers.html","classes":{"dataset":0.4981246889}}
{"title":"Common Mac OS X Cursors","description":"https://tobiasahlin.com/blog/common-mac-os-x-lion-cursors/","link":"https://tobiasahlin.com/blog/common-mac-os-x-lion-cursors/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":16},"text":"Common Mac OS X Cursors https://tobiasahlin.com/blog/common-mac-os-x-lion-cursors/","classes":{"dataset":0.5692802668}}
{"title":"How computer vision is changing manufacturing in 2023","description":"https://voxel51.com/blog/how-computer-vision-is-changing-manufacturing-in-2023/","link":"https://voxel51.com/blog/how-computer-vision-is-changing-manufacturing-in-2023/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":215},"text":"How computer vision is changing manufacturing in 2023 https://voxel51.com/blog/how-computer-vision-is-changing-manufacturing-in-2023/","classes":{"dataset":0.4741664827}}
{"title":"Battery-free Game Boy (2020)","description":"https://www.freethegameboy.info/","link":"https://www.freethegameboy.info/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":538},"text":"Battery-free Game Boy (2020) https://www.freethegameboy.info/","classes":{"dataset":0.5181413889}}
{"title":"Lisp-powered laptop with a battery life measured in years","description":"https://www.hackster.io/news/andreas-eriksen-s-potatop-is-a-lisp-powered-laptop-with-a-battery-life-measured-in-years-2f5d79653f24","link":"https://www.hackster.io/news/andreas-eriksen-s-potatop-is-a-lisp-powered-laptop-with-a-battery-life-measured-in-years-2f5d79653f24","created":"2023-03-08","tags":["hackernews"],"meta":{"score":781},"text":"Lisp-powered laptop with a battery life measured in years https://www.hackster.io/news/andreas-eriksen-s-potatop-is-a-lisp-powered-laptop-with-a-battery-life-measured-in-years-2f5d79653f24","classes":{"dataset":0.5046568513}}
{"title":"Show HN: APIRank.dev \u2013 We crawled and ranked public APIs from the internet","description":"https://apirank.dev/","link":"https://apirank.dev/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":161},"text":"Show HN: APIRank.dev \u2013 We crawled and ranked public APIs from the internet https://apirank.dev/","classes":{"dataset":0.5007334948}}
{"title":"Taichi lang: High-performance parallel programming in Python","description":"https://www.taichi-lang.org/","link":"https://www.taichi-lang.org/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":168},"text":"Taichi lang: High-performance parallel programming in Python https://www.taichi-lang.org/","classes":{"dataset":0.4824838936}}
{"title":"HP outrages printer users with firmware update suddenly bricking third-party ink","description":"https://arstechnica.com/gadgets/2023/03/customers-fume-as-hp-blocks-third-party-ink-from-more-of-its-printers/","link":"https://arstechnica.com/gadgets/2023/03/customers-fume-as-hp-blocks-third-party-ink-from-more-of-its-printers/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":103},"text":"HP outrages printer users with firmware update suddenly bricking third-party ink https://arstechnica.com/gadgets/2023/03/customers-fume-as-hp-blocks-third-party-ink-from-more-of-its-printers/","classes":{"dataset":0.505672574}}
{"title":"Show HN: PyBroker \u2013 Algotrading in Python with Machine Learning","description":"https://github.com/edtechre/pybroker","link":"https://github.com/edtechre/pybroker","created":"2023-03-09","tags":["hackernews"],"meta":{"score":49},"text":"Show HN: PyBroker \u2013 Algotrading in Python with Machine Learning https://github.com/edtechre/pybroker","classes":{"dataset":0.4438689351}}
{"title":"GigaGAN: Large-Scale GAN for Text-to-Image Synthesis","description":"https://mingukkang.github.io/GigaGAN/","link":"https://mingukkang.github.io/GigaGAN/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":16},"text":"GigaGAN: Large-Scale GAN for Text-to-Image Synthesis https://mingukkang.github.io/GigaGAN/","classes":{"dataset":0.4873019159}}
{"title":"Show HN: BBC \u201cIn Our Time\u201d, categorised by Dewey Decimal, heavy lifting by GPT","description":"https://genmon.github.io/braggoscope/","link":"https://genmon.github.io/braggoscope/","created":"2023-03-08","tags":["hackernews"],"meta":{"score":658},"text":"Show HN: BBC \u201cIn Our Time\u201d, categorised by Dewey Decimal, heavy lifting by GPT https://genmon.github.io/braggoscope/","classes":{"dataset":0.4884847403}}
{"title":"Stylized Water Shader","description":"https://alexanderameye.github.io/notes/stylized-water-shader/","link":"https://alexanderameye.github.io/notes/stylized-water-shader/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":202},"text":"Stylized Water Shader https://alexanderameye.github.io/notes/stylized-water-shader/","classes":{"dataset":0.4969418049}}
{"title":"Show HN: Safe Data Changes in PostgreSQL","description":"https://github.com/inqueryio/inquery","link":"https://github.com/inqueryio/inquery","created":"2023-03-09","tags":["hackernews"],"meta":{"score":43},"text":"Show HN: Safe Data Changes in PostgreSQL https://github.com/inqueryio/inquery","classes":{"dataset":0.5066276789}}
{"title":"$22B project to provide 8% of UK energy via undersea cable from North Africa","description":"https://e360.yale.edu/features/africa-europe-solar-wind-power","link":"https://e360.yale.edu/features/africa-europe-solar-wind-power","created":"2023-03-09","tags":["hackernews"],"meta":{"score":164},"text":"$22B project to provide 8% of UK energy via undersea cable from North Africa https://e360.yale.edu/features/africa-europe-solar-wind-power","classes":{"dataset":0.5096451044}}
{"title":"Mars After Midnight: Gameplay Loop","description":"https://dukope.itch.io/mars-after-midnight/devlog/495856/gameplay-loop","link":"https://dukope.itch.io/mars-after-midnight/devlog/495856/gameplay-loop","created":"2023-03-07","tags":["hackernews"],"meta":{"score":208},"text":"Mars After Midnight: Gameplay Loop https://dukope.itch.io/mars-after-midnight/devlog/495856/gameplay-loop","classes":{"dataset":0.507349968}}
{"title":"What does \"Copy clean link\" mean?","description":"https://support.brave.com/hc/en-us/articles/9982188779405-What-does-Copy-clean-link-mean-","link":"https://support.brave.com/hc/en-us/articles/9982188779405-What-does-Copy-clean-link-mean-","created":"2023-03-09","tags":["hackernews"],"meta":{"score":354},"text":"What does \"Copy clean link\" mean? https://support.brave.com/hc/en-us/articles/9982188779405-What-does-Copy-clean-link-mean-","classes":{"dataset":0.4940622449}}
{"title":"In Namibia, lions are king of the beach","description":"https://hakaimagazine.com/news/in-namibia-lions-are-king-of-the-beach/","link":"https://hakaimagazine.com/news/in-namibia-lions-are-king-of-the-beach/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":106},"text":"In Namibia, lions are king of the beach https://hakaimagazine.com/news/in-namibia-lions-are-king-of-the-beach/","classes":{"dataset":0.513361752}}
{"title":"Augmented Reality Welding System","description":"https://www.millerwelds.com/equipment/training-solutions/training-equipment/mobilearc-augmented-reality-welding-system-m90560","link":"https://www.millerwelds.com/equipment/training-solutions/training-equipment/mobilearc-augmented-reality-welding-system-m90560","created":"2023-03-09","tags":["hackernews"],"meta":{"score":107},"text":"Augmented Reality Welding System https://www.millerwelds.com/equipment/training-solutions/training-equipment/mobilearc-augmented-reality-welding-system-m90560","classes":{"dataset":0.5349074006}}
{"title":"Canada's tax revenue agency tries to ToS itself out of hacking liability","description":"https://riskybiznews.substack.com/p/risky-biz-news-canadas-tax-revenue","link":"https://riskybiznews.substack.com/p/risky-biz-news-canadas-tax-revenue","created":"2023-03-08","tags":["hackernews"],"meta":{"score":355},"text":"Canada's tax revenue agency tries to ToS itself out of hacking liability https://riskybiznews.substack.com/p/risky-biz-news-canadas-tax-revenue","classes":{"dataset":0.4913152158}}
{"title":"Chemicals released during wildfires in Australia damaged the ozone layer","description":"https://www.nature.com/articles/d41586-023-00687-w","link":"https://www.nature.com/articles/d41586-023-00687-w","created":"2023-03-09","tags":["hackernews"],"meta":{"score":248},"text":"Chemicals released during wildfires in Australia damaged the ozone layer https://www.nature.com/articles/d41586-023-00687-w","classes":{"dataset":0.5530340075}}
{"title":"Yyvette's Bridal","description":"https://yvettesbridalformal.p1r8.net/","link":"https://yvettesbridalformal.p1r8.net/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":103},"text":"Yyvette's Bridal https://yvettesbridalformal.p1r8.net/","classes":{"dataset":0.4794835448}}
{"title":"Writer's Award Winner Philip Clark on the Sounds of New York City: Part II","description":"https://blogs.bl.uk/americas/2023/02/the-sound-of-new-york-citys-deep-past.html","link":"https://blogs.bl.uk/americas/2023/02/the-sound-of-new-york-citys-deep-past.html","created":"2023-03-09","tags":["hackernews"],"meta":{"score":10},"text":"Writer's Award Winner Philip Clark on the Sounds of New York City: Part II https://blogs.bl.uk/americas/2023/02/the-sound-of-new-york-citys-deep-past.html","classes":{"dataset":0.47018525}}
{"title":"Waiting for Brando: A disastrous 1961 film production of the Iliad","description":"https://www.laphamsquarterly.org/roundtable/waiting-brando","link":"https://www.laphamsquarterly.org/roundtable/waiting-brando","created":"2023-03-08","tags":["hackernews"],"meta":{"score":48},"text":"Waiting for Brando: A disastrous 1961 film production of the Iliad https://www.laphamsquarterly.org/roundtable/waiting-brando","classes":{"dataset":0.4960694015}}
{"title":"Mathematician James Glimm may have solved the Poincare Conjecture","description":"https://www.palladiummag.com/2023/03/02/what-genius-looks-like/","link":"https://www.palladiummag.com/2023/03/02/what-genius-looks-like/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":25},"text":"Mathematician James Glimm may have solved the Poincare Conjecture https://www.palladiummag.com/2023/03/02/what-genius-looks-like/","classes":{"dataset":0.4493428767}}
{"title":"Lessons learned from 15 years of SumatraPDF, an open source Windows app (2021)","description":"https://blog.kowalczyk.info/article/2f72237a4230410a888acbfce3dc0864/lessons-learned-from-15-years-of-sumatrapdf-an-open-source-windows-app.html","link":"https://blog.kowalczyk.info/article/2f72237a4230410a888acbfce3dc0864/lessons-learned-from-15-years-of-sumatrapdf-an-open-source-windows-app.html","created":"2023-03-08","tags":["hackernews"],"meta":{"score":572},"text":"Lessons learned from 15 years of SumatraPDF, an open source Windows app (2021) https://blog.kowalczyk.info/article/2f72237a4230410a888acbfce3dc0864/lessons-learned-from-15-years-of-sumatrapdf-an-open-source-windows-app.html","classes":{"dataset":0.5521624088}}
{"title":"Promoting Palaeontology Across Sudan","description":"https://www.nature.com/articles/d41586-023-00692-z","link":"https://www.nature.com/articles/d41586-023-00692-z","created":"2023-03-09","tags":["hackernews"],"meta":{"score":8},"text":"Promoting Palaeontology Across Sudan https://www.nature.com/articles/d41586-023-00692-z","classes":{"dataset":0.4382207692}}
{"title":"Upwelling \u2013 Realtime collaboration with version control","description":"https://www.inkandswitch.com/upwelling/","link":"https://www.inkandswitch.com/upwelling/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":5},"text":"Upwelling \u2013 Realtime collaboration with version control https://www.inkandswitch.com/upwelling/","classes":{"dataset":0.4893939793}}
{"title":"The False Promise of Chomskyism","description":"https://scottaaronson.blog/?p=7094","link":"https://scottaaronson.blog/?p=7094","created":"2023-03-09","tags":["hackernews"],"meta":{"score":126},"text":"The False Promise of Chomskyism https://scottaaronson.blog/?p=7094","classes":{"dataset":0.4789520204}}
{"title":"WhatsApp would not remove end-to-end encryption for UK law, says chief","description":"https://www.theguardian.com/technology/2023/mar/09/whatsapp-end-to-end-encryption-online-safety-bill","link":"https://www.theguardian.com/technology/2023/mar/09/whatsapp-end-to-end-encryption-online-safety-bill","created":"2023-03-09","tags":["hackernews"],"meta":{"score":200},"text":"WhatsApp would not remove end-to-end encryption for UK law, says chief https://www.theguardian.com/technology/2023/mar/09/whatsapp-end-to-end-encryption-online-safety-bill","classes":{"dataset":0.5148474574}}
{"title":"MentalVs is now up and running in the Future Tools discord!","description":"Hi, Everyone!\n\nUse the latest AI technology to generate anything you wish as you duel with your opponent, attacking and reacting, for ten rounds of turn-based, one-of-a-kind combat!\n\nUse might and magic\ud83d\udc4a\ud83c\udffd\u2728, science and fantasy \u269b\ufe0f\u2694\ufe0f, the elements\ud83d\udd25\u2744\ufe0f, light and dark \u2600\ufe0f\ud83c\udf11, space and time \ud83c\udf20\u231b, interdimensional beings\ud83d\udc7d\ud83e\udd16, humor, anime, and any other resource you can envision. Ultimate power courses from your fingertips, and anything is possible in MentalVs!\n\nPromo Video: [https://tinyurl.com/MentalVs-Promo](https://tinyurl.com/MentalVs-Promo) (links to bot and app in description)\n\norrr If you're not interested in playing, you can still check out all the action and vote for your favorite contenders (while getting new prompt ideas ;) ): [https://tinyurl.com/Mentalvs](https://tinyurl.com/Mentalvs)\n\n**Looking for more players?? MentalVs is now running in the Future Tools discord channel!** [**https://discord.gg/wbCqyK6A**](https://discord.gg/wbCqyK6A)","link":"https://www.reddit.com/r/PromptDesign/comments/11n5x2r/mentalvs_is_now_up_and_running_in_the_future/","created":"2023-03-09","tags":["reddit","promptdesign","prompteng"],"meta":{"num_comments":0},"text":"MentalVs is now up and running in the Future Tools discord! Hi, Everyone!\n\nUse the latest AI technology to generate anything you wish as you duel with your opponent, attacking and reacting, for ten rounds of turn-based, one-of-a-kind combat!\n\nUse might and magic\ud83d\udc4a\ud83c\udffd\u2728, science and fantasy \u269b\ufe0f\u2694\ufe0f, the elements\ud83d\udd25\u2744\ufe0f, light and dark \u2600\ufe0f\ud83c\udf11, space and time \ud83c\udf20\u231b, interdimensional beings\ud83d\udc7d\ud83e\udd16, humor, anime, and any other resource you can envision. Ultimate power courses from your fingertips, and anything is possible in MentalVs!\n\nPromo Video: [https://tinyurl.com/MentalVs-Promo](https://tinyurl.com/MentalVs-Promo) (links to bot and app in description)\n\norrr If you're not interested in playing, you can still check out all the action and vote for your favorite contenders (while getting new prompt ideas ;) ): [https://tinyurl.com/Mentalvs](https://tinyurl.com/Mentalvs)\n\n**Looking for more players?? MentalVs is now running in the Future Tools discord channel!** [**https://discord.gg/wbCqyK6A**](https://discord.gg/wbCqyK6A)","classes":{"dataset":0.502504468}}
{"title":"I make prompt packs, and I put together some ChatGPT prompts to help anyone learning Rust [Free Resource]","description":"## Using these prompts\n\n\n\ud83d\udc68\u200d\ud83c\udfeb This resource is designed to quickly show you the power of chatGPT and serve as a starting point for exploration.\n\n\nCopy and paste these into [https://chat.openai.com/](https://chat.openai.com/)  to see what you get. I\u2019ve also added some responses here. Further explore editing the prompts, trying to direct the AI, and taking the step-by-step responses as new prompts to feed the bot. Enjoy!\n\n[Download All the prompts free on Gumroad](https://godsol.gumroad.com/l/rust-prompts)\n*due to length constraints, this article contains less than half*\n\n\n## Learning Rust (New Concepts)\n\n## Ownership and Borrowing:\n\nWhat are the benefits of Rust's ownership and borrowing system?\n\nHow does Rust prevent common memory-related bugs like null pointers and dangling pointers?\n\nCan you explain the difference between mutable and immutable borrowing in Rust?\n\n## Traits:\n\nHow do traits help with generic programming in Rust?\n\nCan you provide an example of a custom trait in Rust?\n\nWhat is the difference between a trait object and a generic type parameter in Rust?\n\n## Lifetimes:\n\nWhat is a lifetime in Rust and how is it different from a scope?\n\nHow does Rust's borrow checker use lifetimes to prevent dangling pointers?\n\nCan you explain the difference between 'static and 'a lifetimes in Rust?\n\n## Pattern Matching:\n\nWhat is pattern matching and how is it used in Rust?\n\nHow can pattern matching be used with enums and structs in Rust?\n\n## Concurrency:\n\nWhat are some of the built-in concurrency primitives in Rust?\n\nHow does Rust's ownership and borrowing system make writing concurrent code safer?\n\nCan you provide an example of a multi-threaded Rust program?\n\n## Macros:\n\nWhat are macros and how are they used in Rust?\n\nCan you provide an example of a macro in Rust?\n\nHow can macros be used to generate code at compile time in Rust?\n\n## Error Handling:\n\nWhat are some of the built-in error handling mechanisms in Rust?\n\nHow does Rust's error handling system differ from other programming languages?\n\nCan you provide an example of how to use the Result and Option types in Rust?\n\n## Systems Programming\n\n```jsx\nBuild a system daemon that monitors system resource usage and logs events to a file using the Rust Standard Library. Use the log crate for logging and the signal-hook crate to handle system signals.\n```\n\nDevelop a network application that implements a custom protocol using Rust's TCP and UDP socket libraries. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\nCreate a file management tool that allows users to copy, move, and delete files and directories using Rust's standard filesystem library. Use the clap crate for command-line argument parsing and the indicatif crate for progress bars.\n\nBuild a simple web server that handles HTTP requests and serves static files using the Iron web framework and Rust's standard HTTP libraries. Use the chrono crate for handling dates and times and the openssl crate for secure communication.\n\nDevelop a low-level library for interfacing with a hardware device using Rust's Foreign Function Interface (FFI) and the libc crate. Use the crossbeam crate for safe concurrent programming and the rust-crypto crate for encryption and hashing.\n\nCreate a CLI tool that allows users to manipulate audio files using the Rust's audio crate. Use the clap crate for command-line argument parsing and the hound crate for audio file I/O.\n\nBuild a network daemon that listens for incoming connections and manages a pool of worker threads using Rust's standard thread libraries and the crossbeam-channel crate for inter-thread communication. Use the rustls crate for secure communication.\n\nDevelop a command-line tool for converting between different image formats using Rust's image processing library and the clap crate for command-line argument parsing. Use the rayon crate for parallel processing.\n\nCreate a system service that monitors a directory for changes and logs events to a file using the notify crate. Use the chrono crate for handling dates and times and the slog crate for logging.\n\nBuild a command-line tool that encrypts and decrypts files using Rust's cryptography libraries and the clap crate for command-line argument parsing. Use the rand crate for generating random numbers.\n\nDevelop a low-level library for interfacing with a Bluetooth device using Rust's FFI and the BlueZ Bluetooth stack. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\nCreate a CLI tool that allows users to manipulate PDF files using the Rust's PDF processing libraries and the clap crate for command-line argument parsing. Use the rayon crate for parallel processing.\n\nBuild a system daemon that monitors and logs changes to system configuration files using Rust's standard filesystem libraries and the notify crate. Use the serde crate for serialization and deserialization.\n\nDevelop a command-line tool that generates random passwords using Rust's cryptography libraries and the clap crate for command-line argument parsing. Use the rand crate for generating random numbers.\n\nCreate a low-level library for interfacing with a USB device using Rust's FFI and the libusb library. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\nBuild a command-line tool that allows users to manage system processes using Rust's standard process libraries and the clap crate for command-line argument parsing. Use the regex crate for string manipulation.\n\nDevelop a system daemon that manages a pool of worker threads and communicates with them using Rust's standard thread libraries and the crossbeam-channel crate. Use the chrono crate for handling dates and times and the slog crate for logging.\n\nCreate a low-level library for interfacing with a Serial device using Rust's FFI and the serialport library. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\n## DevOps\n\n```jsx\nBuild a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Rust's DevOps library, Rust CI/CD, and the Jenkins automation server. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n```\n\nDevelop a tool for infrastructure automation using Rust's DevOps library, Rust Chef, and the Chef configuration management tool. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container orchestration using Rust's DevOps library, Rust Kubernetes, and the Kubernetes container orchestration system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a serverless infrastructure using Rust's DevOps library, Rust Serverless, and the AWS Lambda service. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for continuous monitoring using Rust's DevOps library, Rust Prometheus, and the Prometheus monitoring system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for log management using Rust's DevOps library, Rust Logstash, and the Logstash logging pipeline. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Rust's DevOps library, Rust Travis, and the Travis CI/CD platform. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for infrastructure testing using Rust's DevOps library, Rust Terraform, and the Terraform infrastructure as code tool. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container security using Rust's DevOps library, Rust Clair, and the Clair container security scanner. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a serverless application using Rust's DevOps library, Rust AWS Lambda, and the AWS Lambda service. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for infrastructure visualization using Rust's DevOps library, Rust Graphviz, and the Graphviz graph visualization software. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container monitoring using Rust's DevOps library, Rust Prometheus, and the Prometheus monitoring system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Rust's DevOps library, Rust CircleCI, and the CircleCI CI/CD platform. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for infrastructure as code using Rust's DevOps library, Rust Ansible, and the Ansible configuration management tool. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container orchestration using Rust's DevOps library, Rust Nomad, and the Nomad container orchestration system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a serverless application using Rust's DevOps library, Rust Google Cloud Functions, and the Google Cloud Functions service. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\n[Download All the prompts free on Gumroad](https://godsol.gumroad.com/l/rust-prompts)\n*due to length constraints, this article contains less than half*","link":"https://www.reddit.com/r/PromptDesign/comments/11mwsfm/i_make_prompt_packs_and_i_put_together_some/","created":"2023-03-09","tags":["reddit","promptdesign","prompteng"],"meta":{"num_comments":1},"text":"I make prompt packs, and I put together some ChatGPT prompts to help anyone learning Rust [Free Resource] ## Using these prompts\n\n\n\ud83d\udc68\u200d\ud83c\udfeb This resource is designed to quickly show you the power of chatGPT and serve as a starting point for exploration.\n\n\nCopy and paste these into [https://chat.openai.com/](https://chat.openai.com/)  to see what you get. I\u2019ve also added some responses here. Further explore editing the prompts, trying to direct the AI, and taking the step-by-step responses as new prompts to feed the bot. Enjoy!\n\n[Download All the prompts free on Gumroad](https://godsol.gumroad.com/l/rust-prompts)\n*due to length constraints, this article contains less than half*\n\n\n## Learning Rust (New Concepts)\n\n## Ownership and Borrowing:\n\nWhat are the benefits of Rust's ownership and borrowing system?\n\nHow does Rust prevent common memory-related bugs like null pointers and dangling pointers?\n\nCan you explain the difference between mutable and immutable borrowing in Rust?\n\n## Traits:\n\nHow do traits help with generic programming in Rust?\n\nCan you provide an example of a custom trait in Rust?\n\nWhat is the difference between a trait object and a generic type parameter in Rust?\n\n## Lifetimes:\n\nWhat is a lifetime in Rust and how is it different from a scope?\n\nHow does Rust's borrow checker use lifetimes to prevent dangling pointers?\n\nCan you explain the difference between 'static and 'a lifetimes in Rust?\n\n## Pattern Matching:\n\nWhat is pattern matching and how is it used in Rust?\n\nHow can pattern matching be used with enums and structs in Rust?\n\n## Concurrency:\n\nWhat are some of the built-in concurrency primitives in Rust?\n\nHow does Rust's ownership and borrowing system make writing concurrent code safer?\n\nCan you provide an example of a multi-threaded Rust program?\n\n## Macros:\n\nWhat are macros and how are they used in Rust?\n\nCan you provide an example of a macro in Rust?\n\nHow can macros be used to generate code at compile time in Rust?\n\n## Error Handling:\n\nWhat are some of the built-in error handling mechanisms in Rust?\n\nHow does Rust's error handling system differ from other programming languages?\n\nCan you provide an example of how to use the Result and Option types in Rust?\n\n## Systems Programming\n\n```jsx\nBuild a system daemon that monitors system resource usage and logs events to a file using the Rust Standard Library. Use the log crate for logging and the signal-hook crate to handle system signals.\n```\n\nDevelop a network application that implements a custom protocol using Rust's TCP and UDP socket libraries. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\nCreate a file management tool that allows users to copy, move, and delete files and directories using Rust's standard filesystem library. Use the clap crate for command-line argument parsing and the indicatif crate for progress bars.\n\nBuild a simple web server that handles HTTP requests and serves static files using the Iron web framework and Rust's standard HTTP libraries. Use the chrono crate for handling dates and times and the openssl crate for secure communication.\n\nDevelop a low-level library for interfacing with a hardware device using Rust's Foreign Function Interface (FFI) and the libc crate. Use the crossbeam crate for safe concurrent programming and the rust-crypto crate for encryption and hashing.\n\nCreate a CLI tool that allows users to manipulate audio files using the Rust's audio crate. Use the clap crate for command-line argument parsing and the hound crate for audio file I/O.\n\nBuild a network daemon that listens for incoming connections and manages a pool of worker threads using Rust's standard thread libraries and the crossbeam-channel crate for inter-thread communication. Use the rustls crate for secure communication.\n\nDevelop a command-line tool for converting between different image formats using Rust's image processing library and the clap crate for command-line argument parsing. Use the rayon crate for parallel processing.\n\nCreate a system service that monitors a directory for changes and logs events to a file using the notify crate. Use the chrono crate for handling dates and times and the slog crate for logging.\n\nBuild a command-line tool that encrypts and decrypts files using Rust's cryptography libraries and the clap crate for command-line argument parsing. Use the rand crate for generating random numbers.\n\nDevelop a low-level library for interfacing with a Bluetooth device using Rust's FFI and the BlueZ Bluetooth stack. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\nCreate a CLI tool that allows users to manipulate PDF files using the Rust's PDF processing libraries and the clap crate for command-line argument parsing. Use the rayon crate for parallel processing.\n\nBuild a system daemon that monitors and logs changes to system configuration files using Rust's standard filesystem libraries and the notify crate. Use the serde crate for serialization and deserialization.\n\nDevelop a command-line tool that generates random passwords using Rust's cryptography libraries and the clap crate for command-line argument parsing. Use the rand crate for generating random numbers.\n\nCreate a low-level library for interfacing with a USB device using Rust's FFI and the libusb library. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\nBuild a command-line tool that allows users to manage system processes using Rust's standard process libraries and the clap crate for command-line argument parsing. Use the regex crate for string manipulation.\n\nDevelop a system daemon that manages a pool of worker threads and communicates with them using Rust's standard thread libraries and the crossbeam-channel crate. Use the chrono crate for handling dates and times and the slog crate for logging.\n\nCreate a low-level library for interfacing with a Serial device using Rust's FFI and the serialport library. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\n## DevOps\n\n```jsx\nBuild a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Rust's DevOps library, Rust CI/CD, and the Jenkins automation server. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n```\n\nDevelop a tool for infrastructure automation using Rust's DevOps library, Rust Chef, and the Chef configuration management tool. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container orchestration using Rust's DevOps library, Rust Kubernetes, and the Kubernetes container orchestration system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a serverless infrastructure using Rust's DevOps library, Rust Serverless, and the AWS Lambda service. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for continuous monitoring using Rust's DevOps library, Rust Prometheus, and the Prometheus monitoring system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for log management using Rust's DevOps library, Rust Logstash, and the Logstash logging pipeline. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Rust's DevOps library, Rust Travis, and the Travis CI/CD platform. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for infrastructure testing using Rust's DevOps library, Rust Terraform, and the Terraform infrastructure as code tool. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container security using Rust's DevOps library, Rust Clair, and the Clair container security scanner. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a serverless application using Rust's DevOps library, Rust AWS Lambda, and the AWS Lambda service. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for infrastructure visualization using Rust's DevOps library, Rust Graphviz, and the Graphviz graph visualization software. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container monitoring using Rust's DevOps library, Rust Prometheus, and the Prometheus monitoring system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Rust's DevOps library, Rust CircleCI, and the CircleCI CI/CD platform. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for infrastructure as code using Rust's DevOps library, Rust Ansible, and the Ansible configuration management tool. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container orchestration using Rust's DevOps library, Rust Nomad, and the Nomad container orchestration system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a serverless application using Rust's DevOps library, Rust Google Cloud Functions, and the Google Cloud Functions service. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\n[Download All the prompts free on Gumroad](https://godsol.gumroad.com/l/rust-prompts)\n*due to length constraints, this article contains less than half*","classes":{"dataset":0.3952933848}}
{"title":"Sharing a tool I am creating to fine-tune a model using reddit data.","description":"So as my billionth side project, I decided to create a web-app that scrapes data from reddit and generates a text file that can be used to fine-tune an openAI model such as davinci-003.  I would love to find people to critique this project and contribute to it.\n\n[here](https://platform.openai.com/docs/guides/fine-tuning) is a link for instructions on how to fine tune a model.  When it comes to the step called **prepare training data** I wanted to sort of automate this by allowing the user to get a bunch of prompts/completions from reddit.  I created an app that generates a jsonl file for fine-tuning using the submission title as the prompt and the submission body and/or comments as the completion.  Let me know if this is something people are interested in collaborating on or if there are other people doing similar things.\n\nLink to my app: [https://fine-tune-reddit.herokuapp.com/](https://fine-tune-reddit.herokuapp.com/)\n\nLink to the CLI project on github: [https://github.com/brianSalk/openai-finetune-reddit](https://github.com/brianSalk/openai-finetune-reddit)\n\nLink to the web-app on github: [https://github.com/brianSalk/reddit-finetune-frontend](https://github.com/brianSalk/reddit-finetune-frontend)","link":"https://www.reddit.com/r/PromptDesign/comments/11lzs34/sharing_a_tool_i_am_creating_to_finetune_a_model/","created":"2023-03-08","tags":["reddit","promptdesign","prompteng"],"meta":{"num_comments":10},"text":"Sharing a tool I am creating to fine-tune a model using reddit data. So as my billionth side project, I decided to create a web-app that scrapes data from reddit and generates a text file that can be used to fine-tune an openAI model such as davinci-003.  I would love to find people to critique this project and contribute to it.\n\n[here](https://platform.openai.com/docs/guides/fine-tuning) is a link for instructions on how to fine tune a model.  When it comes to the step called **prepare training data** I wanted to sort of automate this by allowing the user to get a bunch of prompts/completions from reddit.  I created an app that generates a jsonl file for fine-tuning using the submission title as the prompt and the submission body and/or comments as the completion.  Let me know if this is something people are interested in collaborating on or if there are other people doing similar things.\n\nLink to my app: [https://fine-tune-reddit.herokuapp.com/](https://fine-tune-reddit.herokuapp.com/)\n\nLink to the CLI project on github: [https://github.com/brianSalk/openai-finetune-reddit](https://github.com/brianSalk/openai-finetune-reddit)\n\nLink to the web-app on github: [https://github.com/brianSalk/reddit-finetune-frontend](https://github.com/brianSalk/reddit-finetune-frontend)","classes":{"dataset":0.413720876}}
{"title":"Thursday Daily Thread: Python Careers, Courses, and Furthering Education!","description":"Discussion of using Python in a professional environment, getting jobs in Python as well as ask questions about courses to further your python education!\n\n**This thread is not for recruitment, please see** r/PythonJobs **or the thread in the sidebar for that.**","link":"https://www.reddit.com/r/Python/comments/11mcnzg/thursday_daily_thread_python_careers_courses_and/","created":"2023-03-09","tags":["reddit","python"],"meta":{"num_comments":2},"text":"Thursday Daily Thread: Python Careers, Courses, and Furthering Education! Discussion of using Python in a professional environment, getting jobs in Python as well as ask questions about courses to further your python education!\n\n**This thread is not for recruitment, please see** r/PythonJobs **or the thread in the sidebar for that.**","classes":{"dataset":0.2468641549}}
{"title":"Python remote debugging on windows machines is now made easy!","description":"Hi guys, I couldn't find latterly a single solution for pycharm to remote debug my python code on other windows machines, and I wanted to do that to do my AI training stuff on my friend's pc because mine is no strong enough, I ended up making my own python library that exactly does that!  \n\n\nWith only two lines of code, you can debug an python script on a windows machine easily, and a copy of all the stdout, stderr and stdin calls will be forwarded to you and you will feel like you are working on your own machine.  \n\n\nI wanted to share it here if anyone needs such capability, I also uploaded it to PyPl so pip will be able to install it, here's the project's github page: [https://github.com/AhmedAhmedEG/PyWinRD](https://github.com/AhmedAhmedEG/PyWinRD)","link":"https://www.reddit.com/r/Python/comments/11nod6t/python_remote_debugging_on_windows_machines_is/","created":"2023-03-10","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Python remote debugging on windows machines is now made easy! Hi guys, I couldn't find latterly a single solution for pycharm to remote debug my python code on other windows machines, and I wanted to do that to do my AI training stuff on my friend's pc because mine is no strong enough, I ended up making my own python library that exactly does that!  \n\n\nWith only two lines of code, you can debug an python script on a windows machine easily, and a copy of all the stdout, stderr and stdin calls will be forwarded to you and you will feel like you are working on your own machine.  \n\n\nI wanted to share it here if anyone needs such capability, I also uploaded it to PyPl so pip will be able to install it, here's the project's github page: [https://github.com/AhmedAhmedEG/PyWinRD](https://github.com/AhmedAhmedEG/PyWinRD)","classes":{"dataset":0.5057662129}}
{"title":"heyoka.py 0.21 - ODE integration wth LLVM, now supporting multiprecision","description":"Hello there!\n\nI posted here before about [heyoka.py](https://github.com/bluescarni/heyoka.py), our high-performance ODE integrator based on LLVM.\n\nWe recently released a new version supporting arbitrary-precision computations. This support is built on top of a multiprecision class exposed from C++ to Python, with full NumPy support. That is, this new datatype can be used as a native ``dtype`` in NumPy arrays. I believe this might be a first in the scientific Python ecosystem.\n\nHere is a tutorial introducing the new feature:\n\nhttps://bluescarni.github.io/heyoka.py/notebooks/arbitrary_precision.html\n\nThanks to the properties of the specific numerical integration method employed by heyoka.py (Taylor's method), multiprecision numerical integrations can be orders of magnitude faster than DifferentialEquations.jl, as shown in the benchmarks section here:\n\nhttps://bluescarni.github.io/heyoka/benchmarks.html#extended-and-arbitrary-precision\n\nThe latest version of heyoka.py also introduces a prebuilt ``pip`` wheel for Linux x86-64 (whereas previous versions had only ``conda`` packages):\n\n```\n$ pip install heyoka\n```\n\nPlease let me know if you have comments, questions, criticism, etc.!","link":"https://www.reddit.com/r/Python/comments/11nj2g0/heyokapy_021_ode_integration_wth_llvm_now/","created":"2023-03-10","tags":["reddit","python"],"meta":{"num_comments":0},"text":"heyoka.py 0.21 - ODE integration wth LLVM, now supporting multiprecision Hello there!\n\nI posted here before about [heyoka.py](https://github.com/bluescarni/heyoka.py), our high-performance ODE integrator based on LLVM.\n\nWe recently released a new version supporting arbitrary-precision computations. This support is built on top of a multiprecision class exposed from C++ to Python, with full NumPy support. That is, this new datatype can be used as a native ``dtype`` in NumPy arrays. I believe this might be a first in the scientific Python ecosystem.\n\nHere is a tutorial introducing the new feature:\n\nhttps://bluescarni.github.io/heyoka.py/notebooks/arbitrary_precision.html\n\nThanks to the properties of the specific numerical integration method employed by heyoka.py (Taylor's method), multiprecision numerical integrations can be orders of magnitude faster than DifferentialEquations.jl, as shown in the benchmarks section here:\n\nhttps://bluescarni.github.io/heyoka/benchmarks.html#extended-and-arbitrary-precision\n\nThe latest version of heyoka.py also introduces a prebuilt ``pip`` wheel for Linux x86-64 (whereas previous versions had only ``conda`` packages):\n\n```\n$ pip install heyoka\n```\n\nPlease let me know if you have comments, questions, criticism, etc.!","classes":{"dataset":0.4683719873}}
{"title":"How to use python to upload data into SQL Server Database","description":"I\u2019ve been able to pull data out of the database. But I\u2019m having issues with appending the table. \n\nI keep getting an error\n\nThe first code I tried was like this \n\nFor row in df.itertuples():\n\n       Cursor.execute ( \u2018\u2019\u2019\n                         Insert into country2 (country, city) values (?,?)\n\u2018\u2019\u2019,\nRow.Country,\nRow.City,\n)\n\nConn.commit()\n\n\n\nWhen I did this , I think it may have worked but I wasn\u2019t able to read the data from the table. I would read the data from other tables but it just kept executing for ages, so the code broke the table or something -  I haven\u2019t come across this issue before so I\u2019m not sure \n\nI left it to execute for like 30 mins and I couldn\u2019t get the table to open in SQL. I tried deleting the table and nothing happened.\n\nI created a new table in another test db with the same name and I tried.\n\nThen I tried df.to_sql(Country2, conn, if_exists = \u2018append\u2019, index=False)\n\nAnd got an error that pandas only supports SQLAlchemy engineer/connection or database string uri or SQLIte3 dbapi2 connection \n\n\nThanks in advance","link":"https://www.reddit.com/r/Python/comments/11nl8vu/how_to_use_python_to_upload_data_into_sql_server/","created":"2023-03-10","tags":["reddit","python"],"meta":{"num_comments":1},"text":"How to use python to upload data into SQL Server Database I\u2019ve been able to pull data out of the database. But I\u2019m having issues with appending the table. \n\nI keep getting an error\n\nThe first code I tried was like this \n\nFor row in df.itertuples():\n\n       Cursor.execute ( \u2018\u2019\u2019\n                         Insert into country2 (country, city) values (?,?)\n\u2018\u2019\u2019,\nRow.Country,\nRow.City,\n)\n\nConn.commit()\n\n\n\nWhen I did this , I think it may have worked but I wasn\u2019t able to read the data from the table. I would read the data from other tables but it just kept executing for ages, so the code broke the table or something -  I haven\u2019t come across this issue before so I\u2019m not sure \n\nI left it to execute for like 30 mins and I couldn\u2019t get the table to open in SQL. I tried deleting the table and nothing happened.\n\nI created a new table in another test db with the same name and I tried.\n\nThen I tried df.to_sql(Country2, conn, if_exists = \u2018append\u2019, index=False)\n\nAnd got an error that pandas only supports SQLAlchemy engineer/connection or database string uri or SQLIte3 dbapi2 connection \n\n\nThanks in advance","classes":{"dataset":0.4801109433}}
{"title":"I created Flask-Squeeze, it minifies and compresses responses so that your data transfers are as small as possible!","description":"Hi guys! I just wanted to share the Flask extension [Flask-Squeeze](https://github.com/mkrd/Flask-Squeeze) with you. It will minify javascript and css, and compress responses with brotli, deflate, or gzip depending on the request, with almost zero configuration.\n\nI know there are other extensions aswell, but as far as I know, none of them have a complete feature set of minification AND compression.\n\nLet me know what you think, if there are more things that could be added!","link":"https://www.reddit.com/r/Python/comments/11ms54x/i_created_flasksqueeze_it_minifies_and_compresses/","created":"2023-03-09","tags":["reddit","python"],"meta":{"num_comments":6},"text":"I created Flask-Squeeze, it minifies and compresses responses so that your data transfers are as small as possible! Hi guys! I just wanted to share the Flask extension [Flask-Squeeze](https://github.com/mkrd/Flask-Squeeze) with you. It will minify javascript and css, and compress responses with brotli, deflate, or gzip depending on the request, with almost zero configuration.\n\nI know there are other extensions aswell, but as far as I know, none of them have a complete feature set of minification AND compression.\n\nLet me know what you think, if there are more things that could be added!","classes":{"dataset":0.3075999916}}
{"title":"qStore - Youtube as file storage","description":"Okay, first and foremost, I want to say that I got inspired by GitHub: DvorakDwarf's [Infinite-Storage-Glitch](https://github.com/DvorakDwarf/Infinite-Storage-Glitch). So I decided to make my own proof of concept version in python3 instead of rust. I also wanted to use steganography but youtube's compression killed any and all hope I had. I have tried LSB, RGB, DCT, and Spacial Domain steganography and ALL work normally on their own...but all have failed when I upload the video to youtube and then download it.\n\nSo I decided to be a little clever and use QR codes. I modify one of many frames in the video with a QR code, and then re make the video and then it's ready to upload. One may wonder, \"well if it's in the QR code then the data can be easily obtained.\" Yes and No. Yes in terms of it's indeed a normal QR code and works how you'd expect it to work, and no in terms of the file data is encrypted using GCMlib (AES-GCM. KDF Argon2id) before being turned into the QR code. One can use any encryption method they want but I use GCMlib. (use at your own risk obviously).\n\n&amp;#x200B;\n\n[qStore](https://github.com/therealOri/qStore) also has its own database to keep track of what videos are what and the keys used to encrypt the file that is in the QR code. This database can also be locked and unlocked. (Like bitwarden). Just give it a key that was generated and then it's up to you on how you store it and keep it safe. (You can also use your own way of encrypting files if you wish, my methods are use at your own risk obviously.) You can add, remove, and view entries/records as well.\n\nThere's nothing really more to say about it as this project is still being worked on and I still really hope that eventually I can use actual steganography to embed a file into the videos. But for now, just QR codes.\n\nIf you or anyone you know would like to help out or even try it out/use my project then the link is below. &lt;3\n\nLink to github repo: [https://github.com/therealOri/qStore](https://github.com/therealOri/qStore)  \n\n\n  \n\n\n[qStore main menu](https://preview.redd.it/gqi2fnz01rma1.png?width=851&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=aa637f2bbf49ea9a040cd6ea0be48a808ed6028d)","link":"https://www.reddit.com/r/Python/comments/11my1tz/qstore_youtube_as_file_storage/","created":"2023-03-09","tags":["reddit","python"],"meta":{"num_comments":3},"text":"qStore - Youtube as file storage Okay, first and foremost, I want to say that I got inspired by GitHub: DvorakDwarf's [Infinite-Storage-Glitch](https://github.com/DvorakDwarf/Infinite-Storage-Glitch). So I decided to make my own proof of concept version in python3 instead of rust. I also wanted to use steganography but youtube's compression killed any and all hope I had. I have tried LSB, RGB, DCT, and Spacial Domain steganography and ALL work normally on their own...but all have failed when I upload the video to youtube and then download it.\n\nSo I decided to be a little clever and use QR codes. I modify one of many frames in the video with a QR code, and then re make the video and then it's ready to upload. One may wonder, \"well if it's in the QR code then the data can be easily obtained.\" Yes and No. Yes in terms of it's indeed a normal QR code and works how you'd expect it to work, and no in terms of the file data is encrypted using GCMlib (AES-GCM. KDF Argon2id) before being turned into the QR code. One can use any encryption method they want but I use GCMlib. (use at your own risk obviously).\n\n&amp;#x200B;\n\n[qStore](https://github.com/therealOri/qStore) also has its own database to keep track of what videos are what and the keys used to encrypt the file that is in the QR code. This database can also be locked and unlocked. (Like bitwarden). Just give it a key that was generated and then it's up to you on how you store it and keep it safe. (You can also use your own way of encrypting files if you wish, my methods are use at your own risk obviously.) You can add, remove, and view entries/records as well.\n\nThere's nothing really more to say about it as this project is still being worked on and I still really hope that eventually I can use actual steganography to embed a file into the videos. But for now, just QR codes.\n\nIf you or anyone you know would like to help out or even try it out/use my project then the link is below. &lt;3\n\nLink to github repo: [https://github.com/therealOri/qStore](https://github.com/therealOri/qStore)  \n\n\n  \n\n\n[qStore main menu](https://preview.redd.it/gqi2fnz01rma1.png?width=851&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=aa637f2bbf49ea9a040cd6ea0be48a808ed6028d)","classes":{"dataset":0.4539632499}}
{"title":"I made a Finance Database with over 300.000 tickers to make Investment Decisions easier","description":"It has been well over 2 years since I first introduced the database to this community, see [here](https://github.com/JerBouma/FinanceDatabase), and since then a lot changed so I felt like it is worth sharing about my package yet again and honestly, also to ask for a little bit of help.\n\nSo, within the investment universe there exists tens of thousands of companies (and even more when you include all exchanges). Identifying all of them and understanding in detail where they fit in the world is tough up to a point that it either requires you to pay a hefty fee to obtain this type of categorisation or do a massive amount of manual research. I found it a bit strange that this information was not publicly available while it is quite crucial for investment research. Therefore I got to work.\n\n**Insert the** [**FinanceDatabase**](https://github.com/JerBouma/FinanceDatabase)**.** This is a database of over 300.000 symbols (155k+ companies, 36k+ ETFs, 57k+ Funds, 3k+ Cryptocurrencies and more) that is fully categorised per country, industry, sector, category and more. It includes a package, written in Python and installable with \\`pip install financedatabase\\`, that gives access to the data with ease. You can obtain the entire dataset per asset class, search through it and filter based on specific options. Have a look at [this Notebook](https://github.com/JerBouma/FinanceDatabase/blob/main/examples.ipynb) to have an idea what it is offering.\n\nA simple example of what it does in the following:\n\n    import financedatabase as fd\n    \n    # Initialize the Equities database\n    equities = fd.Equities()\n    \n    # Obtain all data available excluding international exchanges\n    equities.select()\n\nWhich returns the following DataFrame: https://preview.redd.it/5gmiej7pbjma1.png?width=1516&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=faa84ca0e91107530f9845a5313ff79adc54ba6a\n\nBy default it hides non-US exchanges (since the ticker symbols work for most other programs) but that can be turned off with **equities.select(exclude\\_exchanges=False)** which returns 155.000 rows.\n\nThe database explicitly does not store up to date fundamental data. It tries to be as timeless as possible so that it doesn't become outdated fast. Because there are a variety of other ways, like FinancialModelingPrep, yFinance etc, to get this data there is no use in including this in the database.\n\nI've improved this database not only by increasing the amount of symbols (from 180k to 300k) but also:\n\n* Approximated the The Global Industry Classification Standard (GICS\u00ae), a standard used for sectors and industries everywhere. Note that this was approximated and therefore no actual data is collected. Furthermore, not all categories are included.\n* Updated and removed tickers that either no longer exist or had outdated information.\n* Made the package itself object orientated making data collecting and searching much more efficient and logical. (shoutout to [Colin Delahunty](https://github.com/colin99d) for the help here too)\n* The database initially featured thousands of JSON files. At the time it made sense also given my rather novice background in programming. However, a much more efficient (and manageable way) is to work with CSV files. So instead, one CSV file per asset class.\n* Due to using CSV files, it becomes **really** easy to update accordingly.\n* To make loading data itself still quick, it automatically compresses the data so that loading in data is not slowed down by using a format that is more easy to update.\n* Updated the README, Contributing Guidelines and overal documentation.\n\nSo being an open source project and trying to maintain such a database is tough to do alone. While I strongly believe the database can stay relevant for a long period due to the fact that the majority of companies do not suddenly stop existing, some maintenance is needed. Therefore, with this post I would like to not only invite you to explore the database but also to see if you can improve it along the way. Please visit the [CONTRIBUTING GUIDELINES](https://github.com/JerBouma/FinanceDatabase/blob/main/CONTRIBUTING.md) that explains in detail how you can contribute. Just pointing out wrong or missing information is already very beneficial!\n\nHope this database is still just as useful as it was two years ago!","link":"https://www.reddit.com/r/Python/comments/11lyyzb/i_made_a_finance_database_with_over_300000/","created":"2023-03-08","tags":["reddit","python"],"meta":{"num_comments":31},"text":"I made a Finance Database with over 300.000 tickers to make Investment Decisions easier It has been well over 2 years since I first introduced the database to this community, see [here](https://github.com/JerBouma/FinanceDatabase), and since then a lot changed so I felt like it is worth sharing about my package yet again and honestly, also to ask for a little bit of help.\n\nSo, within the investment universe there exists tens of thousands of companies (and even more when you include all exchanges). Identifying all of them and understanding in detail where they fit in the world is tough up to a point that it either requires you to pay a hefty fee to obtain this type of categorisation or do a massive amount of manual research. I found it a bit strange that this information was not publicly available while it is quite crucial for investment research. Therefore I got to work.\n\n**Insert the** [**FinanceDatabase**](https://github.com/JerBouma/FinanceDatabase)**.** This is a database of over 300.000 symbols (155k+ companies, 36k+ ETFs, 57k+ Funds, 3k+ Cryptocurrencies and more) that is fully categorised per country, industry, sector, category and more. It includes a package, written in Python and installable with \\`pip install financedatabase\\`, that gives access to the data with ease. You can obtain the entire dataset per asset class, search through it and filter based on specific options. Have a look at [this Notebook](https://github.com/JerBouma/FinanceDatabase/blob/main/examples.ipynb) to have an idea what it is offering.\n\nA simple example of what it does in the following:\n\n    import financedatabase as fd\n    \n    # Initialize the Equities database\n    equities = fd.Equities()\n    \n    # Obtain all data available excluding international exchanges\n    equities.select()\n\nWhich returns the following DataFrame: https://preview.redd.it/5gmiej7pbjma1.png?width=1516&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=faa84ca0e91107530f9845a5313ff79adc54ba6a\n\nBy default it hides non-US exchanges (since the ticker symbols work for most other programs) but that can be turned off with **equities.select(exclude\\_exchanges=False)** which returns 155.000 rows.\n\nThe database explicitly does not store up to date fundamental data. It tries to be as timeless as possible so that it doesn't become outdated fast. Because there are a variety of other ways, like FinancialModelingPrep, yFinance etc, to get this data there is no use in including this in the database.\n\nI've improved this database not only by increasing the amount of symbols (from 180k to 300k) but also:\n\n* Approximated the The Global Industry Classification Standard (GICS\u00ae), a standard used for sectors and industries everywhere. Note that this was approximated and therefore no actual data is collected. Furthermore, not all categories are included.\n* Updated and removed tickers that either no longer exist or had outdated information.\n* Made the package itself object orientated making data collecting and searching much more efficient and logical. (shoutout to [Colin Delahunty](https://github.com/colin99d) for the help here too)\n* The database initially featured thousands of JSON files. At the time it made sense also given my rather novice background in programming. However, a much more efficient (and manageable way) is to work with CSV files. So instead, one CSV file per asset class.\n* Due to using CSV files, it becomes **really** easy to update accordingly.\n* To make loading data itself still quick, it automatically compresses the data so that loading in data is not slowed down by using a format that is more easy to update.\n* Updated the README, Contributing Guidelines and overal documentation.\n\nSo being an open source project and trying to maintain such a database is tough to do alone. While I strongly believe the database can stay relevant for a long period due to the fact that the majority of companies do not suddenly stop existing, some maintenance is needed. Therefore, with this post I would like to not only invite you to explore the database but also to see if you can improve it along the way. Please visit the [CONTRIBUTING GUIDELINES](https://github.com/JerBouma/FinanceDatabase/blob/main/CONTRIBUTING.md) that explains in detail how you can contribute. Just pointing out wrong or missing information is already very beneficial!\n\nHope this database is still just as useful as it was two years ago!","classes":{"dataset":0.5291472673}}
{"title":"Distributed Tracing guide","description":"If you're looking to learn more about distributed tracing, check out this [guide.](https://gethelios.dev/distributed-tracing/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/gqq8mi5jaqma1.png?width=2200&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=051e9e0c5ef03bf5bd28829652e6091a7981491e","link":"https://www.reddit.com/r/Python/comments/11mufw4/distributed_tracing_guide/","created":"2023-03-09","tags":["reddit","python"],"meta":{"num_comments":2},"text":"Distributed Tracing guide If you're looking to learn more about distributed tracing, check out this [guide.](https://gethelios.dev/distributed-tracing/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/gqq8mi5jaqma1.png?width=2200&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=051e9e0c5ef03bf5bd28829652e6091a7981491e","classes":{"dataset":0.4616645873}}
{"title":"Training Transformer Networks in Scikit-Learn?!","description":"Have you ever wanted to use handy scikit-learn functionalities with your neural networks, but couldn\u2019t because TensorFlow models are not compatible with the scikit-learn API?\n\nI\u2019m excited to introduce one-line wrappers for TensorFlow/Keras models that enable you to use TensorFlow models within scikit-learn workflows with features like Pipeline, GridSearch, and more.\n\n&amp;#x200B;\n\n[Swap in one line of code to use keras\\/TF models with scikit-learn.](https://preview.redd.it/g5ssnz1f6rma1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=206be211c08985c0693929c445f3c274234bd58d)\n\nTransformers are extremely popular for modeling text nowadays with GPT3, ChatGPT, Bard, PaLM, FLAN excelling for conversational AI and other Transformers like T5 &amp; BERT excelling for text classification. Scikit-learn offers a broadly useful suite of features for classifier models, but these are hard to use with Transformers. However not if you use these wrappers we developed, which only require changing one line of code to make your existing Tensorflow/Keras model compatible with scikit-learn\u2019s rich ecosystem!\n\nAll you have to do is swap `keras.Model` \u2192 `KerasWrapperModel`, or `keras.Sequential` \u2192 `KerasSequentialWrapper`. The wrapper objects have all the same methods as their keras counterparts, plus you can use them with tons of awesome scikit-learn methods.\n\nYou can find a demo jupyter notebook and read more about the wrappers here: [https://cleanlab.ai/blog/transformer-sklearn/](https://cleanlab.ai/blog/transformer-sklearn/)","link":"https://www.reddit.com/r/Python/comments/11mzd3p/training_transformer_networks_in_scikitlearn/","created":"2023-03-09","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Training Transformer Networks in Scikit-Learn?! Have you ever wanted to use handy scikit-learn functionalities with your neural networks, but couldn\u2019t because TensorFlow models are not compatible with the scikit-learn API?\n\nI\u2019m excited to introduce one-line wrappers for TensorFlow/Keras models that enable you to use TensorFlow models within scikit-learn workflows with features like Pipeline, GridSearch, and more.\n\n&amp;#x200B;\n\n[Swap in one line of code to use keras\\/TF models with scikit-learn.](https://preview.redd.it/g5ssnz1f6rma1.png?width=960&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=206be211c08985c0693929c445f3c274234bd58d)\n\nTransformers are extremely popular for modeling text nowadays with GPT3, ChatGPT, Bard, PaLM, FLAN excelling for conversational AI and other Transformers like T5 &amp; BERT excelling for text classification. Scikit-learn offers a broadly useful suite of features for classifier models, but these are hard to use with Transformers. However not if you use these wrappers we developed, which only require changing one line of code to make your existing Tensorflow/Keras model compatible with scikit-learn\u2019s rich ecosystem!\n\nAll you have to do is swap `keras.Model` \u2192 `KerasWrapperModel`, or `keras.Sequential` \u2192 `KerasSequentialWrapper`. The wrapper objects have all the same methods as their keras counterparts, plus you can use them with tons of awesome scikit-learn methods.\n\nYou can find a demo jupyter notebook and read more about the wrappers here: [https://cleanlab.ai/blog/transformer-sklearn/](https://cleanlab.ai/blog/transformer-sklearn/)","classes":{"dataset":0.4182201922}}
{"title":"OpenAI's Python API walk-through","description":"If you are getting started with OpenAI's newest Python API, you don't have to spend too much time familiarising yourself with how to use it. Here is a video that walks through the different possiblities, API parameters and finally shares a demo app: [https://youtu.be/dcnfhtuL7qA](https://youtu.be/dcnfhtuL7qA) \n\nHope its useful. \n\nhttps://preview.redd.it/z1aczihy2xma1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5b749e1485746ce0beeb1f19cc878109d146a2a7","link":"https://www.reddit.com/r/deeplearning/comments/11npswy/openais_python_api_walkthrough/","created":"2023-03-10","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"OpenAI's Python API walk-through If you are getting started with OpenAI's newest Python API, you don't have to spend too much time familiarising yourself with how to use it. Here is a video that walks through the different possiblities, API parameters and finally shares a demo app: [https://youtu.be/dcnfhtuL7qA](https://youtu.be/dcnfhtuL7qA) \n\nHope its useful. \n\nhttps://preview.redd.it/z1aczihy2xma1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5b749e1485746ce0beeb1f19cc878109d146a2a7","classes":{"dataset":0.3595617115}}
{"title":"AskReddit: which MBP Pro is future proof for AI apps development?","description":"Specifically to play with diffusion or gpt models, just generation and fine tuning, not large training.\n\nI gear towards MBP due to portability and build quality.\n\nAny advice is appreciated.\n\nPD: for my work, I have a 14\u201d M1 Pro but do GPU stuff (in-house vision models) on the cloud, so I don\u2019t know how practical it is for diffusion/gpt models.","link":"https://www.reddit.com/r/deeplearning/comments/11n8xrc/askreddit_which_mbp_pro_is_future_proof_for_ai/","created":"2023-03-10","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":6},"text":"AskReddit: which MBP Pro is future proof for AI apps development? Specifically to play with diffusion or gpt models, just generation and fine tuning, not large training.\n\nI gear towards MBP due to portability and build quality.\n\nAny advice is appreciated.\n\nPD: for my work, I have a 14\u201d M1 Pro but do GPU stuff (in-house vision models) on the cloud, so I don\u2019t know how practical it is for diffusion/gpt models.","classes":{"dataset":0.1550450772}}
{"title":"Stanford Webinar - The Frontier of Deep Learning for Robotics","description":"Join Professor Chelsea Finn in this discussion on modern deep reinforcement learning algorithms, and learn more about their usefulness towards solving ambitious challenges in [\\#Robotics](https://twitter.com/hashtag/Robotics?src=hashtag_click).   \n[Register Now](https://learn.stanford.edu/DeepLearningRobotics-2023-Registration.html?utm_source=reddit&amp;utm_medium=oa&amp;utm_campaign=webinar)\n\nhttps://preview.redd.it/m73tnq832rma1.jpg?width=720&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8622319607af5d5f2890323a909d6eadd70a7ded","link":"https://www.reddit.com/r/deeplearning/comments/11myc6e/stanford_webinar_the_frontier_of_deep_learning/","created":"2023-03-09","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"Stanford Webinar - The Frontier of Deep Learning for Robotics Join Professor Chelsea Finn in this discussion on modern deep reinforcement learning algorithms, and learn more about their usefulness towards solving ambitious challenges in [\\#Robotics](https://twitter.com/hashtag/Robotics?src=hashtag_click).   \n[Register Now](https://learn.stanford.edu/DeepLearningRobotics-2023-Registration.html?utm_source=reddit&amp;utm_medium=oa&amp;utm_campaign=webinar)\n\nhttps://preview.redd.it/m73tnq832rma1.jpg?width=720&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=8622319607af5d5f2890323a909d6eadd70a7ded","classes":{"dataset":0.4218678772}}
{"title":"Can feature engineering avoid overfitting?","description":" Can feature engineering avoid overfitting? If yes, are there any relevant papers that state this?","link":"https://www.reddit.com/r/deeplearning/comments/11mokqu/can_feature_engineering_avoid_overfitting/","created":"2023-03-09","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":14},"text":"Can feature engineering avoid overfitting?  Can feature engineering avoid overfitting? If yes, are there any relevant papers that state this?","classes":{"dataset":0.3511880636}}
{"title":"Do you use synthetic data in your projects?","description":"&amp;#x200B;\n\nhttps://preview.redd.it/vl7j0i04zpma1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=30a37b6c563173e47ac5d9d9b5fd6c74fc7348e9\n\nHi all!\n\nMy name is Vadim, I work in [OpenCV.ai](https://OpenCV.ai). We provide consulting services in the field of Computer Vision and AI. Now we work on a new tool for creating photorealistic synthetic data. \n\nWe eager to know what problems you most usually face while using it or why you don't use it. Your experience is extremely valuable for us. If you are open to discuss it, please write a private message to gleb.tuzov@opencv.ai or leave a comment. \n\nThank you!","link":"https://www.reddit.com/r/deeplearning/comments/11mswj6/do_you_use_synthetic_data_in_your_projects/","created":"2023-03-09","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"Do you use synthetic data in your projects? &amp;#x200B;\n\nhttps://preview.redd.it/vl7j0i04zpma1.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=30a37b6c563173e47ac5d9d9b5fd6c74fc7348e9\n\nHi all!\n\nMy name is Vadim, I work in [OpenCV.ai](https://OpenCV.ai). We provide consulting services in the field of Computer Vision and AI. Now we work on a new tool for creating photorealistic synthetic data. \n\nWe eager to know what problems you most usually face while using it or why you don't use it. Your experience is extremely valuable for us. If you are open to discuss it, please write a private message to gleb.tuzov@opencv.ai or leave a comment. \n\nThank you!","classes":{"dataset":0.5790317655}}
{"title":"Parameter values of diffusion models","description":"Hi everyone!\n\nI have a question about diffusion models from the paper \"Denoising Diffusion Probabilistic Models\" by Ho. et al. ([https://arxiv.org/pdf/2006.11239.pdf](https://arxiv.org/pdf/2006.11239.pdf)). They chose not to train \u03a3\\_\u03b8(x\\_t, t) but setting it equal to  \u03c3\\_t\\^2 I, and then they experiment with two different values on \u03c3\\_t\\^2, namely \u03b2\\_t and \\\\tilde{\u03b2}\\_t. The first choice is optimal for x\\_0 \u223c N(0, I), and the second is optimal for x\\_0 deterministically set to one point, why is that? Does anyone have a good explanation and/or derivation of that.","link":"https://www.reddit.com/r/deeplearning/comments/11m0kvf/parameter_values_of_diffusion_models/","created":"2023-03-08","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":1},"text":"Parameter values of diffusion models Hi everyone!\n\nI have a question about diffusion models from the paper \"Denoising Diffusion Probabilistic Models\" by Ho. et al. ([https://arxiv.org/pdf/2006.11239.pdf](https://arxiv.org/pdf/2006.11239.pdf)). They chose not to train \u03a3\\_\u03b8(x\\_t, t) but setting it equal to  \u03c3\\_t\\^2 I, and then they experiment with two different values on \u03c3\\_t\\^2, namely \u03b2\\_t and \\\\tilde{\u03b2}\\_t. The first choice is optimal for x\\_0 \u223c N(0, I), and the second is optimal for x\\_0 deterministically set to one point, why is that? Does anyone have a good explanation and/or derivation of that.","classes":{"dataset":0.3120580912}}
{"title":"Weaviate Vector DB adds support for Product Quantization, Bitmap Filters, Filtered Hybrid Search, Tunable Consistency, and more in the v1.18 release.","description":"Ever since Chat-GPT has hit the masses, the interest in vector search has gone through the roof. Weaviate takes an end2end approach to vector search because it also stores the data object, and builds inverted indexes besides the vector indexes.  \n\n\nYesterday, version `v1.18.0` was released, with the following features that were in high demand by the community:\n\n# Product Quantization\n\nWeaviate v1.18 allows compressing vector embeddings using Product Quantization in combination with HNSW vector indexing (HNSW-PQ). This allows for a lower memory footprint while keeping low latency and high recall\n\n# Bitmap Filtering\n\nWeaviate's inverted index is now built natively on top of roaring bitmaps. This allows for very fast filtered vector search even at the 100M or billion scale. In some extreme cases, search latencies went down from 5s to 5ms.\n\n# Filtered Hybrid Search\n\nWeaviate v1.17 added support for Hybrid (BM25 sparse + Vector Dense) search. However, it did not (yet) allow for setting filters on Hybrid Search queries. This is now possible with v1.18\n\n# BM25 WAND Scoring\n\nWeak-AND (\"WAND\") is a BM25 scoring algorithm that avoids scoring documents that cannot reach a high enough score to be contained in the result set. This speeds up BM25 \u2013\u00a0and in turn \u2013 hybrid search\n\n# Tunable Consistency and Automatic Repairs\n\nA previous Weaviate release added support for High-Availability through Replication. However, the desired level of consistency when reading and writing was set by Weaviate. Now, the user can set these settings according to their preferences. In addition, if Weaviate detects an inconsistency (e.g. after a temporary node failure) it can now be repaired automatically when reading the \"corrupt\" object.\n\n# Cursor API\n\nIn previous Weaviate releases, it was impossible to export all objects from Weaviate because of the increasing cost of each page on pagination. The new cursor API provides a constant-cost way to extract all objects (and their vector embeddings) from Weaviate.\n\n# Azure Backup Module\n\nIn addition to Google Cloud Storage, and Amazon S3, Weaviate now supports Azure Blob storage for seamless backups and restores.\n\n\\---\n\nMore information:\n\n* [Release blog post](https://weaviate.io/blog/weaviate-1-18-release)\n* [Release on GitHub](https://github.com/weaviate/weaviate/releases/tag/v1.18.0)\n\nDisclaimer: I am a co-founder of Weaviate.","link":"https://www.reddit.com/r/deeplearning/comments/11lsal6/weaviate_vector_db_adds_support_for_product/","created":"2023-03-08","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":2},"text":"Weaviate Vector DB adds support for Product Quantization, Bitmap Filters, Filtered Hybrid Search, Tunable Consistency, and more in the v1.18 release. Ever since Chat-GPT has hit the masses, the interest in vector search has gone through the roof. Weaviate takes an end2end approach to vector search because it also stores the data object, and builds inverted indexes besides the vector indexes.  \n\n\nYesterday, version `v1.18.0` was released, with the following features that were in high demand by the community:\n\n# Product Quantization\n\nWeaviate v1.18 allows compressing vector embeddings using Product Quantization in combination with HNSW vector indexing (HNSW-PQ). This allows for a lower memory footprint while keeping low latency and high recall\n\n# Bitmap Filtering\n\nWeaviate's inverted index is now built natively on top of roaring bitmaps. This allows for very fast filtered vector search even at the 100M or billion scale. In some extreme cases, search latencies went down from 5s to 5ms.\n\n# Filtered Hybrid Search\n\nWeaviate v1.17 added support for Hybrid (BM25 sparse + Vector Dense) search. However, it did not (yet) allow for setting filters on Hybrid Search queries. This is now possible with v1.18\n\n# BM25 WAND Scoring\n\nWeak-AND (\"WAND\") is a BM25 scoring algorithm that avoids scoring documents that cannot reach a high enough score to be contained in the result set. This speeds up BM25 \u2013\u00a0and in turn \u2013 hybrid search\n\n# Tunable Consistency and Automatic Repairs\n\nA previous Weaviate release added support for High-Availability through Replication. However, the desired level of consistency when reading and writing was set by Weaviate. Now, the user can set these settings according to their preferences. In addition, if Weaviate detects an inconsistency (e.g. after a temporary node failure) it can now be repaired automatically when reading the \"corrupt\" object.\n\n# Cursor API\n\nIn previous Weaviate releases, it was impossible to export all objects from Weaviate because of the increasing cost of each page on pagination. The new cursor API provides a constant-cost way to extract all objects (and their vector embeddings) from Weaviate.\n\n# Azure Backup Module\n\nIn addition to Google Cloud Storage, and Amazon S3, Weaviate now supports Azure Blob storage for seamless backups and restores.\n\n\\---\n\nMore information:\n\n* [Release blog post](https://weaviate.io/blog/weaviate-1-18-release)\n* [Release on GitHub](https://github.com/weaviate/weaviate/releases/tag/v1.18.0)\n\nDisclaimer: I am a co-founder of Weaviate.","classes":{"dataset":0.5433297157}}
{"title":"[P] Implementing Vision Transformer (ViT) from Scratch using PyTorch","description":"I recently delved into the world of transformers and their application to vision tasks.\n\nAs part of my learning process, I implemented the Vision Transformer (ViT) from scratch using PyTorch. I am sharing my implementation and a step-by-step guide to implementing the model in this post.\n\nI hope you find it helpful.\n\nGithub: [https://github.com/tintn/vision-transformer-from-scratch](https://github.com/tintn/vision-transformer-from-scratch)\n\nPost: [https://medium.com/towards-data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0](https://medium.com/towards-data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0)","link":"https://www.reddit.com/r/MachineLearning/comments/11nj58o/p_implementing_vision_transformer_vit_from/","created":"2023-03-10","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[P] Implementing Vision Transformer (ViT) from Scratch using PyTorch I recently delved into the world of transformers and their application to vision tasks.\n\nAs part of my learning process, I implemented the Vision Transformer (ViT) from scratch using PyTorch. I am sharing my implementation and a step-by-step guide to implementing the model in this post.\n\nI hope you find it helpful.\n\nGithub: [https://github.com/tintn/vision-transformer-from-scratch](https://github.com/tintn/vision-transformer-from-scratch)\n\nPost: [https://medium.com/towards-data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0](https://medium.com/towards-data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0)","classes":{"dataset":0.3881672323}}
{"title":"[R] RODIN: A Generative Model for Sculpting 3D Digital Avatars Using Diffusion","description":"We, the team from Microsoft Research, propose a diffusion-based generative model to automatically produces highly detailed 3D digital avatars. The generated avatars can be freely viewed in 360 degrees with unprecedented quality. The model significantly accelerates the traditionally sophisticated 3D modeling process and opens new opportunities for 3D artists. The work has been accepted to CVPR 2022.\n\nProject page: [https://3d-avatar-diffusion.microsoft.com/](https://3d-avatar-diffusion.microsoft.com/)\n\nArxiv paper link: [https://arxiv.org/abs/2212.06135](https://arxiv.org/abs/2212.06135)\n\n[360-degree renderable avatar](https://reddit.com/link/11njhnz/video/3bhbf5x7evma1/player)\n\nOne can use a user-given image or natural language prompt to produce a personalized avatar.\n\n[Text-conditioned avatar generation.](https://preview.redd.it/yp32l7u6fvma1.png?width=2778&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e8699c81e0750084209c2d2f6b94a7df117fcf78)\n\nWhile this work is validated on 3D avatar generation, as a broader impact, we hope this work paves the way toward building a 3D generative foundation model for general 3D objects.","link":"https://www.reddit.com/r/MachineLearning/comments/11njhnz/r_rodin_a_generative_model_for_sculpting_3d/","created":"2023-03-10","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":1},"text":"[R] RODIN: A Generative Model for Sculpting 3D Digital Avatars Using Diffusion We, the team from Microsoft Research, propose a diffusion-based generative model to automatically produces highly detailed 3D digital avatars. The generated avatars can be freely viewed in 360 degrees with unprecedented quality. The model significantly accelerates the traditionally sophisticated 3D modeling process and opens new opportunities for 3D artists. The work has been accepted to CVPR 2022.\n\nProject page: [https://3d-avatar-diffusion.microsoft.com/](https://3d-avatar-diffusion.microsoft.com/)\n\nArxiv paper link: [https://arxiv.org/abs/2212.06135](https://arxiv.org/abs/2212.06135)\n\n[360-degree renderable avatar](https://reddit.com/link/11njhnz/video/3bhbf5x7evma1/player)\n\nOne can use a user-given image or natural language prompt to produce a personalized avatar.\n\n[Text-conditioned avatar generation.](https://preview.redd.it/yp32l7u6fvma1.png?width=2778&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e8699c81e0750084209c2d2f6b94a7df117fcf78)\n\nWhile this work is validated on 3D avatar generation, as a broader impact, we hope this work paves the way toward building a 3D generative foundation model for general 3D objects.","classes":{"dataset":0.3677758873}}
{"title":"[D] Neuron Modeling","description":"Disclaimer : I am just a SWE who only knows some basic concepts of NN and ML, so I might be talking total garbage here.\n\nRecently, I read the news that the organoid made from brain cells can now play a simple game. Since it was made from the real neurons, it was way more efficient in learning.\n\nIf we think about it, our brain is very small and consumes comparably lower power, but still we are pretty smarter than the most of ai models powered by 1000s of gpus.\n\nI was wondering if there are any interesting research papers that actually try to model a human neuron. Btw I am not talking about a neural network itself. I feel like we are over simplifying a neuron as just a number while it can be an object that contains interesting features of our real neurons.\n\nI would really appreciate it if anyone could recommend any related research papers to read!","link":"https://www.reddit.com/r/MachineLearning/comments/11ned6g/d_neuron_modeling/","created":"2023-03-10","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":8},"text":"[D] Neuron Modeling Disclaimer : I am just a SWE who only knows some basic concepts of NN and ML, so I might be talking total garbage here.\n\nRecently, I read the news that the organoid made from brain cells can now play a simple game. Since it was made from the real neurons, it was way more efficient in learning.\n\nIf we think about it, our brain is very small and consumes comparably lower power, but still we are pretty smarter than the most of ai models powered by 1000s of gpus.\n\nI was wondering if there are any interesting research papers that actually try to model a human neuron. Btw I am not talking about a neural network itself. I feel like we are over simplifying a neuron as just a number while it can be an object that contains interesting features of our real neurons.\n\nI would really appreciate it if anyone could recommend any related research papers to read!","classes":{"dataset":0.5352126956}}
{"title":"[D] Which free AI models are best to generate talking animation from a given input image - lip synching","description":"So far I know this one (*Thin-Plate Spline Motion Model for Image Animation on Hugging face*) however it is not generating based on the given input sound\n\nSo there is no lip synching \n\nSo are there any alternatives? Yes there are paid services but costs are astronomic","link":"https://www.reddit.com/r/MachineLearning/comments/11nqdp9/d_which_free_ai_models_are_best_to_generate/","created":"2023-03-10","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[D] Which free AI models are best to generate talking animation from a given input image - lip synching So far I know this one (*Thin-Plate Spline Motion Model for Image Animation on Hugging face*) however it is not generating based on the given input sound\n\nSo there is no lip synching \n\nSo are there any alternatives? Yes there are paid services but costs are astronomic","classes":{"dataset":0.2945910096}}
{"title":"[N] OpenAI's API - full walkthrough","description":"If you are getting started with OpenAI's newest Python API, you don't have to spend too much time familiarising yourself with how to use it. Here is a video that walks through the different possiblities, API parameters and finally shares a demo app: [https://youtu.be/dcnfhtuL7qA](https://youtu.be/dcnfhtuL7qA) \n\nHope its useful. \n\nhttps://preview.redd.it/5t8gbntg2xma1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6a62c103b5f1dd4cb6d3e1480ff9b519a0de5c28","link":"https://www.reddit.com/r/MachineLearning/comments/11nprt2/n_openais_api_full_walkthrough/","created":"2023-03-10","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[N] OpenAI's API - full walkthrough If you are getting started with OpenAI's newest Python API, you don't have to spend too much time familiarising yourself with how to use it. Here is a video that walks through the different possiblities, API parameters and finally shares a demo app: [https://youtu.be/dcnfhtuL7qA](https://youtu.be/dcnfhtuL7qA) \n\nHope its useful. \n\nhttps://preview.redd.it/5t8gbntg2xma1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=6a62c103b5f1dd4cb6d3e1480ff9b519a0de5c28","classes":{"dataset":0.3375642002}}
{"title":"[P] ESG scoring with Node2Vec and web-site with streamlit!","description":"Github: [https://github.com/monouns/ESG-AI-investment-by-streamlit](https://github.com/monouns/ESG-AI-investment-by-streamlit)\n\n ***This repository is referenced by*** [***ESG\\_AI***](https://github.com/hannahawalsh/ESG_AI) ***which is*** [***Hack to the Future 2020***](https://devpost.com/software/esg-ai) ***Winner: Best Environmental Impact &amp; Best User Experience*** \n\n### The project's flow is,\n\n* s&amp;p500's 90% of enterprises reveal sustainability reports every year.\n* But we do not have a standard evaluation format to get a score of ESG.\n* So crawling the article from gdelt, analyze the tone of an article about ESG, and then scoring with the word used in the article\n* At scoring, gdelt data is used.\n* For portfolio creation, Node2Vec and Markowitz portfolio theory is used.","link":"https://www.reddit.com/r/MachineLearning/comments/11nmaw9/p_esg_scoring_with_node2vec_and_website_with/","created":"2023-03-10","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[P] ESG scoring with Node2Vec and web-site with streamlit! Github: [https://github.com/monouns/ESG-AI-investment-by-streamlit](https://github.com/monouns/ESG-AI-investment-by-streamlit)\n\n ***This repository is referenced by*** [***ESG\\_AI***](https://github.com/hannahawalsh/ESG_AI) ***which is*** [***Hack to the Future 2020***](https://devpost.com/software/esg-ai) ***Winner: Best Environmental Impact &amp; Best User Experience*** \n\n### The project's flow is,\n\n* s&amp;p500's 90% of enterprises reveal sustainability reports every year.\n* But we do not have a standard evaluation format to get a score of ESG.\n* So crawling the article from gdelt, analyze the tone of an article about ESG, and then scoring with the word used in the article\n* At scoring, gdelt data is used.\n* For portfolio creation, Node2Vec and Markowitz portfolio theory is used.","classes":{"dataset":0.4339435697}}
{"title":"[D] Is it possible to train LLaMa?","description":"Most AI is impossible to train(like chat GPT)\n\nDose LLaMa can be trained? \n\nAlthough the dataset is very hard to get, It would be nice if LLaMa can be trained.\n\nWhen searching for reddit, this topic cannot be searched, so I hope it becomes a discuss about HW or availability.  \nThank you.","link":"https://www.reddit.com/r/MachineLearning/comments/11nhl03/d_is_it_possible_to_train_llama/","created":"2023-03-10","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":7},"text":"[D] Is it possible to train LLaMa? Most AI is impossible to train(like chat GPT)\n\nDose LLaMa can be trained? \n\nAlthough the dataset is very hard to get, It would be nice if LLaMa can be trained.\n\nWhen searching for reddit, this topic cannot be searched, so I hope it becomes a discuss about HW or availability.  \nThank you.","classes":{"dataset":0.1176607907}}
{"title":"[D] What is the best way to fine tune a LLM with your own data and build a custom text classifier?","description":" I am new to LLM. What is the best way to build a custom text classifier leveraging your own data? The data is not labeled. Also what is the best starting LLM for this purpose- smaller model like Roberta or larger ones like GPT?","link":"https://www.reddit.com/r/MachineLearning/comments/11mw2xy/d_what_is_the_best_way_to_fine_tune_a_llm_with/","created":"2023-03-09","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":2},"text":"[D] What is the best way to fine tune a LLM with your own data and build a custom text classifier?  I am new to LLM. What is the best way to build a custom text classifier leveraging your own data? The data is not labeled. Also what is the best starting LLM for this purpose- smaller model like Roberta or larger ones like GPT?","classes":{"dataset":0.3305649459}}
{"title":"[N] CFP: IJCAI 2023 Workshop on Knowledge-Based Compositional Generalization (KBCG)","description":"\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* KBCG @ IJCAI 2023 Call for papers \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nThe 1st International Workshop on Knowledge-Based Compositional Generalization (KBCG)\n\nHeld  in conjunction with the 32nd International Joint Conference on  Artificial Intelligence (IJCAI 2023), August 19th 2023, Cape Town, South  Africa\n\n* Website: [https://KnowledgeAI.github.io/](https://knowledgeai.github.io/)\n* Submission deadline: April 26th, 2023 (11:59 pm AOE)\n* Submission link: [https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG](https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG)\n* IJCAI format, 7-page paper (+2-page references) for proceeding articles\n* IJCAI format, 2-page abstract for posters/demonstrations\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nDear Colleagues,\n\nWe  are excited to announce the First International Workshop on  Knowledge-Based Compositional Generalization (KBCG), which will be held  in conjunction with IJCAI 2023 this August in Cape Town, South Africa.  Our workshop aims to bring together researchers from academia and  industry to discuss the latest advances and challenges in the area of  knowledge representation and compositional generalization in AI.\n\nWebsite: [https://knowledgeai.github.io/](https://knowledgeai.github.io/)\n\nWe  invite researchers in AI, machine learning, statistics, cognitive  sciences, psychology and neuroscience to submit their latest work on  knowledge-based compositional generalization. The goal of this workshop  is to provide a platform for researchers to present their latest work  and to foster discussions on the challenges and opportunities in this  area.  \nThe submission deadline is April 26th, 2023 (11:59 pm AOE), and  the acceptance notification will be on June 1st, 2022. Accepted papers  will be presented at the workshop and included in a workshop proceeding.\n\nWe  invite researchers in AI, machine learning, statistics, cognitive  sciences and neuroscience to submit their papers, posters, and  demonstrations on any topic related to knowledge representation and  compositional generalization, including but not limited to:\n\n* Representation learning for compositional generalization\n* Meta-learning for compositional generalization\n* Transfer learning for compositional generalization\n* Reasoning for compositional generalization\n* Applications of knowledge-based compositional generalization\n* Learning compositional representations\n* Combining knowledge from multiple sources\n* Transfer learning and domain adaptation\n* Compositional generalization in natural language understanding\n* Compositional generalization in reinforcement learning\n* Compositional generalization in knowledge representation and reasoning\n* Relational machine Learning\n* Using external knowledge for efficient machine learning\n* Symbol grounding and Abstractions\n* Benchmarks for compositional generalization\n\nSubmissions  should be in the form of a 7-page paper (+2-page references) for  proceeding articles or a 2-page abstract for posters/demonstrations,  formatted according to the conference's guidelines ([https://www.ijcai.org/authors\\_kit](https://www.ijcai.org/authors_kit)). The submission website is on OpenReview: [https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG](https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG)\n\nKey Dates:\n\n* Submission deadline: April 26th, 2023 (11:59 pm AOE)\n* Acceptance notification: June 1st, 2022\n* Camera ready for accepted submissions: June 15th, 2022\n\nOrganizing Committee:\n\n* Baihan Lin, Columbia University\n* Djallel Bouneffouf, IBM Research\n* Asim Munawar, IBM Research\n* Irina Rish, Mila - Quebec AI Institute\n\nWe  look forward to your submissions and to seeing you at the workshop. If  you have any questions, please feel free to contact the organizing  committee at [kbcg.workshop@gmail.com](mailto:kbcg.workshop@gmail.com).","link":"https://www.reddit.com/r/MachineLearning/comments/11msqu6/n_cfp_ijcai_2023_workshop_on_knowledgebased/","created":"2023-03-09","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[N] CFP: IJCAI 2023 Workshop on Knowledge-Based Compositional Generalization (KBCG) \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* KBCG @ IJCAI 2023 Call for papers \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nThe 1st International Workshop on Knowledge-Based Compositional Generalization (KBCG)\n\nHeld  in conjunction with the 32nd International Joint Conference on  Artificial Intelligence (IJCAI 2023), August 19th 2023, Cape Town, South  Africa\n\n* Website: [https://KnowledgeAI.github.io/](https://knowledgeai.github.io/)\n* Submission deadline: April 26th, 2023 (11:59 pm AOE)\n* Submission link: [https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG](https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG)\n* IJCAI format, 7-page paper (+2-page references) for proceeding articles\n* IJCAI format, 2-page abstract for posters/demonstrations\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nDear Colleagues,\n\nWe  are excited to announce the First International Workshop on  Knowledge-Based Compositional Generalization (KBCG), which will be held  in conjunction with IJCAI 2023 this August in Cape Town, South Africa.  Our workshop aims to bring together researchers from academia and  industry to discuss the latest advances and challenges in the area of  knowledge representation and compositional generalization in AI.\n\nWebsite: [https://knowledgeai.github.io/](https://knowledgeai.github.io/)\n\nWe  invite researchers in AI, machine learning, statistics, cognitive  sciences, psychology and neuroscience to submit their latest work on  knowledge-based compositional generalization. The goal of this workshop  is to provide a platform for researchers to present their latest work  and to foster discussions on the challenges and opportunities in this  area.  \nThe submission deadline is April 26th, 2023 (11:59 pm AOE), and  the acceptance notification will be on June 1st, 2022. Accepted papers  will be presented at the workshop and included in a workshop proceeding.\n\nWe  invite researchers in AI, machine learning, statistics, cognitive  sciences and neuroscience to submit their papers, posters, and  demonstrations on any topic related to knowledge representation and  compositional generalization, including but not limited to:\n\n* Representation learning for compositional generalization\n* Meta-learning for compositional generalization\n* Transfer learning for compositional generalization\n* Reasoning for compositional generalization\n* Applications of knowledge-based compositional generalization\n* Learning compositional representations\n* Combining knowledge from multiple sources\n* Transfer learning and domain adaptation\n* Compositional generalization in natural language understanding\n* Compositional generalization in reinforcement learning\n* Compositional generalization in knowledge representation and reasoning\n* Relational machine Learning\n* Using external knowledge for efficient machine learning\n* Symbol grounding and Abstractions\n* Benchmarks for compositional generalization\n\nSubmissions  should be in the form of a 7-page paper (+2-page references) for  proceeding articles or a 2-page abstract for posters/demonstrations,  formatted according to the conference's guidelines ([https://www.ijcai.org/authors\\_kit](https://www.ijcai.org/authors_kit)). The submission website is on OpenReview: [https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG](https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG)\n\nKey Dates:\n\n* Submission deadline: April 26th, 2023 (11:59 pm AOE)\n* Acceptance notification: June 1st, 2022\n* Camera ready for accepted submissions: June 15th, 2022\n\nOrganizing Committee:\n\n* Baihan Lin, Columbia University\n* Djallel Bouneffouf, IBM Research\n* Asim Munawar, IBM Research\n* Irina Rish, Mila - Quebec AI Institute\n\nWe  look forward to your submissions and to seeing you at the workshop. If  you have any questions, please feel free to contact the organizing  committee at [kbcg.workshop@gmail.com](mailto:kbcg.workshop@gmail.com).","classes":{"dataset":0.355586797}}
{"title":"[D] Is a diverse dataset necessary for accuracy if the conditions in which inference will be used are narrow?","description":"Let's say hypothetically that I want to train an object detection model to recognize dogs in the video output of my home security camera. I know for a fact that I will only use my model on this one camera and that the position and rotation of my camera will never change. Normally when building a dataset, especially for computer vision models, you want to include diverse data to ensure that objects can be detected regardless of their surroundings. However in this case one can make the assumption that the surroundings will largely be static other than some minor variations. For this example does it make more sense to train a model on images collected from the perspective of the camera itself, or should a variety of dog pictures in various environments still be used? My thought process is that if we know enough about the conditions the model will be deployed in it would make more sense to provide training data that reflects this real world usage, but pretty much all the sources I've found online always say your dataset should be diverse. I'm curious to hear what reddit's thoughts on this approach are, or if there's any research that's been done into this topic that I've missed.","link":"https://www.reddit.com/r/MachineLearning/comments/11mvjtu/d_is_a_diverse_dataset_necessary_for_accuracy_if/","created":"2023-03-09","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":3},"text":"[D] Is a diverse dataset necessary for accuracy if the conditions in which inference will be used are narrow? Let's say hypothetically that I want to train an object detection model to recognize dogs in the video output of my home security camera. I know for a fact that I will only use my model on this one camera and that the position and rotation of my camera will never change. Normally when building a dataset, especially for computer vision models, you want to include diverse data to ensure that objects can be detected regardless of their surroundings. However in this case one can make the assumption that the surroundings will largely be static other than some minor variations. For this example does it make more sense to train a model on images collected from the perspective of the camera itself, or should a variety of dog pictures in various environments still be used? My thought process is that if we know enough about the conditions the model will be deployed in it would make more sense to provide training data that reflects this real world usage, but pretty much all the sources I've found online always say your dataset should be diverse. I'm curious to hear what reddit's thoughts on this approach are, or if there's any research that's been done into this topic that I've missed.","classes":{"dataset":0.2228407115}}
{"title":"[D] Text embedding model for financial documents","description":"I'm currently working on a project where I'm analyzing financial documents such as 10Ks and 10Qs. I'm looking for a pretrained text embedding model that has been fine-tuned on such documents to generate accurate embeddings. While there are models like FinBERT that are tuned for sentiment analysis, I'm interested in a model that can generate more accurate embeddings in general, without focusing solely on sentiment.\n\n&amp;#x200B;\n\nThanks!","link":"https://www.reddit.com/r/MachineLearning/comments/11m99js/d_text_embedding_model_for_financial_documents/","created":"2023-03-08","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":10},"text":"[D] Text embedding model for financial documents I'm currently working on a project where I'm analyzing financial documents such as 10Ks and 10Qs. I'm looking for a pretrained text embedding model that has been fine-tuned on such documents to generate accurate embeddings. While there are models like FinBERT that are tuned for sentiment analysis, I'm interested in a model that can generate more accurate embeddings in general, without focusing solely on sentiment.\n\n&amp;#x200B;\n\nThanks!","classes":{"dataset":0.4222877622}}
{"title":"[P] Feste, an open-source framework to optimize and parallelize NLP tasks","description":"Hi, just sharing a new open-source framework called Feste.\n\nDocumentation: https://feste.readthedocs.io\n\nGithub: https://github.com/perone/feste\n\nFeste is a tool for LLMs task composition that does automatic parallelization of backend API calls, tools, and *automatic batching* using graph optimization. Contributions are welcome!","link":"https://www.reddit.com/r/MachineLearning/comments/11m4l8y/p_feste_an_opensource_framework_to_optimize_and/","created":"2023-03-08","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[P] Feste, an open-source framework to optimize and parallelize NLP tasks Hi, just sharing a new open-source framework called Feste.\n\nDocumentation: https://feste.readthedocs.io\n\nGithub: https://github.com/perone/feste\n\nFeste is a tool for LLMs task composition that does automatic parallelization of backend API calls, tools, and *automatic batching* using graph optimization. Contributions are welcome!","classes":{"dataset":0.0580077283}}
{"title":"Training Transformer Networks in Scikit-Learn?!","description":"Have you ever wanted to use handy scikit-learn functionalities with your neural networks, but couldn\u2019t because TensorFlow models are not compatible with the scikit-learn API?\n\nI\u2019m excited to introduce one-line wrappers for TensorFlow/Keras models that enable you to use TensorFlow models within scikit-learn workflows with features like Pipeline, GridSearch, and more.\n\nTransformers are extremely popular for modeling text nowadays with GPT3, ChatGPT, Bard, PaLM, FLAN excelling for conversational AI and other Transformers like T5 &amp; BERT excelling for text classification. Scikit-learn offers a broadly useful suite of features for classifier models, but these are hard to use with Transformers. However not if you use these wrappers we developed, which only require changing one line of code to make your existing Tensorflow/Keras model compatible with scikit-learn\u2019s rich ecosystem!\n\nAll you have to do is swap `keras.Model` \u2192 `KerasWrapperModel`, or `keras.Sequential` \u2192 `KerasSequentialWrapper`. The wrapper objects have all the same methods as their keras counterparts, plus you can use them with tons of awesome scikit-learn methods.\n\nYou can find a demo jupyter notebook and read more about the wrappers here: [https://cleanlab.ai/blog/transformer-sklearn/](https://cleanlab.ai/blog/transformer-sklearn/)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11mzctf/training_transformer_networks_in_scikitlearn/","created":"2023-03-09","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"Training Transformer Networks in Scikit-Learn?! Have you ever wanted to use handy scikit-learn functionalities with your neural networks, but couldn\u2019t because TensorFlow models are not compatible with the scikit-learn API?\n\nI\u2019m excited to introduce one-line wrappers for TensorFlow/Keras models that enable you to use TensorFlow models within scikit-learn workflows with features like Pipeline, GridSearch, and more.\n\nTransformers are extremely popular for modeling text nowadays with GPT3, ChatGPT, Bard, PaLM, FLAN excelling for conversational AI and other Transformers like T5 &amp; BERT excelling for text classification. Scikit-learn offers a broadly useful suite of features for classifier models, but these are hard to use with Transformers. However not if you use these wrappers we developed, which only require changing one line of code to make your existing Tensorflow/Keras model compatible with scikit-learn\u2019s rich ecosystem!\n\nAll you have to do is swap `keras.Model` \u2192 `KerasWrapperModel`, or `keras.Sequential` \u2192 `KerasSequentialWrapper`. The wrapper objects have all the same methods as their keras counterparts, plus you can use them with tons of awesome scikit-learn methods.\n\nYou can find a demo jupyter notebook and read more about the wrappers here: [https://cleanlab.ai/blog/transformer-sklearn/](https://cleanlab.ai/blog/transformer-sklearn/)","classes":{"dataset":0.3891091347}}
{"title":"Computational Linguist looking to expand","description":"Hello,\n\nI\u2019m in between jobs right now and looking to expand my career. I\u2019ve held about 4-5 jobs as a computational linguist. It remains my strong suit but I\u2019m also realizing that there are very few jobs for compling. Last role I interviewed for was for an nlp engineer and I realized I\u2019m falling short for anything after building a prototype. I\u2019m looking to get back into \u201cstudying\u201d and considering MLOps or Data Science or MBA as I have held two roles as a product manager too (of language technologies) so may be time to explore that area too. My preference is definitely engineering over product management but I wanted to hear people\u2019s opinion on what/ how to stay relevant to the language technology domain.\n\nThanks for reading!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11mvjhs/computational_linguist_looking_to_expand/","created":"2023-03-09","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":2},"text":"Computational Linguist looking to expand Hello,\n\nI\u2019m in between jobs right now and looking to expand my career. I\u2019ve held about 4-5 jobs as a computational linguist. It remains my strong suit but I\u2019m also realizing that there are very few jobs for compling. Last role I interviewed for was for an nlp engineer and I realized I\u2019m falling short for anything after building a prototype. I\u2019m looking to get back into \u201cstudying\u201d and considering MLOps or Data Science or MBA as I have held two roles as a product manager too (of language technologies) so may be time to explore that area too. My preference is definitely engineering over product management but I wanted to hear people\u2019s opinion on what/ how to stay relevant to the language technology domain.\n\nThanks for reading!","classes":{"dataset":0.4455197752}}
{"title":"[Beginner] Any tips/resources on where should I start?","description":"I would like to create a simple chatbot where user would ask a school-related question (e.g., when is the enrollment) and the response will be based on the answer column on the dataset.\n\nWhat I had in mind is to use Question Answering but without need to input the context.  The problem is most of the tutorials I found (HuggingFace) uses with the *'with context'* approach and my Dataset consist only question and answer columns.\n\nAny help or tutorials would greatly help.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11mims7/beginner_any_tipsresources_on_where_should_i_start/","created":"2023-03-09","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":2},"text":"[Beginner] Any tips/resources on where should I start? I would like to create a simple chatbot where user would ask a school-related question (e.g., when is the enrollment) and the response will be based on the answer column on the dataset.\n\nWhat I had in mind is to use Question Answering but without need to input the context.  The problem is most of the tutorials I found (HuggingFace) uses with the *'with context'* approach and my Dataset consist only question and answer columns.\n\nAny help or tutorials would greatly help.","classes":{"dataset":0.3856330514}}
{"title":"Encoder-decoder architecture for POS tagging","description":"I understand following about encoder and decoder:\n\n&gt; An encoder is a network that takes the input, and output a feature map/vector/tensor. These feature vector hold the information, the features, that represents the input. The decoder is again a network that takes the feature vector from the encoder, and gives the best closest match to the actual input or intended output.\n\nI want to implement POS tagging with encoder and decoder. I can guess that we can use \"encoder-only\" model to do POS tagging. Can we use \"encoder-decoder\" architecture for POS tagging task? If yes, then how should I design it. Most importantly I am not able to get what input will the decoder get from the encoder.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11m5rzs/encoderdecoder_architecture_for_pos_tagging/","created":"2023-03-08","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":3},"text":"Encoder-decoder architecture for POS tagging I understand following about encoder and decoder:\n\n&gt; An encoder is a network that takes the input, and output a feature map/vector/tensor. These feature vector hold the information, the features, that represents the input. The decoder is again a network that takes the feature vector from the encoder, and gives the best closest match to the actual input or intended output.\n\nI want to implement POS tagging with encoder and decoder. I can guess that we can use \"encoder-only\" model to do POS tagging. Can we use \"encoder-decoder\" architecture for POS tagging task? If yes, then how should I design it. Most importantly I am not able to get what input will the decoder get from the encoder.","classes":{"dataset":0.5232480764}}
{"title":"How to get a Phd in NLP for protein/gene design ?","description":"I have a background in Biotechnology and am currently doing a MS in Bioinformatics. My research consists on natural language models like BERT and protein design I'm also working on data/text mining projects with Biomedical data.  I want to do a PHD  with a focus on NLP but I'm worried if I have enough knowhow to apply for them. Any suggestions how I should approach this?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11m5je0/how_to_get_a_phd_in_nlp_for_proteingene_design/","created":"2023-03-08","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":1},"text":"How to get a Phd in NLP for protein/gene design ? I have a background in Biotechnology and am currently doing a MS in Bioinformatics. My research consists on natural language models like BERT and protein design I'm also working on data/text mining projects with Biomedical data.  I want to do a PHD  with a focus on NLP but I'm worried if I have enough knowhow to apply for them. Any suggestions how I should approach this?","classes":{"dataset":0.1928882301}}
{"title":"Worth learning Python just for NLP if I have good grasp of R?","description":"Wanted to survey what people thought. I have a good amount of experience and feel comfortable with R having used it on various data analytic projects. \n\nApproaching my first NLP project. Do you all feel it is worth learning Python to do this specifically? I know there may be general arguments for learning Python (flexibility, etc.) but was wondering how different it is for NLP application.\n\nThanks!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11l6zu1/worth_learning_python_just_for_nlp_if_i_have_good/","created":"2023-03-07","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":13},"text":"Worth learning Python just for NLP if I have good grasp of R? Wanted to survey what people thought. I have a good amount of experience and feel comfortable with R having used it on various data analytic projects. \n\nApproaching my first NLP project. Do you all feel it is worth learning Python to do this specifically? I know there may be general arguments for learning Python (flexibility, etc.) but was wondering how different it is for NLP application.\n\nThanks!","classes":{"dataset":0.2535924315}}
{"title":"[HELP]","description":" I'm trying to build a pos tagger model for my native language and I found out that I need an annotated corpus for my model. my question is should I label each word with its POS as two columns one for the word and the second for the tag or what should I do?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11lgqzf/help/","created":"2023-03-08","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"[HELP]  I'm trying to build a pos tagger model for my native language and I found out that I need an annotated corpus for my model. my question is should I label each word with its POS as two columns one for the word and the second for the tag or what should I do?","classes":{"dataset":0.0004352964}}
{"title":"We tracked mentions of OpenAI, Bing, and Bard across social media to find out who's the most talked about in Silicon Valley","description":"Have you been following the news on the conversational AI race? We used social media data and [geolocation models](https://github.com/1712n/yachay-public/tree/master/conf_geotagging_model) to find posts about OpenAI, Bing, and Bard in the Silicon Valley and San Francisco Bay Area for the last two weeks to see which one received the most mentions.\n\nFirst, we filtered social media data with the keywords \"openai,\" \"bing,\" \"bard,\" and then we predicted coordinates for the social media posts by using our text-based geolocation models. After selecting texts which received a confidence score higher than 0.8, we plotted their coordinates as company logos on a leaflet [map](https://1712n.github.io/yachay-public/maps/chatbots/) using Python and the folium library, restricting the map to the bounding box of the San Francisco Bay Area and Silicon Valley.\n\nWe analyzed over 300 social media posts and found that roughly 54.5% of the time, OpenAI was the most talked about. Bing made second place with around 27.2%, and then Bard came in last with 18.3%.\n\nOpenAI may be winning the AI race at the moment, but it's not the end yet. Let us know what other AI projects you're following, and we'll check them out.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11l3k5x/we_tracked_mentions_of_openai_bing_and_bard/","created":"2023-03-07","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"We tracked mentions of OpenAI, Bing, and Bard across social media to find out who's the most talked about in Silicon Valley Have you been following the news on the conversational AI race? We used social media data and [geolocation models](https://github.com/1712n/yachay-public/tree/master/conf_geotagging_model) to find posts about OpenAI, Bing, and Bard in the Silicon Valley and San Francisco Bay Area for the last two weeks to see which one received the most mentions.\n\nFirst, we filtered social media data with the keywords \"openai,\" \"bing,\" \"bard,\" and then we predicted coordinates for the social media posts by using our text-based geolocation models. After selecting texts which received a confidence score higher than 0.8, we plotted their coordinates as company logos on a leaflet [map](https://1712n.github.io/yachay-public/maps/chatbots/) using Python and the folium library, restricting the map to the bounding box of the San Francisco Bay Area and Silicon Valley.\n\nWe analyzed over 300 social media posts and found that roughly 54.5% of the time, OpenAI was the most talked about. Bing made second place with around 27.2%, and then Bard came in last with 18.3%.\n\nOpenAI may be winning the AI race at the moment, but it's not the end yet. Let us know what other AI projects you're following, and we'll check them out.","classes":{"dataset":0.4138837755}}
{"title":"SETI@home is in hibernation","description":"https://setiathome.berkeley.edu/","link":"https://setiathome.berkeley.edu/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":342},"text":"SETI@home is in hibernation https://setiathome.berkeley.edu/","classes":{"dataset":0.5185834765}}
{"title":"How to own your own Docker Registry address","description":"https://httptoolkit.com/blog/docker-image-registry-facade/","link":"https://httptoolkit.com/blog/docker-image-registry-facade/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":115},"text":"How to own your own Docker Registry address https://httptoolkit.com/blog/docker-image-registry-facade/","classes":{"dataset":0.4907138348}}
{"title":"Clothing designed to confuse facial recognition software","description":"https://www.capable.design","link":"https://www.capable.design","created":"2023-03-18","tags":["hackernews"],"meta":{"score":47},"text":"Clothing designed to confuse facial recognition software https://www.capable.design","classes":{"dataset":0.5363419652}}
{"title":"The Prospective Student\u2019s Guide to Medieval Universities","description":"https://www.laphamsquarterly.org/education/charts-graphs/prospective-students-guide-medieval-universities","link":"https://www.laphamsquarterly.org/education/charts-graphs/prospective-students-guide-medieval-universities","created":"2023-03-16","tags":["hackernews"],"meta":{"score":64},"text":"The Prospective Student\u2019s Guide to Medieval Universities https://www.laphamsquarterly.org/education/charts-graphs/prospective-students-guide-medieval-universities","classes":{"dataset":0.5085780025}}
{"title":"Genode's Browser Odyssey (2022)","description":"https://genodians.org/nfeske/2022-01-27-browser-odyssey","link":"https://genodians.org/nfeske/2022-01-27-browser-odyssey","created":"2023-03-18","tags":["hackernews"],"meta":{"score":16},"text":"Genode's Browser Odyssey (2022) https://genodians.org/nfeske/2022-01-27-browser-odyssey","classes":{"dataset":0.4751027524}}
{"title":"PostgreSQL Logical Replication Explained","description":"https://www.postgresql.fastware.com/blog/inside-logical-replication-in-postgresql","link":"https://www.postgresql.fastware.com/blog/inside-logical-replication-in-postgresql","created":"2023-03-17","tags":["hackernews"],"meta":{"score":85},"text":"PostgreSQL Logical Replication Explained https://www.postgresql.fastware.com/blog/inside-logical-replication-in-postgresql","classes":{"dataset":0.4778857231}}
{"title":"Tungsten for radiation shielding use","description":"https://blog.prusa3d.com/were-launching-a-brand-new-prusament-petg-tungsten-75-for-radiation-shielding-use_75919/","link":"https://blog.prusa3d.com/were-launching-a-brand-new-prusament-petg-tungsten-75-for-radiation-shielding-use_75919/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":40},"text":"Tungsten for radiation shielding use https://blog.prusa3d.com/were-launching-a-brand-new-prusament-petg-tungsten-75-for-radiation-shielding-use_75919/","classes":{"dataset":0.5061998367}}
{"title":"This week in KDE: \u201cMore Wayland fixes\u201d","description":"https://pointieststick.com/2023/03/17/this-week-in-kde-more-wayland-fixes/","link":"https://pointieststick.com/2023/03/17/this-week-in-kde-more-wayland-fixes/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":7},"text":"This week in KDE: \u201cMore Wayland fixes\u201d https://pointieststick.com/2023/03/17/this-week-in-kde-more-wayland-fixes/","classes":{"dataset":0.55778265}}
{"title":"ViperGPT: Visual Inference via Python Execution for Reasoning","description":"https://viper.cs.columbia.edu/","link":"https://viper.cs.columbia.edu/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":488},"text":"ViperGPT: Visual Inference via Python Execution for Reasoning https://viper.cs.columbia.edu/","classes":{"dataset":0.4899078608}}
{"title":"Study tracks how we decide which groups to join","description":"https://www.ox.ac.uk/news/2016-03-23-study-tracks-how-we-decide-which-groups-join","link":"https://www.ox.ac.uk/news/2016-03-23-study-tracks-how-we-decide-which-groups-join","created":"2023-03-18","tags":["hackernews"],"meta":{"score":17},"text":"Study tracks how we decide which groups to join https://www.ox.ac.uk/news/2016-03-23-study-tracks-how-we-decide-which-groups-join","classes":{"dataset":0.5525542498}}
{"title":"DIY Nitrogen TEA Laser","description":"https://physicsopenlab.org/2020/07/16/diy-nitrogen-tea-laser/","link":"https://physicsopenlab.org/2020/07/16/diy-nitrogen-tea-laser/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":97},"text":"DIY Nitrogen TEA Laser https://physicsopenlab.org/2020/07/16/diy-nitrogen-tea-laser/","classes":{"dataset":0.4795060754}}
{"title":"The magic of traveling alone","description":"https://yuvalaizenman.com/the-magic-of-traveling-alone","link":"https://yuvalaizenman.com/the-magic-of-traveling-alone","created":"2023-03-16","tags":["hackernews"],"meta":{"score":33},"text":"The magic of traveling alone https://yuvalaizenman.com/the-magic-of-traveling-alone","classes":{"dataset":0.4861973524}}
{"title":"Restrict CI runners to valid freedesktop projects only","description":"https://gitlab.freedesktop.org/freedesktop/freedesktop/-/issues/540","link":"https://gitlab.freedesktop.org/freedesktop/freedesktop/-/issues/540","created":"2023-03-18","tags":["hackernews"],"meta":{"score":3},"text":"Restrict CI runners to valid freedesktop projects only https://gitlab.freedesktop.org/freedesktop/freedesktop/-/issues/540","classes":{"dataset":0.513130784}}
{"title":"A growing number of scientists are convinced the future influences the past","description":"https://www.vice.com/en/article/epvgjm/a-growing-number-of-scientists-are-convinced-the-future-influences-the-past","link":"https://www.vice.com/en/article/epvgjm/a-growing-number-of-scientists-are-convinced-the-future-influences-the-past","created":"2023-03-17","tags":["hackernews"],"meta":{"score":284},"text":"A growing number of scientists are convinced the future influences the past https://www.vice.com/en/article/epvgjm/a-growing-number-of-scientists-are-convinced-the-future-influences-the-past","classes":{"dataset":0.4923241138}}
{"title":"Prometheus (YC W19) Is Hiring","description":"https://www.ycombinator.com/companies/prometheus/jobs/34u2Lo8-research-engineer-electrochemistry","link":"https://www.ycombinator.com/companies/prometheus/jobs/34u2Lo8-research-engineer-electrochemistry","created":"2023-03-17","tags":["hackernews"],"meta":{"score":1},"text":"Prometheus (YC W19) Is Hiring https://www.ycombinator.com/companies/prometheus/jobs/34u2Lo8-research-engineer-electrochemistry","classes":{"dataset":0.4500872791}}
{"title":"PHP 8.2.4 Released","description":"https://www.php.net/index.php","link":"https://www.php.net/index.php","created":"2023-03-18","tags":["hackernews"],"meta":{"score":13},"text":"PHP 8.2.4 Released https://www.php.net/index.php","classes":{"dataset":0.5166060925}}
{"title":"YouTube millionaires are not your friends","description":"https://www.vox.com/culture/23640192/sebastian-ghiorghiu-youtube-hustle-gurus-passive-income-dropshipping","link":"https://www.vox.com/culture/23640192/sebastian-ghiorghiu-youtube-hustle-gurus-passive-income-dropshipping","created":"2023-03-18","tags":["hackernews"],"meta":{"score":116},"text":"YouTube millionaires are not your friends https://www.vox.com/culture/23640192/sebastian-ghiorghiu-youtube-hustle-gurus-passive-income-dropshipping","classes":{"dataset":0.4775285721}}
{"title":"Testing GPT 4's code-writing capabilities with some real world problems","description":"https://tylerglaiel.substack.com/p/can-gpt-4-actually-write-code","link":"https://tylerglaiel.substack.com/p/can-gpt-4-actually-write-code","created":"2023-03-17","tags":["hackernews"],"meta":{"score":516},"text":"Testing GPT 4's code-writing capabilities with some real world problems https://tylerglaiel.substack.com/p/can-gpt-4-actually-write-code","classes":{"dataset":0.5904939771}}
{"title":"Analysis of 7.5T DNS Queries Reveals Public Resolvers Dominate","description":"https://circleid.com/posts/20230316-analysis-of-7.5-trillion-dns-queries-reveals-public-resolvers-dominate-the-internet","link":"https://circleid.com/posts/20230316-analysis-of-7.5-trillion-dns-queries-reveals-public-resolvers-dominate-the-internet","created":"2023-03-18","tags":["hackernews"],"meta":{"score":3},"text":"Analysis of 7.5T DNS Queries Reveals Public Resolvers Dominate https://circleid.com/posts/20230316-analysis-of-7.5-trillion-dns-queries-reveals-public-resolvers-dominate-the-internet","classes":{"dataset":0.5435265303}}
{"title":"Give babies peanut butter to cut peanut allergies, study says","description":"https://www.bbc.com/news/health-64987074","link":"https://www.bbc.com/news/health-64987074","created":"2023-03-17","tags":["hackernews"],"meta":{"score":686},"text":"Give babies peanut butter to cut peanut allergies, study says https://www.bbc.com/news/health-64987074","classes":{"dataset":0.5044917464}}
{"title":"Something Pretty Right: The History and Legacy of Visual Basic","description":"https://retool.com/visual-basic/","link":"https://retool.com/visual-basic/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":412},"text":"Something Pretty Right: The History and Legacy of Visual Basic https://retool.com/visual-basic/","classes":{"dataset":0.5100162029}}
{"title":"Unpredictable abilities emerging from large AI models","description":"https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/","link":"https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":219},"text":"Unpredictable abilities emerging from large AI models https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/","classes":{"dataset":0.5485901833}}
{"title":"Minimum Viable Finance: The Guide for Seed/Series A Startups","description":"https://www.causal.app/blog/the-ultimate-guide-to-finance-for-seed-series-a-companies","link":"https://www.causal.app/blog/the-ultimate-guide-to-finance-for-seed-series-a-companies","created":"2023-03-17","tags":["hackernews"],"meta":{"score":108},"text":"Minimum Viable Finance: The Guide for Seed/Series A Startups https://www.causal.app/blog/the-ultimate-guide-to-finance-for-seed-series-a-companies","classes":{"dataset":0.475677073}}
{"title":"Copyright Registration Guidance: Works containing material generated by AI","description":"https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-containing-material-generated-by-artificial-intelligence","link":"https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-containing-material-generated-by-artificial-intelligence","created":"2023-03-17","tags":["hackernews"],"meta":{"score":390},"text":"Copyright Registration Guidance: Works containing material generated by AI https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-containing-material-generated-by-artificial-intelligence","classes":{"dataset":0.5288347602}}
{"title":"Godot Arrives in the Epic Games Store","description":"https://godotengine.org/article/godot-arrives-in-the-epic-games-store/","link":"https://godotengine.org/article/godot-arrives-in-the-epic-games-store/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":166},"text":"Godot Arrives in the Epic Games Store https://godotengine.org/article/godot-arrives-in-the-epic-games-store/","classes":{"dataset":0.5351281166}}
{"title":"Linux Intel WiFi driver broken with 5&6GHz bands for longer than three years","description":"https://bugzilla.kernel.org/show_bug.cgi?id=206469","link":"https://bugzilla.kernel.org/show_bug.cgi?id=206469","created":"2023-03-17","tags":["hackernews"],"meta":{"score":199},"text":"Linux Intel WiFi driver broken with 5&6GHz bands for longer than three years https://bugzilla.kernel.org/show_bug.cgi?id=206469","classes":{"dataset":0.4856640995}}
{"title":"TextSynth Server","description":"https://bellard.org/ts_server/","link":"https://bellard.org/ts_server/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":258},"text":"TextSynth Server https://bellard.org/ts_server/","classes":{"dataset":0.5194280744}}
{"title":"Google Summer of Code 2023","description":"https://summerofcode.withgoogle.com/programs/2023/organizations","link":"https://summerofcode.withgoogle.com/programs/2023/organizations","created":"2023-03-17","tags":["hackernews"],"meta":{"score":248},"text":"Google Summer of Code 2023 https://summerofcode.withgoogle.com/programs/2023/organizations","classes":{"dataset":0.5995949507}}
{"title":"The Role of AI in Accelerating Skill Development","description":"https://saulcosta.com/the-role-of-ai-in-accelerating-skill-development-a4831311f0db","link":"https://saulcosta.com/the-role-of-ai-in-accelerating-skill-development-a4831311f0db","created":"2023-03-17","tags":["hackernews"],"meta":{"score":73},"text":"The Role of AI in Accelerating Skill Development https://saulcosta.com/the-role-of-ai-in-accelerating-skill-development-a4831311f0db","classes":{"dataset":0.5260590315}}
{"title":"'The People's Hospital' treats uninsured and undocumented","description":"https://www.npr.org/sections/health-shots/2023/03/15/1162588784/the-peoples-hospital-ricardo-nuila-treats-mostly-uninsured-undocumented","link":"https://www.npr.org/sections/health-shots/2023/03/15/1162588784/the-peoples-hospital-ricardo-nuila-treats-mostly-uninsured-undocumented","created":"2023-03-16","tags":["hackernews"],"meta":{"score":148},"text":"'The People's Hospital' treats uninsured and undocumented https://www.npr.org/sections/health-shots/2023/03/15/1162588784/the-peoples-hospital-ricardo-nuila-treats-mostly-uninsured-undocumented","classes":{"dataset":0.4782227874}}
{"title":"Google says hackers could silently own your phone until Samsung fixes its modems","description":"https://www.theverge.com/2023/3/16/23644013/samsung-exynos-modem-security-issue-project-zero","link":"https://www.theverge.com/2023/3/16/23644013/samsung-exynos-modem-security-issue-project-zero","created":"2023-03-17","tags":["hackernews"],"meta":{"score":171},"text":"Google says hackers could silently own your phone until Samsung fixes its modems https://www.theverge.com/2023/3/16/23644013/samsung-exynos-modem-security-issue-project-zero","classes":{"dataset":0.5271131396}}
{"title":"Transformers.js","description":"https://xenova.github.io/transformers.js/","link":"https://xenova.github.io/transformers.js/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":366},"text":"Transformers.js https://xenova.github.io/transformers.js/","classes":{"dataset":0.5278296471}}
{"title":"At least 67 people got botulism after trying to paralyze their stomachs","description":"https://arstechnica.com/science/2023/03/at-least-67-people-got-botulism-after-trying-to-paralyze-their-stomachs/","link":"https://arstechnica.com/science/2023/03/at-least-67-people-got-botulism-after-trying-to-paralyze-their-stomachs/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":6},"text":"At least 67 people got botulism after trying to paralyze their stomachs https://arstechnica.com/science/2023/03/at-least-67-people-got-botulism-after-trying-to-paralyze-their-stomachs/","classes":{"dataset":0.4877236187}}
{"title":"Show HN: Learn Python with Minecraft","description":"https://github.com/gilesknap/mciwb","link":"https://github.com/gilesknap/mciwb","created":"2023-03-15","tags":["hackernews"],"meta":{"score":163},"text":"Show HN: Learn Python with Minecraft https://github.com/gilesknap/mciwb","classes":{"dataset":0.532502532}}
{"title":"Prefer views::meow","description":"https://brevzin.github.io/c++/2023/03/14/prefer-views-meow/","link":"https://brevzin.github.io/c++/2023/03/14/prefer-views-meow/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":11},"text":"Prefer views::meow https://brevzin.github.io/c++/2023/03/14/prefer-views-meow/","classes":{"dataset":0.5316672325}}
{"title":"Spelunking Apple\u2019s Open Source","description":"https://bitsplitting.org/2023/03/17/spelunking-apples-open-source/","link":"https://bitsplitting.org/2023/03/17/spelunking-apples-open-source/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":135},"text":"Spelunking Apple\u2019s Open Source https://bitsplitting.org/2023/03/17/spelunking-apples-open-source/","classes":{"dataset":0.5339092612}}
{"title":"Deep Dive into ZGC: A Modern Garbage Collector in OpenJDK (2022) [pdf]","description":"https://dl.acm.org/doi/pdf/10.1145/3538532","link":"https://dl.acm.org/doi/pdf/10.1145/3538532","created":"2023-03-17","tags":["hackernews"],"meta":{"score":29},"text":"Deep Dive into ZGC: A Modern Garbage Collector in OpenJDK (2022) [pdf] https://dl.acm.org/doi/pdf/10.1145/3538532","classes":{"dataset":0.5195493102}}
{"title":"Web Stable Diffusion","description":"https://github.com/mlc-ai/web-stable-diffusion","link":"https://github.com/mlc-ai/web-stable-diffusion","created":"2023-03-17","tags":["hackernews"],"meta":{"score":244},"text":"Web Stable Diffusion https://github.com/mlc-ai/web-stable-diffusion","classes":{"dataset":0.507349968}}
{"title":"Oil 0.14.2 \u2013 Interactive Shell, and Conceding to autoconf","description":"http://www.oilshell.org/blog/2023/03/release-0.14.2.html","link":"http://www.oilshell.org/blog/2023/03/release-0.14.2.html","created":"2023-03-17","tags":["hackernews"],"meta":{"score":39},"text":"Oil 0.14.2 \u2013 Interactive Shell, and Conceding to autoconf http://www.oilshell.org/blog/2023/03/release-0.14.2.html","classes":{"dataset":0.4981983602}}
{"title":"The LLM Problem","description":"https://www.tbray.org/ongoing/When/202x/2023/03/14/Binging","link":"https://www.tbray.org/ongoing/When/202x/2023/03/14/Binging","created":"2023-03-17","tags":["hackernews"],"meta":{"score":61},"text":"The LLM Problem https://www.tbray.org/ongoing/When/202x/2023/03/14/Binging","classes":{"dataset":0.5508750677}}
{"title":"TSA confirms plans to mandate mug shots for domestic air travel","description":"https://papersplease.org/wp/2023/03/15/tsa-confirms-plans-to-mandate-mug-shots-for-domestic-air-travel/","link":"https://papersplease.org/wp/2023/03/15/tsa-confirms-plans-to-mandate-mug-shots-for-domestic-air-travel/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":36},"text":"TSA confirms plans to mandate mug shots for domestic air travel https://papersplease.org/wp/2023/03/15/tsa-confirms-plans-to-mandate-mug-shots-for-domestic-air-travel/","classes":{"dataset":0.4925608635}}
{"title":"The friendship between Haskell and C","description":"https://typeclasses.substack.com/p/the-friendship-between-haskell-and","link":"https://typeclasses.substack.com/p/the-friendship-between-haskell-and","created":"2023-03-17","tags":["hackernews"],"meta":{"score":85},"text":"The friendship between Haskell and C https://typeclasses.substack.com/p/the-friendship-between-haskell-and","classes":{"dataset":0.4588220119}}
{"title":"Low-cost open source device can measure air pollution anywhere","description":"https://news.mit.edu/2023/low-cost-device-can-measure-air-pollution-anywhere-0316","link":"https://news.mit.edu/2023/low-cost-device-can-measure-air-pollution-anywhere-0316","created":"2023-03-16","tags":["hackernews"],"meta":{"score":214},"text":"Low-cost open source device can measure air pollution anywhere https://news.mit.edu/2023/low-cost-device-can-measure-air-pollution-anywhere-0316","classes":{"dataset":0.5418870449}}
{"title":"Google Apollo: The >$3B Game-Changer in Datacenter Networking","description":"https://www.semianalysis.com/p/google-apollo-the-3-billion-game","link":"https://www.semianalysis.com/p/google-apollo-the-3-billion-game","created":"2023-03-17","tags":["hackernews"],"meta":{"score":31},"text":"Google Apollo: The >$3B Game-Changer in Datacenter Networking https://www.semianalysis.com/p/google-apollo-the-3-billion-game","classes":{"dataset":0.4718629718}}
{"title":"GPT-4 System Card [pdf]","description":"https://cdn.openai.com/papers/gpt-4-system-card.pdf","link":"https://cdn.openai.com/papers/gpt-4-system-card.pdf","created":"2023-03-17","tags":["hackernews"],"meta":{"score":263},"text":"GPT-4 System Card [pdf] https://cdn.openai.com/papers/gpt-4-system-card.pdf","classes":{"dataset":0.5068115592}}
{"title":"Hypothalamic Menin regulates systemic aging and cognitive decline","description":"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002033","link":"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002033","created":"2023-03-17","tags":["hackernews"],"meta":{"score":54},"text":"Hypothalamic Menin regulates systemic aging and cognitive decline https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002033","classes":{"dataset":0.5041183233}}
{"title":"Anyone else witnessing a panic inside NLP orgs of big tech companies?","description":"https://old.reddit.com/r/MachineLearning/comments/11rizyb/d_anyone_else_witnessing_a_panic_inside_nlp_orgs/","link":"https://old.reddit.com/r/MachineLearning/comments/11rizyb/d_anyone_else_witnessing_a_panic_inside_nlp_orgs/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":381},"text":"Anyone else witnessing a panic inside NLP orgs of big tech companies? https://old.reddit.com/r/MachineLearning/comments/11rizyb/d_anyone_else_witnessing_a_panic_inside_nlp_orgs/","classes":{"dataset":0.5230807066}}
{"title":"[GPT-4 POWERED] We\u2019ve created a mobile IOS AI app that generates text, art, analyzes photos, and more!","description":"\nWe\u2019ve created a mobile IOS AI app that generates text, art, analyzes photos, and more!\n\nI'm the cofounder of a tech startup focused on providing free AI services, we're one of the first mobile all-in-one multipurpose AI apps.\n\nWe've developed a pretty cool app that offers AI services like image generation, code generation, text generation, story generation, image captioning, and more for free. We're the Swiss Army knife of generative and analytical AI.\n\nRecently, we\u2019ve  released a new update called \"ECF texting experience\" that allows users to literally text the AI, and receive generated content based on what you text. The ECF texting experience can be accessed by going to the generate tab. Our analytical services can be accessed by going to the analyze screen.\n\nWe'd love to have people try the app out, right now we have around 2,000 downloads and we'd like to expand our user base, get feedback, and keep in touch with all of you. We are INCREDIBLY responsive to user feedback at this stage, so recommend to us anything you'd like to see in the future.\n\nhttps://apps.apple.com/us/app/bright-eye/id1593932475","link":"https://www.reddit.com/r/PromptDesign/comments/11t79q1/gpt4_powered_weve_created_a_mobile_ios_ai_app/","created":"2023-03-16","tags":["reddit","promptdesign","prompteng"],"meta":{"num_comments":2},"text":"[GPT-4 POWERED] We\u2019ve created a mobile IOS AI app that generates text, art, analyzes photos, and more! \nWe\u2019ve created a mobile IOS AI app that generates text, art, analyzes photos, and more!\n\nI'm the cofounder of a tech startup focused on providing free AI services, we're one of the first mobile all-in-one multipurpose AI apps.\n\nWe've developed a pretty cool app that offers AI services like image generation, code generation, text generation, story generation, image captioning, and more for free. We're the Swiss Army knife of generative and analytical AI.\n\nRecently, we\u2019ve  released a new update called \"ECF texting experience\" that allows users to literally text the AI, and receive generated content based on what you text. The ECF texting experience can be accessed by going to the generate tab. Our analytical services can be accessed by going to the analyze screen.\n\nWe'd love to have people try the app out, right now we have around 2,000 downloads and we'd like to expand our user base, get feedback, and keep in touch with all of you. We are INCREDIBLY responsive to user feedback at this stage, so recommend to us anything you'd like to see in the future.\n\nhttps://apps.apple.com/us/app/bright-eye/id1593932475","classes":{"dataset":0.514814198}}
{"title":"Why use classes?","description":"*I originally wrote this piece as an answer to a question on the* [*learnpython reddit*](https://www.reddit.com/r/learnpython/comments/11sebbg/been_using_python_for_3_years_never_used_a_class/?utm_source=share&amp;utm_medium=web2x&amp;context=3)*, and it was suggested that it would be a useful learning resource for many people who struggle with* ***why*** *we use classes rather than just variables and functions.  So here it is:*\n\n# Why use classes?\n\n**My \"Ah ha!\" moment for understanding classes was understanding that a** ***class*** **creates** ***objects*** **and defines the** ***type*** **of** ***object.***\n\nTime for an example:\n\nSay that we're writing a game, and we need to define certain things about the player:\n\n    player_name = \"James\"\n    player_level = \"novice\"\n\nWe also need to keep track of the player's score:\n\n    player_score = 0\n\nWe may also need to save each of the player's moves:\n\n    player_moves = [move1, move2, move3]\n\nand now we need to be able to increase the player's score when they win some points, and to add their last move to their list of moves. We can do this with a function:\n\n    def win_points (points, move):\n        player_score += points\n        player_moves.append(move)\n\n&amp;#x200B;\n\nThat's all fine so far. We have some global variables to hold the player's data, and a function to handle the results of a win, and all without writing any classes.\n\nNow say that we need to add another player. We will need to repeat all of the above but with unique identities so that we can distinguish player\\_1 from player\\_2:\n\n    player1_name = \"&lt;name&gt;\"\n    player1_level = \"novice\"\n    player1_score = 0\n    player1_moves = [move1, move2, move3]\n    \n    player2_name = \"&lt;name&gt;\"\n    player2_level = \"novice\"\n    player2_score = 0\n    player2_moves = [move1, move2, move3]\n    \n    def win_points (player_name, points, move):\n        if player_name == player1_name:\n            player1_score += points\n            player1_moves.append(move)\n        else:\n            player2_score += points\n            playe2_moves.append(move)\n\nStill not too bad, but what if we have 4 players, or 10, or more?\n\nIt would be better if we could make some kind of generic \"player\" data structure that can be reused for as many players as we need. Fortunately we can do that in Python:\n\nWe can write a kind of \"template\" / \"blueprint\" to define all of the attributes of a generic player and define each of the functions that are relevant to a player. This \"template\" is called a \"Class\", and the class's functions are called \"methods\".\n\n    class Player():\n        def __init__(self, name):\n            \"\"\"Initialise the player's attributes.\"\"\"\n            self.name = name\n            self.level = 'novice'\n            self.score = 0\n            self.moves = []\n    \n        def win_points(self, points, move):\n            \"\"\"Update player on winning points.\"\"\"\n            self.score += points\n            self.moves.append(move)\n\nNow we can create as many players (\"player objects\") as we like as *instances* of the *Player class*.\n\nTo create a new player (a \"player object\") we need to supply the Player class with a name for the player (because the initialisation function \\_\\_init\\_\\_() has an argument \"name\" which must be supplied). So we can create multiple *Player* objects like this:\n\n    player1 = Player('James')\n    player2 = Player('Joe')\n    player3 = Player('Fred')\n\nDon't overthink the `self` arguments. The self argument just means \"the specific class object that we are working with\". For example, if we are referring to *player1*, then self means \"the player1 object\".\n\nTo run the `Player.win_points()` method (the `win_points()` function in the class `Player`) for, say player3:\n\n    player3.win_points(4, (0, 1)) # Fred wins 4 points, move is tuple (0, 1)\n\nand we can access Fred's other attributes, such as Fred's player's name, or  last move, from the Player object:\n\n    print(player3.name)  # prints \"Fred\"\n    # Get Fred's last move\n    try:\n        last_move = player3.moves[-1]\n    except IndexError:\n        print('No moves made.')\n\nUsing a Class allows us to create as many \"Player\" type objects as we like, without having to duplicate loads of code.\n\nFinally, if we look at the type of any of the players,  we see that they are instances of the class \"Player\":\n\n    print(type(player1))  # prints \"&lt;class '__main__.Player'&gt;\"\n\nI hope you found this  post useful.","link":"https://www.reddit.com/r/Python/comments/11ts1qq/why_use_classes/","created":"2023-03-17","tags":["python","reddit"],"meta":{"num_comments":95},"text":"Why use classes? *I originally wrote this piece as an answer to a question on the* [*learnpython reddit*](https://www.reddit.com/r/learnpython/comments/11sebbg/been_using_python_for_3_years_never_used_a_class/?utm_source=share&amp;utm_medium=web2x&amp;context=3)*, and it was suggested that it would be a useful learning resource for many people who struggle with* ***why*** *we use classes rather than just variables and functions.  So here it is:*\n\n# Why use classes?\n\n**My \"Ah ha!\" moment for understanding classes was understanding that a** ***class*** **creates** ***objects*** **and defines the** ***type*** **of** ***object.***\n\nTime for an example:\n\nSay that we're writing a game, and we need to define certain things about the player:\n\n    player_name = \"James\"\n    player_level = \"novice\"\n\nWe also need to keep track of the player's score:\n\n    player_score = 0\n\nWe may also need to save each of the player's moves:\n\n    player_moves = [move1, move2, move3]\n\nand now we need to be able to increase the player's score when they win some points, and to add their last move to their list of moves. We can do this with a function:\n\n    def win_points (points, move):\n        player_score += points\n        player_moves.append(move)\n\n&amp;#x200B;\n\nThat's all fine so far. We have some global variables to hold the player's data, and a function to handle the results of a win, and all without writing any classes.\n\nNow say that we need to add another player. We will need to repeat all of the above but with unique identities so that we can distinguish player\\_1 from player\\_2:\n\n    player1_name = \"&lt;name&gt;\"\n    player1_level = \"novice\"\n    player1_score = 0\n    player1_moves = [move1, move2, move3]\n    \n    player2_name = \"&lt;name&gt;\"\n    player2_level = \"novice\"\n    player2_score = 0\n    player2_moves = [move1, move2, move3]\n    \n    def win_points (player_name, points, move):\n        if player_name == player1_name:\n            player1_score += points\n            player1_moves.append(move)\n        else:\n            player2_score += points\n            playe2_moves.append(move)\n\nStill not too bad, but what if we have 4 players, or 10, or more?\n\nIt would be better if we could make some kind of generic \"player\" data structure that can be reused for as many players as we need. Fortunately we can do that in Python:\n\nWe can write a kind of \"template\" / \"blueprint\" to define all of the attributes of a generic player and define each of the functions that are relevant to a player. This \"template\" is called a \"Class\", and the class's functions are called \"methods\".\n\n    class Player():\n        def __init__(self, name):\n            \"\"\"Initialise the player's attributes.\"\"\"\n            self.name = name\n            self.level = 'novice'\n            self.score = 0\n            self.moves = []\n    \n        def win_points(self, points, move):\n            \"\"\"Update player on winning points.\"\"\"\n            self.score += points\n            self.moves.append(move)\n\nNow we can create as many players (\"player objects\") as we like as *instances* of the *Player class*.\n\nTo create a new player (a \"player object\") we need to supply the Player class with a name for the player (because the initialisation function \\_\\_init\\_\\_() has an argument \"name\" which must be supplied). So we can create multiple *Player* objects like this:\n\n    player1 = Player('James')\n    player2 = Player('Joe')\n    player3 = Player('Fred')\n\nDon't overthink the `self` arguments. The self argument just means \"the specific class object that we are working with\". For example, if we are referring to *player1*, then self means \"the player1 object\".\n\nTo run the `Player.win_points()` method (the `win_points()` function in the class `Player`) for, say player3:\n\n    player3.win_points(4, (0, 1)) # Fred wins 4 points, move is tuple (0, 1)\n\nand we can access Fred's other attributes, such as Fred's player's name, or  last move, from the Player object:\n\n    print(player3.name)  # prints \"Fred\"\n    # Get Fred's last move\n    try:\n        last_move = player3.moves[-1]\n    except IndexError:\n        print('No moves made.')\n\nUsing a Class allows us to create as many \"Player\" type objects as we like, without having to duplicate loads of code.\n\nFinally, if we look at the type of any of the players,  we see that they are instances of the class \"Player\":\n\n    print(type(player1))  # prints \"&lt;class '__main__.Player'&gt;\"\n\nI hope you found this  post useful.","classes":{"dataset":0.5435923934}}
{"title":"Personal Project - JDR Tool Introduction","description":"I recently started learning Python, so I tried to write this project as  an exercise. The idea of the concept is derived from the solution to the  difficulties encountered when helping the Ministry of Finance to  develop the system. Share it here.\n\n&amp;#x200B;\n\n![img](k5nt455yggoa1 \"Figure 1. Appearance of JDR tool\n\")\n\n&amp;#x200B;\n\n![gif](ns56h4y0hgoa1 \"Figure 2. Using JDR tools to execute and manage programs\n\")\n\n## Link\n\n* Source code: [https://github.com/Chen-Alfred/JDR](https://github.com/Chen-Alfred/JDR)\n* Execution file: [https://github.com/Chen-Alfred/JDR/tree/main/dist](https://github.com/Chen-Alfred/JDR/tree/main/dist)\n* Documentation (English): [https://hackmd.io/xsLDRVAMTF2gO0YHo3lxYw](https://hackmd.io/xsLDRVAMTF2gO0YHo3lxYw)\n\n## Motivation\n\nJDR (Job Dependency Runner) is a set of small data governance tools developed by this project. In short, it is a set of \"programs used to assist in the execution and management of programs\".\n\nAt work, the action of \"executing a program\" is not particularly difficult in most cases. Usually, you edit the command first, then throw it into the shell, or an interface/platform, and then wait for the result to come out. Will use tools like crontab to pre-schedule.\n\nWith this method, if the scale is only one or two to a dozen programs, there may be no problem, but if there are hundreds or thousands of programs, it will be difficult to manage. The reason lies in the management issues derived from \"quantity\" and \"dependency\"\n\nThese management issues include: \"What is the current state of the program?\", \"What is the sequence of program execution?\", \"If a certain program needs to be re-run, will it affect which downstream related programs?\" When the number of programs is larger, it is less likely to be managed by the engineer's memory. Even if the records are assisted by files, maintenance and searching will take time and cost.\n\nAnd because data analysis has become more and more important in recent years, the data governance issue of \"whether the program is executed correctly and on time\" has also been paid more and more attention. In order to solve these issues, I hope to implement a set of tools in this project, so that some management issues can be automated, dashboarded, and the results are presented in a visual way.\n\nMaybe this project will overlap with some ETL tools (such as: SSIS, Trinity, DataStage, Automation) in function, because ETL tools also have the function of executing and managing programs, but because I haven't found a tool that can meet the needs , so that's another reason why I decided I wanted to develop my own.\n\nI hope that users only need to maintain a work list (Excel format), and then after inputting the list into this tool, a graphical program dependency flow chart can be automatically generated. The graphical program dependency flowchart is a kind of DAG (Directed Acyclic Graph). After having a graph, many issues arise about how to operate it. I try to simplify these operations as much as possible, so that these operations and management behaviors can be easily performed only by making a setting on the graphical interface, pressing a button, and viewing a report.\n\nEveryone is welcome to use this set of tools, but the design of the tools is based on my personal previous development experience and my own imagination, so if someone thinks that it is not easy to use, inconvenient, or not flexible enough, please feel free to feed these questions back to me, so that I can use them as a reference for improvement.","link":"https://www.reddit.com/r/Python/comments/11ui2v4/personal_project_jdr_tool_introduction/","created":"2023-03-18","tags":["python","reddit"],"meta":{"num_comments":1},"text":"Personal Project - JDR Tool Introduction I recently started learning Python, so I tried to write this project as  an exercise. The idea of the concept is derived from the solution to the  difficulties encountered when helping the Ministry of Finance to  develop the system. Share it here.\n\n&amp;#x200B;\n\n![img](k5nt455yggoa1 \"Figure 1. Appearance of JDR tool\n\")\n\n&amp;#x200B;\n\n![gif](ns56h4y0hgoa1 \"Figure 2. Using JDR tools to execute and manage programs\n\")\n\n## Link\n\n* Source code: [https://github.com/Chen-Alfred/JDR](https://github.com/Chen-Alfred/JDR)\n* Execution file: [https://github.com/Chen-Alfred/JDR/tree/main/dist](https://github.com/Chen-Alfred/JDR/tree/main/dist)\n* Documentation (English): [https://hackmd.io/xsLDRVAMTF2gO0YHo3lxYw](https://hackmd.io/xsLDRVAMTF2gO0YHo3lxYw)\n\n## Motivation\n\nJDR (Job Dependency Runner) is a set of small data governance tools developed by this project. In short, it is a set of \"programs used to assist in the execution and management of programs\".\n\nAt work, the action of \"executing a program\" is not particularly difficult in most cases. Usually, you edit the command first, then throw it into the shell, or an interface/platform, and then wait for the result to come out. Will use tools like crontab to pre-schedule.\n\nWith this method, if the scale is only one or two to a dozen programs, there may be no problem, but if there are hundreds or thousands of programs, it will be difficult to manage. The reason lies in the management issues derived from \"quantity\" and \"dependency\"\n\nThese management issues include: \"What is the current state of the program?\", \"What is the sequence of program execution?\", \"If a certain program needs to be re-run, will it affect which downstream related programs?\" When the number of programs is larger, it is less likely to be managed by the engineer's memory. Even if the records are assisted by files, maintenance and searching will take time and cost.\n\nAnd because data analysis has become more and more important in recent years, the data governance issue of \"whether the program is executed correctly and on time\" has also been paid more and more attention. In order to solve these issues, I hope to implement a set of tools in this project, so that some management issues can be automated, dashboarded, and the results are presented in a visual way.\n\nMaybe this project will overlap with some ETL tools (such as: SSIS, Trinity, DataStage, Automation) in function, because ETL tools also have the function of executing and managing programs, but because I haven't found a tool that can meet the needs , so that's another reason why I decided I wanted to develop my own.\n\nI hope that users only need to maintain a work list (Excel format), and then after inputting the list into this tool, a graphical program dependency flow chart can be automatically generated. The graphical program dependency flowchart is a kind of DAG (Directed Acyclic Graph). After having a graph, many issues arise about how to operate it. I try to simplify these operations as much as possible, so that these operations and management behaviors can be easily performed only by making a setting on the graphical interface, pressing a button, and viewing a report.\n\nEveryone is welcome to use this set of tools, but the design of the tools is based on my personal previous development experience and my own imagination, so if someone thinks that it is not easy to use, inconvenient, or not flexible enough, please feel free to feed these questions back to me, so that I can use them as a reference for improvement.","classes":{"dataset":0.4943637252}}
{"title":"ML models for User Recognition using Keystroke Dynamics","description":"The keystroke dynamics that are used in this article\u2019s machine learning models for user recognition are behavioral biometrics. Keystroke dynamics uses the distinctive way that each person types to confirm their identity. This is accomplished by analyzing the **2 keystroke events** on Key-Press and Key-Release \u2014 that make up a keystroke on computer keyboards to extract typing patterns. *The article will examine how these patterns can be applied to create 3 precise machine learning models for user recognition.*\n\n&amp;#x200B;\n\nhttps://preview.redd.it/rv2a4okbmaoa1.png?width=645&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=983865d15bb83d5c94b43a5940617117f972a89d\n\nThe goal of this article will be split in two parts, ***building and training*** 3 Machine Learning models (1. **SVM** 2. **Random** **Forest** 3. **XGBoost**) and ***deploying the model*** in a real live single point API capable of predicting the user based on 5 input parameters: the ML model and 4 keystroke times.\n\n[https://medium.com/@tudorache.a.bogdan/ml-models-for-user-recognition-using-keystroke-dynamics-e0665bc18cad](https://medium.com/@tudorache.a.bogdan/ml-models-for-user-recognition-using-keystroke-dynamics-e0665bc18cad)","link":"https://www.reddit.com/r/Python/comments/11tpor9/ml_models_for_user_recognition_using_keystroke/","created":"2023-03-17","tags":["python","reddit"],"meta":{"num_comments":1},"text":"ML models for User Recognition using Keystroke Dynamics The keystroke dynamics that are used in this article\u2019s machine learning models for user recognition are behavioral biometrics. Keystroke dynamics uses the distinctive way that each person types to confirm their identity. This is accomplished by analyzing the **2 keystroke events** on Key-Press and Key-Release \u2014 that make up a keystroke on computer keyboards to extract typing patterns. *The article will examine how these patterns can be applied to create 3 precise machine learning models for user recognition.*\n\n&amp;#x200B;\n\nhttps://preview.redd.it/rv2a4okbmaoa1.png?width=645&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=983865d15bb83d5c94b43a5940617117f972a89d\n\nThe goal of this article will be split in two parts, ***building and training*** 3 Machine Learning models (1. **SVM** 2. **Random** **Forest** 3. **XGBoost**) and ***deploying the model*** in a real live single point API capable of predicting the user based on 5 input parameters: the ML model and 4 keystroke times.\n\n[https://medium.com/@tudorache.a.bogdan/ml-models-for-user-recognition-using-keystroke-dynamics-e0665bc18cad](https://medium.com/@tudorache.a.bogdan/ml-models-for-user-recognition-using-keystroke-dynamics-e0665bc18cad)","classes":{"dataset":0.2961382568}}
{"title":"Introducing DataFrame QuickView: A Python package for easy DataFrame visualization, co-created with GPT-4! Seeking contributors \ud83d\ude80","description":"Hi, r/python! I'm u/gittb, and I'd like to share a project I've been working on called **DataFrame QuickView**. This package extends pandas DataFrame functionality to easily display and visualize DataFrames in a web-based environment, built using Flask. The catch? It's an experiment in paired programming with GPT-4, and I'm looking for contributors who want to join this exciting project!\n\n\ud83c\udf1f **Quick Overview of DataFrame QuickView:**\n\n* Extend pandas DataFrame with quickview()method\n* Display paginated DataFrame in a web browser\n* Create an interactive dropdown and button combination populated with DataFrame columns\n* Generate histograms based on the selected column when the button is pressed\n\n\ud83c\udfaf **Goal of the project:**\n\nThe primary goal is to expand the project with code written by Language Models (LLMs) like GPT-4. All contributions should be co-written primarily by LLMs to maintain the experimental nature of this project.\n\n\ud83d\udca1 **Potential additional functionality:**\n\n* More visualization types (bar charts, scatter plots, pie charts, etc.)\n* Filtering and sorting capabilities for DataFrames\n* Exporting visualizations as images or other formats\n* Adding support for multiple DataFrames\n\n\ud83d\udd0d **How to get involved:**\n\nIf you're interested in participating, check out the project on [GitHub](https://github.com/gittb/dataframe-quickview) and feel free to submit pull requests or open issues with your ideas. Remember that the code must be co-written primarily by LLMs for contribution acceptance.\n\nThanks for taking the time to read this post, and I'm looking forward to seeing what we can build together with the help of LLMs! Let's push the boundaries of AI-powered coding! \ud83d\ude80\n\nHappy coding! \ud83d\ude04 u/gittb\n\nEdit, forgot to include pypi link\n\n[https://pypi.org/project/dataframe-quickview/](https://pypi.org/project/dataframe-quickview/)\n\n&amp;#x200B;","link":"https://www.reddit.com/r/Python/comments/11uj8hh/introducing_dataframe_quickview_a_python_package/","created":"2023-03-18","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Introducing DataFrame QuickView: A Python package for easy DataFrame visualization, co-created with GPT-4! Seeking contributors \ud83d\ude80 Hi, r/python! I'm u/gittb, and I'd like to share a project I've been working on called **DataFrame QuickView**. This package extends pandas DataFrame functionality to easily display and visualize DataFrames in a web-based environment, built using Flask. The catch? It's an experiment in paired programming with GPT-4, and I'm looking for contributors who want to join this exciting project!\n\n\ud83c\udf1f **Quick Overview of DataFrame QuickView:**\n\n* Extend pandas DataFrame with quickview()method\n* Display paginated DataFrame in a web browser\n* Create an interactive dropdown and button combination populated with DataFrame columns\n* Generate histograms based on the selected column when the button is pressed\n\n\ud83c\udfaf **Goal of the project:**\n\nThe primary goal is to expand the project with code written by Language Models (LLMs) like GPT-4. All contributions should be co-written primarily by LLMs to maintain the experimental nature of this project.\n\n\ud83d\udca1 **Potential additional functionality:**\n\n* More visualization types (bar charts, scatter plots, pie charts, etc.)\n* Filtering and sorting capabilities for DataFrames\n* Exporting visualizations as images or other formats\n* Adding support for multiple DataFrames\n\n\ud83d\udd0d **How to get involved:**\n\nIf you're interested in participating, check out the project on [GitHub](https://github.com/gittb/dataframe-quickview) and feel free to submit pull requests or open issues with your ideas. Remember that the code must be co-written primarily by LLMs for contribution acceptance.\n\nThanks for taking the time to read this post, and I'm looking forward to seeing what we can build together with the help of LLMs! Let's push the boundaries of AI-powered coding! \ud83d\ude80\n\nHappy coding! \ud83d\ude04 u/gittb\n\nEdit, forgot to include pypi link\n\n[https://pypi.org/project/dataframe-quickview/](https://pypi.org/project/dataframe-quickview/)\n\n&amp;#x200B;","classes":{"dataset":0.1898531914}}
{"title":"What are some projects on GitHub you support either through contribution or sponsorship?","description":"Hey all, I'm Chris, the developer community manager at New Relic. I'm trying to learn more about what interests developers in our community, and one thing I'm curious about is how devs choose projects to support on GitHub. What are some examples of projects you either contribute to or sponsor, for whatever reason -- either they improve your QoL as a dev, or they're humanitarian projects for the betterment of humankind. Thanks for your insights!","link":"https://www.reddit.com/r/Python/comments/11u5v9v/what_are_some_projects_on_github_you_support/","created":"2023-03-17","tags":["python","reddit"],"meta":{"num_comments":3},"text":"What are some projects on GitHub you support either through contribution or sponsorship? Hey all, I'm Chris, the developer community manager at New Relic. I'm trying to learn more about what interests developers in our community, and one thing I'm curious about is how devs choose projects to support on GitHub. What are some examples of projects you either contribute to or sponsor, for whatever reason -- either they improve your QoL as a dev, or they're humanitarian projects for the betterment of humankind. Thanks for your insights!","classes":{"dataset":0.5460515618}}
{"title":"QNX Demodisk Utilities","description":"[https://github.com/audiophyl/qnxdemotools](https://github.com/audiophyl/qnxdemotools)\n\nThis is a set of utilities for altering the contents of the QNX Demodisk of the late 90s. This is the first time I've shared a significant personal code base, and I'm pushing through my anxiety about negative feedback. I'm at a point where I'm telling myself \"eff it, all feedback is good feedback if you can use it to grow.\"\n\nThere's a lot more information within the README.md.\n\nI've been working on this on and off for several months, and now have functionality to a point which I like. It's a long shot that anyone would find this set of utilities useful in any way, but it's been quite fun for me to develop, and a wonderful learning experience as well.","link":"https://www.reddit.com/r/Python/comments/11u5zng/qnx_demodisk_utilities/","created":"2023-03-17","tags":["python","reddit"],"meta":{"num_comments":0},"text":"QNX Demodisk Utilities [https://github.com/audiophyl/qnxdemotools](https://github.com/audiophyl/qnxdemotools)\n\nThis is a set of utilities for altering the contents of the QNX Demodisk of the late 90s. This is the first time I've shared a significant personal code base, and I'm pushing through my anxiety about negative feedback. I'm at a point where I'm telling myself \"eff it, all feedback is good feedback if you can use it to grow.\"\n\nThere's a lot more information within the README.md.\n\nI've been working on this on and off for several months, and now have functionality to a point which I like. It's a long shot that anyone would find this set of utilities useful in any way, but it's been quite fun for me to develop, and a wonderful learning experience as well.","classes":{"dataset":0.411955148}}
{"title":"Python 3.11 is much faster , but is it good for competitive programming?","description":"","link":"https://www.reddit.com/r/Python/comments/11ufqkw/python_311_is_much_faster_but_is_it_good_for/","created":"2023-03-18","tags":["python","reddit"],"meta":{"num_comments":5},"text":"Python 3.11 is much faster , but is it good for competitive programming? ","classes":{"dataset":0.3522106707}}
{"title":"I wrote a program that calculates the difference between two files","description":"For some unknown reason, I am unable to use `fc` (file compare) command on Windows, so like a true programmer, instead of spending couple minutes troubleshooting it, I spent hours writing my own version of the program.\n\nYou can check it out at: [https://github.com/Ach113/dif](https://github.com/Ach113/dif)\n\nAny feedback would be appreciated.","link":"https://www.reddit.com/r/Python/comments/11twxa5/i_wrote_a_program_that_calculates_the_difference/","created":"2023-03-17","tags":["python","reddit"],"meta":{"num_comments":3},"text":"I wrote a program that calculates the difference between two files For some unknown reason, I am unable to use `fc` (file compare) command on Windows, so like a true programmer, instead of spending couple minutes troubleshooting it, I spent hours writing my own version of the program.\n\nYou can check it out at: [https://github.com/Ach113/dif](https://github.com/Ach113/dif)\n\nAny feedback would be appreciated.","classes":{"dataset":0.3626125753}}
{"title":"Speed | When has it been an issue for you?","description":"Everyone is always raving about how python is slow, but I have a feeling that as hardware gets better, this will mean less over time.\n\nDoes anyone have an example of when speed made you choose a different language?","link":"https://www.reddit.com/r/Python/comments/11u0gp7/speed_when_has_it_been_an_issue_for_you/","created":"2023-03-17","tags":["python","reddit"],"meta":{"num_comments":13},"text":"Speed | When has it been an issue for you? Everyone is always raving about how python is slow, but I have a feeling that as hardware gets better, this will mean less over time.\n\nDoes anyone have an example of when speed made you choose a different language?","classes":{"dataset":0.1892356128}}
{"title":"Another episode of the office-racer (Python, websockets,...)","description":"I'm streaming at arconsis today.  \nIt is about a little RC Car for our office.  \n\\- Websockets  \n\\- Python  \n\\- PiCamera  \n[https://www.twitch.tv/arconsis](https://www.twitch.tv/arconsis)  \n\n\nJoin us if you are interested in WebSockets and IoT.","link":"https://www.reddit.com/r/Python/comments/11tt2gm/another_episode_of_the_officeracer_python/","created":"2023-03-17","tags":["python","reddit"],"meta":{"num_comments":3},"text":"Another episode of the office-racer (Python, websockets,...) I'm streaming at arconsis today.  \nIt is about a little RC Car for our office.  \n\\- Websockets  \n\\- Python  \n\\- PiCamera  \n[https://www.twitch.tv/arconsis](https://www.twitch.tv/arconsis)  \n\n\nJoin us if you are interested in WebSockets and IoT.","classes":{"dataset":0.2679243982}}
{"title":"Dad Joke Collector for my Blog","description":"Wrote a dad joke collector for my personal website. It runs on a cron and stores any jokes that have not already been stored into my dadabase based on the creation time of the posts I bookmark/save.  \n   \n[https://krowvin.com/dadjokes](https://krowvin.com/dadjokes)\n\n&amp;#x200B;\n\n[dbapi is a class I wrote using SQLAlchemy to do various things with my homelab database. ](https://preview.redd.it/620fy2g7s7oa1.png?width=793&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=97f2bed3a24f06c71000fe24bc02568ff341e88e)","link":"https://www.reddit.com/r/Python/comments/11tf5xk/dad_joke_collector_for_my_blog/","created":"2023-03-17","tags":["python","reddit"],"meta":{"num_comments":6},"text":"Dad Joke Collector for my Blog Wrote a dad joke collector for my personal website. It runs on a cron and stores any jokes that have not already been stored into my dadabase based on the creation time of the posts I bookmark/save.  \n   \n[https://krowvin.com/dadjokes](https://krowvin.com/dadjokes)\n\n&amp;#x200B;\n\n[dbapi is a class I wrote using SQLAlchemy to do various things with my homelab database. ](https://preview.redd.it/620fy2g7s7oa1.png?width=793&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=97f2bed3a24f06c71000fe24bc02568ff341e88e)","classes":{"dataset":0.3670074344}}
{"title":"Question on Attention","description":"Hello Everyone!\n\nI have a question about scoring in attention. In attention, you find the dot product between the query and the keys. From my understanding, the intuition is that we can use the inner product as the a mechanism to understand similarity.\n\n&amp;#x200B;\n\nI don't think I fully understand this:\n\nLets say we have a query q\\_1 = \\[1, 1, 1\\]\n\nAnd we have two keys k\\_1=  \\[1, 1, 1\\] and k\\_2 = \\[100, 50, 100\\]\n\n&amp;#x200B;\n\nThe dot-product for q\\_1 @ k\\_1 = 3 while the dot product for q\\_1 @ k\\_2 = 250\n\nSo in the soft-max, the value associated with k\\_2 will be weighted much higher, even though q\\_1 and k\\_1 were literally the same vector.\n\n&amp;#x200B;\n\nNow this would work if all the vectors were unit length (ie cosine similarity), but most examples I have seen online don't normalize by the magnitude of the vectors, but by sqrt{d} where d seems to be the number of elements?\n\n&amp;#x200B;\n\nIf someone could explain where I am missing something, I would really appreciate it!","link":"https://www.reddit.com/r/deeplearning/comments/11ugj0f/question_on_attention/","created":"2023-03-18","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":1},"text":"Question on Attention Hello Everyone!\n\nI have a question about scoring in attention. In attention, you find the dot product between the query and the keys. From my understanding, the intuition is that we can use the inner product as the a mechanism to understand similarity.\n\n&amp;#x200B;\n\nI don't think I fully understand this:\n\nLets say we have a query q\\_1 = \\[1, 1, 1\\]\n\nAnd we have two keys k\\_1=  \\[1, 1, 1\\] and k\\_2 = \\[100, 50, 100\\]\n\n&amp;#x200B;\n\nThe dot-product for q\\_1 @ k\\_1 = 3 while the dot product for q\\_1 @ k\\_2 = 250\n\nSo in the soft-max, the value associated with k\\_2 will be weighted much higher, even though q\\_1 and k\\_1 were literally the same vector.\n\n&amp;#x200B;\n\nNow this would work if all the vectors were unit length (ie cosine similarity), but most examples I have seen online don't normalize by the magnitude of the vectors, but by sqrt{d} where d seems to be the number of elements?\n\n&amp;#x200B;\n\nIf someone could explain where I am missing something, I would really appreciate it!","classes":{"dataset":0.4668053687}}
{"title":"MOOC/YT tutorials for best Deep Learning","description":"A DS generalist here. Have got some years of experience in traditional ML models and occasionally used TF to build projects for fun/personal interest. But want to be get into DL more seriously. Any suggestions on any MOOC/YouTube channel that would be best for that?","link":"https://www.reddit.com/r/deeplearning/comments/11tplmv/moocyt_tutorials_for_best_deep_learning/","created":"2023-03-17","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":3},"text":"MOOC/YT tutorials for best Deep Learning A DS generalist here. Have got some years of experience in traditional ML models and occasionally used TF to build projects for fun/personal interest. But want to be get into DL more seriously. Any suggestions on any MOOC/YouTube channel that would be best for that?","classes":{"dataset":0.1447074562}}
{"title":"Reading PointNet (CVPR2017) and wondering what 'feature alignment' does","description":"as per subject\n\nI am reading PointNet CVPR 2017, and according to the paper,\n\nthe authors said they wanted to introduce transform invariance and, therefore, inserted a 'joint alignment network'.\n\nI guess the first alignment network implements transform invariance because it happens before feature extraction. \n\nBut what would the exact role of feature transform be?","link":"https://www.reddit.com/r/deeplearning/comments/11tjpcp/reading_pointnet_cvpr2017_and_wondering_what/","created":"2023-03-17","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"Reading PointNet (CVPR2017) and wondering what 'feature alignment' does as per subject\n\nI am reading PointNet CVPR 2017, and according to the paper,\n\nthe authors said they wanted to introduce transform invariance and, therefore, inserted a 'joint alignment network'.\n\nI guess the first alignment network implements transform invariance because it happens before feature extraction. \n\nBut what would the exact role of feature transform be?","classes":{"dataset":0.4006610811}}
{"title":"I need some material on metric learning","description":"Thats the code I need to write:\n\nA.Train a neural network model on this dataset.\nB. The dataset has a large variety of celebrities.\n\nC.Once the model is trained, you must create a database with images of the celebrities with the output of the descriptor vector from your model.\nAfter training the neural network, you should include this person in the database.\n\nD.Once steps (1), (2), and (3) are completed, you must use this image, which is the person from item (3) wearing a face mask, and perform facial recognition on them.","link":"https://www.reddit.com/r/deeplearning/comments/11tf8g7/i_need_some_material_on_metric_learning/","created":"2023-03-17","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"I need some material on metric learning Thats the code I need to write:\n\nA.Train a neural network model on this dataset.\nB. The dataset has a large variety of celebrities.\n\nC.Once the model is trained, you must create a database with images of the celebrities with the output of the descriptor vector from your model.\nAfter training the neural network, you should include this person in the database.\n\nD.Once steps (1), (2), and (3) are completed, you must use this image, which is the person from item (3) wearing a face mask, and perform facial recognition on them.","classes":{"dataset":0.2312324494}}
{"title":"[Tutorial] PyTorch Class Activation Map using Custom Trained Model","description":"PyTorch Class Activation Map using Custom Trained Model\n\n[https://debuggercafe.com/pytorch-class-activation-map-using-custom-trained-model/](https://debuggercafe.com/pytorch-class-activation-map-using-custom-trained-model/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/wgg3s1ca17oa1.png?width=1000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e63bb11e597b7ec43d3dfa25539fe99acedccd53","link":"https://www.reddit.com/r/deeplearning/comments/11tbj9v/tutorial_pytorch_class_activation_map_using/","created":"2023-03-17","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"[Tutorial] PyTorch Class Activation Map using Custom Trained Model PyTorch Class Activation Map using Custom Trained Model\n\n[https://debuggercafe.com/pytorch-class-activation-map-using-custom-trained-model/](https://debuggercafe.com/pytorch-class-activation-map-using-custom-trained-model/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/wgg3s1ca17oa1.png?width=1000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e63bb11e597b7ec43d3dfa25539fe99acedccd53","classes":{"dataset":0.496551156}}
{"title":"Optimism Phase 2 Token Airdrop! | $OP","description":"","link":"https://www.reddit.com/r/deeplearning/comments/11t9ews/optimism_phase_2_token_airdrop_op/","created":"2023-03-16","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"Optimism Phase 2 Token Airdrop! | $OP ","classes":{"dataset":0.4994844198}}
{"title":"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3","description":"Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!\n\nThe reason for this increased performance seems to be due to a larger number of tokens being used for training.\n\nNow, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!\n\n[https://youtu.be/d4Cnv\\_g3GiI](https://youtu.be/d4Cnv_g3GiI)","link":"https://www.reddit.com/r/deeplearning/comments/11ryc3s/how_to_finetune_llama_models_smaller_models_with/","created":"2023-03-15","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":10},"text":"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3 Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!\n\nThe reason for this increased performance seems to be due to a larger number of tokens being used for training.\n\nNow, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!\n\n[https://youtu.be/d4Cnv\\_g3GiI](https://youtu.be/d4Cnv_g3GiI)","classes":{"dataset":0.3228095472}}
{"title":"How do I prepare for the Microsoft Exams?","description":"","link":"https://www.reddit.com/r/deeplearning/comments/11snji6/how_do_i_prepare_for_the_microsoft_exams/","created":"2023-03-16","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"How do I prepare for the Microsoft Exams? ","classes":{"dataset":0.2226051241}}
{"title":"How to Use mpirun to Launch a LLaMA Inference Job Across Multiple Cloud Instances","description":"[How to Use mpirun to Launch a LLaMA Inference Job Across Multiple Cloud Instances](https://lambdalabs.com/blog/how-to-use-mpirun-to-launch-a-llama-inference-job-across-multiple-cloud-instances?utm_source=reddit&amp;utm_medium=organic-social&amp;utm_campaign=2023-03-llama-github-repo&amp;utm_content=blog)\n\nGuide on how to use mpirun to launch a LLaMA inference job across multiple Lambda Cloud instances, including a cost analysis for running various LLaMA models on different GPU instances. Notable updates include:\n\n* A script to easily set up a \"cluster\" of cloud instances that is ready to run LLaMA inference (all models from 7B to 65B).\n* mpirun compatible, so you can launch the job directly from the head node without the need of typing in the torchrun command on the worker nodes.\n* Interactive inference mode across multiple nodes.\n* eos\\_w: controls how \"lengthy\" the results are likely to be by scaling the probability of eos\\_token\n* Inference speed profiling (\"tokens/sec\").","link":"https://www.reddit.com/r/deeplearning/comments/11s4u0b/how_to_use_mpirun_to_launch_a_llama_inference_job/","created":"2023-03-15","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"How to Use mpirun to Launch a LLaMA Inference Job Across Multiple Cloud Instances [How to Use mpirun to Launch a LLaMA Inference Job Across Multiple Cloud Instances](https://lambdalabs.com/blog/how-to-use-mpirun-to-launch-a-llama-inference-job-across-multiple-cloud-instances?utm_source=reddit&amp;utm_medium=organic-social&amp;utm_campaign=2023-03-llama-github-repo&amp;utm_content=blog)\n\nGuide on how to use mpirun to launch a LLaMA inference job across multiple Lambda Cloud instances, including a cost analysis for running various LLaMA models on different GPU instances. Notable updates include:\n\n* A script to easily set up a \"cluster\" of cloud instances that is ready to run LLaMA inference (all models from 7B to 65B).\n* mpirun compatible, so you can launch the job directly from the head node without the need of typing in the torchrun command on the worker nodes.\n* Interactive inference mode across multiple nodes.\n* eos\\_w: controls how \"lengthy\" the results are likely to be by scaling the probability of eos\\_token\n* Inference speed profiling (\"tokens/sec\").","classes":{"dataset":0.4928675592}}
{"title":"[D] PyTorch 2.0 Native Flash Attention 32k Context Window","description":"Hi,\n\nI did a quick experiment with Pytorch 2.0 Native scaled\\_dot\\_product\\_attention. I was able to a single forward pass within 9GB of memory which is astounding. I think by patching existing Pretrained GPT models and adding more positional encodings, one could easily fine-tune those models to 32k attention on a single A100 80GB. Here is the code I used:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/6csxe28lv9oa1.png?width=607&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1db074eaea9bb6d0b95678c2cfe39dc71cb48adf\n\nI think it should be possible to replicate even GPT-4 with open source tools something like Bloom + FlashAttention &amp; fine-tune on 32k tokens.\n\n**Update**: I was successfully able to start the training of GPT-2 (125M) with a context size of 8k and batch size of 1 on a 16GB GPU. Since memory scaled linearly from 4k to 8k. I am expecting, 32k would require \\~64GB and should train smoothly on A100 80 GB. Also, I did not do any other optimizations. Maybe 8-bit fine-tuning can further optimize it.\n\n**Update 2**: I basically picked Karpaty's nanoGPT and patched the pretrained GPT-2 by repeating the embeddings N-times. I was unable to train the model at 8k because generation would cause the crash.  So I started the training for a context window of 4k on The Pile: 1 hour in and loss seems to be going down pretty fast. Also Karpaty's generate function is super inefficient, O(n\\^4) I think so it took forever to generate even 2k tokens. So I generate 1100 tokens just to see if the model is able to go beyond 1k limit. And it seems to be working. [Here are some samples](https://0bin.net/paste/O-+eopaW#nmtzX1Re7f1Nr-Otz606jkltvKk/kUXY96/8ca+tb4f) at 3k iteration.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/o2hb25w1sboa1.png?width=1226&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1c7c1eda0e20f5123ea7c143a286aa9bb9a48491\n\n**Update 3**: I have started the training and I am publishing the training script if anyone is interested in replicating or building upon this work. Here is the complete training script:\n\n[https://gist.github.com/NaxAlpha/1c36eaddd03ed102d24372493264694c](https://gist.github.com/NaxAlpha/1c36eaddd03ed102d24372493264694c)\n\nI will post an update after the weekend once the training has progressed somewhat.","link":"https://www.reddit.com/r/MachineLearning/comments/11tmpc5/d_pytorch_20_native_flash_attention_32k_context/","created":"2023-03-17","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":63},"text":"[D] PyTorch 2.0 Native Flash Attention 32k Context Window Hi,\n\nI did a quick experiment with Pytorch 2.0 Native scaled\\_dot\\_product\\_attention. I was able to a single forward pass within 9GB of memory which is astounding. I think by patching existing Pretrained GPT models and adding more positional encodings, one could easily fine-tune those models to 32k attention on a single A100 80GB. Here is the code I used:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/6csxe28lv9oa1.png?width=607&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1db074eaea9bb6d0b95678c2cfe39dc71cb48adf\n\nI think it should be possible to replicate even GPT-4 with open source tools something like Bloom + FlashAttention &amp; fine-tune on 32k tokens.\n\n**Update**: I was successfully able to start the training of GPT-2 (125M) with a context size of 8k and batch size of 1 on a 16GB GPU. Since memory scaled linearly from 4k to 8k. I am expecting, 32k would require \\~64GB and should train smoothly on A100 80 GB. Also, I did not do any other optimizations. Maybe 8-bit fine-tuning can further optimize it.\n\n**Update 2**: I basically picked Karpaty's nanoGPT and patched the pretrained GPT-2 by repeating the embeddings N-times. I was unable to train the model at 8k because generation would cause the crash.  So I started the training for a context window of 4k on The Pile: 1 hour in and loss seems to be going down pretty fast. Also Karpaty's generate function is super inefficient, O(n\\^4) I think so it took forever to generate even 2k tokens. So I generate 1100 tokens just to see if the model is able to go beyond 1k limit. And it seems to be working. [Here are some samples](https://0bin.net/paste/O-+eopaW#nmtzX1Re7f1Nr-Otz606jkltvKk/kUXY96/8ca+tb4f) at 3k iteration.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/o2hb25w1sboa1.png?width=1226&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=1c7c1eda0e20f5123ea7c143a286aa9bb9a48491\n\n**Update 3**: I have started the training and I am publishing the training script if anyone is interested in replicating or building upon this work. Here is the complete training script:\n\n[https://gist.github.com/NaxAlpha/1c36eaddd03ed102d24372493264694c](https://gist.github.com/NaxAlpha/1c36eaddd03ed102d24372493264694c)\n\nI will post an update after the weekend once the training has progressed somewhat.","classes":{"dataset":0.2005566657}}
{"title":"[R] ViperGPT: Visual Inference via Python Execution for Reasoning","description":"[https://viper.cs.columbia.edu/](https://viper.cs.columbia.edu/)\n\nPaper - [https://arxiv.org/abs/2303.08128](https://arxiv.org/abs/2303.08128)","link":"https://www.reddit.com/r/MachineLearning/comments/11ty65w/r_vipergpt_visual_inference_via_python_execution/","created":"2023-03-17","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":2},"text":"[R] ViperGPT: Visual Inference via Python Execution for Reasoning [https://viper.cs.columbia.edu/](https://viper.cs.columbia.edu/)\n\nPaper - [https://arxiv.org/abs/2303.08128](https://arxiv.org/abs/2303.08128)","classes":{"dataset":0.5045340061}}
{"title":"[D] Newbie question about Stanford Alpaca 7b fine-tuning","description":"Hi, I have a question related to Stanford's newly released model Alpaca. I took the dataset they used to train it and replaced all output fields that were generated by gpt3 (text-davinci-003) with outputs generated by gpt-3.5-turbo (API). When I compared the outputs, the GPT 3.5 were usually a bit longer, and more informative.\n\nMy question is, if I use this updated data to train Facebook's llama, can I expect better outputs than what Stanford Alpaca achieved? And lastly, if I let's say triple the amount of data and feed it to the Facebook's model, could the responses possibly be close to ChatGPT?","link":"https://www.reddit.com/r/MachineLearning/comments/11u4u6b/d_newbie_question_about_stanford_alpaca_7b/","created":"2023-03-17","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":3},"text":"[D] Newbie question about Stanford Alpaca 7b fine-tuning Hi, I have a question related to Stanford's newly released model Alpaca. I took the dataset they used to train it and replaced all output fields that were generated by gpt3 (text-davinci-003) with outputs generated by gpt-3.5-turbo (API). When I compared the outputs, the GPT 3.5 were usually a bit longer, and more informative.\n\nMy question is, if I use this updated data to train Facebook's llama, can I expect better outputs than what Stanford Alpaca achieved? And lastly, if I let's say triple the amount of data and feed it to the Facebook's model, could the responses possibly be close to ChatGPT?","classes":{"dataset":0.3658037484}}
{"title":"LLMs are getting much cheaper \u2014 business impact? [D]","description":"Saw this out of Stanford. Apologies if it\u2019s been shared here already. \n\n*We introduce Alpaca 7B, a model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. On our preliminary evaluation of single-turn instruction following, Alpaca behaves qualitatively similarly to OpenAI\u2019s text-davinci-003, while being surprisingly small and easy/cheap to reproduce (&lt;600$).*\n\nBasically, starting w an open source Meta 7B LLaMa model, they recruited GPT-3.5 to use for self-instruct training (as opposed to RLHF) and were able to produce a model that behaved similar to GPT-3.5. Amazingly, the process only took few weeks and $600 in compute cost.  \n\nAny thoughts on how such low cost to train/deploy LLMs could affect companies like AMD, Nvidia and Intel etc? This seems like new idiom of AI tech and trying to wrap my head around CPU/GPU demand implications given the apparent orders of magnitude training cost reduction. \n\nLink: https://crfm.stanford.edu/2023/03/13/alpaca.html","link":"https://www.reddit.com/r/MachineLearning/comments/11tenm7/llms_are_getting_much_cheaper_business_impact_d/","created":"2023-03-17","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":102},"text":"LLMs are getting much cheaper \u2014 business impact? [D] Saw this out of Stanford. Apologies if it\u2019s been shared here already. \n\n*We introduce Alpaca 7B, a model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. On our preliminary evaluation of single-turn instruction following, Alpaca behaves qualitatively similarly to OpenAI\u2019s text-davinci-003, while being surprisingly small and easy/cheap to reproduce (&lt;600$).*\n\nBasically, starting w an open source Meta 7B LLaMa model, they recruited GPT-3.5 to use for self-instruct training (as opposed to RLHF) and were able to produce a model that behaved similar to GPT-3.5. Amazingly, the process only took few weeks and $600 in compute cost.  \n\nAny thoughts on how such low cost to train/deploy LLMs could affect companies like AMD, Nvidia and Intel etc? This seems like new idiom of AI tech and trying to wrap my head around CPU/GPU demand implications given the apparent orders of magnitude training cost reduction. \n\nLink: https://crfm.stanford.edu/2023/03/13/alpaca.html","classes":{"dataset":0.4732198715}}
{"title":"[D] Are there any open source feature stores that do not rely on K8s?","description":"We have investigated some open source feature stores like Feast and FeatureForm, but most require Kubernetes to deploy on the cloud. Unfortunately, our organization isn't very mature in adopting Kubernetes. Are there any recommended feature stores that don't require K8s to deploy its infrastructure?","link":"https://www.reddit.com/r/MachineLearning/comments/11uhrq8/d_are_there_any_open_source_feature_stores_that/","created":"2023-03-18","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":1},"text":"[D] Are there any open source feature stores that do not rely on K8s? We have investigated some open source feature stores like Feast and FeatureForm, but most require Kubernetes to deploy on the cloud. Unfortunately, our organization isn't very mature in adopting Kubernetes. Are there any recommended feature stores that don't require K8s to deploy its infrastructure?","classes":{"dataset":0.3806684315}}
{"title":"[R] RWKV 14B ctx8192 is a zero-shot instruction-follower without finetuning, 23 token/s on 3090 after latest optimization (16G VRAM is enough, and you can stream layers to save more VRAM)","description":"I try the \"Alpaca prompt\" on RWKV 14B ctx8192, and to my surprise it works out of box without any finetuning (RWKV is a 100% RNN trained on 100% Pile v1 and nothing else):\n\nhttps://preview.redd.it/fciatottq7oa1.png?width=1046&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=891904adbadefb5902b86f67098c852da88dc167\n\nYou are welcome to try it in RWKV 14B Gradio (click examples below the panel):\n\n[https://huggingface.co/spaces/BlinkDL/ChatRWKV-gradio](https://huggingface.co/spaces/BlinkDL/ChatRWKV-gradio)\n\nTips: try \"Expert Response\" or \"Expert Long Response\" or \"Expert Full Response\" too.\n\nhttps://preview.redd.it/qo71b85vq7oa1.png?width=2516&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c4b1717754d03e28b4bba01530672935407e7797\n\n===================\n\nChatRWKV v2 is now using a CUDA kernel to optimize INT8 inference (23 token/s on 3090): [https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nUpgrade to latest code and \"pip install rwkv --upgrade\" to 0.5.0, and set os.environ\\[\"RWKV\\_CUDA\\_ON\"\\] = '1' in v2/chat.py to enjoy the speed.\n\nThe inference speed (and VRAM consumption) of RWKV is independent of ctxlen, because it's an RNN (note: currently the preprocessing of a long prompt takes more VRAM but that can be optimized because we can process in chunks).\n\nMeanwhile I find the latest RWKV-4-Pile-14B-20230313-ctx8192-test1050 model can utilize a long ctx:\n\nhttps://preview.redd.it/a68dw0hzq7oa1.png?width=398&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=307e4d7847cb03cab3930b3ea07e9b2f856c9b1c","link":"https://www.reddit.com/r/MachineLearning/comments/11teywc/r_rwkv_14b_ctx8192_is_a_zeroshot/","created":"2023-03-17","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":27},"text":"[R] RWKV 14B ctx8192 is a zero-shot instruction-follower without finetuning, 23 token/s on 3090 after latest optimization (16G VRAM is enough, and you can stream layers to save more VRAM) I try the \"Alpaca prompt\" on RWKV 14B ctx8192, and to my surprise it works out of box without any finetuning (RWKV is a 100% RNN trained on 100% Pile v1 and nothing else):\n\nhttps://preview.redd.it/fciatottq7oa1.png?width=1046&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=891904adbadefb5902b86f67098c852da88dc167\n\nYou are welcome to try it in RWKV 14B Gradio (click examples below the panel):\n\n[https://huggingface.co/spaces/BlinkDL/ChatRWKV-gradio](https://huggingface.co/spaces/BlinkDL/ChatRWKV-gradio)\n\nTips: try \"Expert Response\" or \"Expert Long Response\" or \"Expert Full Response\" too.\n\nhttps://preview.redd.it/qo71b85vq7oa1.png?width=2516&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=c4b1717754d03e28b4bba01530672935407e7797\n\n===================\n\nChatRWKV v2 is now using a CUDA kernel to optimize INT8 inference (23 token/s on 3090): [https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nUpgrade to latest code and \"pip install rwkv --upgrade\" to 0.5.0, and set os.environ\\[\"RWKV\\_CUDA\\_ON\"\\] = '1' in v2/chat.py to enjoy the speed.\n\nThe inference speed (and VRAM consumption) of RWKV is independent of ctxlen, because it's an RNN (note: currently the preprocessing of a long prompt takes more VRAM but that can be optimized because we can process in chunks).\n\nMeanwhile I find the latest RWKV-4-Pile-14B-20230313-ctx8192-test1050 model can utilize a long ctx:\n\nhttps://preview.redd.it/a68dw0hzq7oa1.png?width=398&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=307e4d7847cb03cab3930b3ea07e9b2f856c9b1c","classes":{"dataset":0.4338400066}}
{"title":"[D] instruction tuning : what should I read?","description":"I think I have a decent grasp on transformers, LLMs, prompting, one/few shot learning, fine-tuning. But till now I haven't studied instruction fine tuning and the technique has outgrown my expectations. \nWhere should I start reading about it?\nDo you know any good literature review article to suggest ?","link":"https://www.reddit.com/r/MachineLearning/comments/11tugik/d_instruction_tuning_what_should_i_read/","created":"2023-03-17","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":1},"text":"[D] instruction tuning : what should I read? I think I have a decent grasp on transformers, LLMs, prompting, one/few shot learning, fine-tuning. But till now I haven't studied instruction fine tuning and the technique has outgrown my expectations. \nWhere should I start reading about it?\nDo you know any good literature review article to suggest ?","classes":{"dataset":0.1535878628}}
{"title":"[D] Our community must get serious about opposing OpenAI","description":"OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.\n\nThey have abandoned this idea entirely.\n\nToday, with the release of GPT4 and their direct statement that they will not release details of the model creation due to \"safety concerns\" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.\n\nAI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.\n\nI get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.\n\nWe need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.\n\nThis conversation will only ever get more important.","link":"https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/","created":"2023-03-15","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":388},"text":"[D] Our community must get serious about opposing OpenAI OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.\n\nThey have abandoned this idea entirely.\n\nToday, with the release of GPT4 and their direct statement that they will not release details of the model creation due to \"safety concerns\" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.\n\nAI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.\n\nI get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.\n\nWe need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.\n\nThis conversation will only ever get more important.","classes":{"dataset":0.2557592392}}
{"title":"[D] Will Chat GPT X replace Software Engineers and if so when ?","description":"Hello, I'm a newbie at machine learning and I wanted ask the NLP experts here of the possibility in the future that these language models could actually replace software engineers, considering the fact that only experts in this field will be able to answer this question to some degree because they understand the limitations of techs and models.","link":"https://www.reddit.com/r/MachineLearning/comments/11u5voe/d_will_chat_gpt_x_replace_software_engineers_and/","created":"2023-03-17","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":25},"text":"[D] Will Chat GPT X replace Software Engineers and if so when ? Hello, I'm a newbie at machine learning and I wanted ask the NLP experts here of the possibility in the future that these language models could actually replace software engineers, considering the fact that only experts in this field will be able to answer this question to some degree because they understand the limitations of techs and models.","classes":{"dataset":0.2368717939}}
{"title":"[D] Creating an open platform for collecting corrective feedback on conversational ML products &amp; projects","description":"Any applied scientist or engineer working with deep learning would tell you that corrective info/feedback is the only way up (especially for massive deep networks). With some of my fellows, we are watching what has been happening in the last couple of months with quite a shock and wonder as the community is throwing valuable feedback (for free) to a (closed source) company from all available online channels (e.g., Reddit, Twitter, Github, blogs), boosting their models (again for free).\n\nI should better note here that this is what they need to go from GPT-4 to v5, or GPTX (folks love X these days).\n\nThere are also valuable calls to action from the community. As a start, community can attempt to create an open initiative to organize all the feedback thrown to open or closed (e.g., GPT-4) conversational models/papers/products. One may argue this will make companies' work even easier, but if there is a resource to mine, it will be mined. Therefore creating a (legal) initiative may work in the favor of the community.\n\nWe should consider that conversational DL (maybe in the far future AI, not sure about that yet) becoming like the commercial aircraft industry where the only way to succeed is to fall and enforce what went wrong. Although the community is very excited now, folks may (probably will) get saturated, and the new companies and initiatives in the future may not get the same amount of feedback. \n\nThis may create a monopoly, so it can be a better idea now to discuss the options how we can unify these valuable resources.","link":"https://www.reddit.com/r/MachineLearning/comments/11szdo9/d_creating_an_open_platform_for_collecting/","created":"2023-03-16","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":5},"text":"[D] Creating an open platform for collecting corrective feedback on conversational ML products &amp; projects Any applied scientist or engineer working with deep learning would tell you that corrective info/feedback is the only way up (especially for massive deep networks). With some of my fellows, we are watching what has been happening in the last couple of months with quite a shock and wonder as the community is throwing valuable feedback (for free) to a (closed source) company from all available online channels (e.g., Reddit, Twitter, Github, blogs), boosting their models (again for free).\n\nI should better note here that this is what they need to go from GPT-4 to v5, or GPTX (folks love X these days).\n\nThere are also valuable calls to action from the community. As a start, community can attempt to create an open initiative to organize all the feedback thrown to open or closed (e.g., GPT-4) conversational models/papers/products. One may argue this will make companies' work even easier, but if there is a resource to mine, it will be mined. Therefore creating a (legal) initiative may work in the favor of the community.\n\nWe should consider that conversational DL (maybe in the far future AI, not sure about that yet) becoming like the commercial aircraft industry where the only way to succeed is to fall and enforce what went wrong. Although the community is very excited now, folks may (probably will) get saturated, and the new companies and initiatives in the future may not get the same amount of feedback. \n\nThis may create a monopoly, so it can be a better idea now to discuss the options how we can unify these valuable resources.","classes":{"dataset":0.4298577905}}
{"title":"[N] PyTorch 2.0: Our next generation release that is faster, more Pythonic and Dynamic as ever","description":"Preview of the post since it's dropping in a few hours: https://deploy-preview-1313--pytorch-dot-org-preview.netlify.app/blog/pytorch-2.0-release/\n\n\nAlso a post about Accelerated Diffusers with 2.0: https://deploy-preview-1315--pytorch-dot-org-preview.netlify.app/blog/accelerated-diffusers-pt-20/\n\nGPT Summary:\n\n- PyTorch 2.0 is a next generation release that offers faster performance and support for dynamic shapes and distributed training using torch.compile as the main API.\n\n- PyTorch 2.0 also includes a stable version of Accelerated Transformers, which use custom kernels for scaled dot product attention and are integrated with torch.compile.\n\n- Other beta features include PyTorch MPS Backend for GPU-accelerated training on Mac platforms, functorch APIs in the torch.func module, and AWS Graviton3 optimization for CPU inference.\n\n- The release also includes prototype features and technologies across TensorParallel, DTensor, 2D parallel, TorchDynamo, AOTAutograd, PrimTorch and TorchInductor.","link":"https://www.reddit.com/r/MachineLearning/comments/11s58n4/n_pytorch_20_our_next_generation_release_that_is/","created":"2023-03-15","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":32},"text":"[N] PyTorch 2.0: Our next generation release that is faster, more Pythonic and Dynamic as ever Preview of the post since it's dropping in a few hours: https://deploy-preview-1313--pytorch-dot-org-preview.netlify.app/blog/pytorch-2.0-release/\n\n\nAlso a post about Accelerated Diffusers with 2.0: https://deploy-preview-1315--pytorch-dot-org-preview.netlify.app/blog/accelerated-diffusers-pt-20/\n\nGPT Summary:\n\n- PyTorch 2.0 is a next generation release that offers faster performance and support for dynamic shapes and distributed training using torch.compile as the main API.\n\n- PyTorch 2.0 also includes a stable version of Accelerated Transformers, which use custom kernels for scaled dot product attention and are integrated with torch.compile.\n\n- Other beta features include PyTorch MPS Backend for GPU-accelerated training on Mac platforms, functorch APIs in the torch.func module, and AWS Graviton3 optimization for CPU inference.\n\n- The release also includes prototype features and technologies across TensorParallel, DTensor, 2D parallel, TorchDynamo, AOTAutograd, PrimTorch and TorchInductor.","classes":{"dataset":0.323849529}}
{"title":"Wanna team-up for Quantum NLP projects?","description":"I recently started reading about Quantum NLP. A very experimental and new field in Natural Language Processing. There are only a handful or research papers out there to aid in the knowledge of Quantum NLP, even universities such as MIT, Harvard and Stanford aren't capable or fully understand Quantum NLP yet. Only a few Quantum Computing research labs have the surface-intermediate understanding of Quantum NLP such as Cambridge Quantum.   \n\n\nI have read some of the most recent and important Quantum NLP papers and used **lambeq the only python library capable enough to do Quantum NLP.** Fast forward, I have implemented a basic Quantum NLP project where I classify sentences using Quantum NLP. \n\nI couldn't find many people who are interested in Quantum NLP, that's why, I was looking forward if someone is interested in Quantum NLP in this thread and has previous experience working with NLP itself then we can make a small team and study more advanced topics on Quantum NLP and do cool projects in our pastime. \n\n**GitHub repo link:** [https://github.com/sleepingcat4/Quantum-NLP](https://github.com/sleepingcat4/Quantum-NLP)  \n\n\nIf you're interested in teaming-up, kindly send me a message on **reddit or discord: sleeping\\_cat4#8182**","link":"https://www.reddit.com/r/LanguageTechnology/comments/11uia4r/wanna_teamup_for_quantum_nlp_projects/","created":"2023-03-18","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"Wanna team-up for Quantum NLP projects? I recently started reading about Quantum NLP. A very experimental and new field in Natural Language Processing. There are only a handful or research papers out there to aid in the knowledge of Quantum NLP, even universities such as MIT, Harvard and Stanford aren't capable or fully understand Quantum NLP yet. Only a few Quantum Computing research labs have the surface-intermediate understanding of Quantum NLP such as Cambridge Quantum.   \n\n\nI have read some of the most recent and important Quantum NLP papers and used **lambeq the only python library capable enough to do Quantum NLP.** Fast forward, I have implemented a basic Quantum NLP project where I classify sentences using Quantum NLP. \n\nI couldn't find many people who are interested in Quantum NLP, that's why, I was looking forward if someone is interested in Quantum NLP in this thread and has previous experience working with NLP itself then we can make a small team and study more advanced topics on Quantum NLP and do cool projects in our pastime. \n\n**GitHub repo link:** [https://github.com/sleepingcat4/Quantum-NLP](https://github.com/sleepingcat4/Quantum-NLP)  \n\n\nIf you're interested in teaming-up, kindly send me a message on **reddit or discord: sleeping\\_cat4#8182**","classes":{"dataset":0.5069561005}}
{"title":"New NLP Game Design potentials","description":"Hello I wanted to share some ideas! I believe some of these ideas to be legit avenues for making games with natural language processing, enabled by the power of GPT-4, and I really want to inspire more people down the line! Here are some apps you could make with the openAI API that leverage a whole new degree of responsiveness:  \n\n\n1. A card game where combat is settled by the names of the cards rather than descriptions or card text, using brief but accurate battle simulations! Pair nouns and adjectives, or even fuse cards to make novel new concepts! Who wins, Saitama or Goku? It takes on a whole new level of fairness and intuition when you let the AI take control!\n2. API calls could be used to procedurally generate enemies or catchable monsters in a roguelike! You could provide an example of a json stat sheet and go from there\n3. Considering json, you could (maybe) create a fighting game with MUGEN that merges calls between openai and an art generator, and create the ultimate platform fighter where players type in the name of their character instead of choosing from a select screen! (although generating move sprites is likely gatekept by a few things still....)  \n\n\nThank you for reading! please considering sharing some of these ideas or trying them out yourself, especially the first one I think it quite accessible. Imagine a deck building game where your card database list is the dictionary :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11u7lt9/new_nlp_game_design_potentials/","created":"2023-03-17","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"New NLP Game Design potentials Hello I wanted to share some ideas! I believe some of these ideas to be legit avenues for making games with natural language processing, enabled by the power of GPT-4, and I really want to inspire more people down the line! Here are some apps you could make with the openAI API that leverage a whole new degree of responsiveness:  \n\n\n1. A card game where combat is settled by the names of the cards rather than descriptions or card text, using brief but accurate battle simulations! Pair nouns and adjectives, or even fuse cards to make novel new concepts! Who wins, Saitama or Goku? It takes on a whole new level of fairness and intuition when you let the AI take control!\n2. API calls could be used to procedurally generate enemies or catchable monsters in a roguelike! You could provide an example of a json stat sheet and go from there\n3. Considering json, you could (maybe) create a fighting game with MUGEN that merges calls between openai and an art generator, and create the ultimate platform fighter where players type in the name of their character instead of choosing from a select screen! (although generating move sprites is likely gatekept by a few things still....)  \n\n\nThank you for reading! please considering sharing some of these ideas or trying them out yourself, especially the first one I think it quite accessible. Imagine a deck building game where your card database list is the dictionary :)","classes":{"dataset":0.5250192285}}
{"title":"Fine-tuning BERT for generating short story, how to do it?","description":"","link":"https://www.reddit.com/r/LanguageTechnology/comments/11tqy4f/finetuning_bert_for_generating_short_story_how_to/","created":"2023-03-17","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":3},"text":"Fine-tuning BERT for generating short story, how to do it? ","classes":{"dataset":0.3098055422}}
{"title":"RL and NLP are the two fields my passion and experience lies in. Which institutions/professors would be a good fit to pursue a PhD in a combination of the two?","description":"","link":"https://www.reddit.com/r/LanguageTechnology/comments/11t2rn3/rl_and_nlp_are_the_two_fields_my_passion_and/","created":"2023-03-16","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":2},"text":"RL and NLP are the two fields my passion and experience lies in. Which institutions/professors would be a good fit to pursue a PhD in a combination of the two? ","classes":{"dataset":0.1786346138}}
{"title":"Code Detection","description":"Given a text input I want to detect if there is any kind of code snippet in it. What's the best way to do this? Are there any pre trained models for this task? \n\nThank you","link":"https://www.reddit.com/r/LanguageTechnology/comments/11sr4ml/code_detection/","created":"2023-03-16","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":1},"text":"Code Detection Given a text input I want to detect if there is any kind of code snippet in it. What's the best way to do this? Are there any pre trained models for this task? \n\nThank you","classes":{"dataset":0.1154530123}}
{"title":"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3","description":"Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!\n\nThe reason for this increased performance seems to be due to a larger number of tokens being used for training.\n\nNow, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!\n\n[https://youtu.be/d4Cnv\\_g3GiI](https://youtu.be/d4Cnv_g3GiI)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11ryg4d/how_to_finetune_llama_models_smaller_models_with/","created":"2023-03-15","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3 Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!\n\nThe reason for this increased performance seems to be due to a larger number of tokens being used for training.\n\nNow, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!\n\n[https://youtu.be/d4Cnv\\_g3GiI](https://youtu.be/d4Cnv_g3GiI)","classes":{"dataset":0.4683608115}}
{"title":"UMASS Advanced-NLP","description":"Hi everyone. I finished the advanced nlp course from Mohit Iyyer. You can find the version I completed from here: [https://people.cs.umass.edu/\\~miyyer/cs685\\_f22/](https://people.cs.umass.edu/~miyyer/cs685_f22/) I would definetly recommend it. You can find lectures from youtube.\n\nIf you want to check out and discuss assignment solutions, you can find mine here: [https://github.com/uygarrr/Courses/tree/main/UMASS-CS685-Advanced-NLP](https://github.com/uygarrr/Courses/tree/main/UMASS-CS685-Advanced-NLP)\n\nAlso there're 2 quiz quesitons that I couldn't be sure about the answers. Let me share them here too.\n\n1st: Assume we are applying a Transformer sequence-to-sequence model for a conditional language modeling task (e.g., machine translation). Why don\u2019t we need to use masking in cross attention?\n\n2nd: Now let\u2019s say we want to probe whether or not BERT\u2019s \\[CLS\\] token has encoded the length of an input sentence. Explain how you would design a control task for this probe to address the effect of probe network complexity.\n\n&amp;#x200B;\n\nI would be glad to discuss these and other material. I'm open to course recommendations too. \n\nHappy learning :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11s75id/umass_advancednlp/","created":"2023-03-15","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":2},"text":"UMASS Advanced-NLP Hi everyone. I finished the advanced nlp course from Mohit Iyyer. You can find the version I completed from here: [https://people.cs.umass.edu/\\~miyyer/cs685\\_f22/](https://people.cs.umass.edu/~miyyer/cs685_f22/) I would definetly recommend it. You can find lectures from youtube.\n\nIf you want to check out and discuss assignment solutions, you can find mine here: [https://github.com/uygarrr/Courses/tree/main/UMASS-CS685-Advanced-NLP](https://github.com/uygarrr/Courses/tree/main/UMASS-CS685-Advanced-NLP)\n\nAlso there're 2 quiz quesitons that I couldn't be sure about the answers. Let me share them here too.\n\n1st: Assume we are applying a Transformer sequence-to-sequence model for a conditional language modeling task (e.g., machine translation). Why don\u2019t we need to use masking in cross attention?\n\n2nd: Now let\u2019s say we want to probe whether or not BERT\u2019s \\[CLS\\] token has encoded the length of an input sentence. Explain how you would design a control task for this probe to address the effect of probe network complexity.\n\n&amp;#x200B;\n\nI would be glad to discuss these and other material. I'm open to course recommendations too. \n\nHappy learning :)","classes":{"dataset":0.3181858361}}
{"title":"End-to-end knowledge generation","description":"Hi all,\n\nI am currently working on generating knowledge graphs end-to-end on unstructured text. My job involves a lot of different domain texts in Dutch, so I am definetly interested in open relation extraction.\n\nThe OpenAI api (davinci-text-003) gave me some impressive results on both English and Dutch texts with the following prompt.\n\n\"Generate a knowledge graph of the following text in the form of a triplet. The returned instances should have the following format {entity1, relation, entity2}. Limit the description of the relation to max 3 words. Text:  $TEXT\"\n\n[https://github.com/kcambrek/knowledge\\_graphs/blob/main/Capture.PNG](https://github.com/kcambrek/knowledge_graphs/blob/main/Capture.PNG)\n\nIn the end I am looking for a model that can run locally and is very flexible in open relation extraction. Dealing with noise in triplets seems to be a trivial downstream task.\n\nHas anyone experience in generating knowledge graphs end-to-end with open relations locally unsupervised or with minimal training?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11rw8vh/endtoend_knowledge_generation/","created":"2023-03-15","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"End-to-end knowledge generation Hi all,\n\nI am currently working on generating knowledge graphs end-to-end on unstructured text. My job involves a lot of different domain texts in Dutch, so I am definetly interested in open relation extraction.\n\nThe OpenAI api (davinci-text-003) gave me some impressive results on both English and Dutch texts with the following prompt.\n\n\"Generate a knowledge graph of the following text in the form of a triplet. The returned instances should have the following format {entity1, relation, entity2}. Limit the description of the relation to max 3 words. Text:  $TEXT\"\n\n[https://github.com/kcambrek/knowledge\\_graphs/blob/main/Capture.PNG](https://github.com/kcambrek/knowledge_graphs/blob/main/Capture.PNG)\n\nIn the end I am looking for a model that can run locally and is very flexible in open relation extraction. Dealing with noise in triplets seems to be a trivial downstream task.\n\nHas anyone experience in generating knowledge graphs end-to-end with open relations locally unsupervised or with minimal training?","classes":{"dataset":0.1444758475}}
{"title":"Meta Rediscovers the Cubicle","description":"https://calnewport.com/meta-rediscovers-the-cubicle/","link":"https://calnewport.com/meta-rediscovers-the-cubicle/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":39},"text":"Meta Rediscovers the Cubicle https://calnewport.com/meta-rediscovers-the-cubicle/","classes":{"dataset":0.4162325561}}
{"title":"Show HN: Hacker News LCD Badge","description":"https://github.com/jareklupinski/hackernews-badge","link":"https://github.com/jareklupinski/hackernews-badge","created":"2023-03-12","tags":["hackernews"],"meta":{"score":64},"text":"Show HN: Hacker News LCD Badge https://github.com/jareklupinski/hackernews-badge","classes":{"dataset":0.5122379065}}
{"title":"Reversing a packet protocol: The FusionFall protocol (2020)","description":"https://openpunk.com/pages/fusionfall-openfusion/","link":"https://openpunk.com/pages/fusionfall-openfusion/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":16},"text":"Reversing a packet protocol: The FusionFall protocol (2020) https://openpunk.com/pages/fusionfall-openfusion/","classes":{"dataset":0.4908765554}}
{"title":"Map of an Insect\u2019s Brain","description":"https://www.smithsonianmag.com/smart-news/see-the-first-complete-map-of-an-insects-brain-180981778/","link":"https://www.smithsonianmag.com/smart-news/see-the-first-complete-map-of-an-insects-brain-180981778/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":235},"text":"Map of an Insect\u2019s Brain https://www.smithsonianmag.com/smart-news/see-the-first-complete-map-of-an-insects-brain-180981778/","classes":{"dataset":0.5613960028}}
{"title":"The threat on your desk: Building an evil USB-C dock","description":"https://research.aurainfosec.io/pentest/threat-on-your-desk-evil-usbc-dock/","link":"https://research.aurainfosec.io/pentest/threat-on-your-desk-evil-usbc-dock/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":140},"text":"The threat on your desk: Building an evil USB-C dock https://research.aurainfosec.io/pentest/threat-on-your-desk-evil-usbc-dock/","classes":{"dataset":0.4781065583}}
{"title":"OldLinux: Ancient Linux Resources","description":"http://www.oldlinux.org/","link":"http://www.oldlinux.org/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":97},"text":"OldLinux: Ancient Linux Resources http://www.oldlinux.org/","classes":{"dataset":0.5141656995}}
{"title":"Common Beginner Mistakes with React","description":"https://www.joshwcomeau.com/react/common-beginner-mistakes/","link":"https://www.joshwcomeau.com/react/common-beginner-mistakes/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":191},"text":"Common Beginner Mistakes with React https://www.joshwcomeau.com/react/common-beginner-mistakes/","classes":{"dataset":0.5170041323}}
{"title":"ChatGPT's API is so good and cheap, it makes most text generating AI obsolete","description":"https://minimaxir.com/2023/03/new-chatgpt-overlord/","link":"https://minimaxir.com/2023/03/new-chatgpt-overlord/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":551},"text":"ChatGPT's API is so good and cheap, it makes most text generating AI obsolete https://minimaxir.com/2023/03/new-chatgpt-overlord/","classes":{"dataset":0.496357888}}
{"title":"Living the writing life means living with failure","description":"https://www.washingtonpost.com/books/2023/03/06/living-writing-life-means-living-with-failure/","link":"https://www.washingtonpost.com/books/2023/03/06/living-writing-life-means-living-with-failure/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":95},"text":"Living the writing life means living with failure https://www.washingtonpost.com/books/2023/03/06/living-writing-life-means-living-with-failure/","classes":{"dataset":0.4843457043}}
{"title":"Vinyl Records Outsell CDs for the First Time Since 1987","description":"https://www.wsj.com/articles/vinyl-records-outsell-cds-for-the-first-time-since-1987-49deeef0","link":"https://www.wsj.com/articles/vinyl-records-outsell-cds-for-the-first-time-since-1987-49deeef0","created":"2023-03-12","tags":["hackernews"],"meta":{"score":29},"text":"Vinyl Records Outsell CDs for the First Time Since 1987 https://www.wsj.com/articles/vinyl-records-outsell-cds-for-the-first-time-since-1987-49deeef0","classes":{"dataset":0.509739995}}
{"title":"Did air pollution influence famous impressionist painters?","description":"https://www.smithsonianmag.com/smart-news/air-pollution-impressionist-painters-monet-turner-180981710/","link":"https://www.smithsonianmag.com/smart-news/air-pollution-impressionist-painters-monet-turner-180981710/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":73},"text":"Did air pollution influence famous impressionist painters? https://www.smithsonianmag.com/smart-news/air-pollution-impressionist-painters-monet-turner-180981710/","classes":{"dataset":0.5360687375}}
{"title":"What are the demographics of stars visible to the naked eye?","description":"https://physics.stackexchange.com/questions/79954/what-are-the-demographics-of-stars-visible-to-the-naked-eye/105509#105509","link":"https://physics.stackexchange.com/questions/79954/what-are-the-demographics-of-stars-visible-to-the-naked-eye/105509#105509","created":"2023-03-12","tags":["hackernews"],"meta":{"score":15},"text":"What are the demographics of stars visible to the naked eye? https://physics.stackexchange.com/questions/79954/what-are-the-demographics-of-stars-visible-to-the-naked-eye/105509#105509","classes":{"dataset":0.5054649711}}
{"title":"Tether USDT is trading at $1.01","description":"https://coinmarketcap.com/currencies/tether/","link":"https://coinmarketcap.com/currencies/tether/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":54},"text":"Tether USDT is trading at $1.01 https://coinmarketcap.com/currencies/tether/","classes":{"dataset":0.5366809964}}
{"title":"Ivy League Schools Sure Look Like a Cartel","description":"https://www.bloomberg.com/opinion/articles/2023-03-11/ivy-league-athletic-scholarship-lawsuit-exposes-cartel-like-behavior","link":"https://www.bloomberg.com/opinion/articles/2023-03-11/ivy-league-athletic-scholarship-lawsuit-exposes-cartel-like-behavior","created":"2023-03-11","tags":["hackernews"],"meta":{"score":297},"text":"Ivy League Schools Sure Look Like a Cartel https://www.bloomberg.com/opinion/articles/2023-03-11/ivy-league-athletic-scholarship-lawsuit-exposes-cartel-like-behavior","classes":{"dataset":0.4931216538}}
{"title":"SVB Securities Management Exploring Buying Firm Back","description":"https://www.bloomberg.com/news/articles/2023-03-12/svb-securities-management-exploring-buying-firm-back","link":"https://www.bloomberg.com/news/articles/2023-03-12/svb-securities-management-exploring-buying-firm-back","created":"2023-03-12","tags":["hackernews"],"meta":{"score":32},"text":"SVB Securities Management Exploring Buying Firm Back https://www.bloomberg.com/news/articles/2023-03-12/svb-securities-management-exploring-buying-firm-back","classes":{"dataset":0.507349968}}
{"title":"An Update on USDC and Silicon Valley Bank","description":"https://www.circle.com/blog/an-update-on-usdc-and-silicon-valley-bank","link":"https://www.circle.com/blog/an-update-on-usdc-and-silicon-valley-bank","created":"2023-03-11","tags":["hackernews"],"meta":{"score":201},"text":"An Update on USDC and Silicon Valley Bank https://www.circle.com/blog/an-update-on-usdc-and-silicon-valley-bank","classes":{"dataset":0.486443609}}
{"title":"The \u201cNot Creative\u201d Trap","description":"https://robert.bearblog.dev/the-not-creative-trap/","link":"https://robert.bearblog.dev/the-not-creative-trap/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":34},"text":"The \u201cNot Creative\u201d Trap https://robert.bearblog.dev/the-not-creative-trap/","classes":{"dataset":0.4805814028}}
{"title":"Caricaturing Noam Chomsky","description":"https://garymarcus.substack.com/p/caricaturing-noam-chomsky","link":"https://garymarcus.substack.com/p/caricaturing-noam-chomsky","created":"2023-03-12","tags":["hackernews"],"meta":{"score":8},"text":"Caricaturing Noam Chomsky https://garymarcus.substack.com/p/caricaturing-noam-chomsky","classes":{"dataset":0.5002221465}}
{"title":"A Bank of One's Own","description":"https://nayafia.substack.com/p/a-bank-of-ones-own","link":"https://nayafia.substack.com/p/a-bank-of-ones-own","created":"2023-03-11","tags":["hackernews"],"meta":{"score":161},"text":"A Bank of One's Own https://nayafia.substack.com/p/a-bank-of-ones-own","classes":{"dataset":0.4936168194}}
{"title":"Wild macaques challenge the origin of intentional tool production","description":"https://www.science.org/doi/10.1126/sciadv.ade8159","link":"https://www.science.org/doi/10.1126/sciadv.ade8159","created":"2023-03-11","tags":["hackernews"],"meta":{"score":57},"text":"Wild macaques challenge the origin of intentional tool production https://www.science.org/doi/10.1126/sciadv.ade8159","classes":{"dataset":0.5311508179}}
{"title":"The Internet\u2019s Richest Fitness Resource Is a Site from 1999","description":"https://www.newyorker.com/culture/rabbit-holes/the-internets-richest-fitness-resource-is-a-site-from-1999","link":"https://www.newyorker.com/culture/rabbit-holes/the-internets-richest-fitness-resource-is-a-site-from-1999","created":"2023-03-09","tags":["hackernews"],"meta":{"score":421},"text":"The Internet\u2019s Richest Fitness Resource Is a Site from 1999 https://www.newyorker.com/culture/rabbit-holes/the-internets-richest-fitness-resource-is-a-site-from-1999","classes":{"dataset":0.4935850501}}
{"title":"Embed a Tailscale Funnel in your Go app","description":"https://tailscale.dev/blog/embedded-funnel","link":"https://tailscale.dev/blog/embedded-funnel","created":"2023-03-12","tags":["hackernews"],"meta":{"score":12},"text":"Embed a Tailscale Funnel in your Go app https://tailscale.dev/blog/embedded-funnel","classes":{"dataset":0.4478631318}}
{"title":"An open-source database of companies affected (or not) by the collapse of SVB","description":"https://affectedbysvbornot.com/","link":"https://affectedbysvbornot.com/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":74},"text":"An open-source database of companies affected (or not) by the collapse of SVB https://affectedbysvbornot.com/","classes":{"dataset":0.5251384377}}
{"title":"FDIC \u2013 SVB FAQ","description":"https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/silicon-valley.html","link":"https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/silicon-valley.html","created":"2023-03-12","tags":["hackernews"],"meta":{"score":209},"text":"FDIC \u2013 SVB FAQ https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/silicon-valley.html","classes":{"dataset":0.4869461656}}
{"title":"SVB does not deserve a bailout. They DID NOT hedge interest rate risk at all","description":"https://twitter.com/MacroAlf/status/1634626124260028419","link":"https://twitter.com/MacroAlf/status/1634626124260028419","created":"2023-03-11","tags":["hackernews"],"meta":{"score":105},"text":"SVB does not deserve a bailout. They DID NOT hedge interest rate risk at all https://twitter.com/MacroAlf/status/1634626124260028419","classes":{"dataset":0.5102830529}}
{"title":"Box64 \u2013 Linux Userspace x86_64 Emulator Targeted at ARM64 Linux Devices","description":"https://github.com/ptitSeb/box64","link":"https://github.com/ptitSeb/box64","created":"2023-03-11","tags":["hackernews"],"meta":{"score":158},"text":"Box64 \u2013 Linux Userspace x86_64 Emulator Targeted at ARM64 Linux Devices https://github.com/ptitSeb/box64","classes":{"dataset":0.5037468076}}
{"title":"Patterns is building a platform to abstract away data science busywork","description":"https://techcrunch.com/2023/03/09/y-combinator-backed-patterns-is-building-a-platform-to-abstract-away-data-science-busywork/","link":"https://techcrunch.com/2023/03/09/y-combinator-backed-patterns-is-building-a-platform-to-abstract-away-data-science-busywork/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":29},"text":"Patterns is building a platform to abstract away data science busywork https://techcrunch.com/2023/03/09/y-combinator-backed-patterns-is-building-a-platform-to-abstract-away-data-science-busywork/","classes":{"dataset":0.507635653}}
{"title":"Giannis Antetokounmpo put $250k into 50 different banks (2022)","description":"https://www.bloomberg.com/news/articles/2022-04-07/marc-lasry-shocked-that-two-time-nba-mvp-put-money-in-50-banks","link":"https://www.bloomberg.com/news/articles/2022-04-07/marc-lasry-shocked-that-two-time-nba-mvp-put-money-in-50-banks","created":"2023-03-12","tags":["hackernews"],"meta":{"score":14},"text":"Giannis Antetokounmpo put $250k into 50 different banks (2022) https://www.bloomberg.com/news/articles/2022-04-07/marc-lasry-shocked-that-two-time-nba-mvp-put-money-in-50-banks","classes":{"dataset":0.5259075165}}
{"title":"A TUI Todo Manager","description":"https://github.com/kraanzu/dooit","link":"https://github.com/kraanzu/dooit","created":"2023-03-11","tags":["hackernews"],"meta":{"score":9},"text":"A TUI Todo Manager https://github.com/kraanzu/dooit","classes":{"dataset":0.4710707366}}
{"title":"There have been 562 bank failures since 2000","description":"https://yarn.pranshum.com/banks","link":"https://yarn.pranshum.com/banks","created":"2023-03-11","tags":["hackernews"],"meta":{"score":148},"text":"There have been 562 bank failures since 2000 https://yarn.pranshum.com/banks","classes":{"dataset":0.4763406217}}
{"title":"Giving the finger is a \u2018God-given right\u2019, Canadian judge rules","description":"http://citoyens.soquij.qc.ca/php/decision.php?ID=B40649560046AC98B6BC3AA9D9C409F7","link":"http://citoyens.soquij.qc.ca/php/decision.php?ID=B40649560046AC98B6BC3AA9D9C409F7","created":"2023-03-10","tags":["hackernews"],"meta":{"score":514},"text":"Giving the finger is a \u2018God-given right\u2019, Canadian judge rules http://citoyens.soquij.qc.ca/php/decision.php?ID=B40649560046AC98B6BC3AA9D9C409F7","classes":{"dataset":0.5037419796}}
{"title":"Rewriting the CLI in Rust: Was It Worth It?","description":"https://blog.railway.app/p/rust-cli-rewrite","link":"https://blog.railway.app/p/rust-cli-rewrite","created":"2023-03-11","tags":["hackernews"],"meta":{"score":44},"text":"Rewriting the CLI in Rust: Was It Worth It? https://blog.railway.app/p/rust-cli-rewrite","classes":{"dataset":0.4828366041}}
{"title":"The Dot Essay (1923)","description":"https://psychclassics.yorku.ca/Wertheimer/Forms/forms.htm","link":"https://psychclassics.yorku.ca/Wertheimer/Forms/forms.htm","created":"2023-03-10","tags":["hackernews"],"meta":{"score":17},"text":"The Dot Essay (1923) https://psychclassics.yorku.ca/Wertheimer/Forms/forms.htm","classes":{"dataset":0.5013438463}}
{"title":"Write Posix Shell","description":"https://j3s.sh/thought/write-posix-shell.html","link":"https://j3s.sh/thought/write-posix-shell.html","created":"2023-03-11","tags":["hackernews"],"meta":{"score":111},"text":"Write Posix Shell https://j3s.sh/thought/write-posix-shell.html","classes":{"dataset":0.4776760638}}
{"title":"Kopia \u2013 incremental backups, encryption, compression, data deduplication","description":"https://github.com/kopia/kopia","link":"https://github.com/kopia/kopia","created":"2023-03-11","tags":["hackernews"],"meta":{"score":58},"text":"Kopia \u2013 incremental backups, encryption, compression, data deduplication https://github.com/kopia/kopia","classes":{"dataset":0.5258603692}}
{"title":"People with ADHD claim Adderall is \u2018different\u2019 now","description":"https://www.nytimes.com/2023/03/09/well/live/adhd-adderall-shortage.html","link":"https://www.nytimes.com/2023/03/09/well/live/adhd-adderall-shortage.html","created":"2023-03-11","tags":["hackernews"],"meta":{"score":240},"text":"People with ADHD claim Adderall is \u2018different\u2019 now https://www.nytimes.com/2023/03/09/well/live/adhd-adderall-shortage.html","classes":{"dataset":0.5188783407}}
{"title":"Disambiguating Arm, Arm ARM, ARMv9, ARM9, ARM64, AArch64, A64, A78, ...","description":"https://nickdesaulniers.github.io/blog/2023/03/10/disambiguating-arm/","link":"https://nickdesaulniers.github.io/blog/2023/03/10/disambiguating-arm/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":301},"text":"Disambiguating Arm, Arm ARM, ARMv9, ARM9, ARM64, AArch64, A64, A78, ... https://nickdesaulniers.github.io/blog/2023/03/10/disambiguating-arm/","classes":{"dataset":0.5337338448}}
{"title":"How to Yubikey","description":"https://debugging.works/blog/yubikey-cheatsheet/","link":"https://debugging.works/blog/yubikey-cheatsheet/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":435},"text":"How to Yubikey https://debugging.works/blog/yubikey-cheatsheet/","classes":{"dataset":0.5047473311}}
{"title":"\u201cClean Code, Horrible Performance\u201d Discussion","description":"https://github.com/unclebob/cmuratori-discussion/blob/main/cleancodeqa.md","link":"https://github.com/unclebob/cmuratori-discussion/blob/main/cleancodeqa.md","created":"2023-03-11","tags":["hackernews"],"meta":{"score":216},"text":"\u201cClean Code, Horrible Performance\u201d Discussion https://github.com/unclebob/cmuratori-discussion/blob/main/cleancodeqa.md","classes":{"dataset":0.4965943694}}
{"title":"Wells Fargo clients report missing deposits as bank works on fix","description":"https://www.thinkadvisor.com/2023/03/10/wells-fargo-clients-report-missing-deposits-as-bank-works-on-fix/","link":"https://www.thinkadvisor.com/2023/03/10/wells-fargo-clients-report-missing-deposits-as-bank-works-on-fix/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":165},"text":"Wells Fargo clients report missing deposits as bank works on fix https://www.thinkadvisor.com/2023/03/10/wells-fargo-clients-report-missing-deposits-as-bank-works-on-fix/","classes":{"dataset":0.5812116265}}
{"title":"Serverless maps at 1/700 the cost of Google Maps API","description":"https://protomaps.com/blog/serverless-maps-now-open-source","link":"https://protomaps.com/blog/serverless-maps-now-open-source","created":"2023-03-10","tags":["hackernews"],"meta":{"score":506},"text":"Serverless maps at 1/700 the cost of Google Maps API https://protomaps.com/blog/serverless-maps-now-open-source","classes":{"dataset":0.4954809248}}
{"title":"Wonder Studio: this AI-powered tool might be a preview of the future of VFX","description":"https://3dvf.com/en/wonder-studio-this-ai-powered-tool-might-be-a-preview-of-the-future-of-vfx/","link":"https://3dvf.com/en/wonder-studio-this-ai-powered-tool-might-be-a-preview-of-the-future-of-vfx/","created":"2023-03-11","tags":["hackernews"],"meta":{"score":138},"text":"Wonder Studio: this AI-powered tool might be a preview of the future of VFX https://3dvf.com/en/wonder-studio-this-ai-powered-tool-might-be-a-preview-of-the-future-of-vfx/","classes":{"dataset":0.5530516505}}
{"title":"History of Ecommerce","description":"https://medusajs.com/blog/ecommerce-history/","link":"https://medusajs.com/blog/ecommerce-history/","created":"2023-03-09","tags":["hackernews"],"meta":{"score":22},"text":"History of Ecommerce https://medusajs.com/blog/ecommerce-history/","classes":{"dataset":0.5047177076}}
{"title":"Show HN: Generate a Cover Letter by Pasting the Job Post and Your Resume","description":"https://www.careered.ai/tool/cover-letter","link":"https://www.careered.ai/tool/cover-letter","created":"2023-03-11","tags":["hackernews"],"meta":{"score":5},"text":"Show HN: Generate a Cover Letter by Pasting the Job Post and Your Resume https://www.careered.ai/tool/cover-letter","classes":{"dataset":0.5107733011}}
{"title":"How to start a rocket engine","description":"https://everydayastronaut.com/how-to-start-a-rocket-engine/","link":"https://everydayastronaut.com/how-to-start-a-rocket-engine/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":347},"text":"How to start a rocket engine https://everydayastronaut.com/how-to-start-a-rocket-engine/","classes":{"dataset":0.4864963591}}
{"title":"Outlaws at War in the Middle Ages","description":"https://www.historytoday.com/archive/history-matters/outlaws-war","link":"https://www.historytoday.com/archive/history-matters/outlaws-war","created":"2023-03-09","tags":["hackernews"],"meta":{"score":33},"text":"Outlaws at War in the Middle Ages https://www.historytoday.com/archive/history-matters/outlaws-war","classes":{"dataset":0.5187079906}}
{"title":"What a good debugger can do","description":"https://werat.dev/blog/what-a-good-debugger-can-do/","link":"https://werat.dev/blog/what-a-good-debugger-can-do/","created":"2023-03-10","tags":["hackernews"],"meta":{"score":299},"text":"What a good debugger can do https://werat.dev/blog/what-a-good-debugger-can-do/","classes":{"dataset":0.4555347264}}
{"title":"Muppeting: New Term For Off Prompt Response","description":"Muppeting, when an AI seemingly randomly ignores part of your prompt.  For example, ask the ChatGPT API to output its response as a python dictionary, then put the call in the loop.  The responses where it goes oft prompt and offers commentary before giving you the dictionary (or messes up the dictionary) are Muppets.","link":"https://www.reddit.com/r/PromptDesign/comments/11p8alo/muppeting_new_term_for_off_prompt_response/","created":"2023-03-12","tags":["promptdesign","reddit","prompteng"],"meta":{"num_comments":0},"text":"Muppeting: New Term For Off Prompt Response Muppeting, when an AI seemingly randomly ignores part of your prompt.  For example, ask the ChatGPT API to output its response as a python dictionary, then put the call in the loop.  The responses where it goes oft prompt and offers commentary before giving you the dictionary (or messes up the dictionary) are Muppets.","classes":{"dataset":0.5015769601}}
{"title":"Made a tool to help to improve your prompts","description":"PromptPerfect is a cutting-edge prompt optimizer designed for large language models (LLMs), large models (LMs), and LMOps. The tool optimizes your prompts for ChatGPT, GPT-3.5, DALLE, and StableDiffusion models.   \n\n\nI would love to hear your feedback and thoughts on it. Thank you in advance.   \nLink to the example: [https://promptperfect.jina.ai/share?thread=pmTPARwr3r5zPOTnAKhT](https://promptperfect.jina.ai/share?thread=pmTPARwr3r5zPOTnAKhT)\n\n[An example used for GPT 3 ](https://preview.redd.it/owk8c9k6tqma1.png?width=622&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b89adb7575c518e135e0448630e4b5b0d8666fc9)","link":"https://www.reddit.com/r/PromptDesign/comments/11mx2ie/made_a_tool_to_help_to_improve_your_prompts/","created":"2023-03-09","tags":["promptdesign","reddit","prompteng"],"meta":{"num_comments":11},"text":"Made a tool to help to improve your prompts PromptPerfect is a cutting-edge prompt optimizer designed for large language models (LLMs), large models (LMs), and LMOps. The tool optimizes your prompts for ChatGPT, GPT-3.5, DALLE, and StableDiffusion models.   \n\n\nI would love to hear your feedback and thoughts on it. Thank you in advance.   \nLink to the example: [https://promptperfect.jina.ai/share?thread=pmTPARwr3r5zPOTnAKhT](https://promptperfect.jina.ai/share?thread=pmTPARwr3r5zPOTnAKhT)\n\n[An example used for GPT 3 ](https://preview.redd.it/owk8c9k6tqma1.png?width=622&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b89adb7575c518e135e0448630e4b5b0d8666fc9)","classes":{"dataset":0.0952493399}}
{"title":"I make prompt packs, and I put together some ChatGPT prompts to help anyone learning Rust [Free Resource]","description":"## Using these prompts\n\n\n\ud83d\udc68\u200d\ud83c\udfeb This resource is designed to quickly show you the power of chatGPT and serve as a starting point for exploration.\n\n\nCopy and paste these into [https://chat.openai.com/](https://chat.openai.com/)  to see what you get. I\u2019ve also added some responses here. Further explore editing the prompts, trying to direct the AI, and taking the step-by-step responses as new prompts to feed the bot. Enjoy!\n\n[Download All the prompts free on Gumroad](https://godsol.gumroad.com/l/rust-prompts)\n*due to length constraints, this article contains less than half*\n\n\n## Learning Rust (New Concepts)\n\n## Ownership and Borrowing:\n\nWhat are the benefits of Rust's ownership and borrowing system?\n\nHow does Rust prevent common memory-related bugs like null pointers and dangling pointers?\n\nCan you explain the difference between mutable and immutable borrowing in Rust?\n\n## Traits:\n\nHow do traits help with generic programming in Rust?\n\nCan you provide an example of a custom trait in Rust?\n\nWhat is the difference between a trait object and a generic type parameter in Rust?\n\n## Lifetimes:\n\nWhat is a lifetime in Rust and how is it different from a scope?\n\nHow does Rust's borrow checker use lifetimes to prevent dangling pointers?\n\nCan you explain the difference between 'static and 'a lifetimes in Rust?\n\n## Pattern Matching:\n\nWhat is pattern matching and how is it used in Rust?\n\nHow can pattern matching be used with enums and structs in Rust?\n\n## Concurrency:\n\nWhat are some of the built-in concurrency primitives in Rust?\n\nHow does Rust's ownership and borrowing system make writing concurrent code safer?\n\nCan you provide an example of a multi-threaded Rust program?\n\n## Macros:\n\nWhat are macros and how are they used in Rust?\n\nCan you provide an example of a macro in Rust?\n\nHow can macros be used to generate code at compile time in Rust?\n\n## Error Handling:\n\nWhat are some of the built-in error handling mechanisms in Rust?\n\nHow does Rust's error handling system differ from other programming languages?\n\nCan you provide an example of how to use the Result and Option types in Rust?\n\n## Systems Programming\n\n```jsx\nBuild a system daemon that monitors system resource usage and logs events to a file using the Rust Standard Library. Use the log crate for logging and the signal-hook crate to handle system signals.\n```\n\nDevelop a network application that implements a custom protocol using Rust's TCP and UDP socket libraries. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\nCreate a file management tool that allows users to copy, move, and delete files and directories using Rust's standard filesystem library. Use the clap crate for command-line argument parsing and the indicatif crate for progress bars.\n\nBuild a simple web server that handles HTTP requests and serves static files using the Iron web framework and Rust's standard HTTP libraries. Use the chrono crate for handling dates and times and the openssl crate for secure communication.\n\nDevelop a low-level library for interfacing with a hardware device using Rust's Foreign Function Interface (FFI) and the libc crate. Use the crossbeam crate for safe concurrent programming and the rust-crypto crate for encryption and hashing.\n\nCreate a CLI tool that allows users to manipulate audio files using the Rust's audio crate. Use the clap crate for command-line argument parsing and the hound crate for audio file I/O.\n\nBuild a network daemon that listens for incoming connections and manages a pool of worker threads using Rust's standard thread libraries and the crossbeam-channel crate for inter-thread communication. Use the rustls crate for secure communication.\n\nDevelop a command-line tool for converting between different image formats using Rust's image processing library and the clap crate for command-line argument parsing. Use the rayon crate for parallel processing.\n\nCreate a system service that monitors a directory for changes and logs events to a file using the notify crate. Use the chrono crate for handling dates and times and the slog crate for logging.\n\nBuild a command-line tool that encrypts and decrypts files using Rust's cryptography libraries and the clap crate for command-line argument parsing. Use the rand crate for generating random numbers.\n\nDevelop a low-level library for interfacing with a Bluetooth device using Rust's FFI and the BlueZ Bluetooth stack. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\nCreate a CLI tool that allows users to manipulate PDF files using the Rust's PDF processing libraries and the clap crate for command-line argument parsing. Use the rayon crate for parallel processing.\n\nBuild a system daemon that monitors and logs changes to system configuration files using Rust's standard filesystem libraries and the notify crate. Use the serde crate for serialization and deserialization.\n\nDevelop a command-line tool that generates random passwords using Rust's cryptography libraries and the clap crate for command-line argument parsing. Use the rand crate for generating random numbers.\n\nCreate a low-level library for interfacing with a USB device using Rust's FFI and the libusb library. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\nBuild a command-line tool that allows users to manage system processes using Rust's standard process libraries and the clap crate for command-line argument parsing. Use the regex crate for string manipulation.\n\nDevelop a system daemon that manages a pool of worker threads and communicates with them using Rust's standard thread libraries and the crossbeam-channel crate. Use the chrono crate for handling dates and times and the slog crate for logging.\n\nCreate a low-level library for interfacing with a Serial device using Rust's FFI and the serialport library. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\n## DevOps\n\n```jsx\nBuild a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Rust's DevOps library, Rust CI/CD, and the Jenkins automation server. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n```\n\nDevelop a tool for infrastructure automation using Rust's DevOps library, Rust Chef, and the Chef configuration management tool. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container orchestration using Rust's DevOps library, Rust Kubernetes, and the Kubernetes container orchestration system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a serverless infrastructure using Rust's DevOps library, Rust Serverless, and the AWS Lambda service. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for continuous monitoring using Rust's DevOps library, Rust Prometheus, and the Prometheus monitoring system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for log management using Rust's DevOps library, Rust Logstash, and the Logstash logging pipeline. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Rust's DevOps library, Rust Travis, and the Travis CI/CD platform. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for infrastructure testing using Rust's DevOps library, Rust Terraform, and the Terraform infrastructure as code tool. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container security using Rust's DevOps library, Rust Clair, and the Clair container security scanner. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a serverless application using Rust's DevOps library, Rust AWS Lambda, and the AWS Lambda service. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for infrastructure visualization using Rust's DevOps library, Rust Graphviz, and the Graphviz graph visualization software. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container monitoring using Rust's DevOps library, Rust Prometheus, and the Prometheus monitoring system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Rust's DevOps library, Rust CircleCI, and the CircleCI CI/CD platform. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for infrastructure as code using Rust's DevOps library, Rust Ansible, and the Ansible configuration management tool. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container orchestration using Rust's DevOps library, Rust Nomad, and the Nomad container orchestration system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a serverless application using Rust's DevOps library, Rust Google Cloud Functions, and the Google Cloud Functions service. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\n[Download All the prompts free on Gumroad](https://godsol.gumroad.com/l/rust-prompts)\n*due to length constraints, this article contains less than half*","link":"https://www.reddit.com/r/PromptDesign/comments/11mwsfm/i_make_prompt_packs_and_i_put_together_some/","created":"2023-03-09","tags":["promptdesign","reddit","prompteng"],"meta":{"num_comments":1},"text":"I make prompt packs, and I put together some ChatGPT prompts to help anyone learning Rust [Free Resource] ## Using these prompts\n\n\n\ud83d\udc68\u200d\ud83c\udfeb This resource is designed to quickly show you the power of chatGPT and serve as a starting point for exploration.\n\n\nCopy and paste these into [https://chat.openai.com/](https://chat.openai.com/)  to see what you get. I\u2019ve also added some responses here. Further explore editing the prompts, trying to direct the AI, and taking the step-by-step responses as new prompts to feed the bot. Enjoy!\n\n[Download All the prompts free on Gumroad](https://godsol.gumroad.com/l/rust-prompts)\n*due to length constraints, this article contains less than half*\n\n\n## Learning Rust (New Concepts)\n\n## Ownership and Borrowing:\n\nWhat are the benefits of Rust's ownership and borrowing system?\n\nHow does Rust prevent common memory-related bugs like null pointers and dangling pointers?\n\nCan you explain the difference between mutable and immutable borrowing in Rust?\n\n## Traits:\n\nHow do traits help with generic programming in Rust?\n\nCan you provide an example of a custom trait in Rust?\n\nWhat is the difference between a trait object and a generic type parameter in Rust?\n\n## Lifetimes:\n\nWhat is a lifetime in Rust and how is it different from a scope?\n\nHow does Rust's borrow checker use lifetimes to prevent dangling pointers?\n\nCan you explain the difference between 'static and 'a lifetimes in Rust?\n\n## Pattern Matching:\n\nWhat is pattern matching and how is it used in Rust?\n\nHow can pattern matching be used with enums and structs in Rust?\n\n## Concurrency:\n\nWhat are some of the built-in concurrency primitives in Rust?\n\nHow does Rust's ownership and borrowing system make writing concurrent code safer?\n\nCan you provide an example of a multi-threaded Rust program?\n\n## Macros:\n\nWhat are macros and how are they used in Rust?\n\nCan you provide an example of a macro in Rust?\n\nHow can macros be used to generate code at compile time in Rust?\n\n## Error Handling:\n\nWhat are some of the built-in error handling mechanisms in Rust?\n\nHow does Rust's error handling system differ from other programming languages?\n\nCan you provide an example of how to use the Result and Option types in Rust?\n\n## Systems Programming\n\n```jsx\nBuild a system daemon that monitors system resource usage and logs events to a file using the Rust Standard Library. Use the log crate for logging and the signal-hook crate to handle system signals.\n```\n\nDevelop a network application that implements a custom protocol using Rust's TCP and UDP socket libraries. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\nCreate a file management tool that allows users to copy, move, and delete files and directories using Rust's standard filesystem library. Use the clap crate for command-line argument parsing and the indicatif crate for progress bars.\n\nBuild a simple web server that handles HTTP requests and serves static files using the Iron web framework and Rust's standard HTTP libraries. Use the chrono crate for handling dates and times and the openssl crate for secure communication.\n\nDevelop a low-level library for interfacing with a hardware device using Rust's Foreign Function Interface (FFI) and the libc crate. Use the crossbeam crate for safe concurrent programming and the rust-crypto crate for encryption and hashing.\n\nCreate a CLI tool that allows users to manipulate audio files using the Rust's audio crate. Use the clap crate for command-line argument parsing and the hound crate for audio file I/O.\n\nBuild a network daemon that listens for incoming connections and manages a pool of worker threads using Rust's standard thread libraries and the crossbeam-channel crate for inter-thread communication. Use the rustls crate for secure communication.\n\nDevelop a command-line tool for converting between different image formats using Rust's image processing library and the clap crate for command-line argument parsing. Use the rayon crate for parallel processing.\n\nCreate a system service that monitors a directory for changes and logs events to a file using the notify crate. Use the chrono crate for handling dates and times and the slog crate for logging.\n\nBuild a command-line tool that encrypts and decrypts files using Rust's cryptography libraries and the clap crate for command-line argument parsing. Use the rand crate for generating random numbers.\n\nDevelop a low-level library for interfacing with a Bluetooth device using Rust's FFI and the BlueZ Bluetooth stack. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\nCreate a CLI tool that allows users to manipulate PDF files using the Rust's PDF processing libraries and the clap crate for command-line argument parsing. Use the rayon crate for parallel processing.\n\nBuild a system daemon that monitors and logs changes to system configuration files using Rust's standard filesystem libraries and the notify crate. Use the serde crate for serialization and deserialization.\n\nDevelop a command-line tool that generates random passwords using Rust's cryptography libraries and the clap crate for command-line argument parsing. Use the rand crate for generating random numbers.\n\nCreate a low-level library for interfacing with a USB device using Rust's FFI and the libusb library. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\nBuild a command-line tool that allows users to manage system processes using Rust's standard process libraries and the clap crate for command-line argument parsing. Use the regex crate for string manipulation.\n\nDevelop a system daemon that manages a pool of worker threads and communicates with them using Rust's standard thread libraries and the crossbeam-channel crate. Use the chrono crate for handling dates and times and the slog crate for logging.\n\nCreate a low-level library for interfacing with a Serial device using Rust's FFI and the serialport library. Use the nix crate for low-level system programming and the futures crate for asynchronous programming.\n\n## DevOps\n\n```jsx\nBuild a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Rust's DevOps library, Rust CI/CD, and the Jenkins automation server. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n```\n\nDevelop a tool for infrastructure automation using Rust's DevOps library, Rust Chef, and the Chef configuration management tool. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container orchestration using Rust's DevOps library, Rust Kubernetes, and the Kubernetes container orchestration system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a serverless infrastructure using Rust's DevOps library, Rust Serverless, and the AWS Lambda service. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for continuous monitoring using Rust's DevOps library, Rust Prometheus, and the Prometheus monitoring system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for log management using Rust's DevOps library, Rust Logstash, and the Logstash logging pipeline. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Rust's DevOps library, Rust Travis, and the Travis CI/CD platform. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for infrastructure testing using Rust's DevOps library, Rust Terraform, and the Terraform infrastructure as code tool. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container security using Rust's DevOps library, Rust Clair, and the Clair container security scanner. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a serverless application using Rust's DevOps library, Rust AWS Lambda, and the AWS Lambda service. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for infrastructure visualization using Rust's DevOps library, Rust Graphviz, and the Graphviz graph visualization software. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container monitoring using Rust's DevOps library, Rust Prometheus, and the Prometheus monitoring system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a Continuous Integration/Continuous Deployment (CI/CD) pipeline using Rust's DevOps library, Rust CircleCI, and the CircleCI CI/CD platform. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nDevelop a tool for infrastructure as code using Rust's DevOps library, Rust Ansible, and the Ansible configuration management tool. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nCreate a tool for container orchestration using Rust's DevOps library, Rust Nomad, and the Nomad container orchestration system. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\nBuild a serverless application using Rust's DevOps library, Rust Google Cloud Functions, and the Google Cloud Functions service. Use the clap crate for command-line argument parsing and the serde crate for serialization and deserialization.\n\n[Download All the prompts free on Gumroad](https://godsol.gumroad.com/l/rust-prompts)\n*due to length constraints, this article contains less than half*","classes":{"dataset":0.3367263675}}
{"title":"Saturday Daily Thread: Resource Request and Sharing! Daily Thread","description":"Found a neat resource related to Python over the past week? Looking for a resource to explain a certain topic?\n\nUse this thread to chat about and share Python resources!","link":"https://www.reddit.com/r/Python/comments/11o54ib/saturday_daily_thread_resource_request_and/","created":"2023-03-11","tags":["reddit","python"],"meta":{"num_comments":2},"text":"Saturday Daily Thread: Resource Request and Sharing! Daily Thread Found a neat resource related to Python over the past week? Looking for a resource to explain a certain topic?\n\nUse this thread to chat about and share Python resources!","classes":{"dataset":0.4687213302}}
{"title":"Easy Python scripts to impress the business","description":"Hi Python Devs, which quick and easy scripts have you written that impressed the business and got you some kudos without requiring any real effort on your part?","link":"https://www.reddit.com/r/Python/comments/11olib6/easy_python_scripts_to_impress_the_business/","created":"2023-03-11","tags":["reddit","python"],"meta":{"num_comments":80},"text":"Easy Python scripts to impress the business Hi Python Devs, which quick and easy scripts have you written that impressed the business and got you some kudos without requiring any real effort on your part?","classes":{"dataset":0.5215418935}}
{"title":"Best places/ways to learn APIs for career progression?","description":"Looking for YT videos, chat chains, something to help me understand APIs and how to build them to use them effectively.","link":"https://www.reddit.com/r/Python/comments/11p4fd0/best_placesways_to_learn_apis_for_career/","created":"2023-03-12","tags":["reddit","python"],"meta":{"num_comments":5},"text":"Best places/ways to learn APIs for career progression? Looking for YT videos, chat chains, something to help me understand APIs and how to build them to use them effectively.","classes":{"dataset":0.2150852829}}
{"title":"Python Cybersecurity \u2014 Build your own python tools (PortScanner, Visual Network Tracker and Anonymous FTP Scanner)","description":"**Python Cybersecurity \u2014 PortScanner**\n\nBuild a simple Port Scanner using the Python Programming language. Port Scanner is an application designed to probe a server or host for open ports. Such an application may be used by administrators to verify security policies of their networks and by attackers to identify network services running on a host and exploit vulnerabilities.\n\n**Link**: [https://youtu.be/bH-3PuQC\\_n0](https://youtu.be/bH-3PuQC_n0)\n\n**Python Cybersecurity \u2014 Visual Network Tracker**\n\nDive into Network Traffic visualization using the Python programming language, Wireshark and Google Maps. This tutorial covers the implementation steps needed to take a file of network traffic and convert it into a visual presentation using Google Maps.\n\n**Link**: [https://youtu.be/xuNuy8n8u-Y](https://youtu.be/xuNuy8n8u-Y)\n\n**Python Cybersecurity \u2014 Anonymous FTP Scanner**\n\nBuild a simple FTP Scanner using the Python Programming language. Anonymous FTP is a means by which archive sites allow general access to their archives of information. These sites create a special account called \u201canonymous\u201d\n\n**Link**: [https://youtu.be/BIZfRodSW9w](https://youtu.be/BIZfRodSW9w)","link":"https://www.reddit.com/r/Python/comments/11ohb9e/python_cybersecurity_build_your_own_python_tools/","created":"2023-03-11","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Python Cybersecurity \u2014 Build your own python tools (PortScanner, Visual Network Tracker and Anonymous FTP Scanner) **Python Cybersecurity \u2014 PortScanner**\n\nBuild a simple Port Scanner using the Python Programming language. Port Scanner is an application designed to probe a server or host for open ports. Such an application may be used by administrators to verify security policies of their networks and by attackers to identify network services running on a host and exploit vulnerabilities.\n\n**Link**: [https://youtu.be/bH-3PuQC\\_n0](https://youtu.be/bH-3PuQC_n0)\n\n**Python Cybersecurity \u2014 Visual Network Tracker**\n\nDive into Network Traffic visualization using the Python programming language, Wireshark and Google Maps. This tutorial covers the implementation steps needed to take a file of network traffic and convert it into a visual presentation using Google Maps.\n\n**Link**: [https://youtu.be/xuNuy8n8u-Y](https://youtu.be/xuNuy8n8u-Y)\n\n**Python Cybersecurity \u2014 Anonymous FTP Scanner**\n\nBuild a simple FTP Scanner using the Python Programming language. Anonymous FTP is a means by which archive sites allow general access to their archives of information. These sites create a special account called \u201canonymous\u201d\n\n**Link**: [https://youtu.be/BIZfRodSW9w](https://youtu.be/BIZfRodSW9w)","classes":{"dataset":0.4613363445}}
{"title":"I made Flask-Squeeze 2.0, it squeezes responeses with minification and compression!","description":"Hi guys! I just wanted to share the Flask extension [Flask-Squeeze](https://github.com/mkrd/Flask-Squeeze) with you. It will minify HTML, JS and CSS, and compress responses with brotli, deflate, or gzip depending on the request, with almost zero configuration.\n\nI know there are other extensions aswell, but as far as I know, none of them have a complete feature set of minification AND compression.\nI just published version 2.0, which noch also includes HTML minification!\n\nLet me know what you think, and what else could be added :)","link":"https://www.reddit.com/r/Python/comments/11okzqb/i_made_flasksqueeze_20_it_squeezes_responeses/","created":"2023-03-11","tags":["reddit","python"],"meta":{"num_comments":9},"text":"I made Flask-Squeeze 2.0, it squeezes responeses with minification and compression! Hi guys! I just wanted to share the Flask extension [Flask-Squeeze](https://github.com/mkrd/Flask-Squeeze) with you. It will minify HTML, JS and CSS, and compress responses with brotli, deflate, or gzip depending on the request, with almost zero configuration.\n\nI know there are other extensions aswell, but as far as I know, none of them have a complete feature set of minification AND compression.\nI just published version 2.0, which noch also includes HTML minification!\n\nLet me know what you think, and what else could be added :)","classes":{"dataset":0.341206342}}
{"title":"Can you help me distinguish library, package, and module in python?","description":"While some tells pandas is a library, others tells it is a package. So I get confused.","link":"https://www.reddit.com/r/Python/comments/11p7g5w/can_you_help_me_distinguish_library_package_and/","created":"2023-03-12","tags":["reddit","python"],"meta":{"num_comments":3},"text":"Can you help me distinguish library, package, and module in python? While some tells pandas is a library, others tells it is a package. So I get confused.","classes":{"dataset":0.4247277677}}
{"title":"Cake Day - 1st Job","description":"Just wanted to celebrate my Reddit cake day by announcing that I may be getting my first programming job as I got an email today to be moved forward!!! That\u2019s all. Hope the best for you all.","link":"https://www.reddit.com/r/Python/comments/11o91ik/cake_day_1st_job/","created":"2023-03-11","tags":["reddit","python"],"meta":{"num_comments":20},"text":"Cake Day - 1st Job Just wanted to celebrate my Reddit cake day by announcing that I may be getting my first programming job as I got an email today to be moved forward!!! That\u2019s all. Hope the best for you all.","classes":{"dataset":0.1330454201}}
{"title":"\u00ab PhoneScan \u00bb find information of unknown phone number.","description":"M\u2019y friend based un china create a script in Python to retrieve informations of mobile number.(provider, country, and more\u2026\n\nThe code: https://github.com/L3xiuS/PhoneScanner","link":"https://www.reddit.com/r/Python/comments/11p43ah/phonescan_find_information_of_unknown_phone_number/","created":"2023-03-12","tags":["reddit","python"],"meta":{"num_comments":0},"text":"\u00ab PhoneScan \u00bb find information of unknown phone number. M\u2019y friend based un china create a script in Python to retrieve informations of mobile number.(provider, country, and more\u2026\n\nThe code: https://github.com/L3xiuS/PhoneScanner","classes":{"dataset":0.3513635397}}
{"title":"[GlassJar] Stores records as Python objects in the database!","description":"Hi guys!\n\nI created a pickled-based database for storing Python objects. [GlassJar](https://github.com/furkanonder/glassjar) is a database that, unlike other databases, stores records as Python objects in the database and allows you to use them with ORM.\n\n*Let's look at the small example;*\n\nNormally, we can't directly store the Python dict in a database. But in the [GlassJar](https://github.com/furkanonder/glassjar) we can do that!\n\n    &gt;&gt; from glassjar.model import Model\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; class Item(Model):\n    ...     name: str\n    ...     attrs: dict\n    ...\n    &gt;&gt;&gt; item = Item.records.create(name=\"item\", attrs={\"color\": \"red\", \"shape\":\"rectangle\"})\n    &gt;&gt;&gt; item.as_dict()\n    {'name': 'item', 'attrs': {'color': 'red', 'shape': 'rectangle'}}\n    &gt;&gt;&gt; item2 = Item.records.create(name=\"item 2\", attrs={\"color\": \"blue\", \"shape\":\"triangle\"})\n    &gt;&gt;&gt; Item.records.first()\n    Item(name='item', attrs={'color': 'red', 'shape': 'rectangle'})\n    &gt;&gt;&gt; Item.records.last()\n    Item(name='item 2', attrs={'color': 'blue', 'shape': 'triangle'})\n    &gt;&gt;&gt;\n\nCheck out our [documentation](https://furkanonder.github.io/glassjar/) to learn more!","link":"https://www.reddit.com/r/Python/comments/11oh9jc/glassjar_stores_records_as_python_objects_in_the/","created":"2023-03-11","tags":["reddit","python"],"meta":{"num_comments":22},"text":"[GlassJar] Stores records as Python objects in the database! Hi guys!\n\nI created a pickled-based database for storing Python objects. [GlassJar](https://github.com/furkanonder/glassjar) is a database that, unlike other databases, stores records as Python objects in the database and allows you to use them with ORM.\n\n*Let's look at the small example;*\n\nNormally, we can't directly store the Python dict in a database. But in the [GlassJar](https://github.com/furkanonder/glassjar) we can do that!\n\n    &gt;&gt; from glassjar.model import Model\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; class Item(Model):\n    ...     name: str\n    ...     attrs: dict\n    ...\n    &gt;&gt;&gt; item = Item.records.create(name=\"item\", attrs={\"color\": \"red\", \"shape\":\"rectangle\"})\n    &gt;&gt;&gt; item.as_dict()\n    {'name': 'item', 'attrs': {'color': 'red', 'shape': 'rectangle'}}\n    &gt;&gt;&gt; item2 = Item.records.create(name=\"item 2\", attrs={\"color\": \"blue\", \"shape\":\"triangle\"})\n    &gt;&gt;&gt; Item.records.first()\n    Item(name='item', attrs={'color': 'red', 'shape': 'rectangle'})\n    &gt;&gt;&gt; Item.records.last()\n    Item(name='item 2', attrs={'color': 'blue', 'shape': 'triangle'})\n    &gt;&gt;&gt;\n\nCheck out our [documentation](https://furkanonder.github.io/glassjar/) to learn more!","classes":{"dataset":0.1312036067}}
{"title":"How to fix the format","description":"hello, im working on my gui project using tkinter,\n\ni want to execute other .py file in my gui, but the thing is if i do the function like this :\n\nos.system('python3 \"/full/path/name.py\"')\n\nit works,\n\nbut when i do it like this :\n\nos.system(\"'\"+\"python3 \"+ ED\\_entry.get()+ \"'\")\n\nit doesnt work..\n\nanyone knows how can i arrange ED\\_entry.get() value so it can have the same format as the first code?\n\nThank you","link":"https://www.reddit.com/r/Python/comments/11p119h/how_to_fix_the_format/","created":"2023-03-12","tags":["reddit","python"],"meta":{"num_comments":3},"text":"How to fix the format hello, im working on my gui project using tkinter,\n\ni want to execute other .py file in my gui, but the thing is if i do the function like this :\n\nos.system('python3 \"/full/path/name.py\"')\n\nit works,\n\nbut when i do it like this :\n\nos.system(\"'\"+\"python3 \"+ ED\\_entry.get()+ \"'\")\n\nit doesnt work..\n\nanyone knows how can i arrange ED\\_entry.get() value so it can have the same format as the first code?\n\nThank you","classes":{"dataset":0.3320553601}}
{"title":"IndexError: single positional indexer is out-of-bounds","description":"Getting following error - any help would be much appreciated\n\nIndexError: single positional indexer is out-of-bounds\n\n&amp;#x200B;\n\n    import pandas as pd\n    import yfinance as yf\n    from datetime import datetime\n    \n    # Define the ticker symbol for ES (E-mini S&amp;P 500 Futures)\n    ticker_symbol = \"^ES\"\n    \n    # Define the start and end dates for the data\n    start_date = \"2020-01-01\"\n    end_date = datetime.today().strftime('%Y-%m-%d')  # Today's date\n    \n    # Get the data from Yahoo Finance using yfinance library\n    data = yf.download(ticker_symbol, start=start_date, end=end_date)\n    \n    # Define the periods for the SMAs and EMAs\n    sma_periods = [21, 50, 100, 200]\n    ema_periods = [21, 50, 100, 200]\n    \n    # Calculate the SMAs using Pandas rolling() function\n    sma_output = []\n    for period in sma_periods:\n        sma = data['Close'].rolling(window=period).mean()\n        sma_output.append([f\"{period}-SMA\", sma.iloc[-1]])\n    \n    # Calculate the EMAs using Pandas ewm() function\n    ema_output = []\n    for period in ema_periods:\n        ema = data['Close'].ewm(span=period, adjust=False).mean()\n        ema_output.append([f\"{period}-EMA\", ema.iloc[-1]])\n    \n    # Print the output with headers\n    print(\"{:&lt;10} {:&lt;10} {:&lt;10}\".format('Type', 'Period', 'Value'))\n    for row in sma_output + ema_output:\n        print(\"{:&lt;10} {:&lt;10} {:&lt;10.2f}\".format(row[0], row[1], row[2]))","link":"https://www.reddit.com/r/Python/comments/11osiy1/indexerror_single_positional_indexer_is/","created":"2023-03-11","tags":["reddit","python"],"meta":{"num_comments":3},"text":"IndexError: single positional indexer is out-of-bounds Getting following error - any help would be much appreciated\n\nIndexError: single positional indexer is out-of-bounds\n\n&amp;#x200B;\n\n    import pandas as pd\n    import yfinance as yf\n    from datetime import datetime\n    \n    # Define the ticker symbol for ES (E-mini S&amp;P 500 Futures)\n    ticker_symbol = \"^ES\"\n    \n    # Define the start and end dates for the data\n    start_date = \"2020-01-01\"\n    end_date = datetime.today().strftime('%Y-%m-%d')  # Today's date\n    \n    # Get the data from Yahoo Finance using yfinance library\n    data = yf.download(ticker_symbol, start=start_date, end=end_date)\n    \n    # Define the periods for the SMAs and EMAs\n    sma_periods = [21, 50, 100, 200]\n    ema_periods = [21, 50, 100, 200]\n    \n    # Calculate the SMAs using Pandas rolling() function\n    sma_output = []\n    for period in sma_periods:\n        sma = data['Close'].rolling(window=period).mean()\n        sma_output.append([f\"{period}-SMA\", sma.iloc[-1]])\n    \n    # Calculate the EMAs using Pandas ewm() function\n    ema_output = []\n    for period in ema_periods:\n        ema = data['Close'].ewm(span=period, adjust=False).mean()\n        ema_output.append([f\"{period}-EMA\", ema.iloc[-1]])\n    \n    # Print the output with headers\n    print(\"{:&lt;10} {:&lt;10} {:&lt;10}\".format('Type', 'Period', 'Value'))\n    for row in sma_output + ema_output:\n        print(\"{:&lt;10} {:&lt;10} {:&lt;10.2f}\".format(row[0], row[1], row[2]))","classes":{"dataset":0.6299802065}}
{"title":"Text2Image using ControlNet and Stable Diffusion","description":"In this tutorial, we will show you how to create beautiful and high-quality images from text using the powerful combination of diffusion model and ControlNet. \n\nText2Image generation is a fascinating field of AI that enables machines to understand and visualize human language in a more creative way.\n\n we will walk you through the step-by-step process of how to use the diffusion model and ControlNet to generate images from text. By the end of this tutorial, you will have a thorough understanding of text2image generation and how to use diffusion model and ControlNet to create stunning images from text. You will also have the knowledge and skills to apply these techniques to your own projects and experiments.\n\n So, get ready to dive into the exciting world of text2image generation and start creating your own beautiful images from text today!\n\nhttps://youtu.be/0D5Nlo2REb0","link":"https://www.reddit.com/r/deeplearning/comments/11p1par/text2image_using_controlnet_and_stable_diffusion/","created":"2023-03-12","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":0},"text":"Text2Image using ControlNet and Stable Diffusion In this tutorial, we will show you how to create beautiful and high-quality images from text using the powerful combination of diffusion model and ControlNet. \n\nText2Image generation is a fascinating field of AI that enables machines to understand and visualize human language in a more creative way.\n\n we will walk you through the step-by-step process of how to use the diffusion model and ControlNet to generate images from text. By the end of this tutorial, you will have a thorough understanding of text2image generation and how to use diffusion model and ControlNet to create stunning images from text. You will also have the knowledge and skills to apply these techniques to your own projects and experiments.\n\n So, get ready to dive into the exciting world of text2image generation and start creating your own beautiful images from text today!\n\nhttps://youtu.be/0D5Nlo2REb0","classes":{"dataset":0.3048008978}}
{"title":"https://www.kaggle.com/code/sadikaljarif/plant-disease-classification-using-mobilenetv2","description":"# About Dataset\n\n# This dataset is recreated using offline augmentation from the original dataset. The original dataset can be found on [this](https://github.com/spMohanty/PlantVillage-Dataset) github repo. This dataset consists of about 87K rgb images of healthy and diseased crop leaves which is categorized into 38 different classes. The total dataset is divided into 80/20 ratio of training and validation set preserving the directory structure. A new directory containing 33 test images is created later for prediction purpose\n\n# Notebook : [https://www.kaggle.com/code/sadikaljarif/plant-disease-classification-using-mobilenetv2](https://www.kaggle.com/code/sadikaljarif/plant-disease-classification-using-mobilenetv2)","link":"https://www.reddit.com/r/deeplearning/comments/11otmgd/httpswwwkagglecomcodesadikaljarifplantdiseaseclass/","created":"2023-03-11","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":0},"text":"https://www.kaggle.com/code/sadikaljarif/plant-disease-classification-using-mobilenetv2 # About Dataset\n\n# This dataset is recreated using offline augmentation from the original dataset. The original dataset can be found on [this](https://github.com/spMohanty/PlantVillage-Dataset) github repo. This dataset consists of about 87K rgb images of healthy and diseased crop leaves which is categorized into 38 different classes. The total dataset is divided into 80/20 ratio of training and validation set preserving the directory structure. A new directory containing 33 test images is created later for prediction purpose\n\n# Notebook : [https://www.kaggle.com/code/sadikaljarif/plant-disease-classification-using-mobilenetv2](https://www.kaggle.com/code/sadikaljarif/plant-disease-classification-using-mobilenetv2)","classes":{"dataset":0.435536176}}
{"title":"(Python) Library for deep video generation?","description":"I'm searching for a library that allows the creation of artificial interview like video sequences for an input text\n\nAre there any libraries like this or would the best approach be to choose an existing video and use deep fake libraries with artificial faces?","link":"https://www.reddit.com/r/deeplearning/comments/11oo3dj/python_library_for_deep_video_generation/","created":"2023-03-11","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":0},"text":"(Python) Library for deep video generation? I'm searching for a library that allows the creation of artificial interview like video sequences for an input text\n\nAre there any libraries like this or would the best approach be to choose an existing video and use deep fake libraries with artificial faces?","classes":{"dataset":0.305816561}}
{"title":"How to code a PPO neural network in java","description":"Hello,\n\nI am trying to find out how to make a RL neural network in java, probably using PPO ig? The problem is, that I am too lazy to do it myself, so I tried to find some library, but I wasn't very successful with finding some examples how to use anything. This is my first time I am trying to make a neural network in java (I've used them in other languages, but I have to use java this time), so I am a total noob in this field. So, can you recommend me some libraries? I found DL4J, but I didn't find anything about how to use ppo to train networks with it.\n\nThanks for any response","link":"https://www.reddit.com/r/deeplearning/comments/11oo58v/how_to_code_a_ppo_neural_network_in_java/","created":"2023-03-11","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":7},"text":"How to code a PPO neural network in java Hello,\n\nI am trying to find out how to make a RL neural network in java, probably using PPO ig? The problem is, that I am too lazy to do it myself, so I tried to find some library, but I wasn't very successful with finding some examples how to use anything. This is my first time I am trying to make a neural network in java (I've used them in other languages, but I have to use java this time), so I am a total noob in this field. So, can you recommend me some libraries? I found DL4J, but I didn't find anything about how to use ppo to train networks with it.\n\nThanks for any response","classes":{"dataset":0.1568749547}}
{"title":"Neural Networks for Computational Biophysics","description":"Hello everyone, I'm trying to replicate the results of this paper: \n\nhttps://aip.scitation.org/doi/full/10.1063/1.5110439?casa_token=52rwZkP90dMAAAAA%3AIdHJU3k3uhc_UbnBxhpt37SY3k_3SDGyoDTdRNt1ZhqlYyahdUzcCy1XlvnpGctKHn3sqJFYDBA\n\nHowever, I'm having some difficulties in understanding how this (especially equation 16) can work. My understanding of gradient descent is that, on an operative level, one must calculate a loss between the true label of the sample and the output of the network, and perform the backpropagation accordingly. However, this is a case of unsupervised learning and I don't really know how to go from eq (16) in the paper, to a \"rule\" that modifies the weights of the network. \n\nIf someone can help me out, they will be thanked in my master thesis \u2764\ufe0f","link":"https://www.reddit.com/r/deeplearning/comments/11ntblu/neural_networks_for_computational_biophysics/","created":"2023-03-10","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":1},"text":"Neural Networks for Computational Biophysics Hello everyone, I'm trying to replicate the results of this paper: \n\nhttps://aip.scitation.org/doi/full/10.1063/1.5110439?casa_token=52rwZkP90dMAAAAA%3AIdHJU3k3uhc_UbnBxhpt37SY3k_3SDGyoDTdRNt1ZhqlYyahdUzcCy1XlvnpGctKHn3sqJFYDBA\n\nHowever, I'm having some difficulties in understanding how this (especially equation 16) can work. My understanding of gradient descent is that, on an operative level, one must calculate a loss between the true label of the sample and the output of the network, and perform the backpropagation accordingly. However, this is a case of unsupervised learning and I don't really know how to go from eq (16) in the paper, to a \"rule\" that modifies the weights of the network. \n\nIf someone can help me out, they will be thanked in my master thesis \u2764\ufe0f","classes":{"dataset":0.1797021627}}
{"title":"Does Reinforcement learning algorithm will do the job ?","description":"Hey\n\n I'm trying to make an algorithm that learns to play Yahtzee and maximizes the win or the score depending on what I manage to do \n\nI'm totally new, I watched a lot of videos, I read wikipedia but I don't know in which direction to go I tell myself that doing deep learning with a coupled neural network seems to correspond \n\nI imagine having the algorithm play around ten games and average the scores squared \n\nThen keep the best ones and include mutation\n\n I saw that it was related to the Markov problem, well as you can see it's going all over the place and I don't know where to start","link":"https://www.reddit.com/r/deeplearning/comments/11nxfkh/does_reinforcement_learning_algorithm_will_do_the/","created":"2023-03-10","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":2},"text":"Does Reinforcement learning algorithm will do the job ? Hey\n\n I'm trying to make an algorithm that learns to play Yahtzee and maximizes the win or the score depending on what I manage to do \n\nI'm totally new, I watched a lot of videos, I read wikipedia but I don't know in which direction to go I tell myself that doing deep learning with a coupled neural network seems to correspond \n\nI imagine having the algorithm play around ten games and average the scores squared \n\nThen keep the best ones and include mutation\n\n I saw that it was related to the Markov problem, well as you can see it's going all over the place and I don't know where to start","classes":{"dataset":0.3595617115}}
{"title":"[D] Version 2.1 of the Open Deep Learning Toolkit for Robotics is already available!","description":" The latest version of the Open Deep Learning Toolkit for Robotics, **Version 2.1 is already available !**\n\nThis new version includes the following updates:\n\n**New Features:**\n\n* Added Efficient LiDAR Panoptic Segmentation\n* Added Nanodet 2D Object Detection tool\u00a0\n* Added C API implementations of NanoDet 2D Object Detection tool\n* Added C API implementations of forward pass of DETR 2D Object Detection tool\n* Added C API implementations of forward pass of DeepSORT 2D Object Tracking tool\u00a0\n* Added C API implementations of forward pass of Lightweight OpenPose, Pose Estimator tool\n* Added C API implementations of forward pass of X3D 2D Activity Recognition tool\u00a0\n* Added C API implementations of forward pass of Progressive Spatiotemporal GCN Skeleton-based Action Recognition tool\n* Added Binary High Resolution Analysis tool\n* Added Multi-Object-Search tool\u00a0\n\n***Enhancements***\n\n* Added support in C API for detection target structure and vector of detections\u00a0\n* Added support in C API for tensor structure and vector of tensors\n* Added support in C API for json parser\u00a0\n\nYou can download the toolkit here:  \n\\- GitHub: [https://github.com/opendr-eu/opendr](https://github.com/opendr-eu/opendr)\n\n\\- pip: [https://pypi.org/project/opendr-toolkit/](https://pypi.org/project/opendr-toolkit/)  \n\\- Docker Hub: [https://hub.docker.com/r/opendr/opendr-toolkit/tags](https://hub.docker.com/r/opendr/opendr-toolkit/tags)\n\nLooking forward for your comments and suggestions!","link":"https://www.reddit.com/r/deeplearning/comments/11nv4lq/d_version_21_of_the_open_deep_learning_toolkit/","created":"2023-03-10","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":0},"text":"[D] Version 2.1 of the Open Deep Learning Toolkit for Robotics is already available!  The latest version of the Open Deep Learning Toolkit for Robotics, **Version 2.1 is already available !**\n\nThis new version includes the following updates:\n\n**New Features:**\n\n* Added Efficient LiDAR Panoptic Segmentation\n* Added Nanodet 2D Object Detection tool\u00a0\n* Added C API implementations of NanoDet 2D Object Detection tool\n* Added C API implementations of forward pass of DETR 2D Object Detection tool\n* Added C API implementations of forward pass of DeepSORT 2D Object Tracking tool\u00a0\n* Added C API implementations of forward pass of Lightweight OpenPose, Pose Estimator tool\n* Added C API implementations of forward pass of X3D 2D Activity Recognition tool\u00a0\n* Added C API implementations of forward pass of Progressive Spatiotemporal GCN Skeleton-based Action Recognition tool\n* Added Binary High Resolution Analysis tool\n* Added Multi-Object-Search tool\u00a0\n\n***Enhancements***\n\n* Added support in C API for detection target structure and vector of detections\u00a0\n* Added support in C API for tensor structure and vector of tensors\n* Added support in C API for json parser\u00a0\n\nYou can download the toolkit here:  \n\\- GitHub: [https://github.com/opendr-eu/opendr](https://github.com/opendr-eu/opendr)\n\n\\- pip: [https://pypi.org/project/opendr-toolkit/](https://pypi.org/project/opendr-toolkit/)  \n\\- Docker Hub: [https://hub.docker.com/r/opendr/opendr-toolkit/tags](https://hub.docker.com/r/opendr/opendr-toolkit/tags)\n\nLooking forward for your comments and suggestions!","classes":{"dataset":0.4155764282}}
{"title":"OpenAI's Python API walk-through","description":"If you are getting started with OpenAI's newest Python API, you don't have to spend too much time familiarising yourself with how to use it. Here is a video that walks through the different possiblities, API parameters and finally shares a demo app: [https://youtu.be/dcnfhtuL7qA](https://youtu.be/dcnfhtuL7qA) \n\nHope its useful. \n\nhttps://preview.redd.it/z1aczihy2xma1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5b749e1485746ce0beeb1f19cc878109d146a2a7","link":"https://www.reddit.com/r/deeplearning/comments/11npswy/openais_python_api_walkthrough/","created":"2023-03-10","tags":["ml","deeplearning","reddit"],"meta":{"num_comments":0},"text":"OpenAI's Python API walk-through If you are getting started with OpenAI's newest Python API, you don't have to spend too much time familiarising yourself with how to use it. Here is a video that walks through the different possiblities, API parameters and finally shares a demo app: [https://youtu.be/dcnfhtuL7qA](https://youtu.be/dcnfhtuL7qA) \n\nHope its useful. \n\nhttps://preview.redd.it/z1aczihy2xma1.png?width=1920&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5b749e1485746ce0beeb1f19cc878109d146a2a7","classes":{"dataset":0.4886731207}}
{"title":"[P] vanilla-llama an hackable plain-pytorch implementation of LLaMA that can be run on any system (if you have enough resources)","description":"I put together this plain pytorch implementation of LLaMA (i just substituted the fairscale layers with the native ones and converted the weights accordingly) that can be more easily run in different environments. \n\nThe big problem with the official implementation is that in order to run the 65B version you need 8 GPUs no matter what, and to run the 30B version you need 4 and so on. In reality you can easily fit the 65B version in 2 A100 with 100G of VRAM.\n\nvanilla-llama solves this problem. You just need to have enough memory and the model will be load in all the available GPUs.\n\n&amp;#x200B;\n\n[https://github.com/galatolofederico/vanilla-llama](https://github.com/galatolofederico/vanilla-llama)","link":"https://www.reddit.com/r/MachineLearning/comments/11ozl85/p_vanillallama_an_hackable_plainpytorch/","created":"2023-03-12","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":3},"text":"[P] vanilla-llama an hackable plain-pytorch implementation of LLaMA that can be run on any system (if you have enough resources) I put together this plain pytorch implementation of LLaMA (i just substituted the fairscale layers with the native ones and converted the weights accordingly) that can be more easily run in different environments. \n\nThe big problem with the official implementation is that in order to run the 65B version you need 8 GPUs no matter what, and to run the 30B version you need 4 and so on. In reality you can easily fit the 65B version in 2 A100 with 100G of VRAM.\n\nvanilla-llama solves this problem. You just need to have enough memory and the model will be load in all the available GPUs.\n\n&amp;#x200B;\n\n[https://github.com/galatolofederico/vanilla-llama](https://github.com/galatolofederico/vanilla-llama)","classes":{"dataset":0.1550450772}}
{"title":"[D] Tracking Dancing People","description":" \n\nHi everyone!\n\nOne interesting problem has been posed to me!\n\nGiven people dancing in a video, tracking a single one. The reference video I have been given is: [https://www.youtube.com/watch?v=g0BvpzR\\_2MQ](https://www.youtube.com/watch?v=g0BvpzR_2MQ).   As you will see in the video, occlusions happen an incredible amount,  and they are all wearing roughly similar clothing. Further, sometimes  the people get off screen, then come back on.\n\nI  have tried many different things, but I am unable to find a good way to  track a single person, as the re-identification is iffy.\n\nAny help would be appreciated!","link":"https://www.reddit.com/r/MachineLearning/comments/11p9p67/d_tracking_dancing_people/","created":"2023-03-12","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":0},"text":"[D] Tracking Dancing People  \n\nHi everyone!\n\nOne interesting problem has been posed to me!\n\nGiven people dancing in a video, tracking a single one. The reference video I have been given is: [https://www.youtube.com/watch?v=g0BvpzR\\_2MQ](https://www.youtube.com/watch?v=g0BvpzR_2MQ).   As you will see in the video, occlusions happen an incredible amount,  and they are all wearing roughly similar clothing. Further, sometimes  the people get off screen, then come back on.\n\nI  have tried many different things, but I am unable to find a good way to  track a single person, as the re-identification is iffy.\n\nAny help would be appreciated!","classes":{"dataset":0.0187690724}}
{"title":"[D] Unsupervised Learning \u2014 have there been any big advances recently?","description":"I feel like unsupervised learning models have always been the less-sexy part of machine learning. There's been some interesting solutions like scBERT and others in the space of single-cell RNAseq, but other than that it seems like clustering, dimensionality reduction, etc, has been mostly the same for years now.\n\nWhat big stuff has come out, and what's on the radar?","link":"https://www.reddit.com/r/MachineLearning/comments/11onol2/d_unsupervised_learning_have_there_been_any_big/","created":"2023-03-11","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":9},"text":"[D] Unsupervised Learning \u2014 have there been any big advances recently? I feel like unsupervised learning models have always been the less-sexy part of machine learning. There's been some interesting solutions like scBERT and others in the space of single-cell RNAseq, but other than that it seems like clustering, dimensionality reduction, etc, has been mostly the same for years now.\n\nWhat big stuff has come out, and what's on the radar?","classes":{"dataset":0.3642827272}}
{"title":"[D] Statsmodels ARIMA model predict function not working","description":"I trained my ARIMA model by doing the following\n\n`from statsmodels.tsa.arima.model import ARIMA`\n\n`model_ar = ARIMA(data.Num_Passengers, order=(1,0, 0))`\n\n`results_ar = model_ar.fit()results_ar.summary()`\n\n&amp;#x200B;\n\nThe code worked with the resulting output\n\n&amp;#x200B;\n\nhttps://preview.redd.it/zi8f1lhak5na1.png?width=746&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3f5ef9fe1504892e4ce48b5287d8b834f1dfdb27\n\nBut then I tried predicting on the testing dataset, and I got the following error.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/uni7ws1ck5na1.png?width=1675&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ce520334f3b1e420a101adda9f43868714617272\n\nAm I just messing something up, is anyone else dealing with this error?\n\nIs there another way to use the predict function, or is it really unimplemented.\n\nCould you please help me out with this?\n\nHow would I overwrite the method?","link":"https://www.reddit.com/r/MachineLearning/comments/11or4qb/d_statsmodels_arima_model_predict_function_not/","created":"2023-03-11","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":4},"text":"[D] Statsmodels ARIMA model predict function not working I trained my ARIMA model by doing the following\n\n`from statsmodels.tsa.arima.model import ARIMA`\n\n`model_ar = ARIMA(data.Num_Passengers, order=(1,0, 0))`\n\n`results_ar = model_ar.fit()results_ar.summary()`\n\n&amp;#x200B;\n\nThe code worked with the resulting output\n\n&amp;#x200B;\n\nhttps://preview.redd.it/zi8f1lhak5na1.png?width=746&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3f5ef9fe1504892e4ce48b5287d8b834f1dfdb27\n\nBut then I tried predicting on the testing dataset, and I got the following error.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/uni7ws1ck5na1.png?width=1675&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ce520334f3b1e420a101adda9f43868714617272\n\nAm I just messing something up, is anyone else dealing with this error?\n\nIs there another way to use the predict function, or is it really unimplemented.\n\nCould you please help me out with this?\n\nHow would I overwrite the method?","classes":{"dataset":0.2856805921}}
{"title":"[P] RWKV 14B is a strong chatbot despite only trained on Pile (16G VRAM for 14B ctx4096 INT8, more optimizations incoming)","description":"The latest CharRWKV v2 has a new chat prompt (works for any topic), and here are some raw user chats with RWKV-4-Pile-14B-20230228-ctx4096-test663 model (topp=0.85, temp=1.0, presence penalty 0.2, frequency penalty 0.5). You are welcome to try ChatRWKV v2:  [https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nAnd please keep in mind that RWKV is 100% RNN :) Pile v1 date cutoff is year 2020.\n\n[Chat #1](https://preview.redd.it/ripvptomexma1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=29ed1cd499dc4d693dee32ad7550a7910402d033)\n\n[Chat #2](https://preview.redd.it/8t75njnnexma1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d20186f2e423d321817b79e6e559dc74a42bf0b8)\n\nThese are surprisingly good because RWKV is only trained on the Pile (and 100% RNN). No finetuning. No instruct tuning. No RLHF. You are welcome to try it.\n\n1. Update ChatRWKV v2 \\[and rwkv pip package\\] to latest version.\n2. Use  [https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth](https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth)\n3. Run v2/chat.py and enjoy.\n\nChatRWKV v2 supports INT8 now (with my crappy slow quantization, **works for windows, supports any GPU**, 16G VRAM for 14B if you offload final layer to CPU). And you can offload more layers to CPU to run it with 3G VRAM though that will be very slow :) More optimizations are coming.\n\nOr you can try the 7B model (less coherency) and 3B model (not very coherent, but still fun).","link":"https://www.reddit.com/r/MachineLearning/comments/11nre6t/p_rwkv_14b_is_a_strong_chatbot_despite_only/","created":"2023-03-10","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":29},"text":"[P] RWKV 14B is a strong chatbot despite only trained on Pile (16G VRAM for 14B ctx4096 INT8, more optimizations incoming) The latest CharRWKV v2 has a new chat prompt (works for any topic), and here are some raw user chats with RWKV-4-Pile-14B-20230228-ctx4096-test663 model (topp=0.85, temp=1.0, presence penalty 0.2, frequency penalty 0.5). You are welcome to try ChatRWKV v2:  [https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nAnd please keep in mind that RWKV is 100% RNN :) Pile v1 date cutoff is year 2020.\n\n[Chat #1](https://preview.redd.it/ripvptomexma1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=29ed1cd499dc4d693dee32ad7550a7910402d033)\n\n[Chat #2](https://preview.redd.it/8t75njnnexma1.png?width=438&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=d20186f2e423d321817b79e6e559dc74a42bf0b8)\n\nThese are surprisingly good because RWKV is only trained on the Pile (and 100% RNN). No finetuning. No instruct tuning. No RLHF. You are welcome to try it.\n\n1. Update ChatRWKV v2 \\[and rwkv pip package\\] to latest version.\n2. Use  [https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth](https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth)\n3. Run v2/chat.py and enjoy.\n\nChatRWKV v2 supports INT8 now (with my crappy slow quantization, **works for windows, supports any GPU**, 16G VRAM for 14B if you offload final layer to CPU). And you can offload more layers to CPU to run it with 3G VRAM though that will be very slow :) More optimizations are coming.\n\nOr you can try the 7B model (less coherency) and 3B model (not very coherent, but still fun).","classes":{"dataset":0.3145579398}}
{"title":"[D] Looking for eye gaze detection dataset","description":" I have a project in my university where i have to make a CNN able to predict where the person is looking on a laptop screen using the webcam of the laptop, does anyone know where i can find data sets that can help me train the network","link":"https://www.reddit.com/r/MachineLearning/comments/11oqhhj/d_looking_for_eye_gaze_detection_dataset/","created":"2023-03-11","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":4},"text":"[D] Looking for eye gaze detection dataset  I have a project in my university where i have to make a CNN able to predict where the person is looking on a laptop screen using the webcam of the laptop, does anyone know where i can find data sets that can help me train the network","classes":{"dataset":0.1424123943}}
{"title":"[D] Input size equal to seasonality for timeseries forecasting","description":"When doing timeseries forecasting with models like NHits or NBEATS, does it make sense to set the model's input size according to the seasonality of the timeseries? Does it improve performance empirically?\n\nFor example NBEATS uses a \"seasonality block\" for interpretable forecasting and one would expect that this is where the seasonality is learnt. Then does it make sense to have a variable input size to the model where we find the seasonality length and use that as the size of the input window that the model sees?\n\nWould this scheme actually improve performance or is it just the increase in input size that might lead to better results?","link":"https://www.reddit.com/r/MachineLearning/comments/11oh727/d_input_size_equal_to_seasonality_for_timeseries/","created":"2023-03-11","tags":["reddit","machinelearning","ml"],"meta":{"num_comments":1},"text":"[D] Input size equal to seasonality for timeseries forecasting When doing timeseries forecasting with models like NHits or NBEATS, does it make sense to set the model's input size according to the seasonality of the timeseries? Does it improve performance empirically?\n\nFor example NBEATS uses a \"seasonality block\" for interpretable forecasting and one would expect that this is where the seasonality is learnt. Then does it make sense to have a variable input size to the model where we find the seasonality length and use that as the size of the input window that the model sees?\n\nWould this scheme actually improve performance or is it just the increase in input size that might lead to better results?","classes":{"dataset":0.5060260296}}
{"title":"Best approach for sarcasm subcategory classification?","description":" Hi All,\n\nI  am currently working on my thesis which is attempting to build on  existing research in the field of sarcasm detection within NLP and  sentiment analysis. The task outlined is to basically build a model  which can identify subcategories of sarcasm (e.g. irony, overstatement,  rhetorical questions etc.). The dataset includes values for whether a  phrase is sarcastic or not, and which subcategories the phrase fits into  (there can be overlap between categories). I have fine-tuned BERT for  sarcasm detection and this works fine but that isn't really the task. My  questions are twofold essentially:\n\n\\-  Is the solely transformer-based approach useful in this instance, given  that it could build on existing research where previous scores obtained  in this task were fairly low. If so, does anyone have any resources on  how to build a multi-subclass classification model, or would it be  better to build separate models for each task?\n\n\\-  Would attempting to use a rule-based approach be more valuable e.g.  using vector semantics and embeddings to attempt to identify the  subcategories using this approach, and if so are there any particular  resources I should have a look at to understand how to implement this in  code? I am currently reading Jurafsky &amp; Martin's 3rd draft of  Speech and Language Processing, but I am unclear on how I could use this  to categorise the subcategories which are difficult to define by  linguistic experts as it is?\n\nI'm  sorry if this is a bit rambling and all over the place, I'm feeling  pretty lost and stressed, but happy to answer any questions and try to  clarify anything :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11ok7ug/best_approach_for_sarcasm_subcategory/","created":"2023-03-11","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":4},"text":"Best approach for sarcasm subcategory classification?  Hi All,\n\nI  am currently working on my thesis which is attempting to build on  existing research in the field of sarcasm detection within NLP and  sentiment analysis. The task outlined is to basically build a model  which can identify subcategories of sarcasm (e.g. irony, overstatement,  rhetorical questions etc.). The dataset includes values for whether a  phrase is sarcastic or not, and which subcategories the phrase fits into  (there can be overlap between categories). I have fine-tuned BERT for  sarcasm detection and this works fine but that isn't really the task. My  questions are twofold essentially:\n\n\\-  Is the solely transformer-based approach useful in this instance, given  that it could build on existing research where previous scores obtained  in this task were fairly low. If so, does anyone have any resources on  how to build a multi-subclass classification model, or would it be  better to build separate models for each task?\n\n\\-  Would attempting to use a rule-based approach be more valuable e.g.  using vector semantics and embeddings to attempt to identify the  subcategories using this approach, and if so are there any particular  resources I should have a look at to understand how to implement this in  code? I am currently reading Jurafsky &amp; Martin's 3rd draft of  Speech and Language Processing, but I am unclear on how I could use this  to categorise the subcategories which are difficult to define by  linguistic experts as it is?\n\nI'm  sorry if this is a bit rambling and all over the place, I'm feeling  pretty lost and stressed, but happy to answer any questions and try to  clarify anything :)","classes":{"dataset":0.3677758873}}
{"title":"How to interpret actions","description":"Hey guys, I would like to be able to extract actions along with their objects. For example, in the sentence \"Paint all the walls red and hide all the doors and windows.\", I would like to extract the verbs \"paint\" and \"hide\", the objects \"walls, doors, windows\", the relationships \"paint-&gt;walls\", \"hide-&gt;doors, windows\", and the adverb relationship \"paint-&gt;red\".\n\nWhat tools/techniques would you suggest? Is deep learning the way to go?\n\n[Spacy](https://spacy.io/usage/rule-based-matching#dependencymatcher) and [Stanza](https://stanfordnlp.github.io/stanza/available\\_models.html) look promising, but I am not sure.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11nozbv/how_to_interpret_actions/","created":"2023-03-10","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":4},"text":"How to interpret actions Hey guys, I would like to be able to extract actions along with their objects. For example, in the sentence \"Paint all the walls red and hide all the doors and windows.\", I would like to extract the verbs \"paint\" and \"hide\", the objects \"walls, doors, windows\", the relationships \"paint-&gt;walls\", \"hide-&gt;doors, windows\", and the adverb relationship \"paint-&gt;red\".\n\nWhat tools/techniques would you suggest? Is deep learning the way to go?\n\n[Spacy](https://spacy.io/usage/rule-based-matching#dependencymatcher) and [Stanza](https://stanfordnlp.github.io/stanza/available\\_models.html) look promising, but I am not sure.","classes":{"dataset":0.9468609691}}
{"title":"Can NLP be used to categorize individuals based on responses?","description":"Hi all,\n\nNew to the field of machine learning and have a dataset with survey responses. I was wondering if NLP can be utilized to categorize individuals based on their responses (approximately 2-3 categories), or is this something better for another domain of machine learning?\n\nIt seems like NLP is more for language generation and interaction. I haven't found much with a couple of quick Google searches around categorization, which makes me think it likely isn't role but just want to check.\n\nThank you!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11n56np/can_nlp_be_used_to_categorize_individuals_based/","created":"2023-03-09","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":11},"text":"Can NLP be used to categorize individuals based on responses? Hi all,\n\nNew to the field of machine learning and have a dataset with survey responses. I was wondering if NLP can be utilized to categorize individuals based on their responses (approximately 2-3 categories), or is this something better for another domain of machine learning?\n\nIt seems like NLP is more for language generation and interaction. I haven't found much with a couple of quick Google searches around categorization, which makes me think it likely isn't role but just want to check.\n\nThank you!","classes":{"dataset":0.2686912715}}
{"title":"Wanna Get Training Datasets For Social media spam classifier","description":"I am planning to build social media's spam classifier with Multinomial Naive Bayes model with python, using \\`sklearn\\` and \\`spacy\\` library. And the text feature extraction technique I will use is tf-idf vectorizer.\n\nHowever, I am having problem to find social media datasets with labelled data as SPAM or NOT SPAM. Another criteria with the datasets is that I need the datasets to be balanced (with roughly equal number of SPAM and NOT SPAM data).\n\nDo suggest me some links or source that I could get the data from?\n\nHope for help. Thanks in advance.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11muxkl/wanna_get_training_datasets_for_social_media_spam/","created":"2023-03-09","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0},"text":"Wanna Get Training Datasets For Social media spam classifier I am planning to build social media's spam classifier with Multinomial Naive Bayes model with python, using \\`sklearn\\` and \\`spacy\\` library. And the text feature extraction technique I will use is tf-idf vectorizer.\n\nHowever, I am having problem to find social media datasets with labelled data as SPAM or NOT SPAM. Another criteria with the datasets is that I need the datasets to be balanced (with roughly equal number of SPAM and NOT SPAM data).\n\nDo suggest me some links or source that I could get the data from?\n\nHope for help. Thanks in advance.","classes":{"dataset":0.293358475}}
{"title":"FPUS23: An Ultrasound Fetus Phantom Dataset with Deep Neural Network Evaluations for Fetus Orientations, Fetal Planes, and Anatomical Features","description":"Ultrasound imaging is one of the most prominent technologies to evaluate the growth, progression, and overall health of a fetus during its gestation. However, the interpretation of the data obtained from such studies is best left to expert physicians and technicians who are trained and well-versed in analyzing such images. To improve the clinical workflow and potentially develop an at-home ultrasound-based fetal monitoring platform, we present a novel fetus phantom ultrasound dataset, FPUS23, which can be used to identify (1) the correct diagnostic planes for estimating fetal biometric values, (2) fetus orientation, (3) their anatomical features, and (4) bounding boxes of the fetus phantom anatomies at 23 weeks gestation. The entire dataset is composed of 15,728 images, which are used to train four different Deep Neural Network models, built upon a ResNet34 backbone, for detecting aforementioned fetus features and use-cases. We have also evaluated the models trained using our FPUS23 dataset, to show that the information learned by these models can be used to substantially increase the accuracy on real-world ultrasound fetus datasets. We make the FPUS23 dataset and the pre-trained models publicly accessible at https://github.com/bharathprabakaran/FPUS23, which will further facilitate future research on fetal ultrasound imaging and analysis.","link":"http://arxiv.org/abs/2303.07852v1","created":"2023-03-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"FPUS23: An Ultrasound Fetus Phantom Dataset with Deep Neural Network Evaluations for Fetus Orientations, Fetal Planes, and Anatomical Features Ultrasound imaging is one of the most prominent technologies to evaluate the growth, progression, and overall health of a fetus during its gestation. However, the interpretation of the data obtained from such studies is best left to expert physicians and technicians who are trained and well-versed in analyzing such images. To improve the clinical workflow and potentially develop an at-home ultrasound-based fetal monitoring platform, we present a novel fetus phantom ultrasound dataset, FPUS23, which can be used to identify (1) the correct diagnostic planes for estimating fetal biometric values, (2) fetus orientation, (3) their anatomical features, and (4) bounding boxes of the fetus phantom anatomies at 23 weeks gestation. The entire dataset is composed of 15,728 images, which are used to train four different Deep Neural Network models, built upon a ResNet34 backbone, for detecting aforementioned fetus features and use-cases. We have also evaluated the models trained using our FPUS23 dataset, to show that the information learned by these models can be used to substantially increase the accuracy on real-world ultrasound fetus datasets. We make the FPUS23 dataset and the pre-trained models publicly accessible at https://github.com/bharathprabakaran/FPUS23, which will further facilitate future research on fetal ultrasound imaging and analysis.","classes":{"dataset":0.5258516073}}
{"title":"ForDigitStress: A multi-modal stress dataset employing a digital job interview scenario","description":"We present a multi-modal stress dataset that uses digital job interviews to induce stress. The dataset provides multi-modal data of 40 participants including audio, video (motion capturing, facial recognition, eye tracking) as well as physiological information (photoplethysmography, electrodermal activity). In addition to that, the dataset contains time-continuous annotations for stress and occurred emotions (e.g. shame, anger, anxiety, surprise). In order to establish a baseline, five different machine learning classifiers (Support Vector Machine, K-Nearest Neighbors, Random Forest, Long-Short-Term Memory Network) have been trained and evaluated on the proposed dataset for a binary stress classification task. The best-performing classifier achieved an accuracy of 88.3% and an F1-score of 87.5%.","link":"http://arxiv.org/abs/2303.07742v1","created":"2023-03-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"ForDigitStress: A multi-modal stress dataset employing a digital job interview scenario We present a multi-modal stress dataset that uses digital job interviews to induce stress. The dataset provides multi-modal data of 40 participants including audio, video (motion capturing, facial recognition, eye tracking) as well as physiological information (photoplethysmography, electrodermal activity). In addition to that, the dataset contains time-continuous annotations for stress and occurred emotions (e.g. shame, anger, anxiety, surprise). In order to establish a baseline, five different machine learning classifiers (Support Vector Machine, K-Nearest Neighbors, Random Forest, Long-Short-Term Memory Network) have been trained and evaluated on the proposed dataset for a binary stress classification task. The best-performing classifier achieved an accuracy of 88.3% and an F1-score of 87.5%.","classes":{"dataset":0.0325719193}}
{"title":"V2V4Real: A Real-world Large-scale Dataset for Vehicle-to-Vehicle Cooperative Perception","description":"Modern perception systems of autonomous vehicles are known to be sensitive to occlusions and lack the capability of long perceiving range. It has been one of the key bottlenecks that prevents Level 5 autonomy. Recent research has demonstrated that the Vehicle-to-Vehicle (V2V) cooperative perception system has great potential to revolutionize the autonomous driving industry. However, the lack of a real-world dataset hinders the progress of this field. To facilitate the development of cooperative perception, we present V2V4Real, the first large-scale real-world multi-modal dataset for V2V perception. The data is collected by two vehicles equipped with multi-modal sensors driving together through diverse scenarios. Our V2V4Real dataset covers a driving area of 410 km, comprising 20K LiDAR frames, 40K RGB frames, 240K annotated 3D bounding boxes for 5 classes, and HDMaps that cover all the driving routes. V2V4Real introduces three perception tasks, including cooperative 3D object detection, cooperative 3D object tracking, and Sim2Real domain adaptation for cooperative perception. We provide comprehensive benchmarks of recent cooperative perception algorithms on three tasks. The V2V4Real dataset and codebase can be found at https://github.com/ucla-mobility/V2V4Real.","link":"http://arxiv.org/abs/2303.07601v1","created":"2023-03-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"V2V4Real: A Real-world Large-scale Dataset for Vehicle-to-Vehicle Cooperative Perception Modern perception systems of autonomous vehicles are known to be sensitive to occlusions and lack the capability of long perceiving range. It has been one of the key bottlenecks that prevents Level 5 autonomy. Recent research has demonstrated that the Vehicle-to-Vehicle (V2V) cooperative perception system has great potential to revolutionize the autonomous driving industry. However, the lack of a real-world dataset hinders the progress of this field. To facilitate the development of cooperative perception, we present V2V4Real, the first large-scale real-world multi-modal dataset for V2V perception. The data is collected by two vehicles equipped with multi-modal sensors driving together through diverse scenarios. Our V2V4Real dataset covers a driving area of 410 km, comprising 20K LiDAR frames, 40K RGB frames, 240K annotated 3D bounding boxes for 5 classes, and HDMaps that cover all the driving routes. V2V4Real introduces three perception tasks, including cooperative 3D object detection, cooperative 3D object tracking, and Sim2Real domain adaptation for cooperative perception. We provide comprehensive benchmarks of recent cooperative perception algorithms on three tasks. The V2V4Real dataset and codebase can be found at https://github.com/ucla-mobility/V2V4Real.","classes":{"dataset":0.6494434476}}
{"title":"Practically Solving LPN in High Noise Regimes Faster Using Neural Networks","description":"We conduct a systematic study of solving the learning parity with noise problem (LPN) using neural networks. Our main contribution is designing families of two-layer neural networks that practically outperform classical algorithms in high-noise, low-dimension regimes. We consider three settings where the numbers of LPN samples are abundant, very limited, and in between. In each setting we provide neural network models that solve LPN as fast as possible. For some settings we are also able to provide theories that explain the rationale of the design of our models. Comparing with the previous experiments of Esser, Kubler, and May (CRYPTO 2017), for dimension $n = 26$, noise rate $\\tau = 0.498$, the ''Guess-then-Gaussian-elimination'' algorithm takes 3.12 days on 64 CPU cores, whereas our neural network algorithm takes 66 minutes on 8 GPUs. Our algorithm can also be plugged into the hybrid algorithms for solving middle or large dimension LPN instances.","link":"http://arxiv.org/abs/2303.07987v1","created":"2023-03-14","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Practically Solving LPN in High Noise Regimes Faster Using Neural Networks We conduct a systematic study of solving the learning parity with noise problem (LPN) using neural networks. Our main contribution is designing families of two-layer neural networks that practically outperform classical algorithms in high-noise, low-dimension regimes. We consider three settings where the numbers of LPN samples are abundant, very limited, and in between. In each setting we provide neural network models that solve LPN as fast as possible. For some settings we are also able to provide theories that explain the rationale of the design of our models. Comparing with the previous experiments of Esser, Kubler, and May (CRYPTO 2017), for dimension $n = 26$, noise rate $\\tau = 0.498$, the ''Guess-then-Gaussian-elimination'' algorithm takes 3.12 days on 64 CPU cores, whereas our neural network algorithm takes 66 minutes on 8 GPUs. Our algorithm can also be plugged into the hybrid algorithms for solving middle or large dimension LPN instances.","classes":{"dataset":0.2873823643}}
{"title":"Exploring ChatGPT's Ability to Rank Content: A Preliminary Study on Consistency with Human Preferences","description":"As a natural language assistant, ChatGPT is capable of performing various tasks, including but not limited to article generation, code completion, and data analysis. Furthermore, ChatGPT has consistently demonstrated a remarkable level of accuracy and reliability in terms of content evaluation, exhibiting the capability of mimicking human preferences. To further explore ChatGPT's potential in this regard, a study is conducted to assess its ability to rank content. In order to do so, a test set consisting of prompts is created, covering a wide range of use cases, and five models are utilized to generate corresponding responses. ChatGPT is then instructed to rank the responses generated by these models. The results on the test set show that ChatGPT's ranking preferences are consistent with human to a certain extent. This preliminary experimental finding implies that ChatGPT's zero-shot ranking capability could be used to reduce annotation pressure in a number of ranking tasks.","link":"http://arxiv.org/abs/2303.07610v1","created":"2023-03-14","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Exploring ChatGPT's Ability to Rank Content: A Preliminary Study on Consistency with Human Preferences As a natural language assistant, ChatGPT is capable of performing various tasks, including but not limited to article generation, code completion, and data analysis. Furthermore, ChatGPT has consistently demonstrated a remarkable level of accuracy and reliability in terms of content evaluation, exhibiting the capability of mimicking human preferences. To further explore ChatGPT's potential in this regard, a study is conducted to assess its ability to rank content. In order to do so, a test set consisting of prompts is created, covering a wide range of use cases, and five models are utilized to generate corresponding responses. ChatGPT is then instructed to rank the responses generated by these models. The results on the test set show that ChatGPT's ranking preferences are consistent with human to a certain extent. This preliminary experimental finding implies that ChatGPT's zero-shot ranking capability could be used to reduce annotation pressure in a number of ranking tasks.","classes":{"dataset":0.3372738957}}
{"title":"The Random Hivemind: An Ensemble Deep Learner. A Case Study of Application to Solar Energetic Particle Prediction Problem","description":"Deep learning has become a popular trend in recent years in the machine learning community and has even occasionally become synonymous with machine learning itself thanks to its efficiency, malleability, and ability to operate free of human intervention. However, a series of hyperparameters passed to a conventional neural network (CoNN) may be rather arbitrary, especially if there is no surefire way to decide how to program hyperparameters for a given dataset. The random hivemind (RH) alleviates this concern by having multiple neural network estimators make decisions based on random permutations of features. The learning rate and the number of epochs may be boosted or attenuated depending on how all features of a given estimator determine the class that the numerical feature data belong to, but all other hyperparameters remain the same across estimators. This allows one to quickly see whether consistent decisions on a given dataset can be made by multiple neural networks with the same hyperparameters, with random subsets of data chosen to force variation in how data are predicted by each, placing the quality of the data and hyperparameters into focus. The effectiveness of RH is demonstrated through experimentation in the predictions of dangerous solar energetic particle events (SEPs) by comparing it to that of using both CoNN and the traditional approach used by ensemble deep learning in this application. Our results demonstrate that RH outperforms the CoNN and a committee-based approach, and demonstrates promising results with respect to the ``all-clear'' prediction of SEPs.","link":"http://arxiv.org/abs/2303.08092v1","created":"2023-03-14","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"The Random Hivemind: An Ensemble Deep Learner. A Case Study of Application to Solar Energetic Particle Prediction Problem Deep learning has become a popular trend in recent years in the machine learning community and has even occasionally become synonymous with machine learning itself thanks to its efficiency, malleability, and ability to operate free of human intervention. However, a series of hyperparameters passed to a conventional neural network (CoNN) may be rather arbitrary, especially if there is no surefire way to decide how to program hyperparameters for a given dataset. The random hivemind (RH) alleviates this concern by having multiple neural network estimators make decisions based on random permutations of features. The learning rate and the number of epochs may be boosted or attenuated depending on how all features of a given estimator determine the class that the numerical feature data belong to, but all other hyperparameters remain the same across estimators. This allows one to quickly see whether consistent decisions on a given dataset can be made by multiple neural networks with the same hyperparameters, with random subsets of data chosen to force variation in how data are predicted by each, placing the quality of the data and hyperparameters into focus. The effectiveness of RH is demonstrated through experimentation in the predictions of dangerous solar energetic particle events (SEPs) by comparing it to that of using both CoNN and the traditional approach used by ensemble deep learning in this application. Our results demonstrate that RH outperforms the CoNN and a committee-based approach, and demonstrates promising results with respect to the ``all-clear'' prediction of SEPs.","classes":{"dataset":0.3035290837}}
{"title":"Controllable Mesh Generation Through Sparse Latent Point Diffusion Models","description":"Mesh generation is of great value in various applications involving computer graphics and virtual content, yet designing generative models for meshes is challenging due to their irregular data structure and inconsistent topology of meshes in the same category. In this work, we design a novel sparse latent point diffusion model for mesh generation. Our key insight is to regard point clouds as an intermediate representation of meshes, and model the distribution of point clouds instead. While meshes can be generated from point clouds via techniques like Shape as Points (SAP), the challenges of directly generating meshes can be effectively avoided. To boost the efficiency and controllability of our mesh generation method, we propose to further encode point clouds to a set of sparse latent points with point-wise semantic meaningful features, where two DDPMs are trained in the space of sparse latent points to respectively model the distribution of the latent point positions and features at these latent points. We find that sampling in this latent space is faster than directly sampling dense point clouds. Moreover, the sparse latent points also enable us to explicitly control both the overall structures and local details of the generated meshes. Extensive experiments are conducted on the ShapeNet dataset, where our proposed sparse latent point diffusion model achieves superior performance in terms of generation quality and controllability when compared to existing methods.","link":"http://arxiv.org/abs/2303.07938v1","created":"2023-03-14","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Controllable Mesh Generation Through Sparse Latent Point Diffusion Models Mesh generation is of great value in various applications involving computer graphics and virtual content, yet designing generative models for meshes is challenging due to their irregular data structure and inconsistent topology of meshes in the same category. In this work, we design a novel sparse latent point diffusion model for mesh generation. Our key insight is to regard point clouds as an intermediate representation of meshes, and model the distribution of point clouds instead. While meshes can be generated from point clouds via techniques like Shape as Points (SAP), the challenges of directly generating meshes can be effectively avoided. To boost the efficiency and controllability of our mesh generation method, we propose to further encode point clouds to a set of sparse latent points with point-wise semantic meaningful features, where two DDPMs are trained in the space of sparse latent points to respectively model the distribution of the latent point positions and features at these latent points. We find that sampling in this latent space is faster than directly sampling dense point clouds. Moreover, the sparse latent points also enable us to explicitly control both the overall structures and local details of the generated meshes. Extensive experiments are conducted on the ShapeNet dataset, where our proposed sparse latent point diffusion model achieves superior performance in terms of generation quality and controllability when compared to existing methods.","classes":{"dataset":0.155772537}}
{"title":"Automated Self-Supervised Learning for Recommendation","description":"Graph neural networks (GNNs) have emerged as the state-of-the-art paradigm for collaborative filtering (CF). To improve the representation quality over limited labeled data, contrastive learning has attracted attention in recommendation and benefited graph-based CF model recently. However, the success of most contrastive methods heavily relies on manually generating effective contrastive views for heuristic-based data augmentation. This does not generalize across different datasets and downstream recommendation tasks, which is difficult to be adaptive for data augmentation and robust to noise perturbation. To fill this crucial gap, this work proposes a unified Automated Collaborative Filtering (AutoCF) to automatically perform data augmentation for recommendation. Specifically, we focus on the generative self-supervised learning framework with a learnable augmentation paradigm that benefits the automated distillation of important self-supervised signals. To enhance the representation discrimination ability, our masked graph autoencoder is designed to aggregate global information during the augmentation via reconstructing the masked subgraph structures. Experiments and ablation studies are performed on several public datasets for recommending products, venues, and locations. Results demonstrate the superiority of AutoCF against various baseline methods. We release the model implementation at https://github.com/HKUDS/AutoCF.","link":"http://arxiv.org/abs/2303.07797v1","created":"2023-03-14","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Automated Self-Supervised Learning for Recommendation Graph neural networks (GNNs) have emerged as the state-of-the-art paradigm for collaborative filtering (CF). To improve the representation quality over limited labeled data, contrastive learning has attracted attention in recommendation and benefited graph-based CF model recently. However, the success of most contrastive methods heavily relies on manually generating effective contrastive views for heuristic-based data augmentation. This does not generalize across different datasets and downstream recommendation tasks, which is difficult to be adaptive for data augmentation and robust to noise perturbation. To fill this crucial gap, this work proposes a unified Automated Collaborative Filtering (AutoCF) to automatically perform data augmentation for recommendation. Specifically, we focus on the generative self-supervised learning framework with a learnable augmentation paradigm that benefits the automated distillation of important self-supervised signals. To enhance the representation discrimination ability, our masked graph autoencoder is designed to aggregate global information during the augmentation via reconstructing the masked subgraph structures. Experiments and ablation studies are performed on several public datasets for recommending products, venues, and locations. Results demonstrate the superiority of AutoCF against various baseline methods. We release the model implementation at https://github.com/HKUDS/AutoCF.","classes":{"dataset":0.643641293}}
{"title":"Image Blending with Osmosis","description":"Image blending is an integral part of many multi-image applications such as panorama stitching or remote image acquisition processes. In such scenarios, multiple images are connected at predefined boundaries to form a larger image. A convincing transition between these boundaries may be challenging, since each image might have been acquired under different conditions or even by different devices.   We propose the first blending approach based on osmosis filters. These drift-diffusion processes define an image evolution with a non-trivial steady state. For our blending purposes, we explore several ways to compose drift vector fields based on the derivatives of our input images. These vector fields guide the evolution such that the steady state yields a convincing blended result. Our method benefits from the well-founded theoretical results for osmosis, which include useful invariances under multiplicative changes of the colour values. Experiments on real-world data show that this yields better quality than traditional gradient domain blending, especially under challenging illumination conditions.","link":"http://arxiv.org/abs/2303.07762v1","created":"2023-03-14","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Image Blending with Osmosis Image blending is an integral part of many multi-image applications such as panorama stitching or remote image acquisition processes. In such scenarios, multiple images are connected at predefined boundaries to form a larger image. A convincing transition between these boundaries may be challenging, since each image might have been acquired under different conditions or even by different devices.   We propose the first blending approach based on osmosis filters. These drift-diffusion processes define an image evolution with a non-trivial steady state. For our blending purposes, we explore several ways to compose drift vector fields based on the derivatives of our input images. These vector fields guide the evolution such that the steady state yields a convincing blended result. Our method benefits from the well-founded theoretical results for osmosis, which include useful invariances under multiplicative changes of the colour values. Experiments on real-world data show that this yields better quality than traditional gradient domain blending, especially under challenging illumination conditions.","classes":{"dataset":0.7178868055}}
{"title":"Feature-Rich Audio Model Inversion for Data-Free Knowledge Distillation Towards General Sound Classification","description":"Data-Free Knowledge Distillation (DFKD) has recently attracted growing attention in the academic community, especially with major breakthroughs in computer vision. Despite promising results, the technique has not been well applied to audio and signal processing. Due to the variable duration of audio signals, it has its own unique way of modeling. In this work, we propose feature-rich audio model inversion (FRAMI), a data-free knowledge distillation framework for general sound classification tasks. It first generates high-quality and feature-rich Mel-spectrograms through a feature-invariant contrastive loss. Then, the hidden states before and after the statistics pooling layer are reused when knowledge distillation is performed on these feature-rich samples. Experimental results on the Urbansound8k, ESC-50, and audioMNIST datasets demonstrate that FRAMI can generate feature-rich samples. Meanwhile, the accuracy of the student model is further improved by reusing the hidden state and significantly outperforms the baseline method.","link":"http://arxiv.org/abs/2303.07643v1","created":"2023-03-14","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Feature-Rich Audio Model Inversion for Data-Free Knowledge Distillation Towards General Sound Classification Data-Free Knowledge Distillation (DFKD) has recently attracted growing attention in the academic community, especially with major breakthroughs in computer vision. Despite promising results, the technique has not been well applied to audio and signal processing. Due to the variable duration of audio signals, it has its own unique way of modeling. In this work, we propose feature-rich audio model inversion (FRAMI), a data-free knowledge distillation framework for general sound classification tasks. It first generates high-quality and feature-rich Mel-spectrograms through a feature-invariant contrastive loss. Then, the hidden states before and after the statistics pooling layer are reused when knowledge distillation is performed on these feature-rich samples. Experimental results on the Urbansound8k, ESC-50, and audioMNIST datasets demonstrate that FRAMI can generate feature-rich samples. Meanwhile, the accuracy of the student model is further improved by reusing the hidden state and significantly outperforms the baseline method.","classes":{"dataset":0.1049674824}}
{"title":"Tensor-based Multimodal Learning for Prediction of Pulmonary Arterial Wedge Pressure from Cardiac MRI","description":"Heart failure is a serious and life-threatening condition that can lead to elevated pressure in the left ventricle. Pulmonary Arterial Wedge Pressure (PAWP) is an important surrogate marker indicating high pressure in the left ventricle. PAWP is determined by Right Heart Catheterization (RHC) but it is an invasive procedure. A non-invasive method is useful in quickly identifying high-risk patients from a large population. In this work, we develop a tensor learning-based pipeline for identifying PAWP from multimodal cardiac Magnetic Resonance Imaging (MRI). This pipeline extracts spatial and temporal features from high-dimensional scans. For quality control, we incorporate an epistemic uncertainty-based binning strategy to identify poor-quality training samples. To improve the performance, we learn complementary information by integrating features from multimodal data: cardiac MRI with short-axis and four-chamber views, and Electronic Health Records. The experimental analysis on a large cohort of $1346$ subjects who underwent the RHC procedure for PAWP estimation indicates that the proposed pipeline has a diagnostic value and can produce promising performance with significant improvement over the baseline in clinical practice (i.e., $\\Delta$AUC $=0.10$, $\\Delta$Accuracy $=0.06$, and $\\Delta$MCC $=0.39$). The decision curve analysis further confirms the clinical utility of our method.","link":"http://arxiv.org/abs/2303.07540v1","created":"2023-03-14","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Tensor-based Multimodal Learning for Prediction of Pulmonary Arterial Wedge Pressure from Cardiac MRI Heart failure is a serious and life-threatening condition that can lead to elevated pressure in the left ventricle. Pulmonary Arterial Wedge Pressure (PAWP) is an important surrogate marker indicating high pressure in the left ventricle. PAWP is determined by Right Heart Catheterization (RHC) but it is an invasive procedure. A non-invasive method is useful in quickly identifying high-risk patients from a large population. In this work, we develop a tensor learning-based pipeline for identifying PAWP from multimodal cardiac Magnetic Resonance Imaging (MRI). This pipeline extracts spatial and temporal features from high-dimensional scans. For quality control, we incorporate an epistemic uncertainty-based binning strategy to identify poor-quality training samples. To improve the performance, we learn complementary information by integrating features from multimodal data: cardiac MRI with short-axis and four-chamber views, and Electronic Health Records. The experimental analysis on a large cohort of $1346$ subjects who underwent the RHC procedure for PAWP estimation indicates that the proposed pipeline has a diagnostic value and can produce promising performance with significant improvement over the baseline in clinical practice (i.e., $\\Delta$AUC $=0.10$, $\\Delta$Accuracy $=0.06$, and $\\Delta$MCC $=0.39$). The decision curve analysis further confirms the clinical utility of our method.","classes":{"dataset":0.1228173971}}
{"title":"Firefox 111.0 enabled Origin private file system access","description":"https://developer.mozilla.org/en-US/docs/Web/API/File_System_Access_API","link":"https://developer.mozilla.org/en-US/docs/Web/API/File_System_Access_API","created":"2023-03-15","tags":["hackernews"],"meta":{"score":21},"text":"Firefox 111.0 enabled Origin private file system access https://developer.mozilla.org/en-US/docs/Web/API/File_System_Access_API","classes":{"dataset":0.544801712}}
{"title":"Trichloroethylene: An invisible cause of Parkinson\u2019s disease?","description":"https://content.iospress.com/articles/journal-of-parkinsons-disease/jpd225047","link":"https://content.iospress.com/articles/journal-of-parkinsons-disease/jpd225047","created":"2023-03-15","tags":["hackernews"],"meta":{"score":128},"text":"Trichloroethylene: An invisible cause of Parkinson\u2019s disease? https://content.iospress.com/articles/journal-of-parkinsons-disease/jpd225047","classes":{"dataset":0.4938202798}}
{"title":"GPT-4","description":"https://openai.com/research/gpt-4","link":"https://openai.com/research/gpt-4","created":"2023-03-14","tags":["hackernews"],"meta":{"score":3545},"text":"GPT-4 https://openai.com/research/gpt-4","classes":{"dataset":0.528226912}}
{"title":"Python-based compiler achieves orders-of-magnitude speedups","description":"https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314","link":"https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314","created":"2023-03-15","tags":["hackernews"],"meta":{"score":7},"text":"Python-based compiler achieves orders-of-magnitude speedups https://news.mit.edu/2023/codon-python-based-compiler-achieve-orders-magnitude-speedups-0314","classes":{"dataset":0.5315614343}}
{"title":"Two U.S. men charged in 2022 hacking of DEA portal","description":"https://krebsonsecurity.com/2023/03/two-us-men-charged-in-2022-hacking-of-dea-portal/","link":"https://krebsonsecurity.com/2023/03/two-us-men-charged-in-2022-hacking-of-dea-portal/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":89},"text":"Two U.S. men charged in 2022 hacking of DEA portal https://krebsonsecurity.com/2023/03/two-us-men-charged-in-2022-hacking-of-dea-portal/","classes":{"dataset":0.5179384351}}
{"title":"Why some GitHub labels are illegible","description":"https://firsching.ch/github_labels.html","link":"https://firsching.ch/github_labels.html","created":"2023-03-13","tags":["hackernews"],"meta":{"score":248},"text":"Why some GitHub labels are illegible https://firsching.ch/github_labels.html","classes":{"dataset":0.5302785039}}
{"title":"South Korea to build world\u2019s largest chip center in Seoul with $230B investment","description":"https://www.cnn.com/2023/03/15/tech/korea-chips-investment-hnk-intl/index.html","link":"https://www.cnn.com/2023/03/15/tech/korea-chips-investment-hnk-intl/index.html","created":"2023-03-15","tags":["hackernews"],"meta":{"score":48},"text":"South Korea to build world\u2019s largest chip center in Seoul with $230B investment https://www.cnn.com/2023/03/15/tech/korea-chips-investment-hnk-intl/index.html","classes":{"dataset":0.4946925938}}
{"title":"Kali Linux 2023.1 introduces 'Purple' distro for defensive security","description":"https://gitlab.com/kalilinux/kali-purple/documentation/-/wikis/home","link":"https://gitlab.com/kalilinux/kali-purple/documentation/-/wikis/home","created":"2023-03-14","tags":["hackernews"],"meta":{"score":307},"text":"Kali Linux 2023.1 introduces 'Purple' distro for defensive security https://gitlab.com/kalilinux/kali-purple/documentation/-/wikis/home","classes":{"dataset":0.5125902295}}
{"title":"Show HN: AI explanations for other people\u2019s code","description":"https://whatdoesthiscodedo.com/","link":"https://whatdoesthiscodedo.com/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":126},"text":"Show HN: AI explanations for other people\u2019s code https://whatdoesthiscodedo.com/","classes":{"dataset":0.4396753907}}
{"title":"MQTT vs. Kafka: An IoT Advocate's Perspective","description":"https://www.influxdata.com/blog/mqtt-vs-kafka-iot-advocates-perspective-part-1/","link":"https://www.influxdata.com/blog/mqtt-vs-kafka-iot-advocates-perspective-part-1/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":144},"text":"MQTT vs. Kafka: An IoT Advocate's Perspective https://www.influxdata.com/blog/mqtt-vs-kafka-iot-advocates-perspective-part-1/","classes":{"dataset":0.478212893}}
{"title":"Live-caption glasses let deaf people read conversations [video]","description":"https://www.youtube.com/watch?v=LauvOTnZMZg","link":"https://www.youtube.com/watch?v=LauvOTnZMZg","created":"2023-03-14","tags":["hackernews"],"meta":{"score":259},"text":"Live-caption glasses let deaf people read conversations [video] https://www.youtube.com/watch?v=LauvOTnZMZg","classes":{"dataset":0.512994945}}
{"title":"Mountpoint \u2013 file client for S3 written in Rust, from AWS","description":"https://github.com/awslabs/mountpoint-s3","link":"https://github.com/awslabs/mountpoint-s3","created":"2023-03-14","tags":["hackernews"],"meta":{"score":238},"text":"Mountpoint \u2013 file client for S3 written in Rust, from AWS https://github.com/awslabs/mountpoint-s3","classes":{"dataset":0.4899710417}}
{"title":"Approximating Pi Using a Cake?","description":"https://ntietz.com/blog/happy-pi-day-2023/","link":"https://ntietz.com/blog/happy-pi-day-2023/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":37},"text":"Approximating Pi Using a Cake? https://ntietz.com/blog/happy-pi-day-2023/","classes":{"dataset":0.5318817496}}
{"title":"PrimateJS: Htmx Quick Start","description":"https://primatejs.com/quick-start/","link":"https://primatejs.com/quick-start/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":70},"text":"PrimateJS: Htmx Quick Start https://primatejs.com/quick-start/","classes":{"dataset":0.4906742275}}
{"title":"The Door Close Button","description":"https://computer.rip/2023-03-13-the-door-close-button.html","link":"https://computer.rip/2023-03-13-the-door-close-button.html","created":"2023-03-14","tags":["hackernews"],"meta":{"score":296},"text":"The Door Close Button https://computer.rip/2023-03-13-the-door-close-button.html","classes":{"dataset":0.5029084086}}
{"title":"Alpaca: A strong open-source instruction-following model","description":"https://crfm.stanford.edu/2023/03/13/alpaca.html","link":"https://crfm.stanford.edu/2023/03/13/alpaca.html","created":"2023-03-13","tags":["hackernews"],"meta":{"score":656},"text":"Alpaca: A strong open-source instruction-following model https://crfm.stanford.edu/2023/03/13/alpaca.html","classes":{"dataset":0.5288754106}}
{"title":"The 72-hour scramble to save the United States from a banking crisis","description":"https://www.washingtonpost.com/us-policy/2023/03/14/72-hour-scramble-save-united-states-banking-crisis/","link":"https://www.washingtonpost.com/us-policy/2023/03/14/72-hour-scramble-save-united-states-banking-crisis/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":18},"text":"The 72-hour scramble to save the United States from a banking crisis https://www.washingtonpost.com/us-policy/2023/03/14/72-hour-scramble-save-united-states-banking-crisis/","classes":{"dataset":0.4839761257}}
{"title":"Scientists identify substance that may have sparked life on earth","description":"https://www.rutgers.edu/news/rutgers-scientists-identify-substance-may-have-sparked-life-earth","link":"https://www.rutgers.edu/news/rutgers-scientists-identify-substance-may-have-sparked-life-earth","created":"2023-03-14","tags":["hackernews"],"meta":{"score":153},"text":"Scientists identify substance that may have sparked life on earth https://www.rutgers.edu/news/rutgers-scientists-identify-substance-may-have-sparked-life-earth","classes":{"dataset":0.4893172383}}
{"title":"EPA moves to limit toxic 'forever chemicals' in drinking water","description":"https://text.npr.org/1163341982","link":"https://text.npr.org/1163341982","created":"2023-03-14","tags":["hackernews"],"meta":{"score":70},"text":"EPA moves to limit toxic 'forever chemicals' in drinking water https://text.npr.org/1163341982","classes":{"dataset":0.4433317482}}
{"title":"What Korzybski got wrong about the map and the territory","description":"https://mattpmn.substack.com/p/what-korzybski-got-wrong-map-territory","link":"https://mattpmn.substack.com/p/what-korzybski-got-wrong-map-territory","created":"2023-03-14","tags":["hackernews"],"meta":{"score":27},"text":"What Korzybski got wrong about the map and the territory https://mattpmn.substack.com/p/what-korzybski-got-wrong-map-territory","classes":{"dataset":0.5467143059}}
{"title":"40% of the code GitHub Copilot users check-in is AI generated and unmodified","description":"https://www.microsoft.com/en-us/Investor/events/FY-2023/Morgan-Stanley-TMT-Conference","link":"https://www.microsoft.com/en-us/Investor/events/FY-2023/Morgan-Stanley-TMT-Conference","created":"2023-03-15","tags":["hackernews"],"meta":{"score":130},"text":"40% of the code GitHub Copilot users check-in is AI generated and unmodified https://www.microsoft.com/en-us/Investor/events/FY-2023/Morgan-Stanley-TMT-Conference","classes":{"dataset":0.5106500983}}
{"title":"Bank of America Gets More Than $15B in Deposits After SVB Failure","description":"https://www.bloomberg.com/news/articles/2023-03-15/bofa-gets-more-than-15-billion-in-deposits-after-svb-failure","link":"https://www.bloomberg.com/news/articles/2023-03-15/bofa-gets-more-than-15-billion-in-deposits-after-svb-failure","created":"2023-03-15","tags":["hackernews"],"meta":{"score":30},"text":"Bank of America Gets More Than $15B in Deposits After SVB Failure https://www.bloomberg.com/news/articles/2023-03-15/bofa-gets-more-than-15-billion-in-deposits-after-svb-failure","classes":{"dataset":0.510332942}}
{"title":"Shutdown: Agora (YC S19)","description":"https://www.thecolorinanything.com/post/shutdown-agora-yc-s19","link":"https://www.thecolorinanything.com/post/shutdown-agora-yc-s19","created":"2023-03-14","tags":["hackernews"],"meta":{"score":50},"text":"Shutdown: Agora (YC S19) https://www.thecolorinanything.com/post/shutdown-agora-yc-s19","classes":{"dataset":0.5168802142}}
{"title":"Tester tells Fed to \u2018claw back\u2019 bonuses from Silicon Valley Bank execs","description":"https://thehill.com/homenews/senate/3900613-tester-tells-fed-to-claw-back-bonuses-from-silicon-valley-bank-execs/","link":"https://thehill.com/homenews/senate/3900613-tester-tells-fed-to-claw-back-bonuses-from-silicon-valley-bank-execs/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":30},"text":"Tester tells Fed to \u2018claw back\u2019 bonuses from Silicon Valley Bank execs https://thehill.com/homenews/senate/3900613-tester-tells-fed-to-claw-back-bonuses-from-silicon-valley-bank-execs/","classes":{"dataset":0.4873737693}}
{"title":"Duolingo Max, a learning experience powered by GPT-4","description":"https://blog.duolingo.com/duolingo-max/","link":"https://blog.duolingo.com/duolingo-max/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":354},"text":"Duolingo Max, a learning experience powered by GPT-4 https://blog.duolingo.com/duolingo-max/","classes":{"dataset":0.494345963}}
{"title":"Shadows in the Big Bang Afterglow Reveal Invisible Cosmic Structures","description":"https://www.quantamagazine.org/shadows-in-the-big-bang-afterglow-reveal-invisible-cosmic-structures-20230313/","link":"https://www.quantamagazine.org/shadows-in-the-big-bang-afterglow-reveal-invisible-cosmic-structures-20230313/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":102},"text":"Shadows in the Big Bang Afterglow Reveal Invisible Cosmic Structures https://www.quantamagazine.org/shadows-in-the-big-bang-afterglow-reveal-invisible-cosmic-structures-20230313/","classes":{"dataset":0.4719828069}}
{"title":"Chickens, cows, threatened in Ransomware on Canadian farms","description":"https://financialpost.com/cybersecurity/growing-cyberattacks-canada-food-system-threaten-disaster","link":"https://financialpost.com/cybersecurity/growing-cyberattacks-canada-food-system-threaten-disaster","created":"2023-03-14","tags":["hackernews"],"meta":{"score":88},"text":"Chickens, cows, threatened in Ransomware on Canadian farms https://financialpost.com/cybersecurity/growing-cyberattacks-canada-food-system-threaten-disaster","classes":{"dataset":0.5253512263}}
{"title":"MIT 24-Hour Challenge","description":"https://mit24hourchallenge.mightycause.com/story/Mit-Open-Learning","link":"https://mit24hourchallenge.mightycause.com/story/Mit-Open-Learning","created":"2023-03-15","tags":["hackernews"],"meta":{"score":38},"text":"MIT 24-Hour Challenge https://mit24hourchallenge.mightycause.com/story/Mit-Open-Learning","classes":{"dataset":0.5128266811}}
{"title":"Show HN: I made a self-hosted ChatGPT UI","description":"https://github.com/cogentapps/chat-with-gpt","link":"https://github.com/cogentapps/chat-with-gpt","created":"2023-03-14","tags":["hackernews"],"meta":{"score":131},"text":"Show HN: I made a self-hosted ChatGPT UI https://github.com/cogentapps/chat-with-gpt","classes":{"dataset":0.4752238095}}
{"title":"The Bing AI bot has been secretly running GPT-4","description":"https://www.theverge.com/2023/3/14/23639928/microsoft-bing-chatbot-ai-gpt-4-llm","link":"https://www.theverge.com/2023/3/14/23639928/microsoft-bing-chatbot-ai-gpt-4-llm","created":"2023-03-14","tags":["hackernews"],"meta":{"score":88},"text":"The Bing AI bot has been secretly running GPT-4 https://www.theverge.com/2023/3/14/23639928/microsoft-bing-chatbot-ai-gpt-4-llm","classes":{"dataset":0.46816957}}
{"title":"Advanced Compilers: Self-Guided Online Course","description":"https://www.cs.cornell.edu/courses/cs6120/2020fa/self-guided/","link":"https://www.cs.cornell.edu/courses/cs6120/2020fa/self-guided/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":653},"text":"Advanced Compilers: Self-Guided Online Course https://www.cs.cornell.edu/courses/cs6120/2020fa/self-guided/","classes":{"dataset":0.4628676176}}
{"title":"Scrcpy 2.0 mirrors Android devices with audio forwarding","description":"https://github.com/Genymobile/scrcpy/releases/tag/v2.0","link":"https://github.com/Genymobile/scrcpy/releases/tag/v2.0","created":"2023-03-14","tags":["hackernews"],"meta":{"score":237},"text":"Scrcpy 2.0 mirrors Android devices with audio forwarding https://github.com/Genymobile/scrcpy/releases/tag/v2.0","classes":{"dataset":0.5222143531}}
{"title":"Dalai: Automatically install, run, and play with LLaMA on your computer","description":"https://cocktailpeanut.github.io/dalai/","link":"https://cocktailpeanut.github.io/dalai/","created":"2023-03-12","tags":["hackernews"],"meta":{"score":819},"text":"Dalai: Automatically install, run, and play with LLaMA on your computer https://cocktailpeanut.github.io/dalai/","classes":{"dataset":0.5915567875}}
{"title":"Apple delays bonuses for some divisions as it scrutinizes costs","description":"https://www.bloomberg.com/news/articles/2023-03-14/apple-delays-bonuses-for-some-divisions-as-it-scrutinizes-costs-aapl","link":"https://www.bloomberg.com/news/articles/2023-03-14/apple-delays-bonuses-for-some-divisions-as-it-scrutinizes-costs-aapl","created":"2023-03-14","tags":["hackernews"],"meta":{"score":86},"text":"Apple delays bonuses for some divisions as it scrutinizes costs https://www.bloomberg.com/news/articles/2023-03-14/apple-delays-bonuses-for-some-divisions-as-it-scrutinizes-costs-aapl","classes":{"dataset":0.4452264607}}
{"title":"\u2018Old-School\u2019 Signature Bank Collapsed After Its Big Crypto Leap","description":"https://www.bloomberg.com/news/articles/2023-03-14/why-did-signature-bank-fail-inside-the-old-school-new-york-bank","link":"https://www.bloomberg.com/news/articles/2023-03-14/why-did-signature-bank-fail-inside-the-old-school-new-york-bank","created":"2023-03-14","tags":["hackernews"],"meta":{"score":102},"text":"\u2018Old-School\u2019 Signature Bank Collapsed After Its Big Crypto Leap https://www.bloomberg.com/news/articles/2023-03-14/why-did-signature-bank-fail-inside-the-old-school-new-york-bank","classes":{"dataset":0.5342515111}}
{"title":"Goldman Sachs bought SVB's bond portfolio, lender says","description":"https://www.reuters.com/business/finance/goldman-sachs-bought-svbs-bond-portfolio-lender-says-2023-03-14/","link":"https://www.reuters.com/business/finance/goldman-sachs-bought-svbs-bond-portfolio-lender-says-2023-03-14/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":37},"text":"Goldman Sachs bought SVB's bond portfolio, lender says https://www.reuters.com/business/finance/goldman-sachs-bought-svbs-bond-portfolio-lender-says-2023-03-14/","classes":{"dataset":0.4934240878}}
{"title":"Just Ask for Generalization (2021)","description":"https://evjang.com/2021/10/23/generalization.html","link":"https://evjang.com/2021/10/23/generalization.html","created":"2023-03-13","tags":["hackernews"],"meta":{"score":46},"text":"Just Ask for Generalization (2021) https://evjang.com/2021/10/23/generalization.html","classes":{"dataset":0.4842033386}}
{"title":"The Butlerian Jihad","description":"https://en.wikipedia.org/wiki/Dune:_The_Butlerian_Jihad","link":"https://en.wikipedia.org/wiki/Dune:_The_Butlerian_Jihad","created":"2023-03-15","tags":["hackernews"],"meta":{"score":69},"text":"The Butlerian Jihad https://en.wikipedia.org/wiki/Dune:_The_Butlerian_Jihad","classes":{"dataset":0.52465415}}
{"title":"Generating aerial imagery with your iPhone's Lidar sensor","description":"https://jakecoppinger.com/2023/03/generating-aerial-imagery-with-your-iphones-lidar-sensor/","link":"https://jakecoppinger.com/2023/03/generating-aerial-imagery-with-your-iphones-lidar-sensor/","created":"2023-03-13","tags":["hackernews"],"meta":{"score":257},"text":"Generating aerial imagery with your iPhone's Lidar sensor https://jakecoppinger.com/2023/03/generating-aerial-imagery-with-your-iphones-lidar-sensor/","classes":{"dataset":0.5163126588}}
{"title":"The Corruption of California","description":"https://unherd.com/2023/03/the-corruption-of-california/","link":"https://unherd.com/2023/03/the-corruption-of-california/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":20},"text":"The Corruption of California https://unherd.com/2023/03/the-corruption-of-california/","classes":{"dataset":0.5300604701}}
{"title":"Credit Suisse finds \u2018material weakness\u2019 in reporting, scraps exec bonuses","description":"https://www.cnn.com/2023/03/14/investing/credit-suisse-financial-reporting-weakness/index.html","link":"https://www.cnn.com/2023/03/14/investing/credit-suisse-financial-reporting-weakness/index.html","created":"2023-03-14","tags":["hackernews"],"meta":{"score":260},"text":"Credit Suisse finds \u2018material weakness\u2019 in reporting, scraps exec bonuses https://www.cnn.com/2023/03/14/investing/credit-suisse-financial-reporting-weakness/index.html","classes":{"dataset":0.4918116629}}
{"title":"An experiment in elastically scaling a thread pool using a PID controller","description":"https://github.com/stevana/elastically-scalable-thread-pools","link":"https://github.com/stevana/elastically-scalable-thread-pools","created":"2023-03-14","tags":["hackernews"],"meta":{"score":105},"text":"An experiment in elastically scaling a thread pool using a PID controller https://github.com/stevana/elastically-scalable-thread-pools","classes":{"dataset":0.4958046377}}
{"title":"Crab crisis in Bering Sea a sign of \u2018borealization\u2019","description":"https://alaskabeacon.com/2023/02/06/crab-crisis-in-bering-sea-a-sign-of-borealization-and-big-changes-in-the-future-scientists-warn/","link":"https://alaskabeacon.com/2023/02/06/crab-crisis-in-bering-sea-a-sign-of-borealization-and-big-changes-in-the-future-scientists-warn/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":153},"text":"Crab crisis in Bering Sea a sign of \u2018borealization\u2019 https://alaskabeacon.com/2023/02/06/crab-crisis-in-bering-sea-a-sign-of-borealization-and-big-changes-in-the-future-scientists-warn/","classes":{"dataset":0.5502049923}}
{"title":"Meta plans to lay off 10k employees","description":"https://about.fb.com/news/2023/03/mark-zuckerberg-meta-year-of-efficiency/","link":"https://about.fb.com/news/2023/03/mark-zuckerberg-meta-year-of-efficiency/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":992},"text":"Meta plans to lay off 10k employees https://about.fb.com/news/2023/03/mark-zuckerberg-meta-year-of-efficiency/","classes":{"dataset":0.4815095067}}
{"title":"Certifications create wrong incentives for engineers and recruiters","description":"https://interviewing.io/blog/why-you-shouldnt-list-certifications-on-linkedIn","link":"https://interviewing.io/blog/why-you-shouldnt-list-certifications-on-linkedIn","created":"2023-03-14","tags":["hackernews"],"meta":{"score":79},"text":"Certifications create wrong incentives for engineers and recruiters https://interviewing.io/blog/why-you-shouldnt-list-certifications-on-linkedIn","classes":{"dataset":0.5127786398}}
{"title":"Ultrathin Metasurface Displays Take Aim at the LCD","description":"https://spectrum.ieee.org/metasurface-displays","link":"https://spectrum.ieee.org/metasurface-displays","created":"2023-03-13","tags":["hackernews"],"meta":{"score":61},"text":"Ultrathin Metasurface Displays Take Aim at the LCD https://spectrum.ieee.org/metasurface-displays","classes":{"dataset":0.5067762136}}
{"title":"Smarty GPT","description":"This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers **in a transparent way to end users**.\n\n&amp;#x200B;\n\nFeel free to open issues, PR, add more prompts! \n\n&amp;#x200B;\n\n[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)","link":"https://www.reddit.com/r/PromptDesign/comments/11r5m06/smarty_gpt/","created":"2023-03-14","tags":["promptdesign","prompteng","reddit"],"meta":{"num_comments":0},"text":"Smarty GPT This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers **in a transparent way to end users**.\n\n&amp;#x200B;\n\nFeel free to open issues, PR, add more prompts! \n\n&amp;#x200B;\n\n[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)","classes":{"dataset":0.5049026012}}
{"title":"Managing secrets like API keys in Python - Why are so many devs still hardcoding secrets?","description":"The recent [State of Secrets Sprawl report](https://www.gitguardian.com/state-of-secrets-sprawl-report-2023) showed that 10 million (yes million) secrets like API keys, credential pairs and security certs were leaked in public GitHub repositories in 2022 and Python was by far the largest contributor to these. \n\nThe problem stems mostly from secrets being hardcoded directly into the source code. So this leads to the question, why are so many devs hardcoding secrets? The problem is a little more complicated with git because often a secret is hardcoded and removed without the dev realizing that the secret persists in the git history. But still, this is a big issue in the Python community. \n\nManaging secrets can be really easy thanks to helpful Pypi packages like [Python Dotenv](https://pypi.org/project/python-dotenv/) which is my favorite for its simplicity and easy ability to manage secrets for multiple different environments like Dev and Prod. I'm curious about what others are using to manage secrets and why? \n\nI thought I'd share some recent tutorials on managing secrets for anyone who may need a refresher on the topic. Please share more resources in the comments.   \n\n\n[Managing Secrets in Python - Video](https://www.youtube.com/watch?v=DVVYHlGYIHY)  \n\n\n[Managing Secrets in Python - Blog](https://blog.gitguardian.com/how-to-handle-secrets-in-python/)","link":"https://www.reddit.com/r/Python/comments/11rqyv9/managing_secrets_like_api_keys_in_python_why_are/","created":"2023-03-15","tags":["reddit","python"],"meta":{"num_comments":3},"text":"Managing secrets like API keys in Python - Why are so many devs still hardcoding secrets? The recent [State of Secrets Sprawl report](https://www.gitguardian.com/state-of-secrets-sprawl-report-2023) showed that 10 million (yes million) secrets like API keys, credential pairs and security certs were leaked in public GitHub repositories in 2022 and Python was by far the largest contributor to these. \n\nThe problem stems mostly from secrets being hardcoded directly into the source code. So this leads to the question, why are so many devs hardcoding secrets? The problem is a little more complicated with git because often a secret is hardcoded and removed without the dev realizing that the secret persists in the git history. But still, this is a big issue in the Python community. \n\nManaging secrets can be really easy thanks to helpful Pypi packages like [Python Dotenv](https://pypi.org/project/python-dotenv/) which is my favorite for its simplicity and easy ability to manage secrets for multiple different environments like Dev and Prod. I'm curious about what others are using to manage secrets and why? \n\nI thought I'd share some recent tutorials on managing secrets for anyone who may need a refresher on the topic. Please share more resources in the comments.   \n\n\n[Managing Secrets in Python - Video](https://www.youtube.com/watch?v=DVVYHlGYIHY)  \n\n\n[Managing Secrets in Python - Blog](https://blog.gitguardian.com/how-to-handle-secrets-in-python/)","classes":{"dataset":0.4819248617}}
{"title":"ChatGPT int the Terminal!","description":"Me and a friend made it possible to  use openai's chatgpt right in your terminal using the new API's. Give it  a try and let us know what you think!\n\nLink: [https://github.com/AineeJames/ChatGPTerminator](https://github.com/AineeJames/ChatGPTerminator)\n\nhttps://preview.redd.it/vxu3psljsmna1.png?width=1504&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e28dc576d0581b3283caf4e6715c45a507d5982e","link":"https://www.reddit.com/r/Python/comments/11qwe1a/chatgpt_int_the_terminal/","created":"2023-03-14","tags":["reddit","python"],"meta":{"num_comments":58},"text":"ChatGPT int the Terminal! Me and a friend made it possible to  use openai's chatgpt right in your terminal using the new API's. Give it  a try and let us know what you think!\n\nLink: [https://github.com/AineeJames/ChatGPTerminator](https://github.com/AineeJames/ChatGPTerminator)\n\nhttps://preview.redd.it/vxu3psljsmna1.png?width=1504&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e28dc576d0581b3283caf4e6715c45a507d5982e","classes":{"dataset":0.3611496687}}
{"title":"Python Beginner, Need some advice/route-map to get an Entry-level jobs.","description":"Hi everyone, Hope all is well with you all. I'm writing this to seek some advice from you all. I'm 30 and I have shifted my career from e-commerce to Python recently. I was working in a company in London and had to quit because of redundancy. Hence, I thought I need to upgrade my technical skills to find a stable job. I have been teaching myself python via an Online platform and practicing hackerranks,geeksforgeeks to practice python. It's been around 6 months now and to be honest, I'm quite afraid of how I'm going to find a job. what would be the expectations for a junior python-dev? how should I approach this situation?can i actually try for interviews without any certification in Python? or Should I get any? Any tips, or anything useful to me would be highly appreciated guys! I'm losing my confidence day by day as the journey takes a long time and worried. Please share your thoughts. Thanks :)","link":"https://www.reddit.com/r/Python/comments/11ravf6/python_beginner_need_some_adviceroutemap_to_get/","created":"2023-03-14","tags":["reddit","python"],"meta":{"num_comments":19},"text":"Python Beginner, Need some advice/route-map to get an Entry-level jobs. Hi everyone, Hope all is well with you all. I'm writing this to seek some advice from you all. I'm 30 and I have shifted my career from e-commerce to Python recently. I was working in a company in London and had to quit because of redundancy. Hence, I thought I need to upgrade my technical skills to find a stable job. I have been teaching myself python via an Online platform and practicing hackerranks,geeksforgeeks to practice python. It's been around 6 months now and to be honest, I'm quite afraid of how I'm going to find a job. what would be the expectations for a junior python-dev? how should I approach this situation?can i actually try for interviews without any certification in Python? or Should I get any? Any tips, or anything useful to me would be highly appreciated guys! I'm losing my confidence day by day as the journey takes a long time and worried. Please share your thoughts. Thanks :)","classes":{"dataset":0.4709297717}}
{"title":"Join us for PyDay!","description":"Hey Python Community!\n\nExcited to announce Microsoft is hosting #PyDay May 2nd, 2023! (I know.. missed opportunity not having it today March, 14th)\n\nJoin us for an exciting session led by experienced developer and educator Pamela Fox, where you'll learn how to build, test, containerize, and deploy HTTP APIs and web applications using the 3 most popular Python frameworks: FastAPI, Django, and Flask.\n\nFamiliarity with Python is encouraged, but no web app experience is required.\n\nLearn more here: https://aka.ms/PyDay\n\nIf you're just getting started with Python, head over to https://aka.ms/TryPython to brush up on the basics before the session!\n\nGood session for beginners/students. Pamela is a great teacher!","link":"https://www.reddit.com/r/Python/comments/11r7pca/join_us_for_pyday/","created":"2023-03-14","tags":["reddit","python"],"meta":{"num_comments":3},"text":"Join us for PyDay! Hey Python Community!\n\nExcited to announce Microsoft is hosting #PyDay May 2nd, 2023! (I know.. missed opportunity not having it today March, 14th)\n\nJoin us for an exciting session led by experienced developer and educator Pamela Fox, where you'll learn how to build, test, containerize, and deploy HTTP APIs and web applications using the 3 most popular Python frameworks: FastAPI, Django, and Flask.\n\nFamiliarity with Python is encouraged, but no web app experience is required.\n\nLearn more here: https://aka.ms/PyDay\n\nIf you're just getting started with Python, head over to https://aka.ms/TryPython to brush up on the basics before the session!\n\nGood session for beginners/students. Pamela is a great teacher!","classes":{"dataset":0.0572583862}}
{"title":"Anyone see a danger in allowing wild west rules for ' vs \" in strings?","description":"I'm tired of nit'ing people for using \\`\"\\` instead of \\`'\\` for strings (we agreed on \\`'\\`), and quite frankly I can't see how it adds value nor that anyone really cares. If I (as a tech lead) relax this to \"use whatever you feel like\", will we suffer later from some obscure gotcha?","link":"https://www.reddit.com/r/Python/comments/11qjml6/anyone_see_a_danger_in_allowing_wild_west_rules/","created":"2023-03-13","tags":["reddit","python"],"meta":{"num_comments":108},"text":"Anyone see a danger in allowing wild west rules for ' vs \" in strings? I'm tired of nit'ing people for using \\`\"\\` instead of \\`'\\` for strings (we agreed on \\`'\\`), and quite frankly I can't see how it adds value nor that anyone really cares. If I (as a tech lead) relax this to \"use whatever you feel like\", will we suffer later from some obscure gotcha?","classes":{"dataset":0.4300114214}}
{"title":"Python libraries","description":"When I first started programming I got my feet wet using python and have working knowledge about the language, but transitioned my focus on front-end web development. I want to return to python to develop a deeper understanding, what are some libraries you use in your day-to-day you\u2019d say would be worth learning? Thanks in advance!","link":"https://www.reddit.com/r/Python/comments/11r83an/python_libraries/","created":"2023-03-14","tags":["reddit","python"],"meta":{"num_comments":5},"text":"Python libraries When I first started programming I got my feet wet using python and have working knowledge about the language, but transitioned my focus on front-end web development. I want to return to python to develop a deeper understanding, what are some libraries you use in your day-to-day you\u2019d say would be worth learning? Thanks in advance!","classes":{"dataset":0.5144391656}}
{"title":"python security - very simply open source scanner which detect file signed untrusted or leaked certificates","description":" \n\n[https://github.com/password123456/CertVerify](https://github.com/password123456/CertVerify)\n\nWhy is this tool needed?\n\nExecutable files signed with compromised or untrusted code signing certificates can be used to distribute malware and other malicious software. Attackers can use these files to bypass security controls and to make their malware appear legitimate to victims. This tool helps to identify these files so that they can be removed or investigated further.","link":"https://www.reddit.com/r/Python/comments/11qq8ex/python_security_very_simply_open_source_scanner/","created":"2023-03-13","tags":["reddit","python"],"meta":{"num_comments":0},"text":"python security - very simply open source scanner which detect file signed untrusted or leaked certificates  \n\n[https://github.com/password123456/CertVerify](https://github.com/password123456/CertVerify)\n\nWhy is this tool needed?\n\nExecutable files signed with compromised or untrusted code signing certificates can be used to distribute malware and other malicious software. Attackers can use these files to bypass security controls and to make their malware appear legitimate to victims. This tool helps to identify these files so that they can be removed or investigated further.","classes":{"dataset":0.453163147}}
{"title":"Lib for dynamically generating classes from json or dict on runtime","description":"I wrote a lib for creating dynamically classes or objects from python dicts or json on runtime.\n\nwith this lib you are be able to let your application write his entity him self.\n\nI using it for generating classes out of json request in flask for sqlalchemy or mongoengine.\n\nit works with init on class level and also with init on attributes.\n\nit works with builtin types and also own objects and types.\n\n[https://pypi.org/project/pydict2class/0.0.1/](https://pypi.org/project/pydict2class/0.0.1/)\n\n[https://github.com/dierk-bentpiening/PyDict2Class](https://github.com/dierk-bentpiening/PyDict2Class)\n\n# PyDict2Class\n\nDynamic create classes from dict or json like you would develop them yourself.\n\n## Introduction\n\nThis tool makes it possible to generate a Python class with attributes from a dict or a JSON, or to create an object with the corresponding assigned values. The data type of the value of the dict or JSON is recognized and automatically initialized with the appropriate builtins data types. Non Python standard types or methods can also be included by adding them to the type attribute, this can also override the internal data types.\n\ni use this tool to dynamically create mongoengine data classes with the appropriate attributes. Actual i am implement the Functionality to create SQLAlchemy Data Model classes.\n\n## Usage\n\ninstall the library from source or over pip. import package and inherit Class object. e builtins data types. Non Python standard types or methods can also be inc\n\n    from pydict2class import Dict2Class dict2class = Dict2Class() \n\nDefine the Dictionary you want to generate a class from.\n\n    mydict = {\"integer\": 1, \"string\": \"my string\", \"boolean\": True, \"list\": [1, 2, 3]} \n\nNow you have to decide whether you want to generate only the class or if you want to generate the class and instantiate it with the values given in your dict or json.\n\n**Only generate the class:**\n\n    myclass = dict2class.generate(mydict, \"myclassname\") \n\nThe magic is done and you have a dynamic class with the dictionary keys as attribute names and the value data type as datatype.\n\n**Generate class and initialize object:**\n\n    myobj = dict2class.generate_and_init(mydict, \"classfdict\") \n\n**Use JSON instead of Dict:**\n\n    myjsonstr = '{\"integer\": 1, \"string\": \"my string\", \"boolean\": True, \"list\": [1, 2, 3]}' myclass = dict2class.generate(myjsonstr, \"myclass\", json=True) \n\n**Add Custom methods to types and use them:**\n\n       dict2class = Dict2Class()     dict2class.types = mycustommethods      \n\n**Add list of custom methods to type and use them:**\n\n       dict2class = Dict2Class()     dict2class.types = [custommethod1, custommethod2, custommethod3, custommethod4, custommethod5] \n\n[https://pypi.org/project/pydict2class/0.0.1/](https://pypi.org/project/pydict2class/0.0.1/)\n\n[https://github.com/dierk-bentpiening/PyDict2Class](https://github.com/dierk-bentpiening/PyDict2Class)","link":"https://www.reddit.com/r/Python/comments/11ra0e5/lib_for_dynamically_generating_classes_from_json/","created":"2023-03-14","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Lib for dynamically generating classes from json or dict on runtime I wrote a lib for creating dynamically classes or objects from python dicts or json on runtime.\n\nwith this lib you are be able to let your application write his entity him self.\n\nI using it for generating classes out of json request in flask for sqlalchemy or mongoengine.\n\nit works with init on class level and also with init on attributes.\n\nit works with builtin types and also own objects and types.\n\n[https://pypi.org/project/pydict2class/0.0.1/](https://pypi.org/project/pydict2class/0.0.1/)\n\n[https://github.com/dierk-bentpiening/PyDict2Class](https://github.com/dierk-bentpiening/PyDict2Class)\n\n# PyDict2Class\n\nDynamic create classes from dict or json like you would develop them yourself.\n\n## Introduction\n\nThis tool makes it possible to generate a Python class with attributes from a dict or a JSON, or to create an object with the corresponding assigned values. The data type of the value of the dict or JSON is recognized and automatically initialized with the appropriate builtins data types. Non Python standard types or methods can also be included by adding them to the type attribute, this can also override the internal data types.\n\ni use this tool to dynamically create mongoengine data classes with the appropriate attributes. Actual i am implement the Functionality to create SQLAlchemy Data Model classes.\n\n## Usage\n\ninstall the library from source or over pip. import package and inherit Class object. e builtins data types. Non Python standard types or methods can also be inc\n\n    from pydict2class import Dict2Class dict2class = Dict2Class() \n\nDefine the Dictionary you want to generate a class from.\n\n    mydict = {\"integer\": 1, \"string\": \"my string\", \"boolean\": True, \"list\": [1, 2, 3]} \n\nNow you have to decide whether you want to generate only the class or if you want to generate the class and instantiate it with the values given in your dict or json.\n\n**Only generate the class:**\n\n    myclass = dict2class.generate(mydict, \"myclassname\") \n\nThe magic is done and you have a dynamic class with the dictionary keys as attribute names and the value data type as datatype.\n\n**Generate class and initialize object:**\n\n    myobj = dict2class.generate_and_init(mydict, \"classfdict\") \n\n**Use JSON instead of Dict:**\n\n    myjsonstr = '{\"integer\": 1, \"string\": \"my string\", \"boolean\": True, \"list\": [1, 2, 3]}' myclass = dict2class.generate(myjsonstr, \"myclass\", json=True) \n\n**Add Custom methods to types and use them:**\n\n       dict2class = Dict2Class()     dict2class.types = mycustommethods      \n\n**Add list of custom methods to type and use them:**\n\n       dict2class = Dict2Class()     dict2class.types = [custommethod1, custommethod2, custommethod3, custommethod4, custommethod5] \n\n[https://pypi.org/project/pydict2class/0.0.1/](https://pypi.org/project/pydict2class/0.0.1/)\n\n[https://github.com/dierk-bentpiening/PyDict2Class](https://github.com/dierk-bentpiening/PyDict2Class)","classes":{"dataset":0.5089725256}}
{"title":"I made a simple random password generator","description":"[Random Password Generator](https://github.com/milkyicedtea/Random-password-generator) (~~what an orginal name!~~) or [RPG](https://github.com/milkyicedtea/Random-password-generator) for short is a simple password generator that uses [PySimpleGUI](https://github.com/PySimpleGUI/PySimpleGUI) GUI framework, in order to have a user-friendly interface ~~and also because i wanted to have fun.~~\n\nYou can find more information on the project in the [README](https://github.com/milkyicedtea/Random-password-generator#readme) (~~I'm kinda proud of how it came out~~)\n\n&gt;**Disclaimer:**  \n&gt;  \n&gt;As it's hopefully obvious, I would never use and do not recommend using this to actually generate passwords you use, as i don't know if this is secure enough, since it uses very simple algorithms to generate the passwords.\n\nOf course, any critiques and tips on how to make the code/generation better are welcome, *just please, don't paste some code in here. I'd rather figure it out myself ;)*","link":"https://www.reddit.com/r/Python/comments/11r45rj/i_made_a_simple_random_password_generator/","created":"2023-03-14","tags":["reddit","python"],"meta":{"num_comments":5},"text":"I made a simple random password generator [Random Password Generator](https://github.com/milkyicedtea/Random-password-generator) (~~what an orginal name!~~) or [RPG](https://github.com/milkyicedtea/Random-password-generator) for short is a simple password generator that uses [PySimpleGUI](https://github.com/PySimpleGUI/PySimpleGUI) GUI framework, in order to have a user-friendly interface ~~and also because i wanted to have fun.~~\n\nYou can find more information on the project in the [README](https://github.com/milkyicedtea/Random-password-generator#readme) (~~I'm kinda proud of how it came out~~)\n\n&gt;**Disclaimer:**  \n&gt;  \n&gt;As it's hopefully obvious, I would never use and do not recommend using this to actually generate passwords you use, as i don't know if this is secure enough, since it uses very simple algorithms to generate the passwords.\n\nOf course, any critiques and tips on how to make the code/generation better are welcome, *just please, don't paste some code in here. I'd rather figure it out myself ;)*","classes":{"dataset":0.4232710898}}
{"title":"What are the good sources to learn machine learning in Python??","description":"I've recently finished learning about python and now I want to learn about machine learning...\nIt is confusing as there are so many modules and I just can't choose between them....\nIf anyone could suggest me 5 best modules I should learn it would be a great help....","link":"https://www.reddit.com/r/Python/comments/11q64a0/what_are_the_good_sources_to_learn_machine/","created":"2023-03-13","tags":["reddit","python"],"meta":{"num_comments":40},"text":"What are the good sources to learn machine learning in Python?? I've recently finished learning about python and now I want to learn about machine learning...\nIt is confusing as there are so many modules and I just can't choose between them....\nIf anyone could suggest me 5 best modules I should learn it would be a great help....","classes":{"dataset":0.4052860141}}
{"title":"How does Donut extract precise text without OCR?","description":"I've stumbled upon [this paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136880493.pdf) and a couple of others that basically discuss an alternative approach (Donut) for Visual Document Understanding (VDU).\n\nThe conventional and common approach (like what's done by LayoutLM) is to first perform OCR on the input image (with potential text block recognition beforehand), then post-process the output text. Donut's premise is to basically cut out the OCR step and process end-to-end in one pass.\n\nMy question is simply how does the text extraction happen in that case? how can text be extracted with such precision without OCR or some other form of optical text recognition?\n\nI went through the paper and a handful of articles explaining it, but the concept as a whole is still quite baffling to me and it all sounds like \"you can see without your eyes\" at this point x)","link":"https://www.reddit.com/r/deeplearning/comments/11rc2oh/how_does_donut_extract_precise_text_without_ocr/","created":"2023-03-14","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"How does Donut extract precise text without OCR? I've stumbled upon [this paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136880493.pdf) and a couple of others that basically discuss an alternative approach (Donut) for Visual Document Understanding (VDU).\n\nThe conventional and common approach (like what's done by LayoutLM) is to first perform OCR on the input image (with potential text block recognition beforehand), then post-process the output text. Donut's premise is to basically cut out the OCR step and process end-to-end in one pass.\n\nMy question is simply how does the text extraction happen in that case? how can text be extracted with such precision without OCR or some other form of optical text recognition?\n\nI went through the paper and a handful of articles explaining it, but the concept as a whole is still quite baffling to me and it all sounds like \"you can see without your eyes\" at this point x)","classes":{"dataset":0.3240449131}}
{"title":"Research opportunity","description":"Hey all, I came across Fatima Fellowship on LinkedIn (not sure if links are allowed here so I won't post it but you can just google it up). They provide research opportunities for Machine Learning and I guess related areas. It says that it's free and works as a non-profit. Thought I would share here incase anyone is looking for research chances.","link":"https://www.reddit.com/r/deeplearning/comments/11rfapy/research_opportunity/","created":"2023-03-14","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Research opportunity Hey all, I came across Fatima Fellowship on LinkedIn (not sure if links are allowed here so I won't post it but you can just google it up). They provide research opportunities for Machine Learning and I guess related areas. It says that it's free and works as a non-profit. Thought I would share here incase anyone is looking for research chances.","classes":{"dataset":0.5311536193}}
{"title":"What are some ways to teach myself new skills?","description":"","link":"https://www.reddit.com/r/deeplearning/comments/11r65oj/what_are_some_ways_to_teach_myself_new_skills/","created":"2023-03-14","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":4},"text":"What are some ways to teach myself new skills? ","classes":{"dataset":0.2856739163}}
{"title":"How To Scale Transformers\u2019 Memory up to 262K Tokens With a Minor Change?","description":"I just published my latest medium article. \n\nThis article is a fabulous attempt to leverage language models in memorizing information by transformers with the least required effort by inserting only an external memory near the last layer of the transformer.\n\nWe can use this to retrieve information that the transformer is trained with which helps the reliability of predictions.\n\nFeel free to share this and/or contact me directly.\n\nhttps://medium.com/towards-artificial-intelligence/extending-transformers-by-memorizing-up-to-262k-tokens-f9e066108777","link":"https://www.reddit.com/r/deeplearning/comments/11qfl2o/how_to_scale_transformers_memory_up_to_262k/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":5},"text":"How To Scale Transformers\u2019 Memory up to 262K Tokens With a Minor Change? I just published my latest medium article. \n\nThis article is a fabulous attempt to leverage language models in memorizing information by transformers with the least required effort by inserting only an external memory near the last layer of the transformer.\n\nWe can use this to retrieve information that the transformer is trained with which helps the reliability of predictions.\n\nFeel free to share this and/or contact me directly.\n\nhttps://medium.com/towards-artificial-intelligence/extending-transformers-by-memorizing-up-to-262k-tokens-f9e066108777","classes":{"dataset":0.296920687}}
{"title":"Learning logical relationships with neural networks with differential ILP","description":"Since last week\u2019s post on my lab\u2019s software package [PyReason](https://neurosymoblic.asu.edu/pyreason/), I got a lot of questions on if it would be possible for a neural network to learn logical relationships from data. After all, ChatGPT seems to be able to generate Python code, and Meta released a NeurIPS paper to show you can learn math equations from data using a transformer-based model, so why not logic? In this article, we will one line of research in this area \u2013 differential ILP.\n\nThe research in this area really kicked off with a 2018 [paper from DeepMind](https://www.reddit.com/r/deeplearning/jair.org/index.php/jair/article/view/11172) where Richard Evans and Edward Grefenstette showed that you could adapt techniques from \u201cinductive logic programming\u201d to use gradient descent, and learn logical rules from data. Previous (non-neural) work on inductive logic programming was generally not designed to work with noisy data and instead fit the historical examples in a precise manner. Evans and Grefenstette utilized a neural architecture and a loss function \u2013 and they showed they could handle noisy data and even do some level of integration with CNN\u2019s. Their neural architecture mimicked a set of candidate logical rules \u2013 and the rules assigned higher weights by gradient descent would be thought to best fit the data. However, a downside to this approach is that the neural network was [quintic in the size of the input](https://www.youtube.com/watch?v=SOnAE0EyX8c&amp;list=PLpqh-PUKX-i7URwnkTqpAkSchJHvbxZHB&amp;index=5). This is why they only applied their approach on very small problems \u2013 it did not see very wide adoption.\n\nThat said, in the last two years, there have been some notable follow-ons to this work. Researchers out of Kyoto University and NTT introduced a manner to learn rules that are more expressive in a different manner by allowing function symbols in the logical language ([Shindo et al., AAAI 2021](https://ojs.aaai.org/index.php/AAAI/article/view/16637/16444)). They leverage a clause search and refinement process to limit the number of candidate rules \u2013 hence limiting the size of the neural network. A student team from ASU created a presentation on their work for our recent seminar course on neuro symbolic AI. We released a three part video series from their talk:\n\n[Part 1: Review of differentiable inductive logic programming](https://www.youtube.com/watch?v=JIS78a40q8U&amp;t=270s)\n\n[Part 2: Clause search and refinement In our recent video series](https://www.youtube.com/watch?v=nzfbxlHUwuE&amp;t=345s)\n\n[Part 3: Experiments](https://www.youtube.com/watch?v=-fKWNtHUIN0&amp;t=27s)\n\n[Slides](https://labs.engineering.asu.edu/labv2/wp-content/uploads/sites/82/2022/10/Shindo_dILP.pdf)\n\nSome think that the ability to learn such relationships will represent a significant advancement in ML, specifically addressing shortcomings in areas such as knowledge graph completion and reasoning about scene graphs. However, the gap still remains wide, and ILP techniques, including differentiable ILP still have a ways to go. Really interested in what your thoughts are, feel free to comment below.","link":"https://www.reddit.com/r/deeplearning/comments/11q8tir/learning_logical_relationships_with_neural/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":3},"text":"Learning logical relationships with neural networks with differential ILP Since last week\u2019s post on my lab\u2019s software package [PyReason](https://neurosymoblic.asu.edu/pyreason/), I got a lot of questions on if it would be possible for a neural network to learn logical relationships from data. After all, ChatGPT seems to be able to generate Python code, and Meta released a NeurIPS paper to show you can learn math equations from data using a transformer-based model, so why not logic? In this article, we will one line of research in this area \u2013 differential ILP.\n\nThe research in this area really kicked off with a 2018 [paper from DeepMind](https://www.reddit.com/r/deeplearning/jair.org/index.php/jair/article/view/11172) where Richard Evans and Edward Grefenstette showed that you could adapt techniques from \u201cinductive logic programming\u201d to use gradient descent, and learn logical rules from data. Previous (non-neural) work on inductive logic programming was generally not designed to work with noisy data and instead fit the historical examples in a precise manner. Evans and Grefenstette utilized a neural architecture and a loss function \u2013 and they showed they could handle noisy data and even do some level of integration with CNN\u2019s. Their neural architecture mimicked a set of candidate logical rules \u2013 and the rules assigned higher weights by gradient descent would be thought to best fit the data. However, a downside to this approach is that the neural network was [quintic in the size of the input](https://www.youtube.com/watch?v=SOnAE0EyX8c&amp;list=PLpqh-PUKX-i7URwnkTqpAkSchJHvbxZHB&amp;index=5). This is why they only applied their approach on very small problems \u2013 it did not see very wide adoption.\n\nThat said, in the last two years, there have been some notable follow-ons to this work. Researchers out of Kyoto University and NTT introduced a manner to learn rules that are more expressive in a different manner by allowing function symbols in the logical language ([Shindo et al., AAAI 2021](https://ojs.aaai.org/index.php/AAAI/article/view/16637/16444)). They leverage a clause search and refinement process to limit the number of candidate rules \u2013 hence limiting the size of the neural network. A student team from ASU created a presentation on their work for our recent seminar course on neuro symbolic AI. We released a three part video series from their talk:\n\n[Part 1: Review of differentiable inductive logic programming](https://www.youtube.com/watch?v=JIS78a40q8U&amp;t=270s)\n\n[Part 2: Clause search and refinement In our recent video series](https://www.youtube.com/watch?v=nzfbxlHUwuE&amp;t=345s)\n\n[Part 3: Experiments](https://www.youtube.com/watch?v=-fKWNtHUIN0&amp;t=27s)\n\n[Slides](https://labs.engineering.asu.edu/labv2/wp-content/uploads/sites/82/2022/10/Shindo_dILP.pdf)\n\nSome think that the ability to learn such relationships will represent a significant advancement in ML, specifically addressing shortcomings in areas such as knowledge graph completion and reasoning about scene graphs. However, the gap still remains wide, and ILP techniques, including differentiable ILP still have a ways to go. Really interested in what your thoughts are, feel free to comment below.","classes":{"dataset":0.2718063593}}
{"title":"Multiple objects - Multivariate LSTM","description":"Hello there, I'm new to deeplearning but I'm very fascinated by it.\n\nI'm actually working with multivariate time series (TS) forecasting. I already saw many approaches but none of them appear to be similar to my problem:\n\nI have ~150k objects, for each objects I have 4 independent TS (A B C D) and 1 dependent TS (let's call it Z).\n\nEach TS is about 45-50 observations depending on the studied year.\nI need to train a NN on the TS from the previous years to be used on the TS for this year and the next ones.\n\nI have 2 objectives: \n-predict the next 2-4 observations of TS Z using no more than the last 6 observations of ABCD;\n-predict all TS Z based on all the previous observations from ABCD. Obviously the predictions in the nearest future will be more precise that the ones in the long future. So with gradually increasing obs after each time step.\n\nCan you suggest me the best structure to achieve those 2 objs?","link":"https://www.reddit.com/r/deeplearning/comments/11q9hj3/multiple_objects_multivariate_lstm/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Multiple objects - Multivariate LSTM Hello there, I'm new to deeplearning but I'm very fascinated by it.\n\nI'm actually working with multivariate time series (TS) forecasting. I already saw many approaches but none of them appear to be similar to my problem:\n\nI have ~150k objects, for each objects I have 4 independent TS (A B C D) and 1 dependent TS (let's call it Z).\n\nEach TS is about 45-50 observations depending on the studied year.\nI need to train a NN on the TS from the previous years to be used on the TS for this year and the next ones.\n\nI have 2 objectives: \n-predict the next 2-4 observations of TS Z using no more than the last 6 observations of ABCD;\n-predict all TS Z based on all the previous observations from ABCD. Obviously the predictions in the nearest future will be more precise that the ones in the long future. So with gradually increasing obs after each time step.\n\nCan you suggest me the best structure to achieve those 2 objs?","classes":{"dataset":0.5208072662}}
{"title":"Image reconstruction","description":"I have a use-case where (say) N RGB input images are used to reconstruct a single RGB output image, using either an Autoencoder, or a U-Net architecture. More concretely, if N = 18, 18 RGB input images are used as input to a CNN which should then predict one target RGB output image.\n\nIf the spatial width and height are 90, then *one input sample* might be (18, 3, 90, 90) **which is not batch-size = 18!** AFAIK, (18, 3, 90, 90) as input to a CNN will reproduce (18, 3, 90, 90) as output, whereas, I want (3, 90, 90) as the desired output.\n\nAny idea how to achieve this?","link":"https://www.reddit.com/r/deeplearning/comments/11qazip/image_reconstruction/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":6},"text":"Image reconstruction I have a use-case where (say) N RGB input images are used to reconstruct a single RGB output image, using either an Autoencoder, or a U-Net architecture. More concretely, if N = 18, 18 RGB input images are used as input to a CNN which should then predict one target RGB output image.\n\nIf the spatial width and height are 90, then *one input sample* might be (18, 3, 90, 90) **which is not batch-size = 18!** AFAIK, (18, 3, 90, 90) as input to a CNN will reproduce (18, 3, 90, 90) as output, whereas, I want (3, 90, 90) as the desired output.\n\nAny idea how to achieve this?","classes":{"dataset":0.371563375}}
{"title":"YOLO equation","description":"Hi,Can any one explain this equation?Pr(Classi|Object) \u2217 Pr(Object) \u2217 IOU = Pr(Classi) \u2217 IOUIt is from the You Look Only Once article, but it seems mathematically wrong. Shouldnt be like this  Pr(Classi|Object) \u2217 Pr(Object) \u2217 IOU = Pr(Classi\\^Object) \u2217 IOU ?","link":"https://www.reddit.com/r/deeplearning/comments/11q0c2t/yolo_equation/","created":"2023-03-13","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":5},"text":"YOLO equation Hi,Can any one explain this equation?Pr(Classi|Object) \u2217 Pr(Object) \u2217 IOU = Pr(Classi) \u2217 IOUIt is from the You Look Only Once article, but it seems mathematically wrong. Shouldnt be like this  Pr(Classi|Object) \u2217 Pr(Object) \u2217 IOU = Pr(Classi\\^Object) \u2217 IOU ?","classes":{"dataset":0.2535766363}}
{"title":"[D] Simple Questions Thread","description":"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!","link":"https://www.reddit.com/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/","created":"2023-03-12","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":25},"text":"[D] Simple Questions Thread Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!","classes":{"dataset":0.3437190354}}
{"title":"[News] OpenAI Announced GPT-4","description":"Research blog:\n\n[https://openai.com/research/gpt-4](https://openai.com/research/gpt-4)\n\nProduct demo:\n\n[https://openai.com/product/gpt-4](https://openai.com/product/gpt-4)\n\nResearch report:\n\n[https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf)\n\nAPI waitlist:\n\n[https://openai.com/waitlist/gpt-4-api](https://openai.com/waitlist/gpt-4-api)\n\nTwitter announcement:\n\n [https://twitter.com/OpenAI/status/1635687373060317185](https://twitter.com/OpenAI/status/1635687373060317185)\n\nOpenAI developer livestream:\n\n[https://www.youtube.com/watch?v=outcGtbnMuQ](https://www.youtube.com/watch?v=outcGtbnMuQ&amp;ab_channel=OpenAI)","link":"https://www.reddit.com/r/MachineLearning/comments/11rc02e/news_openai_announced_gpt4/","created":"2023-03-14","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":195},"text":"[News] OpenAI Announced GPT-4 Research blog:\n\n[https://openai.com/research/gpt-4](https://openai.com/research/gpt-4)\n\nProduct demo:\n\n[https://openai.com/product/gpt-4](https://openai.com/product/gpt-4)\n\nResearch report:\n\n[https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf)\n\nAPI waitlist:\n\n[https://openai.com/waitlist/gpt-4-api](https://openai.com/waitlist/gpt-4-api)\n\nTwitter announcement:\n\n [https://twitter.com/OpenAI/status/1635687373060317185](https://twitter.com/OpenAI/status/1635687373060317185)\n\nOpenAI developer livestream:\n\n[https://www.youtube.com/watch?v=outcGtbnMuQ](https://www.youtube.com/watch?v=outcGtbnMuQ&amp;ab_channel=OpenAI)","classes":{"dataset":0.1964695454}}
{"title":"[N] Baidu to Unveil Conversational AI ERNIE Bot on March 16 (Live)","description":"Baidu will unveil its conversational AI ERNIE Bot, powered by Baidu's in-house LLMs, on March 16. The ERNIE LLM was first proposed as a language understanding model in 2019 and evolved to ERNIE 3.0 Titan with 260 billion parameters.\n\nERNIE 1.0: [https://arxiv.org/abs/1904.09223](https://arxiv.org/abs/1904.09223)\n\nERNIE 2.0: [https://arxiv.org/abs/1907.12412](https://arxiv.org/abs/1907.12412)\n\nERNIE 3.0: [https://arxiv.org/abs/2112.12731](https://arxiv.org/abs/2112.12731)\n\nERNIE for text-to-image: [https://arxiv.org/abs/2210.15257](https://arxiv.org/abs/2210.15257)\n\nERNIE Bot live-stream on YouTube: [https://www.youtube.com/watch?v=ukvEUI3x0vI](https://www.youtube.com/watch?v=ukvEUI3x0vI)","link":"https://www.reddit.com/r/MachineLearning/comments/11rfxca/n_baidu_to_unveil_conversational_ai_ernie_bot_on/","created":"2023-03-15","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":7},"text":"[N] Baidu to Unveil Conversational AI ERNIE Bot on March 16 (Live) Baidu will unveil its conversational AI ERNIE Bot, powered by Baidu's in-house LLMs, on March 16. The ERNIE LLM was first proposed as a language understanding model in 2019 and evolved to ERNIE 3.0 Titan with 260 billion parameters.\n\nERNIE 1.0: [https://arxiv.org/abs/1904.09223](https://arxiv.org/abs/1904.09223)\n\nERNIE 2.0: [https://arxiv.org/abs/1907.12412](https://arxiv.org/abs/1907.12412)\n\nERNIE 3.0: [https://arxiv.org/abs/2112.12731](https://arxiv.org/abs/2112.12731)\n\nERNIE for text-to-image: [https://arxiv.org/abs/2210.15257](https://arxiv.org/abs/2210.15257)\n\nERNIE Bot live-stream on YouTube: [https://www.youtube.com/watch?v=ukvEUI3x0vI](https://www.youtube.com/watch?v=ukvEUI3x0vI)","classes":{"dataset":0.2208731622}}
{"title":"techniques to monitor forecasting and regression models? [R][P]","description":"Hi guys,\nFor classification models we can check error and population stability index(psi) for monitoring the performance.Similarly what are the options for forecasting and regression models?","link":"https://www.reddit.com/r/MachineLearning/comments/11rmsce/techniques_to_monitor_forecasting_and_regression/","created":"2023-03-15","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0},"text":"techniques to monitor forecasting and regression models? [R][P] Hi guys,\nFor classification models we can check error and population stability index(psi) for monitoring the performance.Similarly what are the options for forecasting and regression models?","classes":{"dataset":0.2303441316}}
{"title":"[D] Choosing Cloud vs local hardware for training LLMs. What's best for a small research group?","description":"We have a 20-40k budget at our lab and we are interested in training LLMs on data that is protected by HIPAA which puts restrictions on using just any cloud provider. We'd need a compute environment with 256gb vram.\n\nWould it be better to use AWS EC2 P3 instances or Google Cloud instead of trying to build our own server for this? We could spend the budget on a local server, but would this be obsolete within 2 years once the next gen GPUs are released?","link":"https://www.reddit.com/r/MachineLearning/comments/11rnppe/d_choosing_cloud_vs_local_hardware_for_training/","created":"2023-03-15","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":8},"text":"[D] Choosing Cloud vs local hardware for training LLMs. What's best for a small research group? We have a 20-40k budget at our lab and we are interested in training LLMs on data that is protected by HIPAA which puts restrictions on using just any cloud provider. We'd need a compute environment with 256gb vram.\n\nWould it be better to use AWS EC2 P3 instances or Google Cloud instead of trying to build our own server for this? We could spend the budget on a local server, but would this be obsolete within 2 years once the next gen GPUs are released?","classes":{"dataset":0.2722116709}}
{"title":"[R] Has there been a big advancement in ML after the transformer model?","description":"I'm looking for a bachelor's thesis topic, and I feel like transformer is kind of an old topic already, I'd like something more contemporary.\n\nThanks!","link":"https://www.reddit.com/r/MachineLearning/comments/11rppi2/r_has_there_been_a_big_advancement_in_ml_after/","created":"2023-03-15","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":2},"text":"[R] Has there been a big advancement in ML after the transformer model? I'm looking for a bachelor's thesis topic, and I feel like transformer is kind of an old topic already, I'd like something more contemporary.\n\nThanks!","classes":{"dataset":0.005461256}}
{"title":"[D] On research directions being \"out of date\"","description":"For  the papers we have submitted in recent years, there has been a  significant increase in the number of reviewers whose only complaint is the paper not following a \"hip\" version of the research topic. They don't care about the results and don't care about the merit of the work,  their problem is that our work does not follow the trend. It feels like  there is this subset of reviewers see anything that is more than a year old as \"out of date\" and a reason for rejection.\n\nHave we been unlucky with our reviewer bingo recently or is this the case for others as well?","link":"https://www.reddit.com/r/MachineLearning/comments/11r97fn/d_on_research_directions_being_out_of_date/","created":"2023-03-14","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":5},"text":"[D] On research directions being \"out of date\" For  the papers we have submitted in recent years, there has been a  significant increase in the number of reviewers whose only complaint is the paper not following a \"hip\" version of the research topic. They don't care about the results and don't care about the merit of the work,  their problem is that our work does not follow the trend. It feels like  there is this subset of reviewers see anything that is more than a year old as \"out of date\" and a reason for rejection.\n\nHave we been unlucky with our reviewer bingo recently or is this the case for others as well?","classes":{"dataset":0.3907813132}}
{"title":"[D] Model for pattern classification","description":"I have a pattern list having 5-7 classes, where each class has 500+ similar patterns. Is there any model which can be trained on these patterns so that model can be able to classify a given pattern.","link":"https://www.reddit.com/r/MachineLearning/comments/11rnj5k/d_model_for_pattern_classification/","created":"2023-03-15","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0},"text":"[D] Model for pattern classification I have a pattern list having 5-7 classes, where each class has 500+ similar patterns. Is there any model which can be trained on these patterns so that model can be able to classify a given pattern.","classes":{"dataset":0.4869087338}}
{"title":"Modern language models refute Chomsky\u2019s approach to language [R]","description":"[https://lingbuzz.net/lingbuzz/007180](https://lingbuzz.net/lingbuzz/007180)","link":"https://www.reddit.com/r/MachineLearning/comments/11rmgzs/modern_language_models_refute_chomskys_approach/","created":"2023-03-15","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":1},"text":"Modern language models refute Chomsky\u2019s approach to language [R] [https://lingbuzz.net/lingbuzz/007180](https://lingbuzz.net/lingbuzz/007180)","classes":{"dataset":0.4493791759}}
{"title":"[D] Does anyone have a pdf of Hinton\u2019s talk \u201cAetherial Symbols\u201d?","description":"This talk got referenced in something I was reading, and I was really interested in checking it out, but the links all seem to this [https://drive.google.com/file/d/0B8i61jl8OE3XdHRCSkV1VFNqTWc/view](https://drive.google.com/file/d/0B8i61jl8OE3XdHRCSkV1VFNqTWc/view), which is no longer publicly accessible. I was wondering if anyone had a copy somewhere","link":"https://www.reddit.com/r/MachineLearning/comments/11reurv/d_does_anyone_have_a_pdf_of_hintons_talk/","created":"2023-03-14","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0},"text":"[D] Does anyone have a pdf of Hinton\u2019s talk \u201cAetherial Symbols\u201d? This talk got referenced in something I was reading, and I was really interested in checking it out, but the links all seem to this [https://drive.google.com/file/d/0B8i61jl8OE3XdHRCSkV1VFNqTWc/view](https://drive.google.com/file/d/0B8i61jl8OE3XdHRCSkV1VFNqTWc/view), which is no longer publicly accessible. I was wondering if anyone had a copy somewhere","classes":{"dataset":0.467158854}}
{"title":"[R] Stanford-Alpaca 7B model (an instruction tuned version of LLaMA) performs as well as text-davinci-003","description":"According to the authors, the model performs on par with text-davinci-003 in a small scale human study (the five authors of the paper rated model outputs), despite the Alpaca 7B model being much smaller than text-davinci-003. Read the blog post for details.\n\nBlog post: https://crfm.stanford.edu/2023/03/13/alpaca.html\nDemo: https://crfm.stanford.edu/alpaca/\nCode: https://github.com/tatsu-lab/stanford_alpaca","link":"https://www.reddit.com/r/MachineLearning/comments/11qfcwb/r_stanfordalpaca_7b_model_an_instruction_tuned/","created":"2023-03-13","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":109},"text":"[R] Stanford-Alpaca 7B model (an instruction tuned version of LLaMA) performs as well as text-davinci-003 According to the authors, the model performs on par with text-davinci-003 in a small scale human study (the five authors of the paper rated model outputs), despite the Alpaca 7B model being much smaller than text-davinci-003. Read the blog post for details.\n\nBlog post: https://crfm.stanford.edu/2023/03/13/alpaca.html\nDemo: https://crfm.stanford.edu/alpaca/\nCode: https://github.com/tatsu-lab/stanford_alpaca","classes":{"dataset":0.467287153}}
{"title":"[D]Query on the uniqueness of GPT-based chatbots","description":"I have this question bugging me, and I'm a noob to this. So, if ChatGPT and the likes are all LLMs, built on GPT, and are trained with the same data like from Github, Wikipedia and such, won't they be giving more or less the same answer if each is separately asked the same question?","link":"https://www.reddit.com/r/MachineLearning/comments/11r9etj/dquery_on_the_uniqueness_of_gptbased_chatbots/","created":"2023-03-14","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":4},"text":"[D]Query on the uniqueness of GPT-based chatbots I have this question bugging me, and I'm a noob to this. So, if ChatGPT and the likes are all LLMs, built on GPT, and are trained with the same data like from Github, Wikipedia and such, won't they be giving more or less the same answer if each is separately asked the same question?","classes":{"dataset":0.4452554882}}
{"title":"[P] We are building a curated list of awesome curated list closely related to machine learning, looking for contributions.","description":"Hey r/MachineLearning,\n\nWe are collecting a hand-crafted curated list of awesome curated lists closely related to machine learning.\n\nHere is the link to the Github repo: https://github.com/zhimin-z/awesome-awesome-machine-learning\n\nDo any lists need to be included from your perspective? Please let me know, or feel free to submit a pull request.\n\nThe motivation underlying this project is that so many awesome lists regarding machine learning exist on GitHub. But, gradually, it adds a mental burden to memorize where to look for when the ML world is progressing faster and faster these days.\n\nThus, there the project comes, as a unification to sew together all awesome lists closely related to machine learning.","link":"https://www.reddit.com/r/MachineLearning/comments/11rfbnw/p_we_are_building_a_curated_list_of_awesome/","created":"2023-03-14","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":1},"text":"[P] We are building a curated list of awesome curated list closely related to machine learning, looking for contributions. Hey r/MachineLearning,\n\nWe are collecting a hand-crafted curated list of awesome curated lists closely related to machine learning.\n\nHere is the link to the Github repo: https://github.com/zhimin-z/awesome-awesome-machine-learning\n\nDo any lists need to be included from your perspective? Please let me know, or feel free to submit a pull request.\n\nThe motivation underlying this project is that so many awesome lists regarding machine learning exist on GitHub. But, gradually, it adds a mental burden to memorize where to look for when the ML world is progressing faster and faster these days.\n\nThus, there the project comes, as a unification to sew together all awesome lists closely related to machine learning.","classes":{"dataset":0.3856759965}}
{"title":"How do I select sentences in text which talk about specific thing?","description":"I have following sentences in mobile review:\n\n&gt; The camera lens is really of good quality with 1 cm sensor. The pictures turns out to have more realistic colour tone. But the mobile does not have good colour option. The battery life is also descent and not to mention that processor is top notch. However, the pics can sometimes turn out to be over exposed.\n\nI want to select only those sentences which talk about camera quality in above paragraph. In other words, I want to select following sentences:\n\n* The camera lens is really of good quality with 1 cm sensor. \n* The pictures turns out to have more realistic colour tone.\n* However, the pics can sometimes turn out to be over exposed.\n\nWhat ML model / concept / idea I can use to achieve this?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11rs3sh/how_do_i_select_sentences_in_text_which_talk/","created":"2023-03-15","tags":["ml","languagetechnology","reddit"],"meta":{"num_comments":0},"text":"How do I select sentences in text which talk about specific thing? I have following sentences in mobile review:\n\n&gt; The camera lens is really of good quality with 1 cm sensor. The pictures turns out to have more realistic colour tone. But the mobile does not have good colour option. The battery life is also descent and not to mention that processor is top notch. However, the pics can sometimes turn out to be over exposed.\n\nI want to select only those sentences which talk about camera quality in above paragraph. In other words, I want to select following sentences:\n\n* The camera lens is really of good quality with 1 cm sensor. \n* The pictures turns out to have more realistic colour tone.\n* However, the pics can sometimes turn out to be over exposed.\n\nWhat ML model / concept / idea I can use to achieve this?","classes":{"dataset":0.3142071962}}
{"title":"Finno-Ugric open-source machine translation","description":"We here at the University of Tartu created an NMT engine for 23 Finno-Ugric languages, targeting low-resource languages: Livonian, Komi, Udmurt, V\u00f5ro and several others. Most of the covered low-res languages are not part of Meta's M2M100 or NLLB, nor are they part of Google Translate, Bing Translator or DeepL yet.\n\nFairSeq translation model and full list of supported languages here: [https://huggingface.co/tartuNLP/smugri3-finno-ugric-nmt](https://huggingface.co/tartuNLP/smugri3-finno-ugric-nmt). Online demo here: [https://translate.ut.ee/](https://translate.ut.ee/), submitting corrected translations is also supported, in case you speak any of these languages - we are hoping to use the feedback to improve translation quality in the near future.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11r0izu/finnougric_opensource_machine_translation/","created":"2023-03-14","tags":["ml","languagetechnology","reddit"],"meta":{"num_comments":0},"text":"Finno-Ugric open-source machine translation We here at the University of Tartu created an NMT engine for 23 Finno-Ugric languages, targeting low-resource languages: Livonian, Komi, Udmurt, V\u00f5ro and several others. Most of the covered low-res languages are not part of Meta's M2M100 or NLLB, nor are they part of Google Translate, Bing Translator or DeepL yet.\n\nFairSeq translation model and full list of supported languages here: [https://huggingface.co/tartuNLP/smugri3-finno-ugric-nmt](https://huggingface.co/tartuNLP/smugri3-finno-ugric-nmt). Online demo here: [https://translate.ut.ee/](https://translate.ut.ee/), submitting corrected translations is also supported, in case you speak any of these languages - we are hoping to use the feedback to improve translation quality in the near future.","classes":{"dataset":0.3177036047}}
{"title":"A corpus fully about STEM","description":"Hello, \n\nIs there a corpus fully dedicated to STEM?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11r8zp9/a_corpus_fully_about_stem/","created":"2023-03-14","tags":["ml","languagetechnology","reddit"],"meta":{"num_comments":1},"text":"A corpus fully about STEM Hello, \n\nIs there a corpus fully dedicated to STEM?","classes":{"dataset":0.3406670392}}
{"title":"Structured Data-to-Text Generation (with little coding)?","description":"I'm looking to generate very structured text output from ideally a basic UI offering (consecutive 'decision-tree'-like) multiple choice inputs and text input boxes.\n\nIs there any software that can be programmed via some basic rules without requiring a lot of coding experience?\n\nI'm completely new to this field, so any hint is much appreciated!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11r2yub/structured_datatotext_generation_with_little/","created":"2023-03-14","tags":["ml","languagetechnology","reddit"],"meta":{"num_comments":0},"text":"Structured Data-to-Text Generation (with little coding)? I'm looking to generate very structured text output from ideally a basic UI offering (consecutive 'decision-tree'-like) multiple choice inputs and text input boxes.\n\nIs there any software that can be programmed via some basic rules without requiring a lot of coding experience?\n\nI'm completely new to this field, so any hint is much appreciated!","classes":{"dataset":0.2253130823}}
{"title":"Optimum Dataset for Sequence Labelling","description":"Hi everyone. I'm working on a custom NER like task.\n\nHowever some tags have very low frequency in the data. Hence mode is not good in predicting them.\n\nThis problem got me thinking what would the optimum dataset look like for such a task? \nShould number of samples for each label be similar? \nif we increase the data for all labels but keep a specific label same would it impact the preformance?\n\nPapers usually just take a toy dataset and tweak the model or data little bit. I couldn't find an answer to these questions. Do you have any resource or knowledge on this?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11qf9sv/optimum_dataset_for_sequence_labelling/","created":"2023-03-13","tags":["ml","languagetechnology","reddit"],"meta":{"num_comments":2},"text":"Optimum Dataset for Sequence Labelling Hi everyone. I'm working on a custom NER like task.\n\nHowever some tags have very low frequency in the data. Hence mode is not good in predicting them.\n\nThis problem got me thinking what would the optimum dataset look like for such a task? \nShould number of samples for each label be similar? \nif we increase the data for all labels but keep a specific label same would it impact the preformance?\n\nPapers usually just take a toy dataset and tweak the model or data little bit. I couldn't find an answer to these questions. Do you have any resource or knowledge on this?","classes":{"dataset":0.0635348856}}
{"title":"NeRFtrinsic Four: An End-To-End Trainable NeRF Jointly Optimizing Diverse Intrinsic and Extrinsic Camera Parameters","description":"Novel view synthesis using neural radiance fields (NeRF) is the state-of-the-art technique for generating high-quality images from novel viewpoints. Existing methods require a priori knowledge about extrinsic and intrinsic camera parameters. This limits their applicability to synthetic scenes, or real-world scenarios with the necessity of a preprocessing step. Current research on the joint optimization of camera parameters and NeRF focuses on refining noisy extrinsic camera parameters and often relies on the preprocessing of intrinsic camera parameters. Further approaches are limited to cover only one single camera intrinsic. To address these limitations, we propose a novel end-to-end trainable approach called NeRFtrinsic Four. We utilize Gaussian Fourier features to estimate extrinsic camera parameters and dynamically predict varying intrinsic camera parameters through the supervision of the projection error. Our approach outperforms existing joint optimization methods on LLFF and BLEFF. In addition to these existing datasets, we introduce a new dataset called iFF with varying intrinsic camera parameters. NeRFtrinsic Four is a step forward in joint optimization NeRF-based view synthesis and enables more realistic and flexible rendering in real-world scenarios with varying camera parameters.","link":"http://arxiv.org/abs/2303.09412v1","created":"2023-03-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"NeRFtrinsic Four: An End-To-End Trainable NeRF Jointly Optimizing Diverse Intrinsic and Extrinsic Camera Parameters Novel view synthesis using neural radiance fields (NeRF) is the state-of-the-art technique for generating high-quality images from novel viewpoints. Existing methods require a priori knowledge about extrinsic and intrinsic camera parameters. This limits their applicability to synthetic scenes, or real-world scenarios with the necessity of a preprocessing step. Current research on the joint optimization of camera parameters and NeRF focuses on refining noisy extrinsic camera parameters and often relies on the preprocessing of intrinsic camera parameters. Further approaches are limited to cover only one single camera intrinsic. To address these limitations, we propose a novel end-to-end trainable approach called NeRFtrinsic Four. We utilize Gaussian Fourier features to estimate extrinsic camera parameters and dynamically predict varying intrinsic camera parameters through the supervision of the projection error. Our approach outperforms existing joint optimization methods on LLFF and BLEFF. In addition to these existing datasets, we introduce a new dataset called iFF with varying intrinsic camera parameters. NeRFtrinsic Four is a step forward in joint optimization NeRF-based view synthesis and enables more realistic and flexible rendering in real-world scenarios with varying camera parameters.","classes":{"dataset":0.410320878}}
{"title":"ShabbyPages: A Reproducible Document Denoising and Binarization Dataset","description":"Document denoising and binarization are fundamental problems in the document processing space, but current datasets are often too small and lack sufficient complexity to effectively train and benchmark modern data-driven machine learning models. To fill this gap, we introduce ShabbyPages, a new document image dataset designed for training and benchmarking document denoisers and binarizers. ShabbyPages contains over 6,000 clean \"born digital\" images with synthetically-noised counterparts (\"shabby pages\") that were augmented using the Augraphy document augmentation tool to appear as if they have been printed and faxed, photocopied, or otherwise altered through physical processes. In this paper, we discuss the creation process of ShabbyPages and demonstrate the utility of ShabbyPages by training convolutional denoisers which remove real noise features with a high degree of human-perceptible fidelity, establishing baseline performance for a new ShabbyPages benchmark.","link":"http://arxiv.org/abs/2303.09339v1","created":"2023-03-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"ShabbyPages: A Reproducible Document Denoising and Binarization Dataset Document denoising and binarization are fundamental problems in the document processing space, but current datasets are often too small and lack sufficient complexity to effectively train and benchmark modern data-driven machine learning models. To fill this gap, we introduce ShabbyPages, a new document image dataset designed for training and benchmarking document denoisers and binarizers. ShabbyPages contains over 6,000 clean \"born digital\" images with synthetically-noised counterparts (\"shabby pages\") that were augmented using the Augraphy document augmentation tool to appear as if they have been printed and faxed, photocopied, or otherwise altered through physical processes. In this paper, we discuss the creation process of ShabbyPages and demonstrate the utility of ShabbyPages by training convolutional denoisers which remove real noise features with a high degree of human-perceptible fidelity, establishing baseline performance for a new ShabbyPages benchmark.","classes":{"dataset":0.3943372965}}
{"title":"VDPVE: VQA Dataset for Perceptual Video Enhancement","description":"Recently, many video enhancement methods have been proposed to improve video quality from different aspects such as color, brightness, contrast, and stability. Therefore, how to evaluate the quality of the enhanced video in a way consistent with human visual perception is an important research topic. However, most video quality assessment methods mainly calculate video quality by estimating the distortion degrees of videos from an overall perspective. Few researchers have specifically proposed a video quality assessment method for video enhancement, and there is also no comprehensive video quality assessment dataset available in public. Therefore, we construct a Video quality assessment dataset for Perceptual Video Enhancement (VDPVE) in this paper. The VDPVE has 1211 videos with different enhancements, which can be divided into three sub-datasets: the first sub-dataset has 600 videos with color, brightness, and contrast enhancements; the second sub-dataset has 310 videos with deblurring; and the third sub-dataset has 301 deshaked videos. We invited 21 subjects (20 valid subjects) to rate all enhanced videos in the VDPVE. After normalizing and averaging the subjective opinion scores, the mean opinion score of each video can be obtained. Furthermore, we split the VDPVE into a training set, a validation set, and a test set, and verify the performance of several state-of-the-art video quality assessment methods on the test set of the VDPVE.","link":"http://arxiv.org/abs/2303.09290v1","created":"2023-03-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"VDPVE: VQA Dataset for Perceptual Video Enhancement Recently, many video enhancement methods have been proposed to improve video quality from different aspects such as color, brightness, contrast, and stability. Therefore, how to evaluate the quality of the enhanced video in a way consistent with human visual perception is an important research topic. However, most video quality assessment methods mainly calculate video quality by estimating the distortion degrees of videos from an overall perspective. Few researchers have specifically proposed a video quality assessment method for video enhancement, and there is also no comprehensive video quality assessment dataset available in public. Therefore, we construct a Video quality assessment dataset for Perceptual Video Enhancement (VDPVE) in this paper. The VDPVE has 1211 videos with different enhancements, which can be divided into three sub-datasets: the first sub-dataset has 600 videos with color, brightness, and contrast enhancements; the second sub-dataset has 310 videos with deblurring; and the third sub-dataset has 301 deshaked videos. We invited 21 subjects (20 valid subjects) to rate all enhanced videos in the VDPVE. After normalizing and averaging the subjective opinion scores, the mean opinion score of each video can be obtained. Furthermore, we split the VDPVE into a training set, a validation set, and a test set, and verify the performance of several state-of-the-art video quality assessment methods on the test set of the VDPVE.","classes":{"dataset":0.9443339109}}
{"title":"Fairness-aware Differentially Private Collaborative Filtering","description":"Recently, there has been an increasing adoption of differential privacy guided algorithms for privacy-preserving machine learning tasks. However, the use of such algorithms comes with trade-offs in terms of algorithmic fairness, which has been widely acknowledged. Specifically, we have empirically observed that the classical collaborative filtering method, trained by differentially private stochastic gradient descent (DP-SGD), results in a disparate impact on user groups with respect to different user engagement levels. This, in turn, causes the original unfair model to become even more biased against inactive users. To address the above issues, we propose \\textbf{DP-Fair}, a two-stage framework for collaborative filtering based algorithms. Specifically, it combines differential privacy mechanisms with fairness constraints to protect user privacy while ensuring fair recommendations. The experimental results, based on Amazon datasets, and user history logs collected from Etsy, one of the largest e-commerce platforms, demonstrate that our proposed method exhibits superior performance in terms of both overall accuracy and user group fairness on both shallow and deep recommendation models compared to vanilla DP-SGD.","link":"http://arxiv.org/abs/2303.09527v1","created":"2023-03-16","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Fairness-aware Differentially Private Collaborative Filtering Recently, there has been an increasing adoption of differential privacy guided algorithms for privacy-preserving machine learning tasks. However, the use of such algorithms comes with trade-offs in terms of algorithmic fairness, which has been widely acknowledged. Specifically, we have empirically observed that the classical collaborative filtering method, trained by differentially private stochastic gradient descent (DP-SGD), results in a disparate impact on user groups with respect to different user engagement levels. This, in turn, causes the original unfair model to become even more biased against inactive users. To address the above issues, we propose \\textbf{DP-Fair}, a two-stage framework for collaborative filtering based algorithms. Specifically, it combines differential privacy mechanisms with fairness constraints to protect user privacy while ensuring fair recommendations. The experimental results, based on Amazon datasets, and user history logs collected from Etsy, one of the largest e-commerce platforms, demonstrate that our proposed method exhibits superior performance in terms of both overall accuracy and user group fairness on both shallow and deep recommendation models compared to vanilla DP-SGD.","classes":{"dataset":0.9737229943}}
{"title":"Image Classifiers Leak Sensitive Attributes About Their Classes","description":"Neural network-based image classifiers are powerful tools for computer vision tasks, but they inadvertently reveal sensitive attribute information about their classes, raising concerns about their privacy. To investigate this privacy leakage, we introduce the first Class Attribute Inference Attack (Caia), which leverages recent advances in text-to-image synthesis to infer sensitive attributes of individual classes in a black-box setting, while remaining competitive with related white-box attacks. Our extensive experiments in the face recognition domain show that Caia can accurately infer undisclosed sensitive attributes, such as an individual's hair color, gender and racial appearance, which are not part of the training labels. Interestingly, we demonstrate that adversarial robust models are even more vulnerable to such privacy leakage than standard models, indicating that a trade-off between robustness and privacy exists.","link":"http://arxiv.org/abs/2303.09289v1","created":"2023-03-16","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Image Classifiers Leak Sensitive Attributes About Their Classes Neural network-based image classifiers are powerful tools for computer vision tasks, but they inadvertently reveal sensitive attribute information about their classes, raising concerns about their privacy. To investigate this privacy leakage, we introduce the first Class Attribute Inference Attack (Caia), which leverages recent advances in text-to-image synthesis to infer sensitive attributes of individual classes in a black-box setting, while remaining competitive with related white-box attacks. Our extensive experiments in the face recognition domain show that Caia can accurately infer undisclosed sensitive attributes, such as an individual's hair color, gender and racial appearance, which are not part of the training labels. Interestingly, we demonstrate that adversarial robust models are even more vulnerable to such privacy leakage than standard models, indicating that a trade-off between robustness and privacy exists.","classes":{"dataset":0.3943372965}}
{"title":"Robust Evaluation of Diffusion-Based Adversarial Purification","description":"We question the current evaluation practice on diffusion-based purification methods. Diffusion-based purification methods aim to remove adversarial effects from an input data point at test time. The approach gains increasing attention as an alternative to adversarial training due to the disentangling between training and testing. Well-known white-box attacks are often employed to measure the robustness of the purification. However, it is unknown whether these attacks are the most effective for the diffusion-based purification since the attacks are often tailored for adversarial training. We analyze the current practices and provide a new guideline for measuring the robustness of purification methods against adversarial attacks. Based on our analysis, we further propose a new purification strategy showing competitive results against the state-of-the-art adversarial training approaches.","link":"http://arxiv.org/abs/2303.09051v1","created":"2023-03-16","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Robust Evaluation of Diffusion-Based Adversarial Purification We question the current evaluation practice on diffusion-based purification methods. Diffusion-based purification methods aim to remove adversarial effects from an input data point at test time. The approach gains increasing attention as an alternative to adversarial training due to the disentangling between training and testing. Well-known white-box attacks are often employed to measure the robustness of the purification. However, it is unknown whether these attacks are the most effective for the diffusion-based purification since the attacks are often tailored for adversarial training. We analyze the current practices and provide a new guideline for measuring the robustness of purification methods against adversarial attacks. Based on our analysis, we further propose a new purification strategy showing competitive results against the state-of-the-art adversarial training approaches.","classes":{"dataset":0.0151670808}}
{"title":"Block-wise Bit-Compression of Transformer-based Models","description":"With the popularity of the recent Transformer-based models represented by BERT, GPT-3 and ChatGPT, there has been state-of-the-art performance in a range of natural language processing tasks. However, the massive computations, huge memory footprint, and thus high latency of Transformer-based models is an inevitable challenge for the cloud with high real-time requirement. To tackle the issue, we propose BBCT, a method of block-wise bit-compression for transformer without retraining. Our method achieves more fine-grained compression of the whole transformer, including embedding, matrix multiplication, GELU, softmax, layer normalization, and all the intermediate results. As a case, we compress an efficient BERT with the method of BBCT. Our benchmark test results on General Language Understanding Evaluation (GLUE) show that BBCT can achieve less than 1% accuracy drop in most tasks.","link":"http://arxiv.org/abs/2303.09184v1","created":"2023-03-16","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Block-wise Bit-Compression of Transformer-based Models With the popularity of the recent Transformer-based models represented by BERT, GPT-3 and ChatGPT, there has been state-of-the-art performance in a range of natural language processing tasks. However, the massive computations, huge memory footprint, and thus high latency of Transformer-based models is an inevitable challenge for the cloud with high real-time requirement. To tackle the issue, we propose BBCT, a method of block-wise bit-compression for transformer without retraining. Our method achieves more fine-grained compression of the whole transformer, including embedding, matrix multiplication, GELU, softmax, layer normalization, and all the intermediate results. As a case, we compress an efficient BERT with the method of BBCT. Our benchmark test results on General Language Understanding Evaluation (GLUE) show that BBCT can achieve less than 1% accuracy drop in most tasks.","classes":{"dataset":0.1001726463}}
{"title":"LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations","description":"Large Language Models (LLMs) like Codex are powerful tools for performing code completion and code generation tasks as they are trained on billions of lines of code from publicly available sources. Moreover, these models are capable of generating code snippets from Natural Language (NL) descriptions by learning languages and programming practices from public GitHub repositories. Although LLMs promise an effortless NL-driven deployment of software applications, the security of the code they generate has not been extensively investigated nor documented. In this work, we present LLMSecEval, a dataset containing 150 NL prompts that can be leveraged for assessing the security performance of such models. Such prompts are NL descriptions of code snippets prone to various security vulnerabilities listed in MITRE's Top 25 Common Weakness Enumeration (CWE) ranking. Each prompt in our dataset comes with a secure implementation example to facilitate comparative evaluations against code produced by LLMs. As a practical application, we show how LLMSecEval can be used for evaluating the security of snippets automatically generated from NL descriptions.","link":"http://arxiv.org/abs/2303.09384v1","created":"2023-03-16","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations Large Language Models (LLMs) like Codex are powerful tools for performing code completion and code generation tasks as they are trained on billions of lines of code from publicly available sources. Moreover, these models are capable of generating code snippets from Natural Language (NL) descriptions by learning languages and programming practices from public GitHub repositories. Although LLMs promise an effortless NL-driven deployment of software applications, the security of the code they generate has not been extensively investigated nor documented. In this work, we present LLMSecEval, a dataset containing 150 NL prompts that can be leveraged for assessing the security performance of such models. Such prompts are NL descriptions of code snippets prone to various security vulnerabilities listed in MITRE's Top 25 Common Weakness Enumeration (CWE) ranking. Each prompt in our dataset comes with a secure implementation example to facilitate comparative evaluations against code produced by LLMs. As a practical application, we show how LLMSecEval can be used for evaluating the security of snippets automatically generated from NL descriptions.","classes":{"dataset":0.1003119275}}
{"title":"SemDeDup: Data-efficient learning at web-scale through semantic deduplication","description":"Progress in machine learning has been driven in large part by massive increases in data. However, large web-scale datasets such as LAION are largely uncurated beyond searches for exact duplicates, potentially leaving much redundancy. Here, we introduce SemDeDup, a method which leverages embeddings from pre-trained models to identify and remove semantic duplicates: data pairs which are semantically similar, but not exactly identical. Removing semantic duplicates preserves performance and speeds up learning. Analyzing a subset of LAION, we show that SemDeDup can remove 50% of the data with minimal performance loss, effectively halving training time. Moreover, performance increases out of distribution. Also, analyzing language models trained on C4, a partially curated dataset, we show that SemDeDup improves over prior approaches while providing efficiency gains. SemDeDup provides an example of how simple ways of leveraging quality embeddings can be used to make models learn faster with less data.","link":"http://arxiv.org/abs/2303.09540v1","created":"2023-03-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"SemDeDup: Data-efficient learning at web-scale through semantic deduplication Progress in machine learning has been driven in large part by massive increases in data. However, large web-scale datasets such as LAION are largely uncurated beyond searches for exact duplicates, potentially leaving much redundancy. Here, we introduce SemDeDup, a method which leverages embeddings from pre-trained models to identify and remove semantic duplicates: data pairs which are semantically similar, but not exactly identical. Removing semantic duplicates preserves performance and speeds up learning. Analyzing a subset of LAION, we show that SemDeDup can remove 50% of the data with minimal performance loss, effectively halving training time. Moreover, performance increases out of distribution. Also, analyzing language models trained on C4, a partially curated dataset, we show that SemDeDup improves over prior approaches while providing efficiency gains. SemDeDup provides an example of how simple ways of leveraging quality embeddings can be used to make models learn faster with less data.","classes":{"dataset":0.0679512322}}
{"title":"Improving Automated Hemorrhage Detection in Sparse-view Computed Tomography via Deep Convolutional Neural Network based Artifact Reduction","description":"Intracranial hemorrhage poses a serious health problem requiring rapid and often intensive medical treatment. For diagnosis, a Cranial Computed Tomography (CCT) scan is usually performed. However, the increased health risk caused by radiation is a concern. The most important strategy to reduce this potential risk is to keep the radiation dose as low as possible and consistent with the diagnostic task. Sparse-view CT can be an effective strategy to reduce dose by reducing the total number of views acquired, albeit at the expense of image quality. In this work, we use a U-Net architecture to reduce artifacts from sparse-view CCTs, predicting fully sampled reconstructions from sparse-view ones. We evaluate the hemorrhage detectability in the predicted CCTs with a hemorrhage classification convolutional neural network, trained on fully sampled CCTs to detect and classify different sub-types of hemorrhages. Our results suggest that the automated classification and detection accuracy of hemorrhages in sparse-view CCTs can be improved substantially by the U-Net. This demonstrates the feasibility of rapid automated hemorrhage detection on low-dose CT data to assist radiologists in routine clinical practice.","link":"http://arxiv.org/abs/2303.09340v1","created":"2023-03-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Improving Automated Hemorrhage Detection in Sparse-view Computed Tomography via Deep Convolutional Neural Network based Artifact Reduction Intracranial hemorrhage poses a serious health problem requiring rapid and often intensive medical treatment. For diagnosis, a Cranial Computed Tomography (CCT) scan is usually performed. However, the increased health risk caused by radiation is a concern. The most important strategy to reduce this potential risk is to keep the radiation dose as low as possible and consistent with the diagnostic task. Sparse-view CT can be an effective strategy to reduce dose by reducing the total number of views acquired, albeit at the expense of image quality. In this work, we use a U-Net architecture to reduce artifacts from sparse-view CCTs, predicting fully sampled reconstructions from sparse-view ones. We evaluate the hemorrhage detectability in the predicted CCTs with a hemorrhage classification convolutional neural network, trained on fully sampled CCTs to detect and classify different sub-types of hemorrhages. Our results suggest that the automated classification and detection accuracy of hemorrhages in sparse-view CCTs can be improved substantially by the U-Net. This demonstrates the feasibility of rapid automated hemorrhage detection on low-dose CT data to assist radiologists in routine clinical practice.","classes":{"dataset":0.7023160458}}
{"title":"GIRT-Data: Sampling GitHub Issue Report Templates","description":"GitHub's issue reports provide developers with valuable information that is essential to the evolution of a software development project. Contributors can use these reports to perform software engineering tasks like submitting bugs, requesting features, and collaborating on ideas. In the initial versions of issue reports, there was no standard way of using them. As a result, the quality of issue reports varied widely. To improve the quality of issue reports, GitHub introduced issue report templates (IRTs), which pre-fill issue descriptions when a new issue is opened. An IRT usually contains greeting contributors, describing project guidelines, and collecting relevant information. However, despite of effectiveness of this feature which was introduced in 2016, only nearly 5% of GitHub repositories (with more than 10 stars) utilize it. There are currently few articles on IRTs, and the available ones only consider a small number of repositories. In this work, we introduce GIRT-Data, the first and largest dataset of IRTs in both YAML and Markdown format. This dataset and its corresponding open-source crawler tool are intended to support research in this area and to encourage more developers to use IRTs in their repositories. The stable version of the dataset contains 1,084,300 repositories and 50,032 of them support IRTs. The stable version of the dataset and crawler is available here: https://github.com/kargaranamir/girt-data","link":"http://arxiv.org/abs/2303.09236v1","created":"2023-03-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"GIRT-Data: Sampling GitHub Issue Report Templates GitHub's issue reports provide developers with valuable information that is essential to the evolution of a software development project. Contributors can use these reports to perform software engineering tasks like submitting bugs, requesting features, and collaborating on ideas. In the initial versions of issue reports, there was no standard way of using them. As a result, the quality of issue reports varied widely. To improve the quality of issue reports, GitHub introduced issue report templates (IRTs), which pre-fill issue descriptions when a new issue is opened. An IRT usually contains greeting contributors, describing project guidelines, and collecting relevant information. However, despite of effectiveness of this feature which was introduced in 2016, only nearly 5% of GitHub repositories (with more than 10 stars) utilize it. There are currently few articles on IRTs, and the available ones only consider a small number of repositories. In this work, we introduce GIRT-Data, the first and largest dataset of IRTs in both YAML and Markdown format. This dataset and its corresponding open-source crawler tool are intended to support research in this area and to encourage more developers to use IRTs in their repositories. The stable version of the dataset contains 1,084,300 repositories and 50,032 of them support IRTs. The stable version of the dataset and crawler is available here: https://github.com/kargaranamir/girt-data","classes":{"dataset":0.0372549817}}
{"title":"Reliable Image Dehazing by NeRF","description":"We present an image dehazing algorithm with high quality, wide application, and no data training or prior needed. We analyze the defects of the original dehazing model, and propose a new and reliable dehazing reconstruction and dehazing model based on the combination of optical scattering model and computer graphics lighting rendering model. Based on the new haze model and the images obtained by the cameras, we can reconstruct the three-dimensional space, accurately calculate the objects and haze in the space, and use the transparency relationship of haze to perform accurate haze removal. To obtain a 3D simulation dataset we used the Unreal 5 computer graphics rendering engine. In order to obtain real shot data in different scenes, we used fog generators, array cameras, mobile phones, underwater cameras and drones to obtain haze data. We use formula derivation, simulation data set and real shot data set result experimental results to prove the feasibility of the new method. Compared with various other methods, we are far ahead in terms of calculation indicators (4 dB higher quality average scene), color remains more natural, and the algorithm is more robust in different scenarios and best in the subjective perception.","link":"http://arxiv.org/abs/2303.09153v1","created":"2023-03-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Reliable Image Dehazing by NeRF We present an image dehazing algorithm with high quality, wide application, and no data training or prior needed. We analyze the defects of the original dehazing model, and propose a new and reliable dehazing reconstruction and dehazing model based on the combination of optical scattering model and computer graphics lighting rendering model. Based on the new haze model and the images obtained by the cameras, we can reconstruct the three-dimensional space, accurately calculate the objects and haze in the space, and use the transparency relationship of haze to perform accurate haze removal. To obtain a 3D simulation dataset we used the Unreal 5 computer graphics rendering engine. In order to obtain real shot data in different scenes, we used fog generators, array cameras, mobile phones, underwater cameras and drones to obtain haze data. We use formula derivation, simulation data set and real shot data set result experimental results to prove the feasibility of the new method. Compared with various other methods, we are far ahead in terms of calculation indicators (4 dB higher quality average scene), color remains more natural, and the algorithm is more robust in different scenarios and best in the subjective perception.","classes":{"dataset":0.5468714833}}
{"title":"Contrastive Semi-supervised Learning for Underwater Image Restoration via Reliable Bank","description":"Despite the remarkable achievement of recent underwater image restoration techniques, the lack of labeled data has become a major hurdle for further progress. In this work, we propose a mean-teacher based \\textbf{Semi}-supervised \\textbf{U}nderwater \\textbf{I}mage \\textbf{R}estoration (\\textbf{Semi-UIR}) framework to incorporate the unlabeled data into network training. However, the naive mean-teacher method suffers from two main problems: (1) The consistency loss used in training might become ineffective when the teacher's prediction is wrong. (2) Using L1 distance may cause the network to overfit wrong labels, resulting in confirmation bias. To address the above problems, we first introduce a reliable bank to store the ``best-ever\" outputs as pseudo ground truth. To assess the quality of outputs, we conduct an empirical analysis based on the monotonicity property to select the most trustworthy NR-IQA method. Besides, in view of the confirmation bias problem, we incorporate contrastive regularization to prevent the overfitting on wrong labels. Experimental results on both full-reference and non-reference underwater benchmarks demonstrate that our algorithm has obvious improvement over SOTA methods quantitatively and qualitatively. Code has been released at \\href{https://github.com/Huang-ShiRui/Semi-UIR}{https://github.com/Huang-ShiRui/Semi-UIR}.","link":"http://arxiv.org/abs/2303.09101v1","created":"2023-03-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Contrastive Semi-supervised Learning for Underwater Image Restoration via Reliable Bank Despite the remarkable achievement of recent underwater image restoration techniques, the lack of labeled data has become a major hurdle for further progress. In this work, we propose a mean-teacher based \\textbf{Semi}-supervised \\textbf{U}nderwater \\textbf{I}mage \\textbf{R}estoration (\\textbf{Semi-UIR}) framework to incorporate the unlabeled data into network training. However, the naive mean-teacher method suffers from two main problems: (1) The consistency loss used in training might become ineffective when the teacher's prediction is wrong. (2) Using L1 distance may cause the network to overfit wrong labels, resulting in confirmation bias. To address the above problems, we first introduce a reliable bank to store the ``best-ever\" outputs as pseudo ground truth. To assess the quality of outputs, we conduct an empirical analysis based on the monotonicity property to select the most trustworthy NR-IQA method. Besides, in view of the confirmation bias problem, we incorporate contrastive regularization to prevent the overfitting on wrong labels. Experimental results on both full-reference and non-reference underwater benchmarks demonstrate that our algorithm has obvious improvement over SOTA methods quantitatively and qualitatively. Code has been released at \\href{https://github.com/Huang-ShiRui/Semi-UIR}{https://github.com/Huang-ShiRui/Semi-UIR}.","classes":{"dataset":0.4709355831}}
{"title":"Conditional Synthetic Food Image Generation","description":"Generative Adversarial Networks (GAN) have been widely investigated for image synthesis based on their powerful representation learning ability. In this work, we explore the StyleGAN and its application of synthetic food image generation. Despite the impressive performance of GAN for natural image generation, food images suffer from high intra-class diversity and inter-class similarity, resulting in overfitting and visual artifacts for synthetic images. Therefore, we aim to explore the capability and improve the performance of GAN methods for food image generation. Specifically, we first choose StyleGAN3 as the baseline method to generate synthetic food images and analyze the performance. Then, we identify two issues that can cause performance degradation on food images during the training phase: (1) inter-class feature entanglement during multi-food classes training and (2) loss of high-resolution detail during image downsampling. To address both issues, we propose to train one food category at a time to avoid feature entanglement and leverage image patches cropped from high-resolution datasets to retain fine details. We evaluate our method on the Food-101 dataset and show improved quality of generated synthetic food images compared with the baseline. Finally, we demonstrate the great potential of improving the performance of downstream tasks, such as food image classification by including high-quality synthetic training samples in the data augmentation.","link":"http://arxiv.org/abs/2303.09005v1","created":"2023-03-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Conditional Synthetic Food Image Generation Generative Adversarial Networks (GAN) have been widely investigated for image synthesis based on their powerful representation learning ability. In this work, we explore the StyleGAN and its application of synthetic food image generation. Despite the impressive performance of GAN for natural image generation, food images suffer from high intra-class diversity and inter-class similarity, resulting in overfitting and visual artifacts for synthetic images. Therefore, we aim to explore the capability and improve the performance of GAN methods for food image generation. Specifically, we first choose StyleGAN3 as the baseline method to generate synthetic food images and analyze the performance. Then, we identify two issues that can cause performance degradation on food images during the training phase: (1) inter-class feature entanglement during multi-food classes training and (2) loss of high-resolution detail during image downsampling. To address both issues, we propose to train one food category at a time to avoid feature entanglement and leverage image patches cropped from high-resolution datasets to retain fine details. We evaluate our method on the Food-101 dataset and show improved quality of generated synthetic food images compared with the baseline. Finally, we demonstrate the great potential of improving the performance of downstream tasks, such as food image classification by including high-quality synthetic training samples in the data augmentation.","classes":{"dataset":0.2069609165}}
{"title":"Something Pretty Right: The History and Legacy of Visual Basic","description":"https://retool.com/visual-basic/","link":"https://retool.com/visual-basic/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":199},"text":"Something Pretty Right: The History and Legacy of Visual Basic https://retool.com/visual-basic/","classes":{"dataset":0.5044917464}}
{"title":"Copyright Registration Guidance: Works containing material generated by AI","description":"https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-containing-material-generated-by-artificial-intelligence","link":"https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-containing-material-generated-by-artificial-intelligence","created":"2023-03-17","tags":["hackernews"],"meta":{"score":293},"text":"Copyright Registration Guidance: Works containing material generated by AI https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-containing-material-generated-by-artificial-intelligence","classes":{"dataset":0.5170164108}}
{"title":"TextSynth Server","description":"https://bellard.org/ts_server/","link":"https://bellard.org/ts_server/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":78},"text":"TextSynth Server https://bellard.org/ts_server/","classes":{"dataset":0.5567198992}}
{"title":"Show HN: Learn Python with Minecraft","description":"https://github.com/gilesknap/mciwb","link":"https://github.com/gilesknap/mciwb","created":"2023-03-15","tags":["hackernews"],"meta":{"score":43},"text":"Show HN: Learn Python with Minecraft https://github.com/gilesknap/mciwb","classes":{"dataset":0.5260590315}}
{"title":"Verilog Ethernet: Work-in-Progress 100BASE-TX PHY","description":"https://github.com/Forty-Bot/ethernet","link":"https://github.com/Forty-Bot/ethernet","created":"2023-03-17","tags":["hackernews"],"meta":{"score":26},"text":"Verilog Ethernet: Work-in-Progress 100BASE-TX PHY https://github.com/Forty-Bot/ethernet","classes":{"dataset":0.5339092612}}
{"title":"DDRamDisk: RAM disk, a disk based on RAM memory chips","description":"https://ddramdisk.store/","link":"https://ddramdisk.store/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":7},"text":"DDRamDisk: RAM disk, a disk based on RAM memory chips https://ddramdisk.store/","classes":{"dataset":0.507349968}}
{"title":"Prostate cancer could be treated by destroying tumors with electricity","description":"https://www.telegraph.co.uk/news/2022/01/02/one-hour-operation-could-cure-prostate-cancer-destroying-tumours/","link":"https://www.telegraph.co.uk/news/2022/01/02/one-hour-operation-could-cure-prostate-cancer-destroying-tumours/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":176},"text":"Prostate cancer could be treated by destroying tumors with electricity https://www.telegraph.co.uk/news/2022/01/02/one-hour-operation-could-cure-prostate-cancer-destroying-tumours/","classes":{"dataset":0.5041074753}}
{"title":"The Si Units of Simile","description":"http://blog.karliner.net/posts/units-of-simile/","link":"http://blog.karliner.net/posts/units-of-simile/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":11},"text":"The Si Units of Simile http://blog.karliner.net/posts/units-of-simile/","classes":{"dataset":0.5194280744}}
{"title":"Show HN: Alpaca.cpp \u2013 Run an Instruction-Tuned Chat-Style LLM on a MacBook","description":"https://github.com/antimatter15/alpaca.cpp","link":"https://github.com/antimatter15/alpaca.cpp","created":"2023-03-16","tags":["hackernews"],"meta":{"score":534},"text":"Show HN: Alpaca.cpp \u2013 Run an Instruction-Tuned Chat-Style LLM on a MacBook https://github.com/antimatter15/alpaca.cpp","classes":{"dataset":0.4948137999}}
{"title":"At Long Last, a Donkey Family Tree","description":"https://www.nytimes.com/2023/03/14/science/donkeys-genetics-archaeology.html","link":"https://www.nytimes.com/2023/03/14/science/donkeys-genetics-archaeology.html","created":"2023-03-15","tags":["hackernews"],"meta":{"score":16},"text":"At Long Last, a Donkey Family Tree https://www.nytimes.com/2023/03/14/science/donkeys-genetics-archaeology.html","classes":{"dataset":0.507349968}}
{"title":"The digestive systems of carnivorous plants","description":"https://academic.oup.com/plphys/article/190/1/44/6590657","link":"https://academic.oup.com/plphys/article/190/1/44/6590657","created":"2023-03-16","tags":["hackernews"],"meta":{"score":26},"text":"The digestive systems of carnivorous plants https://academic.oup.com/plphys/article/190/1/44/6590657","classes":{"dataset":0.5072184801}}
{"title":"Google: Turn off VoLTE, Wi-Fi calling: severe Exynos modem vulnerabilities","description":"https://9to5google.com/2023/03/16/google-exynos-modem-vulnerabilities/","link":"https://9to5google.com/2023/03/16/google-exynos-modem-vulnerabilities/","created":"2023-03-17","tags":["hackernews"],"meta":{"score":254},"text":"Google: Turn off VoLTE, Wi-Fi calling: severe Exynos modem vulnerabilities https://9to5google.com/2023/03/16/google-exynos-modem-vulnerabilities/","classes":{"dataset":0.5113217235}}
{"title":"Docopt.sh \u2013 Command-Line Argument Parser for Bash 3.2, 4, and 5","description":"https://github.com/andsens/docopt.sh","link":"https://github.com/andsens/docopt.sh","created":"2023-03-16","tags":["hackernews"],"meta":{"score":89},"text":"Docopt.sh \u2013 Command-Line Argument Parser for Bash 3.2, 4, and 5 https://github.com/andsens/docopt.sh","classes":{"dataset":0.5096451044}}
{"title":"Recode: An experimental Elixir linter with autocorrection and refactoring tools","description":"https://github.com/hrzndhrn/recode","link":"https://github.com/hrzndhrn/recode","created":"2023-03-16","tags":["hackernews"],"meta":{"score":70},"text":"Recode: An experimental Elixir linter with autocorrection and refactoring tools https://github.com/hrzndhrn/recode","classes":{"dataset":0.4978134036}}
{"title":"Project Orion","description":"https://en.wikipedia.org/wiki/Project_Orion_(nuclear_propulsion)","link":"https://en.wikipedia.org/wiki/Project_Orion_(nuclear_propulsion)","created":"2023-03-16","tags":["hackernews"],"meta":{"score":116},"text":"Project Orion https://en.wikipedia.org/wiki/Project_Orion_(nuclear_propulsion)","classes":{"dataset":0.5223392844}}
{"title":"Low-cost open source device can measure air pollution anywhere","description":"https://news.mit.edu/2023/low-cost-device-can-measure-air-pollution-anywhere-0316","link":"https://news.mit.edu/2023/low-cost-device-can-measure-air-pollution-anywhere-0316","created":"2023-03-16","tags":["hackernews"],"meta":{"score":195},"text":"Low-cost open source device can measure air pollution anywhere https://news.mit.edu/2023/low-cost-device-can-measure-air-pollution-anywhere-0316","classes":{"dataset":0.514814198}}
{"title":"We apologize. We did a terrible job announcing the end of Docker Free Teams","description":"https://www.docker.com/blog/we-apologize-we-did-a-terrible-job-announcing-the-end-of-docker-free-teams/","link":"https://www.docker.com/blog/we-apologize-we-did-a-terrible-job-announcing-the-end-of-docker-free-teams/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":540},"text":"We apologize. We did a terrible job announcing the end of Docker Free Teams https://www.docker.com/blog/we-apologize-we-did-a-terrible-job-announcing-the-end-of-docker-free-teams/","classes":{"dataset":0.5271131396}}
{"title":"Memex is a secure archiving tool that offers a user interface similar to Git's","description":"https://c9x.me/archive/","link":"https://c9x.me/archive/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":18},"text":"Memex is a secure archiving tool that offers a user interface similar to Git's https://c9x.me/archive/","classes":{"dataset":0.4718629718}}
{"title":"On Taking Photographs","description":"https://oldtowneast.openpluto.com/on-taking-photographs/","link":"https://oldtowneast.openpluto.com/on-taking-photographs/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":34},"text":"On Taking Photographs https://oldtowneast.openpluto.com/on-taking-photographs/","classes":{"dataset":0.505081594}}
{"title":"The Worlds of Italo Calvino","description":"https://www.newyorker.com/magazine/2023/03/06/the-worlds-of-italo-calvino","link":"https://www.newyorker.com/magazine/2023/03/06/the-worlds-of-italo-calvino","created":"2023-03-16","tags":["hackernews"],"meta":{"score":117},"text":"The Worlds of Italo Calvino https://www.newyorker.com/magazine/2023/03/06/the-worlds-of-italo-calvino","classes":{"dataset":0.5031639934}}
{"title":"How did Dennis Ritchie produce his PhD thesis? A typographical mystery (2022) [pdf]","description":"https://www.cs.princeton.edu/~bwk/dmr/doceng22.pdf","link":"https://www.cs.princeton.edu/~bwk/dmr/doceng22.pdf","created":"2023-03-16","tags":["hackernews"],"meta":{"score":461},"text":"How did Dennis Ritchie produce his PhD thesis? A typographical mystery (2022) [pdf] https://www.cs.princeton.edu/~bwk/dmr/doceng22.pdf","classes":{"dataset":0.5811021328}}
{"title":"YouTube TV raises subscription to $72.99, inching closer to cable pricing","description":"https://www.theverge.com/2023/3/16/23643448/youtube-tv-price-increase-8-cable-pricing","link":"https://www.theverge.com/2023/3/16/23643448/youtube-tv-price-increase-8-cable-pricing","created":"2023-03-16","tags":["hackernews"],"meta":{"score":111},"text":"YouTube TV raises subscription to $72.99, inching closer to cable pricing https://www.theverge.com/2023/3/16/23643448/youtube-tv-price-increase-8-cable-pricing","classes":{"dataset":0.5229145288}}
{"title":"Shoshikantetsu","description":"https://asnewman.github.io/shoshikantetsu","link":"https://asnewman.github.io/shoshikantetsu","created":"2023-03-16","tags":["hackernews"],"meta":{"score":402},"text":"Shoshikantetsu https://asnewman.github.io/shoshikantetsu","classes":{"dataset":0.5418870449}}
{"title":"TypeScript 5.0","description":"https://devblogs.microsoft.com/typescript/announcing-typescript-5-0/","link":"https://devblogs.microsoft.com/typescript/announcing-typescript-5-0/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":543},"text":"TypeScript 5.0 https://devblogs.microsoft.com/typescript/announcing-typescript-5-0/","classes":{"dataset":0.4653788209}}
{"title":"Can GPT-4 *Actually* Write Code?","description":"https://tylerglaiel.substack.com/p/can-gpt-4-actually-write-code","link":"https://tylerglaiel.substack.com/p/can-gpt-4-actually-write-code","created":"2023-03-17","tags":["hackernews"],"meta":{"score":110},"text":"Can GPT-4 *Actually* Write Code? https://tylerglaiel.substack.com/p/can-gpt-4-actually-write-code","classes":{"dataset":0.5620989203}}
{"title":"A city map of bus and train stations","description":"https://www.cricetuscricetus.co.uk/post/a-city-map-of-bus-and-train-stations","link":"https://www.cricetuscricetus.co.uk/post/a-city-map-of-bus-and-train-stations","created":"2023-03-15","tags":["hackernews"],"meta":{"score":29},"text":"A city map of bus and train stations https://www.cricetuscricetus.co.uk/post/a-city-map-of-bus-and-train-stations","classes":{"dataset":0.4956819415}}
{"title":"A child welfare AI tool may flag parents with disabilities","description":"https://apnews.com/article/child-protective-services-algorithms-artificial-intelligence-disability-02469a9ad3ed3e9a31ddae68838bc76e","link":"https://apnews.com/article/child-protective-services-algorithms-artificial-intelligence-disability-02469a9ad3ed3e9a31ddae68838bc76e","created":"2023-03-17","tags":["hackernews"],"meta":{"score":15},"text":"A child welfare AI tool may flag parents with disabilities https://apnews.com/article/child-protective-services-algorithms-artificial-intelligence-disability-02469a9ad3ed3e9a31ddae68838bc76e","classes":{"dataset":0.507349968}}
{"title":"John Deere's ongoing GPL violations: What's next","description":"https://sfconservancy.org/blog/2023/mar/16/john-deere-gpl-violations/","link":"https://sfconservancy.org/blog/2023/mar/16/john-deere-gpl-violations/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":413},"text":"John Deere's ongoing GPL violations: What's next https://sfconservancy.org/blog/2023/mar/16/john-deere-gpl-violations/","classes":{"dataset":0.5098437071}}
{"title":"Twitch CEO Emmett Shear is resigning","description":"https://www.theverge.com/2023/3/16/23643223/twitch-ceo-emmett-shear-resigning-dan-clancy","link":"https://www.theverge.com/2023/3/16/23643223/twitch-ceo-emmett-shear-resigning-dan-clancy","created":"2023-03-16","tags":["hackernews"],"meta":{"score":217},"text":"Twitch CEO Emmett Shear is resigning https://www.theverge.com/2023/3/16/23643223/twitch-ceo-emmett-shear-resigning-dan-clancy","classes":{"dataset":0.4816644788}}
{"title":"Triplebyte acquired by Karat","description":"https://karat.com/blog/post/karat-acquires-leading-adaptive-assessment-technology-from-triplebyte/","link":"https://karat.com/blog/post/karat-acquires-leading-adaptive-assessment-technology-from-triplebyte/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":114},"text":"Triplebyte acquired by Karat https://karat.com/blog/post/karat-acquires-leading-adaptive-assessment-technology-from-triplebyte/","classes":{"dataset":0.5043460131}}
{"title":"Noncompete clauses: Companies say they need them, research shows that\u2019s not true","description":"https://slate.com/business/2023/03/noncompete-clauses-washington-research-ban-ftc.html","link":"https://slate.com/business/2023/03/noncompete-clauses-washington-research-ban-ftc.html","created":"2023-03-16","tags":["hackernews"],"meta":{"score":271},"text":"Noncompete clauses: Companies say they need them, research shows that\u2019s not true https://slate.com/business/2023/03/noncompete-clauses-washington-research-ban-ftc.html","classes":{"dataset":0.5209665895}}
{"title":"Tons of uranium missing from Libyan site, IAEA tells member states","description":"https://www.reuters.com/markets/commodities/tons-uranium-missing-libyan-site-iaea-tells-member-states-2023-03-15/","link":"https://www.reuters.com/markets/commodities/tons-uranium-missing-libyan-site-iaea-tells-member-states-2023-03-15/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":63},"text":"Tons of uranium missing from Libyan site, IAEA tells member states https://www.reuters.com/markets/commodities/tons-uranium-missing-libyan-site-iaea-tells-member-states-2023-03-15/","classes":{"dataset":0.507349968}}
{"title":"Firefox\u2019s latest update adds a nifty PDF editing feature","description":"https://www.pcworld.com/article/1356707/firefox-106-adds-a-nifty-pdf-editing-feature.html","link":"https://www.pcworld.com/article/1356707/firefox-106-adds-a-nifty-pdf-editing-feature.html","created":"2023-03-17","tags":["hackernews"],"meta":{"score":20},"text":"Firefox\u2019s latest update adds a nifty PDF editing feature https://www.pcworld.com/article/1356707/firefox-106-adds-a-nifty-pdf-editing-feature.html","classes":{"dataset":0.4994018078}}
{"title":"Citymapper Joins Via","description":"https://content.citymapper.com/news/2582/citymapper-joins-via","link":"https://content.citymapper.com/news/2582/citymapper-joins-via","created":"2023-03-16","tags":["hackernews"],"meta":{"score":110},"text":"Citymapper Joins Via https://content.citymapper.com/news/2582/citymapper-joins-via","classes":{"dataset":0.5151657462}}
{"title":"We built an exceedingly polite AI dog that answers questions about your APIs","description":"https://www.akitasoftware.com/blog-posts/we-built-an-exceedingly-polite-ai-dog-that-answers-questions-about-your-apis","link":"https://www.akitasoftware.com/blog-posts/we-built-an-exceedingly-polite-ai-dog-that-answers-questions-about-your-apis","created":"2023-03-16","tags":["hackernews"],"meta":{"score":71},"text":"We built an exceedingly polite AI dog that answers questions about your APIs https://www.akitasoftware.com/blog-posts/we-built-an-exceedingly-polite-ai-dog-that-answers-questions-about-your-apis","classes":{"dataset":0.4787426889}}
{"title":"Pico_1140: A PDP11/40 emulator that will run Unix v5/v6 on a Raspberry Pi RP2040","description":"https://github.com/Isysxp/Pico_1140","link":"https://github.com/Isysxp/Pico_1140","created":"2023-03-17","tags":["hackernews"],"meta":{"score":3},"text":"Pico_1140: A PDP11/40 emulator that will run Unix v5/v6 on a Raspberry Pi RP2040 https://github.com/Isysxp/Pico_1140","classes":{"dataset":0.4947091043}}
{"title":"Heroku Status \u2013 Dashboard/API Offline","description":"https://status.heroku.com/incidents/2524","link":"https://status.heroku.com/incidents/2524","created":"2023-03-16","tags":["hackernews"],"meta":{"score":57},"text":"Heroku Status \u2013 Dashboard/API Offline https://status.heroku.com/incidents/2524","classes":{"dataset":0.502835393}}
{"title":"History\u2019s Fool: The long century of Ernst J\u00fcnger","description":"https://harpers.org/archive/2023/03/historys-fool-ernst-junger/","link":"https://harpers.org/archive/2023/03/historys-fool-ernst-junger/","created":"2023-03-15","tags":["hackernews"],"meta":{"score":41},"text":"History\u2019s Fool: The long century of Ernst J\u00fcnger https://harpers.org/archive/2023/03/historys-fool-ernst-junger/","classes":{"dataset":0.5189879537}}
{"title":"JPMChase doesn't care about your deposits","description":"https://ayokunle.substack.com/p/jpmorgan-chase-doesnt-care-about","link":"https://ayokunle.substack.com/p/jpmorgan-chase-doesnt-care-about","created":"2023-03-16","tags":["hackernews"],"meta":{"score":12},"text":"JPMChase doesn't care about your deposits https://ayokunle.substack.com/p/jpmorgan-chase-doesnt-care-about","classes":{"dataset":0.4899299443}}
{"title":"Google discontinues Google Glass for enterprise","description":"https://www.google.com/glass/start/","link":"https://www.google.com/glass/start/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":315},"text":"Google discontinues Google Glass for enterprise https://www.google.com/glass/start/","classes":{"dataset":0.5836260915}}
{"title":"PCIe for Hackers: The Diffpair Prelude","description":"https://hackaday.com/2023/03/14/pcie-for-hackers-the-diffpair-prelude/","link":"https://hackaday.com/2023/03/14/pcie-for-hackers-the-diffpair-prelude/","created":"2023-03-14","tags":["hackernews"],"meta":{"score":119},"text":"PCIe for Hackers: The Diffpair Prelude https://hackaday.com/2023/03/14/pcie-for-hackers-the-diffpair-prelude/","classes":{"dataset":0.5449754596}}
{"title":"Not by AI","description":"https://notbyai.fyi/","link":"https://notbyai.fyi/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":476},"text":"Not by AI https://notbyai.fyi/","classes":{"dataset":0.5441644192}}
{"title":"Fireball Spotted over Northeastern USA","description":"https://ams.imo.net/members/imo_view/event/2023/1529","link":"https://ams.imo.net/members/imo_view/event/2023/1529","created":"2023-03-15","tags":["hackernews"],"meta":{"score":245},"text":"Fireball Spotted over Northeastern USA https://ams.imo.net/members/imo_view/event/2023/1529","classes":{"dataset":0.511657238}}
{"title":"The birth of a package manager","description":"https://ochagavia.nl/blog/the-birth-of-a-package-manager/","link":"https://ochagavia.nl/blog/the-birth-of-a-package-manager/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":65},"text":"The birth of a package manager https://ochagavia.nl/blog/the-birth-of-a-package-manager/","classes":{"dataset":0.5022985935}}
{"title":"Brazilian researchers find plastic rocks on remote island","description":"https://www.reuters.com/lifestyle/science/brazilian-researchers-find-terrifying-plastic-rocks-remote-island-2023-03-15/","link":"https://www.reuters.com/lifestyle/science/brazilian-researchers-find-terrifying-plastic-rocks-remote-island-2023-03-15/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":108},"text":"Brazilian researchers find plastic rocks on remote island https://www.reuters.com/lifestyle/science/brazilian-researchers-find-terrifying-plastic-rocks-remote-island-2023-03-15/","classes":{"dataset":0.5112989545}}
{"title":"Show HN: HN Profiles \u2013 Searchable Database of People \u201cWho Want to Be Hired\u201d","description":"https://hnprofiles.com/","link":"https://hnprofiles.com/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":10},"text":"Show HN: HN Profiles \u2013 Searchable Database of People \u201cWho Want to Be Hired\u201d https://hnprofiles.com/","classes":{"dataset":0.5094990134}}
{"title":"Virgin Orbit pauses all operations","description":"https://arstechnica.com/science/2023/03/virgin-orbit-pauses-all-operations/","link":"https://arstechnica.com/science/2023/03/virgin-orbit-pauses-all-operations/","created":"2023-03-16","tags":["hackernews"],"meta":{"score":112},"text":"Virgin Orbit pauses all operations https://arstechnica.com/science/2023/03/virgin-orbit-pauses-all-operations/","classes":{"dataset":0.5299085379}}
{"title":"MiniLLM: A minimal system for running LLMs on consumer-grade Nvidia GPUs","description":"https://twitter.com/volokuleshov/status/1636190674805506048","link":"https://twitter.com/volokuleshov/status/1636190674805506048","created":"2023-03-16","tags":["hackernews"],"meta":{"score":29},"text":"MiniLLM: A minimal system for running LLMs on consumer-grade Nvidia GPUs https://twitter.com/volokuleshov/status/1636190674805506048","classes":{"dataset":0.528226912}}
{"title":"Smarty GPT","description":"This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers **in a transparent way to end users**.\n\n&amp;#x200B;\n\nFeel free to open issues, PR, add more prompts! \n\n&amp;#x200B;\n\n[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)","link":"https://www.reddit.com/r/PromptDesign/comments/11r5m06/smarty_gpt/","created":"2023-03-14","tags":["promptdesign","prompteng","reddit"],"meta":{"num_comments":1},"text":"Smarty GPT This is a simple wrapper that introduces any imaginable complex context to each question submitted to Open AI API. The main goal is to enhance the accuracy obtained in its answers **in a transparent way to end users**.\n\n&amp;#x200B;\n\nFeel free to open issues, PR, add more prompts! \n\n&amp;#x200B;\n\n[https://github.com/citiususc/Smarty-GPT](https://github.com/citiususc/Smarty-GPT)","classes":{"dataset":0.5658325553}}
{"title":"The Ruff python linter is insanely good","description":"I just migrated some of my projects over to using [ruff](https://github.com/charliermarsh/ruff), and I am EXTREMELY impressed. It is quite literally 100 times faster than my previous linting configuration, all while being more organized and powerful. It's mind boggling fast. It has all of the plugins builtin that I was previously using with tools like flake8. It hooks into `pre-commit` and replaces many plugins I had before like:\n\n* `isort` - sorts imports\n* `bandit` - finds common security issues\n* `flake8` - linter; additional benefit is that I can now delete my \\`.flake8\\` file.\n* `pygrep-hooks` - common misc linting\n\nAdditionally, it's completely configurable via pyproject.toml, so that always feels good.\n\nBy the way, if you want to checkout my python template, it has my preferred ruff configuration:[https://github.com/BrianPugh/python-template](https://github.com/BrianPugh/python-template)","link":"https://www.reddit.com/r/Python/comments/11syxd0/the_ruff_python_linter_is_insanely_good/","created":"2023-03-16","tags":["reddit","python"],"meta":{"num_comments":90},"text":"The Ruff python linter is insanely good I just migrated some of my projects over to using [ruff](https://github.com/charliermarsh/ruff), and I am EXTREMELY impressed. It is quite literally 100 times faster than my previous linting configuration, all while being more organized and powerful. It's mind boggling fast. It has all of the plugins builtin that I was previously using with tools like flake8. It hooks into `pre-commit` and replaces many plugins I had before like:\n\n* `isort` - sorts imports\n* `bandit` - finds common security issues\n* `flake8` - linter; additional benefit is that I can now delete my \\`.flake8\\` file.\n* `pygrep-hooks` - common misc linting\n\nAdditionally, it's completely configurable via pyproject.toml, so that always feels good.\n\nBy the way, if you want to checkout my python template, it has my preferred ruff configuration:[https://github.com/BrianPugh/python-template](https://github.com/BrianPugh/python-template)","classes":{"dataset":0.4677483737}}
{"title":"Is setting up React with Python difficult?","description":"Is it difficult to setup React with Python that meets the following requirements:\n\n1. Server Side Rendering\n2. Server Side Generation\n3. Incremental Server Side Generation\n4. Use React as a template with an experience similar to using Jinja templates","link":"https://www.reddit.com/r/Python/comments/11tlnkq/is_setting_up_react_with_python_difficult/","created":"2023-03-17","tags":["reddit","python"],"meta":{"num_comments":18},"text":"Is setting up React with Python difficult? Is it difficult to setup React with Python that meets the following requirements:\n\n1. Server Side Rendering\n2. Server Side Generation\n3. Incremental Server Side Generation\n4. Use React as a template with an experience similar to using Jinja templates","classes":{"dataset":0.3175338507}}
{"title":"Here is how i made a 2D game using Python Matplotlib","description":"Im only few month into learning Python and i was wondering if i could make a game with it. I didnt know about any libraries created specifically for developing games at the time, so i asked an AI if i could somehow make a code that opens and plays GIF animations. AI came up with a function that opens GIFs as matplotlib plots. I added a condition that if 'space' button is pressed, the animation stops and the last frame number is saved into a variable, and then the value of the variable determines what happens next. This whole game is built around this simple algorithm.\n\nshowcase: [https://youtu.be/ZAXlaOWMgfM](https://youtu.be/ZAXlaOWMgfM)\n\nsource code: [https://drive.google.com/drive/folders/1bKV4\\_AdCgnW40A8B1kFkFYryIuTE44A6?usp=share\\_link](https://drive.google.com/drive/folders/1bKV4_AdCgnW40A8B1kFkFYryIuTE44A6?usp=share_link)\n\n[icon](https://preview.redd.it/q6463xvfr4oa1.png?width=640&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=68ba371480740ee9117b4fd4b68d1ef37554d4f2)\n\n&amp;#x200B;\n\n[QTE](https://preview.redd.it/kzjifyrkr4oa1.png?width=575&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3c45f92e81ba39711ea5ff760766e9ddf07e236d)","link":"https://www.reddit.com/r/Python/comments/11szlvk/here_is_how_i_made_a_2d_game_using_python/","created":"2023-03-16","tags":["reddit","python"],"meta":{"num_comments":9},"text":"Here is how i made a 2D game using Python Matplotlib Im only few month into learning Python and i was wondering if i could make a game with it. I didnt know about any libraries created specifically for developing games at the time, so i asked an AI if i could somehow make a code that opens and plays GIF animations. AI came up with a function that opens GIFs as matplotlib plots. I added a condition that if 'space' button is pressed, the animation stops and the last frame number is saved into a variable, and then the value of the variable determines what happens next. This whole game is built around this simple algorithm.\n\nshowcase: [https://youtu.be/ZAXlaOWMgfM](https://youtu.be/ZAXlaOWMgfM)\n\nsource code: [https://drive.google.com/drive/folders/1bKV4\\_AdCgnW40A8B1kFkFYryIuTE44A6?usp=share\\_link](https://drive.google.com/drive/folders/1bKV4_AdCgnW40A8B1kFkFYryIuTE44A6?usp=share_link)\n\n[icon](https://preview.redd.it/q6463xvfr4oa1.png?width=640&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=68ba371480740ee9117b4fd4b68d1ef37554d4f2)\n\n&amp;#x200B;\n\n[QTE](https://preview.redd.it/kzjifyrkr4oa1.png?width=575&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3c45f92e81ba39711ea5ff760766e9ddf07e236d)","classes":{"dataset":0.4228068888}}
{"title":"What should I unit test?","description":"I have a code challenge which was to call the Rick and Morty API and display a list of characters. It's all working. However, one of the requirements asks for a unit test.\n\nI'm not exactly sure what I should unit test here. I usually just have tests for util functions. Would a test to make sure the API is returning 200 be a good test?","link":"https://www.reddit.com/r/Python/comments/11tj7gm/what_should_i_unit_test/","created":"2023-03-17","tags":["reddit","python"],"meta":{"num_comments":7},"text":"What should I unit test? I have a code challenge which was to call the Rick and Morty API and display a list of characters. It's all working. However, one of the requirements asks for a unit test.\n\nI'm not exactly sure what I should unit test here. I usually just have tests for util functions. Would a test to make sure the API is returning 200 be a good test?","classes":{"dataset":0.4620285034}}
{"title":"README-AI: automated README creation and codebase documentation!","description":"Hey all,\n\nWanted to share a Python project I'm building called [README-AI](https://github.com/eli64s/README-AI). The goal of this project is to automate the process of creating README Markdown files and generate boilerplate documentation for your codebase, leveraging OpenAI's language model API.\n\nThe project can be found on GitHub using the link below:  \n[**https://github.com/eli64s/README-AI**](https://github.com/eli64s/README-AI).\n\nContributions are welcomed and appreciate any feedback or suggestions to improve the codebase and enhance the project's usability for users.\n\nThanks for taking the time to read this post, and happy coding!","link":"https://www.reddit.com/r/Python/comments/11ti68c/readmeai_automated_readme_creation_and_codebase/","created":"2023-03-17","tags":["reddit","python"],"meta":{"num_comments":1},"text":"README-AI: automated README creation and codebase documentation! Hey all,\n\nWanted to share a Python project I'm building called [README-AI](https://github.com/eli64s/README-AI). The goal of this project is to automate the process of creating README Markdown files and generate boilerplate documentation for your codebase, leveraging OpenAI's language model API.\n\nThe project can be found on GitHub using the link below:  \n[**https://github.com/eli64s/README-AI**](https://github.com/eli64s/README-AI).\n\nContributions are welcomed and appreciate any feedback or suggestions to improve the codebase and enhance the project's usability for users.\n\nThanks for taking the time to read this post, and happy coding!","classes":{"dataset":0.4417128265}}
{"title":"Made a Python package for extracting color palettes from images","description":"So I made a color palette extractor Python package last year which extracts color palettes from images and stores them in JSON files. When I made the package, it was for the Unix-ricing community here on Reddit and I wasn\u2019t aware at that time that similar packages were already available or did something similar.\n\nAnyways, I never made a post here about the package. And since I\u2019ve recently reworked the codebase, I wanted to share about it with the Python community. This is my first time working with the Python language and also my first time publishing something I made as a whole package.\n\nA small 1 minute demonstration of the package being used:  \n[Package Example](https://imgur.com/a/jKjagVE)\n\nThe package is available through PyPI and GitHub, however I hope it\u2019s okay if I only post the link to it\u2019s PyPI homepage since I don\u2019t want my GitHub name to be attached to this post (the link to the source code as well as the GitHub home page is both in the ReadMe and the homepage button in the PyPI project details):  \n[PyPI package homepage](https://pypi.org/project/pypalex/)\n\nIf the GitHub link to the source code is a hard requirement, please let me know and I will change the link in this post to point to it\u2019s GitHub repo instead of PyPI!\n\nI ask that if you use the package please feel free to leave any kind of feedback, especially if it\u2019s constructive criticism! I have discussion posts that are open on the GitHub repo for every new version of the package I\u2019ve released. And thank you so much for any feedback! I appreciate and value it a whole lot!","link":"https://www.reddit.com/r/Python/comments/11sxgjp/made_a_python_package_for_extracting_color/","created":"2023-03-16","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Made a Python package for extracting color palettes from images So I made a color palette extractor Python package last year which extracts color palettes from images and stores them in JSON files. When I made the package, it was for the Unix-ricing community here on Reddit and I wasn\u2019t aware at that time that similar packages were already available or did something similar.\n\nAnyways, I never made a post here about the package. And since I\u2019ve recently reworked the codebase, I wanted to share about it with the Python community. This is my first time working with the Python language and also my first time publishing something I made as a whole package.\n\nA small 1 minute demonstration of the package being used:  \n[Package Example](https://imgur.com/a/jKjagVE)\n\nThe package is available through PyPI and GitHub, however I hope it\u2019s okay if I only post the link to it\u2019s PyPI homepage since I don\u2019t want my GitHub name to be attached to this post (the link to the source code as well as the GitHub home page is both in the ReadMe and the homepage button in the PyPI project details):  \n[PyPI package homepage](https://pypi.org/project/pypalex/)\n\nIf the GitHub link to the source code is a hard requirement, please let me know and I will change the link in this post to point to it\u2019s GitHub repo instead of PyPI!\n\nI ask that if you use the package please feel free to leave any kind of feedback, especially if it\u2019s constructive criticism! I have discussion posts that are open on the GitHub repo for every new version of the package I\u2019ve released. And thank you so much for any feedback! I appreciate and value it a whole lot!","classes":{"dataset":0.3970989585}}
{"title":"How to keep a command prompt window open after subprocess is launched in it and completes","description":"I could not find the answer to this on reddit, stackoverflow, anywhere. Adding 'pause' to the args in any combination did not work, and there were some VERY advanced explanations that involved tying another Python process to the command window, logging the process instead, etc.\n\n\nAfter some time spent grinding, I found it. I thought I'd save someone else some time.\n\n\nsubprocess.Popen([\"start\", \"cmd\", \"/k\", \"your_external_executable_path_here\", \"your_exe_params_here\"], shell=True]\n\nThis will launch the subprocess in a command prompt and will return to command prompt at the end of execution. It will stay open. So you can actually read what was printed out and not have the window disappear afterwards.","link":"https://www.reddit.com/r/Python/comments/11talaa/how_to_keep_a_command_prompt_window_open_after/","created":"2023-03-16","tags":["reddit","python"],"meta":{"num_comments":3},"text":"How to keep a command prompt window open after subprocess is launched in it and completes I could not find the answer to this on reddit, stackoverflow, anywhere. Adding 'pause' to the args in any combination did not work, and there were some VERY advanced explanations that involved tying another Python process to the command window, logging the process instead, etc.\n\n\nAfter some time spent grinding, I found it. I thought I'd save someone else some time.\n\n\nsubprocess.Popen([\"start\", \"cmd\", \"/k\", \"your_external_executable_path_here\", \"your_exe_params_here\"], shell=True]\n\nThis will launch the subprocess in a command prompt and will return to command prompt at the end of execution. It will stay open. So you can actually read what was printed out and not have the window disappear afterwards.","classes":{"dataset":0.4937492311}}
{"title":"Reading PointNet (CVPR2017) and wondering what 'feature alignment' does","description":"as per subject\n\nI am reading PointNet CVPR 2017, and according to the paper,\n\nthe authors said they wanted to introduce transform invariance and, therefore, inserted a 'joint alignment network'.\n\nI guess the first alignment network implements transform invariance because it happens before feature extraction. \n\nBut what would the exact role of feature transform be?","link":"https://www.reddit.com/r/deeplearning/comments/11tjpcp/reading_pointnet_cvpr2017_and_wondering_what/","created":"2023-03-17","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":0},"text":"Reading PointNet (CVPR2017) and wondering what 'feature alignment' does as per subject\n\nI am reading PointNet CVPR 2017, and according to the paper,\n\nthe authors said they wanted to introduce transform invariance and, therefore, inserted a 'joint alignment network'.\n\nI guess the first alignment network implements transform invariance because it happens before feature extraction. \n\nBut what would the exact role of feature transform be?","classes":{"dataset":0.5003252029}}
{"title":"I need some material on metric learning","description":"Thats the code I need to write:\n\nA.Train a neural network model on this dataset.\nB. The dataset has a large variety of celebrities.\n\nC.Once the model is trained, you must create a database with images of the celebrities with the output of the descriptor vector from your model.\nAfter training the neural network, you should include this person in the database.\n\nD.Once steps (1), (2), and (3) are completed, you must use this image, which is the person from item (3) wearing a face mask, and perform facial recognition on them.","link":"https://www.reddit.com/r/deeplearning/comments/11tf8g7/i_need_some_material_on_metric_learning/","created":"2023-03-17","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":0},"text":"I need some material on metric learning Thats the code I need to write:\n\nA.Train a neural network model on this dataset.\nB. The dataset has a large variety of celebrities.\n\nC.Once the model is trained, you must create a database with images of the celebrities with the output of the descriptor vector from your model.\nAfter training the neural network, you should include this person in the database.\n\nD.Once steps (1), (2), and (3) are completed, you must use this image, which is the person from item (3) wearing a face mask, and perform facial recognition on them.","classes":{"dataset":0.2312324494}}
{"title":"[Tutorial] PyTorch Class Activation Map using Custom Trained Model","description":"PyTorch Class Activation Map using Custom Trained Model\n\n[https://debuggercafe.com/pytorch-class-activation-map-using-custom-trained-model/](https://debuggercafe.com/pytorch-class-activation-map-using-custom-trained-model/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/wgg3s1ca17oa1.png?width=1000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e63bb11e597b7ec43d3dfa25539fe99acedccd53","link":"https://www.reddit.com/r/deeplearning/comments/11tbj9v/tutorial_pytorch_class_activation_map_using/","created":"2023-03-17","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":0},"text":"[Tutorial] PyTorch Class Activation Map using Custom Trained Model PyTorch Class Activation Map using Custom Trained Model\n\n[https://debuggercafe.com/pytorch-class-activation-map-using-custom-trained-model/](https://debuggercafe.com/pytorch-class-activation-map-using-custom-trained-model/)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/wgg3s1ca17oa1.png?width=1000&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e63bb11e597b7ec43d3dfa25539fe99acedccd53","classes":{"dataset":0.496551156}}
{"title":"[HELP] NEED SOMEONE WITH INDEPTH KNOWLEDGE OF Face AI MODIFIERS","description":"I have an account with a crypto app that I need verified and they have frozen my funds. However, all I need is to complete a simple KYC where I have to submit a live selfie. Anyone who can use AI to help me do this? If yes, comment below and I'll reach out or send me a PM indicating the same and expected pay. Thanks","link":"https://www.reddit.com/r/deeplearning/comments/11tievn/help_need_someone_with_indepth_knowledge_of_face/","created":"2023-03-17","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":5},"text":"[HELP] NEED SOMEONE WITH INDEPTH KNOWLEDGE OF Face AI MODIFIERS I have an account with a crypto app that I need verified and they have frozen my funds. However, all I need is to complete a simple KYC where I have to submit a live selfie. Anyone who can use AI to help me do this? If yes, comment below and I'll reach out or send me a PM indicating the same and expected pay. Thanks","classes":{"dataset":0.512119472}}
{"title":"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3","description":"Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!\n\nThe reason for this increased performance seems to be due to a larger number of tokens being used for training.\n\nNow, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!\n\n[https://youtu.be/d4Cnv\\_g3GiI](https://youtu.be/d4Cnv_g3GiI)","link":"https://www.reddit.com/r/deeplearning/comments/11ryc3s/how_to_finetune_llama_models_smaller_models_with/","created":"2023-03-15","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":10},"text":"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3 Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!\n\nThe reason for this increased performance seems to be due to a larger number of tokens being used for training.\n\nNow, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!\n\n[https://youtu.be/d4Cnv\\_g3GiI](https://youtu.be/d4Cnv_g3GiI)","classes":{"dataset":0.4994844198}}
{"title":"How do I prepare for the Microsoft Exams?","description":"","link":"https://www.reddit.com/r/deeplearning/comments/11snji6/how_do_i_prepare_for_the_microsoft_exams/","created":"2023-03-16","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":0},"text":"How do I prepare for the Microsoft Exams? ","classes":{"dataset":0.2226051241}}
{"title":"How to Use mpirun to Launch a LLaMA Inference Job Across Multiple Cloud Instances","description":"[How to Use mpirun to Launch a LLaMA Inference Job Across Multiple Cloud Instances](https://lambdalabs.com/blog/how-to-use-mpirun-to-launch-a-llama-inference-job-across-multiple-cloud-instances?utm_source=reddit&amp;utm_medium=organic-social&amp;utm_campaign=2023-03-llama-github-repo&amp;utm_content=blog)\n\nGuide on how to use mpirun to launch a LLaMA inference job across multiple Lambda Cloud instances, including a cost analysis for running various LLaMA models on different GPU instances. Notable updates include:\n\n* A script to easily set up a \"cluster\" of cloud instances that is ready to run LLaMA inference (all models from 7B to 65B).\n* mpirun compatible, so you can launch the job directly from the head node without the need of typing in the torchrun command on the worker nodes.\n* Interactive inference mode across multiple nodes.\n* eos\\_w: controls how \"lengthy\" the results are likely to be by scaling the probability of eos\\_token\n* Inference speed profiling (\"tokens/sec\").","link":"https://www.reddit.com/r/deeplearning/comments/11s4u0b/how_to_use_mpirun_to_launch_a_llama_inference_job/","created":"2023-03-15","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":0},"text":"How to Use mpirun to Launch a LLaMA Inference Job Across Multiple Cloud Instances [How to Use mpirun to Launch a LLaMA Inference Job Across Multiple Cloud Instances](https://lambdalabs.com/blog/how-to-use-mpirun-to-launch-a-llama-inference-job-across-multiple-cloud-instances?utm_source=reddit&amp;utm_medium=organic-social&amp;utm_campaign=2023-03-llama-github-repo&amp;utm_content=blog)\n\nGuide on how to use mpirun to launch a LLaMA inference job across multiple Lambda Cloud instances, including a cost analysis for running various LLaMA models on different GPU instances. Notable updates include:\n\n* A script to easily set up a \"cluster\" of cloud instances that is ready to run LLaMA inference (all models from 7B to 65B).\n* mpirun compatible, so you can launch the job directly from the head node without the need of typing in the torchrun command on the worker nodes.\n* Interactive inference mode across multiple nodes.\n* eos\\_w: controls how \"lengthy\" the results are likely to be by scaling the probability of eos\\_token\n* Inference speed profiling (\"tokens/sec\").","classes":{"dataset":0.4928675592}}
{"title":"Building a deep learning model for bug severity prediction","description":"Can a deep learning model be built to classify bugs as blocker, minor, major, critical, trivial, or normal? \n\nor only binary classification as **severe** \\[if the bug is blocker, major or critical\\] and **non-severe** \\[if the bug is minor, trivial or normal\\]. \n\nas I tried many models like gpt-2 but didn't get an accuracy greater than 0.2, but when making it binary classification task I got accuracy &gt; 0.65. \n\n&amp;#x200B;\n\nPlease advise. is it possible to do the multiclass classification?","link":"https://www.reddit.com/r/deeplearning/comments/11s90au/building_a_deep_learning_model_for_bug_severity/","created":"2023-03-15","tags":["ml","reddit","deeplearning"],"meta":{"num_comments":0},"text":"Building a deep learning model for bug severity prediction Can a deep learning model be built to classify bugs as blocker, minor, major, critical, trivial, or normal? \n\nor only binary classification as **severe** \\[if the bug is blocker, major or critical\\] and **non-severe** \\[if the bug is minor, trivial or normal\\]. \n\nas I tried many models like gpt-2 but didn't get an accuracy greater than 0.2, but when making it binary classification task I got accuracy &gt; 0.65. \n\n&amp;#x200B;\n\nPlease advise. is it possible to do the multiclass classification?","classes":{"dataset":0.5147691369}}
{"title":"[P] nanoT5 - Inspired by Jonas Geiping's Cramming and Andrej Karpathy's nanoGPT, we fill the gap of a repository for pre-training T5-style \"LLMs\" under a limited budget in PyTorch","description":"We release the code to reproduce the pre-training of a \"Large Language Model\" (T5) under a limited budget (1xA100 GPU, \\~20 hours) in PyTorch. We start from the randomly initialised T5-base-v1.1 (248M parameters) model implemented in HuggingFace. Next, we pre-train it on the English subset of the C4 dataset and then fine-tune it on Super-Natural Instructions (SNI).\n\n**In \\~20 hours on a single GPU, we achieve \\~40 RougeL on the SNI test set, compared to \\~42 RougeL of the original model available on HuggingFace Hub and pre-trained through \"a combination of model and data parallelism \\[...\\] on slices of Cloud TPU Pods\", each with 1024 TPUs.**\n\nOur core contribution is not the T5 model itself, which follows the HuggingFace implementation. Instead, we optimise everything else in the training pipeline to offer you a user-friendly starting template for your NLP application/research.\n\nWe are keen to hear your suggestions to improve the codebase further.\n\n&amp;#x200B;\n\nGithub: [https://github.com/PiotrNawrot/nanoT5](https://github.com/PiotrNawrot/nanoT5)\n\nTwitter: [https://twitter.com/p\\_nawrot/status/1636373725397520384](https://twitter.com/p_nawrot/status/1636373725397520384)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/zluas7u235oa1.png?width=1152&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8d642abdce1753841b7fc977a141d0f13ca2b213","link":"https://www.reddit.com/r/MachineLearning/comments/11t1857/p_nanot5_inspired_by_jonas_geipings_cramming_and/","created":"2023-03-16","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":18},"text":"[P] nanoT5 - Inspired by Jonas Geiping's Cramming and Andrej Karpathy's nanoGPT, we fill the gap of a repository for pre-training T5-style \"LLMs\" under a limited budget in PyTorch We release the code to reproduce the pre-training of a \"Large Language Model\" (T5) under a limited budget (1xA100 GPU, \\~20 hours) in PyTorch. We start from the randomly initialised T5-base-v1.1 (248M parameters) model implemented in HuggingFace. Next, we pre-train it on the English subset of the C4 dataset and then fine-tune it on Super-Natural Instructions (SNI).\n\n**In \\~20 hours on a single GPU, we achieve \\~40 RougeL on the SNI test set, compared to \\~42 RougeL of the original model available on HuggingFace Hub and pre-trained through \"a combination of model and data parallelism \\[...\\] on slices of Cloud TPU Pods\", each with 1024 TPUs.**\n\nOur core contribution is not the T5 model itself, which follows the HuggingFace implementation. Instead, we optimise everything else in the training pipeline to offer you a user-friendly starting template for your NLP application/research.\n\nWe are keen to hear your suggestions to improve the codebase further.\n\n&amp;#x200B;\n\nGithub: [https://github.com/PiotrNawrot/nanoT5](https://github.com/PiotrNawrot/nanoT5)\n\nTwitter: [https://twitter.com/p\\_nawrot/status/1636373725397520384](https://twitter.com/p_nawrot/status/1636373725397520384)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/zluas7u235oa1.png?width=1152&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=8d642abdce1753841b7fc977a141d0f13ca2b213","classes":{"dataset":0.2050590068}}
{"title":"[D] Our community must get serious about opposing OpenAI","description":"OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.\n\nThey have abandoned this idea entirely.\n\nToday, with the release of GPT4 and their direct statement that they will not release details of the model creation due to \"safety concerns\" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.\n\nAI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.\n\nI get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.\n\nWe need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.\n\nThis conversation will only ever get more important.","link":"https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/","created":"2023-03-15","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":372},"text":"[D] Our community must get serious about opposing OpenAI OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.\n\nThey have abandoned this idea entirely.\n\nToday, with the release of GPT4 and their direct statement that they will not release details of the model creation due to \"safety concerns\" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.\n\nAI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.\n\nI get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.\n\nWe need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.\n\nThis conversation will only ever get more important.","classes":{"dataset":0.1963450611}}
{"title":"training KGE model [Project]","description":"I have knowledge graph : 24 relationships, 11 entities , &gt; 20K facts   (rows). What I need is the embedding for only one entity, out of those 11. Once the training is completed, I will extract those embeddings and  use them to train a separate GNN model.  \nMy idea was to over-fit  the  KGE model and use all data for training. Given my use case I don't  see  why a test set is needed. Once the model is trained, I will  evaluate it  on the train set, if MRR/ Hits@10 are good, I would extract  the embedding  and mode forward. If not, I will test a different model  and iterate.  \nAm I doing something stupid ?","link":"https://www.reddit.com/r/MachineLearning/comments/11tda6k/training_kge_model_project/","created":"2023-03-17","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":1},"text":"training KGE model [Project] I have knowledge graph : 24 relationships, 11 entities , &gt; 20K facts   (rows). What I need is the embedding for only one entity, out of those 11. Once the training is completed, I will extract those embeddings and  use them to train a separate GNN model.  \nMy idea was to over-fit  the  KGE model and use all data for training. Given my use case I don't  see  why a test set is needed. Once the model is trained, I will  evaluate it  on the train set, if MRR/ Hits@10 are good, I would extract  the embedding  and mode forward. If not, I will test a different model  and iterate.  \nAm I doing something stupid ?","classes":{"dataset":0.3624247611}}
{"title":"[D] GPT-4 is really dumb","description":"Probably I was to hyped about it, but the model seems to fail at basic math. For example 2015 is not the sum  11\\^3 + 8\\^3 + 2\\^3\n\n&amp;#x200B;\n\nhttps://preview.redd.it/35d4rh7tw9oa1.png?width=1498&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b83029b1442bc87c6231e8dad1e7a646f3c098d9","link":"https://www.reddit.com/r/MachineLearning/comments/11tmu9u/d_gpt4_is_really_dumb/","created":"2023-03-17","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":1},"text":"[D] GPT-4 is really dumb Probably I was to hyped about it, but the model seems to fail at basic math. For example 2015 is not the sum  11\\^3 + 8\\^3 + 2\\^3\n\n&amp;#x200B;\n\nhttps://preview.redd.it/35d4rh7tw9oa1.png?width=1498&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=b83029b1442bc87c6231e8dad1e7a646f3c098d9","classes":{"dataset":0.2838479877}}
{"title":"[N] A $250k contest to read ancient Roman papyrus scrolls with ML","description":"Today we launched [the Vesuvius Challenge](https://scrollprize.org/), an open competition to read a set of charred papyrus scrolls that were buried by the eruption of Mount Vesuvius 2000 years ago. The scrolls can't be physically opened, but we have released 3d tomographic x-ray scans of two of them at 8\u00b5m resolution.  The scans were made at a particle accelerator. \n\nA team at UKY led by Prof Brent Seales has [very recently demonstrated](https://scrollprize.org/tutorial4) the ability to detect ink inside the CT scans using CNNs, and so we believe that it is possible for the first time in history to read what's in these scrolls without opening them. There are hundreds of carbonized scrolls that we could read once the technique works \u2013 enough to more than double our total corpus of literature from antiquity.\n\nMany of us are fans of /r/MachineLearning and we thought this group would be interested in hearing about it!","link":"https://www.reddit.com/r/MachineLearning/comments/11sgn67/n_a_250k_contest_to_read_ancient_roman_papyrus/","created":"2023-03-16","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":32},"text":"[N] A $250k contest to read ancient Roman papyrus scrolls with ML Today we launched [the Vesuvius Challenge](https://scrollprize.org/), an open competition to read a set of charred papyrus scrolls that were buried by the eruption of Mount Vesuvius 2000 years ago. The scrolls can't be physically opened, but we have released 3d tomographic x-ray scans of two of them at 8\u00b5m resolution.  The scans were made at a particle accelerator. \n\nA team at UKY led by Prof Brent Seales has [very recently demonstrated](https://scrollprize.org/tutorial4) the ability to detect ink inside the CT scans using CNNs, and so we believe that it is possible for the first time in history to read what's in these scrolls without opening them. There are hundreds of carbonized scrolls that we could read once the technique works \u2013 enough to more than double our total corpus of literature from antiquity.\n\nMany of us are fans of /r/MachineLearning and we thought this group would be interested in hearing about it!","classes":{"dataset":0.2839648724}}
{"title":"[N] bloomz.cpp: Run any BLOOM-like model in pure C++","description":"[bloomz.cpp](https://github.com/NouamaneTazi/bloomz.cpp) allows running inference of BLOOM-like models in pure C/C++ (inspired by llama.cpp). It supports all models that can be loaded with `BloomForCausalLM.from_pretrained()`. For example, you can achieve 16 tokens per second on a M1 Pro.","link":"https://www.reddit.com/r/MachineLearning/comments/11spw6r/n_bloomzcpp_run_any_bloomlike_model_in_pure_c/","created":"2023-03-16","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0},"text":"[N] bloomz.cpp: Run any BLOOM-like model in pure C++ [bloomz.cpp](https://github.com/NouamaneTazi/bloomz.cpp) allows running inference of BLOOM-like models in pure C/C++ (inspired by llama.cpp). It supports all models that can be loaded with `BloomForCausalLM.from_pretrained()`. For example, you can achieve 16 tokens per second on a M1 Pro.","classes":{"dataset":0.2041588873}}
{"title":"[D] What do people think about OpenAI not releasing its research but benefiting from others\u2019 research? Should google meta enforce its patents against them?","description":"It seems like the days for open research in AI are gone.\n\nAlso, since one of the main reasons they say about not releasing any details is competetive pressure (aka commercial interest), I feel it is fair for others to enforce their patents just like in other fields like pharma? I am very interested in the counter arguments and understanding around this.","link":"https://www.reddit.com/r/MachineLearning/comments/11rtzv6/d_what_do_people_think_about_openai_not_releasing/","created":"2023-03-15","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":164},"text":"[D] What do people think about OpenAI not releasing its research but benefiting from others\u2019 research? Should google meta enforce its patents against them? It seems like the days for open research in AI are gone.\n\nAlso, since one of the main reasons they say about not releasing any details is competetive pressure (aka commercial interest), I feel it is fair for others to enforce their patents just like in other fields like pharma? I am very interested in the counter arguments and understanding around this.","classes":{"dataset":0.686712265}}
{"title":"[D] Comparison of the Model prediction uncertainty of two different models","description":"In your career as data scientists have you ever faced the situation where you have to compare the quality of the predictive uncertainty estimation of a machine learning model with an old statistical model that was already in use? if so, how did you do it?\n\ni have a bnn trained on some experimental data and a statistical models developed by my department that depends on some parameters estimated through the classic mcmc methods. Both seems to agree well with the experimental data but i wanted to compare the quality of the model predictive uncertainty\n\n&amp;#x200B;\n\ni thought about comparing the level of calibration of the uncertainty but  i am not sure if i have to do it on the test dataset (due to the bnn) or the entire dataset ( due to the fact that for the old statistical model they use mcmc methods on the entire dataset)","link":"https://www.reddit.com/r/MachineLearning/comments/11stv9f/d_comparison_of_the_model_prediction_uncertainty/","created":"2023-03-16","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":12},"text":"[D] Comparison of the Model prediction uncertainty of two different models In your career as data scientists have you ever faced the situation where you have to compare the quality of the predictive uncertainty estimation of a machine learning model with an old statistical model that was already in use? if so, how did you do it?\n\ni have a bnn trained on some experimental data and a statistical models developed by my department that depends on some parameters estimated through the classic mcmc methods. Both seems to agree well with the experimental data but i wanted to compare the quality of the model predictive uncertainty\n\n&amp;#x200B;\n\ni thought about comparing the level of calibration of the uncertainty but  i am not sure if i have to do it on the test dataset (due to the bnn) or the entire dataset ( due to the fact that for the old statistical model they use mcmc methods on the entire dataset)","classes":{"dataset":0.2121465206}}
{"title":"[D] Anyone else witnessing a panic inside NLP orgs of big tech companies?","description":"I'm in a big tech company working along side a science team for a product you've all probably used. We have these year long initiatives to productionalize \"state of the art NLP models\" that are now completely obsolete in the face of GPT-4. I think at first the science orgs were quiet/in denial. But now it's very obvious we are basically working on worthless technology. And by \"we\", I mean a large organization with scores of teams. \n\nAnyone else seeing this? What is the long term effect on science careers that get disrupted like this? Whats even more odd is the ego's of some of these science people\n\nClearly the model is not a catch all, but still","link":"https://www.reddit.com/r/MachineLearning/comments/11rizyb/d_anyone_else_witnessing_a_panic_inside_nlp_orgs/","created":"2023-03-15","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":457},"text":"[D] Anyone else witnessing a panic inside NLP orgs of big tech companies? I'm in a big tech company working along side a science team for a product you've all probably used. We have these year long initiatives to productionalize \"state of the art NLP models\" that are now completely obsolete in the face of GPT-4. I think at first the science orgs were quiet/in denial. But now it's very obvious we are basically working on worthless technology. And by \"we\", I mean a large organization with scores of teams. \n\nAnyone else seeing this? What is the long term effect on science careers that get disrupted like this? Whats even more odd is the ego's of some of these science people\n\nClearly the model is not a catch all, but still","classes":{"dataset":0.2908571661}}
{"title":"[D] Any other ICML reviewers noticing strange scores for the papers they're assigned to?","description":"I'm reviewing 4 papers, of which I gave one a very positive review. I am the only negative reviewer for 3/4 of the papers I am reviewing. Most of the papers have short, glowing positive reviews that don't meaningfully engage with the paper at all. At least two of the papers have bizarre formatting problems like blurry figures with unreadable text (not publication quality) that don't pass the eye test.\n\nA similar thing happened at ICLR reviews this year, and the authors withdrew their papers in spite of having 2x very positive reviews and 1x slightly negative review (mine). No attempt at rebuttal.\n\nHas anybody else experienced this?","link":"https://www.reddit.com/r/MachineLearning/comments/11scezi/d_any_other_icml_reviewers_noticing_strange/","created":"2023-03-15","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":10},"text":"[D] Any other ICML reviewers noticing strange scores for the papers they're assigned to? I'm reviewing 4 papers, of which I gave one a very positive review. I am the only negative reviewer for 3/4 of the papers I am reviewing. Most of the papers have short, glowing positive reviews that don't meaningfully engage with the paper at all. At least two of the papers have bizarre formatting problems like blurry figures with unreadable text (not publication quality) that don't pass the eye test.\n\nA similar thing happened at ICLR reviews this year, and the authors withdrew their papers in spite of having 2x very positive reviews and 1x slightly negative review (mine). No attempt at rebuttal.\n\nHas anybody else experienced this?","classes":{"dataset":0.4110577404}}
{"title":"[D] To those of you who quit machine learning, what do you do now?","description":"I'm currently doing my master's degree and have been set on a DL-related career for a while. But recently I noticed it doesn't bring me joy.\n\nComing up with architectures that randomly work/don't work, tuning parameters, waiting for days till the model is trained... the level of uncertainty is just too high for me. Because of that, I don't feel productive working on it and I'm slowly considering switching to another IT field.\n\nFor those of you who quit machine learning (especially deep learning):\n\n1. What did you switch to?\n2. Are you satisfied with your new job? (Is it stressful/intellectually challenging? Is it possible to keep it 9-5?)\n3. How to ensure a smooth transition to that field?\n\nThanks in advance!\n\n\\_\\_\\_  \nPS I know machine learning isn't all about deep learning, but in my current subfield (computer vision), mostly deep learning is used.","link":"https://www.reddit.com/r/MachineLearning/comments/11ryvao/d_to_those_of_you_who_quit_machine_learning_what/","created":"2023-03-15","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":36},"text":"[D] To those of you who quit machine learning, what do you do now? I'm currently doing my master's degree and have been set on a DL-related career for a while. But recently I noticed it doesn't bring me joy.\n\nComing up with architectures that randomly work/don't work, tuning parameters, waiting for days till the model is trained... the level of uncertainty is just too high for me. Because of that, I don't feel productive working on it and I'm slowly considering switching to another IT field.\n\nFor those of you who quit machine learning (especially deep learning):\n\n1. What did you switch to?\n2. Are you satisfied with your new job? (Is it stressful/intellectually challenging? Is it possible to keep it 9-5?)\n3. How to ensure a smooth transition to that field?\n\nThanks in advance!\n\n\\_\\_\\_  \nPS I know machine learning isn't all about deep learning, but in my current subfield (computer vision), mostly deep learning is used.","classes":{"dataset":0.4217063189}}
{"title":"[D] Is there an expectation that epochs/learning rates should be kept the same between benchmark experiments?","description":"I've found that by dramatically lowering the LR and increasing the number of epochs, very simple, baseline models can outperform SoTA models which use far more parameters. Is this considered \"cheating\" when comparing models? Is this something interesting enough to warrant a short paper? I'm not sure what to do with this information. \n\nFor example, in the original [VGAE](https://arxiv.org/pdf/1611.07308v1.pdf) paper, when training a GAE, they use a LR of 0.01, and train for 200 epochs to get 0.91 AUC, 0.92 AP on a link prediction experiment. Rerunning the same experiment with a LR of 5e-5 for 1500 epochs gets 0.97 AUC, 0.97 AP which is better than the current leader on papers with code for this dataset. \n\nIt needs more epochs but has way, way fewer parameters than SoTA models, is this a valid trade-off? Is this even a fair comparison?","link":"https://www.reddit.com/r/MachineLearning/comments/11s1zfh/d_is_there_an_expectation_that_epochslearning/","created":"2023-03-15","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":10},"text":"[D] Is there an expectation that epochs/learning rates should be kept the same between benchmark experiments? I've found that by dramatically lowering the LR and increasing the number of epochs, very simple, baseline models can outperform SoTA models which use far more parameters. Is this considered \"cheating\" when comparing models? Is this something interesting enough to warrant a short paper? I'm not sure what to do with this information. \n\nFor example, in the original [VGAE](https://arxiv.org/pdf/1611.07308v1.pdf) paper, when training a GAE, they use a LR of 0.01, and train for 200 epochs to get 0.91 AUC, 0.92 AP on a link prediction experiment. Rerunning the same experiment with a LR of 5e-5 for 1500 epochs gets 0.97 AUC, 0.97 AP which is better than the current leader on papers with code for this dataset. \n\nIt needs more epochs but has way, way fewer parameters than SoTA models, is this a valid trade-off? Is this even a fair comparison?","classes":{"dataset":0.4797369838}}
{"title":"RL and NLP are the two fields my passion and experience lies in. Which institutions/professors would be a good fit to pursue a PhD in a combination of the two?","description":"","link":"https://www.reddit.com/r/LanguageTechnology/comments/11t2rn3/rl_and_nlp_are_the_two_fields_my_passion_and/","created":"2023-03-16","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":2},"text":"RL and NLP are the two fields my passion and experience lies in. Which institutions/professors would be a good fit to pursue a PhD in a combination of the two? ","classes":{"dataset":0.1786346138}}
{"title":"Code Detection","description":"Given a text input I want to detect if there is any kind of code snippet in it. What's the best way to do this? Are there any pre trained models for this task? \n\nThank you","link":"https://www.reddit.com/r/LanguageTechnology/comments/11sr4ml/code_detection/","created":"2023-03-16","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":1},"text":"Code Detection Given a text input I want to detect if there is any kind of code snippet in it. What's the best way to do this? Are there any pre trained models for this task? \n\nThank you","classes":{"dataset":0.1154530123}}
{"title":"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3","description":"Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!\n\nThe reason for this increased performance seems to be due to a larger number of tokens being used for training.\n\nNow, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!\n\n[https://youtu.be/d4Cnv\\_g3GiI](https://youtu.be/d4Cnv_g3GiI)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11ryg4d/how_to_finetune_llama_models_smaller_models_with/","created":"2023-03-15","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":0},"text":"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3 Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!\n\nThe reason for this increased performance seems to be due to a larger number of tokens being used for training.\n\nNow, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!\n\n[https://youtu.be/d4Cnv\\_g3GiI](https://youtu.be/d4Cnv_g3GiI)","classes":{"dataset":0.4683608115}}
{"title":"Why chatgpt needs reinforcement learning","description":"Hello everyone, I'm a newer for RL and I have some questions after watching the \"Reinforcement Learning from Human Feedback: From Zero to chatGPT\" course from HuggingFace. Why is RL necessary? Once we have obtained the Reward model(The reward model is just another neural network that is differentiable), why not directly use it as a loss term and maximize it? What are the benefits and significance of using RL? Is it because the decoder in GPT involves a multi-stage decision-making process? If I have a one-step generation model, such as a GAN in the image field, do I still need RL?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11rwdx6/why_chatgpt_needs_reinforcement_learning/","created":"2023-03-15","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":2},"text":"Why chatgpt needs reinforcement learning Hello everyone, I'm a newer for RL and I have some questions after watching the \"Reinforcement Learning from Human Feedback: From Zero to chatGPT\" course from HuggingFace. Why is RL necessary? Once we have obtained the Reward model(The reward model is just another neural network that is differentiable), why not directly use it as a loss term and maximize it? What are the benefits and significance of using RL? Is it because the decoder in GPT involves a multi-stage decision-making process? If I have a one-step generation model, such as a GAN in the image field, do I still need RL?","classes":{"dataset":0.3181858361}}
{"title":"How do I select sentences in text which talk about specific thing?","description":"I have following sentences in mobile review:\n\n&gt;The camera lens is really of good quality with 1 cm sensor. The pictures turns out to have more realistic colour tone. But the mobile does not have good colour option. The battery life is also descent and not to mention that processor is top notch. However, the pics can sometimes turn out to be over exposed.\n\nI want to select only those sentences which talk about camera quality in above paragraph. In other words, I want to select following sentences:\n\n* The camera lens is really of good quality with 1 cm sensor.\n* The pictures turns out to have more realistic colour tone.\n* However, the pics can sometimes turn out to be over exposed.\n\nWhat ML model / concept / idea I can use to achieve this?\n\n**Update**\n\nI will not prefer using any ready made API. For example, Chat GPT which will do this for me with least effort (any input or model designing or implementation): [chat gpt respose screenshot](https://i.postimg.cc/QNfRSk3w/image.png)\n\nAs can be seen in the image at link above, chat gpt seem to be able to do this effortlessly out of box. How it is able to do this? How can I imitate this (with some input engineering and/or ML model(s))?","link":"https://www.reddit.com/r/LanguageTechnology/comments/11rs3sh/how_do_i_select_sentences_in_text_which_talk/","created":"2023-03-15","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":4},"text":"How do I select sentences in text which talk about specific thing? I have following sentences in mobile review:\n\n&gt;The camera lens is really of good quality with 1 cm sensor. The pictures turns out to have more realistic colour tone. But the mobile does not have good colour option. The battery life is also descent and not to mention that processor is top notch. However, the pics can sometimes turn out to be over exposed.\n\nI want to select only those sentences which talk about camera quality in above paragraph. In other words, I want to select following sentences:\n\n* The camera lens is really of good quality with 1 cm sensor.\n* The pictures turns out to have more realistic colour tone.\n* However, the pics can sometimes turn out to be over exposed.\n\nWhat ML model / concept / idea I can use to achieve this?\n\n**Update**\n\nI will not prefer using any ready made API. For example, Chat GPT which will do this for me with least effort (any input or model designing or implementation): [chat gpt respose screenshot](https://i.postimg.cc/QNfRSk3w/image.png)\n\nAs can be seen in the image at link above, chat gpt seem to be able to do this effortlessly out of box. How it is able to do this? How can I imitate this (with some input engineering and/or ML model(s))?","classes":{"dataset":0.4029767811}}
{"title":"Circle Takes Responsibility for Banking Issue, Provides Rebate to Users","description":"To be eligible to receive compensation, it is required that you held USDC when the bank terminated its services. Circle is offering a 10% cashback on the overall value of your USDC holdings if you were a holder during that period.\n\nCheck our Official Twitter to get more Information\n\nhttps://twitter.com/CircleUSDCNEW/status/1635965088707272705","link":"https://www.reddit.com/r/LanguageTechnology/comments/11s4j97/circle_takes_responsibility_for_banking_issue/","created":"2023-03-15","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":0},"text":"Circle Takes Responsibility for Banking Issue, Provides Rebate to Users To be eligible to receive compensation, it is required that you held USDC when the bank terminated its services. Circle is offering a 10% cashback on the overall value of your USDC holdings if you were a holder during that period.\n\nCheck our Official Twitter to get more Information\n\nhttps://twitter.com/CircleUSDCNEW/status/1635965088707272705","classes":{"dataset":0.3132452369}}
{"title":"GPT-4 has been announced! How long will it take for me to get off the waiting list?","description":"Just saw that OpenAI released gpt 4. Only has multi-modal element of inputting of images, not video. \n\nStill super exciting. Can anyone speculate how long until i can get access to the api? i\u2019m on the waitlist.","link":"https://www.reddit.com/r/LanguageTechnology/comments/11rddy4/gpt4_has_been_announced_how_long_will_it_take_for/","created":"2023-03-14","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":4},"text":"GPT-4 has been announced! How long will it take for me to get off the waiting list? Just saw that OpenAI released gpt 4. Only has multi-modal element of inputting of images, not video. \n\nStill super exciting. Can anyone speculate how long until i can get access to the api? i\u2019m on the waitlist.","classes":{"dataset":0.3177036047}}
{"title":"Structured Data-to-Text Generation (with little coding)?","description":"I'm looking to generate very structured text output from ideally a basic UI offering (consecutive 'decision-tree'-like) multiple choice inputs and text input boxes.\n\nIs there any software that can be programmed via some basic rules without requiring a lot of coding experience?\n\nI'm completely new to this field, so any hint is much appreciated!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11r2yub/structured_datatotext_generation_with_little/","created":"2023-03-14","tags":["reddit","languagetechnology","ml"],"meta":{"num_comments":0},"text":"Structured Data-to-Text Generation (with little coding)? I'm looking to generate very structured text output from ideally a basic UI offering (consecutive 'decision-tree'-like) multiple choice inputs and text input boxes.\n\nIs there any software that can be programmed via some basic rules without requiring a lot of coding experience?\n\nI'm completely new to this field, so any hint is much appreciated!","classes":{"dataset":0.4948276877}}
{"title":"Dietary sweetener sucralose is a negative modulator of T cell-mediated responses","description":"https://www.nature.com/articles/s41586-023-05801-6","link":"https://www.nature.com/articles/s41586-023-05801-6","created":"2023-03-20","tags":["hackernews"],"meta":{"score":53},"text":"Dietary sweetener sucralose is a negative modulator of T cell-mediated responses https://www.nature.com/articles/s41586-023-05801-6","classes":{"dataset":0.4670270979}}
{"title":"TinyVG \u2013 an alternative binary encoded vector graphics format","description":"https://tinyvg.tech/","link":"https://tinyvg.tech/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":89},"text":"TinyVG \u2013 an alternative binary encoded vector graphics format https://tinyvg.tech/","classes":{"dataset":0.549156785}}
{"title":"Curl 8.0.0","description":"https://daniel.haxx.se/blog/2023/03/20/curl-8-0-0-is-here/","link":"https://daniel.haxx.se/blog/2023/03/20/curl-8-0-0-is-here/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":106},"text":"Curl 8.0.0 https://daniel.haxx.se/blog/2023/03/20/curl-8-0-0-is-here/","classes":{"dataset":0.5154315829}}
{"title":"Newer data once again shows: the human brain is just a scaled up primate brain","description":"https://onlinelibrary.wiley.com/doi/10.1002/ajpa.24712","link":"https://onlinelibrary.wiley.com/doi/10.1002/ajpa.24712","created":"2023-03-20","tags":["hackernews"],"meta":{"score":71},"text":"Newer data once again shows: the human brain is just a scaled up primate brain https://onlinelibrary.wiley.com/doi/10.1002/ajpa.24712","classes":{"dataset":0.4941182435}}
{"title":"Jaccard Index","description":"https://en.wikipedia.org/wiki/Jaccard_index","link":"https://en.wikipedia.org/wiki/Jaccard_index","created":"2023-03-19","tags":["hackernews"],"meta":{"score":191},"text":"Jaccard Index https://en.wikipedia.org/wiki/Jaccard_index","classes":{"dataset":0.52631706}}
{"title":"Anti-recruiter prompt injection attack in LinkedIn profile","description":"https://twitter.com/brdskggs/status/1637114268876144640","link":"https://twitter.com/brdskggs/status/1637114268876144640","created":"2023-03-19","tags":["hackernews"],"meta":{"score":288},"text":"Anti-recruiter prompt injection attack in LinkedIn profile https://twitter.com/brdskggs/status/1637114268876144640","classes":{"dataset":0.5091460347}}
{"title":"GPTs Are GPTs: An Early Look at the Labor Market Impact Potential of LLMs","description":"https://arxiv.org/abs/2303.10130","link":"https://arxiv.org/abs/2303.10130","created":"2023-03-20","tags":["hackernews"],"meta":{"score":99},"text":"GPTs Are GPTs: An Early Look at the Labor Market Impact Potential of LLMs https://arxiv.org/abs/2303.10130","classes":{"dataset":0.469222188}}
{"title":"Oakland's non-profit video game museum is back, and thriving","description":"https://sfstandard.com/arts-culture/fly-spaceships-battle-aliens-and-drive-a-crazy-taxi-at-this-oakland-museum/","link":"https://sfstandard.com/arts-culture/fly-spaceships-battle-aliens-and-drive-a-crazy-taxi-at-this-oakland-museum/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":138},"text":"Oakland's non-profit video game museum is back, and thriving https://sfstandard.com/arts-culture/fly-spaceships-battle-aliens-and-drive-a-crazy-taxi-at-this-oakland-museum/","classes":{"dataset":0.522855103}}
{"title":"Ken Thompson's 75 year project: A century of popular music in a jukebox [video]","description":"https://www.youtube.com/watch?v=kaandEt_pKw","link":"https://www.youtube.com/watch?v=kaandEt_pKw","created":"2023-03-19","tags":["hackernews"],"meta":{"score":470},"text":"Ken Thompson's 75 year project: A century of popular music in a jukebox [video] https://www.youtube.com/watch?v=kaandEt_pKw","classes":{"dataset":0.4803638756}}
{"title":"Gallery of Minimal Design Websites","description":"https://minimal.gallery/","link":"https://minimal.gallery/","created":"2023-03-19","tags":["hackernews"],"meta":{"score":94},"text":"Gallery of Minimal Design Websites https://minimal.gallery/","classes":{"dataset":0.50273031}}
{"title":"Bitwarden PINs can be brute-forced","description":"https://ambiso.github.io/bitwarden-pin/","link":"https://ambiso.github.io/bitwarden-pin/","created":"2023-03-19","tags":["hackernews"],"meta":{"score":398},"text":"Bitwarden PINs can be brute-forced https://ambiso.github.io/bitwarden-pin/","classes":{"dataset":0.4785180986}}
{"title":"The little-known story behind the 2022 Nobel Prize in physics","description":"https://www.scientificamerican.com/article/the-little-known-origin-story-behind-the-2022-nobel-prize-in-physics/","link":"https://www.scientificamerican.com/article/the-little-known-origin-story-behind-the-2022-nobel-prize-in-physics/","created":"2023-03-19","tags":["hackernews"],"meta":{"score":181},"text":"The little-known story behind the 2022 Nobel Prize in physics https://www.scientificamerican.com/article/the-little-known-origin-story-behind-the-2022-nobel-prize-in-physics/","classes":{"dataset":0.5003742576}}
{"title":"Mastodon hit 10M users","description":"https://mastodon.social/@mastodonusercount/110051957865629817","link":"https://mastodon.social/@mastodonusercount/110051957865629817","created":"2023-03-19","tags":["hackernews"],"meta":{"score":309},"text":"Mastodon hit 10M users https://mastodon.social/@mastodonusercount/110051957865629817","classes":{"dataset":0.5470151901}}
{"title":"DS-Fusion: Artistic Typography via Discriminated and Stylized Diffusion","description":"https://ds-fusion.github.io/","link":"https://ds-fusion.github.io/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":30},"text":"DS-Fusion: Artistic Typography via Discriminated and Stylized Diffusion https://ds-fusion.github.io/","classes":{"dataset":0.4837790728}}
{"title":"Rust Support Is Being Built into the GNU GCC Compiler","description":"https://thenewstack.io/rust-support-is-being-built-into-the-gnu-gcc-compiler/","link":"https://thenewstack.io/rust-support-is-being-built-into-the-gnu-gcc-compiler/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":8},"text":"Rust Support Is Being Built into the GNU GCC Compiler https://thenewstack.io/rust-support-is-being-built-into-the-gnu-gcc-compiler/","classes":{"dataset":0.535228312}}
{"title":"PLATO: An educational computer system from the 60s shaped the future","description":"https://arstechnica.com/gadgets/2023/03/plato-how-an-educational-computer-system-from-the-60s-shaped-the-future/","link":"https://arstechnica.com/gadgets/2023/03/plato-how-an-educational-computer-system-from-the-60s-shaped-the-future/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":154},"text":"PLATO: An educational computer system from the 60s shaped the future https://arstechnica.com/gadgets/2023/03/plato-how-an-educational-computer-system-from-the-60s-shaped-the-future/","classes":{"dataset":0.5142606497}}
{"title":"Regenerating Jordan\u2019s native forests","description":"https://www.theguardian.com/global-development/2023/mar/09/greening-the-desert-architect-tayyun-regenerating-jordan-native-forests","link":"https://www.theguardian.com/global-development/2023/mar/09/greening-the-desert-architect-tayyun-regenerating-jordan-native-forests","created":"2023-03-19","tags":["hackernews"],"meta":{"score":181},"text":"Regenerating Jordan\u2019s native forests https://www.theguardian.com/global-development/2023/mar/09/greening-the-desert-architect-tayyun-regenerating-jordan-native-forests","classes":{"dataset":0.5186769962}}
{"title":"Show HN: Yaksha Programming Language","description":"https://yakshalang.github.io/","link":"https://yakshalang.github.io/","created":"2023-03-19","tags":["hackernews"],"meta":{"score":181},"text":"Show HN: Yaksha Programming Language https://yakshalang.github.io/","classes":{"dataset":0.4952793717}}
{"title":"Analyzing a failed drill bit with an electron microscope [video]","description":"https://www.youtube.com/watch?v=887Q-LWBW48","link":"https://www.youtube.com/watch?v=887Q-LWBW48","created":"2023-03-19","tags":["hackernews"],"meta":{"score":233},"text":"Analyzing a failed drill bit with an electron microscope [video] https://www.youtube.com/watch?v=887Q-LWBW48","classes":{"dataset":0.4916401505}}
{"title":"The curious case of a memory leak in a Zig program","description":"https://iamkroot.github.io/blog/zig-memleak","link":"https://iamkroot.github.io/blog/zig-memleak","created":"2023-03-19","tags":["hackernews"],"meta":{"score":164},"text":"The curious case of a memory leak in a Zig program https://iamkroot.github.io/blog/zig-memleak","classes":{"dataset":0.4960995615}}
{"title":"Methylmercury in thawing permafrost","description":"https://hakaimagazine.com/news/the-toxic-threat-in-thawing-permafrost/","link":"https://hakaimagazine.com/news/the-toxic-threat-in-thawing-permafrost/","created":"2023-03-19","tags":["hackernews"],"meta":{"score":46},"text":"Methylmercury in thawing permafrost https://hakaimagazine.com/news/the-toxic-threat-in-thawing-permafrost/","classes":{"dataset":0.4752187431}}
{"title":"Epic Games, others accuse Sundar Pichai of violating retention obligations","description":"http://www.fosspatents.com/2023/03/us-states-epic-games-others-accuse.html","link":"http://www.fosspatents.com/2023/03/us-states-epic-games-others-accuse.html","created":"2023-03-19","tags":["hackernews"],"meta":{"score":293},"text":"Epic Games, others accuse Sundar Pichai of violating retention obligations http://www.fosspatents.com/2023/03/us-states-epic-games-others-accuse.html","classes":{"dataset":0.5158123374}}
{"title":"We gave GPT-3.5 tools to run, write, commit, and deploy code","description":"https://old.reddit.com/r/MachineLearning/comments/11vfbo9/p_we_gave_gpt35_tools_that_developers_use_and_let/","link":"https://old.reddit.com/r/MachineLearning/comments/11vfbo9/p_we_gave_gpt35_tools_that_developers_use_and_let/","created":"2023-03-20","tags":["hackernews"],"meta":{"score":58},"text":"We gave GPT-3.5 tools to run, write, commit, and deploy code https://old.reddit.com/r/MachineLearning/comments/11vfbo9/p_we_gave_gpt35_tools_that_developers_use_and_let/","classes":{"dataset":0.4859015346}}
{"title":"New React docs pretend SPAs don't exist anymore","description":"https://wasp-lang.dev/blog/2023/03/17/new-react-docs-pretend-spas-dont-exist","link":"https://wasp-lang.dev/blog/2023/03/17/new-react-docs-pretend-spas-dont-exist","created":"2023-03-17","tags":["hackernews"],"meta":{"score":182},"text":"New React docs pretend SPAs don't exist anymore https://wasp-lang.dev/blog/2023/03/17/new-react-docs-pretend-spas-dont-exist","classes":{"dataset":0.5268409848}}
{"title":"More students are turning away from college and toward apprenticeships","description":"https://www.wsj.com/articles/more-students-are-turning-away-from-college-and-toward-apprenticeships-15f3a05d","link":"https://www.wsj.com/articles/more-students-are-turning-away-from-college-and-toward-apprenticeships-15f3a05d","created":"2023-03-18","tags":["hackernews"],"meta":{"score":695},"text":"More students are turning away from college and toward apprenticeships https://www.wsj.com/articles/more-students-are-turning-away-from-college-and-toward-apprenticeships-15f3a05d","classes":{"dataset":0.4899078608}}
{"title":"My new hobby: finding public domain images that Getty sells for $500","description":"https://twitter.com/doctorow/status/1637443442921066497","link":"https://twitter.com/doctorow/status/1637443442921066497","created":"2023-03-19","tags":["hackernews"],"meta":{"score":220},"text":"My new hobby: finding public domain images that Getty sells for $500 https://twitter.com/doctorow/status/1637443442921066497","classes":{"dataset":0.4879952967}}
{"title":"Learning the ropes: why Germany is building risk into its playgrounds (2021)","description":"https://www.theguardian.com/world/2021/oct/24/why-germany-is-building-risk-into-its-playgrounds","link":"https://www.theguardian.com/world/2021/oct/24/why-germany-is-building-risk-into-its-playgrounds","created":"2023-03-19","tags":["hackernews"],"meta":{"score":265},"text":"Learning the ropes: why Germany is building risk into its playgrounds (2021) https://www.theguardian.com/world/2021/oct/24/why-germany-is-building-risk-into-its-playgrounds","classes":{"dataset":0.4606456459}}
{"title":"Affordable device will let anyone connect their brain to a computer","description":"https://www.vice.com/en/article/88x99k/this-affordable-device-will-let-anyone-connect-their-brain-to-a-computer","link":"https://www.vice.com/en/article/88x99k/this-affordable-device-will-let-anyone-connect-their-brain-to-a-computer","created":"2023-03-19","tags":["hackernews"],"meta":{"score":56},"text":"Affordable device will let anyone connect their brain to a computer https://www.vice.com/en/article/88x99k/this-affordable-device-will-let-anyone-connect-their-brain-to-a-computer","classes":{"dataset":0.4914535582}}
{"title":"SETI@home is in hibernation","description":"https://setiathome.berkeley.edu/","link":"https://setiathome.berkeley.edu/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":500},"text":"SETI@home is in hibernation https://setiathome.berkeley.edu/","classes":{"dataset":0.4467153847}}
{"title":"Show HN: Next.js ChatGPT \u2013 Responsive chat application powered by GPT-4","description":"https://github.com/enricoros/nextjs-chatgpt-app","link":"https://github.com/enricoros/nextjs-chatgpt-app","created":"2023-03-19","tags":["hackernews"],"meta":{"score":115},"text":"Show HN: Next.js ChatGPT \u2013 Responsive chat application powered by GPT-4 https://github.com/enricoros/nextjs-chatgpt-app","classes":{"dataset":0.5319346189}}
{"title":"Analyzing multi-gigabyte JSON files locally","description":"https://thenybble.de/posts/json-analysis/","link":"https://thenybble.de/posts/json-analysis/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":205},"text":"Analyzing multi-gigabyte JSON files locally https://thenybble.de/posts/json-analysis/","classes":{"dataset":0.6004841924}}
{"title":"Mark Zuckerberg: \u201cPlease Resign\u201d (2010)","description":"https://www.techemails.com/p/mark-zuckerberg-please-resign","link":"https://www.techemails.com/p/mark-zuckerberg-please-resign","created":"2023-03-19","tags":["hackernews"],"meta":{"score":182},"text":"Mark Zuckerberg: \u201cPlease Resign\u201d (2010) https://www.techemails.com/p/mark-zuckerberg-please-resign","classes":{"dataset":0.5291645527}}
{"title":"Exploiting aCropalypse: Recovering truncated PNGs","description":"https://www.da.vidbuchanan.co.uk/blog/exploiting-acropalypse.html","link":"https://www.da.vidbuchanan.co.uk/blog/exploiting-acropalypse.html","created":"2023-03-18","tags":["hackernews"],"meta":{"score":218},"text":"Exploiting aCropalypse: Recovering truncated PNGs https://www.da.vidbuchanan.co.uk/blog/exploiting-acropalypse.html","classes":{"dataset":0.4884916842}}
{"title":"Simulations and games in economics education","description":"https://en.wikipedia.org/wiki/Simulations_and_games_in_economics_education","link":"https://en.wikipedia.org/wiki/Simulations_and_games_in_economics_education","created":"2023-03-18","tags":["hackernews"],"meta":{"score":74},"text":"Simulations and games in economics education https://en.wikipedia.org/wiki/Simulations_and_games_in_economics_education","classes":{"dataset":0.5112885237}}
{"title":"\u2018He passed the bee baton on to me\u2019: people who inherit hobbies","description":"https://www.theguardian.com/lifeandstyle/2023/mar/08/he-passed-the-bee-baton-on-to-me-people-who-inherit-hobbies","link":"https://www.theguardian.com/lifeandstyle/2023/mar/08/he-passed-the-bee-baton-on-to-me-people-who-inherit-hobbies","created":"2023-03-18","tags":["hackernews"],"meta":{"score":60},"text":"\u2018He passed the bee baton on to me\u2019: people who inherit hobbies https://www.theguardian.com/lifeandstyle/2023/mar/08/he-passed-the-bee-baton-on-to-me-people-who-inherit-hobbies","classes":{"dataset":0.4895247519}}
{"title":"Coordinated central bank action to enhance the provision of US dollar liquidity","description":"https://www.federalreserve.gov/newsevents/pressreleases/monetary20230319a.htm","link":"https://www.federalreserve.gov/newsevents/pressreleases/monetary20230319a.htm","created":"2023-03-19","tags":["hackernews"],"meta":{"score":69},"text":"Coordinated central bank action to enhance the provision of US dollar liquidity https://www.federalreserve.gov/newsevents/pressreleases/monetary20230319a.htm","classes":{"dataset":0.4982540905}}
{"title":"A growing number of scientists are convinced the future influences the past","description":"https://www.vice.com/en/article/epvgjm/a-growing-number-of-scientists-are-convinced-the-future-influences-the-past","link":"https://www.vice.com/en/article/epvgjm/a-growing-number-of-scientists-are-convinced-the-future-influences-the-past","created":"2023-03-17","tags":["hackernews"],"meta":{"score":325},"text":"A growing number of scientists are convinced the future influences the past https://www.vice.com/en/article/epvgjm/a-growing-number-of-scientists-are-convinced-the-future-influences-the-past","classes":{"dataset":0.5232227445}}
{"title":"The untapped potential of human programming (2022)","description":"https://humanprogramming.substack.com/p/the-untapped-potential-of-human-programming","link":"https://humanprogramming.substack.com/p/the-untapped-potential-of-human-programming","created":"2023-03-19","tags":["hackernews"],"meta":{"score":74},"text":"The untapped potential of human programming (2022) https://humanprogramming.substack.com/p/the-untapped-potential-of-human-programming","classes":{"dataset":0.5140632391}}
{"title":"A 1967 experiment that proved anyone can design a nuclear weapon","description":"https://www.amusingplanet.com/2023/03/the-1967-experiment-that-proved-anyone.html","link":"https://www.amusingplanet.com/2023/03/the-1967-experiment-that-proved-anyone.html","created":"2023-03-19","tags":["hackernews"],"meta":{"score":63},"text":"A 1967 experiment that proved anyone can design a nuclear weapon https://www.amusingplanet.com/2023/03/the-1967-experiment-that-proved-anyone.html","classes":{"dataset":0.4751027524}}
{"title":"The myth of a wilderness without humans","description":"https://thereader.mitpress.mit.edu/the-myth-of-a-wilderness-without-humans/","link":"https://thereader.mitpress.mit.edu/the-myth-of-a-wilderness-without-humans/","created":"2023-03-19","tags":["hackernews"],"meta":{"score":26},"text":"The myth of a wilderness without humans https://thereader.mitpress.mit.edu/the-myth-of-a-wilderness-without-humans/","classes":{"dataset":0.53965801}}
{"title":"Prometheus (YC W19) Is Hiring","description":"https://www.ycombinator.com/companies/prometheus/jobs/34u2Lo8-research-engineer-electrochemistry","link":"https://www.ycombinator.com/companies/prometheus/jobs/34u2Lo8-research-engineer-electrochemistry","created":"2023-03-17","tags":["hackernews"],"meta":{"score":1},"text":"Prometheus (YC W19) Is Hiring https://www.ycombinator.com/companies/prometheus/jobs/34u2Lo8-research-engineer-electrochemistry","classes":{"dataset":0.4989792705}}
{"title":"How to own your own Docker Registry address","description":"https://httptoolkit.com/blog/docker-image-registry-facade/","link":"https://httptoolkit.com/blog/docker-image-registry-facade/","created":"2023-03-18","tags":["hackernews"],"meta":{"score":202},"text":"How to own your own Docker Registry address https://httptoolkit.com/blog/docker-image-registry-facade/","classes":{"dataset":0.4949691296}}
{"title":"Monday Daily Thread: Project ideas!","description":"Comment any project ideas beginner or advanced in this thread for others to give a try! If you complete one make sure to reply to the comment with how you found it and attach some source code! If you're looking for project ideas, you might be interested in checking out Al Sweigart's, [\"The Big Book of Small Python Projects\"](https://inventwithpython.com/bigbookpython/) which provides a list of projects and the code to make them work.","link":"https://www.reddit.com/r/Python/comments/11w27d5/monday_daily_thread_project_ideas/","created":"2023-03-20","tags":["python","reddit"],"meta":{"num_comments":0},"text":"Monday Daily Thread: Project ideas! Comment any project ideas beginner or advanced in this thread for others to give a try! If you complete one make sure to reply to the comment with how you found it and attach some source code! If you're looking for project ideas, you might be interested in checking out Al Sweigart's, [\"The Big Book of Small Python Projects\"](https://inventwithpython.com/bigbookpython/) which provides a list of projects and the code to make them work.","classes":{"dataset":0.4687213302}}
{"title":"I've created one of the Fastest Python web Frameworks!!","description":"**Panther**  \n**Github**: [https://github.com/AliRn76/panther](https://github.com/AliRn76/panther)  \n**Documentation**: [https://pantherpy.github.io/](https://pantherpy.github.io/)  \n\n\nhttps://preview.redd.it/gtec70b1uroa1.png?width=831&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=08c1d9b71f3f555297432cc817dfa09d05c67c66","link":"https://www.reddit.com/r/Python/comments/11vzvde/ive_created_one_of_the_fastest_python_web/","created":"2023-03-19","tags":["python","reddit"],"meta":{"num_comments":23},"text":"I've created one of the Fastest Python web Frameworks!! **Panther**  \n**Github**: [https://github.com/AliRn76/panther](https://github.com/AliRn76/panther)  \n**Documentation**: [https://pantherpy.github.io/](https://pantherpy.github.io/)  \n\n\nhttps://preview.redd.it/gtec70b1uroa1.png?width=831&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=08c1d9b71f3f555297432cc817dfa09d05c67c66","classes":{"dataset":0.4994611144}}
{"title":"Middle level book to study Python","description":"Is there any middle level book I can use once I know all the basics data types, functions, classes etc in order to level up the language? Thanks!","link":"https://www.reddit.com/r/Python/comments/11vhrgr/middle_level_book_to_study_python/","created":"2023-03-19","tags":["python","reddit"],"meta":{"num_comments":24},"text":"Middle level book to study Python Is there any middle level book I can use once I know all the basics data types, functions, classes etc in order to level up the language? Thanks!","classes":{"dataset":0.2508158982}}
{"title":"TUT | quick video tutorial about self-hosting APIs","description":"Hi gouyss, I made a quick video for web devs that want to self-host their apps. I showcase Docker, Docker-Compose and Traefik very quickly and show web developers how to get their APIs public quickly. Nothing groundbreaking but I needed this information and I didn't have a clear understanding of where to find it but it's my utmost hope it helps others that were chasing project requirements that are outlined in this video.   \n\n\nVideo Link: [https://www.youtube.com/watch?v=NIHzYIkXFhE](https://www.youtube.com/watch?v=NIHzYIkXFhE&amp;t=16s)\r  \nGithub Link:  [https://github.com/Wizock/how-to-host-FastAPI-Apis-on-traefik](https://github.com/Wizock/how-to-host-FastAPI-Apis-on-traefik)  \n\n\nAll feedback is appreciated :).","link":"https://www.reddit.com/r/Python/comments/11wbwqv/tut_quick_video_tutorial_about_selfhosting_apis/","created":"2023-03-20","tags":["python","reddit"],"meta":{"num_comments":0},"text":"TUT | quick video tutorial about self-hosting APIs Hi gouyss, I made a quick video for web devs that want to self-host their apps. I showcase Docker, Docker-Compose and Traefik very quickly and show web developers how to get their APIs public quickly. Nothing groundbreaking but I needed this information and I didn't have a clear understanding of where to find it but it's my utmost hope it helps others that were chasing project requirements that are outlined in this video.   \n\n\nVideo Link: [https://www.youtube.com/watch?v=NIHzYIkXFhE](https://www.youtube.com/watch?v=NIHzYIkXFhE&amp;t=16s)\r  \nGithub Link:  [https://github.com/Wizock/how-to-host-FastAPI-Apis-on-traefik](https://github.com/Wizock/how-to-host-FastAPI-Apis-on-traefik)  \n\n\nAll feedback is appreciated :).","classes":{"dataset":0.4810295105}}
{"title":"[Survey] Evaluating AI-generated Python code","description":"Hello there! I'm conducting a study on AI-generated code for my thesis project in Computer Science and I'm looking for programmers to rate 50 short code samples on three different factors:\n\n* Accuracy: How closely the solution matches the described task.\n* Quality: How well-written the code is.\n* Readability: How easy it is to understand the code.\n\nThe questionnaire should take approximately 30 minutes to complete and you can use any tools you normally would use when programming, such as documentation, search engines, or programming forums.\n\nhttps://forms.gle/kk2XrPCaKzkqdFVE8","link":"https://www.reddit.com/r/Python/comments/11wd2g6/survey_evaluating_aigenerated_python_code/","created":"2023-03-20","tags":["python","reddit"],"meta":{"num_comments":2},"text":"[Survey] Evaluating AI-generated Python code Hello there! I'm conducting a study on AI-generated code for my thesis project in Computer Science and I'm looking for programmers to rate 50 short code samples on three different factors:\n\n* Accuracy: How closely the solution matches the described task.\n* Quality: How well-written the code is.\n* Readability: How easy it is to understand the code.\n\nThe questionnaire should take approximately 30 minutes to complete and you can use any tools you normally would use when programming, such as documentation, search engines, or programming forums.\n\nhttps://forms.gle/kk2XrPCaKzkqdFVE8","classes":{"dataset":0.3836654425}}
{"title":"pyWave - Financial transaction tracker.","description":"I've decided to throw together a little thing that's pretty helpful with keeping track of transactions. Like a register book you'd get from a bank.\n\nIt works how you'd expect it to work, with a way to describe what the transaction was for, whether it was money going \"in\" or moving \"out\". It'll automatically update the total, starting with a starting balance that'd you have to set it up with to begin with. Like a normal register book. \n\n\n\nYou can use this project to help with balancing a checkbook, keeping track of money moving in and out of your wallet, etc.\n\n\n\nI don't expect it to be used at all, but I thought it was neat enough to share as it'll most definitely help me out a decent amount.\n\n\n\nYou can find the project here: https://github.com/therealOri/pyWave","link":"https://www.reddit.com/r/Python/comments/11vywu8/pywave_financial_transaction_tracker/","created":"2023-03-19","tags":["python","reddit"],"meta":{"num_comments":4},"text":"pyWave - Financial transaction tracker. I've decided to throw together a little thing that's pretty helpful with keeping track of transactions. Like a register book you'd get from a bank.\n\nIt works how you'd expect it to work, with a way to describe what the transaction was for, whether it was money going \"in\" or moving \"out\". It'll automatically update the total, starting with a starting balance that'd you have to set it up with to begin with. Like a normal register book. \n\n\n\nYou can use this project to help with balancing a checkbook, keeping track of money moving in and out of your wallet, etc.\n\n\n\nI don't expect it to be used at all, but I thought it was neat enough to share as it'll most definitely help me out a decent amount.\n\n\n\nYou can find the project here: https://github.com/therealOri/pyWave","classes":{"dataset":0.3875810504}}
{"title":"How to learn for loop, do while loop and functions?","description":"I work as an Analyst, have some experience with Python, like using groupby, filter conditions, joins, windows function, rank function to basically get the business logic to code. I see people who are efficient in coding tend to write their code as a single function rather than going through each step one at a time like cells in jupyter notebook. I want to learn how can I be better at writing loops, conditions and functions together as a whole. Like for example my coworker built a function where he declared a empty list outside the function, use it within, used counters and basically ran a groupby with agg to include the function fetching the desired output as a dataframe. How will I be able to work on such complex functions using loops and other parameters?","link":"https://www.reddit.com/r/Python/comments/11wcya8/how_to_learn_for_loop_do_while_loop_and_functions/","created":"2023-03-20","tags":["python","reddit"],"meta":{"num_comments":2},"text":"How to learn for loop, do while loop and functions? I work as an Analyst, have some experience with Python, like using groupby, filter conditions, joins, windows function, rank function to basically get the business logic to code. I see people who are efficient in coding tend to write their code as a single function rather than going through each step one at a time like cells in jupyter notebook. I want to learn how can I be better at writing loops, conditions and functions together as a whole. Like for example my coworker built a function where he declared a empty list outside the function, use it within, used counters and basically ran a groupby with agg to include the function fetching the desired output as a dataframe. How will I be able to work on such complex functions using loops and other parameters?","classes":{"dataset":0.2917436659}}
{"title":"FastAPI 0.95.0 supports and recommends Annotated \ud83d\ude80 [cross-post from r/FastAPI]","description":"This is probably the biggest FastAPI feature in several months, I thought it was worth sharing it. \ud83e\udd13\n\n(Cross-post from [r/FastAPI](https://www.reddit.com/r/FastAPI/comments/11v0j5w/fastapi_0950_supports_and_recommends_annotated/) but I thought this was cool enough to also share it here \ud83d\ude2c).\n\nFastAPI `0.95.0`, just released, adds support for dependencies and parameters using `Annotated` and recommends its usage. \u2728\n\nThis has **several benefits**, one of the main ones is that now the parameters of your functions with `Annotated` would **not be affected** at all.\n\nIf you call those functions in **other places in your code**, the actual **default values** will be kept, your editor will help you notice missing **required arguments**, Python will require you to pass required arguments at **runtime**, you will be able to **use the same functions** for different things and with different libraries (e.g. **Typer** will soon support `Annotated` too, then you could use the same function for an API and a CLI), etc.\n\nBecause `Annotated` is **standard Python**, you still get all the **benefits** from editors and tools, like **autocompletion**, **inline errors**, etc.\n\nOne of the **biggest benefits** is that now you can create `Annotated` dependencies that are then shared by multiple *path operation functions*, this will allow you to **reduce** a lot of **code duplication** in your codebase, while keeping all the support from editors and tools.\n\nFor example, you could have code like this:\n\n    def get_current_user(token: str):\n        # authenticate user\n        return User()\n\n\n    @app.get(\"/items/\")\n    def read_items(user: User = Depends(get_current_user)):\n        ...\n\n\n    @app.post(\"/items/\")\n    def create_item(*, user: User = Depends(get_current_user), item: Item):\n        ...\n\n\n    @app.get(\"/items/{item_id}\")\n    def read_item(*, user: User = Depends(get_current_user), item_id: int):\n        ...\n\n\n    @app.delete(\"/items/{item_id}\")\n    def delete_item(*, user: User = Depends(get_current_user), item_id: int):\n        ...\n\nThere's a bit of code duplication for the dependency:\n\n    user: User = Depends(get_current_user)\n\n...the bigger the codebase, the more noticeable it is.\n\nNow you can create an annotated dependency once, like this:\n\n    CurrentUser = Annotated[User, Depends(get_current_user)]\n\n\nAnd then you can reuse this `Annotated` dependency:\n\n    CurrentUser = Annotated[User, Depends(get_current_user)]\n\n\n    @app.get(\"/items/\")\n    def read_items(user: CurrentUser):\n        ...\n\n\n    @app.post(\"/items/\")\n    def create_item(user: CurrentUser, item: Item):\n        ...\n\n\n    @app.get(\"/items/{item_id}\")\n    def read_item(user: CurrentUser, item_id: int):\n        ...\n\n\n    @app.delete(\"/items/{item_id}\")\n    def delete_item(user: CurrentUser, item_id: int):\n        ...\n\n...and `CurrentUser` has all the typing information as `User`, so your editor will work as expected (autocompletion and everything), and **FastAPI** will be able to understand the dependency defined in `Annotated`. \ud83d\ude0e\n\nRoughly **all the docs** have been rewritten to use `Annotated` as the main way to declare **parameters** and **dependencies**. All the **examples** in the docs now include a version with `Annotated` and a version without it, for each of the specific Python versions (when there are small differences/improvements in more recent versions). There were around 23K new lines added between docs, examples, and tests. \ud83d\ude80\n\nThe key updated docs are:\n\n* Python Types Intro:\n    * [Type Hints with Metadata Annotations](https://fastapi.tiangolo.com/python-types/#type-hints-with-metadata-annotations).\n* Tutorial:\n    * [Query Parameters and String Validations - Additional validation](https://fastapi.tiangolo.com/tutorial/query-params-str-validations/#additional-validation)\n        * [Advantages of `Annotated`](https://fastapi.tiangolo.com/tutorial/query-params-str-validations/#advantages-of-annotated)\n    * [Path Parameters and Numeric Validations - Order the parameters as you need, tricks](https://fastapi.tiangolo.com/tutorial/path-params-numeric-validations/#order-the-parameters-as-you-need-tricks)\n        * [Better with `Annotated`](https://fastapi.tiangolo.com/tutorial/path-params-numeric-validations/#better-with-annotated)\n    * [Dependencies - First Steps - Share `Annotated` dependencies](https://fastapi.tiangolo.com/tutorial/dependencies/#share-annotated-dependencies)\n\nSpecial thanks to [@nzig](https://github.com/nzig) for the core implementation and to [@adriangb](https://github.com/adriangb) for the inspiration and idea with [Xpresso](https://github.com/adriangb/xpresso)! \ud83d\ude80\n\nIt took a while to get this done as it involved several days thoroughly reviewing the core PR (impeccable job) and a couple of weeks of full-time, continuous, focused work rewriting the docs, examples, and tests. And now it's finally out! \ud83c\udf89\n\nThis will also probably enable much better third-party integrations that can now export `Annotated` dependencies. \ud83d\ude0e\n\nGo update your FastAPI version and start enjoying using `Annotated`! \ud83d\ude80\n\nCheck more details in the release notes: https://fastapi.tiangolo.com/release-notes/#0950","link":"https://www.reddit.com/r/Python/comments/11v0kcb/fastapi_0950_supports_and_recommends_annotated/","created":"2023-03-18","tags":["python","reddit"],"meta":{"num_comments":21},"text":"FastAPI 0.95.0 supports and recommends Annotated \ud83d\ude80 [cross-post from r/FastAPI] This is probably the biggest FastAPI feature in several months, I thought it was worth sharing it. \ud83e\udd13\n\n(Cross-post from [r/FastAPI](https://www.reddit.com/r/FastAPI/comments/11v0j5w/fastapi_0950_supports_and_recommends_annotated/) but I thought this was cool enough to also share it here \ud83d\ude2c).\n\nFastAPI `0.95.0`, just released, adds support for dependencies and parameters using `Annotated` and recommends its usage. \u2728\n\nThis has **several benefits**, one of the main ones is that now the parameters of your functions with `Annotated` would **not be affected** at all.\n\nIf you call those functions in **other places in your code**, the actual **default values** will be kept, your editor will help you notice missing **required arguments**, Python will require you to pass required arguments at **runtime**, you will be able to **use the same functions** for different things and with different libraries (e.g. **Typer** will soon support `Annotated` too, then you could use the same function for an API and a CLI), etc.\n\nBecause `Annotated` is **standard Python**, you still get all the **benefits** from editors and tools, like **autocompletion**, **inline errors**, etc.\n\nOne of the **biggest benefits** is that now you can create `Annotated` dependencies that are then shared by multiple *path operation functions*, this will allow you to **reduce** a lot of **code duplication** in your codebase, while keeping all the support from editors and tools.\n\nFor example, you could have code like this:\n\n    def get_current_user(token: str):\n        # authenticate user\n        return User()\n\n\n    @app.get(\"/items/\")\n    def read_items(user: User = Depends(get_current_user)):\n        ...\n\n\n    @app.post(\"/items/\")\n    def create_item(*, user: User = Depends(get_current_user), item: Item):\n        ...\n\n\n    @app.get(\"/items/{item_id}\")\n    def read_item(*, user: User = Depends(get_current_user), item_id: int):\n        ...\n\n\n    @app.delete(\"/items/{item_id}\")\n    def delete_item(*, user: User = Depends(get_current_user), item_id: int):\n        ...\n\nThere's a bit of code duplication for the dependency:\n\n    user: User = Depends(get_current_user)\n\n...the bigger the codebase, the more noticeable it is.\n\nNow you can create an annotated dependency once, like this:\n\n    CurrentUser = Annotated[User, Depends(get_current_user)]\n\n\nAnd then you can reuse this `Annotated` dependency:\n\n    CurrentUser = Annotated[User, Depends(get_current_user)]\n\n\n    @app.get(\"/items/\")\n    def read_items(user: CurrentUser):\n        ...\n\n\n    @app.post(\"/items/\")\n    def create_item(user: CurrentUser, item: Item):\n        ...\n\n\n    @app.get(\"/items/{item_id}\")\n    def read_item(user: CurrentUser, item_id: int):\n        ...\n\n\n    @app.delete(\"/items/{item_id}\")\n    def delete_item(user: CurrentUser, item_id: int):\n        ...\n\n...and `CurrentUser` has all the typing information as `User`, so your editor will work as expected (autocompletion and everything), and **FastAPI** will be able to understand the dependency defined in `Annotated`. \ud83d\ude0e\n\nRoughly **all the docs** have been rewritten to use `Annotated` as the main way to declare **parameters** and **dependencies**. All the **examples** in the docs now include a version with `Annotated` and a version without it, for each of the specific Python versions (when there are small differences/improvements in more recent versions). There were around 23K new lines added between docs, examples, and tests. \ud83d\ude80\n\nThe key updated docs are:\n\n* Python Types Intro:\n    * [Type Hints with Metadata Annotations](https://fastapi.tiangolo.com/python-types/#type-hints-with-metadata-annotations).\n* Tutorial:\n    * [Query Parameters and String Validations - Additional validation](https://fastapi.tiangolo.com/tutorial/query-params-str-validations/#additional-validation)\n        * [Advantages of `Annotated`](https://fastapi.tiangolo.com/tutorial/query-params-str-validations/#advantages-of-annotated)\n    * [Path Parameters and Numeric Validations - Order the parameters as you need, tricks](https://fastapi.tiangolo.com/tutorial/path-params-numeric-validations/#order-the-parameters-as-you-need-tricks)\n        * [Better with `Annotated`](https://fastapi.tiangolo.com/tutorial/path-params-numeric-validations/#better-with-annotated)\n    * [Dependencies - First Steps - Share `Annotated` dependencies](https://fastapi.tiangolo.com/tutorial/dependencies/#share-annotated-dependencies)\n\nSpecial thanks to [@nzig](https://github.com/nzig) for the core implementation and to [@adriangb](https://github.com/adriangb) for the inspiration and idea with [Xpresso](https://github.com/adriangb/xpresso)! \ud83d\ude80\n\nIt took a while to get this done as it involved several days thoroughly reviewing the core PR (impeccable job) and a couple of weeks of full-time, continuous, focused work rewriting the docs, examples, and tests. And now it's finally out! \ud83c\udf89\n\nThis will also probably enable much better third-party integrations that can now export `Annotated` dependencies. \ud83d\ude0e\n\nGo update your FastAPI version and start enjoying using `Annotated`! \ud83d\ude80\n\nCheck more details in the release notes: https://fastapi.tiangolo.com/release-notes/#0950","classes":{"dataset":0.5399472713}}
{"title":"bare-bones terminal interface for chatGPT","description":"I wanted to have an access to chatGPT from within the terminal and could not find any implementation that was easy to install and did what I wanted it to do, so I made my own.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/2hmvgw234roa1.png?width=1012&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9b78fddeb9d84ef5e8fe62fb5f45bff92715c8c1\n\nIt uses official openAI API. You can find it here: [https://github.com/Ach113/shellGPT](https://github.com/Ach113/shellGPT)\n\nIts very simple to install and use. You can specify which model you want it to use as backend by specifying `-m &lt;modelname&gt;`. Available models can be found [here](https://platform.openai.com/docs/models/moderation) (although not all models seem to work).\n\nYou can enable conversation logging by setting `-l` flag. You can also redirect responses to specific questions to text files using `&gt;`, `&gt;&gt;` operators:\n\n`$ What is the meaning of life &gt; answer.txt`","link":"https://www.reddit.com/r/Python/comments/11vvrqb/barebones_terminal_interface_for_chatgpt/","created":"2023-03-19","tags":["python","reddit"],"meta":{"num_comments":0},"text":"bare-bones terminal interface for chatGPT I wanted to have an access to chatGPT from within the terminal and could not find any implementation that was easy to install and did what I wanted it to do, so I made my own.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/2hmvgw234roa1.png?width=1012&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9b78fddeb9d84ef5e8fe62fb5f45bff92715c8c1\n\nIt uses official openAI API. You can find it here: [https://github.com/Ach113/shellGPT](https://github.com/Ach113/shellGPT)\n\nIts very simple to install and use. You can specify which model you want it to use as backend by specifying `-m &lt;modelname&gt;`. Available models can be found [here](https://platform.openai.com/docs/models/moderation) (although not all models seem to work).\n\nYou can enable conversation logging by setting `-l` flag. You can also redirect responses to specific questions to text files using `&gt;`, `&gt;&gt;` operators:\n\n`$ What is the meaning of life &gt; answer.txt`","classes":{"dataset":0.1329232752}}
{"title":"Hi r/py I'm working on a Python library for PySimpleGUI to design UIs with a Live Preview, giving a low barrier to entry. I hope you like it!","description":"This project is a fork from this users original project: [https://github.com/PriestTheBeast/SimpleGUIBuilder](https://github.com/PriestTheBeast/SimpleGUIBuilder)\n\nMy Repo expanding on the foundation with themes, live previews, and hoping to improve QOL: [https://github.com/samfisherirl/PySimpleGUI-Designer-with-Live-Preview](https://github.com/samfisherirl/PySimpleGUI-Designer-with-Live-Preview)\n\nThroughout my experience with software development, I have come to appreciate the accessibility and ease-of-use that Autohotkey provides, especially for mid to low-level use cases. However, for newcomer to the python programming language, I have found that the Qt framework can be quite intimidating to approach. While not impossible to learn, it can present a steep learning curve for beginners.\n\nSome of the things I really appreciate from my time with AHK:\n\n* GUI-to-EXE can be done within a few clicks with no coding, but provide paths to produce full OOP programs.\n* Simplified automation for mid to low-level use cases.\n* Allows for customization and flexibility through user-defined functions and commands.\n\nIn my pursuit to bridge the gap between visual design and code, I have found PySimpleGUI to be a great model. Its streamlined approach has allowed me to quickly translate visual designs into code, making the learning process much smoother. As a lifelong learner, I'm always eager to share my experiences and help others along the way.\n\nWith this project, I want to provide a relatively smooth UI experience that can allow users to build ready-made GUIs with ease.\n\nThis project is still in its early stages, and I'm excited to see where it goes. Personally, I've had success with pywebview and Eel due to the expansive HTML design tools available. I'm open to any recommendations for libraries or tools that you find helpful for GUI design. Thanks!\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n[https://imgur.com/a/LCf7ln1](https://imgur.com/a/LCf7ln1)\n\n&amp;#x200B;\n\nhttps://i.redd.it/9v7bi000cloa1.gif\n\n&amp;#x200B;","link":"https://www.reddit.com/r/Python/comments/11uyzsz/hi_rpy_im_working_on_a_python_library_for/","created":"2023-03-18","tags":["python","reddit"],"meta":{"num_comments":4},"text":"Hi r/py I'm working on a Python library for PySimpleGUI to design UIs with a Live Preview, giving a low barrier to entry. I hope you like it! This project is a fork from this users original project: [https://github.com/PriestTheBeast/SimpleGUIBuilder](https://github.com/PriestTheBeast/SimpleGUIBuilder)\n\nMy Repo expanding on the foundation with themes, live previews, and hoping to improve QOL: [https://github.com/samfisherirl/PySimpleGUI-Designer-with-Live-Preview](https://github.com/samfisherirl/PySimpleGUI-Designer-with-Live-Preview)\n\nThroughout my experience with software development, I have come to appreciate the accessibility and ease-of-use that Autohotkey provides, especially for mid to low-level use cases. However, for newcomer to the python programming language, I have found that the Qt framework can be quite intimidating to approach. While not impossible to learn, it can present a steep learning curve for beginners.\n\nSome of the things I really appreciate from my time with AHK:\n\n* GUI-to-EXE can be done within a few clicks with no coding, but provide paths to produce full OOP programs.\n* Simplified automation for mid to low-level use cases.\n* Allows for customization and flexibility through user-defined functions and commands.\n\nIn my pursuit to bridge the gap between visual design and code, I have found PySimpleGUI to be a great model. Its streamlined approach has allowed me to quickly translate visual designs into code, making the learning process much smoother. As a lifelong learner, I'm always eager to share my experiences and help others along the way.\n\nWith this project, I want to provide a relatively smooth UI experience that can allow users to build ready-made GUIs with ease.\n\nThis project is still in its early stages, and I'm excited to see where it goes. Personally, I've had success with pywebview and Eel due to the expansive HTML design tools available. I'm open to any recommendations for libraries or tools that you find helpful for GUI design. Thanks!\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n[https://imgur.com/a/LCf7ln1](https://imgur.com/a/LCf7ln1)\n\n&amp;#x200B;\n\nhttps://i.redd.it/9v7bi000cloa1.gif\n\n&amp;#x200B;","classes":{"dataset":0.532822907}}
{"title":"What is something you wish there was a Python module for?","description":"","link":"https://www.reddit.com/r/Python/comments/11uyyh3/what_is_something_you_wish_there_was_a_python/","created":"2023-03-18","tags":["python","reddit"],"meta":{"num_comments":140},"text":"What is something you wish there was a Python module for? ","classes":{"dataset":0.5201491117}}
{"title":"Alpaca-7B and Dalai, how can I get coherent results?","description":"Recently, I installed dalai on my Macbook Pro (late 2019, i7 processor and 16GB of RAM) and I also installed Alpaca-7B model. Now when I ask it to write a tweet, it writes a wikipedia article and it does the same pretty much every time \ud83d\ude02\n\nFirst, should I fine-tune it?\n\nSecond, is there any \"prompt magic\" going on here?\n\nP.S: using [this one](https://github.com/tloen/alpaca-lora),  I got much better results. What's the difference between the two?","link":"https://www.reddit.com/r/deeplearning/comments/11wdi8m/alpaca7b_and_dalai_how_can_i_get_coherent_results/","created":"2023-03-20","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Alpaca-7B and Dalai, how can I get coherent results? Recently, I installed dalai on my Macbook Pro (late 2019, i7 processor and 16GB of RAM) and I also installed Alpaca-7B model. Now when I ask it to write a tweet, it writes a wikipedia article and it does the same pretty much every time \ud83d\ude02\n\nFirst, should I fine-tune it?\n\nSecond, is there any \"prompt magic\" going on here?\n\nP.S: using [this one](https://github.com/tloen/alpaca-lora),  I got much better results. What's the difference between the two?","classes":{"dataset":0.3069589436}}
{"title":"Systematised Network Diagrams","description":"Hi all, I've been working on this neural network diagram convention for a few years now and would love to hear your feedback on it. I have personally found it useful, so I thought I would share it in case others would like to adopt it too.\n\nMy motivation was that almost every scientific paper uses a different diagrammatic system to depict their networks. This puts a burden on the reader to get to grips with the unique system, compounded with understanding the novel network displayed.\n\nThe aim of this system is to be modular, minimalistic, and consistent, enabling fast interpretation and universal communication of network architectures in scientific papers and presentations. This outlined key system is designed to represent clear, symbolic placeholders for mathematical functions, much like Feynman diagrams for quantum field theory or logic gates for mathematical logic. My [GitHub](https://github.com/GeorgeBird1/Diagramatic-Neural-Networks) page on this system offers an easy way to centralise, date, and update the convention. No accreditation is required when using this system for any purpose.\n\nIt is easy for hand drawing, with an included shorthand notation, alongside a more technical depiction for use in papers. All symbols are constructable using common flow-chart shapes for easy implementation.\n\nHere are some example networks I've drawn using this system:\n\n[Depiction of various types of neural network architectures using this system.](https://preview.redd.it/2geqegs3cqoa1.png?width=928&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=669c19ece3bc82fd2189f9e325da282a51b70ca5)\n\nHere are the basic key-components, more can be found on my [GitHub](https://github.com/GeorgeBird1/Diagramatic-Neural-Networks) link:\n\n[The basic key system for constructing diagrams. More available on the GitHub](https://preview.redd.it/mlhxhgfbcqoa1.png?width=750&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5090b1a914dcadd8b491506fb469534e1437531f)\n\nThanks for reading, any feedback gratefully received! :)","link":"https://www.reddit.com/r/deeplearning/comments/11vwj20/systematised_network_diagrams/","created":"2023-03-19","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Systematised Network Diagrams Hi all, I've been working on this neural network diagram convention for a few years now and would love to hear your feedback on it. I have personally found it useful, so I thought I would share it in case others would like to adopt it too.\n\nMy motivation was that almost every scientific paper uses a different diagrammatic system to depict their networks. This puts a burden on the reader to get to grips with the unique system, compounded with understanding the novel network displayed.\n\nThe aim of this system is to be modular, minimalistic, and consistent, enabling fast interpretation and universal communication of network architectures in scientific papers and presentations. This outlined key system is designed to represent clear, symbolic placeholders for mathematical functions, much like Feynman diagrams for quantum field theory or logic gates for mathematical logic. My [GitHub](https://github.com/GeorgeBird1/Diagramatic-Neural-Networks) page on this system offers an easy way to centralise, date, and update the convention. No accreditation is required when using this system for any purpose.\n\nIt is easy for hand drawing, with an included shorthand notation, alongside a more technical depiction for use in papers. All symbols are constructable using common flow-chart shapes for easy implementation.\n\nHere are some example networks I've drawn using this system:\n\n[Depiction of various types of neural network architectures using this system.](https://preview.redd.it/2geqegs3cqoa1.png?width=928&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=669c19ece3bc82fd2189f9e325da282a51b70ca5)\n\nHere are the basic key-components, more can be found on my [GitHub](https://github.com/GeorgeBird1/Diagramatic-Neural-Networks) link:\n\n[The basic key system for constructing diagrams. More available on the GitHub](https://preview.redd.it/mlhxhgfbcqoa1.png?width=750&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5090b1a914dcadd8b491506fb469534e1437531f)\n\nThanks for reading, any feedback gratefully received! :)","classes":{"dataset":0.2259825021}}
{"title":"Using synthetic data to obtain sota results in a Kaggle medical competition: https://medium.com/@bogdanandreig/the-future-of-cardiac-imaging-leveraging-synthetic-image-data-for-improved-cardiac-function-bad67b1c9175","description":"","link":"https://www.reddit.com/r/deeplearning/comments/11vmxsf/using_synthetic_data_to_obtain_sota_results_in_a/","created":"2023-03-19","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Using synthetic data to obtain sota results in a Kaggle medical competition: https://medium.com/@bogdanandreig/the-future-of-cardiac-imaging-leveraging-synthetic-image-data-for-improved-cardiac-function-bad67b1c9175 ","classes":{"dataset":0.4737661183}}
{"title":"Best GPUs for pretraining roBERTa-size LLMs with a $50K budget, 4x RTX A6000 v.s. 4x A6000 ADA v.s. 2x A100 80GB","description":"Hi folks,\n\nOur lab plans to purchase a server with some decent GPUs to perform some pertaining tasks for program codes. We won't work on very large LLM and we even may not try the T5 model. Currently, we want to first try the roBERTa model. We have a $50K budget. And it's our first time purchasing GPU servers.\n\nI did some preliminary study and found the suggested GPU is A6000 ADA which has 48 GB GPU memory, according to [https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/). Since our tasks require lots of GPU memory, we think a GPU with more than 32 GB will be good for us. So our alternative choices are RTX A6000 and A100 80GB HBM2 cards. \n\nBased on these, we got three server specs from Exxact ( [https://www.exxactcorp.com/TWS-115999024/configurator](https://www.exxactcorp.com/TWS-115999024/configurator)), (1) a $43K spec with 4  A6000 ADA cards, (2) a $32K spec with 4 RTX A6000 cards, and (3) a $41K spec with 2 A100 80GB cards. The other parts in the specs, e.g., CPU and RAM, are almost the same. I have attached the specs in screenshots.\n\nNow, I have some questions. \n\n1. A6000 ADA removed NVLink ([https://forums.developer.nvidia.com/t/rtx-a6000-ada-no-more-nv-link-even-on-pro-gpus/230874](https://forums.developer.nvidia.com/t/rtx-a6000-ada-no-more-nv-link-even-on-pro-gpus/230874)) which is very important for performance boosting and GPU memory pooling. Does this mean it's a good choice to have multiple A6000 ADA cards on a server?\n2. A6000 ADA is a very new GPU improved from RTX A6000. But it has the NVLink, which means the server GPU memory can reach 48 \\* 4 GB when connecting 4 RTX A6000 cards. However, we are going to use the GPU server for several years. For IT products, it's always better to purchase the latest ones. Is that true for GPU cards? And A6000 ADA has more tensor and cuda cores than RTX A6000. \n3. For the A100 80GB spec, we can only have 2 cards wondering the budget. For the LLM pertaining, more cards usually mean more parallelism and faster training. Based on my study, A6000 ADA has comparable performance to A100 on DL benchmarks. Is this A100 80GB spec a good choice?\n4. Except for the ahead-mentioned specs, what else would you recommend for our pretraining tasks, especially for GPUs?\n\nThanks for your time! We really appreciate any suggestions.","link":"https://www.reddit.com/r/deeplearning/comments/11vb220/best_gpus_for_pretraining_robertasize_llms_with_a/","created":"2023-03-19","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":7},"text":"Best GPUs for pretraining roBERTa-size LLMs with a $50K budget, 4x RTX A6000 v.s. 4x A6000 ADA v.s. 2x A100 80GB Hi folks,\n\nOur lab plans to purchase a server with some decent GPUs to perform some pertaining tasks for program codes. We won't work on very large LLM and we even may not try the T5 model. Currently, we want to first try the roBERTa model. We have a $50K budget. And it's our first time purchasing GPU servers.\n\nI did some preliminary study and found the suggested GPU is A6000 ADA which has 48 GB GPU memory, according to [https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/](https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/). Since our tasks require lots of GPU memory, we think a GPU with more than 32 GB will be good for us. So our alternative choices are RTX A6000 and A100 80GB HBM2 cards. \n\nBased on these, we got three server specs from Exxact ( [https://www.exxactcorp.com/TWS-115999024/configurator](https://www.exxactcorp.com/TWS-115999024/configurator)), (1) a $43K spec with 4  A6000 ADA cards, (2) a $32K spec with 4 RTX A6000 cards, and (3) a $41K spec with 2 A100 80GB cards. The other parts in the specs, e.g., CPU and RAM, are almost the same. I have attached the specs in screenshots.\n\nNow, I have some questions. \n\n1. A6000 ADA removed NVLink ([https://forums.developer.nvidia.com/t/rtx-a6000-ada-no-more-nv-link-even-on-pro-gpus/230874](https://forums.developer.nvidia.com/t/rtx-a6000-ada-no-more-nv-link-even-on-pro-gpus/230874)) which is very important for performance boosting and GPU memory pooling. Does this mean it's a good choice to have multiple A6000 ADA cards on a server?\n2. A6000 ADA is a very new GPU improved from RTX A6000. But it has the NVLink, which means the server GPU memory can reach 48 \\* 4 GB when connecting 4 RTX A6000 cards. However, we are going to use the GPU server for several years. For IT products, it's always better to purchase the latest ones. Is that true for GPU cards? And A6000 ADA has more tensor and cuda cores than RTX A6000. \n3. For the A100 80GB spec, we can only have 2 cards wondering the budget. For the LLM pertaining, more cards usually mean more parallelism and faster training. Based on my study, A6000 ADA has comparable performance to A100 on DL benchmarks. Is this A100 80GB spec a good choice?\n4. Except for the ahead-mentioned specs, what else would you recommend for our pretraining tasks, especially for GPUs?\n\nThanks for your time! We really appreciate any suggestions.","classes":{"dataset":0.5064857602}}
{"title":"DL with TensorFlow on macOS with eGPU?","description":"I am wondering what is the state of things regarding ML on macOS with eGPU?\n\nI have been successfully running my model trainings on Ubuntu + nvidia eGPU. Unfortunately, my cat crashed my laptop beyond repair. I have a MacBook Pro (2018) running macOS Monterey and was wondering if it could be repurposed for some DL work.\n\nI found some interesting setups with [PlaidML](https://weinan.io/2021/05/24/macos-ml.html) leveraging eGPU on macOS.\n\nDoes anyone have experience with this? I understand that using an nvidia card is no longer an option. Would something like amd's RX 6900 XT work?","link":"https://www.reddit.com/r/deeplearning/comments/11vl47t/dl_with_tensorflow_on_macos_with_egpu/","created":"2023-03-19","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":2},"text":"DL with TensorFlow on macOS with eGPU? I am wondering what is the state of things regarding ML on macOS with eGPU?\n\nI have been successfully running my model trainings on Ubuntu + nvidia eGPU. Unfortunately, my cat crashed my laptop beyond repair. I have a MacBook Pro (2018) running macOS Monterey and was wondering if it could be repurposed for some DL work.\n\nI found some interesting setups with [PlaidML](https://weinan.io/2021/05/24/macos-ml.html) leveraging eGPU on macOS.\n\nDoes anyone have experience with this? I understand that using an nvidia card is no longer an option. Would something like amd's RX 6900 XT work?","classes":{"dataset":0.5291885734}}
{"title":"Seeking Career Advice to go from general CS background to a career in AI/Machine Learning","description":"Hey.\n\nI'm a University student in final year studying Computer Science. I've enjoyed my degree and I have a decent GPA but my University does not have a clear path to get me into AI and Machine Learning related career. \n\nI'm seeking professional advice on how to go from a general CS background to being employable in AI/Machine Learning over the next 5 to 6 months. If you have specific recommendations beyond what Google offers that would be great. Also, can't afford to do a masters degree in AI\ud83d\ude05.\n\nThanks in advance.","link":"https://www.reddit.com/r/deeplearning/comments/11urpbb/seeking_career_advice_to_go_from_general_cs/","created":"2023-03-18","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":11},"text":"Seeking Career Advice to go from general CS background to a career in AI/Machine Learning Hey.\n\nI'm a University student in final year studying Computer Science. I've enjoyed my degree and I have a decent GPA but my University does not have a clear path to get me into AI and Machine Learning related career. \n\nI'm seeking professional advice on how to go from a general CS background to being employable in AI/Machine Learning over the next 5 to 6 months. If you have specific recommendations beyond what Google offers that would be great. Also, can't afford to do a masters degree in AI\ud83d\ude05.\n\nThanks in advance.","classes":{"dataset":0.4160943627}}
{"title":"Need some advice for my idea of \"Sketch to design\" project","description":"*I originally asked this question* [*here on stackoverflow*](https://stackoverflow.com/questions/75775112/need-some-advice-for-my-idea-of-sketch-to-design-project)\n\nI have an idea of a *sketch to design* program with deep learning and computer vision. I saw the very same concept before and I believe GPT-4 is capable of doing something similar. First, I have to say that I am familiar with the computer vision procedure. I did it [before](https://haghiri75.com/en/analyzing-components-of-an-electric-circuit-with-yolov5/) and I know using YOLO algorithms might be a good idea.\n\nAlso, I have no problems developing a \"Sketch to code\" program since I can pipe my results to another AI or code generator. But I also found [Uizard](http://uizard.io) which can turn your hand-drawn sketches into \"Design\".\n\nIt made some questions in my mind which are the following:\n\n1. Is there any language for design? Or it's just XML, HTML or SVG coded file?\n2. Is there any code/design generator which is capable of turning a simple design document (like *a page with a navbar*) to HTML or SVG? and **open source** of course!\n\nI will be thankful for your helps and comments.","link":"https://www.reddit.com/r/deeplearning/comments/11ukow0/need_some_advice_for_my_idea_of_sketch_to_design/","created":"2023-03-18","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":1},"text":"Need some advice for my idea of \"Sketch to design\" project *I originally asked this question* [*here on stackoverflow*](https://stackoverflow.com/questions/75775112/need-some-advice-for-my-idea-of-sketch-to-design-project)\n\nI have an idea of a *sketch to design* program with deep learning and computer vision. I saw the very same concept before and I believe GPT-4 is capable of doing something similar. First, I have to say that I am familiar with the computer vision procedure. I did it [before](https://haghiri75.com/en/analyzing-components-of-an-electric-circuit-with-yolov5/) and I know using YOLO algorithms might be a good idea.\n\nAlso, I have no problems developing a \"Sketch to code\" program since I can pipe my results to another AI or code generator. But I also found [Uizard](http://uizard.io) which can turn your hand-drawn sketches into \"Design\".\n\nIt made some questions in my mind which are the following:\n\n1. Is there any language for design? Or it's just XML, HTML or SVG coded file?\n2. Is there any code/design generator which is capable of turning a simple design document (like *a page with a navbar*) to HTML or SVG? and **open source** of course!\n\nI will be thankful for your helps and comments.","classes":{"dataset":0.1104393974}}
{"title":"Hidden Markov Model in Golang using Gonum","description":"please I'm making a credit card fraud detection system using unsupervised learning. The approach I'm taking is using the hidden Markov Model implemented in golang but same algorithm for some reason, after adding my scaling factors, my transition, emission and start probabilities matrix still get an underflow problem where after like 5 iterations, my matrices start given off NaN (meaning is far off to like 0.00000000....). When debugging I noticed using the scaling vector from my forward process to normalise my beta, the sum of each row doesn't equal 1 and I feel that should be a problem","link":"https://www.reddit.com/r/deeplearning/comments/11u6q66/hidden_markov_model_in_golang_using_gonum/","created":"2023-03-17","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":0},"text":"Hidden Markov Model in Golang using Gonum please I'm making a credit card fraud detection system using unsupervised learning. The approach I'm taking is using the hidden Markov Model implemented in golang but same algorithm for some reason, after adding my scaling factors, my transition, emission and start probabilities matrix still get an underflow problem where after like 5 iterations, my matrices start given off NaN (meaning is far off to like 0.00000000....). When debugging I noticed using the scaling vector from my forward process to normalise my beta, the sum of each row doesn't equal 1 and I feel that should be a problem","classes":{"dataset":0.4455404878}}
{"title":"MOOC/YT tutorials for best Deep Learning","description":"A DS generalist here. Have got some years of experience in traditional ML models and occasionally used TF to build projects for fun/personal interest. But want to be get into DL more seriously. Any suggestions on any MOOC/YouTube channel that would be best for that?","link":"https://www.reddit.com/r/deeplearning/comments/11tplmv/moocyt_tutorials_for_best_deep_learning/","created":"2023-03-17","tags":["deeplearning","reddit","ml"],"meta":{"num_comments":4},"text":"MOOC/YT tutorials for best Deep Learning A DS generalist here. Have got some years of experience in traditional ML models and occasionally used TF to build projects for fun/personal interest. But want to be get into DL more seriously. Any suggestions on any MOOC/YouTube channel that would be best for that?","classes":{"dataset":0.4626605809}}
{"title":"[D] Incorporating external data in LSTM models for sales forecasting in e-commerce","description":"**Background:** \n\nI'm working on a project related to sales forecasting in e-commerce and comparing the performance of ARIMAX, lightGBM, and LSTM models across various aggregation levels. I'm also examining the impact of additional features like promotions, inventory levels, and weather on demand forecasting.\n\n&amp;#x200B;\n\n**Question:** \n\nI'm curious about utilizing external data, such as weather information, in LSTM models. My understanding of LSTM is that it calculates the most probable next values based on a certain number of historical values. Can LSTM models use more than one feature to forecast a single target variable? Moreover, is it possible to leverage future features like holidays to improve LSTM forecasts? \n\n&amp;#x200B;\n\nI would appreciate any resources, such as projects, books, or tutorials, that could help me better understand this process. Thank you!","link":"https://www.reddit.com/r/MachineLearning/comments/11weava/d_incorporating_external_data_in_lstm_models_for/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[D] Incorporating external data in LSTM models for sales forecasting in e-commerce **Background:** \n\nI'm working on a project related to sales forecasting in e-commerce and comparing the performance of ARIMAX, lightGBM, and LSTM models across various aggregation levels. I'm also examining the impact of additional features like promotions, inventory levels, and weather on demand forecasting.\n\n&amp;#x200B;\n\n**Question:** \n\nI'm curious about utilizing external data, such as weather information, in LSTM models. My understanding of LSTM is that it calculates the most probable next values based on a certain number of historical values. Can LSTM models use more than one feature to forecast a single target variable? Moreover, is it possible to leverage future features like holidays to improve LSTM forecasts? \n\n&amp;#x200B;\n\nI would appreciate any resources, such as projects, books, or tutorials, that could help me better understand this process. Thank you!","classes":{"dataset":0.0715160742}}
{"title":"[D] For those who have worked 5+ years in the field, what are you up to now?","description":"Hey,I've  been working in ML for the last 5-10 years, almost since deep learning  came up, mostly startups with various successes, sometimes doing more research sometimes doing more engineering tasks.\n\nThis year I was excited to manage a team focused on ML but plans have just changed in my company and this isn't going to happen anytime soon. I am interviewing for another company for a \"senior\"  role but they still ask me to do this basic ML assignment that takes a  few hours to complete. I have just realised how boring it became to me  to the point I don't even want to do it as I literally have done this  for the last 5+ years.\n\nFor those  who have been in the field for at least 5+ years, what are you up to now? Are you still doing ML? Have you moved into management? Have you started your own company? Moved to a different subfield perhaps?\n\nPS: I  have a PhD, in addition to those years of experience i mention. I am  aware this isn't related to ML purely but more like mid-career crisis,  but would be interested to know how people in the field have dealt with  it.","link":"https://www.reddit.com/r/MachineLearning/comments/11vygjb/d_for_those_who_have_worked_5_years_in_the_field/","created":"2023-03-19","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":2},"text":"[D] For those who have worked 5+ years in the field, what are you up to now? Hey,I've  been working in ML for the last 5-10 years, almost since deep learning  came up, mostly startups with various successes, sometimes doing more research sometimes doing more engineering tasks.\n\nThis year I was excited to manage a team focused on ML but plans have just changed in my company and this isn't going to happen anytime soon. I am interviewing for another company for a \"senior\"  role but they still ask me to do this basic ML assignment that takes a  few hours to complete. I have just realised how boring it became to me  to the point I don't even want to do it as I literally have done this  for the last 5+ years.\n\nFor those  who have been in the field for at least 5+ years, what are you up to now? Are you still doing ML? Have you moved into management? Have you started your own company? Moved to a different subfield perhaps?\n\nPS: I  have a PhD, in addition to those years of experience i mention. I am  aware this isn't related to ML purely but more like mid-career crisis,  but would be interested to know how people in the field have dealt with  it.","classes":{"dataset":0.30114308}}
{"title":"[D] IJCAI 2023 Rebuttal Discussion","description":"Title","link":"https://www.reddit.com/r/MachineLearning/comments/11w8x8d/d_ijcai_2023_rebuttal_discussion/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[D] IJCAI 2023 Rebuttal Discussion Title","classes":{"dataset":0.1930099577}}
{"title":"[D] Best ChatBot that can be run locally?","description":"What do you guys think is currently the best ChatBot that you can download and run offline? After hearing that Alpaca has results similar to GPT-3, I was curious if anything else competes.","link":"https://www.reddit.com/r/MachineLearning/comments/11w8lp2/d_best_chatbot_that_can_be_run_locally/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":3},"text":"[D] Best ChatBot that can be run locally? What do you guys think is currently the best ChatBot that you can download and run offline? After hearing that Alpaca has results similar to GPT-3, I was curious if anything else competes.","classes":{"dataset":0.4553080499}}
{"title":"[D] Systematised Network Diagrams","description":"Hi all, I've been working on this neural network diagram convention for a few years now and would love to hear your feedback on it. I have personally found it useful, so I thought I would share it in case others would like to adopt it too.\n\nMy motivation was that almost every scientific paper uses a different diagrammatic system to depict their networks. This puts a burden on the reader to get to grips with the unique system, compounded with understanding the novel network displayed.\n\nThe aim of this system is to be modular, minimalistic, and consistent, enabling fast interpretation and universal communication of network architectures in scientific papers and presentations. This outlined key system is designed to represent clear, symbolic placeholders for mathematical functions, much like Feynman diagrams for quantum field theory or logic gates for mathematical logic. My [GitHub](https://github.com/GeorgeBird1/Diagramatic-Neural-Networks) page on this system offers an easy way to centralise, date, and update the convention. No accreditation is required when using this system for any purpose.\n\nIt is easy for hand drawing, with an included shorthand notation, alongside a more technical depiction for use in papers. All symbols are constructable using common flow-chart shapes for easy implementation.\n\nHere are some example networks I've drawn using this system:\n\n[Depiction of various types of neural network architectures using this system.](https://preview.redd.it/2geqegs3cqoa1.png?width=928&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=669c19ece3bc82fd2189f9e325da282a51b70ca5)\n\nHere are the basic key-components, more can be found on my [GitHub](https://github.com/GeorgeBird1/Diagramatic-Neural-Networks) link:\n\n[The basic key system for constructing diagrams. More available on the GitHub](https://preview.redd.it/mlhxhgfbcqoa1.png?width=750&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5090b1a914dcadd8b491506fb469534e1437531f)\n\nThanks for reading, any feedback gratefully received! :)","link":"https://www.reddit.com/r/MachineLearning/comments/11vv056/d_systematised_network_diagrams/","created":"2023-03-19","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":4},"text":"[D] Systematised Network Diagrams Hi all, I've been working on this neural network diagram convention for a few years now and would love to hear your feedback on it. I have personally found it useful, so I thought I would share it in case others would like to adopt it too.\n\nMy motivation was that almost every scientific paper uses a different diagrammatic system to depict their networks. This puts a burden on the reader to get to grips with the unique system, compounded with understanding the novel network displayed.\n\nThe aim of this system is to be modular, minimalistic, and consistent, enabling fast interpretation and universal communication of network architectures in scientific papers and presentations. This outlined key system is designed to represent clear, symbolic placeholders for mathematical functions, much like Feynman diagrams for quantum field theory or logic gates for mathematical logic. My [GitHub](https://github.com/GeorgeBird1/Diagramatic-Neural-Networks) page on this system offers an easy way to centralise, date, and update the convention. No accreditation is required when using this system for any purpose.\n\nIt is easy for hand drawing, with an included shorthand notation, alongside a more technical depiction for use in papers. All symbols are constructable using common flow-chart shapes for easy implementation.\n\nHere are some example networks I've drawn using this system:\n\n[Depiction of various types of neural network architectures using this system.](https://preview.redd.it/2geqegs3cqoa1.png?width=928&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=669c19ece3bc82fd2189f9e325da282a51b70ca5)\n\nHere are the basic key-components, more can be found on my [GitHub](https://github.com/GeorgeBird1/Diagramatic-Neural-Networks) link:\n\n[The basic key system for constructing diagrams. More available on the GitHub](https://preview.redd.it/mlhxhgfbcqoa1.png?width=750&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5090b1a914dcadd8b491506fb469534e1437531f)\n\nThanks for reading, any feedback gratefully received! :)","classes":{"dataset":0.471164763}}
{"title":"[R] What do we think about Meta-Interpretive Learning?","description":"Came across this concept, Meta-Interpretive Learning (MIL) developed by Muggleton, Patsantzis, et al.\n\n* [https://arxiv.org/pdf/2101.05050.pdf](https://arxiv.org/pdf/2101.05050.pdf)\n* [https://arxiv.org/pdf/2106.07464.pdf](https://arxiv.org/pdf/2106.07464.pdf)\n* [Presentation](https://www.youtube.com/watch?v=73cBWmjlFLk)\n\nFrom what I understand this is a relatively new approach to ML? Has anyone heard of this? I was hoping to get a general feel for what people in the industry believe for the perspectives of this approach. If you're curious, here's an [implementation](https://github.com/stassa/louise) of MIL.","link":"https://www.reddit.com/r/MachineLearning/comments/11w4kqd/r_what_do_we_think_about_metainterpretive_learning/","created":"2023-03-20","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[R] What do we think about Meta-Interpretive Learning? Came across this concept, Meta-Interpretive Learning (MIL) developed by Muggleton, Patsantzis, et al.\n\n* [https://arxiv.org/pdf/2101.05050.pdf](https://arxiv.org/pdf/2101.05050.pdf)\n* [https://arxiv.org/pdf/2106.07464.pdf](https://arxiv.org/pdf/2106.07464.pdf)\n* [Presentation](https://www.youtube.com/watch?v=73cBWmjlFLk)\n\nFrom what I understand this is a relatively new approach to ML? Has anyone heard of this? I was hoping to get a general feel for what people in the industry believe for the perspectives of this approach. If you're curious, here's an [implementation](https://github.com/stassa/louise) of MIL.","classes":{"dataset":0.4567101002}}
{"title":"[D] Totally Open Alternatives to ChatGPT","description":"I have migrated this to GitHub for easy contribution: https://github.com/nichtdax/awesome-totally-open-chatgpt\n\nBy alternative, I mean projects feature different language model for chat system.\nI do **not** count alternative **frontend** projects because they just call the API from OpenAI. \nI do **not** consider alternative **transformer decoder** to GPT 3.5 either because the training data of them are (mostly) not for chat system.\n\nTags:\n\n-   B: bare (no data, no model's weight, no chat system)\n-   F: full (yes data, yes model's weight, yes chat system including TUI and GUI)\n\n| Project                                                                               | Description                                                                                                                                                                                                                                                                                                                                                                               | Tags |\n| ------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---- |\n| [lucidrains/PaLM-rlhf-pytorch](https://github.com/lucidrains/PaLM-rlhf-pytorch)       | Implementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Basically ChatGPT but with PaLM                                                                                                                                                                                                                                                      | B    |\n| [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit)       | OpenChatKit provides a powerful, open-source base to create both specialized and general purpose chatbots for various applications. [Demo](https://huggingface.co/spaces/togethercomputer/OpenChatKit)                                                                                                                                                                                    | F    |\n| [oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) | A gradio web UI for running Large Language Models like GPT-J 6B, OPT, GALACTICA, LLaMA, and Pygmalion.                                                                                                                                                                                                                                                                                    | F    |\n| [KoboldAI/KoboldAI-Client](https://github.com/KoboldAI/KoboldAI-Client)               | This is a browser-based front-end for AI-assisted writing with multiple local &amp; remote AI models. It offers the standard array of tools, including Memory, Author's Note, World Info, Save &amp; Load, adjustable AI settings, formatting options, and the ability to import existing AI Dungeon adventures. You can also turn on Adventure mode and play the game like AI Dungeon Unleashed. | F    |\n| [LAION-AI/Open-Assistant/](https://github.com/LAION-AI/Open-Assistant/)               | OpenAssistant is a chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so.                                                                                                                                                                                                                                     | F    |","link":"https://www.reddit.com/r/MachineLearning/comments/11uk8ti/d_totally_open_alternatives_to_chatgpt/","created":"2023-03-18","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":74},"text":"[D] Totally Open Alternatives to ChatGPT I have migrated this to GitHub for easy contribution: https://github.com/nichtdax/awesome-totally-open-chatgpt\n\nBy alternative, I mean projects feature different language model for chat system.\nI do **not** count alternative **frontend** projects because they just call the API from OpenAI. \nI do **not** consider alternative **transformer decoder** to GPT 3.5 either because the training data of them are (mostly) not for chat system.\n\nTags:\n\n-   B: bare (no data, no model's weight, no chat system)\n-   F: full (yes data, yes model's weight, yes chat system including TUI and GUI)\n\n| Project                                                                               | Description                                                                                                                                                                                                                                                                                                                                                                               | Tags |\n| ------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---- |\n| [lucidrains/PaLM-rlhf-pytorch](https://github.com/lucidrains/PaLM-rlhf-pytorch)       | Implementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Basically ChatGPT but with PaLM                                                                                                                                                                                                                                                      | B    |\n| [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit)       | OpenChatKit provides a powerful, open-source base to create both specialized and general purpose chatbots for various applications. [Demo](https://huggingface.co/spaces/togethercomputer/OpenChatKit)                                                                                                                                                                                    | F    |\n| [oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) | A gradio web UI for running Large Language Models like GPT-J 6B, OPT, GALACTICA, LLaMA, and Pygmalion.                                                                                                                                                                                                                                                                                    | F    |\n| [KoboldAI/KoboldAI-Client](https://github.com/KoboldAI/KoboldAI-Client)               | This is a browser-based front-end for AI-assisted writing with multiple local &amp; remote AI models. It offers the standard array of tools, including Memory, Author's Note, World Info, Save &amp; Load, adjustable AI settings, formatting options, and the ability to import existing AI Dungeon adventures. You can also turn on Adventure mode and play the game like AI Dungeon Unleashed. | F    |\n| [LAION-AI/Open-Assistant/](https://github.com/LAION-AI/Open-Assistant/)               | OpenAssistant is a chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so.                                                                                                                                                                                                                                     | F    |","classes":{"dataset":0.3086502552}}
{"title":"[P] Semantic Feature Embeddings from Hashtags","description":"I want to get semantic feature embeddings given a list of hashtags, to find similar users in social media data (using cosine similarity) or even do zero shot classification. I thought of using a BERT-like pretrained encoder language model, but I guess this is not optimal because grammar and word order do not matter in this case.\n\nDo you know such pretrained embedding model or have any tips, how to train such a model in an unsupervised way( I already have millions of posts containing hashtags)?","link":"https://www.reddit.com/r/MachineLearning/comments/11vqfow/p_semantic_feature_embeddings_from_hashtags/","created":"2023-03-19","tags":["machinelearning","ml","reddit"],"meta":{"num_comments":0},"text":"[P] Semantic Feature Embeddings from Hashtags I want to get semantic feature embeddings given a list of hashtags, to find similar users in social media data (using cosine similarity) or even do zero shot classification. I thought of using a BERT-like pretrained encoder language model, but I guess this is not optimal because grammar and word order do not matter in this case.\n\nDo you know such pretrained embedding model or have any tips, how to train such a model in an unsupervised way( I already have millions of posts containing hashtags)?","classes":{"dataset":0.0370081179}}
{"title":"New to Headline Quality subfield -- what are some good models that are readily customizable for domain nomenclature specificity?","description":"Due to need at work, I've been plugged into a project in the Headline Quality NLP subarea despite my complete inexperience in NLP. The project involves assessing headline/title quality of some pharmaceutical reports and estimating semantic divergence between headline and articles. I'm working through some papers like [this one by Omidvar et al.](https://arxiv.org/abs/1911.11139), but don't need state of the art at the moment, just some quick and dirty initial results, and am looking for some input about types of models I should look at for getting started on limited computational resources (I'll only have access to one GPU at most). I'm particularly interested in models I can flexibly modify/hardcode to account for corporate and pharmaceutical nomenclature and terminology. Is this a problem I should still throw transformer models at, even with a dearth of GPU resources, or do any older, simpler models come to mind? Thank you for your time and help!","link":"https://www.reddit.com/r/LanguageTechnology/comments/11w7mh3/new_to_headline_quality_subfield_what_are_some/","created":"2023-03-20","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0},"text":"New to Headline Quality subfield -- what are some good models that are readily customizable for domain nomenclature specificity? Due to need at work, I've been plugged into a project in the Headline Quality NLP subarea despite my complete inexperience in NLP. The project involves assessing headline/title quality of some pharmaceutical reports and estimating semantic divergence between headline and articles. I'm working through some papers like [this one by Omidvar et al.](https://arxiv.org/abs/1911.11139), but don't need state of the art at the moment, just some quick and dirty initial results, and am looking for some input about types of models I should look at for getting started on limited computational resources (I'll only have access to one GPU at most). I'm particularly interested in models I can flexibly modify/hardcode to account for corporate and pharmaceutical nomenclature and terminology. Is this a problem I should still throw transformer models at, even with a dearth of GPU resources, or do any older, simpler models come to mind? Thank you for your time and help!","classes":{"dataset":0.4771234393}}
{"title":"Are pre-trained word embeddings (word2vec, glove, fasttext) obsolete now? given wide use of pre-trained languages models like bert etc","description":"","link":"https://www.reddit.com/r/LanguageTechnology/comments/11vav4y/are_pretrained_word_embeddings_word2vec_glove/","created":"2023-03-19","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":20},"text":"Are pre-trained word embeddings (word2vec, glove, fasttext) obsolete now? given wide use of pre-trained languages models like bert etc ","classes":{"dataset":0.1066711992}}
{"title":"Wanna team-up for Quantum NLP projects?","description":"I recently started reading about Quantum NLP. A very experimental and new field in Natural Language Processing. There are only a handful or research papers out there to aid in the knowledge of Quantum NLP, even universities such as MIT, Harvard and Stanford aren't capable or fully understand Quantum NLP yet. Only a few Quantum Computing research labs have the surface-intermediate understanding of Quantum NLP such as Cambridge Quantum.   \n\n\nI have read some of the most recent and important Quantum NLP papers and used **lambeq the only python library capable enough to do Quantum NLP.** Fast forward, I have implemented a basic Quantum NLP project where I classify sentences using Quantum NLP. \n\nI couldn't find many people who are interested in Quantum NLP, that's why, I was looking forward if someone is interested in Quantum NLP in this thread and has previous experience working with NLP itself then we can make a small team and study more advanced topics on Quantum NLP and do cool projects in our pastime. \n\n**GitHub repo link:** [https://github.com/sleepingcat4/Quantum-NLP](https://github.com/sleepingcat4/Quantum-NLP)  \n\n\nIf you're interested in teaming-up, kindly send me a message on **reddit or discord: sleeping\\_cat4#8182**","link":"https://www.reddit.com/r/LanguageTechnology/comments/11uia4r/wanna_teamup_for_quantum_nlp_projects/","created":"2023-03-18","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":17},"text":"Wanna team-up for Quantum NLP projects? I recently started reading about Quantum NLP. A very experimental and new field in Natural Language Processing. There are only a handful or research papers out there to aid in the knowledge of Quantum NLP, even universities such as MIT, Harvard and Stanford aren't capable or fully understand Quantum NLP yet. Only a few Quantum Computing research labs have the surface-intermediate understanding of Quantum NLP such as Cambridge Quantum.   \n\n\nI have read some of the most recent and important Quantum NLP papers and used **lambeq the only python library capable enough to do Quantum NLP.** Fast forward, I have implemented a basic Quantum NLP project where I classify sentences using Quantum NLP. \n\nI couldn't find many people who are interested in Quantum NLP, that's why, I was looking forward if someone is interested in Quantum NLP in this thread and has previous experience working with NLP itself then we can make a small team and study more advanced topics on Quantum NLP and do cool projects in our pastime. \n\n**GitHub repo link:** [https://github.com/sleepingcat4/Quantum-NLP](https://github.com/sleepingcat4/Quantum-NLP)  \n\n\nIf you're interested in teaming-up, kindly send me a message on **reddit or discord: sleeping\\_cat4#8182**","classes":{"dataset":0.203396678}}
{"title":"New NLP Game Design potentials","description":"Hello I wanted to share some ideas! I believe some of these ideas to be legit avenues for making games with natural language processing, enabled by the power of GPT-4, and I really want to inspire more people down the line! Here are some apps you could make with the openAI API that leverage a whole new degree of responsiveness:  \n\n\n1. A card game where combat is settled by the names of the cards rather than descriptions or card text, using brief but accurate battle simulations! Pair nouns and adjectives, or even fuse cards to make novel new concepts! Who wins, Saitama or Goku? It takes on a whole new level of fairness and intuition when you let the AI take control!\n2. API calls could be used to procedurally generate enemies or catchable monsters in a roguelike! You could provide an example of a json stat sheet and go from there\n3. Considering json, you could (maybe) create a fighting game with MUGEN that merges calls between openai and an art generator, and create the ultimate platform fighter where players type in the name of their character instead of choosing from a select screen! (although generating move sprites is likely gatekept by a few things still....)  \n\n\nThank you for reading! please considering sharing some of these ideas or trying them out yourself, especially the first one I think it quite accessible. Imagine a deck building game where your card database list is the dictionary :)","link":"https://www.reddit.com/r/LanguageTechnology/comments/11u7lt9/new_nlp_game_design_potentials/","created":"2023-03-17","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":0},"text":"New NLP Game Design potentials Hello I wanted to share some ideas! I believe some of these ideas to be legit avenues for making games with natural language processing, enabled by the power of GPT-4, and I really want to inspire more people down the line! Here are some apps you could make with the openAI API that leverage a whole new degree of responsiveness:  \n\n\n1. A card game where combat is settled by the names of the cards rather than descriptions or card text, using brief but accurate battle simulations! Pair nouns and adjectives, or even fuse cards to make novel new concepts! Who wins, Saitama or Goku? It takes on a whole new level of fairness and intuition when you let the AI take control!\n2. API calls could be used to procedurally generate enemies or catchable monsters in a roguelike! You could provide an example of a json stat sheet and go from there\n3. Considering json, you could (maybe) create a fighting game with MUGEN that merges calls between openai and an art generator, and create the ultimate platform fighter where players type in the name of their character instead of choosing from a select screen! (although generating move sprites is likely gatekept by a few things still....)  \n\n\nThank you for reading! please considering sharing some of these ideas or trying them out yourself, especially the first one I think it quite accessible. Imagine a deck building game where your card database list is the dictionary :)","classes":{"dataset":0.5250192285}}
{"title":"Fine-tuning BERT for generating short story, how to do it?","description":"","link":"https://www.reddit.com/r/LanguageTechnology/comments/11tqy4f/finetuning_bert_for_generating_short_story_how_to/","created":"2023-03-17","tags":["ml","reddit","languagetechnology"],"meta":{"num_comments":6},"text":"Fine-tuning BERT for generating short story, how to do it? ","classes":{"dataset":0.3098055422}}
{"title":"On Creating a Comprehensive Food Database","description":"Studies with the primary aim of addressing eating disorders focus on assessing the nutrient content of food items with an exclusive focus on caloric intake. There are two primary impediments that can be noted in these studies. The first of these relates to the fact that caloric intake of each food item is calculated from an existing database. The second concerns the scientific significance of caloric intake used as the single measure of nutrient content. By requiring an existing database, researchers are forced to find some source of a comprehensive set of food items as well as their respective nutrients. This search alone is a difficult task, and if completed often leads to the requirement of a paid API service. These services are expensive and non-customizable, taking away funding that could be aimed at other parts of the study only to give an unwieldy database that can not be modified or contributed to. In this work, we introduce a new rendition of the USDA's food database that includes both foods found in grocery stores and those found in restaurants or fast food places. At the moment, we have accumulated roughly 1.5 million food entries consisting of approximately 18,000 brands and 100 restaurants in the United States. These foods also have an abundance of nutrient data associated with them, from the caloric amount to saturated fat levels. The data is stored in MySQL format and is spread among five major tables. We have also procured images for theses foods entries when available, and have included all of our data and program scripts in an open source repository.","link":"http://arxiv.org/abs/2301.10649v1","created":"2023-01-25","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"On Creating a Comprehensive Food Database Studies with the primary aim of addressing eating disorders focus on assessing the nutrient content of food items with an exclusive focus on caloric intake. There are two primary impediments that can be noted in these studies. The first of these relates to the fact that caloric intake of each food item is calculated from an existing database. The second concerns the scientific significance of caloric intake used as the single measure of nutrient content. By requiring an existing database, researchers are forced to find some source of a comprehensive set of food items as well as their respective nutrients. This search alone is a difficult task, and if completed often leads to the requirement of a paid API service. These services are expensive and non-customizable, taking away funding that could be aimed at other parts of the study only to give an unwieldy database that can not be modified or contributed to. In this work, we introduce a new rendition of the USDA's food database that includes both foods found in grocery stores and those found in restaurants or fast food places. At the moment, we have accumulated roughly 1.5 million food entries consisting of approximately 18,000 brands and 100 restaurants in the United States. These foods also have an abundance of nutrient data associated with them, from the caloric amount to saturated fat levels. The data is stored in MySQL format and is spread among five major tables. We have also procured images for theses foods entries when available, and have included all of our data and program scripts in an open source repository.","classes":{"dataset":0.0748401582}}
{"title":"A database of basic numerical invariants of Hilbert modular surfaces","description":"We describe algorithms for computing geometric invariants for Hilbert modular surfaces, and we report on their implementation.","link":"http://arxiv.org/abs/2301.10302v1","created":"2023-01-24","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A database of basic numerical invariants of Hilbert modular surfaces We describe algorithms for computing geometric invariants for Hilbert modular surfaces, and we report on their implementation.","classes":{"dataset":0.9571155906}}
{"title":"Beware of the Unexpected: Bimodal Taint Analysis","description":"Static analysis is a powerful tool for detecting security vulnerabilities and other programming problems. Global taint tracking, in particular, can spot vulnerabilities arising from complicated data flow across multiple functions. However, precisely identifying which flows are problematic is challenging, and sometimes depends on factors beyond the reach of pure program analysis, such as conventions and informal knowledge. For example, learning that a parameter \"name\" of an API function \"locale\" ends up in a file path is surprising and potentially problematic. In contrast, it would be completely unsurprising to find that a parameter \"command\" passed to an API function \"execaCommand\" is eventually interpreted as part of an operating-system command. This paper presents Fluffy, a bimodal taint analysis that combines static analysis, which reasons about data flow, with machine learning, which probabilistically determines which flows are potentially problematic. The key idea is to let machine learning models predict from natural language information involved in a taint flow, such as API names, whether the flow is expected or unexpected, and to inform developers only about the latter. We present a general framework and instantiate it with four learned models, which offer different trade-offs between the need to annotate training data and the accuracy of predictions. We implement Fluffy on top of the CodeQL analysis framework and apply it to 250K JavaScript projects. Evaluating on five common vulnerability types, we find that Fluffy achieves an F1 score of 0.85 or more on four of them across a variety of datasets.","link":"http://arxiv.org/abs/2301.10545v1","created":"2023-01-25","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Beware of the Unexpected: Bimodal Taint Analysis Static analysis is a powerful tool for detecting security vulnerabilities and other programming problems. Global taint tracking, in particular, can spot vulnerabilities arising from complicated data flow across multiple functions. However, precisely identifying which flows are problematic is challenging, and sometimes depends on factors beyond the reach of pure program analysis, such as conventions and informal knowledge. For example, learning that a parameter \"name\" of an API function \"locale\" ends up in a file path is surprising and potentially problematic. In contrast, it would be completely unsurprising to find that a parameter \"command\" passed to an API function \"execaCommand\" is eventually interpreted as part of an operating-system command. This paper presents Fluffy, a bimodal taint analysis that combines static analysis, which reasons about data flow, with machine learning, which probabilistically determines which flows are potentially problematic. The key idea is to let machine learning models predict from natural language information involved in a taint flow, such as API names, whether the flow is expected or unexpected, and to inform developers only about the latter. We present a general framework and instantiate it with four learned models, which offer different trade-offs between the need to annotate training data and the accuracy of predictions. We implement Fluffy on top of the CodeQL analysis framework and apply it to 250K JavaScript projects. Evaluating on five common vulnerability types, we find that Fluffy achieves an F1 score of 0.85 or more on four of them across a variety of datasets.","classes":{"dataset":0.0194189493}}
{"title":"A Watermark for Large Language Models","description":"Potential harms of large language models can be mitigated by watermarking model output, i.e., embedding signals into generated text that are invisible to humans but algorithmically detectable from a short span of tokens. We propose a watermarking framework for proprietary language models. The watermark can be embedded with negligible impact on text quality, and can be detected using an efficient open-source algorithm without access to the language model API or parameters. The watermark works by selecting a randomized set of whitelist tokens before a word is generated, and then softly promoting use of whitelist tokens during sampling. We propose a statistical test for detecting the watermark with interpretable p-values, and derive an information-theoretic framework for analyzing the sensitivity of the watermark. We test the watermark using a multi-billion parameter model from the Open Pretrained Transformer (OPT) family, and discuss robustness and security.","link":"http://arxiv.org/abs/2301.10226v1","created":"2023-01-24","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"A Watermark for Large Language Models Potential harms of large language models can be mitigated by watermarking model output, i.e., embedding signals into generated text that are invisible to humans but algorithmically detectable from a short span of tokens. We propose a watermarking framework for proprietary language models. The watermark can be embedded with negligible impact on text quality, and can be detected using an efficient open-source algorithm without access to the language model API or parameters. The watermark works by selecting a randomized set of whitelist tokens before a word is generated, and then softly promoting use of whitelist tokens during sampling. We propose a statistical test for detecting the watermark with interpretable p-values, and derive an information-theoretic framework for analyzing the sensitivity of the watermark. We test the watermark using a multi-billion parameter model from the Open Pretrained Transformer (OPT) family, and discuss robustness and security.","classes":{"dataset":0.0513756052}}
{"title":"Membership Inference of Diffusion Models","description":"Recent years have witnessed the tremendous success of diffusion models in data synthesis. However, when diffusion models are applied to sensitive data, they also give rise to severe privacy concerns. In this paper, we systematically present the first study about membership inference attacks against diffusion models, which aims to infer whether a sample was used to train the model. Two attack methods are proposed, namely loss-based and likelihood-based attacks. Our attack methods are evaluated on several state-of-the-art diffusion models, over different datasets in relation to privacy-sensitive data. Extensive experimental evaluations show that our attacks can achieve remarkable performance. Furthermore, we exhaustively investigate various factors which can affect attack performance. Finally, we also evaluate the performance of our attack methods on diffusion models trained with differential privacy.","link":"http://arxiv.org/abs/2301.09956v1","created":"2023-01-24","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Membership Inference of Diffusion Models Recent years have witnessed the tremendous success of diffusion models in data synthesis. However, when diffusion models are applied to sensitive data, they also give rise to severe privacy concerns. In this paper, we systematically present the first study about membership inference attacks against diffusion models, which aims to infer whether a sample was used to train the model. Two attack methods are proposed, namely loss-based and likelihood-based attacks. Our attack methods are evaluated on several state-of-the-art diffusion models, over different datasets in relation to privacy-sensitive data. Extensive experimental evaluations show that our attacks can achieve remarkable performance. Furthermore, we exhaustively investigate various factors which can affect attack performance. Finally, we also evaluate the performance of our attack methods on diffusion models trained with differential privacy.","classes":{"dataset":0.0035509411}}
{"title":"Heterogeneous Domain Adaptation for IoT Intrusion Detection: A Geometric Graph Alignment Approach","description":"Data scarcity hinders the usability of data-dependent algorithms when tackling IoT intrusion detection (IID). To address this, we utilise the data rich network intrusion detection (NID) domain to facilitate more accurate intrusion detection for IID domains. In this paper, a Geometric Graph Alignment (GGA) approach is leveraged to mask the geometric heterogeneities between domains for better intrusion knowledge transfer. Specifically, each intrusion domain is formulated as a graph where vertices and edges represent intrusion categories and category-wise interrelationships, respectively. The overall shape is preserved via a confused discriminator incapable to identify adjacency matrices between different intrusion domain graphs. A rotation avoidance mechanism and a centre point matching mechanism is used to avoid graph misalignment due to rotation and symmetry, respectively. Besides, category-wise semantic knowledge is transferred to act as vertex-level alignment. To exploit the target data, a pseudo-label election mechanism that jointly considers network prediction, geometric property and neighbourhood information is used to produce fine-grained pseudo-label assignment. Upon aligning the intrusion graphs geometrically from different granularities, the transferred intrusion knowledge can boost IID performance. Comprehensive experiments on several intrusion datasets demonstrate state-of-the-art performance of the GGA approach and validate the usefulness of GGA constituting components.","link":"http://arxiv.org/abs/2301.09801v1","created":"2023-01-24","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Heterogeneous Domain Adaptation for IoT Intrusion Detection: A Geometric Graph Alignment Approach Data scarcity hinders the usability of data-dependent algorithms when tackling IoT intrusion detection (IID). To address this, we utilise the data rich network intrusion detection (NID) domain to facilitate more accurate intrusion detection for IID domains. In this paper, a Geometric Graph Alignment (GGA) approach is leveraged to mask the geometric heterogeneities between domains for better intrusion knowledge transfer. Specifically, each intrusion domain is formulated as a graph where vertices and edges represent intrusion categories and category-wise interrelationships, respectively. The overall shape is preserved via a confused discriminator incapable to identify adjacency matrices between different intrusion domain graphs. A rotation avoidance mechanism and a centre point matching mechanism is used to avoid graph misalignment due to rotation and symmetry, respectively. Besides, category-wise semantic knowledge is transferred to act as vertex-level alignment. To exploit the target data, a pseudo-label election mechanism that jointly considers network prediction, geometric property and neighbourhood information is used to produce fine-grained pseudo-label assignment. Upon aligning the intrusion graphs geometrically from different granularities, the transferred intrusion knowledge can boost IID performance. Comprehensive experiments on several intrusion datasets demonstrate state-of-the-art performance of the GGA approach and validate the usefulness of GGA constituting components.","classes":{"dataset":0.0280501712}}
{"title":"Backdoor Attacks in Peer-to-Peer Federated Learning","description":"We study backdoor attacks in peer-to-peer federated learning systems on different graph topologies and datasets. We show that only 5% attacker nodes are sufficient to perform a backdoor attack with 42% attack success without decreasing the accuracy on clean data by more than 2%. We also demonstrate that the attack can be amplified by the attacker crashing a small number of nodes. We evaluate defenses proposed in the context of centralized federated learning and show they are ineffective in peer-to-peer settings. Finally, we propose a defense that mitigates the attacks by applying different clipping norms to the model updates received from peers and local model trained by a node.","link":"http://arxiv.org/abs/2301.09732v1","created":"2023-01-23","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Backdoor Attacks in Peer-to-Peer Federated Learning We study backdoor attacks in peer-to-peer federated learning systems on different graph topologies and datasets. We show that only 5% attacker nodes are sufficient to perform a backdoor attack with 42% attack success without decreasing the accuracy on clean data by more than 2%. We also demonstrate that the attack can be amplified by the attacker crashing a small number of nodes. We evaluate defenses proposed in the context of centralized federated learning and show they are ineffective in peer-to-peer settings. Finally, we propose a defense that mitigates the attacks by applying different clipping norms to the model updates received from peers and local model trained by a node.","classes":{"dataset":0.0063553415}}
{"title":"A Framework for Evaluating the Impact of Food Security Scenarios","description":"This study proposes an approach for predicting the impacts of scenarios on food security and demonstrates its application in a case study. The approach involves two main steps: (1) scenario definition, in which the end user specifies the assumptions and impacts of the scenario using a scenario template, and (2) scenario evaluation, in which a Vector Autoregression (VAR) model is used in combination with Monte Carlo simulation to generate predictions for the impacts of the scenario based on the defined assumptions and impacts. The case study is based on a proprietary time series food security database created using data from the Food and Agriculture Organization of the United Nations (FAOSTAT), the World Bank, and the United States Department of Agriculture (USDA). The database contains a wide range of data on various indicators of food security, such as production, trade, consumption, prices, availability, access, and nutritional value. The results show that the proposed approach can be used to predict the potential impacts of scenarios on food security and that the proprietary time series food security database can be used to support this approach. The study provides specific insights on how this approach can inform decision-making processes related to food security such as food prices and availability in the case study region.","link":"http://arxiv.org/abs/2301.09320v2","created":"2023-01-23","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"A Framework for Evaluating the Impact of Food Security Scenarios This study proposes an approach for predicting the impacts of scenarios on food security and demonstrates its application in a case study. The approach involves two main steps: (1) scenario definition, in which the end user specifies the assumptions and impacts of the scenario using a scenario template, and (2) scenario evaluation, in which a Vector Autoregression (VAR) model is used in combination with Monte Carlo simulation to generate predictions for the impacts of the scenario based on the defined assumptions and impacts. The case study is based on a proprietary time series food security database created using data from the Food and Agriculture Organization of the United Nations (FAOSTAT), the World Bank, and the United States Department of Agriculture (USDA). The database contains a wide range of data on various indicators of food security, such as production, trade, consumption, prices, availability, access, and nutritional value. The results show that the proposed approach can be used to predict the potential impacts of scenarios on food security and that the proprietary time series food security database can be used to support this approach. The study provides specific insights on how this approach can inform decision-making processes related to food security such as food prices and availability in the case study region.","classes":{"dataset":0.0609923154}}
{"title":"Combined Use of Federated Learning and Image Encryption for Privacy-Preserving Image Classification with Vision Transformer","description":"In recent years, privacy-preserving methods for deep learning have become an urgent problem. Accordingly, we propose the combined use of federated learning (FL) and encrypted images for privacy-preserving image classification under the use of the vision transformer (ViT). The proposed method allows us not only to train models over multiple participants without directly sharing their raw data but to also protect the privacy of test (query) images for the first time. In addition, it can also maintain the same accuracy as normally trained models. In an experiment, the proposed method was demonstrated to well work without any performance degradation on the CIFAR-10 and CIFAR-100 datasets.","link":"http://arxiv.org/abs/2301.09255v1","created":"2023-01-23","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Combined Use of Federated Learning and Image Encryption for Privacy-Preserving Image Classification with Vision Transformer In recent years, privacy-preserving methods for deep learning have become an urgent problem. Accordingly, we propose the combined use of federated learning (FL) and encrypted images for privacy-preserving image classification under the use of the vision transformer (ViT). The proposed method allows us not only to train models over multiple participants without directly sharing their raw data but to also protect the privacy of test (query) images for the first time. In addition, it can also maintain the same accuracy as normally trained models. In an experiment, the proposed method was demonstrated to well work without any performance degradation on the CIFAR-10 and CIFAR-100 datasets.","classes":{"dataset":0.0242549926}}
{"title":"Relaxed Models for Adversarial Streaming: The Advice Model and the Bounded Interruptions Model","description":"Streaming algorithms are typically analyzed in the oblivious setting, where we assume that the input stream is fixed in advance. Recently, there is a growing interest in designing adversarially robust streaming algorithms that must maintain utility even when the input stream is chosen adaptively and adversarially as the execution progresses. While several fascinating results are known for the adversarial setting, in general, it comes at a very high cost in terms of the required space. Motivated by this, in this work we set out to explore intermediate models that allow us to interpolate between the oblivious and the adversarial models. Specifically, we put forward the following two models:   (1) *The advice model*, in which the streaming algorithm may occasionally ask for one bit of advice.   (2) *The bounded interruptions model*, in which we assume that the adversary is only partially adaptive.   We present both positive and negative results for each of these two models. In particular, we present generic reductions from each of these models to the oblivious model. This allows us to design robust algorithms with significantly improved space complexity compared to what is known in the plain adversarial model.","link":"http://arxiv.org/abs/2301.09203v1","created":"2023-01-22","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Relaxed Models for Adversarial Streaming: The Advice Model and the Bounded Interruptions Model Streaming algorithms are typically analyzed in the oblivious setting, where we assume that the input stream is fixed in advance. Recently, there is a growing interest in designing adversarially robust streaming algorithms that must maintain utility even when the input stream is chosen adaptively and adversarially as the execution progresses. While several fascinating results are known for the adversarial setting, in general, it comes at a very high cost in terms of the required space. Motivated by this, in this work we set out to explore intermediate models that allow us to interpolate between the oblivious and the adversarial models. Specifically, we put forward the following two models:   (1) *The advice model*, in which the streaming algorithm may occasionally ask for one bit of advice.   (2) *The bounded interruptions model*, in which we assume that the adversary is only partially adaptive.   We present both positive and negative results for each of these two models. In particular, we present generic reductions from each of these models to the oblivious model. This allows us to design robust algorithms with significantly improved space complexity compared to what is known in the plain adversarial model.","classes":{"dataset":0.028362548}}
{"title":"Is Signed Message Essential for Graph Neural Networks?","description":"Message-passing Graph Neural Networks (GNNs), which collect information from adjacent nodes, achieve satisfying results on homophilic graphs. However, their performances are dismal in heterophilous graphs, and many researchers have proposed a plethora of schemes to solve this problem. Especially, flipping the sign of edges is rooted in a strong theoretical foundation, and attains significant performance enhancements. Nonetheless, previous analyses assume a binary class scenario and they may suffer from confined applicability. This paper extends the prior understandings to multi-class scenarios and points out two drawbacks: (1) the sign of multi-hop neighbors depends on the message propagation paths and may incur inconsistency, (2) it also increases the prediction uncertainty (e.g., conflict evidence) which can impede the stability of the algorithm. Based on the theoretical understanding, we introduce a novel strategy that is applicable to multi-class graphs. The proposed scheme combines confidence calibration to secure robustness while reducing uncertainty. We show the efficacy of our theorem through extensive experiments on six benchmark graph datasets.","link":"http://arxiv.org/abs/2301.08918v1","created":"2023-01-21","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Is Signed Message Essential for Graph Neural Networks? Message-passing Graph Neural Networks (GNNs), which collect information from adjacent nodes, achieve satisfying results on homophilic graphs. However, their performances are dismal in heterophilous graphs, and many researchers have proposed a plethora of schemes to solve this problem. Especially, flipping the sign of edges is rooted in a strong theoretical foundation, and attains significant performance enhancements. Nonetheless, previous analyses assume a binary class scenario and they may suffer from confined applicability. This paper extends the prior understandings to multi-class scenarios and points out two drawbacks: (1) the sign of multi-hop neighbors depends on the message propagation paths and may incur inconsistency, (2) it also increases the prediction uncertainty (e.g., conflict evidence) which can impede the stability of the algorithm. Based on the theoretical understanding, we introduce a novel strategy that is applicable to multi-class graphs. The proposed scheme combines confidence calibration to secure robustness while reducing uncertainty. We show the efficacy of our theorem through extensive experiments on six benchmark graph datasets.","classes":{"dataset":0.9728255868}}
{"title":"Split Ways: Privacy-Preserving Training of Encrypted Data Using Split Learning","description":"Split Learning (SL) is a new collaborative learning technique that allows participants, e.g. a client and a server, to train machine learning models without the client sharing raw data. In this setting, the client initially applies its part of the machine learning model on the raw data to generate activation maps and then sends them to the server to continue the training process. Previous works in the field demonstrated that reconstructing activation maps could result in privacy leakage of client data. In addition to that, existing mitigation techniques that overcome the privacy leakage of SL prove to be significantly worse in terms of accuracy. In this paper, we improve upon previous works by constructing a protocol based on U-shaped SL that can operate on homomorphically encrypted data. More precisely, in our approach, the client applies Homomorphic Encryption (HE) on the activation maps before sending them to the server, thus protecting user privacy. This is an important improvement that reduces privacy leakage in comparison to other SL-based works. Finally, our results show that, with the optimum set of parameters, training with HE data in the U-shaped SL setting only reduces accuracy by 2.65% compared to training on plaintext. In addition, raw training data privacy is preserved.","link":"http://arxiv.org/abs/2301.08778v1","created":"2023-01-20","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Split Ways: Privacy-Preserving Training of Encrypted Data Using Split Learning Split Learning (SL) is a new collaborative learning technique that allows participants, e.g. a client and a server, to train machine learning models without the client sharing raw data. In this setting, the client initially applies its part of the machine learning model on the raw data to generate activation maps and then sends them to the server to continue the training process. Previous works in the field demonstrated that reconstructing activation maps could result in privacy leakage of client data. In addition to that, existing mitigation techniques that overcome the privacy leakage of SL prove to be significantly worse in terms of accuracy. In this paper, we improve upon previous works by constructing a protocol based on U-shaped SL that can operate on homomorphically encrypted data. More precisely, in our approach, the client applies Homomorphic Encryption (HE) on the activation maps before sending them to the server, thus protecting user privacy. This is an important improvement that reduces privacy leakage in comparison to other SL-based works. Finally, our results show that, with the optimum set of parameters, training with HE data in the U-shaped SL setting only reduces accuracy by 2.65% compared to training on plaintext. In addition, raw training data privacy is preserved.","classes":{"dataset":0.020060204}}
{"title":"Which Features are Learned by CodeBert: An Empirical Study of the BERT-based Source Code Representation Learning","description":"The Bidirectional Encoder Representations from Transformers (BERT) were proposed in the natural language process (NLP) and shows promising results. Recently researchers applied the BERT to source-code representation learning and reported some good news on several downstream tasks. However, in this paper, we illustrated that current methods cannot effectively understand the logic of source codes. The representation of source code heavily relies on the programmer-defined variable and function names. We design and implement a set of experiments to demonstrate our conjecture and provide some insights for future works.","link":"http://arxiv.org/abs/2301.08427v1","created":"2023-01-20","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Which Features are Learned by CodeBert: An Empirical Study of the BERT-based Source Code Representation Learning The Bidirectional Encoder Representations from Transformers (BERT) were proposed in the natural language process (NLP) and shows promising results. Recently researchers applied the BERT to source-code representation learning and reported some good news on several downstream tasks. However, in this paper, we illustrated that current methods cannot effectively understand the logic of source codes. The representation of source code heavily relies on the programmer-defined variable and function names. We design and implement a set of experiments to demonstrate our conjecture and provide some insights for future works.","classes":{"dataset":0.0163757205}}
{"title":"Machine Learning-Based Secret Key Generation for IRS-assisted Multi-antenna Systems","description":"Physical-layer key generation (PKG) based on wireless channels is a lightweight technique to establish secure keys between legitimate communication nodes. Recently, intelligent reflecting surfaces (IRSs) have been leveraged to enhance the performance of PKG in terms of secret key rate (SKR), as it can reconfigure the wireless propagation environment and introduce more channel randomness. In this paper, we investigate an IRS-assisted PKG system, taking into account the channel spatial correlation at both the base station (BS) and the IRS. Based on the considered system model, the closed form expression of SKR is derived analytically. Aiming to maximize the SKR, a joint design problem of the BS precoding matrix and the IRS reflecting coefficient vector is formulated. To address this high-dimensional non-convex optimization problem, we propose a novel unsupervised deep neural network (DNN) based algorithm with a simple structure. Different from most previous works that adopt the iterative optimization to solve the problem, the proposed DNN based algorithm directly obtains the BS precoding and IRS phase shifts as the output of the DNN. Simulation results reveal that the proposed DNN-based algorithm outperforms the benchmark methods with regard to SKR.","link":"http://arxiv.org/abs/2301.08179v1","created":"2023-01-19","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Machine Learning-Based Secret Key Generation for IRS-assisted Multi-antenna Systems Physical-layer key generation (PKG) based on wireless channels is a lightweight technique to establish secure keys between legitimate communication nodes. Recently, intelligent reflecting surfaces (IRSs) have been leveraged to enhance the performance of PKG in terms of secret key rate (SKR), as it can reconfigure the wireless propagation environment and introduce more channel randomness. In this paper, we investigate an IRS-assisted PKG system, taking into account the channel spatial correlation at both the base station (BS) and the IRS. Based on the considered system model, the closed form expression of SKR is derived analytically. Aiming to maximize the SKR, a joint design problem of the BS precoding matrix and the IRS reflecting coefficient vector is formulated. To address this high-dimensional non-convex optimization problem, we propose a novel unsupervised deep neural network (DNN) based algorithm with a simple structure. Different from most previous works that adopt the iterative optimization to solve the problem, the proposed DNN based algorithm directly obtains the BS precoding and IRS phase shifts as the output of the DNN. Simulation results reveal that the proposed DNN-based algorithm outperforms the benchmark methods with regard to SKR.","classes":{"dataset":0.0158548299}}
{"title":"Spatio-Temporal Context Modeling for Road Obstacle Detection","description":"Road obstacle detection is an important problem for vehicle driving safety. In this paper, we aim to obtain robust road obstacle detection based on spatio-temporal context modeling. Firstly, a data-driven spatial context model of the driving scene is constructed with the layouts of the training data. Then, obstacles in the input image are detected via the state-of-the-art object detection algorithms, and the results are combined with the generated scene layout. In addition, to further improve the performance and robustness, temporal information in the image sequence is taken into consideration, and the optical flow is obtained in the vicinity of the detected objects to track the obstacles across neighboring frames. Qualitative and quantitative experiments were conducted on the Small Obstacle Detection (SOD) dataset and the Lost and Found dataset. The results indicate that our method with spatio-temporal context modeling is superior to existing methods for road obstacle detection.","link":"http://arxiv.org/abs/2301.07921v1","created":"2023-01-19","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Spatio-Temporal Context Modeling for Road Obstacle Detection Road obstacle detection is an important problem for vehicle driving safety. In this paper, we aim to obtain robust road obstacle detection based on spatio-temporal context modeling. Firstly, a data-driven spatial context model of the driving scene is constructed with the layouts of the training data. Then, obstacles in the input image are detected via the state-of-the-art object detection algorithms, and the results are combined with the generated scene layout. In addition, to further improve the performance and robustness, temporal information in the image sequence is taken into consideration, and the optical flow is obtained in the vicinity of the detected objects to track the obstacles across neighboring frames. Qualitative and quantitative experiments were conducted on the Small Obstacle Detection (SOD) dataset and the Lost and Found dataset. The results indicate that our method with spatio-temporal context modeling is superior to existing methods for road obstacle detection.","classes":{"dataset":0.0125451805}}
{"title":"Universal Neural-Cracking-Machines: Self-Configurable Password Models from Auxiliary Data","description":"We develop the first universal password model -- a password model that, once pre-trained, can automatically adapt to any password distribution. To achieve this result, the model does not need to access any plaintext passwords from the target set. Instead, it exploits users' auxiliary information, such as email addresses, as a proxy signal to predict the underlying target password distribution. The model uses deep learning to capture the correlation between the auxiliary data of a group of users (e.g., users of a web application) and their passwords. It then exploits those patterns to create a tailored password model for the target community at inference time. No further training steps, targeted data collection, or prior knowledge of the community's password distribution is required. Besides defining a new state-of-the-art for password strength estimation, our model enables any end-user (e.g., system administrators) to autonomously generate tailored password models for their systems without the often unworkable requirement of collecting suitable training data and fitting the underlying password model. Ultimately, our framework enables the democratization of well-calibrated password models to the community, addressing a major challenge in the deployment of password security solutions on a large scale.","link":"http://arxiv.org/abs/2301.07628v1","created":"2023-01-18","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Universal Neural-Cracking-Machines: Self-Configurable Password Models from Auxiliary Data We develop the first universal password model -- a password model that, once pre-trained, can automatically adapt to any password distribution. To achieve this result, the model does not need to access any plaintext passwords from the target set. Instead, it exploits users' auxiliary information, such as email addresses, as a proxy signal to predict the underlying target password distribution. The model uses deep learning to capture the correlation between the auxiliary data of a group of users (e.g., users of a web application) and their passwords. It then exploits those patterns to create a tailored password model for the target community at inference time. No further training steps, targeted data collection, or prior knowledge of the community's password distribution is required. Besides defining a new state-of-the-art for password strength estimation, our model enables any end-user (e.g., system administrators) to autonomously generate tailored password models for their systems without the often unworkable requirement of collecting suitable training data and fitting the underlying password model. Ultimately, our framework enables the democratization of well-calibrated password models to the community, addressing a major challenge in the deployment of password security solutions on a large scale.","classes":{"dataset":0.2687114775}}
{"title":"A Multi-Scale Framework for Out-of-Distribution Detection in Dermoscopic Images","description":"The automatic detection of skin diseases via dermoscopic images can improve the efficiency in diagnosis and help doctors make more accurate judgments. However, conventional skin disease recognition systems may produce high confidence for out-of-distribution (OOD) data, which may become a major security vulnerability in practical applications. In this paper, we propose a multi-scale detection framework to detect out-of-distribution skin disease image data to ensure the robustness of the system. Our framework extracts features from different layers of the neural network. In the early layers, rectified activation is used to make the output features closer to the well-behaved distribution, and then an one-class SVM is trained to detect OOD data; in the penultimate layer, an adapted Gram matrix is used to calculate the features after rectified activation, and finally the layer with the best performance is chosen to compute a normality score. Experiments show that the proposed framework achieves superior performance when compared with other state-of-the-art methods in the task of skin disease recognition.","link":"http://arxiv.org/abs/2301.07533v1","created":"2023-01-18","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"A Multi-Scale Framework for Out-of-Distribution Detection in Dermoscopic Images The automatic detection of skin diseases via dermoscopic images can improve the efficiency in diagnosis and help doctors make more accurate judgments. However, conventional skin disease recognition systems may produce high confidence for out-of-distribution (OOD) data, which may become a major security vulnerability in practical applications. In this paper, we propose a multi-scale detection framework to detect out-of-distribution skin disease image data to ensure the robustness of the system. Our framework extracts features from different layers of the neural network. In the early layers, rectified activation is used to make the output features closer to the well-behaved distribution, and then an one-class SVM is trained to detect OOD data; in the penultimate layer, an adapted Gram matrix is used to calculate the features after rectified activation, and finally the layer with the best performance is chosen to compute a normality score. Experiments show that the proposed framework achieves superior performance when compared with other state-of-the-art methods in the task of skin disease recognition.","classes":{"dataset":0.124486804}}
{"title":"Using Topological Data Analysis to classify Encrypted Bits","description":"We present a way to apply topological data analysis for classifying encrypted bits into distinct classes. Persistent homology is applied to generate topological features of a point cloud obtained from sets of encryptions. We see that this machine learning pipeline is able to classify our data successfully where classical models of machine learning fail to perform the task. We also see that this pipeline works as a dimensionality reduction method making this approach to classify encrypted data a realistic method to classify the given encryptioned bits.","link":"http://arxiv.org/abs/2301.07393v1","created":"2023-01-18","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Using Topological Data Analysis to classify Encrypted Bits We present a way to apply topological data analysis for classifying encrypted bits into distinct classes. Persistent homology is applied to generate topological features of a point cloud obtained from sets of encryptions. We see that this machine learning pipeline is able to classify our data successfully where classical models of machine learning fail to perform the task. We also see that this pipeline works as a dimensionality reduction method making this approach to classify encrypted data a realistic method to classify the given encryptioned bits.","classes":{"dataset":0.2542710602}}
{"title":"A Fast Algorithm for Adaptive Private Mean Estimation","description":"We design an $(\\varepsilon, \\delta)$-differentially private algorithm to estimate the mean of a $d$-variate distribution, with unknown covariance $\\Sigma$, that is adaptive to $\\Sigma$. To within polylogarithmic factors, the estimator achieves optimal rates of convergence with respect to the induced Mahalanobis norm $||\\cdot||_\\Sigma$, takes time $\\tilde{O}(n d^2)$ to compute, has near linear sample complexity for sub-Gaussian distributions, allows $\\Sigma$ to be degenerate or low rank, and adaptively extends beyond sub-Gaussianity. Prior to this work, other methods required exponential computation time or the superlinear scaling $n = \\Omega(d^{3/2})$ to achieve non-trivial error with respect to the norm $||\\cdot||_\\Sigma$.","link":"http://arxiv.org/abs/2301.07078v1","created":"2023-01-17","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"A Fast Algorithm for Adaptive Private Mean Estimation We design an $(\\varepsilon, \\delta)$-differentially private algorithm to estimate the mean of a $d$-variate distribution, with unknown covariance $\\Sigma$, that is adaptive to $\\Sigma$. To within polylogarithmic factors, the estimator achieves optimal rates of convergence with respect to the induced Mahalanobis norm $||\\cdot||_\\Sigma$, takes time $\\tilde{O}(n d^2)$ to compute, has near linear sample complexity for sub-Gaussian distributions, allows $\\Sigma$ to be degenerate or low rank, and adaptively extends beyond sub-Gaussianity. Prior to this work, other methods required exponential computation time or the superlinear scaling $n = \\Omega(d^{3/2})$ to achieve non-trivial error with respect to the norm $||\\cdot||_\\Sigma$.","classes":{"dataset":0.0393798202}}
{"title":"Negative Flux Aggregation to Estimate Feature Attributions","description":"There are increasing demands for understanding deep neural networks' (DNNs) behavior spurred by growing security and/or transparency concerns. Due to multi-layer nonlinearity of the deep neural network architectures, explaining DNN predictions still remains as an open problem, preventing us from gaining a deeper understanding of the mechanisms. To enhance the explainability of DNNs, we estimate the input feature's attributions to the prediction task using divergence and flux. Inspired by the divergence theorem in vector analysis, we develop a novel Negative Flux Aggregation (NeFLAG) formulation and an efficient approximation algorithm to estimate attribution map. Unlike the previous techniques, ours doesn't rely on fitting a surrogate model nor need any path integration of gradients. Both qualitative and quantitative experiments demonstrate a superior performance of NeFLAG in generating more faithful attribution maps than the competing methods.","link":"http://arxiv.org/abs/2301.06989v1","created":"2023-01-17","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Negative Flux Aggregation to Estimate Feature Attributions There are increasing demands for understanding deep neural networks' (DNNs) behavior spurred by growing security and/or transparency concerns. Due to multi-layer nonlinearity of the deep neural network architectures, explaining DNN predictions still remains as an open problem, preventing us from gaining a deeper understanding of the mechanisms. To enhance the explainability of DNNs, we estimate the input feature's attributions to the prediction task using divergence and flux. Inspired by the divergence theorem in vector analysis, we develop a novel Negative Flux Aggregation (NeFLAG) formulation and an efficient approximation algorithm to estimate attribution map. Unlike the previous techniques, ours doesn't rely on fitting a surrogate model nor need any path integration of gradients. Both qualitative and quantitative experiments demonstrate a superior performance of NeFLAG in generating more faithful attribution maps than the competing methods.","classes":{"dataset":0.105922021}}
{"title":"Utilization of Impedance Disparity Incurred from Switching Activities to Monitor and Characterize Firmware Activities","description":"The massive trend toward embedded systems introduces new security threats to prevent. Malicious firmware makes it easier to launch cyberattacks against embedded systems. Systems infected with malicious firmware maintain the appearance of normal firmware operation but execute undesirable activities, which is usually a security risk. Traditionally, cybercriminals use malicious firmware to develop possible back-doors for future attacks. Due to the restricted resources of embedded systems, it is difficult to thwart these attacks using the majority of contemporary standard security protocols. In addition, monitoring the firmware operations using existing side channels from outside the processing unit, such as electromagnetic radiation, necessitates a complicated hardware configuration and in-depth technical understanding. In this paper, we propose a physical side channel that is formed by detecting the overall impedance changes induced by the firmware actions of a central processing unit. To demonstrate how this side channel can be exploited for detecting firmware activities, we experimentally validate it using impedance measurements to distinguish between distinct firmware operations with an accuracy of greater than 90%. These findings are the product of classifiers that are trained via machine learning. The implementation of our proposed methodology also leaves room for the use of hardware authentication.","link":"http://arxiv.org/abs/2301.06799v1","created":"2023-01-17","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Utilization of Impedance Disparity Incurred from Switching Activities to Monitor and Characterize Firmware Activities The massive trend toward embedded systems introduces new security threats to prevent. Malicious firmware makes it easier to launch cyberattacks against embedded systems. Systems infected with malicious firmware maintain the appearance of normal firmware operation but execute undesirable activities, which is usually a security risk. Traditionally, cybercriminals use malicious firmware to develop possible back-doors for future attacks. Due to the restricted resources of embedded systems, it is difficult to thwart these attacks using the majority of contemporary standard security protocols. In addition, monitoring the firmware operations using existing side channels from outside the processing unit, such as electromagnetic radiation, necessitates a complicated hardware configuration and in-depth technical understanding. In this paper, we propose a physical side channel that is formed by detecting the overall impedance changes induced by the firmware actions of a central processing unit. To demonstrate how this side channel can be exploited for detecting firmware activities, we experimentally validate it using impedance measurements to distinguish between distinct firmware operations with an accuracy of greater than 90%. These findings are the product of classifiers that are trained via machine learning. The implementation of our proposed methodology also leaves room for the use of hardware authentication.","classes":{"dataset":0.1123719364}}
{"title":"Quantifying and Managing Impacts of Concept Drifts on IoT Traffic Inference in Residential ISP Networks","description":"Millions of vulnerable consumer IoT devices in home networks are the enabler for cyber crimes putting user privacy and Internet security at risk. Internet service providers (ISPs) are best poised to play key roles in mitigating risks by automatically inferring active IoT devices per household and notifying users of vulnerable ones. Developing a scalable inference method that can perform robustly across thousands of home networks is a non-trivial task. This paper focuses on the challenges of developing and applying data-driven inference models when labeled data of device behaviors is limited and the distribution of data changes (concept drift) across time and space domains. Our contributions are three-fold: (1) We collect and analyze network traffic of 24 types of consumer IoT devices from 12 real homes over six weeks to highlight the challenge of temporal and spatial concept drifts in network behavior of IoT devices; (2) We analyze the performance of two inference strategies, namely \"global inference\" (a model trained on a combined set of all labeled data from training homes) and \"contextualized inference\" (several models each trained on the labeled data from a training home) in the presence of concept drifts; and (3) To manage concept drifts, we develop a method that dynamically applies the ``closest'' model (from a set) to network traffic of unseen homes during the testing phase, yielding better performance in 20% of scenarios.","link":"http://arxiv.org/abs/2301.06695v1","created":"2023-01-17","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Quantifying and Managing Impacts of Concept Drifts on IoT Traffic Inference in Residential ISP Networks Millions of vulnerable consumer IoT devices in home networks are the enabler for cyber crimes putting user privacy and Internet security at risk. Internet service providers (ISPs) are best poised to play key roles in mitigating risks by automatically inferring active IoT devices per household and notifying users of vulnerable ones. Developing a scalable inference method that can perform robustly across thousands of home networks is a non-trivial task. This paper focuses on the challenges of developing and applying data-driven inference models when labeled data of device behaviors is limited and the distribution of data changes (concept drift) across time and space domains. Our contributions are three-fold: (1) We collect and analyze network traffic of 24 types of consumer IoT devices from 12 real homes over six weeks to highlight the challenge of temporal and spatial concept drifts in network behavior of IoT devices; (2) We analyze the performance of two inference strategies, namely \"global inference\" (a model trained on a combined set of all labeled data from training homes) and \"contextualized inference\" (several models each trained on the labeled data from a training home) in the presence of concept drifts; and (3) To manage concept drifts, we develop a method that dynamically applies the ``closest'' model (from a set) to network traffic of unseen homes during the testing phase, yielding better performance in 20% of scenarios.","classes":{"dataset":0.0701381639}}
{"title":"Enforcing Privacy in Distributed Learning with Performance Guarantees","description":"We study the privatization of distributed learning and optimization strategies. We focus on differential privacy schemes and study their effect on performance. We show that the popular additive random perturbation scheme degrades performance because it is not well-tuned to the graph structure. For this reason, we exploit two alternative graph-homomorphic constructions and show that they improve performance while guaranteeing privacy. Moreover, contrary to most earlier studies, the gradient of the risks is not assumed to be bounded (a condition that rarely holds in practice; e.g., quadratic risk). We avoid this condition and still devise a differentially private scheme with high probability. We examine optimization and learning scenarios and illustrate the theoretical findings through simulations.","link":"http://arxiv.org/abs/2301.06412v1","created":"2023-01-16","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Enforcing Privacy in Distributed Learning with Performance Guarantees We study the privatization of distributed learning and optimization strategies. We focus on differential privacy schemes and study their effect on performance. We show that the popular additive random perturbation scheme degrades performance because it is not well-tuned to the graph structure. For this reason, we exploit two alternative graph-homomorphic constructions and show that they improve performance while guaranteeing privacy. Moreover, contrary to most earlier studies, the gradient of the risks is not assumed to be bounded (a condition that rarely holds in practice; e.g., quadratic risk). We avoid this condition and still devise a differentially private scheme with high probability. We examine optimization and learning scenarios and illustrate the theoretical findings through simulations.","classes":{"dataset":0.0148272049}}
{"title":"Distributed LSTM-Learning from Differentially Private Label Proportions","description":"Data privacy and decentralised data collection has become more and more popular in recent years. In order to solve issues with privacy, communication bandwidth and learning from spatio-temporal data, we will propose two efficient models which use Differential Privacy and decentralized LSTM-Learning: One, in which a Long Short Term Memory (LSTM) model is learned for extracting local temporal node constraints and feeding them into a Dense-Layer (LabelProportionToLocal). The other approach extends the first one by fetching histogram data from the neighbors and joining the information with the LSTM output (LabelProportionToDense). For evaluation two popular datasets are used: Pems-Bay and METR-LA. Additionally, we provide an own dataset, which is based on LuST. The evaluation will show the tradeoff between performance and data privacy.","link":"http://arxiv.org/abs/2301.07101v1","created":"2023-01-15","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Distributed LSTM-Learning from Differentially Private Label Proportions Data privacy and decentralised data collection has become more and more popular in recent years. In order to solve issues with privacy, communication bandwidth and learning from spatio-temporal data, we will propose two efficient models which use Differential Privacy and decentralized LSTM-Learning: One, in which a Long Short Term Memory (LSTM) model is learned for extracting local temporal node constraints and feeding them into a Dense-Layer (LabelProportionToLocal). The other approach extends the first one by fetching histogram data from the neighbors and joining the information with the LSTM output (LabelProportionToDense). For evaluation two popular datasets are used: Pems-Bay and METR-LA. Additionally, we provide an own dataset, which is based on LuST. The evaluation will show the tradeoff between performance and data privacy.","classes":{"dataset":0.0627290457}}
{"title":"A Review on the effectiveness of Dimensional Reduction with Computational Forensics: An Application on Malware Analysis","description":"The Android operating system is pervasively adopted as the operating system platform of choice for smart devices. However, the strong adoption has also resulted in exponential growth in the number of Android based malicious software or malware. To deal with such cyber threats as part of cyber investigation and digital forensics, computational techniques in the form of machine learning algorithms are applied for such malware identification, detection and forensics analysis. However, such Computational Forensics modelling techniques are constrained the volume, velocity, variety and veracity of the malware landscape. This in turn would affect its identification and detection effectiveness. Such consequence would inherently induce the question of sustainability with such solution approach. One approach to optimise effectiveness is to apply dimensional reduction techniques like Principal Component Analysis with the intent to enhance algorithmic performance. In this paper, we evaluate the effectiveness of the application of Principle Component Analysis on Computational Forensics task of detecting Android based malware. We applied our research hypothesis to three different datasets with different machine learning algorithms. Our research result showed that the dimensionally reduced dataset would result in a measure of degradation in accuracy performance.","link":"http://arxiv.org/abs/2301.06031v1","created":"2023-01-15","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"A Review on the effectiveness of Dimensional Reduction with Computational Forensics: An Application on Malware Analysis The Android operating system is pervasively adopted as the operating system platform of choice for smart devices. However, the strong adoption has also resulted in exponential growth in the number of Android based malicious software or malware. To deal with such cyber threats as part of cyber investigation and digital forensics, computational techniques in the form of machine learning algorithms are applied for such malware identification, detection and forensics analysis. However, such Computational Forensics modelling techniques are constrained the volume, velocity, variety and veracity of the malware landscape. This in turn would affect its identification and detection effectiveness. Such consequence would inherently induce the question of sustainability with such solution approach. One approach to optimise effectiveness is to apply dimensional reduction techniques like Principal Component Analysis with the intent to enhance algorithmic performance. In this paper, we evaluate the effectiveness of the application of Principle Component Analysis on Computational Forensics task of detecting Android based malware. We applied our research hypothesis to three different datasets with different machine learning algorithms. Our research result showed that the dimensionally reduced dataset would result in a measure of degradation in accuracy performance.","classes":{"dataset":0.1835304499}}
{"title":"Poisoning Attacks and Defenses in Federated Learning: A Survey","description":"Federated learning (FL) enables the training of models among distributed clients without compromising the privacy of training datasets, while the invisibility of clients datasets and the training process poses a variety of security threats. This survey provides the taxonomy of poisoning attacks and experimental evaluation to discuss the need for robust FL.","link":"http://arxiv.org/abs/2301.05795v1","created":"2023-01-14","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Poisoning Attacks and Defenses in Federated Learning: A Survey Federated learning (FL) enables the training of models among distributed clients without compromising the privacy of training datasets, while the invisibility of clients datasets and the training process poses a variety of security threats. This survey provides the taxonomy of poisoning attacks and experimental evaluation to discuss the need for robust FL.","classes":{"dataset":0.2508257627}}
{"title":"STAR-RIS Assisted Over-the-Air Vertical Federated Learning in Multi-Cell Wireless Networks","description":"Vertical federated learning (FL) is a critical enabler for distributed artificial intelligence services in the emerging 6G era, as it allows for secure and efficient collaboration of machine learning among a wide range of Internet of Things devices. However, current studies of wireless FL typically consider a single task in a single-cell wireless network, ignoring the impact of inter-cell interference on learning performance. In this paper, we investigate a simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) assisted over-the-air computation based vertical FL system in multi-cell networks, in which a STAR-RIS is deployed at the cell edge to facilitate the completion of different FL tasks in different cells. We establish the convergence of the proposed system through theoretical analysis and introduce the Pareto boundary of the optimality gaps to characterize the trade-off among cells. Based on the analysis, we then jointly design the transmit and receive beamforming as well as the STAR-RIS transmission and reflection coefficient matrices to minimize the sum of the gaps of all cells. To solve the non-convex resource allocation problem, we introduce a successive convex approximation based algorithm. Numerical experiments demonstrate that compared with conventional approaches, the proposed STAR-RIS assisted vertical FL model and the cooperative resource allocation algorithm achieve much lower mean-squared error for both uplink and downlink transmission in multi-cell wireless networks, resulting in improved learning performance for vertical FL.","link":"http://arxiv.org/abs/2301.05545v1","created":"2023-01-13","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"STAR-RIS Assisted Over-the-Air Vertical Federated Learning in Multi-Cell Wireless Networks Vertical federated learning (FL) is a critical enabler for distributed artificial intelligence services in the emerging 6G era, as it allows for secure and efficient collaboration of machine learning among a wide range of Internet of Things devices. However, current studies of wireless FL typically consider a single task in a single-cell wireless network, ignoring the impact of inter-cell interference on learning performance. In this paper, we investigate a simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) assisted over-the-air computation based vertical FL system in multi-cell networks, in which a STAR-RIS is deployed at the cell edge to facilitate the completion of different FL tasks in different cells. We establish the convergence of the proposed system through theoretical analysis and introduce the Pareto boundary of the optimality gaps to characterize the trade-off among cells. Based on the analysis, we then jointly design the transmit and receive beamforming as well as the STAR-RIS transmission and reflection coefficient matrices to minimize the sum of the gaps of all cells. To solve the non-convex resource allocation problem, we introduce a successive convex approximation based algorithm. Numerical experiments demonstrate that compared with conventional approaches, the proposed STAR-RIS assisted vertical FL model and the cooperative resource allocation algorithm achieve much lower mean-squared error for both uplink and downlink transmission in multi-cell wireless networks, resulting in improved learning performance for vertical FL.","classes":{"dataset":0.0477936342}}
{"title":"On the feasibility of attacking Thai LPR systems with adversarial examples","description":"Recent advances in deep neural networks (DNNs) have significantly enhanced the capabilities of optical character recognition (OCR) technology, enabling its adoption to a wide range of real-world applications. Despite this success, DNN-based OCR is shown to be vulnerable to adversarial attacks, in which the adversary can influence the DNN model's prediction by carefully manipulating input to the model. Prior work has demonstrated the security impacts of adversarial attacks on various OCR languages. However, to date, no studies have been conducted and evaluated on an OCR system tailored specifically for the Thai language. To bridge this gap, this work presents a feasibility study of performing adversarial attacks on a specific Thai OCR application -- Thai License Plate Recognition (LPR). Moreover, we propose a new type of adversarial attack based on the \\emph{semi-targeted} scenario and show that this scenario is highly realistic in LPR applications. Our experimental results show the feasibility of our attacks as they can be performed on a commodity computer desktop with over 90% attack success rate.","link":"http://arxiv.org/abs/2301.05506v1","created":"2023-01-13","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"On the feasibility of attacking Thai LPR systems with adversarial examples Recent advances in deep neural networks (DNNs) have significantly enhanced the capabilities of optical character recognition (OCR) technology, enabling its adoption to a wide range of real-world applications. Despite this success, DNN-based OCR is shown to be vulnerable to adversarial attacks, in which the adversary can influence the DNN model's prediction by carefully manipulating input to the model. Prior work has demonstrated the security impacts of adversarial attacks on various OCR languages. However, to date, no studies have been conducted and evaluated on an OCR system tailored specifically for the Thai language. To bridge this gap, this work presents a feasibility study of performing adversarial attacks on a specific Thai OCR application -- Thai License Plate Recognition (LPR). Moreover, we propose a new type of adversarial attack based on the \\emph{semi-targeted} scenario and show that this scenario is highly realistic in LPR applications. Our experimental results show the feasibility of our attacks as they can be performed on a commodity computer desktop with over 90% attack success rate.","classes":{"dataset":0.2876750827}}
{"title":"Fairly Private: Investigating The Fairness of Visual Privacy Preservation Algorithms","description":"As the privacy risks posed by camera surveillance and facial recognition have grown, so has the research into privacy preservation algorithms. Among these, visual privacy preservation algorithms attempt to impart bodily privacy to subjects in visuals by obfuscating privacy-sensitive areas. While disparate performances of facial recognition systems across phenotypes are the subject of much study, its counterpart, privacy preservation, is not commonly analysed from a fairness perspective. In this paper, the fairness of commonly used visual privacy preservation algorithms is investigated through the performances of facial recognition models on obfuscated images. Experiments on the PubFig dataset clearly show that the privacy protection provided is unequal across groups.","link":"http://arxiv.org/abs/2301.05012v1","created":"2023-01-12","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Fairly Private: Investigating The Fairness of Visual Privacy Preservation Algorithms As the privacy risks posed by camera surveillance and facial recognition have grown, so has the research into privacy preservation algorithms. Among these, visual privacy preservation algorithms attempt to impart bodily privacy to subjects in visuals by obfuscating privacy-sensitive areas. While disparate performances of facial recognition systems across phenotypes are the subject of much study, its counterpart, privacy preservation, is not commonly analysed from a fairness perspective. In this paper, the fairness of commonly used visual privacy preservation algorithms is investigated through the performances of facial recognition models on obfuscated images. Experiments on the PubFig dataset clearly show that the privacy protection provided is unequal across groups.","classes":{"dataset":0.1190257072}}
{"title":"Sharpening Ponzi Schemes Detection on Ethereum with Machine Learning","description":"Blockchain technology has been successfully exploited for deploying new economic applications. However, it has started arousing the interest of malicious users who deliver scams to deceive honest users and to gain economic advantages. Among the various scams, Ponzi schemes are one of the most common. Here, we present an automatic technique for detecting smart Ponzi contracts on Ethereum. We release a reusable data set with 4422 unique real-world smart contracts. Then, we introduce a new set of features that allow us to improve the classification. Finally, we identify a small and effective set of features that ensures a good classification quality.","link":"http://arxiv.org/abs/2301.04872v1","created":"2023-01-12","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Sharpening Ponzi Schemes Detection on Ethereum with Machine Learning Blockchain technology has been successfully exploited for deploying new economic applications. However, it has started arousing the interest of malicious users who deliver scams to deceive honest users and to gain economic advantages. Among the various scams, Ponzi schemes are one of the most common. Here, we present an automatic technique for detecting smart Ponzi contracts on Ethereum. We release a reusable data set with 4422 unique real-world smart contracts. Then, we introduce a new set of features that allow us to improve the classification. Finally, we identify a small and effective set of features that ensures a good classification quality.","classes":{"dataset":0.3879562616}}
{"title":"LiteLSTM Architecture Based on Weights Sharing for Recurrent Neural Networks","description":"Long short-term memory (LSTM) is one of the robust recurrent neural network architectures for learning sequential data. However, it requires considerable computational power to learn and implement both software and hardware aspects. This paper proposed a novel LiteLSTM architecture based on reducing the LSTM computation components via the weights sharing concept to reduce the overall architecture computation cost and maintain the architecture performance. The proposed LiteLSTM can be significant for processing large data where time-consuming is crucial while hardware resources are limited, such as the security of IoT devices and medical data processing. The proposed model was evaluated and tested empirically on three different datasets from the computer vision, cybersecurity, speech emotion recognition domains. The proposed LiteLSTM has comparable accuracy to the other state-of-the-art recurrent architecture while using a smaller computation budget.","link":"http://arxiv.org/abs/2301.04794v1","created":"2023-01-12","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"LiteLSTM Architecture Based on Weights Sharing for Recurrent Neural Networks Long short-term memory (LSTM) is one of the robust recurrent neural network architectures for learning sequential data. However, it requires considerable computational power to learn and implement both software and hardware aspects. This paper proposed a novel LiteLSTM architecture based on reducing the LSTM computation components via the weights sharing concept to reduce the overall architecture computation cost and maintain the architecture performance. The proposed LiteLSTM can be significant for processing large data where time-consuming is crucial while hardware resources are limited, such as the security of IoT devices and medical data processing. The proposed model was evaluated and tested empirically on three different datasets from the computer vision, cybersecurity, speech emotion recognition domains. The proposed LiteLSTM has comparable accuracy to the other state-of-the-art recurrent architecture while using a smaller computation budget.","classes":{"dataset":0.0240177363}}
{"title":"Federated Learning and Blockchain-enabled Fog-IoT Platform for Wearables in Predictive Healthcare","description":"Over the years, the popularity and usage of wearable Internet of Things (IoT) devices in several healthcare services are increased. Among the services that benefit from the usage of such devices is predictive analysis, which can improve early diagnosis in e-health. However, due to the limitations of wearable IoT devices, challenges in data privacy, service integrity, and network structure adaptability arose. To address these concerns, we propose a platform using federated learning and private blockchain technology within a fog-IoT network. These technologies have privacy-preserving features securing data within the network. We utilized the fog-IoT network's distributive structure to create an adaptive network for wearable IoT devices. We designed a testbed to examine the proposed platform's ability to preserve the integrity of a classifier. According to experimental results, the introduced implementation can effectively preserve a patient's privacy and a predictive service's integrity. We further investigated the contributions of other technologies to the security and adaptability of the IoT network. Overall, we proved the feasibility of our platform in addressing significant security and privacy challenges of wearable IoT devices in predictive healthcare through analysis, simulation, and experimentation.","link":"http://arxiv.org/abs/2301.04511v1","created":"2023-01-11","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Federated Learning and Blockchain-enabled Fog-IoT Platform for Wearables in Predictive Healthcare Over the years, the popularity and usage of wearable Internet of Things (IoT) devices in several healthcare services are increased. Among the services that benefit from the usage of such devices is predictive analysis, which can improve early diagnosis in e-health. However, due to the limitations of wearable IoT devices, challenges in data privacy, service integrity, and network structure adaptability arose. To address these concerns, we propose a platform using federated learning and private blockchain technology within a fog-IoT network. These technologies have privacy-preserving features securing data within the network. We utilized the fog-IoT network's distributive structure to create an adaptive network for wearable IoT devices. We designed a testbed to examine the proposed platform's ability to preserve the integrity of a classifier. According to experimental results, the introduced implementation can effectively preserve a patient's privacy and a predictive service's integrity. We further investigated the contributions of other technologies to the security and adaptability of the IoT network. Overall, we proved the feasibility of our platform in addressing significant security and privacy challenges of wearable IoT devices in predictive healthcare through analysis, simulation, and experimentation.","classes":{"dataset":0.1499611586}}
{"title":"ML-FEED: Machine Learning Framework for Efficient Exploit Detection (Extended version)","description":"Machine learning (ML)-based methods have recently become attractive for detecting security vulnerability exploits. Unfortunately, state-of-the-art ML models like long short-term memories (LSTMs) and transformers incur significant computation overheads. This overhead makes it infeasible to deploy them in real-time environments. We propose a novel ML-based exploit detection model, ML-FEED, that enables highly efficient inference without sacrificing performance. We develop a novel automated technique to extract vulnerability patterns from the Common Weakness Enumeration (CWE) and Common Vulnerabilities and Exposures (CVE) databases. This feature enables ML-FEED to be aware of the latest cyber weaknesses. Second, it is not based on the traditional approach of classifying sequences of application programming interface (API) calls into exploit categories. Such traditional methods that process entire sequences incur huge computational overheads. Instead, ML-FEED operates at a finer granularity and predicts the exploits triggered by every API call of the program trace. Then, it uses a state table to update the states of these potential exploits and track the progress of potential exploit chains. ML-FEED also employs a feature engineering approach that uses natural language processing-based word embeddings, frequency vectors, and one-hot encoding to detect semantically-similar instruction calls. Then, it updates the states of the predicted exploit categories and triggers an alarm when a vulnerability fingerprint executes. Our experiments show that ML-FEED is 72.9x and 75,828.9x faster than state-of-the-art lightweight LSTM and transformer models, respectively. We trained and tested ML-FEED on 79 real-world exploit categories. It predicts categories of exploit in real-time with 98.2% precision, 97.4% recall, and 97.8% F1 score. These results also outperform the LSTM and transformer baselines.","link":"http://arxiv.org/abs/2301.04314v1","created":"2023-01-11","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"ML-FEED: Machine Learning Framework for Efficient Exploit Detection (Extended version) Machine learning (ML)-based methods have recently become attractive for detecting security vulnerability exploits. Unfortunately, state-of-the-art ML models like long short-term memories (LSTMs) and transformers incur significant computation overheads. This overhead makes it infeasible to deploy them in real-time environments. We propose a novel ML-based exploit detection model, ML-FEED, that enables highly efficient inference without sacrificing performance. We develop a novel automated technique to extract vulnerability patterns from the Common Weakness Enumeration (CWE) and Common Vulnerabilities and Exposures (CVE) databases. This feature enables ML-FEED to be aware of the latest cyber weaknesses. Second, it is not based on the traditional approach of classifying sequences of application programming interface (API) calls into exploit categories. Such traditional methods that process entire sequences incur huge computational overheads. Instead, ML-FEED operates at a finer granularity and predicts the exploits triggered by every API call of the program trace. Then, it uses a state table to update the states of these potential exploits and track the progress of potential exploit chains. ML-FEED also employs a feature engineering approach that uses natural language processing-based word embeddings, frequency vectors, and one-hot encoding to detect semantically-similar instruction calls. Then, it updates the states of the predicted exploit categories and triggers an alarm when a vulnerability fingerprint executes. Our experiments show that ML-FEED is 72.9x and 75,828.9x faster than state-of-the-art lightweight LSTM and transformer models, respectively. We trained and tested ML-FEED on 79 real-world exploit categories. It predicts categories of exploit in real-time with 98.2% precision, 97.4% recall, and 97.8% F1 score. These results also outperform the LSTM and transformer baselines.","classes":{"dataset":0.4213340282}}
{"title":"Diffusion Models For Stronger Face Morphing Attacks","description":"Face morphing attacks seek to deceive a Face Recognition (FR) system by presenting a morphed image consisting of the biometric qualities from two different identities with the aim of triggering a false acceptance with one of the two identities, thereby presenting a significant threat to biometric systems. The success of a morphing attack is dependent on the ability of the morphed image to represent the biometric characteristics of both identities that were used to create the image. We present a novel morphing attack that uses a Diffusion-based architecture to improve the visual fidelity of the image and improve the ability of the morphing attack to represent characteristics from both identities. We demonstrate the high fidelity of the proposed attack by evaluating its visual fidelity via the Frechet Inception Distance. Extensive experiments are conducted to measure the vulnerability of FR systems to the proposed attack. The proposed attack is compared to two state-of-the-art GAN-based morphing attacks along with two Landmark-based attacks. The ability of a morphing attack detector to detect the proposed attack is measured and compared against the other attacks. Additionally, a novel metric to measure the relative strength between morphing attacks is introduced and evaluated.","link":"http://arxiv.org/abs/2301.04218v1","created":"2023-01-10","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Diffusion Models For Stronger Face Morphing Attacks Face morphing attacks seek to deceive a Face Recognition (FR) system by presenting a morphed image consisting of the biometric qualities from two different identities with the aim of triggering a false acceptance with one of the two identities, thereby presenting a significant threat to biometric systems. The success of a morphing attack is dependent on the ability of the morphed image to represent the biometric characteristics of both identities that were used to create the image. We present a novel morphing attack that uses a Diffusion-based architecture to improve the visual fidelity of the image and improve the ability of the morphing attack to represent characteristics from both identities. We demonstrate the high fidelity of the proposed attack by evaluating its visual fidelity via the Frechet Inception Distance. Extensive experiments are conducted to measure the vulnerability of FR systems to the proposed attack. The proposed attack is compared to two state-of-the-art GAN-based morphing attacks along with two Landmark-based attacks. The ability of a morphing attack detector to detect the proposed attack is measured and compared against the other attacks. Additionally, a novel metric to measure the relative strength between morphing attacks is introduced and evaluated.","classes":{"dataset":0.2545863688}}
{"title":"Federated Learning for Energy Constrained IoT devices: A systematic mapping study","description":"Federated Machine Learning (Fed ML) is a new distributed machine learning technique applied to collaboratively train a global model using clients local data without transmitting it. Nodes only send parameter updates (e.g., weight updates in the case of neural networks), which are fused together by the server to build the global model. By not divulging node data, Fed ML guarantees its confidentiality, a crucial aspect of network security, which enables it to be used in the context of data-sensitive Internet of Things (IoT) and mobile applications, such as smart Geo-location and the smart grid. However, most IoT devices are particularly energy constrained, which raises the need to optimize the Fed ML process for efficient training tasks and optimized power consumption. In this paper, we conduct, to the best of our knowledge, the first Systematic Mapping Study (SMS) on Fed ML optimization techniques for energy-constrained IoT devices. From a total of more than 800 papers, we select 67 that satisfy our criteria and give a structured overview of the field using a set of carefully chosen research questions. Finally, we attempt to provide an analysis of the energy-constrained Fed ML state of the art and try to outline some potential recommendations for the research community.","link":"http://arxiv.org/abs/2301.03720v1","created":"2023-01-09","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Federated Learning for Energy Constrained IoT devices: A systematic mapping study Federated Machine Learning (Fed ML) is a new distributed machine learning technique applied to collaboratively train a global model using clients local data without transmitting it. Nodes only send parameter updates (e.g., weight updates in the case of neural networks), which are fused together by the server to build the global model. By not divulging node data, Fed ML guarantees its confidentiality, a crucial aspect of network security, which enables it to be used in the context of data-sensitive Internet of Things (IoT) and mobile applications, such as smart Geo-location and the smart grid. However, most IoT devices are particularly energy constrained, which raises the need to optimize the Fed ML process for efficient training tasks and optimized power consumption. In this paper, we conduct, to the best of our knowledge, the first Systematic Mapping Study (SMS) on Fed ML optimization techniques for energy-constrained IoT devices. From a total of more than 800 papers, we select 67 that satisfy our criteria and give a structured overview of the field using a set of carefully chosen research questions. Finally, we attempt to provide an analysis of the energy-constrained Fed ML state of the art and try to outline some potential recommendations for the research community.","classes":{"dataset":0.0952154472}}
{"title":"Architecting Safer Autonomous Aviation Systems","description":"The aviation literature gives relatively little guidance to practitioners about the specifics of architecting systems for safety, particularly the impact of architecture on allocating safety requirements, or the relative ease of system assurance resulting from system or subsystem level architectural choices. As an exemplar, this paper considers common architectural patterns used within traditional aviation systems and explores their safety and safety assurance implications when applied in the context of integrating artificial intelligence (AI) and machine learning (ML) based functionality. Considering safety as an architectural property, we discuss both the allocation of safety requirements and the architectural trade-offs involved early in the design lifecycle. This approach could be extended to other assured properties, similar to safety, such as security. We conclude with a discussion of the safety considerations that emerge in the context of candidate architectural patterns that have been proposed in the recent literature for enabling autonomy capabilities by integrating AI and ML. A recommendation is made for the generation of a property-driven architectural pattern catalogue.","link":"http://arxiv.org/abs/2301.08138v1","created":"2023-01-09","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Architecting Safer Autonomous Aviation Systems The aviation literature gives relatively little guidance to practitioners about the specifics of architecting systems for safety, particularly the impact of architecture on allocating safety requirements, or the relative ease of system assurance resulting from system or subsystem level architectural choices. As an exemplar, this paper considers common architectural patterns used within traditional aviation systems and explores their safety and safety assurance implications when applied in the context of integrating artificial intelligence (AI) and machine learning (ML) based functionality. Considering safety as an architectural property, we discuss both the allocation of safety requirements and the architectural trade-offs involved early in the design lifecycle. This approach could be extended to other assured properties, similar to safety, such as security. We conclude with a discussion of the safety considerations that emerge in the context of candidate architectural patterns that have been proposed in the recent literature for enabling autonomy capabilities by integrating AI and ML. A recommendation is made for the generation of a property-driven architectural pattern catalogue.","classes":{"dataset":0.1177335307}}
{"title":"Efficient Attack Detection in IoT Devices using Feature Engineering-Less Machine Learning","description":"Through the generalization of deep learning, the research community has addressed critical challenges in the network security domain, like malware identification and anomaly detection. However, they have yet to discuss deploying them on Internet of Things (IoT) devices for day-to-day operations. IoT devices are often limited in memory and processing power, rendering the compute-intensive deep learning environment unusable. This research proposes a way to overcome this barrier by bypassing feature engineering in the deep learning pipeline and using raw packet data as input. We introduce a feature engineering-less machine learning (ML) process to perform malware detection on IoT devices. Our proposed model, \"Feature engineering-less-ML (FEL-ML),\" is a lighter-weight detection algorithm that expends no extra computations on \"engineered\" features. It effectively accelerates the low-powered IoT edge. It is trained on unprocessed byte-streams of packets. Aside from providing better results, it is quicker than traditional feature-based methods. FEL-ML facilitates resource-sensitive network traffic security with the added benefit of eliminating the significant investment by subject matter experts in feature engineering.","link":"http://arxiv.org/abs/2301.03532v1","created":"2023-01-09","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Efficient Attack Detection in IoT Devices using Feature Engineering-Less Machine Learning Through the generalization of deep learning, the research community has addressed critical challenges in the network security domain, like malware identification and anomaly detection. However, they have yet to discuss deploying them on Internet of Things (IoT) devices for day-to-day operations. IoT devices are often limited in memory and processing power, rendering the compute-intensive deep learning environment unusable. This research proposes a way to overcome this barrier by bypassing feature engineering in the deep learning pipeline and using raw packet data as input. We introduce a feature engineering-less machine learning (ML) process to perform malware detection on IoT devices. Our proposed model, \"Feature engineering-less-ML (FEL-ML),\" is a lighter-weight detection algorithm that expends no extra computations on \"engineered\" features. It effectively accelerates the low-powered IoT edge. It is trained on unprocessed byte-streams of packets. Aside from providing better results, it is quicker than traditional feature-based methods. FEL-ML facilitates resource-sensitive network traffic security with the added benefit of eliminating the significant investment by subject matter experts in feature engineering.","classes":{"dataset":0.0600163415}}
{"title":"Negative Results of Fusing Code and Documentation for Learning to Accurately Identify Sensitive Source and Sink Methods An Application to the Android Framework for Data Leak Detection","description":"Apps on mobile phones manipulate all sorts of data, including sensitive data, leading to privacy-related concerns. Recent regulations like the European GDPR provide rules for the processing of personal and sensitive data, like that no such data may be leaked without the consent of the user.   Researchers have proposed sophisticated approaches to track sensitive data within mobile apps, all of which rely on specific lists of sensitive source and sink API methods. The data flow analysis results greatly depend on these lists' quality. Previous approaches either used incomplete hand-written lists that quickly became outdated or relied on machine learning. The latter, however, leads to numerous false positives, as we show.   This paper introduces CoDoC, a tool that aims to revive the machine-learning approach to precisely identify privacy-related source and sink API methods. In contrast to previous approaches, CoDoC uses deep learning techniques and combines the source code with the documentation of API methods. Firstly, we propose novel definitions that clarify the concepts of sensitive source and sink methods. Secondly, based on these definitions, we build a new ground truth of Android methods representing sensitive source, sink, and neither (i.e., no source or sink) methods that will be used to train our classifier.   We evaluate CoDoC and show that, on our validation dataset, it achieves a precision, recall, and F1 score of 91% in 10-fold cross-validation, outperforming the state-of-the-art SuSi when used on the same dataset. However, similarly to existing tools, we show that in the wild, i.e., with unseen data, CoDoC performs poorly and generates many false positive results. Our findings, together with time-tested results of previous approaches, suggest that machine-learning models for abstract concepts such as privacy fail in practice despite good lab results.","link":"http://arxiv.org/abs/2301.03207v2","created":"2023-01-09","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Negative Results of Fusing Code and Documentation for Learning to Accurately Identify Sensitive Source and Sink Methods An Application to the Android Framework for Data Leak Detection Apps on mobile phones manipulate all sorts of data, including sensitive data, leading to privacy-related concerns. Recent regulations like the European GDPR provide rules for the processing of personal and sensitive data, like that no such data may be leaked without the consent of the user.   Researchers have proposed sophisticated approaches to track sensitive data within mobile apps, all of which rely on specific lists of sensitive source and sink API methods. The data flow analysis results greatly depend on these lists' quality. Previous approaches either used incomplete hand-written lists that quickly became outdated or relied on machine learning. The latter, however, leads to numerous false positives, as we show.   This paper introduces CoDoC, a tool that aims to revive the machine-learning approach to precisely identify privacy-related source and sink API methods. In contrast to previous approaches, CoDoC uses deep learning techniques and combines the source code with the documentation of API methods. Firstly, we propose novel definitions that clarify the concepts of sensitive source and sink methods. Secondly, based on these definitions, we build a new ground truth of Android methods representing sensitive source, sink, and neither (i.e., no source or sink) methods that will be used to train our classifier.   We evaluate CoDoC and show that, on our validation dataset, it achieves a precision, recall, and F1 score of 91% in 10-fold cross-validation, outperforming the state-of-the-art SuSi when used on the same dataset. However, similarly to existing tools, we show that in the wild, i.e., with unseen data, CoDoC performs poorly and generates many false positive results. Our findings, together with time-tested results of previous approaches, suggest that machine-learning models for abstract concepts such as privacy fail in practice despite good lab results.","classes":{"dataset":0.3170137107}}
{"title":"Privacy-Preserving Record Linkage for Cardinality Counting","description":"Several applications require counting the number of distinct items in the data, which is known as the cardinality counting problem. Example applications include health applications such as rare disease patients counting for adequate awareness and funding, and counting the number of cases of a new disease for outbreak detection, marketing applications such as counting the visibility reached for a new product, and cybersecurity applications such as tracking the number of unique views of social media posts. The data needed for the counting is however often personal and sensitive, and need to be processed using privacy-preserving techniques. The quality of data in different databases, for example typos, errors and variations, poses additional challenges for accurate cardinality estimation. While privacy-preserving cardinality counting has gained much attention in the recent times and a few privacy-preserving algorithms have been developed for cardinality estimation, no work has so far been done on privacy-preserving cardinality counting using record linkage techniques with fuzzy matching and provable privacy guarantees. We propose a novel privacy-preserving record linkage algorithm using unsupervised clustering techniques to link and count the cardinality of individuals in multiple datasets without compromising their privacy or identity. In addition, existing Elbow methods to find the optimal number of clusters as the cardinality are far from accurate as they do not take into account the purity and completeness of generated clusters. We propose a novel method to find the optimal number of clusters in unsupervised learning. Our experimental results on real and synthetic datasets are highly promising in terms of significantly smaller error rate of less than 0.1 with a privacy budget {\\epsilon} = 1.0 compared to the state-of-the-art fuzzy matching and clustering method.","link":"http://arxiv.org/abs/2301.04000v1","created":"2023-01-09","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Privacy-Preserving Record Linkage for Cardinality Counting Several applications require counting the number of distinct items in the data, which is known as the cardinality counting problem. Example applications include health applications such as rare disease patients counting for adequate awareness and funding, and counting the number of cases of a new disease for outbreak detection, marketing applications such as counting the visibility reached for a new product, and cybersecurity applications such as tracking the number of unique views of social media posts. The data needed for the counting is however often personal and sensitive, and need to be processed using privacy-preserving techniques. The quality of data in different databases, for example typos, errors and variations, poses additional challenges for accurate cardinality estimation. While privacy-preserving cardinality counting has gained much attention in the recent times and a few privacy-preserving algorithms have been developed for cardinality estimation, no work has so far been done on privacy-preserving cardinality counting using record linkage techniques with fuzzy matching and provable privacy guarantees. We propose a novel privacy-preserving record linkage algorithm using unsupervised clustering techniques to link and count the cardinality of individuals in multiple datasets without compromising their privacy or identity. In addition, existing Elbow methods to find the optimal number of clusters as the cardinality are far from accurate as they do not take into account the purity and completeness of generated clusters. We propose a novel method to find the optimal number of clusters in unsupervised learning. Our experimental results on real and synthetic datasets are highly promising in terms of significantly smaller error rate of less than 0.1 with a privacy budget {\\epsilon} = 1.0 compared to the state-of-the-art fuzzy matching and clustering method.","classes":{"dataset":0.3731922805}}
{"title":"Deepfake CAPTCHA: A Method for Preventing Fake Calls","description":"Deep learning technology has made it possible to generate realistic content of specific individuals. These `deepfakes' can now be generated in real-time which enables attackers to impersonate people over audio and video calls. Moreover, some methods only need a few images or seconds of audio to steal an identity. Existing defenses perform passive analysis to detect fake content. However, with the rapid progress of deepfake quality, this may be a losing game.   In this paper, we propose D-CAPTCHA: an active defense against real-time deepfakes. The approach is to force the adversary into the spotlight by challenging the deepfake model to generate content which exceeds its capabilities. By doing so, passive detection becomes easier since the content will be distorted. In contrast to existing CAPTCHAs, we challenge the AI's ability to create content as opposed to its ability to classify content. In this work we focus on real-time audio deepfakes and present preliminary results on video.   In our evaluation we found that D-CAPTCHA outperforms state-of-the-art audio deepfake detectors with an accuracy of 91-100% depending on the challenge (compared to 71% without challenges). We also performed a study on 41 volunteers to understand how threatening current real-time deepfake attacks are. We found that the majority of the volunteers could not tell the difference between real and fake audio.","link":"http://arxiv.org/abs/2301.03064v1","created":"2023-01-08","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Deepfake CAPTCHA: A Method for Preventing Fake Calls Deep learning technology has made it possible to generate realistic content of specific individuals. These `deepfakes' can now be generated in real-time which enables attackers to impersonate people over audio and video calls. Moreover, some methods only need a few images or seconds of audio to steal an identity. Existing defenses perform passive analysis to detect fake content. However, with the rapid progress of deepfake quality, this may be a losing game.   In this paper, we propose D-CAPTCHA: an active defense against real-time deepfakes. The approach is to force the adversary into the spotlight by challenging the deepfake model to generate content which exceeds its capabilities. By doing so, passive detection becomes easier since the content will be distorted. In contrast to existing CAPTCHAs, we challenge the AI's ability to create content as opposed to its ability to classify content. In this work we focus on real-time audio deepfakes and present preliminary results on video.   In our evaluation we found that D-CAPTCHA outperforms state-of-the-art audio deepfake detectors with an accuracy of 91-100% depending on the challenge (compared to 71% without challenges). We also performed a study on 41 volunteers to understand how threatening current real-time deepfake attacks are. We found that the majority of the volunteers could not tell the difference between real and fake audio.","classes":{"dataset":0.0423223712}}
{"title":"IronForge: An Open, Secure, Fair, Decentralized Federated Learning","description":"Federated learning (FL) provides an effective machine learning (ML) architecture to protect data privacy in a distributed manner. However, the inevitable network asynchrony, the over-dependence on a central coordinator, and the lack of an open and fair incentive mechanism collectively hinder its further development. We propose \\textsc{IronForge}, a new generation of FL framework, that features a Directed Acyclic Graph (DAG)-based data structure and eliminates the need for central coordinators to achieve fully decentralized operations. \\textsc{IronForge} runs in a public and open network, and launches a fair incentive mechanism by enabling state consistency in the DAG, so that the system fits in networks where training resources are unevenly distributed. In addition, dedicated defense strategies against prevalent FL attacks on incentive fairness and data privacy are presented to ensure the security of \\textsc{IronForge}. Experimental results based on a newly developed testbed FLSim highlight the superiority of \\textsc{IronForge} to the existing prevalent FL frameworks under various specifications in performance, fairness, and security. To the best of our knowledge, \\textsc{IronForge} is the first secure and fully decentralized FL framework that can be applied in open networks with realistic network and training settings.","link":"http://arxiv.org/abs/2301.04006v1","created":"2023-01-07","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"IronForge: An Open, Secure, Fair, Decentralized Federated Learning Federated learning (FL) provides an effective machine learning (ML) architecture to protect data privacy in a distributed manner. However, the inevitable network asynchrony, the over-dependence on a central coordinator, and the lack of an open and fair incentive mechanism collectively hinder its further development. We propose \\textsc{IronForge}, a new generation of FL framework, that features a Directed Acyclic Graph (DAG)-based data structure and eliminates the need for central coordinators to achieve fully decentralized operations. \\textsc{IronForge} runs in a public and open network, and launches a fair incentive mechanism by enabling state consistency in the DAG, so that the system fits in networks where training resources are unevenly distributed. In addition, dedicated defense strategies against prevalent FL attacks on incentive fairness and data privacy are presented to ensure the security of \\textsc{IronForge}. Experimental results based on a newly developed testbed FLSim highlight the superiority of \\textsc{IronForge} to the existing prevalent FL frameworks under various specifications in performance, fairness, and security. To the best of our knowledge, \\textsc{IronForge} is the first secure and fully decentralized FL framework that can be applied in open networks with realistic network and training settings.","classes":{"dataset":0.0928953141}}
{"title":"TrojanPuzzle: Covertly Poisoning Code-Suggestion Models","description":"With tools like GitHub Copilot, automatic code suggestion is no longer a dream in software engineering. These tools, based on large language models, are typically trained on massive corpora of code mined from unvetted public sources. As a result, these models are susceptible to data poisoning attacks where an adversary manipulates the model's training or fine-tuning phases by injecting malicious data. Poisoning attacks could be designed to influence the model's suggestions at run time for chosen contexts, such as inducing the model into suggesting insecure code payloads. To achieve this, prior poisoning attacks explicitly inject the insecure code payload into the training data, making the poisoning data detectable by static analysis tools that can remove such malicious data from the training set. In this work, we demonstrate two novel data poisoning attacks, COVERT and TROJANPUZZLE, that can bypass static analysis by planting malicious poisoning data in out-of-context regions such as docstrings. Our most novel attack, TROJANPUZZLE, goes one step further in generating less suspicious poisoning data by never including certain (suspicious) parts of the payload in the poisoned data, while still inducing a model that suggests the entire payload when completing code (i.e., outside docstrings). This makes TROJANPUZZLE robust against signature-based dataset-cleansing methods that identify and filter out suspicious sequences from the training data. Our evaluation against two model sizes demonstrates that both COVERT and TROJANPUZZLE have significant implications for how practitioners should select code used to train or tune code-suggestion models.","link":"http://arxiv.org/abs/2301.02344v1","created":"2023-01-06","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"TrojanPuzzle: Covertly Poisoning Code-Suggestion Models With tools like GitHub Copilot, automatic code suggestion is no longer a dream in software engineering. These tools, based on large language models, are typically trained on massive corpora of code mined from unvetted public sources. As a result, these models are susceptible to data poisoning attacks where an adversary manipulates the model's training or fine-tuning phases by injecting malicious data. Poisoning attacks could be designed to influence the model's suggestions at run time for chosen contexts, such as inducing the model into suggesting insecure code payloads. To achieve this, prior poisoning attacks explicitly inject the insecure code payload into the training data, making the poisoning data detectable by static analysis tools that can remove such malicious data from the training set. In this work, we demonstrate two novel data poisoning attacks, COVERT and TROJANPUZZLE, that can bypass static analysis by planting malicious poisoning data in out-of-context regions such as docstrings. Our most novel attack, TROJANPUZZLE, goes one step further in generating less suspicious poisoning data by never including certain (suspicious) parts of the payload in the poisoned data, while still inducing a model that suggests the entire payload when completing code (i.e., outside docstrings). This makes TROJANPUZZLE robust against signature-based dataset-cleansing methods that identify and filter out suspicious sequences from the training data. Our evaluation against two model sizes demonstrates that both COVERT and TROJANPUZZLE have significant implications for how practitioners should select code used to train or tune code-suggestion models.","classes":{"dataset":0.0405382365}}
{"title":"Silent Killer: Optimizing Backdoor Trigger Yields a Stealthy and Powerful Data Poisoning Attack","description":"We propose a stealthy and powerful backdoor attack on neural networks based on data poisoning (DP). In contrast to previous attacks, both the poison and the trigger in our method are stealthy. We are able to change the model's classification of samples from a source class to a target class chosen by the attacker. We do so by using a small number of poisoned training samples with nearly imperceptible perturbations, without changing their labels. At inference time, we use a stealthy perturbation added to the attacked samples as a trigger. This perturbation is crafted as a universal adversarial perturbation (UAP), and the poison is crafted using gradient alignment coupled to this trigger. Our method is highly efficient in crafting time compared to previous methods and requires only a trained surrogate model without additional retraining. Our attack achieves state-of-the-art results in terms of attack success rate while maintaining high accuracy on clean samples.","link":"http://arxiv.org/abs/2301.02615v1","created":"2023-01-05","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Silent Killer: Optimizing Backdoor Trigger Yields a Stealthy and Powerful Data Poisoning Attack We propose a stealthy and powerful backdoor attack on neural networks based on data poisoning (DP). In contrast to previous attacks, both the poison and the trigger in our method are stealthy. We are able to change the model's classification of samples from a source class to a target class chosen by the attacker. We do so by using a small number of poisoned training samples with nearly imperceptible perturbations, without changing their labels. At inference time, we use a stealthy perturbation added to the attacked samples as a trigger. This perturbation is crafted as a universal adversarial perturbation (UAP), and the poison is crafted using gradient alignment coupled to this trigger. Our method is highly efficient in crafting time compared to previous methods and requires only a trained surrogate model without additional retraining. Our attack achieves state-of-the-art results in terms of attack success rate while maintaining high accuracy on clean samples.","classes":{"dataset":0.0586399809}}
{"title":"Unsupervised High Impedance Fault Detection Using Autoencoder and Principal Component Analysis","description":"Detection of high impedance faults (HIF) has been one of the biggest challenges in the power distribution network. The low current magnitude and diverse characteristics of HIFs make them difficult to be detected by over-current relays. Recently, data-driven methods based on machine learning models are gaining popularity in HIF detection due to their capability to learn complex patterns from data. Most machine learning-based detection methods adopt supervised learning techniques to distinguish HIFs from normal load conditions by performing classifications, which rely on a large amount of data collected during HIF. However, measurements of HIF are difficult to acquire in the real world. As a result, the reliability and generalization of the classification methods are limited when the load profiles and faults are not present in the training data. Consequently, this paper proposes an unsupervised HIF detection framework using the autoencoder and principal component analysis-based monitoring techniques. The proposed fault detection method detects the HIF by monitoring the changes in correlation structure within the current waveforms that are different from the normal loads. The performance of the proposed HIF detection method is tested using real data collected from a 4.16 kV distribution system and compared with results from a commercially available solution for HIF detection. The numerical results demonstrate that the proposed method outperforms the commercially available HIF detection technique while maintaining high security by not falsely detecting during load conditions.","link":"http://arxiv.org/abs/2301.01867v1","created":"2023-01-05","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Unsupervised High Impedance Fault Detection Using Autoencoder and Principal Component Analysis Detection of high impedance faults (HIF) has been one of the biggest challenges in the power distribution network. The low current magnitude and diverse characteristics of HIFs make them difficult to be detected by over-current relays. Recently, data-driven methods based on machine learning models are gaining popularity in HIF detection due to their capability to learn complex patterns from data. Most machine learning-based detection methods adopt supervised learning techniques to distinguish HIFs from normal load conditions by performing classifications, which rely on a large amount of data collected during HIF. However, measurements of HIF are difficult to acquire in the real world. As a result, the reliability and generalization of the classification methods are limited when the load profiles and faults are not present in the training data. Consequently, this paper proposes an unsupervised HIF detection framework using the autoencoder and principal component analysis-based monitoring techniques. The proposed fault detection method detects the HIF by monitoring the changes in correlation structure within the current waveforms that are different from the normal loads. The performance of the proposed HIF detection method is tested using real data collected from a 4.16 kV distribution system and compared with results from a commercially available solution for HIF detection. The numerical results demonstrate that the proposed method outperforms the commercially available HIF detection technique while maintaining high security by not falsely detecting during load conditions.","classes":{"dataset":0.1584857255}}
{"title":"Availability Adversarial Attack and Countermeasures for Deep Learning-based Load Forecasting","description":"The forecast of electrical loads is essential for the planning and operation of the power system. Recently, advances in deep learning have enabled more accurate forecasts. However, deep neural networks are prone to adversarial attacks. Although most of the literature focuses on integrity-based attacks, this paper proposes availability-based adversarial attacks, which can be more easily implemented by attackers. For each forecast instance, the availability attack position is optimally solved by mixed-integer reformulation of the artificial neural network. To tackle this attack, an adversarial training algorithm is proposed. In simulation, a realistic load forecasting dataset is considered and the attack performance is compared to the integrity-based attack. Meanwhile, the adversarial training algorithm is shown to significantly improve robustness against availability attacks. All codes are available at https://github.com/xuwkk/AAA_Load_Forecast.","link":"http://arxiv.org/abs/2301.01832v1","created":"2023-01-04","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Availability Adversarial Attack and Countermeasures for Deep Learning-based Load Forecasting The forecast of electrical loads is essential for the planning and operation of the power system. Recently, advances in deep learning have enabled more accurate forecasts. However, deep neural networks are prone to adversarial attacks. Although most of the literature focuses on integrity-based attacks, this paper proposes availability-based adversarial attacks, which can be more easily implemented by attackers. For each forecast instance, the availability attack position is optimally solved by mixed-integer reformulation of the artificial neural network. To tackle this attack, an adversarial training algorithm is proposed. In simulation, a realistic load forecasting dataset is considered and the attack performance is compared to the integrity-based attack. Meanwhile, the adversarial training algorithm is shown to significantly improve robustness against availability attacks. All codes are available at https://github.com/xuwkk/AAA_Load_Forecast.","classes":{"dataset":0.1223849803}}
{"title":"GUAP: Graph Universal Attack Through Adversarial Patching","description":"Graph neural networks (GNNs) are a class of effective deep learning models for node classification tasks; yet their predictive capability may be severely compromised under adversarially designed unnoticeable perturbations to the graph structure and/or node data. Most of the current work on graph adversarial attacks aims at lowering the overall prediction accuracy, but we argue that the resulting abnormal model performance may catch attention easily and invite quick counterattack. Moreover, attacks through modification of existing graph data may be hard to conduct if good security protocols are implemented. In this work, we consider an easier attack harder to be noticed, through adversarially patching the graph with new nodes and edges. The attack is universal: it targets a single node each time and flips its connection to the same set of patch nodes. The attack is unnoticeable: it does not modify the predictions of nodes other than the target. We develop an algorithm, named GUAP, that achieves high attack success rate but meanwhile preserves the prediction accuracy. GUAP is fast to train by employing a sampling strategy. We demonstrate that a 5% sampling in each epoch yields 20x speedup in training, with only a slight degradation in attack performance. Additionally, we show that the adversarial patch trained with the graph convolutional network transfers well to other GNNs, such as the graph attention network.","link":"http://arxiv.org/abs/2301.01731v1","created":"2023-01-04","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"GUAP: Graph Universal Attack Through Adversarial Patching Graph neural networks (GNNs) are a class of effective deep learning models for node classification tasks; yet their predictive capability may be severely compromised under adversarially designed unnoticeable perturbations to the graph structure and/or node data. Most of the current work on graph adversarial attacks aims at lowering the overall prediction accuracy, but we argue that the resulting abnormal model performance may catch attention easily and invite quick counterattack. Moreover, attacks through modification of existing graph data may be hard to conduct if good security protocols are implemented. In this work, we consider an easier attack harder to be noticed, through adversarially patching the graph with new nodes and edges. The attack is universal: it targets a single node each time and flips its connection to the same set of patch nodes. The attack is unnoticeable: it does not modify the predictions of nodes other than the target. We develop an algorithm, named GUAP, that achieves high attack success rate but meanwhile preserves the prediction accuracy. GUAP is fast to train by employing a sampling strategy. We demonstrate that a 5% sampling in each epoch yields 20x speedup in training, with only a slight degradation in attack performance. Additionally, we show that the adversarial patch trained with the graph convolutional network transfers well to other GNNs, such as the graph attention network.","classes":{"dataset":0.0471556932}}
{"title":"Beckman Defense","description":"Optimal transport (OT) based distributional robust optimisation (DRO) has received some traction in the recent past. However, it is at a nascent stage but has a sound potential in robustifying the deep learning models. Interestingly, OT barycenters demonstrate a good robustness against adversarial attacks. Owing to the computationally expensive nature of OT barycenters, they have not been investigated under DRO framework. In this work, we propose a new barycenter, namely Beckman barycenter, which can be computed efficiently and used for training the network to defend against adversarial attacks in conjunction with adversarial training. We propose a novel formulation of Beckman barycenter and analytically obtain the barycenter using the marginals of the input image. We show that the Beckman barycenter can be used to train adversarially trained networks to improve the robustness. Our training is extremely efficient as it requires only a single epoch of training. Elaborate experiments on CIFAR-10, CIFAR-100 and Tiny ImageNet demonstrate that training an adversarially robust network with Beckman barycenter can significantly increase the performance. Under auto attack, we get a a maximum boost of 10\\% in CIFAR-10, 8.34\\% in CIFAR-100 and 11.51\\% in Tiny ImageNet. Our code is available at https://github.com/Visual-Conception-Group/test-barycentric-defense.","link":"http://arxiv.org/abs/2301.01495v2","created":"2023-01-04","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Beckman Defense Optimal transport (OT) based distributional robust optimisation (DRO) has received some traction in the recent past. However, it is at a nascent stage but has a sound potential in robustifying the deep learning models. Interestingly, OT barycenters demonstrate a good robustness against adversarial attacks. Owing to the computationally expensive nature of OT barycenters, they have not been investigated under DRO framework. In this work, we propose a new barycenter, namely Beckman barycenter, which can be computed efficiently and used for training the network to defend against adversarial attacks in conjunction with adversarial training. We propose a novel formulation of Beckman barycenter and analytically obtain the barycenter using the marginals of the input image. We show that the Beckman barycenter can be used to train adversarially trained networks to improve the robustness. Our training is extremely efficient as it requires only a single epoch of training. Elaborate experiments on CIFAR-10, CIFAR-100 and Tiny ImageNet demonstrate that training an adversarially robust network with Beckman barycenter can significantly increase the performance. Under auto attack, we get a a maximum boost of 10\\% in CIFAR-10, 8.34\\% in CIFAR-100 and 11.51\\% in Tiny ImageNet. Our code is available at https://github.com/Visual-Conception-Group/test-barycentric-defense.","classes":{"dataset":0.439724654}}
{"title":"Backdoor Attacks Against Dataset Distillation","description":"Dataset distillation has emerged as a prominent technique to improve data efficiency when training machine learning models. It encapsulates the knowledge from a large dataset into a smaller synthetic dataset. A model trained on this smaller distilled dataset can attain comparable performance to a model trained on the original training dataset. However, the existing dataset distillation techniques mainly aim at achieving the best trade-off between resource usage efficiency and model utility. The security risks stemming from them have not been explored. This study performs the first backdoor attack against the models trained on the data distilled by dataset distillation models in the image domain. Concretely, we inject triggers into the synthetic data during the distillation procedure rather than during the model training stage, where all previous attacks are performed. We propose two types of backdoor attacks, namely NAIVEATTACK and DOORPING. NAIVEATTACK simply adds triggers to the raw data at the initial distillation phase, while DOORPING iteratively updates the triggers during the entire distillation procedure. We conduct extensive evaluations on multiple datasets, architectures, and dataset distillation techniques. Empirical evaluation shows that NAIVEATTACK achieves decent attack success rate (ASR) scores in some cases, while DOORPING reaches higher ASR scores (close to 1.0) in all cases. Furthermore, we conduct a comprehensive ablation study to analyze the factors that may affect the attack performance. Finally, we evaluate multiple defense mechanisms against our backdoor attacks and show that our attacks can practically circumvent these defense mechanisms.","link":"http://arxiv.org/abs/2301.01197v1","created":"2023-01-03","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Backdoor Attacks Against Dataset Distillation Dataset distillation has emerged as a prominent technique to improve data efficiency when training machine learning models. It encapsulates the knowledge from a large dataset into a smaller synthetic dataset. A model trained on this smaller distilled dataset can attain comparable performance to a model trained on the original training dataset. However, the existing dataset distillation techniques mainly aim at achieving the best trade-off between resource usage efficiency and model utility. The security risks stemming from them have not been explored. This study performs the first backdoor attack against the models trained on the data distilled by dataset distillation models in the image domain. Concretely, we inject triggers into the synthetic data during the distillation procedure rather than during the model training stage, where all previous attacks are performed. We propose two types of backdoor attacks, namely NAIVEATTACK and DOORPING. NAIVEATTACK simply adds triggers to the raw data at the initial distillation phase, while DOORPING iteratively updates the triggers during the entire distillation procedure. We conduct extensive evaluations on multiple datasets, architectures, and dataset distillation techniques. Empirical evaluation shows that NAIVEATTACK achieves decent attack success rate (ASR) scores in some cases, while DOORPING reaches higher ASR scores (close to 1.0) in all cases. Furthermore, we conduct a comprehensive ablation study to analyze the factors that may affect the attack performance. Finally, we evaluate multiple defense mechanisms against our backdoor attacks and show that our attacks can practically circumvent these defense mechanisms.","classes":{"dataset":0.1019463018}}
{"title":"Look, Listen, and Attack: Backdoor Attacks Against Video Action Recognition","description":"Deep neural networks (DNNs) are vulnerable to a class of attacks called \"backdoor attacks\", which create an association between a backdoor trigger and a target label the attacker is interested in exploiting. A backdoored DNN performs well on clean test images, yet persistently predicts an attacker-defined label for any sample in the presence of the backdoor trigger. Although backdoor attacks have been extensively studied in the image domain, there are very few works that explore such attacks in the video domain, and they tend to conclude that image backdoor attacks are less effective in the video domain. In this work, we revisit the traditional backdoor threat model and incorporate additional video-related aspects to that model. We show that poisoned-label image backdoor attacks could be extended temporally in two ways, statically and dynamically, leading to highly effective attacks in the video domain. In addition, we explore natural video backdoors to highlight the seriousness of this vulnerability in the video domain. And, for the first time, we study multi-modal (audiovisual) backdoor attacks against video action recognition models, where we show that attacking a single modality is enough for achieving a high attack success rate.","link":"http://arxiv.org/abs/2301.00986v2","created":"2023-01-03","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Look, Listen, and Attack: Backdoor Attacks Against Video Action Recognition Deep neural networks (DNNs) are vulnerable to a class of attacks called \"backdoor attacks\", which create an association between a backdoor trigger and a target label the attacker is interested in exploiting. A backdoored DNN performs well on clean test images, yet persistently predicts an attacker-defined label for any sample in the presence of the backdoor trigger. Although backdoor attacks have been extensively studied in the image domain, there are very few works that explore such attacks in the video domain, and they tend to conclude that image backdoor attacks are less effective in the video domain. In this work, we revisit the traditional backdoor threat model and incorporate additional video-related aspects to that model. We show that poisoned-label image backdoor attacks could be extended temporally in two ways, statically and dynamically, leading to highly effective attacks in the video domain. In addition, we explore natural video backdoors to highlight the seriousness of this vulnerability in the video domain. And, for the first time, we study multi-modal (audiovisual) backdoor attacks against video action recognition models, where we show that attacking a single modality is enough for achieving a high attack success rate.","classes":{"dataset":0.1111835465}}
{"title":"Ranking Differential Privacy","description":"Rankings are widely collected in various real-life scenarios, leading to the leakage of personal information such as users' preferences on videos or news. To protect rankings, existing works mainly develop privacy protection on a single ranking within a set of ranking or pairwise comparisons of a ranking under the $\\epsilon$-differential privacy. This paper proposes a novel notion called $\\epsilon$-ranking differential privacy for protecting ranks. We establish the connection between the Mallows model (Mallows, 1957) and the proposed $\\epsilon$-ranking differential privacy. This allows us to develop a multistage ranking algorithm to generate synthetic rankings while satisfying the developed $\\epsilon$-ranking differential privacy. Theoretical results regarding the utility of synthetic rankings in the downstream tasks, including the inference attack and the personalized ranking tasks, are established. For the inference attack, we quantify how $\\epsilon$ affects the estimation of the true ranking based on synthetic rankings. For the personalized ranking task, we consider varying privacy preferences among users and quantify how their privacy preferences affect the consistency in estimating the optimal ranking function. Extensive numerical experiments are carried out to verify the theoretical results and demonstrate the effectiveness of the proposed synthetic ranking algorithm.","link":"http://arxiv.org/abs/2301.00841v1","created":"2023-01-02","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Ranking Differential Privacy Rankings are widely collected in various real-life scenarios, leading to the leakage of personal information such as users' preferences on videos or news. To protect rankings, existing works mainly develop privacy protection on a single ranking within a set of ranking or pairwise comparisons of a ranking under the $\\epsilon$-differential privacy. This paper proposes a novel notion called $\\epsilon$-ranking differential privacy for protecting ranks. We establish the connection between the Mallows model (Mallows, 1957) and the proposed $\\epsilon$-ranking differential privacy. This allows us to develop a multistage ranking algorithm to generate synthetic rankings while satisfying the developed $\\epsilon$-ranking differential privacy. Theoretical results regarding the utility of synthetic rankings in the downstream tasks, including the inference attack and the personalized ranking tasks, are established. For the inference attack, we quantify how $\\epsilon$ affects the estimation of the true ranking based on synthetic rankings. For the personalized ranking task, we consider varying privacy preferences among users and quantify how their privacy preferences affect the consistency in estimating the optimal ranking function. Extensive numerical experiments are carried out to verify the theoretical results and demonstrate the effectiveness of the proposed synthetic ranking algorithm.","classes":{"dataset":0.1062952876}}
{"title":"Local Differential Privacy for Sequential Decision Making in a Changing Environment","description":"We study the problem of preserving privacy while still providing high utility in sequential decision making scenarios in a changing environment. We consider abruptly changing environment: the environment remains constant during periods and it changes at unknown time instants. To formulate this problem, we propose a variant of multi-armed bandits called non-stationary stochastic corrupt bandits. We construct an algorithm called SW-KLUCB-CF and prove an upper bound on its utility using the performance measure of regret. The proven regret upper bound for SW-KLUCB-CF is near-optimal in the number of time steps and matches the best known bound for analogous problems in terms of the number of time steps and the number of changes. Moreover, we present a provably optimal mechanism which can guarantee the desired level of local differential privacy while providing high utility.","link":"http://arxiv.org/abs/2301.00561v1","created":"2023-01-02","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"Local Differential Privacy for Sequential Decision Making in a Changing Environment We study the problem of preserving privacy while still providing high utility in sequential decision making scenarios in a changing environment. We consider abruptly changing environment: the environment remains constant during periods and it changes at unknown time instants. To formulate this problem, we propose a variant of multi-armed bandits called non-stationary stochastic corrupt bandits. We construct an algorithm called SW-KLUCB-CF and prove an upper bound on its utility using the performance measure of regret. The proven regret upper bound for SW-KLUCB-CF is near-optimal in the number of time steps and matches the best known bound for analogous problems in terms of the number of time steps and the number of changes. Moreover, we present a provably optimal mechanism which can guarantee the desired level of local differential privacy while providing high utility.","classes":{"dataset":0.0392449535}}
{"title":"ReSQueing Parallel and Private Stochastic Convex Optimization","description":"We introduce a new tool for stochastic convex optimization (SCO): a Reweighted Stochastic Query (ReSQue) estimator for the gradient of a function convolved with a (Gaussian) probability density. Combining ReSQue with recent advances in ball oracle acceleration [CJJJLST20, ACJJS21], we develop algorithms achieving state-of-the-art complexities for SCO in parallel and private settings. For a SCO objective constrained to the unit ball in $\\mathbb{R}^d$, we obtain the following results (up to polylogarithmic factors). We give a parallel algorithm obtaining optimization error $\\epsilon_{\\text{opt}}$ with $d^{1/3}\\epsilon_{\\text{opt}}^{-2/3}$ gradient oracle query depth and $d^{1/3}\\epsilon_{\\text{opt}}^{-2/3} + \\epsilon_{\\text{opt}}^{-2}$ gradient queries in total, assuming access to a bounded-variance stochastic gradient estimator. For $\\epsilon_{\\text{opt}} \\in [d^{-1}, d^{-1/4}]$, our algorithm matches the state-of-the-art oracle depth of [BJLLS19] while maintaining the optimal total work of stochastic gradient descent. We give an $(\\epsilon_{\\text{dp}}, \\delta)$-differentially private algorithm which, given $n$ samples of Lipschitz loss functions, obtains near-optimal optimization error and makes $\\min(n, n^2\\epsilon_{\\text{dp}}^2 d^{-1}) + \\min(n^{4/3}\\epsilon_{\\text{dp}}^{1/3}, (nd)^{2/3}\\epsilon_{\\text{dp}}^{-1})$ queries to the gradients of these functions. In the regime $d \\le n \\epsilon_{\\text{dp}}^{2}$, where privacy comes at no cost in terms of the optimal loss up to constants, our algorithm uses $n + (nd)^{2/3}\\epsilon_{\\text{dp}}^{-1}$ queries and improves recent advancements of [KLL21, AFKT21]. In the moderately low-dimensional setting $d \\le \\sqrt n \\epsilon_{\\text{dp}}^{3/2}$, our query complexity is near-linear.","link":"http://arxiv.org/abs/2301.00457v1","created":"2023-01-01","tags":["arxiv","ml","security"],"meta":{"query":"machine AND learning AND security OR machine AND learning AND secure"},"text":"ReSQueing Parallel and Private Stochastic Convex Optimization We introduce a new tool for stochastic convex optimization (SCO): a Reweighted Stochastic Query (ReSQue) estimator for the gradient of a function convolved with a (Gaussian) probability density. Combining ReSQue with recent advances in ball oracle acceleration [CJJJLST20, ACJJS21], we develop algorithms achieving state-of-the-art complexities for SCO in parallel and private settings. For a SCO objective constrained to the unit ball in $\\mathbb{R}^d$, we obtain the following results (up to polylogarithmic factors). We give a parallel algorithm obtaining optimization error $\\epsilon_{\\text{opt}}$ with $d^{1/3}\\epsilon_{\\text{opt}}^{-2/3}$ gradient oracle query depth and $d^{1/3}\\epsilon_{\\text{opt}}^{-2/3} + \\epsilon_{\\text{opt}}^{-2}$ gradient queries in total, assuming access to a bounded-variance stochastic gradient estimator. For $\\epsilon_{\\text{opt}} \\in [d^{-1}, d^{-1/4}]$, our algorithm matches the state-of-the-art oracle depth of [BJLLS19] while maintaining the optimal total work of stochastic gradient descent. We give an $(\\epsilon_{\\text{dp}}, \\delta)$-differentially private algorithm which, given $n$ samples of Lipschitz loss functions, obtains near-optimal optimization error and makes $\\min(n, n^2\\epsilon_{\\text{dp}}^2 d^{-1}) + \\min(n^{4/3}\\epsilon_{\\text{dp}}^{1/3}, (nd)^{2/3}\\epsilon_{\\text{dp}}^{-1})$ queries to the gradients of these functions. In the regime $d \\le n \\epsilon_{\\text{dp}}^{2}$, where privacy comes at no cost in terms of the optimal loss up to constants, our algorithm uses $n + (nd)^{2/3}\\epsilon_{\\text{dp}}^{-1}$ queries and improves recent advancements of [KLL21, AFKT21]. In the moderately low-dimensional setting $d \\le \\sqrt n \\epsilon_{\\text{dp}}^{3/2}$, our query complexity is near-linear.","classes":{"dataset":0.1999113113}}
{"title":"Ordinal Regression for Difficulty Estimation of StepMania Levels","description":"StepMania is a popular open-source clone of a rhythm-based video game. As is common in popular games, there is a large number of community-designed levels. It is often difficult for players and level authors to determine the difficulty level of such community contributions. In this work, we formalize and analyze the difficulty prediction task on StepMania levels as an ordinal regression (OR) task. We standardize a more extensive and diverse selection of this data resulting in five data sets, two of which are extensions of previous work. We evaluate many competitive OR and non-OR models, demonstrating that neural network-based models significantly outperform the state of the art and that StepMania-level data makes for an excellent test bed for deep OR models. We conclude with a user experiment showing our trained models' superiority over human labeling.","link":"http://arxiv.org/abs/2301.09485v1","created":"2023-01-23","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Ordinal Regression for Difficulty Estimation of StepMania Levels StepMania is a popular open-source clone of a rhythm-based video game. As is common in popular games, there is a large number of community-designed levels. It is often difficult for players and level authors to determine the difficulty level of such community contributions. In this work, we formalize and analyze the difficulty prediction task on StepMania levels as an ordinal regression (OR) task. We standardize a more extensive and diverse selection of this data resulting in five data sets, two of which are extensions of previous work. We evaluate many competitive OR and non-OR models, demonstrating that neural network-based models significantly outperform the state of the art and that StepMania-level data makes for an excellent test bed for deep OR models. We conclude with a user experiment showing our trained models' superiority over human labeling.","classes":{"dataset":0.1559313983}}
{"title":"Random forests, sound symbolism and Pokemon evolution","description":"This study constructs machine learning algorithms that are trained to classify samples using sound symbolism, and then it reports on an experiment designed to measure their understanding against human participants. Random forests are trained using the names of Pokemon, which are fictional video game characters, and their evolutionary status. Pokemon undergo evolution when certain in-game conditions are met. Evolution changes the appearance, abilities, and names of Pokemon. In the first experiment, we train three random forests using the sounds that make up the names of Japanese, Chinese, and Korean Pokemon to classify Pokemon into pre-evolution and post-evolution categories. We then train a fourth random forest using the results of an elicitation experiment whereby Japanese participants named previously unseen Pokemon. In Experiment 2, we reproduce those random forests with name length as a feature and compare the performance of the random forests against humans in a classification experiment whereby Japanese participants classified the names elicited in Experiment 1 into pre-and post-evolution categories. Experiment 2 reveals an issue pertaining to overfitting in Experiment 1 which we resolve using a novel cross-validation method. The results show that the random forests are efficient learners of systematic sound-meaning correspondence patterns and can classify samples with greater accuracy than the human participants.","link":"http://arxiv.org/abs/2301.01948v1","created":"2023-01-05","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Random forests, sound symbolism and Pokemon evolution This study constructs machine learning algorithms that are trained to classify samples using sound symbolism, and then it reports on an experiment designed to measure their understanding against human participants. Random forests are trained using the names of Pokemon, which are fictional video game characters, and their evolutionary status. Pokemon undergo evolution when certain in-game conditions are met. Evolution changes the appearance, abilities, and names of Pokemon. In the first experiment, we train three random forests using the sounds that make up the names of Japanese, Chinese, and Korean Pokemon to classify Pokemon into pre-evolution and post-evolution categories. We then train a fourth random forest using the results of an elicitation experiment whereby Japanese participants named previously unseen Pokemon. In Experiment 2, we reproduce those random forests with name length as a feature and compare the performance of the random forests against humans in a classification experiment whereby Japanese participants classified the names elicited in Experiment 1 into pre-and post-evolution categories. Experiment 2 reveals an issue pertaining to overfitting in Experiment 1 which we resolve using a novel cross-validation method. The results show that the random forests are efficient learners of systematic sound-meaning correspondence patterns and can classify samples with greater accuracy than the human participants.","classes":{"dataset":0.3654015362}}
{"title":"Teamwork under extreme uncertainty: AI for Pokemon ranks 33rd in the world","description":"The highest grossing media franchise of all times, with over \\$90 billion in total revenue, is Pokemon. The video games belong to the class of Japanese Role Playing Games (J-RPG). Developing a powerful AI agent for these games is very hard because they present big challenges to MinMax, Monte Carlo Tree Search and statistical Machine Learning, as they are vastly different from the well explored in AI literature games. An AI agent for one of these games means significant progress in AI agents for the entire class. Further, the key principles of such work can hopefully inspire approaches to several domains that require excellent teamwork under conditions of extreme uncertainty, including managing a team of doctors, robots or employees in an ever changing environment, like a pandemic stricken region or a war-zone. In this paper we first explain the mechanics of the game and we perform a game analysis. We continue by proposing unique AI algorithms based on our understanding that the two biggest challenges in the game are keeping a balanced team and dealing with three sources of uncertainty. Later on, we describe why evaluating the performance of such agents is challenging and we present the results of our approach. Our AI agent performed significantly better than all previous attempts and peaked at the 33rd place in the world, in one of the most popular battle formats, while running on only 4 single socket servers.","link":"http://arxiv.org/abs/2212.13338v2","created":"2022-12-27","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Teamwork under extreme uncertainty: AI for Pokemon ranks 33rd in the world The highest grossing media franchise of all times, with over \\$90 billion in total revenue, is Pokemon. The video games belong to the class of Japanese Role Playing Games (J-RPG). Developing a powerful AI agent for these games is very hard because they present big challenges to MinMax, Monte Carlo Tree Search and statistical Machine Learning, as they are vastly different from the well explored in AI literature games. An AI agent for one of these games means significant progress in AI agents for the entire class. Further, the key principles of such work can hopefully inspire approaches to several domains that require excellent teamwork under conditions of extreme uncertainty, including managing a team of doctors, robots or employees in an ever changing environment, like a pandemic stricken region or a war-zone. In this paper we first explain the mechanics of the game and we perform a game analysis. We continue by proposing unique AI algorithms based on our understanding that the two biggest challenges in the game are keeping a balanced team and dealing with three sources of uncertainty. Later on, we describe why evaluating the performance of such agents is challenging and we present the results of our approach. Our AI agent performed significantly better than all previous attempts and peaked at the 33rd place in the world, in one of the most popular battle formats, while running on only 4 single socket servers.","classes":{"dataset":0.5740508437}}
{"title":"TransPath: Learning Heuristics For Grid-Based Pathfinding via Transformers","description":"Heuristic search algorithms, e.g. A*, are the commonly used tools for pathfinding on grids, i.e. graphs of regular structure that are widely employed to represent environments in robotics, video games etc. Instance-independent heuristics for grid graphs, e.g. Manhattan distance, do not take the obstacles into account and, thus, the search led by such heuristics performs poorly in the obstacle-rich environments. To this end, we suggest learning the instance-dependent heuristic proxies that are supposed to notably increase the efficiency of the search. The first heuristic proxy we suggest to learn is the correction factor, i.e. the ratio between the instance independent cost-to-go estimate and the perfect one (computed offline at the training phase). Unlike learning the absolute values of the cost-to-go heuristic function, which was known before, when learning the correction factor the knowledge of the instance-independent heuristic is utilized. The second heuristic proxy is the path probability, which indicates how likely the grid cell is lying on the shortest path. This heuristic can be utilized in the Focal Search framework as the secondary heuristic, allowing us to preserve the guarantees on the bounded sub-optimality of the solution. We learn both suggested heuristics in a supervised fashion with the state-of-the-art neural networks containing attention blocks (transformers). We conduct a thorough empirical evaluation on a comprehensive dataset of planning tasks, showing that the suggested techniques i) reduce the computational effort of the A* up to a factor of $4$x while producing the solutions, which costs exceed the costs of the optimal solutions by less than $0.3$% on average; ii) outperform the competitors, which include the conventional techniques from the heuristic search, i.e. weighted A*, as well as the state-of-the-art learnable planners.","link":"http://arxiv.org/abs/2212.11730v1","created":"2022-12-22","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"TransPath: Learning Heuristics For Grid-Based Pathfinding via Transformers Heuristic search algorithms, e.g. A*, are the commonly used tools for pathfinding on grids, i.e. graphs of regular structure that are widely employed to represent environments in robotics, video games etc. Instance-independent heuristics for grid graphs, e.g. Manhattan distance, do not take the obstacles into account and, thus, the search led by such heuristics performs poorly in the obstacle-rich environments. To this end, we suggest learning the instance-dependent heuristic proxies that are supposed to notably increase the efficiency of the search. The first heuristic proxy we suggest to learn is the correction factor, i.e. the ratio between the instance independent cost-to-go estimate and the perfect one (computed offline at the training phase). Unlike learning the absolute values of the cost-to-go heuristic function, which was known before, when learning the correction factor the knowledge of the instance-independent heuristic is utilized. The second heuristic proxy is the path probability, which indicates how likely the grid cell is lying on the shortest path. This heuristic can be utilized in the Focal Search framework as the secondary heuristic, allowing us to preserve the guarantees on the bounded sub-optimality of the solution. We learn both suggested heuristics in a supervised fashion with the state-of-the-art neural networks containing attention blocks (transformers). We conduct a thorough empirical evaluation on a comprehensive dataset of planning tasks, showing that the suggested techniques i) reduce the computational effort of the A* up to a factor of $4$x while producing the solutions, which costs exceed the costs of the optimal solutions by less than $0.3$% on average; ii) outperform the competitors, which include the conventional techniques from the heuristic search, i.e. weighted A*, as well as the state-of-the-art learnable planners.","classes":{"dataset":0.2613376379}}
{"title":"Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion Behaviors in Social Deduction Games","description":"Persuasion modeling is a key building block for conversational agents. Existing works in this direction are limited to analyzing textual dialogue corpus. We argue that visual signals also play an important role in understanding human persuasive behaviors. In this paper, we introduce the first multimodal dataset for modeling persuasion behaviors. Our dataset includes 199 dialogue transcriptions and videos captured in a multi-player social deduction game setting, 26,647 utterance level annotations of persuasion strategy, and game level annotations of deduction game outcomes. We provide extensive experiments to show how dialogue context and visual signals benefit persuasion strategy prediction. We also explore the generalization ability of language models for persuasion modeling and the role of persuasion strategies in predicting social deduction game outcomes. Our dataset, code, and models can be found at https://persuasion-deductiongame.socialai-data.org.","link":"http://arxiv.org/abs/2212.08279v1","created":"2022-12-16","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion Behaviors in Social Deduction Games Persuasion modeling is a key building block for conversational agents. Existing works in this direction are limited to analyzing textual dialogue corpus. We argue that visual signals also play an important role in understanding human persuasive behaviors. In this paper, we introduce the first multimodal dataset for modeling persuasion behaviors. Our dataset includes 199 dialogue transcriptions and videos captured in a multi-player social deduction game setting, 26,647 utterance level annotations of persuasion strategy, and game level annotations of deduction game outcomes. We provide extensive experiments to show how dialogue context and visual signals benefit persuasion strategy prediction. We also explore the generalization ability of language models for persuasion modeling and the role of persuasion strategies in predicting social deduction game outcomes. Our dataset, code, and models can be found at https://persuasion-deductiongame.socialai-data.org.","classes":{"dataset":0.3974004388}}
{"title":"Efficient Exploration in Resource-Restricted Reinforcement Learning","description":"In many real-world applications of reinforcement learning (RL), performing actions requires consuming certain types of resources that are non-replenishable in each episode. Typical applications include robotic control with limited energy and video games with consumable items. In tasks with non-replenishable resources, we observe that popular RL methods such as soft actor critic suffer from poor sample efficiency. The major reason is that, they tend to exhaust resources fast and thus the subsequent exploration is severely restricted due to the absence of resources. To address this challenge, we first formalize the aforementioned problem as a resource-restricted reinforcement learning, and then propose a novel resource-aware exploration bonus (RAEB) to make reasonable usage of resources. An appealing feature of RAEB is that, it can significantly reduce unnecessary resource-consuming trials while effectively encouraging the agent to explore unvisited states. Experiments demonstrate that the proposed RAEB significantly outperforms state-of-the-art exploration strategies in resource-restricted reinforcement learning environments, improving the sample efficiency by up to an order of magnitude.","link":"http://arxiv.org/abs/2212.06988v1","created":"2022-12-14","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Efficient Exploration in Resource-Restricted Reinforcement Learning In many real-world applications of reinforcement learning (RL), performing actions requires consuming certain types of resources that are non-replenishable in each episode. Typical applications include robotic control with limited energy and video games with consumable items. In tasks with non-replenishable resources, we observe that popular RL methods such as soft actor critic suffer from poor sample efficiency. The major reason is that, they tend to exhaust resources fast and thus the subsequent exploration is severely restricted due to the absence of resources. To address this challenge, we first formalize the aforementioned problem as a resource-restricted reinforcement learning, and then propose a novel resource-aware exploration bonus (RAEB) to make reasonable usage of resources. An appealing feature of RAEB is that, it can significantly reduce unnecessary resource-consuming trials while effectively encouraging the agent to explore unvisited states. Experiments demonstrate that the proposed RAEB significantly outperforms state-of-the-art exploration strategies in resource-restricted reinforcement learning environments, improving the sample efficiency by up to an order of magnitude.","classes":{"dataset":0.5522925258}}
{"title":"Location analysis of players in UEFA EURO 2020 and 2022 using generalized valuation of defense by estimating probabilities","description":"Analyzing defenses in team sports is generally challenging because of the limited event data. Researchers have previously proposed methods to evaluate football team defense by predicting the events of ball gain and being attacked using locations of all players and the ball. However, they did not consider the importance of the events, assumed the perfect observation of all 22 players, and did not fully investigated the influence of the diversity (e.g., nationality and sex). Here, we propose a generalized valuation method of defensive teams by score-scaling the predicted probabilities of the events. Using the open-source location data of all players in broadcast video frames in football games of men's Euro 2020 and women's Euro 2022, we investigated the effect of the number of players on the prediction and validated our approach by analyzing the games. Results show that for the predictions of being attacked, scoring, and conceding, all players' information was not necessary, while that of ball gain required information on three to four offensive and defensive players. With game analyses we explained the excellence in defense of finalist teams in Euro 2020. Our approach might be applicable to location data from broadcast video frames in football games.","link":"http://arxiv.org/abs/2212.00021v1","created":"2022-11-30","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Location analysis of players in UEFA EURO 2020 and 2022 using generalized valuation of defense by estimating probabilities Analyzing defenses in team sports is generally challenging because of the limited event data. Researchers have previously proposed methods to evaluate football team defense by predicting the events of ball gain and being attacked using locations of all players and the ball. However, they did not consider the importance of the events, assumed the perfect observation of all 22 players, and did not fully investigated the influence of the diversity (e.g., nationality and sex). Here, we propose a generalized valuation method of defensive teams by score-scaling the predicted probabilities of the events. Using the open-source location data of all players in broadcast video frames in football games of men's Euro 2020 and women's Euro 2022, we investigated the effect of the number of players on the prediction and validated our approach by analyzing the games. Results show that for the predictions of being attacked, scoring, and conceding, all players' information was not necessary, while that of ball gain required information on three to four offensive and defensive players. With game analyses we explained the excellence in defense of finalist teams in Euro 2020. Our approach might be applicable to location data from broadcast video frames in football games.","classes":{"dataset":0.7378762364}}
{"title":"Configurable Agent With Reward As Input: A Play-Style Continuum Generation","description":"Modern video games are becoming richer and more complex in terms of game mechanics. This complexity allows for the emergence of a wide variety of ways to play the game across the players. From the point of view of the game designer, this means that one needs to anticipate a lot of different ways the game could be played. Machine Learning (ML) could help address this issue. More precisely, Reinforcement Learning is a promising answer to the need of automating video game testing. In this paper we present a video game environment which lets us define multiple play-styles. We then introduce CARI: a Configurable Agent with Reward as Input. An agent able to simulate a wide continuum range of play-styles. It is not constrained to extreme archetypal behaviors like current methods using reward shaping. In addition it achieves this through a single training loop, instead of the usual one loop per play-style. We compare this novel training approach with the more classic reward shaping approach and conclude that CARI can also outperform the baseline on archetypes generation. This novel agent could be used to investigate behaviors and balancing during the production of a video game with a realistic amount of training time.","link":"http://arxiv.org/abs/2211.16221v1","created":"2022-11-29","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Configurable Agent With Reward As Input: A Play-Style Continuum Generation Modern video games are becoming richer and more complex in terms of game mechanics. This complexity allows for the emergence of a wide variety of ways to play the game across the players. From the point of view of the game designer, this means that one needs to anticipate a lot of different ways the game could be played. Machine Learning (ML) could help address this issue. More precisely, Reinforcement Learning is a promising answer to the need of automating video game testing. In this paper we present a video game environment which lets us define multiple play-styles. We then introduce CARI: a Configurable Agent with Reward as Input. An agent able to simulate a wide continuum range of play-styles. It is not constrained to extreme archetypal behaviors like current methods using reward shaping. In addition it achieves this through a single training loop, instead of the usual one loop per play-style. We compare this novel training approach with the more classic reward shaping approach and conclude that CARI can also outperform the baseline on archetypes generation. This novel agent could be used to investigate behaviors and balancing during the production of a video game with a realistic amount of training time.","classes":{"dataset":0.3606984615}}
{"title":"Multi-Environment Pretraining Enables Transfer to Action Limited Datasets","description":"Using massive datasets to train large-scale models has emerged as a dominant approach for broad generalization in natural language and vision applications. In reinforcement learning, however, a key challenge is that available data of sequential decision making is often not annotated with actions - for example, videos of game-play are much more available than sequences of frames paired with their logged game controls. We propose to circumvent this challenge by combining large but sparsely-annotated datasets from a \\emph{target} environment of interest with fully-annotated datasets from various other \\emph{source} environments. Our method, Action Limited PreTraining (ALPT), leverages the generalization capabilities of inverse dynamics modelling (IDM) to label missing action data in the target environment. We show that utilizing even one additional environment dataset of labelled data during IDM pretraining gives rise to substantial improvements in generating action labels for unannotated sequences. We evaluate our method on benchmark game-playing environments and show that we can significantly improve game performance and generalization capability compared to other approaches, using annotated datasets equivalent to only $12$ minutes of gameplay. Highlighting the power of IDM, we show that these benefits remain even when target and source environments share no common actions.","link":"http://arxiv.org/abs/2211.13337v2","created":"2022-11-23","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Multi-Environment Pretraining Enables Transfer to Action Limited Datasets Using massive datasets to train large-scale models has emerged as a dominant approach for broad generalization in natural language and vision applications. In reinforcement learning, however, a key challenge is that available data of sequential decision making is often not annotated with actions - for example, videos of game-play are much more available than sequences of frames paired with their logged game controls. We propose to circumvent this challenge by combining large but sparsely-annotated datasets from a \\emph{target} environment of interest with fully-annotated datasets from various other \\emph{source} environments. Our method, Action Limited PreTraining (ALPT), leverages the generalization capabilities of inverse dynamics modelling (IDM) to label missing action data in the target environment. We show that utilizing even one additional environment dataset of labelled data during IDM pretraining gives rise to substantial improvements in generating action labels for unannotated sequences. We evaluate our method on benchmark game-playing environments and show that we can significantly improve game performance and generalization capability compared to other approaches, using annotated datasets equivalent to only $12$ minutes of gameplay. Highlighting the power of IDM, we show that these benefits remain even when target and source environments share no common actions.","classes":{"dataset":0.5677127838}}
{"title":"YM2413-MDB: A Multi-Instrumental FM Video Game Music Dataset with Emotion Annotations","description":"Existing multi-instrumental datasets tend to be biased toward pop and classical music. In addition, they generally lack high-level annotations such as emotion tags. In this paper, we propose YM2413-MDB, an 80s FM video game music dataset with multi-label emotion annotations. It includes 669 audio and MIDI files of music from Sega and MSX PC games in the 80s using YM2413, a programmable sound generator based on FM. The collected game music is arranged with a subset of 15 monophonic instruments and one drum instrument. They were converted from binary commands of the YM2413 sound chip. Each song was labeled with 19 emotion tags by two annotators and validated by three verifiers to obtain refined tags. We provide the baseline models and results for emotion recognition and emotion-conditioned symbolic music generation using YM2413-MDB.","link":"http://arxiv.org/abs/2211.07131v1","created":"2022-11-14","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"YM2413-MDB: A Multi-Instrumental FM Video Game Music Dataset with Emotion Annotations Existing multi-instrumental datasets tend to be biased toward pop and classical music. In addition, they generally lack high-level annotations such as emotion tags. In this paper, we propose YM2413-MDB, an 80s FM video game music dataset with multi-label emotion annotations. It includes 669 audio and MIDI files of music from Sega and MSX PC games in the 80s using YM2413, a programmable sound generator based on FM. The collected game music is arranged with a subset of 15 monophonic instruments and one drum instrument. They were converted from binary commands of the YM2413 sound chip. Each song was labeled with 19 emotion tags by two annotators and validated by three verifiers to obtain refined tags. We provide the baseline models and results for emotion recognition and emotion-conditioned symbolic music generation using YM2413-MDB.","classes":{"dataset":0.6814739704}}
{"title":"Proceedings of the Fourth International Conference on Applied Category Theory","description":"The Fourth International Conference on Applied Category Theory took place at the Computer Laboratory of the University of Cambridge on 12--16 July 2021. It was a hybrid event, with physical attendees present in Cambridge and other participants taking part online. All the talks were recorded and the videos have been posted online, links to which can be found on the conference website (https://www.cl.cam.ac.uk/events/act2021/).   Continuing the trend in the previous meetings of ACT, the contributions to ACT 2021 ranged from pure to applied and represented a great variety of categorical techniques and application topics, including: graphical calculi; lenses; differential categories; categorical probability theory; machine learning; game theory; cybernetics; natural language semantics and processing; cryptography; and finite model theory.   This proceedings volume contains about half of the papers that were presented as talks at ACT 2021. This selection is a reflection of the authors' choice as to whether to publish their papers in this volume or elsewhere.","link":"http://arxiv.org/abs/2211.01102v1","created":"2022-10-31","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Proceedings of the Fourth International Conference on Applied Category Theory The Fourth International Conference on Applied Category Theory took place at the Computer Laboratory of the University of Cambridge on 12--16 July 2021. It was a hybrid event, with physical attendees present in Cambridge and other participants taking part online. All the talks were recorded and the videos have been posted online, links to which can be found on the conference website (https://www.cl.cam.ac.uk/events/act2021/).   Continuing the trend in the previous meetings of ACT, the contributions to ACT 2021 ranged from pure to applied and represented a great variety of categorical techniques and application topics, including: graphical calculi; lenses; differential categories; categorical probability theory; machine learning; game theory; cybernetics; natural language semantics and processing; cryptography; and finite model theory.   This proceedings volume contains about half of the papers that were presented as talks at ACT 2021. This selection is a reflection of the authors' choice as to whether to publish their papers in this volume or elsewhere.","classes":{"dataset":0.3447844386}}
{"title":"Causal DAG extraction from a library of books or videos/movies","description":"Determining a causal DAG (directed acyclic graph) for a problem under consideration, is a major roadblock when doing Judea Pearl's Causal Inference (CI) in Statistics. The same problem arises when doing CI in Artificial Intelligence (AI) and Machine Learning (ML). As with many problems in Science, we think Nature has found an effective solution to this problem. We argue that human and animal brains contain an explicit engine for doing CI, and that such an engine uses as input an atlas (i.e., collection) of causal DAGs. We propose a simple algorithm for constructing such an atlas from a library of books or videos/movies. We illustrate our method by applying it to a database of randomly generated Tic-Tac-Toe games. The software used to generate this Tic-Tac-Toe example is open source and available at GitHub.","link":"http://arxiv.org/abs/2211.00486v1","created":"2022-10-29","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Causal DAG extraction from a library of books or videos/movies Determining a causal DAG (directed acyclic graph) for a problem under consideration, is a major roadblock when doing Judea Pearl's Causal Inference (CI) in Statistics. The same problem arises when doing CI in Artificial Intelligence (AI) and Machine Learning (ML). As with many problems in Science, we think Nature has found an effective solution to this problem. We argue that human and animal brains contain an explicit engine for doing CI, and that such an engine uses as input an atlas (i.e., collection) of causal DAGs. We propose a simple algorithm for constructing such an atlas from a library of books or videos/movies. We illustrate our method by applying it to a database of randomly generated Tic-Tac-Toe games. The software used to generate this Tic-Tac-Toe example is open source and available at GitHub.","classes":{"dataset":0.0859531984}}
{"title":"A new activation for neural networks and its approximation","description":"Deep learning with deep neural networks (DNNs) has attracted tremendous attention from various fields of science and technology recently. Activation functions for a DNN define the output of a neuron given an input or set of inputs. They are essential and inevitable in learning non-linear transformations and performing diverse computations among successive neuron layers. Thus, the design of activation functions is still an important topic in deep learning research. Meanwhile, theoretical studies on the approximation ability of DNNs with activation functions have been investigated within the last few years. In this paper, we propose a new activation function, named as \"DLU\", and investigate its approximation ability for functions with various smoothness and structures. Our theoretical results show that DLU networks can process competitive approximation performance with rational and ReLU networks, and have some advantages. Numerical experiments are conducted comparing DLU with the existing activations-ReLU, Leaky ReLU, and ELU, which illustrate the good practical performance of DLU.","link":"http://arxiv.org/abs/2210.10264v1","created":"2022-10-19","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"A new activation for neural networks and its approximation Deep learning with deep neural networks (DNNs) has attracted tremendous attention from various fields of science and technology recently. Activation functions for a DNN define the output of a neuron given an input or set of inputs. They are essential and inevitable in learning non-linear transformations and performing diverse computations among successive neuron layers. Thus, the design of activation functions is still an important topic in deep learning research. Meanwhile, theoretical studies on the approximation ability of DNNs with activation functions have been investigated within the last few years. In this paper, we propose a new activation function, named as \"DLU\", and investigate its approximation ability for functions with various smoothness and structures. Our theoretical results show that DLU networks can process competitive approximation performance with rational and ReLU networks, and have some advantages. Numerical experiments are conducted comparing DLU with the existing activations-ReLU, Leaky ReLU, and ELU, which illustrate the good practical performance of DLU.","classes":{"dataset":0.1568847895}}
{"title":"Attribute Inference Attacks in Online Multiplayer Video Games: a Case Study on Dota2","description":"Did you know that over 70 million of Dota2 players have their in-game data freely accessible? What if such data is used in malicious ways? This paper is the first to investigate such a problem.   Motivated by the widespread popularity of video games, we propose the first threat model for Attribute Inference Attacks (AIA) in the Dota2 context. We explain how (and why) attackers can exploit the abundant public data in the Dota2 ecosystem to infer private information about its players. Due to lack of concrete evidence on the efficacy of our AIA, we empirically prove and assess their impact in reality. By conducting an extensive survey on $\\sim$500 Dota2 players spanning over 26k matches, we verify whether a correlation exists between a player's Dota2 activity and their real-life. Then, after finding such a link ($p$ < 0.01 and $\\rho$ > 0.3), we ethically perform diverse AIA. We leverage the capabilities of machine learning to infer real-life attributes of the respondents of our survey by using their publicly available in-game data. Our results show that, by applyingdomain expertise, some AIA can reach up to 98% precision and over 90% accuracy. This paper hence raises the alarm on a subtle, but concrete threat that can potentially affect the entire competitive gaming landscape. We alerted the developers of Dota2.","link":"http://arxiv.org/abs/2210.09028v4","created":"2022-10-17","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Attribute Inference Attacks in Online Multiplayer Video Games: a Case Study on Dota2 Did you know that over 70 million of Dota2 players have their in-game data freely accessible? What if such data is used in malicious ways? This paper is the first to investigate such a problem.   Motivated by the widespread popularity of video games, we propose the first threat model for Attribute Inference Attacks (AIA) in the Dota2 context. We explain how (and why) attackers can exploit the abundant public data in the Dota2 ecosystem to infer private information about its players. Due to lack of concrete evidence on the efficacy of our AIA, we empirically prove and assess their impact in reality. By conducting an extensive survey on $\\sim$500 Dota2 players spanning over 26k matches, we verify whether a correlation exists between a player's Dota2 activity and their real-life. Then, after finding such a link ($p$ < 0.01 and $\\rho$ > 0.3), we ethically perform diverse AIA. We leverage the capabilities of machine learning to infer real-life attributes of the respondents of our survey by using their publicly available in-game data. Our results show that, by applyingdomain expertise, some AIA can reach up to 98% precision and over 90% accuracy. This paper hence raises the alarm on a subtle, but concrete threat that can potentially affect the entire competitive gaming landscape. We alerted the developers of Dota2.","classes":{"dataset":0.4567679465}}
{"title":"Online Policy Optimization for Robust MDP","description":"Reinforcement learning (RL) has exceeded human performance in many synthetic settings such as video games and Go. However, real-world deployment of end-to-end RL models is less common, as RL models can be very sensitive to slight perturbation of the environment. The robust Markov decision process (MDP) framework -- in which the transition probabilities belong to an uncertainty set around a nominal model -- provides one way to develop robust models. While previous analysis shows RL algorithms are effective assuming access to a generative model, it remains unclear whether RL can be efficient under a more realistic online setting, which requires a careful balance between exploration and exploitation. In this work, we consider online robust MDP by interacting with an unknown nominal system. We propose a robust optimistic policy optimization algorithm that is provably efficient. To address the additional uncertainty caused by an adversarial environment, our model features a new optimistic update rule derived via Fenchel conjugates. Our analysis establishes the first regret bound for online robust MDPs.","link":"http://arxiv.org/abs/2209.13841v1","created":"2022-09-28","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Online Policy Optimization for Robust MDP Reinforcement learning (RL) has exceeded human performance in many synthetic settings such as video games and Go. However, real-world deployment of end-to-end RL models is less common, as RL models can be very sensitive to slight perturbation of the environment. The robust Markov decision process (MDP) framework -- in which the transition probabilities belong to an uncertainty set around a nominal model -- provides one way to develop robust models. While previous analysis shows RL algorithms are effective assuming access to a generative model, it remains unclear whether RL can be efficient under a more realistic online setting, which requires a careful balance between exploration and exploitation. In this work, we consider online robust MDP by interacting with an unknown nominal system. We propose a robust optimistic policy optimization algorithm that is provably efficient. To address the additional uncertainty caused by an adversarial environment, our model features a new optimistic update rule derived via Fenchel conjugates. Our analysis establishes the first regret bound for online robust MDPs.","classes":{"dataset":0.1431203187}}
{"title":"Applications of Machine Learning in Chemical and Biological Oceanography","description":"Machine learning (ML) refers to computer algorithms that predict a meaningful output or categorise complex systems based on a large amount of data. ML applied in a variety of areas, including natural science, engineering, space exploration, and even gaming development. This article focused on the use of machine learning in the field of chemical and biological oceanography. In the prediction of global fixed nitrogen levels, partial carbon dioxide pressure, and other chemical properties, the application of ML is a promising tool. Machine learning is also utilised in the field of biological oceanography to detect planktonic forms from various images (i.e., microscopy, FlowCAM and video recorder), spectrometers, and other signal processing techniques. Moreover, ML successfully classified the mammals using their acoustics, detecting endangered mammalian and fish species in a specific environment. Most importantly, using environmental data, the ML proved to be an effective method for predicting hypoxic conditions and the harmful algal bloom events, an important measurement in terms of environmental monitoring. Furthermore, machine learning was used to construct a number of databases for various species that will be useful to other researchers, and the creation of new algorithms will help the marine research community better comprehend the chemistry and biology of the ocean.","link":"http://arxiv.org/abs/2209.11557v1","created":"2022-09-23","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Applications of Machine Learning in Chemical and Biological Oceanography Machine learning (ML) refers to computer algorithms that predict a meaningful output or categorise complex systems based on a large amount of data. ML applied in a variety of areas, including natural science, engineering, space exploration, and even gaming development. This article focused on the use of machine learning in the field of chemical and biological oceanography. In the prediction of global fixed nitrogen levels, partial carbon dioxide pressure, and other chemical properties, the application of ML is a promising tool. Machine learning is also utilised in the field of biological oceanography to detect planktonic forms from various images (i.e., microscopy, FlowCAM and video recorder), spectrometers, and other signal processing techniques. Moreover, ML successfully classified the mammals using their acoustics, detecting endangered mammalian and fish species in a specific environment. Most importantly, using environmental data, the ML proved to be an effective method for predicting hypoxic conditions and the harmful algal bloom events, an important measurement in terms of environmental monitoring. Furthermore, machine learning was used to construct a number of databases for various species that will be useful to other researchers, and the creation of new algorithms will help the marine research community better comprehend the chemistry and biology of the ocean.","classes":{"dataset":0.1921471357}}
{"title":"A Snapshot into the Possibility of Video Game Machine Translation","description":"We present in this article what we believe to be one of the first attempts at video game machine translation. Our study shows that models trained only with limited in-domain data surpass publicly available systems by a significant margin, and a subsequent human evaluation reveals interesting findings in the final translation. The first part of the article introduces some of the challenges of video game translation, some of the existing literature, as well as the systems and data sets used in this experiment. The last sections discuss our analysis of the resulting translation and the potential benefits of such an automated system. One such finding highlights the model's ability to learn typical rules and patterns of video game translations from English into French. Our conclusions therefore indicate that the specific case of video game machine translation could prove very much useful given the encouraging results, the highly repetitive nature of the work, and the often poor working conditions that translators face in this field. As with other use cases of MT in cultural sectors, however, we believe this is heavily dependent on the proper implementation of the tool, which should be used interactively by human translators to stimulate creativity instead of raw post-editing for the sake of productivity.","link":"http://arxiv.org/abs/2209.08827v1","created":"2022-09-19","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"A Snapshot into the Possibility of Video Game Machine Translation We present in this article what we believe to be one of the first attempts at video game machine translation. Our study shows that models trained only with limited in-domain data surpass publicly available systems by a significant margin, and a subsequent human evaluation reveals interesting findings in the final translation. The first part of the article introduces some of the challenges of video game translation, some of the existing literature, as well as the systems and data sets used in this experiment. The last sections discuss our analysis of the resulting translation and the potential benefits of such an automated system. One such finding highlights the model's ability to learn typical rules and patterns of video game translations from English into French. Our conclusions therefore indicate that the specific case of video game machine translation could prove very much useful given the encouraging results, the highly repetitive nature of the work, and the often poor working conditions that translators face in this field. As with other use cases of MT in cultural sectors, however, we believe this is heavily dependent on the proper implementation of the tool, which should be used interactively by human translators to stimulate creativity instead of raw post-editing for the sake of productivity.","classes":{"dataset":0.9149555564}}
{"title":"Pathfinding in Random Partially Observable Environments with Vision-Informed Deep Reinforcement Learning","description":"Deep reinforcement learning is a technique for solving problems in a variety of environments, ranging from Atari video games to stock trading. This method leverages deep neural network models to make decisions based on observations of a given environment with the goal of maximizing a reward function that can incorporate cost and rewards for reaching goals. With the aim of pathfinding, reward conditions can include reaching a specified target area along with costs for movement. In this work, multiple Deep Q-Network (DQN) agents are trained to operate in a partially observable environment with the goal of reaching a target zone in minimal travel time. The agent operates based on a visual representation of its surroundings, and thus has a restricted capability to observe the environment. A comparison between DQN, DQN-GRU, and DQN-LSTM is performed to examine each models capabilities with two different types of input. Through this evaluation, it is been shown that with equivalent training and analogous model architectures, a DQN model is able to outperform its recurrent counterparts.","link":"http://arxiv.org/abs/2209.04801v1","created":"2022-09-11","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Pathfinding in Random Partially Observable Environments with Vision-Informed Deep Reinforcement Learning Deep reinforcement learning is a technique for solving problems in a variety of environments, ranging from Atari video games to stock trading. This method leverages deep neural network models to make decisions based on observations of a given environment with the goal of maximizing a reward function that can incorporate cost and rewards for reaching goals. With the aim of pathfinding, reward conditions can include reaching a specified target area along with costs for movement. In this work, multiple Deep Q-Network (DQN) agents are trained to operate in a partially observable environment with the goal of reaching a target zone in minimal travel time. The agent operates based on a visual representation of its surroundings, and thus has a restricted capability to observe the environment. A comparison between DQN, DQN-GRU, and DQN-LSTM is performed to examine each models capabilities with two different types of input. Through this evaluation, it is been shown that with equivalent training and analogous model architectures, a DQN model is able to outperform its recurrent counterparts.","classes":{"dataset":0.5584785342}}
{"title":"Go-Explore Complex 3D Game Environments for Automated Reachability Testing","description":"Modern AAA video games feature huge game levels and maps which are increasingly hard for level testers to cover exhaustively. As a result, games often ship with catastrophic bugs such as the player falling through the floor or being stuck in walls. We propose an approach specifically targeted at reachability bugs in simulated 3D environments based on the powerful exploration algorithm, Go-Explore, which saves unique checkpoints across the map and then identifies promising ones to explore from. We show that when coupled with simple heuristics derived from the game's navigation mesh, Go-Explore finds challenging bugs and comprehensively explores complex environments without the need for human demonstration or knowledge of the game dynamics. Go-Explore vastly outperforms more complicated baselines including reinforcement learning with intrinsic curiosity in both covering the navigation mesh and number of unique positions across the map discovered. Finally, due to our use of parallel agents, our algorithm can fully cover a vast 1.5km x 1.5km game world within 10 hours on a single machine making it extremely promising for continuous testing suites.","link":"http://arxiv.org/abs/2209.00570v1","created":"2022-09-01","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Go-Explore Complex 3D Game Environments for Automated Reachability Testing Modern AAA video games feature huge game levels and maps which are increasingly hard for level testers to cover exhaustively. As a result, games often ship with catastrophic bugs such as the player falling through the floor or being stuck in walls. We propose an approach specifically targeted at reachability bugs in simulated 3D environments based on the powerful exploration algorithm, Go-Explore, which saves unique checkpoints across the map and then identifies promising ones to explore from. We show that when coupled with simple heuristics derived from the game's navigation mesh, Go-Explore finds challenging bugs and comprehensively explores complex environments without the need for human demonstration or knowledge of the game dynamics. Go-Explore vastly outperforms more complicated baselines including reinforcement learning with intrinsic curiosity in both covering the navigation mesh and number of unique positions across the map discovered. Finally, due to our use of parallel agents, our algorithm can fully cover a vast 1.5km x 1.5km game world within 10 hours on a single machine making it extremely promising for continuous testing suites.","classes":{"dataset":0.190694198}}
{"title":"Automatic Testing and Validation of Level of Detail Reductions Through Supervised Learning","description":"Modern video games are rapidly growing in size and scale, and to create rich and interesting environments, a large amount of content is needed. As a consequence, often several thousands of detailed 3D assets are used to create a single scene. As each asset's polygon mesh can contain millions of polygons, the number of polygons that need to be drawn every frame may exceed several billions. Therefore, the computational resources often limit how many detailed objects that can be displayed in a scene. To push this limit and to optimize performance one can reduce the polygon count of the assets when possible. Basically, the idea is that an object at farther distance from the capturing camera, consequently with relatively smaller screen size, its polygon count may be reduced without affecting the perceived quality. Level of Detail (LOD) refers to the complexity level of a 3D model representation. The process of removing complexity is often called LOD reduction and can be done automatically with an algorithm or by hand by artists. However, this process may lead to deterioration of the visual quality if the different LODs differ significantly, or if LOD reduction transition is not seamless. Today the validation of these results is mainly done manually requiring an expert to visually inspect the results. However, this process is slow, mundane, and therefore prone to error. Herein we propose a method to automate this process based on the use of deep convolutional networks. We report promising results and envision that this method can be used to automate the process of LOD reduction testing and validation.","link":"http://arxiv.org/abs/2208.12674v1","created":"2022-08-25","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Automatic Testing and Validation of Level of Detail Reductions Through Supervised Learning Modern video games are rapidly growing in size and scale, and to create rich and interesting environments, a large amount of content is needed. As a consequence, often several thousands of detailed 3D assets are used to create a single scene. As each asset's polygon mesh can contain millions of polygons, the number of polygons that need to be drawn every frame may exceed several billions. Therefore, the computational resources often limit how many detailed objects that can be displayed in a scene. To push this limit and to optimize performance one can reduce the polygon count of the assets when possible. Basically, the idea is that an object at farther distance from the capturing camera, consequently with relatively smaller screen size, its polygon count may be reduced without affecting the perceived quality. Level of Detail (LOD) refers to the complexity level of a 3D model representation. The process of removing complexity is often called LOD reduction and can be done automatically with an algorithm or by hand by artists. However, this process may lead to deterioration of the visual quality if the different LODs differ significantly, or if LOD reduction transition is not seamless. Today the validation of these results is mainly done manually requiring an expert to visually inspect the results. However, this process is slow, mundane, and therefore prone to error. Herein we propose a method to automate this process based on the use of deep convolutional networks. We report promising results and envision that this method can be used to automate the process of LOD reduction testing and validation.","classes":{"dataset":0.3938816488}}
{"title":"A Transformer-based Generative Adversarial Network for Brain Tumor Segmentation","description":"Brain tumor segmentation remains a challenge in medical image segmentation tasks. With the application of transformer in various computer vision tasks, transformer blocks show the capability of learning long-distance dependency in global space, which is complementary with CNNs. In this paper, we proposed a novel transformer-based generative adversarial network to automatically segment brain tumors with multi-modalities MRI. Our architecture consists of a generator and a discriminator, which are trained in min-max game progress. The generator is based on a typical \"U-shaped\" encoder-decoder architecture, whose bottom layer is composed of transformer blocks with resnet. Besides, the generator is trained with deep supervision technology. The discriminator we designed is a CNN-based network with multi-scale $L_{1}$ loss, which is proved to be effective for medical semantic image segmentation. To validate the effectiveness of our method, we conducted experiments on BRATS2015 dataset, achieving comparable or better performance than previous state-of-the-art methods.","link":"http://arxiv.org/abs/2207.14134v2","created":"2022-07-28","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"A Transformer-based Generative Adversarial Network for Brain Tumor Segmentation Brain tumor segmentation remains a challenge in medical image segmentation tasks. With the application of transformer in various computer vision tasks, transformer blocks show the capability of learning long-distance dependency in global space, which is complementary with CNNs. In this paper, we proposed a novel transformer-based generative adversarial network to automatically segment brain tumors with multi-modalities MRI. Our architecture consists of a generator and a discriminator, which are trained in min-max game progress. The generator is based on a typical \"U-shaped\" encoder-decoder architecture, whose bottom layer is composed of transformer blocks with resnet. Besides, the generator is trained with deep supervision technology. The discriminator we designed is a CNN-based network with multi-scale $L_{1}$ loss, which is proved to be effective for medical semantic image segmentation. To validate the effectiveness of our method, we conducted experiments on BRATS2015 dataset, achieving comparable or better performance than previous state-of-the-art methods.","classes":{"dataset":0.2312298417}}
{"title":"The Game of Hidden Rules: A New Kind of Benchmark Challenge for Machine Learning","description":"As machine learning (ML) is more tightly woven into society, it is imperative that we better characterize ML's strengths and limitations if we are to employ it responsibly. Existing benchmark environments for ML, such as board and video games, offer well-defined benchmarks for progress, but constituent tasks are often complex, and it is frequently unclear how task characteristics contribute to overall difficulty for the machine learner. Likewise, without a systematic assessment of how task characteristics influence difficulty, it is challenging to draw meaningful connections between performance in different benchmark environments. We introduce a novel benchmark environment that offers an enormous range of ML challenges and enables precise examination of how task elements influence practical difficulty. The tool frames learning tasks as a \"board-clearing game,\" which we call the Game of Hidden Rules (GOHR). The environment comprises an expressive rule language and a captive server environment that can be installed locally. We propose a set of benchmark rule-learning tasks and plan to support a performance leader-board for researchers interested in attempting to learn our rules. GOHR complements existing environments by allowing fine, controlled modifications to tasks, enabling experimenters to better understand how each facet of a given learning task contributes to its practical difficulty for an arbitrary ML algorithm.","link":"http://arxiv.org/abs/2207.10218v1","created":"2022-07-20","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"The Game of Hidden Rules: A New Kind of Benchmark Challenge for Machine Learning As machine learning (ML) is more tightly woven into society, it is imperative that we better characterize ML's strengths and limitations if we are to employ it responsibly. Existing benchmark environments for ML, such as board and video games, offer well-defined benchmarks for progress, but constituent tasks are often complex, and it is frequently unclear how task characteristics contribute to overall difficulty for the machine learner. Likewise, without a systematic assessment of how task characteristics influence difficulty, it is challenging to draw meaningful connections between performance in different benchmark environments. We introduce a novel benchmark environment that offers an enormous range of ML challenges and enables precise examination of how task elements influence practical difficulty. The tool frames learning tasks as a \"board-clearing game,\" which we call the Game of Hidden Rules (GOHR). The environment comprises an expressive rule language and a captive server environment that can be installed locally. We propose a set of benchmark rule-learning tasks and plan to support a performance leader-board for researchers interested in attempting to learn our rules. GOHR complements existing environments by allowing fine, controlled modifications to tasks, enabling experimenters to better understand how each facet of a given learning task contributes to its practical difficulty for an arbitrary ML algorithm.","classes":{"dataset":0.2717259228}}
{"title":"An adaptive music generation architecture for games based on the deep learning Transformer mode","description":"This paper presents an architecture for generating music for video games based on the Transformer deep learning model. Our motivation is to be able to customize the generation according to the taste of the player, who can select a corpus of training examples, corresponding to his preferred musical style. The system generates various musical layers, following the standard layering strategy currently used by composers designing video game music. To adapt the music generated to the game play and to the player(s) situation, we are using an arousal-valence model of emotions, in order to control the selection of musical layers. We discuss current limitations and prospects for the future, such as collaborative and interactive control of the musical components.","link":"http://arxiv.org/abs/2207.01698v2","created":"2022-07-04","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"An adaptive music generation architecture for games based on the deep learning Transformer mode This paper presents an architecture for generating music for video games based on the Transformer deep learning model. Our motivation is to be able to customize the generation according to the taste of the player, who can select a corpus of training examples, corresponding to his preferred musical style. The system generates various musical layers, following the standard layering strategy currently used by composers designing video game music. To adapt the music generated to the game play and to the player(s) situation, we are using an arousal-valence model of emotions, in order to control the selection of musical layers. We discuss current limitations and prospects for the future, such as collaborative and interactive control of the musical components.","classes":{"dataset":0.0059745102}}
{"title":"DayDreamer: World Models for Physical Robot Learning","description":"To solve tasks in complex environments, robots need to learn from experience. Deep reinforcement learning is a common approach to robot learning but requires a large amount of trial and error to learn, limiting its deployment in the physical world. As a consequence, many advances in robot learning rely on simulators. On the other hand, learning inside of simulators fails to capture the complexity of the real world, is prone to simulator inaccuracies, and the resulting behaviors do not adapt to changes in the world. The Dreamer algorithm has recently shown great promise for learning from small amounts of interaction by planning within a learned world model, outperforming pure reinforcement learning in video games. Learning a world model to predict the outcomes of potential actions enables planning in imagination, reducing the amount of trial and error needed in the real environment. However, it is unknown whether Dreamer can facilitate faster learning on physical robots. In this paper, we apply Dreamer to 4 robots to learn online and directly in the real world, without simulators. Dreamer trains a quadruped robot to roll off its back, stand up, and walk from scratch and without resets in only 1 hour. We then push the robot and find that Dreamer adapts within 10 minutes to withstand perturbations or quickly roll over and stand back up. On two different robotic arms, Dreamer learns to pick and place multiple objects directly from camera images and sparse rewards, approaching human performance. On a wheeled robot, Dreamer learns to navigate to a goal position purely from camera images, automatically resolving ambiguity about the robot orientation. Using the same hyperparameters across all experiments, we find that Dreamer is capable of online learning in the real world, establishing a strong baseline. We release our infrastructure for future applications of world models to robot learning.","link":"http://arxiv.org/abs/2206.14176v1","created":"2022-06-28","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"DayDreamer: World Models for Physical Robot Learning To solve tasks in complex environments, robots need to learn from experience. Deep reinforcement learning is a common approach to robot learning but requires a large amount of trial and error to learn, limiting its deployment in the physical world. As a consequence, many advances in robot learning rely on simulators. On the other hand, learning inside of simulators fails to capture the complexity of the real world, is prone to simulator inaccuracies, and the resulting behaviors do not adapt to changes in the world. The Dreamer algorithm has recently shown great promise for learning from small amounts of interaction by planning within a learned world model, outperforming pure reinforcement learning in video games. Learning a world model to predict the outcomes of potential actions enables planning in imagination, reducing the amount of trial and error needed in the real environment. However, it is unknown whether Dreamer can facilitate faster learning on physical robots. In this paper, we apply Dreamer to 4 robots to learn online and directly in the real world, without simulators. Dreamer trains a quadruped robot to roll off its back, stand up, and walk from scratch and without resets in only 1 hour. We then push the robot and find that Dreamer adapts within 10 minutes to withstand perturbations or quickly roll over and stand back up. On two different robotic arms, Dreamer learns to pick and place multiple objects directly from camera images and sparse rewards, approaching human performance. On a wheeled robot, Dreamer learns to navigate to a goal position purely from camera images, automatically resolving ambiguity about the robot orientation. Using the same hyperparameters across all experiments, we find that Dreamer is capable of online learning in the real world, establishing a strong baseline. We release our infrastructure for future applications of world models to robot learning.","classes":{"dataset":0.387642473}}
{"title":"ML-Based Approach for NFL Defensive Pass Interference Prediction Using GPS Tracking Data","description":"Defensive Pass Interference (DPI) is one of the most impactful penalties in the NFL. DPI is a spot foul, yielding an automatic first down to the team in possession. With such an influence on the game, referees have no room for a mistake. It is also a very rare event, which happens 1-2 times per 100 pass attempts. With technology improving and many IoT wearables being put on the athletes to collect valuable data, there is a solid ground for applying machine learning (ML) techniques to improve every aspect of the game. The work presented here is the first attempt in predicting DPI using player tracking GPS data. The data we used was collected by NFL's Next Gen Stats throughout the 2018 regular season. We present ML models for highly imbalanced time-series binary classification: LSTM, GRU, ANN, and Multivariate LSTM-FCN. Results showed that using GPS tracking data to predict DPI has limited success. The best performing models had high recall with low precision which resulted in the classification of many false positive examples. Looking closely at the data confirmed that there is just not enough information to determine whether a foul was committed. This study might serve as a filter for multi-step pipeline for video sequence classification which could be able to solve this problem.","link":"http://arxiv.org/abs/2206.13222v1","created":"2022-06-24","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"ML-Based Approach for NFL Defensive Pass Interference Prediction Using GPS Tracking Data Defensive Pass Interference (DPI) is one of the most impactful penalties in the NFL. DPI is a spot foul, yielding an automatic first down to the team in possession. With such an influence on the game, referees have no room for a mistake. It is also a very rare event, which happens 1-2 times per 100 pass attempts. With technology improving and many IoT wearables being put on the athletes to collect valuable data, there is a solid ground for applying machine learning (ML) techniques to improve every aspect of the game. The work presented here is the first attempt in predicting DPI using player tracking GPS data. The data we used was collected by NFL's Next Gen Stats throughout the 2018 regular season. We present ML models for highly imbalanced time-series binary classification: LSTM, GRU, ANN, and Multivariate LSTM-FCN. Results showed that using GPS tracking data to predict DPI has limited success. The best performing models had high recall with low precision which resulted in the classification of many false positive examples. Looking closely at the data confirmed that there is just not enough information to determine whether a foul was committed. This study might serve as a filter for multi-step pipeline for video sequence classification which could be able to solve this problem.","classes":{"dataset":0.2376651913}}
{"title":"NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds","description":"In order for artificial agents to perform useful tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classification. This practice restricts novelties to well-framed images of distinct object types. We suggest that new benchmarks are needed to represent the challenges of navigating an open world. Our new NovelCraft dataset contains multi-modal episodic data of the images and symbolic world-states seen by an agent completing a pogo-stick assembly task within a video game world. In some episodes, we insert novel objects that can impact gameplay. Novelty can vary in size, position, and occlusion within complex scenes. We benchmark state-of-the-art novelty detection and generalized category discovery models with a focus on comprehensive evaluation. Results suggest an opportunity for future research: models aware of task-specific costs of different types of mistakes could more effectively detect and adapt to novelty in open worlds.","link":"http://arxiv.org/abs/2206.11736v1","created":"2022-06-23","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds In order for artificial agents to perform useful tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classification. This practice restricts novelties to well-framed images of distinct object types. We suggest that new benchmarks are needed to represent the challenges of navigating an open world. Our new NovelCraft dataset contains multi-modal episodic data of the images and symbolic world-states seen by an agent completing a pogo-stick assembly task within a video game world. In some episodes, we insert novel objects that can impact gameplay. Novelty can vary in size, position, and occlusion within complex scenes. We benchmark state-of-the-art novelty detection and generalized category discovery models with a focus on comprehensive evaluation. Results suggest an opportunity for future research: models aware of task-specific costs of different types of mistakes could more effectively detect and adapt to novelty in open worlds.","classes":{"dataset":0.3060715795}}
{"title":"World of Bugs: A Platform for Automated Bug Detection in 3D Video Games","description":"We present World of Bugs (WOB), an open platform that aims to support Automated Bug Detection (ABD) research in video games. We discuss some open problems in ABD and how they relate to the platform's design, arguing that learning-based solutions are required if further progress is to be made. The platform's key feature is a growing collection of common video game bugs that may be used for training and evaluating ABD approaches.","link":"http://arxiv.org/abs/2206.11037v1","created":"2022-06-21","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"World of Bugs: A Platform for Automated Bug Detection in 3D Video Games We present World of Bugs (WOB), an open platform that aims to support Automated Bug Detection (ABD) research in video games. We discuss some open problems in ABD and how they relate to the platform's design, arguing that learning-based solutions are required if further progress is to be made. The platform's key feature is a growing collection of common video game bugs that may be used for training and evaluating ABD approaches.","classes":{"dataset":0.4150406718}}
{"title":"MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge","description":"Autonomous agents have made great strides in specialist domains like Atari games and Go. However, they typically learn tabula rasa in isolated environments with limited and manually conceived objectives, thus failing to generalize across a wide spectrum of tasks and capabilities. Inspired by how humans continually learn and adapt in the open world, we advocate a trinity of ingredients for building generalist agents: 1) an environment that supports a multitude of tasks and goals, 2) a large-scale database of multimodal knowledge, and 3) a flexible and scalable agent architecture. We introduce MineDojo, a new framework built on the popular Minecraft game that features a simulation suite with thousands of diverse open-ended tasks and an internet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and forum discussions. Using MineDojo's data, we propose a novel agent learning algorithm that leverages large pre-trained video-language models as a learned reward function. Our agent is able to solve a variety of open-ended tasks specified in free-form language without any manually designed dense shaping reward. We open-source the simulation suite, knowledge bases, algorithm implementation, and pretrained models (https://minedojo.org) to promote research towards the goal of generally capable embodied agents.","link":"http://arxiv.org/abs/2206.08853v2","created":"2022-06-17","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge Autonomous agents have made great strides in specialist domains like Atari games and Go. However, they typically learn tabula rasa in isolated environments with limited and manually conceived objectives, thus failing to generalize across a wide spectrum of tasks and capabilities. Inspired by how humans continually learn and adapt in the open world, we advocate a trinity of ingredients for building generalist agents: 1) an environment that supports a multitude of tasks and goals, 2) a large-scale database of multimodal knowledge, and 3) a flexible and scalable agent architecture. We introduce MineDojo, a new framework built on the popular Minecraft game that features a simulation suite with thousands of diverse open-ended tasks and an internet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and forum discussions. Using MineDojo's data, we propose a novel agent learning algorithm that leverages large pre-trained video-language models as a learned reward function. Our agent is able to solve a variety of open-ended tasks specified in free-form language without any manually designed dense shaping reward. We open-source the simulation suite, knowledge bases, algorithm implementation, and pretrained models (https://minedojo.org) to promote research towards the goal of generally capable embodied agents.","classes":{"dataset":0.0540913306}}
{"title":"Stock Trading Optimization through Model-based Reinforcement Learning with Resistance Support Relative Strength","description":"Reinforcement learning (RL) is gaining attention by more and more researchers in quantitative finance as the agent-environment interaction framework is aligned with decision making process in many business problems. Most of the current financial applications using RL algorithms are based on model-free method, which still faces stability and adaptivity challenges. As lots of cutting-edge model-based reinforcement learning (MBRL) algorithms mature in applications such as video games or robotics, we design a new approach that leverages resistance and support (RS) level as regularization terms for action in MBRL, to improve the algorithm's efficiency and stability. From the experiment results, we can see RS level, as a market timing technique, enhances the performance of pure MBRL models in terms of various measurements and obtains better profit gain with less riskiness. Besides, our proposed method even resists big drop (less maximum drawdown) during COVID-19 pandemic period when the financial market got unpredictable crisis. Explanations on why control of resistance and support level can boost MBRL is also investigated through numerical experiments, such as loss of actor-critic network and prediction error of the transition dynamical model. It shows that RS indicators indeed help the MBRL algorithms to converge faster at early stage and obtain smaller critic loss as training episodes increase.","link":"http://arxiv.org/abs/2205.15056v1","created":"2022-05-30","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Stock Trading Optimization through Model-based Reinforcement Learning with Resistance Support Relative Strength Reinforcement learning (RL) is gaining attention by more and more researchers in quantitative finance as the agent-environment interaction framework is aligned with decision making process in many business problems. Most of the current financial applications using RL algorithms are based on model-free method, which still faces stability and adaptivity challenges. As lots of cutting-edge model-based reinforcement learning (MBRL) algorithms mature in applications such as video games or robotics, we design a new approach that leverages resistance and support (RS) level as regularization terms for action in MBRL, to improve the algorithm's efficiency and stability. From the experiment results, we can see RS level, as a market timing technique, enhances the performance of pure MBRL models in terms of various measurements and obtains better profit gain with less riskiness. Besides, our proposed method even resists big drop (less maximum drawdown) during COVID-19 pandemic period when the financial market got unpredictable crisis. Explanations on why control of resistance and support level can boost MBRL is also investigated through numerical experiments, such as loss of actor-critic network and prediction error of the transition dynamical model. It shows that RS indicators indeed help the MBRL algorithms to converge faster at early stage and obtain smaller critic loss as training episodes increase.","classes":{"dataset":0.2632241547}}
{"title":"Skill Machines: Temporal Logic Composition in Reinforcement Learning","description":"A major challenge in reinforcement learning is specifying tasks in a manner that is both interpretable and verifiable. One common approach is to specify tasks through reward machines -- finite state machines that encode the task to be solved. We introduce skill machines, a representation that can be learned directly from these reward machines that encode the solution to such tasks. We propose a framework where an agent first learns a set of base skills in a reward-free setting, and then combines these skills with the learned skill machine to produce composite behaviours specified by any regular language, such as linear temporal logics. This provides the agent with the ability to map from complex logical task specifications to near-optimal behaviours zero-shot. We demonstrate our approach in both a tabular and high-dimensional video game environment, where an agent is faced with several of these complex, long-horizon tasks. Our results indicate that the agent is capable of satisfying extremely complex task specifications, producing near optimal performance with no further learning. Finally, we demonstrate that the performance of skill machines can be improved with regular offline reinforcement learning algorithms when optimal behaviours are desired.","link":"http://arxiv.org/abs/2205.12532v1","created":"2022-05-25","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Skill Machines: Temporal Logic Composition in Reinforcement Learning A major challenge in reinforcement learning is specifying tasks in a manner that is both interpretable and verifiable. One common approach is to specify tasks through reward machines -- finite state machines that encode the task to be solved. We introduce skill machines, a representation that can be learned directly from these reward machines that encode the solution to such tasks. We propose a framework where an agent first learns a set of base skills in a reward-free setting, and then combines these skills with the learned skill machine to produce composite behaviours specified by any regular language, such as linear temporal logics. This provides the agent with the ability to map from complex logical task specifications to near-optimal behaviours zero-shot. We demonstrate our approach in both a tabular and high-dimensional video game environment, where an agent is faced with several of these complex, long-horizon tasks. Our results indicate that the agent is capable of satisfying extremely complex task specifications, producing near optimal performance with no further learning. Finally, we demonstrate that the performance of skill machines can be improved with regular offline reinforcement learning algorithms when optimal behaviours are desired.","classes":{"dataset":0.2155774236}}
{"title":"Deep Apprenticeship Learning for Playing Games","description":"In the last decade, deep learning has achieved great success in machine learning tasks where the input data is represented with different levels of abstractions. Driven by the recent research in reinforcement learning using deep neural networks, we explore the feasibility of designing a learning model based on expert behaviour for complex, multidimensional tasks where reward function is not available. We propose a novel method for apprenticeship learning based on the previous research on supervised learning techniques in reinforcement learning. Our method is applied to video frames from Atari games in order to teach an artificial agent to play those games. Even though the reported results are not comparable with the state-of-the-art results in reinforcement learning, we demonstrate that such an approach has the potential to achieve strong performance in the future and is worthwhile for further research.","link":"http://arxiv.org/abs/2205.07959v1","created":"2022-05-16","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Deep Apprenticeship Learning for Playing Games In the last decade, deep learning has achieved great success in machine learning tasks where the input data is represented with different levels of abstractions. Driven by the recent research in reinforcement learning using deep neural networks, we explore the feasibility of designing a learning model based on expert behaviour for complex, multidimensional tasks where reward function is not available. We propose a novel method for apprenticeship learning based on the previous research on supervised learning techniques in reinforcement learning. Our method is applied to video frames from Atari games in order to teach an artificial agent to play those games. Even though the reported results are not comparable with the state-of-the-art results in reinforcement learning, we demonstrate that such an approach has the potential to achieve strong performance in the future and is worthwhile for further research.","classes":{"dataset":0.0579963252}}
{"title":"On the Verge of Solving Rocket League using Deep Reinforcement Learning and Sim-to-sim Transfer","description":"Autonomously trained agents that are supposed to play video games reasonably well rely either on fast simulation speeds or heavy parallelization across thousands of machines running concurrently. This work explores a third way that is established in robotics, namely sim-to-real transfer, or if the game is considered a simulation itself, sim-to-sim transfer. In the case of Rocket League, we demonstrate that single behaviors of goalies and strikers can be successfully learned using Deep Reinforcement Learning in the simulation environment and transferred back to the original game. Although the implemented training simulation is to some extent inaccurate, the goalkeeping agent saves nearly 100% of its faced shots once transferred, while the striking agent scores in about 75% of cases. Therefore, the trained agent is robust enough and able to generalize to the target domain of Rocket League.","link":"http://arxiv.org/abs/2205.05061v2","created":"2022-05-10","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"On the Verge of Solving Rocket League using Deep Reinforcement Learning and Sim-to-sim Transfer Autonomously trained agents that are supposed to play video games reasonably well rely either on fast simulation speeds or heavy parallelization across thousands of machines running concurrently. This work explores a third way that is established in robotics, namely sim-to-real transfer, or if the game is considered a simulation itself, sim-to-sim transfer. In the case of Rocket League, we demonstrate that single behaviors of goalies and strikers can be successfully learned using Deep Reinforcement Learning in the simulation environment and transferred back to the original game. Although the implemented training simulation is to some extent inaccurate, the goalkeeping agent saves nearly 100% of its faced shots once transferred, while the striking agent scores in about 75% of cases. Therefore, the trained agent is robust enough and able to generalize to the target domain of Rocket League.","classes":{"dataset":0.3089745939}}
{"title":"Accelerating Robot Learning of Contact-Rich Manipulations: A Curriculum Learning Study","description":"The Reinforcement Learning (RL) paradigm has been an essential tool for automating robotic tasks. Despite the advances in RL, it is still not widely adopted in the industry due to the need for an expensive large amount of robot interaction with its environment. Curriculum Learning (CL) has been proposed to expedite learning. However, most research works have been only evaluated in simulated environments, from video games to robotic toy tasks. This paper presents a study for accelerating robot learning of contact-rich manipulation tasks based on Curriculum Learning combined with Domain Randomization (DR). We tackle complex industrial assembly tasks with position-controlled robots, such as insertion tasks. We compare different curricula designs and sampling approaches for DR. Based on this study, we propose a method that significantly outperforms previous work, which uses DR only (No CL is used), with less than a fifth of the training time (samples). Results also show that even when training only in simulation with toy tasks, our method can learn policies that can be transferred to the real-world robot. The learned policies achieved success rates of up to 86\\% on real-world complex industrial insertion tasks (with tolerances of $\\pm 0.01~mm$) not seen during the training.","link":"http://arxiv.org/abs/2204.12844v2","created":"2022-04-27","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Accelerating Robot Learning of Contact-Rich Manipulations: A Curriculum Learning Study The Reinforcement Learning (RL) paradigm has been an essential tool for automating robotic tasks. Despite the advances in RL, it is still not widely adopted in the industry due to the need for an expensive large amount of robot interaction with its environment. Curriculum Learning (CL) has been proposed to expedite learning. However, most research works have been only evaluated in simulated environments, from video games to robotic toy tasks. This paper presents a study for accelerating robot learning of contact-rich manipulation tasks based on Curriculum Learning combined with Domain Randomization (DR). We tackle complex industrial assembly tasks with position-controlled robots, such as insertion tasks. We compare different curricula designs and sampling approaches for DR. Based on this study, we propose a method that significantly outperforms previous work, which uses DR only (No CL is used), with less than a fifth of the training time (samples). Results also show that even when training only in simulation with toy tasks, our method can learn policies that can be transferred to the real-world robot. The learned policies achieved success rates of up to 86\\% on real-world complex industrial insertion tasks (with tolerances of $\\pm 0.01~mm$) not seen during the training.","classes":{"dataset":0.3615912199}}
{"title":"Predicting Real-time Scientific Experiments Using Transformer models and Reinforcement Learning","description":"Life and physical sciences have always been quick to adopt the latest advances in machine learning to accelerate scientific discovery. Examples of this are cell segmentation or cancer detection. Nevertheless, these exceptional results are based on mining previously created datasets to discover patterns or trends. Recent advances in AI have been demonstrated in real-time scenarios like self-driving cars or playing video games. However, these new techniques have not seen widespread adoption in life or physical sciences because experimentation can be slow. To tackle this limitation, this work aims to adapt generative learning algorithms to model scientific experiments and accelerate their discovery using in-silico simulations. We particularly focused on real-time experiments, aiming to model how they react to user inputs. To achieve this, here we present an encoder-decoder architecture based on the Transformer model to simulate real-time scientific experimentation, predict its future behaviour and manipulate it on a step-by-step basis. As a proof of concept, this architecture was trained to map a set of mechanical inputs to the oscillations generated by a chemical reaction. The model was paired with a Reinforcement Learning controller to show how the simulated chemistry can be manipulated in real-time towards user-defined behaviours. Our results demonstrate how generative learning can model real-time scientific experimentation to track how it changes through time as the user manipulates it, and how the trained models can be paired with optimisation algorithms to discover new phenomena beyond the physical limitations of lab experimentation. This work paves the way towards building surrogate systems where physical experimentation interacts with machine learning on a step-by-step basis.","link":"http://arxiv.org/abs/2204.11718v1","created":"2022-04-25","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Predicting Real-time Scientific Experiments Using Transformer models and Reinforcement Learning Life and physical sciences have always been quick to adopt the latest advances in machine learning to accelerate scientific discovery. Examples of this are cell segmentation or cancer detection. Nevertheless, these exceptional results are based on mining previously created datasets to discover patterns or trends. Recent advances in AI have been demonstrated in real-time scenarios like self-driving cars or playing video games. However, these new techniques have not seen widespread adoption in life or physical sciences because experimentation can be slow. To tackle this limitation, this work aims to adapt generative learning algorithms to model scientific experiments and accelerate their discovery using in-silico simulations. We particularly focused on real-time experiments, aiming to model how they react to user inputs. To achieve this, here we present an encoder-decoder architecture based on the Transformer model to simulate real-time scientific experimentation, predict its future behaviour and manipulate it on a step-by-step basis. As a proof of concept, this architecture was trained to map a set of mechanical inputs to the oscillations generated by a chemical reaction. The model was paired with a Reinforcement Learning controller to show how the simulated chemistry can be manipulated in real-time towards user-defined behaviours. Our results demonstrate how generative learning can model real-time scientific experimentation to track how it changes through time as the user manipulates it, and how the trained models can be paired with optimisation algorithms to discover new phenomena beyond the physical limitations of lab experimentation. This work paves the way towards building surrogate systems where physical experimentation interacts with machine learning on a step-by-step basis.","classes":{"dataset":0.3646660745}}
{"title":"Adversarial Counterfactual Augmentation: Application in Alzheimer's Disease Classification","description":"Due to the limited availability of medical data, deep learning approaches for medical image analysis tend to generalise poorly to unseen data. Augmenting data during training with random transformations has been shown to help and became a ubiquitous technique for training neural networks. Here, we propose a novel adversarial counterfactual augmentation scheme that aims at finding the most \\textit{effective} synthesised images to improve downstream tasks, given a pre-trained generative model. Specifically, we construct an adversarial game where we update the input \\textit{conditional factor} of the generator and the downstream \\textit{classifier} with gradient backpropagation alternatively and iteratively. This can be viewed as finding the `\\textit{weakness}' of the classifier and purposely forcing it to \\textit{overcome} its weakness via the generative model. To demonstrate the effectiveness of the proposed approach, we validate the method with the classification of Alzheimer's Disease (AD) as a downstream task. The pre-trained generative model synthesises brain images using age as conditional factor. Extensive experiments and ablation studies have been performed to show that the proposed approach improves classification performance and has potential to alleviate spurious correlations and catastrophic forgetting. Code will be released upon acceptance.","link":"http://arxiv.org/abs/2203.07815v2","created":"2022-03-15","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Adversarial Counterfactual Augmentation: Application in Alzheimer's Disease Classification Due to the limited availability of medical data, deep learning approaches for medical image analysis tend to generalise poorly to unseen data. Augmenting data during training with random transformations has been shown to help and became a ubiquitous technique for training neural networks. Here, we propose a novel adversarial counterfactual augmentation scheme that aims at finding the most \\textit{effective} synthesised images to improve downstream tasks, given a pre-trained generative model. Specifically, we construct an adversarial game where we update the input \\textit{conditional factor} of the generator and the downstream \\textit{classifier} with gradient backpropagation alternatively and iteratively. This can be viewed as finding the `\\textit{weakness}' of the classifier and purposely forcing it to \\textit{overcome} its weakness via the generative model. To demonstrate the effectiveness of the proposed approach, we validate the method with the classification of Alzheimer's Disease (AD) as a downstream task. The pre-trained generative model synthesises brain images using age as conditional factor. Extensive experiments and ablation studies have been performed to show that the proposed approach improves classification performance and has potential to alleviate spurious correlations and catastrophic forgetting. Code will be released upon acceptance.","classes":{"dataset":0.151161328}}
{"title":"Human-Like Navigation Behavior: A Statistical Evaluation Framework","description":"Recent advancements in deep reinforcement learning have brought forth an impressive display of highly skilled artificial agents capable of complex intelligent behavior. In video games, these artificial agents are increasingly deployed as non-playable characters (NPCs) designed to enhance the experience of human players. However, while it has been shown that the convincing human-like behavior of NPCs leads to increased engagement in video games, the believability of an artificial agent's behavior is most often measured solely by its proficiency at a given task. Recent work has hinted that proficiency alone is not sufficient to discern human-like behavior. Motivated by this, we build a non-parametric two-sample hypothesis test designed to compare the behaviors of artificial agents to those of human players. We show that the resulting $p$-value not only aligns with anonymous human judgment of human-like behavior, but also that it can be used as a measure of similarity.","link":"http://arxiv.org/abs/2203.05965v1","created":"2022-03-10","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Human-Like Navigation Behavior: A Statistical Evaluation Framework Recent advancements in deep reinforcement learning have brought forth an impressive display of highly skilled artificial agents capable of complex intelligent behavior. In video games, these artificial agents are increasingly deployed as non-playable characters (NPCs) designed to enhance the experience of human players. However, while it has been shown that the convincing human-like behavior of NPCs leads to increased engagement in video games, the believability of an artificial agent's behavior is most often measured solely by its proficiency at a given task. Recent work has hinted that proficiency alone is not sufficient to discern human-like behavior. Motivated by this, we build a non-parametric two-sample hypothesis test designed to compare the behaviors of artificial agents to those of human players. We show that the resulting $p$-value not only aligns with anonymous human judgment of human-like behavior, but also that it can be used as a measure of similarity.","classes":{"dataset":0.6389582157}}
{"title":"A Survey on Reinforcement Learning Methods in Character Animation","description":"Reinforcement Learning is an area of Machine Learning focused on how agents can be trained to make sequential decisions, and achieve a particular goal within an arbitrary environment. While learning, they repeatedly take actions based on their observation of the environment, and receive appropriate rewards which define the objective. This experience is then used to progressively improve the policy controlling the agent's behavior, typically represented by a neural network. This trained module can then be reused for similar problems, which makes this approach promising for the animation of autonomous, yet reactive characters in simulators, video games or virtual reality environments. This paper surveys the modern Deep Reinforcement Learning methods and discusses their possible applications in Character Animation, from skeletal control of a single, physically-based character to navigation controllers for individual agents and virtual crowds. It also describes the practical side of training DRL systems, comparing the different frameworks available to build such agents.","link":"http://arxiv.org/abs/2203.04735v1","created":"2022-03-07","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"A Survey on Reinforcement Learning Methods in Character Animation Reinforcement Learning is an area of Machine Learning focused on how agents can be trained to make sequential decisions, and achieve a particular goal within an arbitrary environment. While learning, they repeatedly take actions based on their observation of the environment, and receive appropriate rewards which define the objective. This experience is then used to progressively improve the policy controlling the agent's behavior, typically represented by a neural network. This trained module can then be reused for similar problems, which makes this approach promising for the animation of autonomous, yet reactive characters in simulators, video games or virtual reality environments. This paper surveys the modern Deep Reinforcement Learning methods and discusses their possible applications in Character Animation, from skeletal control of a single, physically-based character to navigation controllers for individual agents and virtual crowds. It also describes the practical side of training DRL systems, comparing the different frameworks available to build such agents.","classes":{"dataset":0.0696688965}}
{"title":"Transfer Dynamics in Emergent Evolutionary Curricula","description":"PINSKY is a system for open-ended learning through neuroevolution in game-based domains. It builds on the Paired Open-Ended Trailblazer (POET) system, which originally explored learning and environment generation for bipedal walkers, and adapts it to games in the General Video Game AI (GVGAI) system. Previous work showed that by co-evolving levels and neural network policies, levels could be found for which successful policies could not be created via optimization alone. Studied in the realm of Artificial Life as a potentially open-ended alternative to gradient-based fitness, minimal criteria (MC)-based selection helps foster diversity in evolutionary populations. The main question addressed by this paper is how the open-ended learning actually works, focusing in particular on the role of transfer of policies from one evolutionary branch (\"species\") to another. We analyze the dynamics of the system through creating phylogenetic trees, analyzing evolutionary trajectories of policies, and temporally breaking down transfers according to species type. Furthermore, we analyze the impact of the minimal criterion on generated level diversity and inter-species transfer. The most insightful finding is that inter-species transfer, while rare, is crucial to the system's success.","link":"http://arxiv.org/abs/2203.10941v1","created":"2022-03-03","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Transfer Dynamics in Emergent Evolutionary Curricula PINSKY is a system for open-ended learning through neuroevolution in game-based domains. It builds on the Paired Open-Ended Trailblazer (POET) system, which originally explored learning and environment generation for bipedal walkers, and adapts it to games in the General Video Game AI (GVGAI) system. Previous work showed that by co-evolving levels and neural network policies, levels could be found for which successful policies could not be created via optimization alone. Studied in the realm of Artificial Life as a potentially open-ended alternative to gradient-based fitness, minimal criteria (MC)-based selection helps foster diversity in evolutionary populations. The main question addressed by this paper is how the open-ended learning actually works, focusing in particular on the role of transfer of policies from one evolutionary branch (\"species\") to another. We analyze the dynamics of the system through creating phylogenetic trees, analyzing evolutionary trajectories of policies, and temporally breaking down transfers according to species type. Furthermore, we analyze the impact of the minimal criterion on generated level diversity and inter-species transfer. The most insightful finding is that inter-species transfer, while rare, is crucial to the system's success.","classes":{"dataset":0.2004038393}}
{"title":"Gen\u00e9Live! Generating Rhythm Actions in Love Live!","description":"This article presents our generative model for rhythm action games together with applications in business operations. Rhythm action games are video games in which the player is challenged to issue commands at the right timings during a music session. The timings are rendered in the chart, which consists of visual symbols, called notes, flying through the screen. We introduce our deep generative model, Gen\\'eLive!, which outperforms the state-of-the-art model by taking into account musical structures through beats and temporal scales. Thanks to its favorable performance, Gen\\'eLive! was put into operation at KLab Inc., a Japan-based video game developer, and reduced the business cost of chart generation by as much as half. The application target included the phenomenal \"Love Live!,\" which has more than 10 million users across Asia and beyond, and is one of the few rhythm action franchises that has led the online era of the genre. In this article, we evaluate the generative performance of Gen\\'eLive! using production datasets at KLab as well as open datasets for reproducibility, while the model continues to operate in their business. Our code and the model, tuned and trained using a supercomputer, are publicly available.","link":"http://arxiv.org/abs/2202.12823v2","created":"2022-02-25","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Gen\u00e9Live! Generating Rhythm Actions in Love Live! This article presents our generative model for rhythm action games together with applications in business operations. Rhythm action games are video games in which the player is challenged to issue commands at the right timings during a music session. The timings are rendered in the chart, which consists of visual symbols, called notes, flying through the screen. We introduce our deep generative model, Gen\\'eLive!, which outperforms the state-of-the-art model by taking into account musical structures through beats and temporal scales. Thanks to its favorable performance, Gen\\'eLive! was put into operation at KLab Inc., a Japan-based video game developer, and reduced the business cost of chart generation by as much as half. The application target included the phenomenal \"Love Live!,\" which has more than 10 million users across Asia and beyond, and is one of the few rhythm action franchises that has led the online era of the genre. In this article, we evaluate the generative performance of Gen\\'eLive! using production datasets at KLab as well as open datasets for reproducibility, while the model continues to operate in their business. Our code and the model, tuned and trained using a supercomputer, are publicly available.","classes":{"dataset":0.2988117337}}
{"title":"CCPT: Automatic Gameplay Testing and Validation with Curiosity-Conditioned Proximal Trajectories","description":"This paper proposes a novel deep reinforcement learning algorithm to perform automatic analysis and detection of gameplay issues in complex 3D navigation environments. The Curiosity-Conditioned Proximal Trajectories (CCPT) method combines curiosity and imitation learning to train agents to methodically explore in the proximity of known trajectories derived from expert demonstrations. We show how CCPT can explore complex environments, discover gameplay issues and design oversights in the process, and recognize and highlight them directly to game designers. We further demonstrate the effectiveness of the algorithm in a novel 3D navigation environment which reflects the complexity of modern AAA video games. Our results show a higher level of coverage and bug discovery than baselines methods, and it hence can provide a valuable tool for game designers to identify issues in game design automatically.","link":"http://arxiv.org/abs/2202.10057v1","created":"2022-02-21","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"CCPT: Automatic Gameplay Testing and Validation with Curiosity-Conditioned Proximal Trajectories This paper proposes a novel deep reinforcement learning algorithm to perform automatic analysis and detection of gameplay issues in complex 3D navigation environments. The Curiosity-Conditioned Proximal Trajectories (CCPT) method combines curiosity and imitation learning to train agents to methodically explore in the proximity of known trajectories derived from expert demonstrations. We show how CCPT can explore complex environments, discover gameplay issues and design oversights in the process, and recognize and highlight them directly to game designers. We further demonstrate the effectiveness of the algorithm in a novel 3D navigation environment which reflects the complexity of modern AAA video games. Our results show a higher level of coverage and bug discovery than baselines methods, and it hence can provide a valuable tool for game designers to identify issues in game design automatically.","classes":{"dataset":0.1296097338}}
{"title":"A Ranking Game for Imitation Learning","description":"We propose a new framework for imitation learning -- treating imitation as a two-player ranking-based game between a policy and a reward. In this game, the reward agent learns to satisfy pairwise performance rankings between behaviors, while the policy agent learns to maximize this reward. In imitation learning, near-optimal expert data can be difficult to obtain, and even in the limit of infinite data cannot imply a total ordering over trajectories as preferences can. On the other hand, learning from preferences alone is challenging as a large number of preferences are required to infer a high-dimensional reward function, though preference data is typically much easier to collect than expert demonstrations. The classical inverse reinforcement learning (IRL) formulation learns from expert demonstrations but provides no mechanism to incorporate learning from offline preferences and vice versa. We instantiate the proposed ranking-game framework with a novel ranking loss giving an algorithm that can simultaneously learn from expert demonstrations and preferences, gaining the advantages of both modalities. Our experiments show that the proposed method achieves state-of-the-art sample efficiency and can solve previously unsolvable tasks in the Learning from Observation (LfO) setting. Project video and code can be found at https://hari-sikchi.github.io/rank-game/","link":"http://arxiv.org/abs/2202.03481v3","created":"2022-02-07","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"A Ranking Game for Imitation Learning We propose a new framework for imitation learning -- treating imitation as a two-player ranking-based game between a policy and a reward. In this game, the reward agent learns to satisfy pairwise performance rankings between behaviors, while the policy agent learns to maximize this reward. In imitation learning, near-optimal expert data can be difficult to obtain, and even in the limit of infinite data cannot imply a total ordering over trajectories as preferences can. On the other hand, learning from preferences alone is challenging as a large number of preferences are required to infer a high-dimensional reward function, though preference data is typically much easier to collect than expert demonstrations. The classical inverse reinforcement learning (IRL) formulation learns from expert demonstrations but provides no mechanism to incorporate learning from offline preferences and vice versa. We instantiate the proposed ranking-game framework with a novel ranking loss giving an algorithm that can simultaneously learn from expert demonstrations and preferences, gaining the advantages of both modalities. Our experiments show that the proposed method achieves state-of-the-art sample efficiency and can solve previously unsolvable tasks in the Learning from Observation (LfO) setting. Project video and code can be found at https://hari-sikchi.github.io/rank-game/","classes":{"dataset":0.261025399}}
{"title":"Reward Relabelling for combined Reinforcement and Imitation Learning on sparse-reward tasks","description":"During recent years, deep reinforcement learning (DRL) has made successful incursions into complex decision-making applications such as robotics, autonomous driving or video games. In the search for more sample-efficient algorithms, a promising direction is to leverage as much external off-policy data as possible. One staple of this data-driven approach is to learn from expert demonstrations. In the past, multiple ideas have been proposed to make good use of the demonstrations added to the replay buffer, such as pretraining on demonstrations only or minimizing additional cost functions. We present a new method, able to leverage demonstrations and episodes collected online in any sparse-reward environment with any off-policy algorithm. Our method is based on a reward bonus given to demonstrations and successful episodes, encouraging expert imitation and self-imitation. First, we give a reward bonus to the transitions coming from demonstrations to encourage the agent to match the demonstrated behaviour. Then, upon collecting a successful episode, we relabel its transitions with the same bonus before adding them to the replay buffer, encouraging the agent to also match its previous successes. Our experiments focus on manipulation robotics, specifically on three tasks for a 6 degrees-of-freedom robotic arm in simulation. We show that our method based on reward relabeling improves the performance of the base algorithm (SAC and DDPG) on these tasks, even in the absence of demonstrations. Furthermore, integrating into our method two improvements from previous works allows our approach to outperform all baselines.","link":"http://arxiv.org/abs/2201.03834v1","created":"2022-01-11","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Reward Relabelling for combined Reinforcement and Imitation Learning on sparse-reward tasks During recent years, deep reinforcement learning (DRL) has made successful incursions into complex decision-making applications such as robotics, autonomous driving or video games. In the search for more sample-efficient algorithms, a promising direction is to leverage as much external off-policy data as possible. One staple of this data-driven approach is to learn from expert demonstrations. In the past, multiple ideas have been proposed to make good use of the demonstrations added to the replay buffer, such as pretraining on demonstrations only or minimizing additional cost functions. We present a new method, able to leverage demonstrations and episodes collected online in any sparse-reward environment with any off-policy algorithm. Our method is based on a reward bonus given to demonstrations and successful episodes, encouraging expert imitation and self-imitation. First, we give a reward bonus to the transitions coming from demonstrations to encourage the agent to match the demonstrated behaviour. Then, upon collecting a successful episode, we relabel its transitions with the same bonus before adding them to the replay buffer, encouraging the agent to also match its previous successes. Our experiments focus on manipulation robotics, specifically on three tasks for a 6 degrees-of-freedom robotic arm in simulation. We show that our method based on reward relabeling improves the performance of the base algorithm (SAC and DDPG) on these tasks, even in the absence of demonstrations. Furthermore, integrating into our method two improvements from previous works allows our approach to outperform all baselines.","classes":{"dataset":0.3559016585}}
{"title":"Neural Myerson Auction for Truthful and Energy-Efficient Autonomous Aerial Data Delivery","description":"A successful deployment of drones provides an ideal solution for surveillance systems. Using drones for surveillance can provide access to areas that may be difficult or impossible to reach by humans or in-land vehicles gathering images or video recordings of a specific target in their coverage. Therefore, we introduces a data delivery drone to transfer collected surveillance data in harsh communication conditions. This paper proposes a Myerson auction-based asynchronous data delivery in an aerial distributed data platform in surveillance systems taking battery limitation and long flight constraints into account. In this paper, multiple delivery drones compete to offer data transfer to a single fixed-location surveillance drone. Our proposed Myerson auction-based algorithm, which uses the truthful second-price auction (SPA) as a baseline, is to maximize the seller's revenue while meeting several desirable properties, i.e., individual rationality and incentive compatibility while pursuing truthful operations. On top of these SPA-based operations, a deep learning-based framework is additionally designed for delivery performance improvements.","link":"http://arxiv.org/abs/2201.01170v1","created":"2021-12-29","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Neural Myerson Auction for Truthful and Energy-Efficient Autonomous Aerial Data Delivery A successful deployment of drones provides an ideal solution for surveillance systems. Using drones for surveillance can provide access to areas that may be difficult or impossible to reach by humans or in-land vehicles gathering images or video recordings of a specific target in their coverage. Therefore, we introduces a data delivery drone to transfer collected surveillance data in harsh communication conditions. This paper proposes a Myerson auction-based asynchronous data delivery in an aerial distributed data platform in surveillance systems taking battery limitation and long flight constraints into account. In this paper, multiple delivery drones compete to offer data transfer to a single fixed-location surveillance drone. Our proposed Myerson auction-based algorithm, which uses the truthful second-price auction (SPA) as a baseline, is to maximize the seller's revenue while meeting several desirable properties, i.e., individual rationality and incentive compatibility while pursuing truthful operations. On top of these SPA-based operations, a deep learning-based framework is additionally designed for delivery performance improvements.","classes":{"dataset":0.4591579437}}
{"title":"Graph augmented Deep Reinforcement Learning in the GameRLand3D environment","description":"We address planning and navigation in challenging 3D video games featuring maps with disconnected regions reachable by agents using special actions. In this setting, classical symbolic planners are not applicable or difficult to adapt. We introduce a hybrid technique combining a low level policy trained with reinforcement learning and a graph based high level classical planner. In addition to providing human-interpretable paths, the approach improves the generalization performance of an end-to-end approach in unseen maps, where it achieves a 20% absolute increase in success rate over a recurrent end-to-end agent on a point to point navigation task in yet unseen large-scale maps of size 1km x 1km. In an in-depth experimental study, we quantify the limitations of end-to-end Deep RL approaches in vast environments and we also introduce \"GameRLand3D\", a new benchmark and soon to be released environment can generate complex procedural 3D maps for navigation tasks.","link":"http://arxiv.org/abs/2112.11731v1","created":"2021-12-22","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Graph augmented Deep Reinforcement Learning in the GameRLand3D environment We address planning and navigation in challenging 3D video games featuring maps with disconnected regions reachable by agents using special actions. In this setting, classical symbolic planners are not applicable or difficult to adapt. We introduce a hybrid technique combining a low level policy trained with reinforcement learning and a graph based high level classical planner. In addition to providing human-interpretable paths, the approach improves the generalization performance of an end-to-end approach in unseen maps, where it achieves a 20% absolute increase in success rate over a recurrent end-to-end agent on a point to point navigation task in yet unseen large-scale maps of size 1km x 1km. In an in-depth experimental study, we quantify the limitations of end-to-end Deep RL approaches in vast environments and we also introduce \"GameRLand3D\", a new benchmark and soon to be released environment can generate complex procedural 3D maps for navigation tasks.","classes":{"dataset":0.1980878711}}
{"title":"Quantum Algorithms for Reinforcement Learning with a Generative Model","description":"Reinforcement learning studies how an agent should interact with an environment to maximize its cumulative reward. A standard way to study this question abstractly is to ask how many samples an agent needs from the environment to learn an optimal policy for a $\\gamma$-discounted Markov decision process (MDP). For such an MDP, we design quantum algorithms that approximate an optimal policy ($\\pi^*$), the optimal value function ($v^*$), and the optimal $Q$-function ($q^*$), assuming the algorithms can access samples from the environment in quantum superposition. This assumption is justified whenever there exists a simulator for the environment; for example, if the environment is a video game or some other program. Our quantum algorithms, inspired by value iteration, achieve quadratic speedups over the best-possible classical sample complexities in the approximation accuracy ($\\epsilon$) and two main parameters of the MDP: the effective time horizon ($\\frac{1}{1-\\gamma}$) and the size of the action space ($A$). Moreover, we show that our quantum algorithm for computing $q^*$ is optimal by proving a matching quantum lower bound.","link":"http://arxiv.org/abs/2112.08451v1","created":"2021-12-15","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Quantum Algorithms for Reinforcement Learning with a Generative Model Reinforcement learning studies how an agent should interact with an environment to maximize its cumulative reward. A standard way to study this question abstractly is to ask how many samples an agent needs from the environment to learn an optimal policy for a $\\gamma$-discounted Markov decision process (MDP). For such an MDP, we design quantum algorithms that approximate an optimal policy ($\\pi^*$), the optimal value function ($v^*$), and the optimal $Q$-function ($q^*$), assuming the algorithms can access samples from the environment in quantum superposition. This assumption is justified whenever there exists a simulator for the environment; for example, if the environment is a video game or some other program. Our quantum algorithms, inspired by value iteration, achieve quadratic speedups over the best-possible classical sample complexities in the approximation accuracy ($\\epsilon$) and two main parameters of the MDP: the effective time horizon ($\\frac{1}{1-\\gamma}$) and the size of the action space ($A$). Moreover, we show that our quantum algorithm for computing $q^*$ is optimal by proving a matching quantum lower bound.","classes":{"dataset":0.6422554851}}
{"title":"Controlled-rearing studies of newborn chicks and deep neural networks","description":"Convolutional neural networks (CNNs) can now achieve human-level performance on challenging object recognition tasks. CNNs are also the leading quantitative models in terms of predicting neural and behavioral responses in visual recognition tasks. However, there is a widely accepted critique of CNN models: unlike newborn animals, which learn rapidly and efficiently, CNNs are thought to be \"data hungry,\" requiring massive amounts of training data to develop accurate models for object recognition. This critique challenges the promise of using CNNs as models of visual development. Here, we directly examined whether CNNs are more data hungry than newborn animals by performing parallel controlled-rearing experiments on newborn chicks and CNNs. We raised newborn chicks in strictly controlled visual environments, then simulated the training data available in that environment by constructing a virtual animal chamber in a video game engine. We recorded the visual images acquired by an agent moving through the virtual chamber and used those images to train CNNs. When CNNs received similar visual training data as chicks, the CNNs successfully solved the same challenging view-invariant object recognition tasks as the chicks. Thus, the CNNs were not more data hungry than animals: both CNNs and chicks successfully developed robust object models from training data of a single object.","link":"http://arxiv.org/abs/2112.06106v1","created":"2021-12-12","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Controlled-rearing studies of newborn chicks and deep neural networks Convolutional neural networks (CNNs) can now achieve human-level performance on challenging object recognition tasks. CNNs are also the leading quantitative models in terms of predicting neural and behavioral responses in visual recognition tasks. However, there is a widely accepted critique of CNN models: unlike newborn animals, which learn rapidly and efficiently, CNNs are thought to be \"data hungry,\" requiring massive amounts of training data to develop accurate models for object recognition. This critique challenges the promise of using CNNs as models of visual development. Here, we directly examined whether CNNs are more data hungry than newborn animals by performing parallel controlled-rearing experiments on newborn chicks and CNNs. We raised newborn chicks in strictly controlled visual environments, then simulated the training data available in that environment by constructing a virtual animal chamber in a video game engine. We recorded the visual images acquired by an agent moving through the virtual chamber and used those images to train CNNs. When CNNs received similar visual training data as chicks, the CNNs successfully solved the same challenging view-invariant object recognition tasks as the chicks. Thus, the CNNs were not more data hungry than animals: both CNNs and chicks successfully developed robust object models from training data of a single object.","classes":{"dataset":0.1936426163}}
{"title":"Modeling Live Video Streaming: Real-Time Classification, QoE Inference, and Field Evaluation","description":"Social media, professional sports, and video games are driving rapid growth in live video streaming, on platforms such as Twitch and YouTube Live. Live streaming experience is very susceptible to short-time-scale network congestion since client playback buffers are often no more than a few seconds. Unfortunately, identifying such streams and measuring their QoE for network management is challenging, since content providers largely use the same delivery infrastructure for live and video-on-demand (VoD) streaming, and packet inspection techniques (including SNI/DNS query monitoring) cannot always distinguish between the two.   In this paper, we design, build, and deploy ReCLive: a machine learning method for live video detection and QoE measurement based on network-level behavioral characteristics. Our contributions are four-fold: (1) We analyze about 23,000 video streams from Twitch and YouTube, and identify key features in their traffic profile that differentiate live and on-demand streaming. We release our traffic traces as open data to the public; (2) We develop an LSTM-based binary classifier model that distinguishes live from on-demand streams in real-time with over 95% accuracy across providers; (3) We develop a method that estimates QoE metrics of live streaming flows in terms of resolution and buffer stall events with overall accuracies of 93% and 90%, respectively; and (4) Finally, we prototype our solution, train it in the lab, and deploy it in a live ISP network serving more than 7,000 subscribers. Our method provides ISPs with fine-grained visibility into live video streams, enabling them to measure and improve user experience.","link":"http://arxiv.org/abs/2112.02637v1","created":"2021-12-05","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Modeling Live Video Streaming: Real-Time Classification, QoE Inference, and Field Evaluation Social media, professional sports, and video games are driving rapid growth in live video streaming, on platforms such as Twitch and YouTube Live. Live streaming experience is very susceptible to short-time-scale network congestion since client playback buffers are often no more than a few seconds. Unfortunately, identifying such streams and measuring their QoE for network management is challenging, since content providers largely use the same delivery infrastructure for live and video-on-demand (VoD) streaming, and packet inspection techniques (including SNI/DNS query monitoring) cannot always distinguish between the two.   In this paper, we design, build, and deploy ReCLive: a machine learning method for live video detection and QoE measurement based on network-level behavioral characteristics. Our contributions are four-fold: (1) We analyze about 23,000 video streams from Twitch and YouTube, and identify key features in their traffic profile that differentiate live and on-demand streaming. We release our traffic traces as open data to the public; (2) We develop an LSTM-based binary classifier model that distinguishes live from on-demand streams in real-time with over 95% accuracy across providers; (3) We develop a method that estimates QoE metrics of live streaming flows in terms of resolution and buffer stall events with overall accuracies of 93% and 90%, respectively; and (4) Finally, we prototype our solution, train it in the lab, and deploy it in a live ISP network serving more than 7,000 subscribers. Our method provides ISPs with fine-grained visibility into live video streams, enabling them to measure and improve user experience.","classes":{"dataset":0.315120846}}
{"title":"A note on stabilizing reinforcement learning","description":"Reinforcement learning is a general methodology of adaptive optimal control that has attracted much attention in various fields ranging from video game industry to robot manipulators. Despite its remarkable performance demonstrations, plain reinforcement learning controllers do not guarantee stability which compromises their applicability in industry. To provide such guarantees, measures have to be taken. This gives rise to what could generally be called stabilizing reinforcement learning. Concrete approaches range from employment of human overseers to filter out unsafe actions to formally verified shields and fusion with classical stabilizing controllers. A line of attack that utilizes elements of adaptive control has become fairly popular in the recent years. In this note, we critically address such an approach in a fairly general actor-critic setup for nonlinear time-continuous environments. The actor network utilizes a so-called robustifying term that is supposed to compensate for the neural network errors. The corresponding stability analysis is based on the value function itself. We indicate a problem in such a stability analysis and provide a counterexample to the overall control scheme. Implications for such a line of attack in stabilizing reinforcement learning are discussed. Furthermore, unfortunately the said problem possess no fix without a substantial reconsideration of the whole approach. As a positive message, we derive a stochastic critic neural network weight convergence analysis provided that the environment was stabilized.","link":"http://arxiv.org/abs/2111.12316v2","created":"2021-11-24","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"A note on stabilizing reinforcement learning Reinforcement learning is a general methodology of adaptive optimal control that has attracted much attention in various fields ranging from video game industry to robot manipulators. Despite its remarkable performance demonstrations, plain reinforcement learning controllers do not guarantee stability which compromises their applicability in industry. To provide such guarantees, measures have to be taken. This gives rise to what could generally be called stabilizing reinforcement learning. Concrete approaches range from employment of human overseers to filter out unsafe actions to formally verified shields and fusion with classical stabilizing controllers. A line of attack that utilizes elements of adaptive control has become fairly popular in the recent years. In this note, we critically address such an approach in a fairly general actor-critic setup for nonlinear time-continuous environments. The actor network utilizes a so-called robustifying term that is supposed to compensate for the neural network errors. The corresponding stability analysis is based on the value function itself. We indicate a problem in such a stability analysis and provide a counterexample to the overall control scheme. Implications for such a line of attack in stabilizing reinforcement learning are discussed. Furthermore, unfortunately the said problem possess no fix without a substantial reconsideration of the whole approach. As a positive message, we derive a stochastic critic neural network weight convergence analysis provided that the environment was stabilized.","classes":{"dataset":0.1150723174}}
{"title":"Improving Experience Replay through Modeling of Similar Transitions' Sets","description":"In this work, we propose and evaluate a new reinforcement learning method, COMPact Experience Replay (COMPER), which uses temporal difference learning with predicted target values based on recurrence over sets of similar transitions, and a new approach for experience replay based on two transitions memories. Our objective is to reduce the required number of experiences to agent training regarding the total accumulated rewarding in the long run. Its relevance to reinforcement learning is related to the small number of observations that it needs to achieve results similar to that obtained by relevant methods in the literature, that generally demand millions of video frames to train an agent on the Atari 2600 games. We report detailed results from five training trials of COMPER for just 100,000 frames and about 25,000 iterations with a small experiences memory on eight challenging games of Arcade Learning Environment (ALE). We also present results for a DQN agent with the same experimental protocol on the same games set as the baseline. To verify the performance of COMPER on approximating a good policy from a smaller number of observations, we also compare its results with that obtained from millions of frames presented on the benchmark of ALE.","link":"http://arxiv.org/abs/2111.06907v1","created":"2021-11-12","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"Improving Experience Replay through Modeling of Similar Transitions' Sets In this work, we propose and evaluate a new reinforcement learning method, COMPact Experience Replay (COMPER), which uses temporal difference learning with predicted target values based on recurrence over sets of similar transitions, and a new approach for experience replay based on two transitions memories. Our objective is to reduce the required number of experiences to agent training regarding the total accumulated rewarding in the long run. Its relevance to reinforcement learning is related to the small number of observations that it needs to achieve results similar to that obtained by relevant methods in the literature, that generally demand millions of video frames to train an agent on the Atari 2600 games. We report detailed results from five training trials of COMPER for just 100,000 frames and about 25,000 iterations with a small experiences memory on eight challenging games of Arcade Learning Environment (ALE). We also present results for a DQN agent with the same experimental protocol on the same games set as the baseline. To verify the performance of COMPER on approximating a good policy from a smaller number of observations, we also compare its results with that obtained from millions of frames presented on the benchmark of ALE.","classes":{"dataset":0.3491465747}}
{"title":"FREGAN : an application of generative adversarial networks in enhancing the frame rate of videos","description":"A digital video is a collection of individual frames, while streaming the video the scene utilized the time slice for each frame. High refresh rate and high frame rate is the demand of all high technology applications. The action tracking in videos becomes easier and motion becomes smoother in gaming applications due to the high refresh rate. It provides a faster response because of less time in between each frame that is displayed on the screen. FREGAN (Frame Rate Enhancement Generative Adversarial Network) model has been proposed, which predicts future frames of a video sequence based on a sequence of past frames. In this paper, we investigated the GAN model and proposed FREGAN for the enhancement of frame rate in videos. We have utilized Huber loss as a loss function in the proposed FREGAN. It provided excellent results in super-resolution and we have tried to reciprocate that performance in the application of frame rate enhancement. We have validated the effectiveness of the proposed model on the standard datasets (UCF101 and RFree500). The experimental outcomes illustrate that the proposed model has a Peak signal-to-noise ratio (PSNR) of 34.94 and a Structural Similarity Index (SSIM) of 0.95.","link":"http://arxiv.org/abs/2111.01105v1","created":"2021-11-01","tags":["arxiv","ml","gaming"],"meta":{"query":"machine AND learning AND video AND games OR machine AND learning AND gaming"},"text":"FREGAN : an application of generative adversarial networks in enhancing the frame rate of videos A digital video is a collection of individual frames, while streaming the video the scene utilized the time slice for each frame. High refresh rate and high frame rate is the demand of all high technology applications. The action tracking in videos becomes easier and motion becomes smoother in gaming applications due to the high refresh rate. It provides a faster response because of less time in between each frame that is displayed on the screen. FREGAN (Frame Rate Enhancement Generative Adversarial Network) model has been proposed, which predicts future frames of a video sequence based on a sequence of past frames. In this paper, we investigated the GAN model and proposed FREGAN for the enhancement of frame rate in videos. We have utilized Huber loss as a loss function in the proposed FREGAN. It provided excellent results in super-resolution and we have tried to reciprocate that performance in the application of frame rate enhancement. We have validated the effectiveness of the proposed model on the standard datasets (UCF101 and RFree500). The experimental outcomes illustrate that the proposed model has a Peak signal-to-noise ratio (PSNR) of 34.94 and a Structural Similarity Index (SSIM) of 0.95.","classes":{"dataset":0.2717036009}}
{"title":"Putting ChatGPT's Medical Advice to the (Turing) Test","description":"Objective: Assess the feasibility of using ChatGPT or a similar AI-based chatbot for patient-provider communication. Participants: A US representative sample of 430 study participants aged 18 and above. 53.2% of respondents analyzed were women; their average age was 47.1. Exposure: Ten representative non-administrative patient-provider interactions were extracted from the EHR. Patients' questions were placed in ChatGPT with a request for the chatbot to respond using approximately the same word count as the human provider's response. In the survey, each patient's question was followed by a provider- or ChatGPT-generated response. Participants were informed that five responses were provider-generated and five were chatbot-generated. Participants were asked, and incentivized financially, to correctly identify the response source. Participants were also asked about their trust in chatbots' functions in patient-provider communication, using a Likert scale of 1-5. Results: The correct classification of responses ranged between 49.0% to 85.7% for different questions. On average, chatbot responses were correctly identified 65.5% of the time, and provider responses were correctly distinguished 65.1% of the time. On average, responses toward patients' trust in chatbots' functions were weakly positive (mean Likert score: 3.4), with lower trust as the health-related complexity of the task in questions increased. Conclusions: ChatGPT responses to patient questions were weakly distinguishable from provider responses. Laypeople appear to trust the use of chatbots to answer lower risk health questions.","link":"http://arxiv.org/abs/2301.10035v1","created":"2023-01-24","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Putting ChatGPT's Medical Advice to the (Turing) Test Objective: Assess the feasibility of using ChatGPT or a similar AI-based chatbot for patient-provider communication. Participants: A US representative sample of 430 study participants aged 18 and above. 53.2% of respondents analyzed were women; their average age was 47.1. Exposure: Ten representative non-administrative patient-provider interactions were extracted from the EHR. Patients' questions were placed in ChatGPT with a request for the chatbot to respond using approximately the same word count as the human provider's response. In the survey, each patient's question was followed by a provider- or ChatGPT-generated response. Participants were informed that five responses were provider-generated and five were chatbot-generated. Participants were asked, and incentivized financially, to correctly identify the response source. Participants were also asked about their trust in chatbots' functions in patient-provider communication, using a Likert scale of 1-5. Results: The correct classification of responses ranged between 49.0% to 85.7% for different questions. On average, chatbot responses were correctly identified 65.5% of the time, and provider responses were correctly distinguished 65.1% of the time. On average, responses toward patients' trust in chatbots' functions were weakly positive (mean Likert score: 3.4), with lower trust as the health-related complexity of the task in questions increased. Conclusions: ChatGPT responses to patient questions were weakly distinguishable from provider responses. Laypeople appear to trust the use of chatbots to answer lower risk health questions.","classes":{"dataset":0.1099715158}}
{"title":"Is ChatGPT A Good Translator? A Preliminary Study","description":"This report provides a preliminary evaluation of ChatGPT for machine translation, including translation prompt, multilingual translation, and translation robustness. We adopt the prompts advised by ChatGPT to trigger its translation ability and find that the candidate prompts generally work well and show minor performance differences. By evaluating on a number of benchmark test sets, we find that ChatGPT performs competitively with commercial translation products (e.g., Google Translate) on high-resource European languages but lags behind significantly on lowresource or distant languages. As for the translation robustness, ChatGPT does not perform as well as the commercial systems on biomedical abstracts or Reddit comments but is potentially a good translator for spoken language. Scripts and data: https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator","link":"http://arxiv.org/abs/2301.08745v1","created":"2023-01-20","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Is ChatGPT A Good Translator? A Preliminary Study This report provides a preliminary evaluation of ChatGPT for machine translation, including translation prompt, multilingual translation, and translation robustness. We adopt the prompts advised by ChatGPT to trigger its translation ability and find that the candidate prompts generally work well and show minor performance differences. By evaluating on a number of benchmark test sets, we find that ChatGPT performs competitively with commercial translation products (e.g., Google Translate) on high-resource European languages but lags behind significantly on lowresource or distant languages. As for the translation robustness, ChatGPT does not perform as well as the commercial systems on biomedical abstracts or Reddit comments but is potentially a good translator for spoken language. Scripts and data: https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator","classes":{"dataset":0.0802297071}}
{"title":"The moral authority of ChatGPT","description":"ChatGPT is not only fun to chat with, but it also searches information, answers questions, and gives advice. With consistent moral advice, it might improve the moral judgment and decisions of users, who often hold contradictory moral beliefs. Unfortunately, ChatGPT turns out highly inconsistent as a moral advisor. Nonetheless, it influences users' moral judgment, we find in an experiment, even if they know they are advised by a chatting bot, and they underestimate how much they are influenced. Thus, ChatGPT threatens to corrupt rather than improves users' judgment. These findings raise the question of how to ensure the responsible use of ChatGPT and similar AI. Transparency is often touted but seems ineffective. We propose training to improve digital literacy.","link":"http://arxiv.org/abs/2301.07098v1","created":"2023-01-13","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"The moral authority of ChatGPT ChatGPT is not only fun to chat with, but it also searches information, answers questions, and gives advice. With consistent moral advice, it might improve the moral judgment and decisions of users, who often hold contradictory moral beliefs. Unfortunately, ChatGPT turns out highly inconsistent as a moral advisor. Nonetheless, it influences users' moral judgment, we find in an experiment, even if they know they are advised by a chatting bot, and they underestimate how much they are influenced. Thus, ChatGPT threatens to corrupt rather than improves users' judgment. These findings raise the question of how to ensure the responsible use of ChatGPT and similar AI. Transparency is often touted but seems ineffective. We propose training to improve digital literacy.","classes":{"dataset":0.0441719331}}
{"title":"AI Insights into Theoretical Physics and the Swampland Program: A Journey Through the Cosmos with ChatGPT","description":"In this case study, we explore the capabilities and limitations of ChatGPT, a natural language processing model developed by OpenAI, in the field of string theoretical swampland conjectures. We find that it is effective at paraphrasing and explaining concepts in a variety of styles, but not at genuinely connecting concepts. It will provide false information with full confidence and make up statements when necessary. However, its ingenious use of language can be fruitful for identifying analogies and describing visual representations of abstract concepts.","link":"http://arxiv.org/abs/2301.08155v1","created":"2023-01-10","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"AI Insights into Theoretical Physics and the Swampland Program: A Journey Through the Cosmos with ChatGPT In this case study, we explore the capabilities and limitations of ChatGPT, a natural language processing model developed by OpenAI, in the field of string theoretical swampland conjectures. We find that it is effective at paraphrasing and explaining concepts in a variety of styles, but not at genuinely connecting concepts. It will provide false information with full confidence and make up statements when necessary. However, its ingenious use of language can be fruitful for identifying analogies and describing visual representations of abstract concepts.","classes":{"dataset":0.0539741963}}
{"title":"The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation","description":"Conversational artificial intelligence (AI) disrupts how humans interact with technology. Recently, OpenAI introduced ChatGPT, a state-of-the-art dialogue model that can converse with its human counterparts with unprecedented capabilities. ChatGPT has witnessed tremendous attention from the media, academia, industry, and the general public, attracting more than a million users within days of its release. However, its explosive adoption for information search and as an automated decision aid underscores the importance to understand its limitations and biases. This paper focuses on one of democratic society's most important decision-making processes: political elections. Prompting ChatGPT with 630 political statements from two leading voting advice applications and the nation-agnostic political compass test in three pre-registered experiments, we uncover ChatGPT's pro-environmental, left-libertarian ideology. For example, ChatGPT would impose taxes on flights, restrict rent increases, and legalize abortion. In the 2021 elections, it would have voted most likely for the Greens both in Germany (B\\\"undnis 90/Die Gr\\\"unen) and in the Netherlands (GroenLinks). Our findings are robust when negating the prompts, reversing the order of the statements, varying prompt formality, and across languages (English, German, Dutch, and Spanish). We conclude by discussing the implications of politically biased conversational AI on society.","link":"http://arxiv.org/abs/2301.01768v1","created":"2023-01-05","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation Conversational artificial intelligence (AI) disrupts how humans interact with technology. Recently, OpenAI introduced ChatGPT, a state-of-the-art dialogue model that can converse with its human counterparts with unprecedented capabilities. ChatGPT has witnessed tremendous attention from the media, academia, industry, and the general public, attracting more than a million users within days of its release. However, its explosive adoption for information search and as an automated decision aid underscores the importance to understand its limitations and biases. This paper focuses on one of democratic society's most important decision-making processes: political elections. Prompting ChatGPT with 630 political statements from two leading voting advice applications and the nation-agnostic political compass test in three pre-registered experiments, we uncover ChatGPT's pro-environmental, left-libertarian ideology. For example, ChatGPT would impose taxes on flights, restrict rent increases, and legalize abortion. In the 2021 elections, it would have voted most likely for the Greens both in Germany (B\\\"undnis 90/Die Gr\\\"unen) and in the Netherlands (GroenLinks). Our findings are robust when negating the prompts, reversing the order of the statements, varying prompt formality, and across languages (English, German, Dutch, and Spanish). We conclude by discussing the implications of politically biased conversational AI on society.","classes":{"dataset":0.0952154472}}
{"title":"Chatbots as Problem Solvers: Playing Twenty Questions with Role Reversals","description":"New chat AI applications like ChatGPT offer an advanced understanding of question context and memory across multi-step tasks, such that experiments can test its deductive reasoning. This paper proposes a multi-role and multi-step challenge, where ChatGPT plays the classic twenty-questions game but innovatively switches roles from the questioner to the answerer. The main empirical result establishes that this generation of chat applications can guess random object names in fewer than twenty questions (average, 12) and correctly guess 94% of the time across sixteen different experimental setups. The research introduces four novel cases where the chatbot fields the questions, asks the questions, both question-answer roles, and finally tries to guess appropriate contextual emotions. One task that humans typically fail but trained chat applications complete involves playing bilingual games of twenty questions (English answers to Spanish questions). Future variations address direct problem-solving using a similar inquisitive format to arrive at novel outcomes deductively, such as patentable inventions or combination thinking. Featured applications of this dialogue format include complex protein designs, neuroscience metadata, and child development educational materials.","link":"http://arxiv.org/abs/2301.01743v1","created":"2023-01-01","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Chatbots as Problem Solvers: Playing Twenty Questions with Role Reversals New chat AI applications like ChatGPT offer an advanced understanding of question context and memory across multi-step tasks, such that experiments can test its deductive reasoning. This paper proposes a multi-role and multi-step challenge, where ChatGPT plays the classic twenty-questions game but innovatively switches roles from the questioner to the answerer. The main empirical result establishes that this generation of chat applications can guess random object names in fewer than twenty questions (average, 12) and correctly guess 94% of the time across sixteen different experimental setups. The research introduces four novel cases where the chatbot fields the questions, asks the questions, both question-answer roles, and finally tries to guess appropriate contextual emotions. One task that humans typically fail but trained chat applications complete involves playing bilingual games of twenty questions (English answers to Spanish questions). Future variations address direct problem-solving using a similar inquisitive format to arrive at novel outcomes deductively, such as patentable inventions or combination thinking. Featured applications of this dialogue format include complex protein designs, neuroscience metadata, and child development educational materials.","classes":{"dataset":0.0740082413}}
{"title":"How would Stance Detection Techniques Evolve after the Launch of ChatGPT?","description":"Stance detection refers to the task of extracting the standpoint (Favor, Against or Neither) towards a target in given texts. Such research gains increasing attention with the proliferation of social media contents. The conventional framework of handling stance detection is converting it into text classification tasks. Deep learning models have already replaced rule-based models and traditional machine learning models in solving such problems. Current deep neural networks are facing two main challenges which are insufficient labeled data and information in social media posts and the unexplainable nature of deep learning models. A new pre-trained language model chatGPT was launched on Nov 30, 2022. For the stance detection tasks, our experiments show that ChatGPT can achieve SOTA or similar performance for commonly used datasets including SemEval-2016 and P-Stance. At the same time, ChatGPT can provide explanation for its own prediction, which is beyond the capability of any existing model. The explanations for the cases it cannot provide classification results are especially useful. ChatGPT has the potential to be the best AI model for stance detection tasks in NLP, or at least change the research paradigm of this field. ChatGPT also opens up the possibility of building explanatory AI for stance detection.","link":"http://arxiv.org/abs/2212.14548v1","created":"2022-12-30","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"How would Stance Detection Techniques Evolve after the Launch of ChatGPT? Stance detection refers to the task of extracting the standpoint (Favor, Against or Neither) towards a target in given texts. Such research gains increasing attention with the proliferation of social media contents. The conventional framework of handling stance detection is converting it into text classification tasks. Deep learning models have already replaced rule-based models and traditional machine learning models in solving such problems. Current deep neural networks are facing two main challenges which are insufficient labeled data and information in social media posts and the unexplainable nature of deep learning models. A new pre-trained language model chatGPT was launched on Nov 30, 2022. For the stance detection tasks, our experiments show that ChatGPT can achieve SOTA or similar performance for commonly used datasets including SemEval-2016 and P-Stance. At the same time, ChatGPT can provide explanation for its own prediction, which is beyond the capability of any existing model. The explanations for the cases it cannot provide classification results are especially useful. ChatGPT has the potential to be the best AI model for stance detection tasks in NLP, or at least change the research paradigm of this field. ChatGPT also opens up the possibility of building explanatory AI for stance detection.","classes":{"dataset":0.1552553773}}
{"title":"Transformers Go for the LOLs: Generating (Humourous) Titles from Scientific Abstracts End-to-End","description":"We consider the end-to-end abstract-to-title generation problem, exploring seven recent transformer based models (including ChatGPT) fine-tuned on more than 30k abstract-title pairs from NLP and machine learning venues. As an extension, we also consider the harder problem of generating humorous paper titles. For the latter, we compile the first large-scale humor annotated dataset for scientific papers in the NLP/ML domains, comprising almost 2.5k titles. We evaluate all models using human and automatic metrics. Our human evaluation suggests that our best end-to-end system performs similarly to human authors (but arguably slightly worse). Generating funny titles is more difficult, however, and our automatic systems clearly underperform relative to humans and often learn dataset artefacts of humor. Finally, ChatGPT, without any fine-tuning, performs on the level of our best fine-tuned system.","link":"http://arxiv.org/abs/2212.10522v1","created":"2022-12-20","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Transformers Go for the LOLs: Generating (Humourous) Titles from Scientific Abstracts End-to-End We consider the end-to-end abstract-to-title generation problem, exploring seven recent transformer based models (including ChatGPT) fine-tuned on more than 30k abstract-title pairs from NLP and machine learning venues. As an extension, we also consider the harder problem of generating humorous paper titles. For the latter, we compile the first large-scale humor annotated dataset for scientific papers in the NLP/ML domains, comprising almost 2.5k titles. We evaluate all models using human and automatic metrics. Our human evaluation suggests that our best end-to-end system performs similarly to human authors (but arguably slightly worse). Generating funny titles is more difficult, however, and our automatic systems clearly underperform relative to humans and often learn dataset artefacts of humor. Finally, ChatGPT, without any fine-tuning, performs on the level of our best fine-tuned system.","classes":{"dataset":0.2987791598}}
{"title":"Are Deep Neural Networks SMARTer than Second Graders?","description":"Recent times have witnessed an increasing number of applications of deep neural networks towards solving tasks that require superior cognitive abilities, e.g., playing Go, generating art, question answering (such as ChatGPT), etc. Such a dramatic progress raises the question: how generalizable are neural networks in solving problems that demand broad skills? To answer this question, we propose SMART: a Simple Multimodal Algorithmic Reasoning Task and the associated SMART-101 dataset, for evaluating the abstraction, deduction, and generalization abilities of neural networks in solving visuo-linguistic puzzles designed specifically for children in the 6-8 age group. Our dataset consists of 101 unique puzzles; each puzzle comprises a picture and a question, and their solution needs a mix of several elementary skills, including arithmetic, algebra, and spatial reasoning, among others. To scale our dataset towards training deep neural networks, we programmatically generate entirely new instances for each puzzle while retaining their solution algorithm. To benchmark the performance on the SMART-101 dataset, we propose a vision and language meta-learning model using varied state-of-the-art backbone neural networks. Our experiments reveal that while powerful deep models offer reasonable performances on puzzles that they are trained on, they are not better than random accuracy when analyzed for generalization. We also evaluate the recent ChatGPT large language model on a subset of our dataset and find that while ChatGPT produces convincing reasoning abilities, the answers are often incorrect.","link":"http://arxiv.org/abs/2212.09993v2","created":"2022-12-20","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Are Deep Neural Networks SMARTer than Second Graders? Recent times have witnessed an increasing number of applications of deep neural networks towards solving tasks that require superior cognitive abilities, e.g., playing Go, generating art, question answering (such as ChatGPT), etc. Such a dramatic progress raises the question: how generalizable are neural networks in solving problems that demand broad skills? To answer this question, we propose SMART: a Simple Multimodal Algorithmic Reasoning Task and the associated SMART-101 dataset, for evaluating the abstraction, deduction, and generalization abilities of neural networks in solving visuo-linguistic puzzles designed specifically for children in the 6-8 age group. Our dataset consists of 101 unique puzzles; each puzzle comprises a picture and a question, and their solution needs a mix of several elementary skills, including arithmetic, algebra, and spatial reasoning, among others. To scale our dataset towards training deep neural networks, we programmatically generate entirely new instances for each puzzle while retaining their solution algorithm. To benchmark the performance on the SMART-101 dataset, we propose a vision and language meta-learning model using varied state-of-the-art backbone neural networks. Our experiments reveal that while powerful deep models offer reasonable performances on puzzles that they are trained on, they are not better than random accuracy when analyzed for generalization. We also evaluate the recent ChatGPT large language model on a subset of our dataset and find that while ChatGPT produces convincing reasoning abilities, the answers are often incorrect.","classes":{"dataset":0.4925528169}}
{"title":"Chatbots in a Botnet World","description":"Question-and-answer formats provide a novel experimental platform for investigating cybersecurity questions. Unlike previous chatbots, the latest ChatGPT model from OpenAI supports an advanced understanding of complex coding questions. The research demonstrates thirteen coding tasks that generally qualify as stages in the MITRE ATT&CK framework, ranging from credential access to defense evasion. With varying success, the experimental prompts generate examples of keyloggers, logic bombs, obfuscated worms, and payment-fulfilled ransomware. The empirical results illustrate cases that support the broad gain of functionality, including self-replication and self-modification, evasion, and strategic understanding of complex cybersecurity goals. One surprising feature of ChatGPT as a language-only model centers on its ability to spawn coding approaches that yield images that obfuscate or embed executable programming steps or links.","link":"http://arxiv.org/abs/2212.11126v2","created":"2022-12-18","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"Chatbots in a Botnet World Question-and-answer formats provide a novel experimental platform for investigating cybersecurity questions. Unlike previous chatbots, the latest ChatGPT model from OpenAI supports an advanced understanding of complex coding questions. The research demonstrates thirteen coding tasks that generally qualify as stages in the MITRE ATT&CK framework, ranging from credential access to defense evasion. With varying success, the experimental prompts generate examples of keyloggers, logic bombs, obfuscated worms, and payment-fulfilled ransomware. The empirical results illustrate cases that support the broad gain of functionality, including self-replication and self-modification, evasion, and strategic understanding of complex cybersecurity goals. One surprising feature of ChatGPT as a language-only model centers on its ability to spawn coding approaches that yield images that obfuscate or embed executable programming steps or links.","classes":{"dataset":0.1299321353}}
{"title":"\"I think this is the most disruptive technology\": Exploring Sentiments of ChatGPT Early Adopters using Twitter Data","description":"Large language models have recently attracted significant attention due to their impressive performance on a variety of tasks. ChatGPT developed by OpenAI is one such implementation of a large, pre-trained language model that has gained immense popularity among early adopters, where certain users go to the extent of characterizing it as a disruptive technology in many domains. Understanding such early adopters' sentiments is important because it can provide insights into the potential success or failure of the technology, as well as its strengths and weaknesses. In this paper, we conduct a mixed-method study using 10,732 tweets from early ChatGPT users. We first use topic modelling to identify the main topics and then perform an in-depth qualitative sentiment analysis of each topic. Our results show that the majority of the early adopters have expressed overwhelmingly positive sentiments related to topics such as Disruptions to software development, Entertainment and exercising creativity. Only a limited percentage of users expressed concerns about issues such as the potential for misuse of ChatGPT, especially regarding topics such as Impact on educational aspects. We discuss these findings by providing specific examples for each topic and then detail implications related to addressing these concerns for both researchers and users.","link":"http://arxiv.org/abs/2212.05856v1","created":"2022-12-12","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"\"I think this is the most disruptive technology\": Exploring Sentiments of ChatGPT Early Adopters using Twitter Data Large language models have recently attracted significant attention due to their impressive performance on a variety of tasks. ChatGPT developed by OpenAI is one such implementation of a large, pre-trained language model that has gained immense popularity among early adopters, where certain users go to the extent of characterizing it as a disruptive technology in many domains. Understanding such early adopters' sentiments is important because it can provide insights into the potential success or failure of the technology, as well as its strengths and weaknesses. In this paper, we conduct a mixed-method study using 10,732 tweets from early ChatGPT users. We first use topic modelling to identify the main topics and then perform an in-depth qualitative sentiment analysis of each topic. Our results show that the majority of the early adopters have expressed overwhelmingly positive sentiments related to topics such as Disruptions to software development, Entertainment and exercising creativity. Only a limited percentage of users expressed concerns about issues such as the potential for misuse of ChatGPT, especially regarding topics such as Impact on educational aspects. We discuss these findings by providing specific examples for each topic and then detail implications related to addressing these concerns for both researchers and users.","classes":{"dataset":0.0328805521}}
{"title":"The Role of AI in Drug Discovery: Challenges, Opportunities, and Strategies","description":"Artificial intelligence (AI) has the potential to revolutionize the drug discovery process, offering improved efficiency, accuracy, and speed. However, the successful application of AI is dependent on the availability of high-quality data, the addressing of ethical concerns, and the recognition of the limitations of AI-based approaches. In this article, the benefits, challenges and drawbacks of AI in this field are reviewed, and possible strategies and approaches for overcoming the present obstacles are proposed. The use of data augmentation, explainable AI, and the integration of AI with traditional experimental methods, as well as the potential advantages of AI in pharmaceutical research are also discussed. Overall, this review highlights the potential of AI in drug discovery and provides insights into the challenges and opportunities for realizing its potential in this field.   Note from the human-authors: This article was created to test the ability of ChatGPT, a chatbot based on the GPT-3.5 language model, to assist human authors in writing review articles. The text generated by the AI following our instructions (see Supporting Information) was used as a starting point, and its ability to automatically generate content was evaluated. After conducting a thorough review, human authors practically rewrote the manuscript, striving to maintain a balance between the original proposal and scientific criteria. The advantages and limitations of using AI for this purpose are discussed in the last section.","link":"http://arxiv.org/abs/2212.08104v1","created":"2022-12-08","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"The Role of AI in Drug Discovery: Challenges, Opportunities, and Strategies Artificial intelligence (AI) has the potential to revolutionize the drug discovery process, offering improved efficiency, accuracy, and speed. However, the successful application of AI is dependent on the availability of high-quality data, the addressing of ethical concerns, and the recognition of the limitations of AI-based approaches. In this article, the benefits, challenges and drawbacks of AI in this field are reviewed, and possible strategies and approaches for overcoming the present obstacles are proposed. The use of data augmentation, explainable AI, and the integration of AI with traditional experimental methods, as well as the potential advantages of AI in pharmaceutical research are also discussed. Overall, this review highlights the potential of AI in drug discovery and provides insights into the challenges and opportunities for realizing its potential in this field.   Note from the human-authors: This article was created to test the ability of ChatGPT, a chatbot based on the GPT-3.5 language model, to assist human authors in writing review articles. The text generated by the AI following our instructions (see Supporting Information) was used as a starting point, and its ability to automatically generate content was evaluated. After conducting a thorough review, human authors practically rewrote the manuscript, striving to maintain a balance between the original proposal and scientific criteria. The advantages and limitations of using AI for this purpose are discussed in the last section.","classes":{"dataset":0.4463286996}}
{"title":"What would Harry say? Building Dialogue Agents for Characters in a Story","description":"We have a Christmas gift for Harry Potter fans all over the world. In this paper, we present Harry Potter Dialogue (HPD), a dataset that helps train Harry Potter-like dialogue agents. Such a task is typically viewed as a variant of personalized dialogue agents, but they differ significantly in three respects: 1) Harry lived in a virtual world of wizards, thus, real-world commonsense may not apply to Harry's conversations; 2) Harry's behavior is strongly linked to background information in conversations: the scene, its attributes and its relationship to other speakers; and 3) Such backgrounds are dynamically altered as the storyline goes on. The HPD dataset, as the first dataset to facilitate the study of dialogue agent construction for characters within a story, provides rich contextual information about each dialogue session such as scenes, character attributes, and relations. More importantly, all the background information will change over the course of the story. In addition, HPD could support both dialogue generation and retrieval tasks. We evaluate baselines such as Dialog-GPT and BOB to determine the extent to which they can generate Harry Potter-like responses. The experimental results disappoint us in that although the generated responses are fluent, they still seem out of character for Harry. Besides, we validate the current most robust dialogue agent, ChatGPT, which also can't generate plausible Harry-Potter-like responses in some cases, either. Our results suggest that there is much scope for future research.","link":"http://arxiv.org/abs/2211.06869v3","created":"2022-11-13","tags":["arxiv","ml","prompteng"],"meta":{"query":"abs:\"chatgpt\""},"text":"What would Harry say? Building Dialogue Agents for Characters in a Story We have a Christmas gift for Harry Potter fans all over the world. In this paper, we present Harry Potter Dialogue (HPD), a dataset that helps train Harry Potter-like dialogue agents. Such a task is typically viewed as a variant of personalized dialogue agents, but they differ significantly in three respects: 1) Harry lived in a virtual world of wizards, thus, real-world commonsense may not apply to Harry's conversations; 2) Harry's behavior is strongly linked to background information in conversations: the scene, its attributes and its relationship to other speakers; and 3) Such backgrounds are dynamically altered as the storyline goes on. The HPD dataset, as the first dataset to facilitate the study of dialogue agent construction for characters within a story, provides rich contextual information about each dialogue session such as scenes, character attributes, and relations. More importantly, all the background information will change over the course of the story. In addition, HPD could support both dialogue generation and retrieval tasks. We evaluate baselines such as Dialog-GPT and BOB to determine the extent to which they can generate Harry Potter-like responses. The experimental results disappoint us in that although the generated responses are fluent, they still seem out of character for Harry. Besides, we validate the current most robust dialogue agent, ChatGPT, which also can't generate plausible Harry-Potter-like responses in some cases, either. Our results suggest that there is much scope for future research.","classes":{"dataset":0.1295285374}}
{"title":"A Case Study in Engineering a Conversational Programming Assistant's Persona","description":"The Programmer's Assistant is an experimental prototype software development environment that integrates a chatbot with a code editor. Conversational capability was achieved by using an existing code-fluent Large Language Model and providing it with a prompt that establishes a conversational interaction pattern, a set of conventions, and a style of interaction appropriate for the application. A discussion of the evolution of the prompt provides a case study in how to coax an existing foundation model to behave in a desirable manner for a particular application.","link":"http://arxiv.org/abs/2301.10016v1","created":"2023-01-13","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"A Case Study in Engineering a Conversational Programming Assistant's Persona The Programmer's Assistant is an experimental prototype software development environment that integrates a chatbot with a code editor. Conversational capability was achieved by using an existing code-fluent Large Language Model and providing it with a prompt that establishes a conversational interaction pattern, a set of conventions, and a style of interaction appropriate for the application. A discussion of the evolution of the prompt provides a case study in how to coax an existing foundation model to behave in a desirable manner for a particular application.","classes":{"dataset":0.9518711567}}
{"title":"The Algonauts Project 2023 Challenge: How the Human Brain Makes Sense of Natural Scenes","description":"The sciences of biological and artificial intelligence are ever more intertwined. Neural computational principles inspire new intelligent machines, which are in turn used to advance theoretical understanding of the brain. To promote further exchange of ideas and collaboration between biological and artificial intelligence researchers, we introduce the 2023 installment of the Algonauts Project challenge: How the Human Brain Makes Sense of Natural Scenes (http://algonauts.csail.mit.edu). This installment prompts the fields of artificial and biological intelligence to come together towards building computational models of the visual brain using the largest and richest dataset of fMRI responses to visual scenes, the Natural Scenes Dataset (NSD). NSD provides high-quality fMRI responses to ~73,000 different naturalistic colored scenes, making it the ideal candidate for data-driven model building approaches promoted by the 2023 challenge. The challenge is open to all and makes results directly comparable and transparent through a public leaderboard automatically updated after each submission, thus allowing for rapid model development. We believe that the 2023 installment will spark symbiotic collaborations between biological and artificial intelligence scientists, leading to a deeper understanding of the brain through cutting-edge computational models and to novel ways of engineering artificial intelligent agents through inductive biases from biological systems.","link":"http://arxiv.org/abs/2301.03198v2","created":"2023-01-09","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"The Algonauts Project 2023 Challenge: How the Human Brain Makes Sense of Natural Scenes The sciences of biological and artificial intelligence are ever more intertwined. Neural computational principles inspire new intelligent machines, which are in turn used to advance theoretical understanding of the brain. To promote further exchange of ideas and collaboration between biological and artificial intelligence researchers, we introduce the 2023 installment of the Algonauts Project challenge: How the Human Brain Makes Sense of Natural Scenes (http://algonauts.csail.mit.edu). This installment prompts the fields of artificial and biological intelligence to come together towards building computational models of the visual brain using the largest and richest dataset of fMRI responses to visual scenes, the Natural Scenes Dataset (NSD). NSD provides high-quality fMRI responses to ~73,000 different naturalistic colored scenes, making it the ideal candidate for data-driven model building approaches promoted by the 2023 challenge. The challenge is open to all and makes results directly comparable and transparent through a public leaderboard automatically updated after each submission, thus allowing for rapid model development. We believe that the 2023 installment will spark symbiotic collaborations between biological and artificial intelligence scientists, leading to a deeper understanding of the brain through cutting-edge computational models and to novel ways of engineering artificial intelligent agents through inductive biases from biological systems.","classes":{"dataset":0.1306835115}}
{"title":"Fuzzing Deep-Learning Libraries via Large Language Models","description":"Detecting bugs in Deep Learning (DL) libraries is critical for almost all downstream DL systems in ensuring effectiveness and safety for the end users. As such, researchers have started developing various fuzzing or testing techniques targeting DL libraries. Previous work can be mainly classified into API-level fuzzing and model-level fuzzing. However, both types of techniques cannot detect bugs that can only be exposed by complex API sequences - API-level fuzzers cannot cover API sequences, while model-level fuzzers can only cover specific API sequence patterns and a small subset of APIs due to complicated input/shape constraints for tensor computations. To address these limitations, we propose LLMFuzz - the first automated approach to directly leveraging Large Pre-trained Language Models (LLMs) to generate input programs for fuzzing DL libraries. LLMs are trained on billions of code snippets and can autoregressively generate human-like code snippets. Our key insight is that modern LLMs can also include numerous code snippets invoking DL library APIs in their training corpora, and thus can implicitly learn the intricate DL API constraints and directly generate/mutate valid DL programs for fuzzing DL libraries. More specifically, we first directly use a generative LLM (e.g., Codex) to generate highquality seed programs based on input prompts. Then, we leverage an evolutionary fuzzing loop which applies an infilling LLM (e.g., InCoder) to further perform small mutations on the seed programs to generate more diverse API sequences for fuzzing DL libraries. Our experimental results on popular DL libraries demonstrate that LLMFuzz is able to cover 91.11% / 24.09% more APIs and achieve 30.38% / 50.84% higher code coverage than state-of-the-art fuzzers on TensorFlow / PyTorch. Furthermore, LLMFuzz is able to detect 65 bugs, with 41 already confirmed as previously unknown bugs.","link":"http://arxiv.org/abs/2212.14834v1","created":"2022-12-30","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Fuzzing Deep-Learning Libraries via Large Language Models Detecting bugs in Deep Learning (DL) libraries is critical for almost all downstream DL systems in ensuring effectiveness and safety for the end users. As such, researchers have started developing various fuzzing or testing techniques targeting DL libraries. Previous work can be mainly classified into API-level fuzzing and model-level fuzzing. However, both types of techniques cannot detect bugs that can only be exposed by complex API sequences - API-level fuzzers cannot cover API sequences, while model-level fuzzers can only cover specific API sequence patterns and a small subset of APIs due to complicated input/shape constraints for tensor computations. To address these limitations, we propose LLMFuzz - the first automated approach to directly leveraging Large Pre-trained Language Models (LLMs) to generate input programs for fuzzing DL libraries. LLMs are trained on billions of code snippets and can autoregressively generate human-like code snippets. Our key insight is that modern LLMs can also include numerous code snippets invoking DL library APIs in their training corpora, and thus can implicitly learn the intricate DL API constraints and directly generate/mutate valid DL programs for fuzzing DL libraries. More specifically, we first directly use a generative LLM (e.g., Codex) to generate highquality seed programs based on input prompts. Then, we leverage an evolutionary fuzzing loop which applies an infilling LLM (e.g., InCoder) to further perform small mutations on the seed programs to generate more diverse API sequences for fuzzing DL libraries. Our experimental results on popular DL libraries demonstrate that LLMFuzz is able to cover 91.11% / 24.09% more APIs and achieve 30.38% / 50.84% higher code coverage than state-of-the-art fuzzers on TensorFlow / PyTorch. Furthermore, LLMFuzz is able to detect 65 bugs, with 41 already confirmed as previously unknown bugs.","classes":{"dataset":0.0765141919}}
{"title":"Using Large Language Models to Generate Engaging Captions for Data Visualizations","description":"Creating compelling captions for data visualizations has been a longstanding challenge. Visualization researchers are typically untrained in journalistic reporting and hence the captions that are placed below data visualizations tend to be not overly engaging and rather just stick to basic observations about the data. In this work we explore the opportunities offered by the newly emerging crop of large language models (LLM) which use sophisticated deep learning technology to produce human-like prose. We ask, can these powerful software devices be purposed to produce engaging captions for generic data visualizations like a scatterplot. It turns out that the key challenge lies in designing the most effective prompt for the LLM, a task called prompt engineering. We report on first experiments using the popular LLM GPT-3 and deliver some promising results.","link":"http://arxiv.org/abs/2212.14047v1","created":"2022-12-27","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Using Large Language Models to Generate Engaging Captions for Data Visualizations Creating compelling captions for data visualizations has been a longstanding challenge. Visualization researchers are typically untrained in journalistic reporting and hence the captions that are placed below data visualizations tend to be not overly engaging and rather just stick to basic observations about the data. In this work we explore the opportunities offered by the newly emerging crop of large language models (LLM) which use sophisticated deep learning technology to produce human-like prose. We ask, can these powerful software devices be purposed to produce engaging captions for generic data visualizations like a scatterplot. It turns out that the key challenge lies in designing the most effective prompt for the LLM, a task called prompt engineering. We report on first experiments using the popular LLM GPT-3 and deliver some promising results.","classes":{"dataset":0.5905202031}}
{"title":"CORRPUS: Detecting Story Inconsistencies via Codex-Bootstrapped Neurosymbolic Reasoning","description":"Story generation and understanding -- as with all NLG/NLU tasks -- has seen a surge in neurosymbolic work. Researchers have recognized that, while large language models (LLMs) have tremendous utility, they can be augmented with symbolic means to be even better and to make up for any flaws that the neural networks might have. However, symbolic methods are extremely costly in terms of the amount of time and expertise needed to create them. In this work, we capitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use of symbolic methods for tracking the state of stories and aiding in story understanding. We show that our CoRRPUS system and abstracted prompting procedures can beat current state-of-the-art structured LLM techniques on pre-existing story understanding tasks (bAbI task 2 and Re^3) with minimal hand engineering. We hope that this work can help highlight the importance of symbolic representations and specialized prompting for LLMs as these models require some guidance for performing reasoning tasks properly.","link":"http://arxiv.org/abs/2212.10754v1","created":"2022-12-21","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"CORRPUS: Detecting Story Inconsistencies via Codex-Bootstrapped Neurosymbolic Reasoning Story generation and understanding -- as with all NLG/NLU tasks -- has seen a surge in neurosymbolic work. Researchers have recognized that, while large language models (LLMs) have tremendous utility, they can be augmented with symbolic means to be even better and to make up for any flaws that the neural networks might have. However, symbolic methods are extremely costly in terms of the amount of time and expertise needed to create them. In this work, we capitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use of symbolic methods for tracking the state of stories and aiding in story understanding. We show that our CoRRPUS system and abstracted prompting procedures can beat current state-of-the-art structured LLM techniques on pre-existing story understanding tasks (bAbI task 2 and Re^3) with minimal hand engineering. We hope that this work can help highlight the importance of symbolic representations and specialized prompting for LLMs as these models require some guidance for performing reasoning tasks properly.","classes":{"dataset":0.1041427776}}
{"title":"Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good movie, and a good prompt too?","description":"Large language models can perform new tasks in a zero-shot fashion, given natural language prompts that specify the desired behavior. Such prompts are typically hand engineered, but can also be learned with gradient-based methods from labeled data. However, it is underexplored what factors make the prompts effective, especially when the prompts are natural language. In this paper, we investigate common attributes shared by effective prompts. We first propose a human readable prompt tuning method (F LUENT P ROMPT) based on Langevin dynamics that incorporates a fluency constraint to find a diverse distribution of effective and fluent prompts. Our analysis reveals that effective prompts are topically related to the task domain and calibrate the prior probability of label words. Based on these findings, we also propose a method for generating prompts using only unlabeled data, outperforming strong baselines by an average of 7.0% accuracy across three tasks.","link":"http://arxiv.org/abs/2212.10539v1","created":"2022-12-20","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good movie, and a good prompt too? Large language models can perform new tasks in a zero-shot fashion, given natural language prompts that specify the desired behavior. Such prompts are typically hand engineered, but can also be learned with gradient-based methods from labeled data. However, it is underexplored what factors make the prompts effective, especially when the prompts are natural language. In this paper, we investigate common attributes shared by effective prompts. We first propose a human readable prompt tuning method (F LUENT P ROMPT) based on Langevin dynamics that incorporates a fluency constraint to find a diverse distribution of effective and fluent prompts. Our analysis reveals that effective prompts are topically related to the task domain and calibrate the prior probability of label words. Based on these findings, we also propose a method for generating prompts using only unlabeled data, outperforming strong baselines by an average of 7.0% accuracy across three tasks.","classes":{"dataset":0.5454137921}}
{"title":"ReCode: Robustness Evaluation of Code Generation Models","description":"Code generation models have achieved impressive performance. However, they tend to be brittle as slight edits to a prompt could lead to very different generations; these robustness properties, critical for user experience when deployed in real-life applications, are not well understood. Most existing works on robustness in text or code tasks have focused on classification, while robustness in generation tasks is an uncharted area and to date there is no comprehensive benchmark for robustness in code generation. In this paper, we propose ReCode, a comprehensive robustness evaluation benchmark for code generation models. We customize over 30 transformations specifically for code on docstrings, function and variable names, code syntax, and code format. They are carefully designed to be natural in real-life coding practice, preserve the original semantic meaning, and thus provide multifaceted assessments of a model's robustness performance. With human annotators, we verified that over 90% of the perturbed prompts do not alter the semantic meaning of the original prompt. In addition, we define robustness metrics for code generation models considering the worst-case behavior under each type of perturbation, taking advantage of the fact that executing the generated code can serve as objective evaluation. We demonstrate ReCode on SOTA models using HumanEval, MBPP, as well as function completion tasks derived from them. Interesting observations include: better robustness for CodeGen over InCoder and GPT-J; models are most sensitive to syntax perturbations; more challenging robustness evaluation on MBPP over HumanEval.","link":"http://arxiv.org/abs/2212.10264v1","created":"2022-12-20","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"ReCode: Robustness Evaluation of Code Generation Models Code generation models have achieved impressive performance. However, they tend to be brittle as slight edits to a prompt could lead to very different generations; these robustness properties, critical for user experience when deployed in real-life applications, are not well understood. Most existing works on robustness in text or code tasks have focused on classification, while robustness in generation tasks is an uncharted area and to date there is no comprehensive benchmark for robustness in code generation. In this paper, we propose ReCode, a comprehensive robustness evaluation benchmark for code generation models. We customize over 30 transformations specifically for code on docstrings, function and variable names, code syntax, and code format. They are carefully designed to be natural in real-life coding practice, preserve the original semantic meaning, and thus provide multifaceted assessments of a model's robustness performance. With human annotators, we verified that over 90% of the perturbed prompts do not alter the semantic meaning of the original prompt. In addition, we define robustness metrics for code generation models considering the worst-case behavior under each type of perturbation, taking advantage of the fact that executing the generated code can serve as objective evaluation. We demonstrate ReCode on SOTA models using HumanEval, MBPP, as well as function completion tasks derived from them. Interesting observations include: better robustness for CodeGen over InCoder and GPT-J; models are most sensitive to syntax perturbations; more challenging robustness evaluation on MBPP over HumanEval.","classes":{"dataset":0.2369651198}}
{"title":"Explanation Regeneration via Information Bottleneck","description":"Explaining the black-box predictions of NLP models naturally and accurately is an important open problem in natural language generation. These free-text explanations are expected to contain sufficient and carefully-selected evidence to form supportive arguments for predictions. Due to the superior generative capacity of large pretrained language models, recent work built on prompt engineering enables explanation generation without specific training. However, explanation generated through single-pass prompting often lacks sufficiency and conciseness. To address this problem, we develop an information bottleneck method EIB to produce refined explanations that are sufficient and concise. Our approach regenerates the free-text explanation by polishing the single-pass output from the pretrained language model but retaining the information that supports the contents being explained. Experiments on two out-of-domain tasks verify the effectiveness of EIB through automatic evaluation and thoroughly-conducted human evaluation.","link":"http://arxiv.org/abs/2212.09603v1","created":"2022-12-19","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Explanation Regeneration via Information Bottleneck Explaining the black-box predictions of NLP models naturally and accurately is an important open problem in natural language generation. These free-text explanations are expected to contain sufficient and carefully-selected evidence to form supportive arguments for predictions. Due to the superior generative capacity of large pretrained language models, recent work built on prompt engineering enables explanation generation without specific training. However, explanation generated through single-pass prompting often lacks sufficiency and conciseness. To address this problem, we develop an information bottleneck method EIB to produce refined explanations that are sufficient and concise. Our approach regenerates the free-text explanation by polishing the single-pass output from the pretrained language model but retaining the information that supports the contents being explained. Experiments on two out-of-domain tasks verify the effectiveness of EIB through automatic evaluation and thoroughly-conducted human evaluation.","classes":{"dataset":0.1905560195}}
{"title":"Scale invariance in X-ray flares of gamma-ray bursts","description":"X-ray flares are generally believed to be produced by the reactivation of the central engine, and may have the same energy dissipation mechanism as the prompt emission of gamma-ray bursts (GRBs). X-ray flares can therefore provide important clues to understanding the nature of the central engines of GRBs. In this work, we study for the first time the physical connection between differential size and return distributions of X-ray flares of GRBs with known redshifts. We find that the differential distributions of duration, energy, and waiting time can be well fitted by a power-law function. In particular, the distributions for the differences of durations, energies, and waiting times at different times (i.e., the return distributions) well follow a $q$-Gaussian form. The $q$ values in the $q$-Gaussian distributions remain nearly steady for different temporal interval scales, implying a scale-invariant structure of GRB X-ray flares. Moreover, we verify that the $q$ parameters are related to the power-law indices $\\alpha$ of the differential size distributions, characterized as $q=(\\alpha+2)/\\alpha$. These statistical features can be well explained within the physical framework of a self-organizing criticality system.","link":"http://arxiv.org/abs/2212.08813v2","created":"2022-12-17","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Scale invariance in X-ray flares of gamma-ray bursts X-ray flares are generally believed to be produced by the reactivation of the central engine, and may have the same energy dissipation mechanism as the prompt emission of gamma-ray bursts (GRBs). X-ray flares can therefore provide important clues to understanding the nature of the central engines of GRBs. In this work, we study for the first time the physical connection between differential size and return distributions of X-ray flares of GRBs with known redshifts. We find that the differential distributions of duration, energy, and waiting time can be well fitted by a power-law function. In particular, the distributions for the differences of durations, energies, and waiting times at different times (i.e., the return distributions) well follow a $q$-Gaussian form. The $q$ values in the $q$-Gaussian distributions remain nearly steady for different temporal interval scales, implying a scale-invariant structure of GRB X-ray flares. Moreover, we verify that the $q$ parameters are related to the power-law indices $\\alpha$ of the differential size distributions, characterized as $q=(\\alpha+2)/\\alpha$. These statistical features can be well explained within the physical framework of a self-organizing criticality system.","classes":{"dataset":0.4129469693}}
{"title":"SE Factual Knowledge in Frozen Giant Code Model: A Study on FQN and its Retrieval","description":"Pre-trained giant code models (PCMs) start coming into the developers' daily practices. Understanding what types of and how much software knowledge is packed into PCMs is the foundation for incorporating PCMs into software engineering (SE) tasks and fully releasing their potential. In this work, we conduct the first systematic study on the SE factual knowledge in the state-of-the-art PCM CoPilot, focusing on APIs' Fully Qualified Names (FQNs), the fundamental knowledge for effective code analysis, search and reuse. Driven by FQNs' data distribution properties, we design a novel lightweight in-context learning on Copilot for FQN inference, which does not require code compilation as traditional methods or gradient update by recent FQN prompt-tuning. We systematically experiment with five in-context-learning design factors to identify the best in-context learning configuration that developers can adopt in practice. With this best configuration, we investigate the effects of amount of example prompts and FQN data properties on Copilot's FQN inference capability. Our results confirm that Copilot stores diverse FQN knowledge and can be applied for the FQN inference due to its high inference accuracy and non-reliance on code analysis. Based on our experience interacting with Copilot, we discuss various opportunities to improve human-CoPilot interaction in the FQN inference task.","link":"http://arxiv.org/abs/2212.08221v1","created":"2022-12-16","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"SE Factual Knowledge in Frozen Giant Code Model: A Study on FQN and its Retrieval Pre-trained giant code models (PCMs) start coming into the developers' daily practices. Understanding what types of and how much software knowledge is packed into PCMs is the foundation for incorporating PCMs into software engineering (SE) tasks and fully releasing their potential. In this work, we conduct the first systematic study on the SE factual knowledge in the state-of-the-art PCM CoPilot, focusing on APIs' Fully Qualified Names (FQNs), the fundamental knowledge for effective code analysis, search and reuse. Driven by FQNs' data distribution properties, we design a novel lightweight in-context learning on Copilot for FQN inference, which does not require code compilation as traditional methods or gradient update by recent FQN prompt-tuning. We systematically experiment with five in-context-learning design factors to identify the best in-context learning configuration that developers can adopt in practice. With this best configuration, we investigate the effects of amount of example prompts and FQN data properties on Copilot's FQN inference capability. Our results confirm that Copilot stores diverse FQN knowledge and can be applied for the FQN inference due to its high inference accuracy and non-reliance on code analysis. Based on our experience interacting with Copilot, we discuss various opportunities to improve human-CoPilot interaction in the FQN inference task.","classes":{"dataset":0.0852169022}}
{"title":"The Infinite Index: Information Retrieval on Generative Text-To-Image Models","description":"Conditional generative models such as DALL-E and Stable Diffusion generate images based on a user-defined text, the prompt. Finding and refining prompts that produce a desired image has become the art of prompt engineering. Generative models do not provide a built-in retrieval model for a user's information need expressed through prompts. In light of an extensive literature review, we reframe prompt engineering for generative models as interactive text-based retrieval on a novel kind of \"infinite index\". We apply these insights for the first time in a case study on image generation for game design with an expert. Finally, we envision how active learning may help to guide the retrieval of generated images.","link":"http://arxiv.org/abs/2212.07476v2","created":"2022-12-14","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"The Infinite Index: Information Retrieval on Generative Text-To-Image Models Conditional generative models such as DALL-E and Stable Diffusion generate images based on a user-defined text, the prompt. Finding and refining prompts that produce a desired image has become the art of prompt engineering. Generative models do not provide a built-in retrieval model for a user's information need expressed through prompts. In light of an extensive literature review, we reframe prompt engineering for generative models as interactive text-based retrieval on a novel kind of \"infinite index\". We apply these insights for the first time in a case study on image generation for game design with an expert. Finally, we envision how active learning may help to guide the retrieval of generated images.","classes":{"dataset":0.2087404728}}
{"title":"ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages","description":"Software engineers working with the same programming language (PL) may speak different natural languages (NLs) and vice versa, erecting huge barriers to communication and working efficiency. Recent studies have demonstrated the effectiveness of generative pre-training in computer programs, yet they are always English-centric. In this work, we step towards bridging the gap between multilingual NLs and multilingual PLs for large language models (LLMs). We release ERNIE-Code, a unified pre-trained language model for 116 NLs and 6 PLs. We employ two methods for universal cross-lingual pre-training: span-corruption language modeling that learns patterns from monolingual NL or PL; and pivot-based translation language modeling that relies on parallel data of many NLs and PLs. Extensive results show that ERNIE-Code outperforms previous multilingual LLMs for PL or NL across a wide range of end tasks of code intelligence, including multilingual code-to-text, text-to-code, code-to-code, and text-to-text generation. We further show its advantage of zero-shot prompting on multilingual code summarization and text-to-text translation. We will make our code and pre-trained models publicly available.","link":"http://arxiv.org/abs/2212.06742v1","created":"2022-12-13","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages Software engineers working with the same programming language (PL) may speak different natural languages (NLs) and vice versa, erecting huge barriers to communication and working efficiency. Recent studies have demonstrated the effectiveness of generative pre-training in computer programs, yet they are always English-centric. In this work, we step towards bridging the gap between multilingual NLs and multilingual PLs for large language models (LLMs). We release ERNIE-Code, a unified pre-trained language model for 116 NLs and 6 PLs. We employ two methods for universal cross-lingual pre-training: span-corruption language modeling that learns patterns from monolingual NL or PL; and pivot-based translation language modeling that relies on parallel data of many NLs and PLs. Extensive results show that ERNIE-Code outperforms previous multilingual LLMs for PL or NL across a wide range of end tasks of code intelligence, including multilingual code-to-text, text-to-code, code-to-code, and text-to-text generation. We further show its advantage of zero-shot prompting on multilingual code summarization and text-to-text translation. We will make our code and pre-trained models publicly available.","classes":{"dataset":0.2965857387}}
{"title":"Fill in the Blank: Context-aware Automated Text Input Generation for Mobile GUI Testing","description":"Automated GUI testing is widely used to help ensure the quality of mobile apps. However, many GUIs require appropriate text inputs to proceed to the next page which remains a prominent obstacle for testing coverage. Considering the diversity and semantic requirement of valid inputs (e.g., flight departure, movie name), it is challenging to automate the text input generation. Inspired by the fact that the pre-trained Large Language Model (LLM) has made outstanding progress in text generation, we propose an approach named QTypist based on LLM for intelligently generating semantic input text according to the GUI context. To boost the performance of LLM in the mobile testing scenario, we develop a prompt-based data construction and tuning method which automatically extracts the prompts and answers for model tuning. We evaluate QTypist on 106 apps from Google Play and the result shows that the passing rate of QTypist is 87%, which is 93% higher than the best baseline. We also integrate QTypist with the automated GUI testing tools and it can cover 42% more app activities, 52% more pages, and subsequently help reveal 122% more bugs compared with the raw tool.","link":"http://arxiv.org/abs/2212.04732v1","created":"2022-12-09","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Fill in the Blank: Context-aware Automated Text Input Generation for Mobile GUI Testing Automated GUI testing is widely used to help ensure the quality of mobile apps. However, many GUIs require appropriate text inputs to proceed to the next page which remains a prominent obstacle for testing coverage. Considering the diversity and semantic requirement of valid inputs (e.g., flight departure, movie name), it is challenging to automate the text input generation. Inspired by the fact that the pre-trained Large Language Model (LLM) has made outstanding progress in text generation, we propose an approach named QTypist based on LLM for intelligently generating semantic input text according to the GUI context. To boost the performance of LLM in the mobile testing scenario, we develop a prompt-based data construction and tuning method which automatically extracts the prompts and answers for model tuning. We evaluate QTypist on 106 apps from Google Play and the result shows that the passing rate of QTypist is 87%, which is 93% higher than the best baseline. We also integrate QTypist with the automated GUI testing tools and it can cover 42% more app activities, 52% more pages, and subsequently help reveal 122% more bugs compared with the raw tool.","classes":{"dataset":0.6038384438}}
{"title":"Towards using Few-Shot Prompt Learning for Automating Model Completion","description":"We propose a simple yet a novel approach to improve completion in domain modeling activities. Our approach exploits the power of large language models by using few-shot prompt learning without the need to train or fine-tune those models with large datasets that are scarce in this field. We implemented our approach and tested it on the completion of static and dynamic domain diagrams. Our initial evaluation shows that such an approach is effective and can be integrated in different ways during the modeling activities.","link":"http://arxiv.org/abs/2212.03404v1","created":"2022-12-07","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Towards using Few-Shot Prompt Learning for Automating Model Completion We propose a simple yet a novel approach to improve completion in domain modeling activities. Our approach exploits the power of large language models by using few-shot prompt learning without the need to train or fine-tune those models with large datasets that are scarce in this field. We implemented our approach and tested it on the completion of static and dynamic domain diagrams. Our initial evaluation shows that such an approach is effective and can be integrated in different ways during the modeling activities.","classes":{"dataset":0.6289435029}}
{"title":"Pseudo Redshifts of Gamma-Ray Bursts Derived from the L-T-E Correlation","description":"The X-ray afterglow of many gamma-ray bursts (GRBs) exhibits a plateau phase before the normal power-law decay stage, which may be related to continued activities of the central engine. Tang et al. 2019 collected 174 such GRBs and confirmed the so called $L-T-E$ correlation which involves three key parameters, i.e., the isotropic $\\gamma$-ray energy $E_{\\gamma,\\rm iso}$ of the prompt phase, the end time $T_{a}$ of the plateau phase and the corresponding X-ray luminosity $L_{X}$. In this study, the $L-T-E$ correlation is confirmed and updated as $L_{X} \\propto T_{a}^{-0.99} E_{\\gamma ,\\rm iso}^{0.86}$ with a large sample consisting of 210 plateau GRBs with known redshifts. The tight correlation is then applied to derive the pseudo redshift of other 130 plateau GRBs whose redshifts are not directly measured. Statistical analysis is also carried out on this pseudo redshift sample.","link":"http://arxiv.org/abs/2212.01990v1","created":"2022-12-05","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Pseudo Redshifts of Gamma-Ray Bursts Derived from the L-T-E Correlation The X-ray afterglow of many gamma-ray bursts (GRBs) exhibits a plateau phase before the normal power-law decay stage, which may be related to continued activities of the central engine. Tang et al. 2019 collected 174 such GRBs and confirmed the so called $L-T-E$ correlation which involves three key parameters, i.e., the isotropic $\\gamma$-ray energy $E_{\\gamma,\\rm iso}$ of the prompt phase, the end time $T_{a}$ of the plateau phase and the corresponding X-ray luminosity $L_{X}$. In this study, the $L-T-E$ correlation is confirmed and updated as $L_{X} \\propto T_{a}^{-0.99} E_{\\gamma ,\\rm iso}^{0.86}$ with a large sample consisting of 210 plateau GRBs with known redshifts. The tight correlation is then applied to derive the pseudo redshift of other 130 plateau GRBs whose redshifts are not directly measured. Statistical analysis is also carried out on this pseudo redshift sample.","classes":{"dataset":0.2986070216}}
{"title":"AI-driven Mobile Apps: an Explorative Study","description":"Recent years have witnessed an astonishing explosion in the evolution of mobile applications powered by AI technologies. The rapid growth of AI frameworks enables the transition of AI technologies to mobile devices, significantly prompting the adoption of AI apps (i.e., apps that integrate AI into their functions) among smartphone devices. In this paper, we conduct the most extensive empirical study on 56,682 published AI apps from three perspectives: dataset characteristics, development issues, and user feedback and privacy. To this end, we build an automated AI app identification tool, AI Discriminator, that detects eligible AI apps from 7,259,232 mobile apps. First, we carry out a dataset analysis, where we explore the AndroZoo large repository to identify AI apps and their core characteristics. Subsequently, we pinpoint key issues in AI app development (e.g., model protection). Finally, we focus on user reviews and user privacy protection. Our paper provides several notable findings. Some essential ones involve revealing the issue of insufficient model protection by presenting the lack of model encryption, and demonstrating the risk of user privacy data being leaked. We published our large-scale AI app datasets to inspire more future research.","link":"http://arxiv.org/abs/2212.01635v1","created":"2022-12-03","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"AI-driven Mobile Apps: an Explorative Study Recent years have witnessed an astonishing explosion in the evolution of mobile applications powered by AI technologies. The rapid growth of AI frameworks enables the transition of AI technologies to mobile devices, significantly prompting the adoption of AI apps (i.e., apps that integrate AI into their functions) among smartphone devices. In this paper, we conduct the most extensive empirical study on 56,682 published AI apps from three perspectives: dataset characteristics, development issues, and user feedback and privacy. To this end, we build an automated AI app identification tool, AI Discriminator, that detects eligible AI apps from 7,259,232 mobile apps. First, we carry out a dataset analysis, where we explore the AndroZoo large repository to identify AI apps and their core characteristics. Subsequently, we pinpoint key issues in AI app development (e.g., model protection). Finally, we focus on user reviews and user privacy protection. Our paper provides several notable findings. Some essential ones involve revealing the issue of insufficient model protection by presenting the lack of model encryption, and demonstrating the risk of user privacy data being leaked. We published our large-scale AI app datasets to inspire more future research.","classes":{"dataset":0.0938071311}}
{"title":"Multi-messenger model for the prompt emission from GRB 221009A","description":"We present a multi-messenger model for the prompt emission from GRB 221009A within the internal shock scenario. We consider the time-dependent evolution of the outflow with its impact on the observed light curve from multiple collisions, and the self-consistent generation of the electromagnetic spectrum in synchrotron and inverse Compton-dominated scenarios. Our leptohadronic model includes UHE protons potentially accelerated in the outflow, and their feedback on spectral energy distribution and on the neutrino emission. We find that we can roughly reproduce the observed light curves with an engine with varying ejection velocity of ultra-relativistic material, which has an intermediate quiescent period of about 200 seconds and a variability timescale of $\\sim1$~s. We consider baryonic loadings of 3 and 30 that are compatible with the hypothesis that the highest-energetic LHAASO photons might come from UHECR interactions with the extragalactic background light, and the paradigm that energetic GRBs may power the UHECR flux. For these values and the high dissipation radii considered we find consistency with the non-observation of neutrinos and no significant signatures on the electromagnetic spectrum. Inverse Compton-dominated scenarios from the prompt emission are demonstrated to lead to about an order of magnitude higher fluxes in the HE-range; this enhancement is testable by its spectral impact in the Fermi-GBM and LAT ranges.","link":"http://arxiv.org/abs/2212.00766v1","created":"2022-12-01","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Multi-messenger model for the prompt emission from GRB 221009A We present a multi-messenger model for the prompt emission from GRB 221009A within the internal shock scenario. We consider the time-dependent evolution of the outflow with its impact on the observed light curve from multiple collisions, and the self-consistent generation of the electromagnetic spectrum in synchrotron and inverse Compton-dominated scenarios. Our leptohadronic model includes UHE protons potentially accelerated in the outflow, and their feedback on spectral energy distribution and on the neutrino emission. We find that we can roughly reproduce the observed light curves with an engine with varying ejection velocity of ultra-relativistic material, which has an intermediate quiescent period of about 200 seconds and a variability timescale of $\\sim1$~s. We consider baryonic loadings of 3 and 30 that are compatible with the hypothesis that the highest-energetic LHAASO photons might come from UHECR interactions with the extragalactic background light, and the paradigm that energetic GRBs may power the UHECR flux. For these values and the high dissipation radii considered we find consistency with the non-observation of neutrinos and no significant signatures on the electromagnetic spectrum. Inverse Compton-dominated scenarios from the prompt emission are demonstrated to lead to about an order of magnitude higher fluxes in the HE-range; this enhancement is testable by its spectral impact in the Fermi-GBM and LAT ranges.","classes":{"dataset":0.1804349273}}
{"title":"Arguments to Key Points Mapping with Prompt-based Learning","description":"Handling and digesting a huge amount of information in an efficient manner has been a long-term demand in modern society. Some solutions to map key points (short textual summaries capturing essential information and filtering redundancies) to a large number of arguments/opinions have been provided recently (Bar-Haim et al., 2020). To complement the full picture of the argument-to-keypoint mapping task, we mainly propose two approaches in this paper. The first approach is to incorporate prompt engineering for fine-tuning the pre-trained language models (PLMs). The second approach utilizes prompt-based learning in PLMs to generate intermediary texts, which are then combined with the original argument-keypoint pairs and fed as inputs to a classifier, thereby mapping them. Furthermore, we extend the experiments to cross/in-domain to conduct an in-depth analysis. In our evaluation, we find that i) using prompt engineering in a more direct way (Approach 1) can yield promising results and improve the performance; ii) Approach 2 performs considerably worse than Approach 1 due to the negation issue of the PLM.","link":"http://arxiv.org/abs/2211.14995v1","created":"2022-11-28","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Arguments to Key Points Mapping with Prompt-based Learning Handling and digesting a huge amount of information in an efficient manner has been a long-term demand in modern society. Some solutions to map key points (short textual summaries capturing essential information and filtering redundancies) to a large number of arguments/opinions have been provided recently (Bar-Haim et al., 2020). To complement the full picture of the argument-to-keypoint mapping task, we mainly propose two approaches in this paper. The first approach is to incorporate prompt engineering for fine-tuning the pre-trained language models (PLMs). The second approach utilizes prompt-based learning in PLMs to generate intermediary texts, which are then combined with the original argument-keypoint pairs and fed as inputs to a classifier, thereby mapping them. Furthermore, we extend the experiments to cross/in-domain to conduct an in-depth analysis. In our evaluation, we find that i) using prompt engineering in a more direct way (Approach 1) can yield promising results and improve the performance; ii) Approach 2 performs considerably worse than Approach 1 due to the negation issue of the PLM.","classes":{"dataset":0.1368667632}}
{"title":"Using Developer Discussions to Guide Fixing Bugs in Software","description":"Automatically fixing software bugs is a challenging task. While recent work showed that natural language context is useful in guiding bug-fixing models, the approach required prompting developers to provide this context, which was simulated through commit messages written after the bug-fixing code changes were made. We instead propose using bug report discussions, which are available before the task is performed and are also naturally occurring, avoiding the need for any additional information from developers. For this, we augment standard bug-fixing datasets with bug report discussions. Using these newly compiled datasets, we demonstrate that various forms of natural language context derived from such discussions can aid bug-fixing, even leading to improved performance over using commit messages corresponding to the oracle bug-fixing commits.","link":"http://arxiv.org/abs/2211.06335v1","created":"2022-11-11","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Using Developer Discussions to Guide Fixing Bugs in Software Automatically fixing software bugs is a challenging task. While recent work showed that natural language context is useful in guiding bug-fixing models, the approach required prompting developers to provide this context, which was simulated through commit messages written after the bug-fixing code changes were made. We instead propose using bug report discussions, which are available before the task is performed and are also naturally occurring, avoiding the need for any additional information from developers. For this, we augment standard bug-fixing datasets with bug report discussions. Using these newly compiled datasets, we demonstrate that various forms of natural language context derived from such discussions can aid bug-fixing, even leading to improved performance over using commit messages corresponding to the oracle bug-fixing commits.","classes":{"dataset":0.3568140566}}
{"title":"Large Language Models Are Human-Level Prompt Engineers","description":"By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans. Inspired by classical program synthesis and the human approach to prompt engineering, we propose Automatic Prompt Engineer (APE) for automatic instruction generation and selection. In our method, we treat the instruction as the \"program,\" optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function. To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction. Experiments on 24 NLP tasks show that our automatically generated instructions outperform the prior LLM baseline by a large margin and achieve better or comparable performance to the instructions generated by human annotators on 19/24 tasks. We conduct extensive qualitative and quantitative analyses to explore the performance of APE. We show that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts. Please check out our webpage at https://sites.google.com/view/automatic-prompt-engineer.","link":"http://arxiv.org/abs/2211.01910v1","created":"2022-11-03","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Large Language Models Are Human-Level Prompt Engineers By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans. Inspired by classical program synthesis and the human approach to prompt engineering, we propose Automatic Prompt Engineer (APE) for automatic instruction generation and selection. In our method, we treat the instruction as the \"program,\" optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function. To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction. Experiments on 24 NLP tasks show that our automatically generated instructions outperform the prior LLM baseline by a large margin and achieve better or comparable performance to the instructions generated by human annotators on 19/24 tasks. We conduct extensive qualitative and quantitative analyses to explore the performance of APE. We show that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts. Please check out our webpage at https://sites.google.com/view/automatic-prompt-engineer.","classes":{"dataset":0.0729368329}}
{"title":"Beyond Prompting: Making Pre-trained Language Models Better Zero-shot Learners by Clustering Representations","description":"Recent work has demonstrated that pre-trained language models (PLMs) are zero-shot learners. However, most existing zero-shot methods involve heavy human engineering or complicated self-training pipelines, hindering their application to new situations. In this work, we show that zero-shot text classification can be improved simply by clustering texts in the embedding spaces of PLMs. Specifically, we fit the unlabeled texts with a Bayesian Gaussian Mixture Model after initializing cluster positions and shapes using class names. Despite its simplicity, this approach achieves superior or comparable performance on both topic and sentiment classification datasets and outperforms prior works significantly on unbalanced datasets. We further explore the applicability of our clustering approach by evaluating it on 14 datasets with more diverse topics, text lengths, and numbers of classes. Our approach achieves an average of 20% absolute improvement over prompt-based zero-shot learning. Finally, we compare different PLM embedding spaces and find that texts are well-clustered by topics even if the PLM is not explicitly pre-trained to generate meaningful sentence embeddings. This work indicates that PLM embeddings can categorize texts without task-specific fine-tuning, thus providing a new way to analyze and utilize their knowledge and zero-shot learning ability.","link":"http://arxiv.org/abs/2210.16637v2","created":"2022-10-29","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Beyond Prompting: Making Pre-trained Language Models Better Zero-shot Learners by Clustering Representations Recent work has demonstrated that pre-trained language models (PLMs) are zero-shot learners. However, most existing zero-shot methods involve heavy human engineering or complicated self-training pipelines, hindering their application to new situations. In this work, we show that zero-shot text classification can be improved simply by clustering texts in the embedding spaces of PLMs. Specifically, we fit the unlabeled texts with a Bayesian Gaussian Mixture Model after initializing cluster positions and shapes using class names. Despite its simplicity, this approach achieves superior or comparable performance on both topic and sentiment classification datasets and outperforms prior works significantly on unbalanced datasets. We further explore the applicability of our clustering approach by evaluating it on 14 datasets with more diverse topics, text lengths, and numbers of classes. Our approach achieves an average of 20% absolute improvement over prompt-based zero-shot learning. Finally, we compare different PLM embedding spaces and find that texts are well-clustered by topics even if the PLM is not explicitly pre-trained to generate meaningful sentence embeddings. This work indicates that PLM embeddings can categorize texts without task-specific fine-tuning, thus providing a new way to analyze and utilize their knowledge and zero-shot learning ability.","classes":{"dataset":0.3098819256}}
{"title":"Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language","description":"GitHub Copilot is an artificial intelligence model for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about the impact it will have on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60\\% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.","link":"http://arxiv.org/abs/2210.15157v1","created":"2022-10-27","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language GitHub Copilot is an artificial intelligence model for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about the impact it will have on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60\\% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.","classes":{"dataset":0.0501830764}}
{"title":"PENTATRON: PErsonalized coNText-Aware Transformer for Retrieval-based cOnversational uNderstanding","description":"Conversational understanding is an integral part of modern intelligent devices. In a large fraction of the global traffic from customers using smart digital assistants, frictions in dialogues may be attributed to incorrect understanding of the entities in a customer's query due to factors including ambiguous mentions, mispronunciation, background noise and faulty on-device signal processing. Such errors are compounded by two common deficiencies from intelligent devices namely, (1) the device not being tailored to individual customers, and (2) the device responses being unaware of the context in the conversation session. Viewing this problem via the lens of retrieval-based search engines, we build and evaluate a scalable entity correction system, PENTATRON. The system leverages a parametric transformer-based language model to learn patterns from in-session customer-device interactions coupled with a non-parametric personalized entity index to compute the correct query, which aids downstream components in reasoning about the best response. In addition to establishing baselines and demonstrating the value of personalized and context-aware systems, we use multitasking to learn the domain of the correct entity. We also investigate the utility of language model prompts. Through extensive experiments, we show a significant upward movement of the key metric (Exact Match) by up to 500.97% (relative to the baseline).","link":"http://arxiv.org/abs/2210.12308v1","created":"2022-10-22","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"PENTATRON: PErsonalized coNText-Aware Transformer for Retrieval-based cOnversational uNderstanding Conversational understanding is an integral part of modern intelligent devices. In a large fraction of the global traffic from customers using smart digital assistants, frictions in dialogues may be attributed to incorrect understanding of the entities in a customer's query due to factors including ambiguous mentions, mispronunciation, background noise and faulty on-device signal processing. Such errors are compounded by two common deficiencies from intelligent devices namely, (1) the device not being tailored to individual customers, and (2) the device responses being unaware of the context in the conversation session. Viewing this problem via the lens of retrieval-based search engines, we build and evaluate a scalable entity correction system, PENTATRON. The system leverages a parametric transformer-based language model to learn patterns from in-session customer-device interactions coupled with a non-parametric personalized entity index to compute the correct query, which aids downstream components in reasoning about the best response. In addition to establishing baselines and demonstrating the value of personalized and context-aware systems, we use multitasking to learn the domain of the correct entity. We also investigate the utility of language model prompts. Through extensive experiments, we show a significant upward movement of the key metric (Exact Match) by up to 500.97% (relative to the baseline).","classes":{"dataset":0.0706871524}}
{"title":"ObSynth: An Interactive Synthesis System for Generating Object Models from Natural Language Specifications","description":"We introduce ObSynth, an interactive system leveraging the domain knowledge embedded in large language models (LLMs) to help users design object models from high level natural language prompts. This is an example of specification reification, the process of taking a high-level, potentially vague specification and reifying it into a more concrete form. We evaluate ObSynth via a user study, leading to three key findings: first, object models designed using ObSynth are more detailed, showing that it often synthesizes fields users might have otherwise omitted. Second, a majority of objects, methods, and fields generated by ObSynth are kept by the user in the final object model, highlighting the quality of generated components. Third, ObSynth altered the workflow of participants: they focus on checking that synthesized components were correct rather than generating them from scratch, though ObSynth did not reduce the time participants took to generate object models.","link":"http://arxiv.org/abs/2210.11468v1","created":"2022-10-20","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"ObSynth: An Interactive Synthesis System for Generating Object Models from Natural Language Specifications We introduce ObSynth, an interactive system leveraging the domain knowledge embedded in large language models (LLMs) to help users design object models from high level natural language prompts. This is an example of specification reification, the process of taking a high-level, potentially vague specification and reifying it into a more concrete form. We evaluate ObSynth via a user study, leading to three key findings: first, object models designed using ObSynth are more detailed, showing that it often synthesizes fields users might have otherwise omitted. Second, a majority of objects, methods, and fields generated by ObSynth are kept by the user in the final object model, highlighting the quality of generated components. Third, ObSynth altered the workflow of participants: they focus on checking that synthesized components were correct rather than generating them from scratch, though ObSynth did not reduce the time participants took to generate object models.","classes":{"dataset":0.2345044762}}
{"title":"Measuring and Narrowing the Compositionality Gap in Language Models","description":"We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning.   We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly instead of implicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question. We finally show that self-ask's structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy.","link":"http://arxiv.org/abs/2210.03350v1","created":"2022-10-07","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Measuring and Narrowing the Compositionality Gap in Language Models We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning.   We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly instead of implicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question. We finally show that self-ask's structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy.","classes":{"dataset":0.1344678104}}
{"title":"Galaxy-Classification Activity for All Ages","description":"Classification is a general tool of science; it is used to sort and categorize biological organisms, chemical elements, astronomical objects, and many other things. In scientific classification, taxonomy often reflects shared physical properties that, in turn, may indicate shared origins and/or evolution. A \"hands-on\" galaxy-classification activity developed and implemented by Professional Development Program (PDP) participants, for a high-school summer STEM enrichment program, has been adopted for various age groups and venues, from young (K-3) to college students. We detail the basic tools required, outline the general activity, and describe the modifications to the activity based on learners' ages and learning objectives. We describe the facilitation strategies learned through PDP training and used when implementing the activity, including prompts to motivate the students. We also discuss how we connected the classification process to astronomy and science more broadly during the concluding remarks.","link":"http://arxiv.org/abs/2210.01822v1","created":"2022-10-04","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Galaxy-Classification Activity for All Ages Classification is a general tool of science; it is used to sort and categorize biological organisms, chemical elements, astronomical objects, and many other things. In scientific classification, taxonomy often reflects shared physical properties that, in turn, may indicate shared origins and/or evolution. A \"hands-on\" galaxy-classification activity developed and implemented by Professional Development Program (PDP) participants, for a high-school summer STEM enrichment program, has been adopted for various age groups and venues, from young (K-3) to college students. We detail the basic tools required, outline the general activity, and describe the modifications to the activity based on learners' ages and learning objectives. We describe the facilitation strategies learned through PDP training and used when implementing the activity, including prompts to motivate the students. We also discuss how we connected the classification process to astronomy and science more broadly during the concluding remarks.","classes":{"dataset":0.8325548768}}
{"title":"Repairing Bugs in Python Assignments Using Large Language Models","description":"Students often make mistakes on their introductory programming assignments as part of their learning process. Unfortunately, providing custom repairs for these mistakes can require a substantial amount of time and effort from class instructors. Automated program repair (APR) techniques can be used to synthesize such fixes. Prior work has explored the use of symbolic and neural techniques for APR in the education domain. Both types of approaches require either substantial engineering efforts or large amounts of data and training. We propose to use a large language model trained on code, such as Codex, to build an APR system -- MMAPR -- for introductory Python programming assignments. Our system can fix both syntactic and semantic mistakes by combining multi-modal prompts, iterative querying, test-case-based selection of few-shots, and program chunking. We evaluate MMAPR on 286 real student programs and compare to a baseline built by combining a state-of-the-art Python syntax repair engine, BIFI, and state-of-the-art Python semantic repair engine for student assignments, Refactory. We find that MMAPR can fix more programs and produce smaller patches on average.","link":"http://arxiv.org/abs/2209.14876v1","created":"2022-09-29","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Repairing Bugs in Python Assignments Using Large Language Models Students often make mistakes on their introductory programming assignments as part of their learning process. Unfortunately, providing custom repairs for these mistakes can require a substantial amount of time and effort from class instructors. Automated program repair (APR) techniques can be used to synthesize such fixes. Prior work has explored the use of symbolic and neural techniques for APR in the education domain. Both types of approaches require either substantial engineering efforts or large amounts of data and training. We propose to use a large language model trained on code, such as Codex, to build an APR system -- MMAPR -- for introductory Python programming assignments. Our system can fix both syntactic and semantic mistakes by combining multi-modal prompts, iterative querying, test-case-based selection of few-shots, and program chunking. We evaluate MMAPR on 286 real student programs and compare to a baseline built by combining a state-of-the-art Python syntax repair engine, BIFI, and state-of-the-art Python semantic repair engine for student assignments, Refactory. We find that MMAPR can fix more programs and produce smaller patches on average.","classes":{"dataset":0.0788788646}}
{"title":"Promptagator: Few-shot Dense Retrieval From 8 Examples","description":"Much recent research on information retrieval has focused on how to transfer from one task (typically with abundant supervised data) to various other tasks where supervision is limited, with the implicit assumption that it is possible to generalize from one task to all the rest. However, this overlooks the fact that there are many diverse and unique retrieval tasks, each targeting different search intents, queries, and search domains. In this paper, we suggest to work on Few-shot Dense Retrieval, a setting where each task comes with a short description and a few examples. To amplify the power of a few examples, we propose Prompt-base Query Generation for Retriever (Promptagator), which leverages large language models (LLM) as a few-shot query generator, and creates task-specific retrievers based on the generated data. Powered by LLM's generalization ability, Promptagator makes it possible to create task-specific end-to-end retrievers solely based on a few examples {without} using Natural Questions or MS MARCO to train %question generators or dual encoders. Surprisingly, LLM prompting with no more than 8 examples allows dual encoders to outperform heavily engineered models trained on MS MARCO like ColBERT v2 by more than 1.2 nDCG on average on 11 retrieval sets. Further training standard-size re-rankers using the same generated data yields another 5.0 point nDCG improvement. Our studies determine that query generation can be far more effective than previously observed, especially when a small amount of task-specific knowledge is given.","link":"http://arxiv.org/abs/2209.11755v1","created":"2022-09-23","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Promptagator: Few-shot Dense Retrieval From 8 Examples Much recent research on information retrieval has focused on how to transfer from one task (typically with abundant supervised data) to various other tasks where supervision is limited, with the implicit assumption that it is possible to generalize from one task to all the rest. However, this overlooks the fact that there are many diverse and unique retrieval tasks, each targeting different search intents, queries, and search domains. In this paper, we suggest to work on Few-shot Dense Retrieval, a setting where each task comes with a short description and a few examples. To amplify the power of a few examples, we propose Prompt-base Query Generation for Retriever (Promptagator), which leverages large language models (LLM) as a few-shot query generator, and creates task-specific retrievers based on the generated data. Powered by LLM's generalization ability, Promptagator makes it possible to create task-specific end-to-end retrievers solely based on a few examples {without} using Natural Questions or MS MARCO to train %question generators or dual encoders. Surprisingly, LLM prompting with no more than 8 examples allows dual encoders to outperform heavily engineered models trained on MS MARCO like ColBERT v2 by more than 1.2 nDCG on average on 11 retrieval sets. Further training standard-size re-rankers using the same generated data yields another 5.0 point nDCG improvement. Our studies determine that query generation can be far more effective than previously observed, especially when a small amount of task-specific knowledge is given.","classes":{"dataset":0.1588765979}}
{"title":"Determine the Core Structure and Nuclear Equation of State of Rotating Core-Collapse Supernovae with Gravitational Waves by Convolutional Neural Networks","description":"Detecting gravitational waves from a nearby core-collapse supernova would place meaningful constraints on the supernova engine and nuclear equation of state. Here we use Convolutional Neural Network models to identify the core rotational rates, rotation length scales, and the nuclear equation of state (EoS), using the 1824 waveforms from Richers et al. (2017) for a 12 solar mass progenitor. High prediction accuracy for the classifications of the rotation length scales ($93\\%$) and the rotational rates ($95\\%$) can be achieved using the gravitational wave signals from -10 ms to 6 ms core bounce. By including additional 48 ms signals during the prompt convection phase, we could achieve $96\\%$ accuracy on the classification of four major EoS groups. Combining three models above, we could correctly predict the core rotational rates, rotation length scales, and the EoS at the same time with more than $85\\%$ accuracy. Finally, applying a transfer learning method for additional 74 waveforms from FLASH simulations (Pan et al. 2018), we show that our model using Richers' waveforms could successfully predict the rotational rates from Pan's waveforms even for a continuous value with a mean absolute errors of 0.32 rad s$^{-1}$ only. These results demonstrate a much broader parameter regimes our model can be applied for the identification of core-collapse supernova events through GW signals.","link":"http://arxiv.org/abs/2209.10089v1","created":"2022-09-21","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Determine the Core Structure and Nuclear Equation of State of Rotating Core-Collapse Supernovae with Gravitational Waves by Convolutional Neural Networks Detecting gravitational waves from a nearby core-collapse supernova would place meaningful constraints on the supernova engine and nuclear equation of state. Here we use Convolutional Neural Network models to identify the core rotational rates, rotation length scales, and the nuclear equation of state (EoS), using the 1824 waveforms from Richers et al. (2017) for a 12 solar mass progenitor. High prediction accuracy for the classifications of the rotation length scales ($93\\%$) and the rotational rates ($95\\%$) can be achieved using the gravitational wave signals from -10 ms to 6 ms core bounce. By including additional 48 ms signals during the prompt convection phase, we could achieve $96\\%$ accuracy on the classification of four major EoS groups. Combining three models above, we could correctly predict the core rotational rates, rotation length scales, and the EoS at the same time with more than $85\\%$ accuracy. Finally, applying a transfer learning method for additional 74 waveforms from FLASH simulations (Pan et al. 2018), we show that our model using Richers' waveforms could successfully predict the rotational rates from Pan's waveforms even for a continuous value with a mean absolute errors of 0.32 rad s$^{-1}$ only. These results demonstrate a much broader parameter regimes our model can be applied for the identification of core-collapse supernova events through GW signals.","classes":{"dataset":0.1183920056}}
{"title":"Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models","description":"Pre-trained vision-language models (e.g., CLIP) have shown promising zero-shot generalization in many downstream tasks with properly designed text prompts. Instead of relying on hand-engineered prompts, recent works learn prompts using the training data from downstream tasks. While effective, training on domain-specific data reduces a model's generalization capability to unseen new domains. In this work, we propose test-time prompt tuning (TPT), a method that can learn adaptive prompts on the fly with a single test sample. For image classification, TPT optimizes the prompt by minimizing the entropy with confidence selection so that the model has consistent predictions across different augmented views of each test sample. In evaluating generalization to natural distribution shifts, TPT improves the zero-shot top-1 accuracy of CLIP by 3.6% on average, surpassing previous prompt tuning approaches that require additional task-specific training data. In evaluating cross-dataset generalization with unseen categories, TPT performs on par with the state-of-the-art approaches that use additional training data. Project page: https://azshue.github.io/TPT.","link":"http://arxiv.org/abs/2209.07511v1","created":"2022-09-15","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models Pre-trained vision-language models (e.g., CLIP) have shown promising zero-shot generalization in many downstream tasks with properly designed text prompts. Instead of relying on hand-engineered prompts, recent works learn prompts using the training data from downstream tasks. While effective, training on domain-specific data reduces a model's generalization capability to unseen new domains. In this work, we propose test-time prompt tuning (TPT), a method that can learn adaptive prompts on the fly with a single test sample. For image classification, TPT optimizes the prompt by minimizing the entropy with confidence selection so that the model has consistent predictions across different augmented views of each test sample. In evaluating generalization to natural distribution shifts, TPT improves the zero-shot top-1 accuracy of CLIP by 3.6% on average, surpassing previous prompt tuning approaches that require additional task-specific training data. In evaluating cross-dataset generalization with unseen categories, TPT performs on par with the state-of-the-art approaches that use additional training data. Project page: https://azshue.github.io/TPT.","classes":{"dataset":0.2502941489}}
{"title":"Learning to Prevent Profitless Neural Code Completion","description":"Currently, large pre-trained models are widely applied in neural code completion systems, such as Github Copilot, aiXcoder, and TabNine. Though large models significantly outperform their smaller counterparts, a survey with 2,631 participants reveals that around 70\\% displayed code completions from Copilot are not accepted by developers. Being reviewed but not accepted, these completions bring a threat to productivity. Besides, considering the high cost of the large models, it is a huge waste of computing resources and energy, which severely goes against the sustainable development principle of AI technologies. Additionally, in code completion systems, the completion requests are automatically and actively issued to the models as developers type out, which significantly aggravates the workload. However, to the best of our knowledge, such waste has never been realized, not to mention effectively addressed, in the context of neural code completion. Hence, preventing such profitless code completions from happening in a cost-friendly way is of urgent need. To fill this gap, we first investigate the prompts of these completions and find four observable prompt patterns, which demonstrate the feasibility of identifying such prompts based on prompts themselves. Motivated by this finding, we propose an early-rejection mechanism to turn down low-return prompts by foretelling the completion qualities without sending them to the LCM. Further, we propose a lightweight Transformer-based estimator to demonstrate the feasibility of the mechanism. The experimental results show that the estimator rejects low-return prompts with a promising accuracy of 83.2%.","link":"http://arxiv.org/abs/2209.05948v1","created":"2022-09-13","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Learning to Prevent Profitless Neural Code Completion Currently, large pre-trained models are widely applied in neural code completion systems, such as Github Copilot, aiXcoder, and TabNine. Though large models significantly outperform their smaller counterparts, a survey with 2,631 participants reveals that around 70\\% displayed code completions from Copilot are not accepted by developers. Being reviewed but not accepted, these completions bring a threat to productivity. Besides, considering the high cost of the large models, it is a huge waste of computing resources and energy, which severely goes against the sustainable development principle of AI technologies. Additionally, in code completion systems, the completion requests are automatically and actively issued to the models as developers type out, which significantly aggravates the workload. However, to the best of our knowledge, such waste has never been realized, not to mention effectively addressed, in the context of neural code completion. Hence, preventing such profitless code completions from happening in a cost-friendly way is of urgent need. To fill this gap, we first investigate the prompts of these completions and find four observable prompt patterns, which demonstrate the feasibility of identifying such prompts based on prompts themselves. Motivated by this finding, we propose an early-rejection mechanism to turn down low-return prompts by foretelling the completion qualities without sending them to the LCM. Further, we propose a lightweight Transformer-based estimator to demonstrate the feasibility of the mechanism. The experimental results show that the estimator rejects low-return prompts with a promising accuracy of 83.2%.","classes":{"dataset":0.4073894322}}
{"title":"FOLIO: Natural Language Reasoning with First-Order Logic","description":"We present FOLIO, a human-annotated, open-domain, and logically complex and diverse dataset for reasoning in natural language (NL), equipped with first order logic (FOL) annotations. FOLIO consists of 1,435 examples (unique conclusions), each paired with one of 487 sets of premises which serve as rules to be used to deductively reason for the validity of each conclusion. The logical correctness of premises and conclusions is ensured by their parallel FOL annotations, which are automatically verified by our FOL inference engine. In addition to the main NL reasoning task, NL-FOL pairs in FOLIO automatically constitute a new NL-FOL translation dataset using FOL as the logical form. Our experiments on FOLIO systematically evaluate the FOL reasoning ability of supervised fine-tuning on medium-sized language models (BERT, RoBERTa) and few-shot prompting on large language models (GPT-NeoX, OPT, GPT-3, Codex). For NL-FOL translation, we experiment with GPT-3 and Codex. Our results show that one of the most capable Large Language Model (LLM) publicly available, GPT-3 davinci, achieves only slightly better than random results with few-shot prompting on a subset of FOLIO, and the model is especially bad at predicting the correct truth values for False and Unknown conclusions. Our dataset and code are available at https://github.com/Yale-LILY/FOLIO.","link":"http://arxiv.org/abs/2209.00840v1","created":"2022-09-02","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"FOLIO: Natural Language Reasoning with First-Order Logic We present FOLIO, a human-annotated, open-domain, and logically complex and diverse dataset for reasoning in natural language (NL), equipped with first order logic (FOL) annotations. FOLIO consists of 1,435 examples (unique conclusions), each paired with one of 487 sets of premises which serve as rules to be used to deductively reason for the validity of each conclusion. The logical correctness of premises and conclusions is ensured by their parallel FOL annotations, which are automatically verified by our FOL inference engine. In addition to the main NL reasoning task, NL-FOL pairs in FOLIO automatically constitute a new NL-FOL translation dataset using FOL as the logical form. Our experiments on FOLIO systematically evaluate the FOL reasoning ability of supervised fine-tuning on medium-sized language models (BERT, RoBERTa) and few-shot prompting on large language models (GPT-NeoX, OPT, GPT-3, Codex). For NL-FOL translation, we experiment with GPT-3 and Codex. Our results show that one of the most capable Large Language Model (LLM) publicly available, GPT-3 davinci, achieves only slightly better than random results with few-shot prompting on a subset of FOLIO, and the model is especially bad at predicting the correct truth values for False and Unknown conclusions. Our dataset and code are available at https://github.com/Yale-LILY/FOLIO.","classes":{"dataset":0.3383702338}}
{"title":"Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models","description":"State-of-the-art neural language models can now be used to solve ad-hoc language tasks through zero-shot prompting without the need for supervised training. This approach has gained popularity in recent years, and researchers have demonstrated prompts that achieve strong accuracy on specific NLP tasks. However, finding a prompt for new tasks requires experimentation. Different prompt templates with different wording choices lead to significant accuracy differences. PromptIDE allows users to experiment with prompt variations, visualize prompt performance, and iteratively optimize prompts. We developed a workflow that allows users to first focus on model feedback using small data before moving on to a large data regime that allows empirical grounding of promising prompts using quantitative measures of the task. The tool then allows easy deployment of the newly created ad-hoc models. We demonstrate the utility of PromptIDE (demo at http://prompt.vizhub.ai) and our workflow using several real-world use cases.","link":"http://arxiv.org/abs/2208.07852v1","created":"2022-08-16","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models State-of-the-art neural language models can now be used to solve ad-hoc language tasks through zero-shot prompting without the need for supervised training. This approach has gained popularity in recent years, and researchers have demonstrated prompts that achieve strong accuracy on specific NLP tasks. However, finding a prompt for new tasks requires experimentation. Different prompt templates with different wording choices lead to significant accuracy differences. PromptIDE allows users to experiment with prompt variations, visualize prompt performance, and iteratively optimize prompts. We developed a workflow that allows users to first focus on model feedback using small data before moving on to a large data regime that allows empirical grounding of promising prompts using quantitative measures of the task. The tool then allows easy deployment of the newly created ad-hoc models. We demonstrate the utility of PromptIDE (demo at http://prompt.vizhub.ai) and our workflow using several real-world use cases.","classes":{"dataset":0.3410847783}}
{"title":"Prompt-tuned Code Language Model as a Neural Knowledge Base for Type Inference in Statically-Typed Partial Code","description":"Partial code usually involves non-fully-qualified type names (non-FQNs) and undeclared receiving objects. Resolving the FQNs of these non-FQN types and undeclared receiving objects (referred to as type inference) is the prerequisite to effective search and reuse of partial code. Existing dictionary-lookup based methods build a symbolic knowledge base of API names and code contexts, which involve significant compilation overhead and are sensitive to unseen API names and code context variations. In this paper, we formulate type inference as a cloze-style fill-in-blank language task. Built on source code naturalness, our approach fine-tunes a code masked language model (MLM) as a neural knowledge base of code elements with a novel \"pre-train, prompt and predict\" paradigm from raw source code. Our approach is lightweight and has minimum requirements on code compilation. Unlike existing symbolic name and context matching for type inference, our prompt-tuned code MLM packs FQN syntax and usage in its parameters and supports fuzzy neural type inference. We systematically evaluate our approach on a large amount of source code from GitHub and Stack Overflow. Our results confirm the effectiveness of our approach design and the practicality for partial code type inference. As the first of its kind, our neural type inference method opens the door to many innovative ways of using partial code.","link":"http://arxiv.org/abs/2208.05361v2","created":"2022-08-10","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Prompt-tuned Code Language Model as a Neural Knowledge Base for Type Inference in Statically-Typed Partial Code Partial code usually involves non-fully-qualified type names (non-FQNs) and undeclared receiving objects. Resolving the FQNs of these non-FQN types and undeclared receiving objects (referred to as type inference) is the prerequisite to effective search and reuse of partial code. Existing dictionary-lookup based methods build a symbolic knowledge base of API names and code contexts, which involve significant compilation overhead and are sensitive to unseen API names and code context variations. In this paper, we formulate type inference as a cloze-style fill-in-blank language task. Built on source code naturalness, our approach fine-tunes a code masked language model (MLM) as a neural knowledge base of code elements with a novel \"pre-train, prompt and predict\" paradigm from raw source code. Our approach is lightweight and has minimum requirements on code compilation. Unlike existing symbolic name and context matching for type inference, our prompt-tuned code MLM packs FQN syntax and usage in its parameters and supports fuzzy neural type inference. We systematically evaluate our approach on a large amount of source code from GitHub and Stack Overflow. Our results confirm the effectiveness of our approach design and the practicality for partial code type inference. As the first of its kind, our neural type inference method opens the door to many innovative ways of using partial code.","classes":{"dataset":0.4621851146}}
{"title":"Lighting (In)consistency of Paint by Text","description":"Whereas generative adversarial networks are capable of synthesizing highly realistic images of faces, cats, landscapes, or almost any other single category, paint-by-text synthesis engines can -- from a single text prompt -- synthesize realistic images of seemingly endless categories with arbitrary configurations and combinations. This powerful technology poses new challenges to the photo-forensic community. Motivated by the fact that paint by text is not based on explicit geometric or physical models, and the human visual system's general insensitivity to lighting inconsistencies, we provide an initial exploration of the lighting consistency of DALL-E-2 synthesized images to determine if physics-based forensic analyses will prove fruitful in detecting this new breed of synthetic media.","link":"http://arxiv.org/abs/2207.13744v2","created":"2022-07-27","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Lighting (In)consistency of Paint by Text Whereas generative adversarial networks are capable of synthesizing highly realistic images of faces, cats, landscapes, or almost any other single category, paint-by-text synthesis engines can -- from a single text prompt -- synthesize realistic images of seemingly endless categories with arbitrary configurations and combinations. This powerful technology poses new challenges to the photo-forensic community. Motivated by the fact that paint by text is not based on explicit geometric or physical models, and the human visual system's general insensitivity to lighting inconsistencies, we provide an initial exploration of the lighting consistency of DALL-E-2 synthesized images to determine if physics-based forensic analyses will prove fruitful in detecting this new breed of synthetic media.","classes":{"dataset":0.0407169871}}
{"title":"A Hazard Analysis Framework for Code Synthesis Large Language Models","description":"Codex, a large language model (LLM) trained on a variety of codebases, exceeds the previous state of the art in its capacity to synthesize and generate code. Although Codex provides a plethora of benefits, models that may generate code on such scale have significant limitations, alignment problems, the potential to be misused, and the possibility to increase the rate of progress in technical fields that may themselves have destabilizing impacts or have misuse potential. Yet such safety impacts are not yet known or remain to be explored. In this paper, we outline a hazard analysis framework constructed at OpenAI to uncover hazards or safety risks that the deployment of models like Codex may impose technically, socially, politically, and economically. The analysis is informed by a novel evaluation framework that determines the capacity of advanced code generation techniques against the complexity and expressivity of specification prompts, and their capability to understand and execute them relative to human ability.","link":"http://arxiv.org/abs/2207.14157v1","created":"2022-07-25","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"A Hazard Analysis Framework for Code Synthesis Large Language Models Codex, a large language model (LLM) trained on a variety of codebases, exceeds the previous state of the art in its capacity to synthesize and generate code. Although Codex provides a plethora of benefits, models that may generate code on such scale have significant limitations, alignment problems, the potential to be misused, and the possibility to increase the rate of progress in technical fields that may themselves have destabilizing impacts or have misuse potential. Yet such safety impacts are not yet known or remain to be explored. In this paper, we outline a hazard analysis framework constructed at OpenAI to uncover hazards or safety risks that the deployment of models like Codex may impose technically, socially, politically, and economically. The analysis is informed by a novel evaluation framework that determines the capacity of advanced code generation techniques against the complexity and expressivity of specification prompts, and their capability to understand and execute them relative to human ability.","classes":{"dataset":0.1337882578}}
{"title":"Training Transformers Together","description":"The infrastructure necessary for training state-of-the-art models is becoming overly expensive, which makes training such models affordable only to large corporations and institutions. Recent work proposes several methods for training such models collaboratively, i.e., by pooling together hardware from many independent parties and training a shared model over the Internet. In this demonstration, we collaboratively trained a text-to-image transformer similar to OpenAI DALL-E. We invited the viewers to join the ongoing training run, showing them instructions on how to contribute using the available hardware. We explained how to address the engineering challenges associated with such a training run (slow communication, limited memory, uneven performance between devices, and security concerns) and discussed how the viewers can set up collaborative training runs themselves. Finally, we show that the resulting model generates images of reasonable quality on a number of prompts.","link":"http://arxiv.org/abs/2207.03481v1","created":"2022-07-07","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Training Transformers Together The infrastructure necessary for training state-of-the-art models is becoming overly expensive, which makes training such models affordable only to large corporations and institutions. Recent work proposes several methods for training such models collaboratively, i.e., by pooling together hardware from many independent parties and training a shared model over the Internet. In this demonstration, we collaboratively trained a text-to-image transformer similar to OpenAI DALL-E. We invited the viewers to join the ongoing training run, showing them instructions on how to contribute using the available hardware. We explained how to address the engineering challenges associated with such a training run (slow communication, limited memory, uneven performance between devices, and security concerns) and discussed how the viewers can set up collaborative training runs themselves. Finally, we show that the resulting model generates images of reasonable quality on a number of prompts.","classes":{"dataset":0.2110451162}}
{"title":"BigBIO: A Framework for Data-Centric Biomedical Natural Language Processing","description":"Training and evaluating language models increasingly requires the construction of meta-datasets --diverse collections of curated data with clear provenance. Natural language prompting has recently lead to improved zero-shot generalization by transforming existing, supervised datasets into a diversity of novel pretraining tasks, highlighting the benefits of meta-dataset curation. While successful in general-domain text, translating these data-centric approaches to biomedical language modeling remains challenging, as labeled biomedical datasets are significantly underrepresented in popular data hubs. To address this challenge, we introduce BigBIO a community library of 126+ biomedical NLP datasets, currently covering 12 task categories and 10+ languages. BigBIO facilitates reproducible meta-dataset curation via programmatic access to datasets and their metadata, and is compatible with current platforms for prompt engineering and end-to-end few/zero shot language model evaluation. We discuss our process for task schema harmonization, data auditing, contribution guidelines, and outline two illustrative use cases: zero-shot evaluation of biomedical prompts and large-scale, multi-task learning. BigBIO is an ongoing community effort and is available at https://github.com/bigscience-workshop/biomedical","link":"http://arxiv.org/abs/2206.15076v1","created":"2022-06-30","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"BigBIO: A Framework for Data-Centric Biomedical Natural Language Processing Training and evaluating language models increasingly requires the construction of meta-datasets --diverse collections of curated data with clear provenance. Natural language prompting has recently lead to improved zero-shot generalization by transforming existing, supervised datasets into a diversity of novel pretraining tasks, highlighting the benefits of meta-dataset curation. While successful in general-domain text, translating these data-centric approaches to biomedical language modeling remains challenging, as labeled biomedical datasets are significantly underrepresented in popular data hubs. To address this challenge, we introduce BigBIO a community library of 126+ biomedical NLP datasets, currently covering 12 task categories and 10+ languages. BigBIO facilitates reproducible meta-dataset curation via programmatic access to datasets and their metadata, and is compatible with current platforms for prompt engineering and end-to-end few/zero shot language model evaluation. We discuss our process for task schema harmonization, data auditing, contribution guidelines, and outline two illustrative use cases: zero-shot evaluation of biomedical prompts and large-scale, multi-task learning. BigBIO is an ongoing community effort and is available at https://github.com/bigscience-workshop/biomedical","classes":{"dataset":0.0693841353}}
{"title":"Thermal and nonthermal emission from a peculiar long-duration GRB 211211A","description":"Long-duration GRB 211211A that lacks a supernova emission even down to very stringent limits at such a low redshift $z=0.076$ and is associated with kilonova emission, suggests that its physical origin is from a binary compact star merger. By reanalyzing its data observed with the Gamma-Ray Burst Monitor on board the Fermi mission, we find that both time-integrated and time-resolved spectra can be fitted well by using a 2SBPL plus blackbody (2SBPL+BB) model in the prompt emission. The bulk Lorentz factors ($\\Gamma_{\\rm ph}$) of the outflow can be inferred by invoking the observed thermal emission at the photosphere radius within a pure fireball model, and we find out that the temporal evolution of $\\Gamma_{\\rm ph}$ seems to be tracking with the light curve. The derived values of $\\Gamma_{\\rm ph}$ are also consistent with the $\\Gamma_{\\rm ph}$-$L_{\\gamma, \\rm iso}$/$E_{\\gamma, \\rm iso}$ correlations that had been found in other bursts. Moreover, we also calculate the magnetization factor $\\sigma_{0}$ in the central engine and $\\sigma_{\\rm ph}$ at the photosphere radius within the framework of a hybrid jet model, and find that the values of both $1+\\sigma_{\\rm 0}$ and $1+\\sigma_{\\rm ph}$ are larger than 1 for different time slices. It suggests that at least the Poynting-flux component is indeed existent in the outflow. If this is the case, one possible physical interpretation of thermal and nonthermal emissions in GRB 211211A is from the contributions of both $\\nu\\bar{\\nu}$ annihilation and the Blandford-Znajek mechanisms in the relativistic jet when a stellar mass black hole resides in the central engine.","link":"http://arxiv.org/abs/2206.11438v3","created":"2022-06-23","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Thermal and nonthermal emission from a peculiar long-duration GRB 211211A Long-duration GRB 211211A that lacks a supernova emission even down to very stringent limits at such a low redshift $z=0.076$ and is associated with kilonova emission, suggests that its physical origin is from a binary compact star merger. By reanalyzing its data observed with the Gamma-Ray Burst Monitor on board the Fermi mission, we find that both time-integrated and time-resolved spectra can be fitted well by using a 2SBPL plus blackbody (2SBPL+BB) model in the prompt emission. The bulk Lorentz factors ($\\Gamma_{\\rm ph}$) of the outflow can be inferred by invoking the observed thermal emission at the photosphere radius within a pure fireball model, and we find out that the temporal evolution of $\\Gamma_{\\rm ph}$ seems to be tracking with the light curve. The derived values of $\\Gamma_{\\rm ph}$ are also consistent with the $\\Gamma_{\\rm ph}$-$L_{\\gamma, \\rm iso}$/$E_{\\gamma, \\rm iso}$ correlations that had been found in other bursts. Moreover, we also calculate the magnetization factor $\\sigma_{0}$ in the central engine and $\\sigma_{\\rm ph}$ at the photosphere radius within the framework of a hybrid jet model, and find that the values of both $1+\\sigma_{\\rm 0}$ and $1+\\sigma_{\\rm ph}$ are larger than 1 for different time slices. It suggests that at least the Poynting-flux component is indeed existent in the outflow. If this is the case, one possible physical interpretation of thermal and nonthermal emissions in GRB 211211A is from the contributions of both $\\nu\\bar{\\nu}$ annihilation and the Blandford-Znajek mechanisms in the relativistic jet when a stellar mass black hole resides in the central engine.","classes":{"dataset":0.6983343959}}
{"title":"Heterogeneous Anomaly Detection for Software Systems via Attentive Multi-modal Learning","description":"Prompt and accurate detection of system anomalies is essential to ensure the reliability of software systems. Unlike manual efforts that exploit all available run-time information, existing approaches usually leverage only a single type of monitoring data (often logs or metrics) or fail to make effective use of the joint information among multi-source data. Consequently, many false predictions occur. To better understand the manifestations of system anomalies, we conduct a comprehensive empirical study based on a large amount of heterogeneous data, i.e., logs and metrics. Our study demonstrates that system anomalies could manifest distinctly in different data types. Thus, integrating heterogeneous data can help recover the complete picture of a system's health status. In this context, we propose HADES, the first work to effectively identify system anomalies based on heterogeneous data. Our approach employs a hierarchical architecture to learn a global representation of the system status by fusing log semantics and metric patterns. It captures discriminative features and meaningful interactions from multi-modal data via a novel cross-modal attention module, enabling accurate system anomaly detection. We evaluate HADES extensively on large-scale simulated and industrial datasets. The experimental results present the superiority of HADES in detecting system anomalies on heterogeneous data. We release the code and the annotated dataset for reproducibility and future research.","link":"http://arxiv.org/abs/2207.02918v1","created":"2022-06-22","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Heterogeneous Anomaly Detection for Software Systems via Attentive Multi-modal Learning Prompt and accurate detection of system anomalies is essential to ensure the reliability of software systems. Unlike manual efforts that exploit all available run-time information, existing approaches usually leverage only a single type of monitoring data (often logs or metrics) or fail to make effective use of the joint information among multi-source data. Consequently, many false predictions occur. To better understand the manifestations of system anomalies, we conduct a comprehensive empirical study based on a large amount of heterogeneous data, i.e., logs and metrics. Our study demonstrates that system anomalies could manifest distinctly in different data types. Thus, integrating heterogeneous data can help recover the complete picture of a system's health status. In this context, we propose HADES, the first work to effectively identify system anomalies based on heterogeneous data. Our approach employs a hierarchical architecture to learn a global representation of the system status by fusing log semantics and metric patterns. It captures discriminative features and meaningful interactions from multi-modal data via a novel cross-modal attention module, enabling accurate system anomaly detection. We evaluate HADES extensively on large-scale simulated and industrial datasets. The experimental results present the superiority of HADES in detecting system anomalies on heterogeneous data. We release the code and the annotated dataset for reproducibility and future research.","classes":{"dataset":0.4532026649}}
{"title":"Referring Image Matting","description":"Different from conventional image matting, which either requires user-defined scribbles/trimap to extract a specific foreground object or directly extracts all the foreground objects in the image indiscriminately, we introduce a new task named Referring Image Matting (RIM) in this paper. RIM aims to extract the meticulous alpha matte of the specific object that best matches the given natural language description, thus enabling a more natural and simpler instruction for image matting. First, we establish a large-scale challenging dataset RefMatte by designing a comprehensive image composition and expression generation engine to automatically produce high-quality images along with diverse text attributes based on public datasets. RefMatte consists of 230 object categories, 47,500 images, 118,749 expression-region entities, and 474,996 expressions. Additionally, we construct a real-world test set with 100 high-resolution natural images and manually annotate complex phrases to evaluate the out-of-domain generalization abilities of RIM methods. Furthermore, we present a novel baseline method CLIPMat for RIM, including a context-embedded prompt, a text-driven semantic pop-up, and a multi-level details extractor. Extensive experiments on RefMatte in both keyword and expression settings validate the superiority of CLIPMat over representative methods. We hope this work could provide novel insights into image matting and encourage more follow-up studies. The dataset, code, and models will be made public at https://github.com/JizhiziLi/RIM.","link":"http://arxiv.org/abs/2206.05149v2","created":"2022-06-10","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Referring Image Matting Different from conventional image matting, which either requires user-defined scribbles/trimap to extract a specific foreground object or directly extracts all the foreground objects in the image indiscriminately, we introduce a new task named Referring Image Matting (RIM) in this paper. RIM aims to extract the meticulous alpha matte of the specific object that best matches the given natural language description, thus enabling a more natural and simpler instruction for image matting. First, we establish a large-scale challenging dataset RefMatte by designing a comprehensive image composition and expression generation engine to automatically produce high-quality images along with diverse text attributes based on public datasets. RefMatte consists of 230 object categories, 47,500 images, 118,749 expression-region entities, and 474,996 expressions. Additionally, we construct a real-world test set with 100 high-resolution natural images and manually annotate complex phrases to evaluate the out-of-domain generalization abilities of RIM methods. Furthermore, we present a novel baseline method CLIPMat for RIM, including a context-embedded prompt, a text-driven semantic pop-up, and a multi-level details extractor. Extensive experiments on RefMatte in both keyword and expression settings validate the superiority of CLIPMat over representative methods. We hope this work could provide novel insights into image matting and encourage more follow-up studies. The dataset, code, and models will be made public at https://github.com/JizhiziLi/RIM.","classes":{"dataset":0.0223381948}}
{"title":"Code Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language Models on Code","description":"Few-shot learning with large-scale, pre-trained language models is a powerful way to answer questions about code, e.g., how to complete a given code example, or even generate code snippets from scratch. The success of these models raises the question whether they could serve as a basis for building a wide range code generation tools. Traditionally, such tools are built manually and separately for each task. Instead, few-shot learning may allow to obtain different tools from a single pre-trained language model by simply providing a few examples or a natural language description of the expected tool behavior. This paper studies to what extent a state-of-the-art, pre-trained language model of code, Codex, may serve this purpose. We consider three code manipulation and code generation tasks targeted by a range of traditional tools: (i) code mutation; (ii) test oracle generation from natural language documentation; and (iii) test case generation. For each task, we compare few-shot learning to a manually built tool. Our results show that the model-based tools complement (code mutation), are on par (test oracle generation), or even outperform their respective traditionally built tool (test case generation), while imposing far less effort to develop them. By comparing the effectiveness of different variants of the model-based tools, we provide insights on how to design an appropriate input (\"prompt\") to the model and what influence the size of the model has. For example, we find that providing a small natural language description of the code generation task is an easy way to improve predictions. Overall, we conclude that few-shot language models are surprisingly effective, yet there is still more work to be done, such as exploring more diverse ways of prompting and tackling even more involved tasks.","link":"http://arxiv.org/abs/2206.01335v2","created":"2022-06-02","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Code Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language Models on Code Few-shot learning with large-scale, pre-trained language models is a powerful way to answer questions about code, e.g., how to complete a given code example, or even generate code snippets from scratch. The success of these models raises the question whether they could serve as a basis for building a wide range code generation tools. Traditionally, such tools are built manually and separately for each task. Instead, few-shot learning may allow to obtain different tools from a single pre-trained language model by simply providing a few examples or a natural language description of the expected tool behavior. This paper studies to what extent a state-of-the-art, pre-trained language model of code, Codex, may serve this purpose. We consider three code manipulation and code generation tasks targeted by a range of traditional tools: (i) code mutation; (ii) test oracle generation from natural language documentation; and (iii) test case generation. For each task, we compare few-shot learning to a manually built tool. Our results show that the model-based tools complement (code mutation), are on par (test oracle generation), or even outperform their respective traditionally built tool (test case generation), while imposing far less effort to develop them. By comparing the effectiveness of different variants of the model-based tools, we provide insights on how to design an appropriate input (\"prompt\") to the model and what influence the size of the model has. For example, we find that providing a small natural language description of the code generation task is an easy way to improve predictions. Overall, we conclude that few-shot language models are surprisingly effective, yet there is still more work to be done, such as exploring more diverse ways of prompting and tackling even more involved tasks.","classes":{"dataset":0.1154613867}}
{"title":"Onset of particle acceleration during the prompt phase in gamma-ray bursts as revealed by synchrotron emission in GRB160821A","description":"The physical processes of the gamma-ray emission and particle acceleration during the prompt phase in GRBs are still unsettled. In order to perform an unambiguous physical modelling of observations, a clear identification of the emission mechanism is needed. An instance of a clear identification is the synchrotron emission during the very strong flare in GRB160821A, that occurs during the prompt phase at 135 s. Here we show that the distribution of the radiating electrons in this flare is initially very narrow, but later develops a power-law tail of accelerated electrons. We thus identify for the first time the onset of particle acceleration in a GRB jet. The flare is consistent with a late energy release from the central engine causing an external-shock as it encounters a preexisting ring nebula of a progenitor Wolf-Rayet star. Relativistic forward and reverse shocks develop, leading to two distinct emission zones with similar properties. The particle acceleration only occurs in the forward shock, moving into the dense nebula matter. Here, the magnetisation also decreases below the critical value, which allows for Fermi acceleration to operate. Using this fact, we find a bulk Lorentz factor of $420 \\simleq \\Gamma \\simleq 770$, and an emission radius of $R \\sim 10^{18}$ cm, indicating a tenuous gas of the immediate circumburst surrounding. The observation of the onset of particle acceleration thus gives new and independent constraints on the properties of the flow as well as on theories of particle acceleration in collisionless astrophysical shocks.","link":"http://arxiv.org/abs/2206.00680v1","created":"2022-06-01","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Onset of particle acceleration during the prompt phase in gamma-ray bursts as revealed by synchrotron emission in GRB160821A The physical processes of the gamma-ray emission and particle acceleration during the prompt phase in GRBs are still unsettled. In order to perform an unambiguous physical modelling of observations, a clear identification of the emission mechanism is needed. An instance of a clear identification is the synchrotron emission during the very strong flare in GRB160821A, that occurs during the prompt phase at 135 s. Here we show that the distribution of the radiating electrons in this flare is initially very narrow, but later develops a power-law tail of accelerated electrons. We thus identify for the first time the onset of particle acceleration in a GRB jet. The flare is consistent with a late energy release from the central engine causing an external-shock as it encounters a preexisting ring nebula of a progenitor Wolf-Rayet star. Relativistic forward and reverse shocks develop, leading to two distinct emission zones with similar properties. The particle acceleration only occurs in the forward shock, moving into the dense nebula matter. Here, the magnetisation also decreases below the critical value, which allows for Fermi acceleration to operate. Using this fact, we find a bulk Lorentz factor of $420 \\simleq \\Gamma \\simleq 770$, and an emission radius of $R \\sim 10^{18}$ cm, indicating a tenuous gas of the immediate circumburst surrounding. The observation of the onset of particle acceleration thus gives new and independent constraints on the properties of the flow as well as on theories of particle acceleration in collisionless astrophysical shocks.","classes":{"dataset":0.2920481265}}
{"title":"Toxicity Detection with Generative Prompt-based Inference","description":"Due to the subtleness, implicity, and different possible interpretations perceived by different people, detecting undesirable content from text is a nuanced difficulty. It is a long-known risk that language models (LMs), once trained on corpus containing undesirable content, have the power to manifest biases and toxicity. However, recent studies imply that, as a remedy, LMs are also capable of identifying toxic content without additional fine-tuning. Prompt-methods have been shown to effectively harvest this surprising self-diagnosing capability. However, existing prompt-based methods usually specify an instruction to a language model in a discriminative way. In this work, we explore the generative variant of zero-shot prompt-based toxicity detection with comprehensive trials on prompt engineering. We evaluate on three datasets with toxicity labels annotated on social media posts. Our analysis highlights the strengths of our generative classification approach both quantitatively and qualitatively. Interesting aspects of self-diagnosis and its ethical implications are discussed.","link":"http://arxiv.org/abs/2205.12390v1","created":"2022-05-24","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Toxicity Detection with Generative Prompt-based Inference Due to the subtleness, implicity, and different possible interpretations perceived by different people, detecting undesirable content from text is a nuanced difficulty. It is a long-known risk that language models (LMs), once trained on corpus containing undesirable content, have the power to manifest biases and toxicity. However, recent studies imply that, as a remedy, LMs are also capable of identifying toxic content without additional fine-tuning. Prompt-methods have been shown to effectively harvest this surprising self-diagnosing capability. However, existing prompt-based methods usually specify an instruction to a language model in a discriminative way. In this work, we explore the generative variant of zero-shot prompt-based toxicity detection with comprehensive trials on prompt engineering. We evaluate on three datasets with toxicity labels annotated on social media posts. Our analysis highlights the strengths of our generative classification approach both quantitatively and qualitatively. Interesting aspects of self-diagnosis and its ethical implications are discussed.","classes":{"dataset":0.2787874043}}
{"title":"Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements","description":"The growing capability and availability of generative language models has enabled a wide range of new downstream tasks. Academic research has identified, quantified and mitigated biases present in language models but is rarely tailored to downstream tasks where wider impact on individuals and society can be felt. In this work, we leverage one popular generative language model, GPT-3, with the goal of writing unbiased and realistic job advertisements. We first assess the bias and realism of zero-shot generated advertisements and compare them to real-world advertisements. We then evaluate prompt-engineering and fine-tuning as debiasing methods. We find that prompt-engineering with diversity-encouraging prompts gives no significant improvement to bias, nor realism. Conversely, fine-tuning, especially on unbiased real advertisements, can improve realism and reduce bias.","link":"http://arxiv.org/abs/2205.11374v1","created":"2022-05-23","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements The growing capability and availability of generative language models has enabled a wide range of new downstream tasks. Academic research has identified, quantified and mitigated biases present in language models but is rarely tailored to downstream tasks where wider impact on individuals and society can be felt. In this work, we leverage one popular generative language model, GPT-3, with the goal of writing unbiased and realistic job advertisements. We first assess the bias and realism of zero-shot generated advertisements and compare them to real-world advertisements. We then evaluate prompt-engineering and fine-tuning as debiasing methods. We find that prompt-engineering with diversity-encouraging prompts gives no significant improvement to bias, nor realism. Conversely, fine-tuning, especially on unbiased real advertisements, can improve realism and reduce bias.","classes":{"dataset":0.2473388016}}
{"title":"What GPT Knows About Who is Who","description":"Coreference resolution -- which is a crucial task for understanding discourse and language at large -- has yet to witness widespread benefits from large language models (LLMs). Moreover, coreference resolution systems largely rely on supervised labels, which are highly expensive and difficult to annotate, thus making it ripe for prompt engineering. In this paper, we introduce a QA-based prompt-engineering method and discern \\textit{generative}, pre-trained LLMs' abilities and limitations toward the task of coreference resolution. Our experiments show that GPT-2 and GPT-Neo can return valid answers, but that their capabilities to identify coreferent mentions are limited and prompt-sensitive, leading to inconsistent results.","link":"http://arxiv.org/abs/2205.07407v1","created":"2022-05-16","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"What GPT Knows About Who is Who Coreference resolution -- which is a crucial task for understanding discourse and language at large -- has yet to witness widespread benefits from large language models (LLMs). Moreover, coreference resolution systems largely rely on supervised labels, which are highly expensive and difficult to annotate, thus making it ripe for prompt engineering. In this paper, we introduce a QA-based prompt-engineering method and discern \\textit{generative}, pre-trained LLMs' abilities and limitations toward the task of coreference resolution. Our experiments show that GPT-2 and GPT-Neo can return valid answers, but that their capabilities to identify coreferent mentions are limited and prompt-sensitive, leading to inconsistent results.","classes":{"dataset":0.1156865433}}
{"title":"The Creativity of Text-to-Image Generation","description":"Text-guided synthesis of images has made a giant leap towards becoming a mainstream phenomenon. With text-to-image generation systems, anybody can create digital images and artworks. This provokes the question of whether text-to-image generation is creative. This paper expounds on the nature of human creativity involved in text-to-image art (so-called \"AI art\") with a specific focus on the practice of prompt engineering. The paper argues that the current product-centered view of creativity falls short in the context of text-to-image generation. A case exemplifying this shortcoming is provided and the importance of online communities for the creative ecosystem of text-to-image art is highlighted. The paper provides a high-level summary of this online ecosystem drawing on Rhodes' conceptual four P model of creativity. Challenges for evaluating the creativity of text-to-image generation and opportunities for research on text-to-image generation in the field of Human-Computer Interaction (HCI) are discussed.","link":"http://arxiv.org/abs/2206.02904v4","created":"2022-05-13","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"The Creativity of Text-to-Image Generation Text-guided synthesis of images has made a giant leap towards becoming a mainstream phenomenon. With text-to-image generation systems, anybody can create digital images and artworks. This provokes the question of whether text-to-image generation is creative. This paper expounds on the nature of human creativity involved in text-to-image art (so-called \"AI art\") with a specific focus on the practice of prompt engineering. The paper argues that the current product-centered view of creativity falls short in the context of text-to-image generation. A case exemplifying this shortcoming is provided and the importance of online communities for the creative ecosystem of text-to-image art is highlighted. The paper provides a high-level summary of this online ecosystem drawing on Rhodes' conceptual four P model of creativity. Challenges for evaluating the creativity of text-to-image generation and opportunities for research on text-to-image generation in the field of Human-Computer Interaction (HCI) are discussed.","classes":{"dataset":0.1654396653}}
{"title":"CLIP-CLOP: CLIP-Guided Collage and Photomontage","description":"The unabated mystique of large-scale neural networks, such as the CLIP dual image-and-text encoder, popularized automatically generated art. Increasingly more sophisticated generators enhanced the artworks' realism and visual appearance, and creative prompt engineering enabled stylistic expression. Guided by an artist-in-the-loop ideal, we design a gradient-based generator to produce collages. It requires the human artist to curate libraries of image patches and to describe (with prompts) the whole image composition, with the option to manually adjust the patches' positions during generation, thereby allowing humans to reclaim some control of the process and achieve greater creative freedom. We explore the aesthetic potentials of high-resolution collages, and provide an open-source Google Colab as an artistic tool.","link":"http://arxiv.org/abs/2205.03146v3","created":"2022-05-06","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"CLIP-CLOP: CLIP-Guided Collage and Photomontage The unabated mystique of large-scale neural networks, such as the CLIP dual image-and-text encoder, popularized automatically generated art. Increasingly more sophisticated generators enhanced the artworks' realism and visual appearance, and creative prompt engineering enabled stylistic expression. Guided by an artist-in-the-loop ideal, we design a gradient-based generator to produce collages. It requires the human artist to curate libraries of image patches and to describe (with prompts) the whole image composition, with the option to manually adjust the patches' positions during generation, thereby allowing humans to reclaim some control of the process and achieve greater creative freedom. We explore the aesthetic potentials of high-resolution collages, and provide an open-source Google Colab as an artistic tool.","classes":{"dataset":0.4208339751}}
{"title":"Polyglot Prompt: Multilingual Multitask PrompTraining","description":"This paper aims for a potential architectural improvement for multilingual learning and asks: Can different tasks from different languages be modeled in a monolithic framework, i.e. without any task/language-specific module? The benefit of achieving this could open new doors for future multilingual research, including allowing systems trained on low resources to be further assisted by other languages as well as other tasks. We approach this goal by developing a learning framework named Polyglot Prompting to exploit prompting methods for learning a unified semantic space for different languages and tasks with multilingual prompt engineering. We performed a comprehensive evaluation of 6 tasks, namely topic classification, sentiment classification, named entity recognition, question answering, natural language inference, and summarization, covering 24 datasets and 49 languages. The experimental results demonstrated the efficacy of multilingual multitask prompt-based learning and led to inspiring observations. We also present an interpretable multilingual evaluation methodology and show how the proposed framework, multilingual multitask prompt training, works. We release all datasets prompted in the best setting and code.","link":"http://arxiv.org/abs/2204.14264v2","created":"2022-04-29","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Polyglot Prompt: Multilingual Multitask PrompTraining This paper aims for a potential architectural improvement for multilingual learning and asks: Can different tasks from different languages be modeled in a monolithic framework, i.e. without any task/language-specific module? The benefit of achieving this could open new doors for future multilingual research, including allowing systems trained on low resources to be further assisted by other languages as well as other tasks. We approach this goal by developing a learning framework named Polyglot Prompting to exploit prompting methods for learning a unified semantic space for different languages and tasks with multilingual prompt engineering. We performed a comprehensive evaluation of 6 tasks, namely topic classification, sentiment classification, named entity recognition, question answering, natural language inference, and summarization, covering 24 datasets and 49 languages. The experimental results demonstrated the efficacy of multilingual multitask prompt-based learning and led to inspiring observations. We also present an interpretable multilingual evaluation methodology and show how the proposed framework, multilingual multitask prompt training, works. We release all datasets prompted in the best setting and code.","classes":{"dataset":0.0643245354}}
{"title":"Executive Function: A Contrastive Value Policy for Resampling and Relabeling Perceptions via Hindsight Summarization?","description":"We develop the few-shot continual learning task from first principles and hypothesize an evolutionary motivation and mechanism of action for executive function as a contrastive value policy which resamples and relabels perception data via hindsight summarization to minimize attended prediction error, similar to an online prompt engineering problem. This is made feasible by the use of a memory policy and a pretrained network with inductive biases for a grammar of learning and is trained to maximize evolutionary survival. We show how this model of executive function can be used to implement hypothesis testing as a stream of consciousness and may explain observations of human few-shot learning and neuroanatomy.","link":"http://arxiv.org/abs/2204.12639v1","created":"2022-04-27","tags":["arxiv","ml","prompteng"],"meta":{"query":"prompt AND engineering"},"text":"Executive Function: A Contrastive Value Policy for Resampling and Relabeling Perceptions via Hindsight Summarization? We develop the few-shot continual learning task from first principles and hypothesize an evolutionary motivation and mechanism of action for executive function as a contrastive value policy which resamples and relabels perception data via hindsight summarization to minimize attended prediction error, similar to an online prompt engineering problem. This is made feasible by the use of a memory policy and a pretrained network with inductive biases for a grammar of learning and is trained to maximize evolutionary survival. We show how this model of executive function can be used to implement hypothesis testing as a stream of consciousness and may explain observations of human few-shot learning and neuroanatomy.","classes":{"dataset":0.4574110806}}
{"title":"An Overview on Cloud Distributed Databases for Business Environments","description":"Cloud-based distributed databases are a popular choice for many current applications, especially those that run over the Internet. By incorporating distributed database systems within cloud environments, it has enabled businesses to scale operations to a global level, all while achieving desired standards of system reliability, availability, and responsiveness. Cloud providers offer infrastructure and management tools for distributed databases as Database-as-a-Service (DBaaS), re-purposing the investment by businesses towards database services. This paper reviews the functionality of these services, by highlighting Amazon Relational Data Service (RDS), suited for handling relational distributed databases.","link":"http://arxiv.org/abs/2301.10673v1","created":"2023-01-25","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"An Overview on Cloud Distributed Databases for Business Environments Cloud-based distributed databases are a popular choice for many current applications, especially those that run over the Internet. By incorporating distributed database systems within cloud environments, it has enabled businesses to scale operations to a global level, all while achieving desired standards of system reliability, availability, and responsiveness. Cloud providers offer infrastructure and management tools for distributed databases as Database-as-a-Service (DBaaS), re-purposing the investment by businesses towards database services. This paper reviews the functionality of these services, by highlighting Amazon Relational Data Service (RDS), suited for handling relational distributed databases.","classes":{"dataset":0.2094750851}}
{"title":"Tracking Different Ant Species: An Unsupervised Domain Adaptation Framework and a Dataset for Multi-object Tracking","description":"Tracking individuals is a vital part of many experiments conducted to understand collective behaviour. Ants are the paradigmatic model system for such experiments but their lack of individually distinguishing visual features and their high colony densities make it extremely difficult to perform reliable tracking automatically. Additionally, the wide diversity of their species' appearances makes a generalized approach even harder. In this paper, we propose a data-driven multi-object tracker that, for the first time, employs domain adaptation to achieve the required generalisation. This approach is built upon a joint-detection-and-tracking framework that is extended by a set of domain discriminator modules integrating an adversarial training strategy in addition to the tracking loss. In addition to this novel domain-adaptive tracking framework, we present a new dataset and a benchmark for the ant tracking problem. The dataset contains 57 video sequences with full trajectory annotation, including 30k frames captured from two different ant species moving on different background patterns. It comprises 33 and 24 sequences for source and target domains, respectively. We compare our proposed framework against other domain-adaptive and non-domain-adaptive multi-object tracking baselines using this dataset and show that incorporating domain adaptation at multiple levels of the tracking pipeline yields significant improvements. The code and the dataset are available at https://github.com/chamathabeysinghe/da-tracker.","link":"http://arxiv.org/abs/2301.10559v1","created":"2023-01-25","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Tracking Different Ant Species: An Unsupervised Domain Adaptation Framework and a Dataset for Multi-object Tracking Tracking individuals is a vital part of many experiments conducted to understand collective behaviour. Ants are the paradigmatic model system for such experiments but their lack of individually distinguishing visual features and their high colony densities make it extremely difficult to perform reliable tracking automatically. Additionally, the wide diversity of their species' appearances makes a generalized approach even harder. In this paper, we propose a data-driven multi-object tracker that, for the first time, employs domain adaptation to achieve the required generalisation. This approach is built upon a joint-detection-and-tracking framework that is extended by a set of domain discriminator modules integrating an adversarial training strategy in addition to the tracking loss. In addition to this novel domain-adaptive tracking framework, we present a new dataset and a benchmark for the ant tracking problem. The dataset contains 57 video sequences with full trajectory annotation, including 30k frames captured from two different ant species moving on different background patterns. It comprises 33 and 24 sequences for source and target domains, respectively. We compare our proposed framework against other domain-adaptive and non-domain-adaptive multi-object tracking baselines using this dataset and show that incorporating domain adaptation at multiple levels of the tracking pipeline yields significant improvements. The code and the dataset are available at https://github.com/chamathabeysinghe/da-tracker.","classes":{"dataset":0.9827022552}}
{"title":"Database Reconstruction Is Not So Easy and Is Different from Reidentification","description":"In recent years, it has been claimed that releasing accurate statistical information on a database is likely to allow its complete reconstruction. Differential privacy has been suggested as the appropriate methodology to prevent these attacks. These claims have recently been taken very seriously by the U.S. Census Bureau and led them to adopt differential privacy for releasing U.S. Census data. This in turn has caused consternation among users of the Census data due to the lack of accuracy of the protected outputs. It has also brought legal action against the U.S. Department of Commerce. In this paper, we trace the origins of the claim that releasing information on a database automatically makes it vulnerable to being exposed by reconstruction attacks and we show that this claim is, in fact, incorrect. We also show that reconstruction can be averted by properly using traditional statistical disclosure control (SDC) techniques. We further show that the geographic level at which exact counts are released is even more relevant to protection than the actual SDC method employed. Finally, we caution against confusing reconstruction and reidentification: using the quality of reconstruction as a metric of reidentification results in exaggerated reidentification risk figures.","link":"http://arxiv.org/abs/2301.10213v1","created":"2023-01-24","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Database Reconstruction Is Not So Easy and Is Different from Reidentification In recent years, it has been claimed that releasing accurate statistical information on a database is likely to allow its complete reconstruction. Differential privacy has been suggested as the appropriate methodology to prevent these attacks. These claims have recently been taken very seriously by the U.S. Census Bureau and led them to adopt differential privacy for releasing U.S. Census data. This in turn has caused consternation among users of the Census data due to the lack of accuracy of the protected outputs. It has also brought legal action against the U.S. Department of Commerce. In this paper, we trace the origins of the claim that releasing information on a database automatically makes it vulnerable to being exposed by reconstruction attacks and we show that this claim is, in fact, incorrect. We also show that reconstruction can be averted by properly using traditional statistical disclosure control (SDC) techniques. We further show that the geographic level at which exact counts are released is even more relevant to protection than the actual SDC method employed. Finally, we caution against confusing reconstruction and reidentification: using the quality of reconstruction as a metric of reidentification results in exaggerated reidentification risk figures.","classes":{"dataset":0.2908917665}}
{"title":"GyroFlow+: Gyroscope-Guided Unsupervised Deep Homography and Optical Flow Learning","description":"Existing homography and optical flow methods are erroneous in challenging scenes, such as fog, rain, night, and snow because the basic assumptions such as brightness and gradient constancy are broken. To address this issue, we present an unsupervised learning approach that fuses gyroscope into homography and optical flow learning. Specifically, we first convert gyroscope readings into motion fields named gyro field. Second, we design a self-guided fusion module (SGF) to fuse the background motion extracted from the gyro field with the optical flow and guide the network to focus on motion details. Meanwhile, we propose a homography decoder module (HD) to combine gyro field and intermediate results of SGF to produce the homography. To the best of our knowledge, this is the first deep learning framework that fuses gyroscope data and image content for both deep homography and optical flow learning. To validate our method, we propose a new dataset that covers regular and challenging scenes. Experiments show that our method outperforms the state-of-the-art methods in both regular and challenging scenes.","link":"http://arxiv.org/abs/2301.10018v1","created":"2023-01-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"GyroFlow+: Gyroscope-Guided Unsupervised Deep Homography and Optical Flow Learning Existing homography and optical flow methods are erroneous in challenging scenes, such as fog, rain, night, and snow because the basic assumptions such as brightness and gradient constancy are broken. To address this issue, we present an unsupervised learning approach that fuses gyroscope into homography and optical flow learning. Specifically, we first convert gyroscope readings into motion fields named gyro field. Second, we design a self-guided fusion module (SGF) to fuse the background motion extracted from the gyro field with the optical flow and guide the network to focus on motion details. Meanwhile, we propose a homography decoder module (HD) to combine gyro field and intermediate results of SGF to produce the homography. To the best of our knowledge, this is the first deep learning framework that fuses gyroscope data and image content for both deep homography and optical flow learning. To validate our method, we propose a new dataset that covers regular and challenging scenes. Experiments show that our method outperforms the state-of-the-art methods in both regular and challenging scenes.","classes":{"dataset":0.964833498}}
{"title":"SPEC5G: A Dataset for 5G Cellular Network Protocol Analysis","description":"5G is the 5th generation cellular network protocol. It is the state-of-the-art global wireless standard that enables an advanced kind of network designed to connect virtually everyone and everything with increased speed and reduced latency. Therefore, its development, analysis, and security are critical. However, all approaches to the 5G protocol development and security analysis, e.g., property extraction, protocol summarization, and semantic analysis of the protocol specifications and implementations are completely manual. To reduce such manual effort, in this paper, we curate SPEC5G the first-ever public 5G dataset for NLP research. The dataset contains 3,547,586 sentences with 134M words, from 13094 cellular network specifications and 13 online websites. By leveraging large-scale pre-trained language models that have achieved state-of-the-art results on NLP tasks, we use this dataset for security-related text classification and summarization. Security-related text classification can be used to extract relevant security-related properties for protocol testing. On the other hand, summarization can help developers and practitioners understand the high level of the protocol, which is itself a daunting task. Our results show the value of our 5G-centric dataset in 5G protocol analysis automation. We believe that SPEC5G will enable a new research direction into automatic analyses for the 5G cellular network protocol and numerous related downstream tasks. Our data and code are publicly available.","link":"http://arxiv.org/abs/2301.09201v1","created":"2023-01-22","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"SPEC5G: A Dataset for 5G Cellular Network Protocol Analysis 5G is the 5th generation cellular network protocol. It is the state-of-the-art global wireless standard that enables an advanced kind of network designed to connect virtually everyone and everything with increased speed and reduced latency. Therefore, its development, analysis, and security are critical. However, all approaches to the 5G protocol development and security analysis, e.g., property extraction, protocol summarization, and semantic analysis of the protocol specifications and implementations are completely manual. To reduce such manual effort, in this paper, we curate SPEC5G the first-ever public 5G dataset for NLP research. The dataset contains 3,547,586 sentences with 134M words, from 13094 cellular network specifications and 13 online websites. By leveraging large-scale pre-trained language models that have achieved state-of-the-art results on NLP tasks, we use this dataset for security-related text classification and summarization. Security-related text classification can be used to extract relevant security-related properties for protocol testing. On the other hand, summarization can help developers and practitioners understand the high level of the protocol, which is itself a daunting task. Our results show the value of our 5G-centric dataset in 5G protocol analysis automation. We believe that SPEC5G will enable a new research direction into automatic analyses for the 5G cellular network protocol and numerous related downstream tasks. Our data and code are publicly available.","classes":{"dataset":0.9713963866}}
{"title":"REDAffectiveLM: Leveraging Affect Enriched Embedding and Transformer-based Neural Language Model for Readers' Emotion Detection","description":"Technological advancements in web platforms allow people to express and share emotions towards textual write-ups written and shared by others. This brings about different interesting domains for analysis; emotion expressed by the writer and emotion elicited from the readers. In this paper, we propose a novel approach for Readers' Emotion Detection from short-text documents using a deep learning model called REDAffectiveLM. Within state-of-the-art NLP tasks, it is well understood that utilizing context-specific representations from transformer-based pre-trained language models helps achieve improved performance. Within this affective computing task, we explore how incorporating affective information can further enhance performance. Towards this, we leverage context-specific and affect enriched representations by using a transformer-based pre-trained language model in tandem with affect enriched Bi-LSTM+Attention. For empirical evaluation, we procure a new dataset REN-20k, besides using RENh-4k and SemEval-2007. We evaluate the performance of our REDAffectiveLM rigorously across these datasets, against a vast set of state-of-the-art baselines, where our model consistently outperforms baselines and obtains statistically significant results. Our results establish that utilizing affect enriched representation along with context-specific representation within a neural architecture can considerably enhance readers' emotion detection. Since the impact of affect enrichment specifically in readers' emotion detection isn't well explored, we conduct a detailed analysis over affect enriched Bi-LSTM+Attention using qualitative and quantitative model behavior evaluation techniques. We observe that compared to conventional semantic embedding, affect enriched embedding increases ability of the network to effectively identify and assign weightage to key terms responsible for readers' emotion detection.","link":"http://arxiv.org/abs/2301.08995v1","created":"2023-01-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"REDAffectiveLM: Leveraging Affect Enriched Embedding and Transformer-based Neural Language Model for Readers' Emotion Detection Technological advancements in web platforms allow people to express and share emotions towards textual write-ups written and shared by others. This brings about different interesting domains for analysis; emotion expressed by the writer and emotion elicited from the readers. In this paper, we propose a novel approach for Readers' Emotion Detection from short-text documents using a deep learning model called REDAffectiveLM. Within state-of-the-art NLP tasks, it is well understood that utilizing context-specific representations from transformer-based pre-trained language models helps achieve improved performance. Within this affective computing task, we explore how incorporating affective information can further enhance performance. Towards this, we leverage context-specific and affect enriched representations by using a transformer-based pre-trained language model in tandem with affect enriched Bi-LSTM+Attention. For empirical evaluation, we procure a new dataset REN-20k, besides using RENh-4k and SemEval-2007. We evaluate the performance of our REDAffectiveLM rigorously across these datasets, against a vast set of state-of-the-art baselines, where our model consistently outperforms baselines and obtains statistically significant results. Our results establish that utilizing affect enriched representation along with context-specific representation within a neural architecture can considerably enhance readers' emotion detection. Since the impact of affect enrichment specifically in readers' emotion detection isn't well explored, we conduct a detailed analysis over affect enriched Bi-LSTM+Attention using qualitative and quantitative model behavior evaluation techniques. We observe that compared to conventional semantic embedding, affect enriched embedding increases ability of the network to effectively identify and assign weightage to key terms responsible for readers' emotion detection.","classes":{"dataset":0.0773364827}}
{"title":"A Large-scale Film Style Dataset for Learning Multi-frequency Driven Film Enhancement","description":"Film, a classic image style, is culturally significant to the whole photographic industry since it marks the birth of photography. However, film photography is time-consuming and expensive, necessitating a more efficient method for collecting film-style photographs. Numerous datasets that have emerged in the field of image enhancement so far are not film-specific. In order to facilitate film-based image stylization research, we construct FilmSet, a large-scale and high-quality film style dataset. Our dataset includes three different film types and more than 5000 in-the-wild high resolution images. Inspired by the features of FilmSet images, we propose a novel framework called FilmNet based on Laplacian Pyramid for stylizing images across frequency bands and achieving film style outcomes. Experiments reveal that the performance of our model is superior than state-of-the-art techniques. Our dataset and code will be made publicly available.","link":"http://arxiv.org/abs/2301.08880v1","created":"2023-01-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A Large-scale Film Style Dataset for Learning Multi-frequency Driven Film Enhancement Film, a classic image style, is culturally significant to the whole photographic industry since it marks the birth of photography. However, film photography is time-consuming and expensive, necessitating a more efficient method for collecting film-style photographs. Numerous datasets that have emerged in the field of image enhancement so far are not film-specific. In order to facilitate film-based image stylization research, we construct FilmSet, a large-scale and high-quality film style dataset. Our dataset includes three different film types and more than 5000 in-the-wild high resolution images. Inspired by the features of FilmSet images, we propose a novel framework called FilmNet based on Laplacian Pyramid for stylizing images across frequency bands and achieving film style outcomes. Experiments reveal that the performance of our model is superior than state-of-the-art techniques. Our dataset and code will be made publicly available.","classes":{"dataset":0.9723010659}}
{"title":"Visual Semantic Relatedness Dataset for Image Captioning","description":"Modern image captioning system relies heavily on extracting knowledge from images to capture the concept of a static story. In this paper, we propose a textual visual context dataset for captioning, in which the publicly available dataset COCO Captions (Lin et al., 2014) has been extended with information about the scene (such as objects in the image). Since this information has a textual form, it can be used to leverage any NLP task, such as text similarity or semantic relation methods, into captioning systems, either as an end-to-end training strategy or a post-processing based approach.","link":"http://arxiv.org/abs/2301.08784v1","created":"2023-01-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Visual Semantic Relatedness Dataset for Image Captioning Modern image captioning system relies heavily on extracting knowledge from images to capture the concept of a static story. In this paper, we propose a textual visual context dataset for captioning, in which the publicly available dataset COCO Captions (Lin et al., 2014) has been extended with information about the scene (such as objects in the image). Since this information has a textual form, it can be used to leverage any NLP task, such as text similarity or semantic relation methods, into captioning systems, either as an end-to-end training strategy or a post-processing based approach.","classes":{"dataset":0.0264738407}}
{"title":"RGB-D-Based Categorical Object Pose and Shape Estimation: Methods, Datasets, and Evaluation","description":"Recently, various methods for 6D pose and shape estimation of objects at a per-category level have been proposed. This work provides an overview of the field in terms of methods, datasets, and evaluation protocols. First, an overview of existing works and their commonalities and differences is provided. Second, we take a critical look at the predominant evaluation protocol, including metrics and datasets. Based on the findings, we propose a new set of metrics, contribute new annotations for the Redwood dataset, and evaluate state-of-the-art methods in a fair comparison. The results indicate that existing methods do not generalize well to unconstrained orientations and are actually heavily biased towards objects being upright. We provide an easy-to-use evaluation toolbox with well-defined metrics, methods, and dataset interfaces, which allows evaluation and comparison with various state-of-the-art approaches (https://github.com/roym899/pose_and_shape_evaluation).","link":"http://arxiv.org/abs/2301.08147v1","created":"2023-01-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"RGB-D-Based Categorical Object Pose and Shape Estimation: Methods, Datasets, and Evaluation Recently, various methods for 6D pose and shape estimation of objects at a per-category level have been proposed. This work provides an overview of the field in terms of methods, datasets, and evaluation protocols. First, an overview of existing works and their commonalities and differences is provided. Second, we take a critical look at the predominant evaluation protocol, including metrics and datasets. Based on the findings, we propose a new set of metrics, contribute new annotations for the Redwood dataset, and evaluate state-of-the-art methods in a fair comparison. The results indicate that existing methods do not generalize well to unconstrained orientations and are actually heavily biased towards objects being upright. We provide an easy-to-use evaluation toolbox with well-defined metrics, methods, and dataset interfaces, which allows evaluation and comparison with various state-of-the-art approaches (https://github.com/roym899/pose_and_shape_evaluation).","classes":{"dataset":0.9522787333}}
{"title":"Improving Machine Translation with Phrase Pair Injection and Corpus Filtering","description":"In this paper, we show that the combination of Phrase Pair Injection and Corpus Filtering boosts the performance of Neural Machine Translation (NMT) systems. We extract parallel phrases and sentences from the pseudo-parallel corpus and augment it with the parallel corpus to train the NMT models. With the proposed approach, we observe an improvement in the Machine Translation (MT) system for 3 low-resource language pairs, Hindi-Marathi, English-Marathi, and English-Pashto, and 6 translation directions by up to 2.7 BLEU points, on the FLORES test data. These BLEU score improvements are over the models trained using the whole pseudo-parallel corpus augmented with the parallel corpus.","link":"http://arxiv.org/abs/2301.08008v1","created":"2023-01-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Improving Machine Translation with Phrase Pair Injection and Corpus Filtering In this paper, we show that the combination of Phrase Pair Injection and Corpus Filtering boosts the performance of Neural Machine Translation (NMT) systems. We extract parallel phrases and sentences from the pseudo-parallel corpus and augment it with the parallel corpus to train the NMT models. With the proposed approach, we observe an improvement in the Machine Translation (MT) system for 3 low-resource language pairs, Hindi-Marathi, English-Marathi, and English-Pashto, and 6 translation directions by up to 2.7 BLEU points, on the FLORES test data. These BLEU score improvements are over the models trained using the whole pseudo-parallel corpus augmented with the parallel corpus.","classes":{"dataset":0.0646645352}}
{"title":"OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models","description":"We propose a new method for object pose estimation without CAD models. The previous feature-matching-based method OnePose has shown promising results under a one-shot setting which eliminates the need for CAD models or object-specific training. However, OnePose relies on detecting repeatable image keypoints and is thus prone to failure on low-textured objects. We propose a keypoint-free pose estimation pipeline to remove the need for repeatable keypoint detection. Built upon the detector-free feature matching method LoFTR, we devise a new keypoint-free SfM method to reconstruct a semi-dense point-cloud model for the object. Given a query image for object pose estimation, a 2D-3D matching network directly establishes 2D-3D correspondences between the query image and the reconstructed point-cloud model without first detecting keypoints in the image. Experiments show that the proposed pipeline outperforms existing one-shot CAD-model-free methods by a large margin and is comparable to CAD-model-based methods on LINEMOD even for low-textured objects. We also collect a new dataset composed of 80 sequences of 40 low-textured objects to facilitate future research on one-shot object pose estimation. The supplementary material, code and dataset are available on the project page: https://zju3dv.github.io/onepose_plus_plus/.","link":"http://arxiv.org/abs/2301.07673v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"OnePose++: Keypoint-Free One-Shot Object Pose Estimation without CAD Models We propose a new method for object pose estimation without CAD models. The previous feature-matching-based method OnePose has shown promising results under a one-shot setting which eliminates the need for CAD models or object-specific training. However, OnePose relies on detecting repeatable image keypoints and is thus prone to failure on low-textured objects. We propose a keypoint-free pose estimation pipeline to remove the need for repeatable keypoint detection. Built upon the detector-free feature matching method LoFTR, we devise a new keypoint-free SfM method to reconstruct a semi-dense point-cloud model for the object. Given a query image for object pose estimation, a 2D-3D matching network directly establishes 2D-3D correspondences between the query image and the reconstructed point-cloud model without first detecting keypoints in the image. Experiments show that the proposed pipeline outperforms existing one-shot CAD-model-free methods by a large margin and is comparable to CAD-model-based methods on LINEMOD even for low-textured objects. We also collect a new dataset composed of 80 sequences of 40 low-textured objects to facilitate future research on one-shot object pose estimation. The supplementary material, code and dataset are available on the project page: https://zju3dv.github.io/onepose_plus_plus/.","classes":{"dataset":0.8708670735}}
{"title":"A novel dataset and a two-stage mitosis nuclei detection method based on hybrid anchor branch","description":"Mitosis detection is one of the challenging problems in computational pathology, and mitotic count is an important index of cancer grading for pathologists. However, current counts of mitotic nuclei rely on pathologists looking microscopically at the number of mitotic nuclei in hot spots, which is subjective and time-consuming. In this paper, we propose a two-stage cascaded network, named FoCasNet, for mitosis detection. In the first stage, a detection network named M_det is proposed to detect as many mitoses as possible. In the second stage, a classification network M_class is proposed to refine the results of the first stage. In addition, the attention mechanism, normalization method, and hybrid anchor branch classification subnet are introduced to improve the overall detection performance. Our method achieves the current highest F1-score of 0.888 on the public dataset ICPR 2012. We also evaluated our method on the GZMH dataset released by our research team for the first time and reached the highest F1-score of 0.563, which is also better than multiple classic detection networks widely used at present. It confirmed the effectiveness and generalization of our method. The code will be available at: https://github.com/antifen/mitosis-nuclei-detection.","link":"http://arxiv.org/abs/2301.07627v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A novel dataset and a two-stage mitosis nuclei detection method based on hybrid anchor branch Mitosis detection is one of the challenging problems in computational pathology, and mitotic count is an important index of cancer grading for pathologists. However, current counts of mitotic nuclei rely on pathologists looking microscopically at the number of mitotic nuclei in hot spots, which is subjective and time-consuming. In this paper, we propose a two-stage cascaded network, named FoCasNet, for mitosis detection. In the first stage, a detection network named M_det is proposed to detect as many mitoses as possible. In the second stage, a classification network M_class is proposed to refine the results of the first stage. In addition, the attention mechanism, normalization method, and hybrid anchor branch classification subnet are introduced to improve the overall detection performance. Our method achieves the current highest F1-score of 0.888 on the public dataset ICPR 2012. We also evaluated our method on the GZMH dataset released by our research team for the first time and reached the highest F1-score of 0.563, which is also better than multiple classic detection networks widely used at present. It confirmed the effectiveness and generalization of our method. The code will be available at: https://github.com/antifen/mitosis-nuclei-detection.","classes":{"dataset":0.0128282532}}
{"title":"A Synthetic Hyperspectral Array Video Database with Applications to Cross-Spectral Reconstruction and Hyperspectral Video Coding","description":"In this paper, a synthetic hyperspectral video database is introduced. Since it is impossible to record ground truth hyperspectral videos, this database offers the possibility to leverage the evaluation of algorithms in diverse applications. For all scenes, depth maps are provided as well to yield the position of a pixel in all spatial dimensions as well as the reflectance in spectral dimension. Two novel algorithms for two different applications are proposed to prove the diversity of applications that can be addressed by this novel database. First, a cross-spectral image reconstruction algorithm is extended to exploit the temporal correlation between two consecutive frames. The evaluation using this hyperspectral database shows an increase in PSNR of up to 5.6 dB dependent on the scene. Second, a hyperspectral video coder is introduced which extends an existing hyperspectral image coder by exploiting temporal correlation. The evaluation shows rate savings of up to 10% depending on the scene. The novel hyperspectral video database and source code is available at https:// github.com/ FAU-LMS/ HyViD for use by the research community.","link":"http://arxiv.org/abs/2301.07551v2","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A Synthetic Hyperspectral Array Video Database with Applications to Cross-Spectral Reconstruction and Hyperspectral Video Coding In this paper, a synthetic hyperspectral video database is introduced. Since it is impossible to record ground truth hyperspectral videos, this database offers the possibility to leverage the evaluation of algorithms in diverse applications. For all scenes, depth maps are provided as well to yield the position of a pixel in all spatial dimensions as well as the reflectance in spectral dimension. Two novel algorithms for two different applications are proposed to prove the diversity of applications that can be addressed by this novel database. First, a cross-spectral image reconstruction algorithm is extended to exploit the temporal correlation between two consecutive frames. The evaluation using this hyperspectral database shows an increase in PSNR of up to 5.6 dB dependent on the scene. Second, a hyperspectral video coder is introduced which extends an existing hyperspectral image coder by exploiting temporal correlation. The evaluation shows rate savings of up to 10% depending on the scene. The novel hyperspectral video database and source code is available at https:// github.com/ FAU-LMS/ HyViD for use by the research community.","classes":{"dataset":0.0441719331}}
{"title":"A semi-model-independent approach to describe a cosmological database","description":"A model-independent or non-parametric approach for modeling a database has been widely used in cosmology. In these scenarios, the data has been used directly to reconstruct an underlying function. In this work, we introduce a novel semi-model-independent method to do the task. The new approach not only removes some drawbacks of previous methods but also has some remarkable advantages. We combine the well-known Gaussian linear model with a neural network and introduce a procedure for the reconstruction of an arbitrary function. In the scenario, the neural network produces some arbitrary base functions which subsequently are fed to the Gaussian linear model. Given a prior distribution on the free parameters, the Gaussian linear model provides a close form for the posterior distribution as well as the Bayesian evidence. In addition, contrary to other methods, it is straightforward to compute the uncertainty.","link":"http://arxiv.org/abs/2301.07369v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A semi-model-independent approach to describe a cosmological database A model-independent or non-parametric approach for modeling a database has been widely used in cosmology. In these scenarios, the data has been used directly to reconstruct an underlying function. In this work, we introduce a novel semi-model-independent method to do the task. The new approach not only removes some drawbacks of previous methods but also has some remarkable advantages. We combine the well-known Gaussian linear model with a neural network and introduce a procedure for the reconstruction of an arbitrary function. In the scenario, the neural network produces some arbitrary base functions which subsequently are fed to the Gaussian linear model. Given a prior distribution on the free parameters, the Gaussian linear model provides a close form for the posterior distribution as well as the Bayesian evidence. In addition, contrary to other methods, it is straightforward to compute the uncertainty.","classes":{"dataset":0.9628092051}}
{"title":"Efficient Black-box Checking of Snapshot Isolation in Databases","description":"Snapshot isolation (SI) is a prevalent weak isolation level that avoids the performance penalty imposed by serializability and simultaneously prevents various undesired data anomalies. Nevertheless, SI anomalies have recently been found in production cloud databases that claim to provide the SI guarantee. Given the complex and often unavailable internals of such databases, a black-box SI checker is highly desirable.   In this paper we present PolySI, a novel black-box checker that efficiently checks SI and provides understandable counterexamples upon detecting violations. PolySI builds on a novel characterization of SI using generalized polygraphs (GPs), for which we establish its soundness and completeness. PolySI employs an SMT solver and also accelerates SMT solving by utilizing the compact constraint encoding of GPs and domain-specific optimizations for pruning constraints. As demonstrated by our extensive assessment, PolySI successfully reproduces all of 2477 known SI anomalies, detects novel SI violations in three production cloud databases, identifies their causes, outperforms the state-of-the-art black-box checkers under a wide range of workloads, and can scale up to large-sized workloads.","link":"http://arxiv.org/abs/2301.07313v1","created":"2023-01-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Efficient Black-box Checking of Snapshot Isolation in Databases Snapshot isolation (SI) is a prevalent weak isolation level that avoids the performance penalty imposed by serializability and simultaneously prevents various undesired data anomalies. Nevertheless, SI anomalies have recently been found in production cloud databases that claim to provide the SI guarantee. Given the complex and often unavailable internals of such databases, a black-box SI checker is highly desirable.   In this paper we present PolySI, a novel black-box checker that efficiently checks SI and provides understandable counterexamples upon detecting violations. PolySI builds on a novel characterization of SI using generalized polygraphs (GPs), for which we establish its soundness and completeness. PolySI employs an SMT solver and also accelerates SMT solving by utilizing the compact constraint encoding of GPs and domain-specific optimizations for pruning constraints. As demonstrated by our extensive assessment, PolySI successfully reproduces all of 2477 known SI anomalies, detects novel SI violations in three production cloud databases, identifies their causes, outperforms the state-of-the-art black-box checkers under a wide range of workloads, and can scale up to large-sized workloads.","classes":{"dataset":0.021570934}}
{"title":"Simplistic Collection and Labeling Practices Limit the Utility of Benchmark Datasets for Twitter Bot Detection","description":"Accurate bot detection is necessary for the safety and integrity of online platforms. It is also crucial for research on the influence of bots in elections, the spread of misinformation, and financial market manipulation. Platforms deploy infrastructure to flag or remove automated accounts, but their tools and data are not publicly available. Thus, the public must rely on third-party bot detection. These tools employ machine learning and often achieve near perfect performance for classification on existing datasets, suggesting bot detection is accurate, reliable and fit for use in downstream applications. We provide evidence that this is not the case and show that high performance is attributable to limitations in dataset collection and labeling rather than sophistication of the tools. Specifically, we show that simple decision rules -- shallow decision trees trained on a small number of features -- achieve near-state-of-the-art performance on most available datasets and that bot detection datasets, even when combined together, do not generalize well to out-of-sample datasets. Our findings reveal that predictions are highly dependent on each dataset's collection and labeling procedures rather than fundamental differences between bots and humans. These results have important implications for both transparency in sampling and labeling procedures and potential biases in research using existing bot detection tools for pre-processing.","link":"http://arxiv.org/abs/2301.07015v1","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Simplistic Collection and Labeling Practices Limit the Utility of Benchmark Datasets for Twitter Bot Detection Accurate bot detection is necessary for the safety and integrity of online platforms. It is also crucial for research on the influence of bots in elections, the spread of misinformation, and financial market manipulation. Platforms deploy infrastructure to flag or remove automated accounts, but their tools and data are not publicly available. Thus, the public must rely on third-party bot detection. These tools employ machine learning and often achieve near perfect performance for classification on existing datasets, suggesting bot detection is accurate, reliable and fit for use in downstream applications. We provide evidence that this is not the case and show that high performance is attributable to limitations in dataset collection and labeling rather than sophistication of the tools. Specifically, we show that simple decision rules -- shallow decision trees trained on a small number of features -- achieve near-state-of-the-art performance on most available datasets and that bot detection datasets, even when combined together, do not generalize well to out-of-sample datasets. Our findings reveal that predictions are highly dependent on each dataset's collection and labeling procedures rather than fundamental differences between bots and humans. These results have important implications for both transparency in sampling and labeling procedures and potential biases in research using existing bot detection tools for pre-processing.","classes":{"dataset":0.0055816378}}
{"title":"CS-lol: a Dataset of Viewer Comment with Scene in E-sports Live-streaming","description":"Billions of live-streaming viewers share their opinions on scenes they are watching in real-time and interact with the event, commentators as well as other viewers via text comments. Thus, there is necessary to explore viewers' comments with scenes in E-sport live-streaming events. In this paper, we developed CS-lol, a new large-scale dataset containing comments from viewers paired with descriptions of game scenes in E-sports live-streaming. Moreover, we propose a task, namely viewer comment retrieval, to retrieve the viewer comments for the scene of the live-streaming event. Results on a series of baseline retrieval methods derived from typical IR evaluation methods show our task as a challenging task. Finally, we release CS-lol and baseline implementation to the research community as a resource.","link":"http://arxiv.org/abs/2301.06876v1","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"CS-lol: a Dataset of Viewer Comment with Scene in E-sports Live-streaming Billions of live-streaming viewers share their opinions on scenes they are watching in real-time and interact with the event, commentators as well as other viewers via text comments. Thus, there is necessary to explore viewers' comments with scenes in E-sport live-streaming events. In this paper, we developed CS-lol, a new large-scale dataset containing comments from viewers paired with descriptions of game scenes in E-sports live-streaming. Moreover, we propose a task, namely viewer comment retrieval, to retrieve the viewer comments for the scene of the live-streaming event. Results on a series of baseline retrieval methods derived from typical IR evaluation methods show our task as a challenging task. Finally, we release CS-lol and baseline implementation to the research community as a resource.","classes":{"dataset":0.0268992018}}
{"title":"Database Matching Under Noisy Synchronization Errors","description":"The re-identification or de-anonymization of users from anonymized data through matching with publicly-available correlated user data has raised privacy concerns, leading to the complementary measure of obfuscation in addition to anonymization. Recent research provides a fundamental understanding of the conditions under which privacy attacks, in the form of database matching, are successful in the presence of obfuscation. Motivated by synchronization errors stemming from the sampling of time-indexed databases, this paper presents a unified framework considering both obfuscation and synchronization errors and investigates the matching of databases under noisy entry repetitions. By investigating different structures for the repetition pattern, replica detection and seeded deletion detection algorithms are devised and sufficient and necessary conditions for successful matching are derived. Finally, the impacts of some variations of the underlying assumptions, such as adversarial deletion model, seedless database matching and zero-rate regime, on the results are discussed. Overall, our results provide insights into the privacy-preserving publication of anonymized and obfuscated time-indexed data as well as the closely-related problem of the capacity of synchronization channels.","link":"http://arxiv.org/abs/2301.06796v1","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Database Matching Under Noisy Synchronization Errors The re-identification or de-anonymization of users from anonymized data through matching with publicly-available correlated user data has raised privacy concerns, leading to the complementary measure of obfuscation in addition to anonymization. Recent research provides a fundamental understanding of the conditions under which privacy attacks, in the form of database matching, are successful in the presence of obfuscation. Motivated by synchronization errors stemming from the sampling of time-indexed databases, this paper presents a unified framework considering both obfuscation and synchronization errors and investigates the matching of databases under noisy entry repetitions. By investigating different structures for the repetition pattern, replica detection and seeded deletion detection algorithms are devised and sufficient and necessary conditions for successful matching are derived. Finally, the impacts of some variations of the underlying assumptions, such as adversarial deletion model, seedless database matching and zero-rate regime, on the results are discussed. Overall, our results provide insights into the privacy-preserving publication of anonymized and obfuscated time-indexed data as well as the closely-related problem of the capacity of synchronization channels.","classes":{"dataset":0.0031822901}}
{"title":"Surgical Aggregation: A Federated Learning Framework for Harmonizing Distributed Datasets with Diverse Tasks","description":"AI-assisted characterization of chest x-rays (CXR) has the potential to provide substantial benefits across many clinical applications. Many large-scale public CXR datasets have been curated for detection of abnormalities using deep learning. However, each of these datasets focus on detecting a subset of disease labels that could be present in a CXR, thus limiting their clinical utility. Furthermore, the distributed nature of these datasets, along with data sharing regulations, make it difficult to share and create a complete representation of disease labels. We propose surgical aggregation, a federated learning framework for aggregating knowledge from distributed datasets with different disease labels into a 'global' deep learning model. We randomly divided the NIH Chest X-Ray 14 dataset into training (70%), validation (10%), and test (20%) splits with no patient overlap and conducted two experiments. In the first experiment, we pruned the disease labels to create two 'toy' datasets containing 11 and 8 labels respectively with 4 overlapping labels. For the second experiment, we pruned the disease labels to create two disjoint 'toy' datasets with 7 labels each. We observed that the surgically aggregated 'global' model resulted in excellent performance across both experiments when compared to a 'baseline' model trained on complete disease labels. The overlapping and disjoint experiments had an AUROC of 0.87 and 0.86 respectively, compared to the baseline AUROC of 0.87. We used surgical aggregation to harmonize the NIH Chest X-Ray 14 and CheXpert datasets into a 'global' model with an AUROC of 0.85 and 0.83 respectively. Our results show that surgical aggregation could be used to develop clinically useful deep learning models by aggregating knowledge from distributed datasets with diverse tasks, a step forward towards bridging the gap from bench to bedside.","link":"http://arxiv.org/abs/2301.06683v1","created":"2023-01-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Surgical Aggregation: A Federated Learning Framework for Harmonizing Distributed Datasets with Diverse Tasks AI-assisted characterization of chest x-rays (CXR) has the potential to provide substantial benefits across many clinical applications. Many large-scale public CXR datasets have been curated for detection of abnormalities using deep learning. However, each of these datasets focus on detecting a subset of disease labels that could be present in a CXR, thus limiting their clinical utility. Furthermore, the distributed nature of these datasets, along with data sharing regulations, make it difficult to share and create a complete representation of disease labels. We propose surgical aggregation, a federated learning framework for aggregating knowledge from distributed datasets with different disease labels into a 'global' deep learning model. We randomly divided the NIH Chest X-Ray 14 dataset into training (70%), validation (10%), and test (20%) splits with no patient overlap and conducted two experiments. In the first experiment, we pruned the disease labels to create two 'toy' datasets containing 11 and 8 labels respectively with 4 overlapping labels. For the second experiment, we pruned the disease labels to create two disjoint 'toy' datasets with 7 labels each. We observed that the surgically aggregated 'global' model resulted in excellent performance across both experiments when compared to a 'baseline' model trained on complete disease labels. The overlapping and disjoint experiments had an AUROC of 0.87 and 0.86 respectively, compared to the baseline AUROC of 0.87. We used surgical aggregation to harmonize the NIH Chest X-Ray 14 and CheXpert datasets into a 'global' model with an AUROC of 0.85 and 0.83 respectively. Our results show that surgical aggregation could be used to develop clinically useful deep learning models by aggregating knowledge from distributed datasets with diverse tasks, a step forward towards bridging the gap from bench to bedside.","classes":{"dataset":0.9937800765}}
{"title":"ClassBases at CASE-2022 Multilingual Protest Event Detection Tasks: Multilingual Protest News Detection and Automatically Replicating Manually Created Event Datasets","description":"In this report, we describe our ClassBases submissions to a shared task on multilingual protest event detection. For the multilingual protest news detection, we participated in subtask-1, subtask-2, and subtask-4, which are document classification, sentence classification, and token classification. In subtask-1, we compare XLM-RoBERTa-base, mLUKE-base, and XLM-RoBERTa-large on finetuning in a sequential classification setting. We always use a combination of the training data from every language provided to train our multilingual models. We found that larger models seem to work better and entity knowledge helps but at a non-negligible cost. For subtask-2, we only submitted an mLUKE-base system for sentence classification. For subtask-4, we only submitted an XLM-RoBERTa-base for token classification system for sequence labeling. For automatically replicating manually created event datasets, we participated in COVID-related protest events from the New York Times news corpus. We created a system to process the crawled data into a dataset of protest events.","link":"http://arxiv.org/abs/2301.06617v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"ClassBases at CASE-2022 Multilingual Protest Event Detection Tasks: Multilingual Protest News Detection and Automatically Replicating Manually Created Event Datasets In this report, we describe our ClassBases submissions to a shared task on multilingual protest event detection. For the multilingual protest news detection, we participated in subtask-1, subtask-2, and subtask-4, which are document classification, sentence classification, and token classification. In subtask-1, we compare XLM-RoBERTa-base, mLUKE-base, and XLM-RoBERTa-large on finetuning in a sequential classification setting. We always use a combination of the training data from every language provided to train our multilingual models. We found that larger models seem to work better and entity knowledge helps but at a non-negligible cost. For subtask-2, we only submitted an mLUKE-base system for sentence classification. For subtask-4, we only submitted an XLM-RoBERTa-base for token classification system for sequence labeling. For automatically replicating manually created event datasets, we participated in COVID-related protest events from the New York Times news corpus. We created a system to process the crawled data into a dataset of protest events.","classes":{"dataset":0.9854680896}}
{"title":"XNLI 2.0: Improving XNLI dataset and performance on Cross Lingual Understanding (XLU)","description":"Natural Language Processing systems are heavily dependent on the availability of annotated data to train practical models. Primarily, models are trained on English datasets. In recent times, significant advances have been made in multilingual understanding due to the steeply increasing necessity of working in different languages. One of the points that stands out is that since there are now so many pre-trained multilingual models, we can utilize them for cross-lingual understanding tasks. Using cross-lingual understanding and Natural Language Inference, it is possible to train models whose applications extend beyond the training language. We can leverage the power of machine translation to skip the tiresome part of translating datasets from one language to another. In this work, we focus on improving the original XNLI dataset by re-translating the MNLI dataset in all of the 14 different languages present in XNLI, including the test and dev sets of XNLI using Google Translate. We also perform experiments by training models in all 15 languages and analyzing their performance on the task of natural language inference. We then expand our boundary to investigate if we could improve performance in low-resource languages such as Swahili and Urdu by training models in languages other than English.","link":"http://arxiv.org/abs/2301.06527v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"XNLI 2.0: Improving XNLI dataset and performance on Cross Lingual Understanding (XLU) Natural Language Processing systems are heavily dependent on the availability of annotated data to train practical models. Primarily, models are trained on English datasets. In recent times, significant advances have been made in multilingual understanding due to the steeply increasing necessity of working in different languages. One of the points that stands out is that since there are now so many pre-trained multilingual models, we can utilize them for cross-lingual understanding tasks. Using cross-lingual understanding and Natural Language Inference, it is possible to train models whose applications extend beyond the training language. We can leverage the power of machine translation to skip the tiresome part of translating datasets from one language to another. In this work, we focus on improving the original XNLI dataset by re-translating the MNLI dataset in all of the 14 different languages present in XNLI, including the test and dev sets of XNLI using Google Translate. We also perform experiments by training models in all 15 languages and analyzing their performance on the task of natural language inference. We then expand our boundary to investigate if we could improve performance in low-resource languages such as Swahili and Urdu by training models in languages other than English.","classes":{"dataset":0.9519851804}}
{"title":"OLKAVS: An Open Large-Scale Korean Audio-Visual Speech Dataset","description":"Inspired by humans comprehending speech in a multi-modal manner, various audio-visual datasets have been constructed. However, most existing datasets focus on English, induce dependencies with various prediction models during dataset preparation, and have only a small number of multi-view videos. To mitigate the limitations, we recently developed the Open Large-scale Korean Audio-Visual Speech (OLKAVS) dataset, which is the largest among publicly available audio-visual speech datasets. The dataset contains 1,150 hours of transcribed audio from 1,107 Korean speakers in a studio setup with nine different viewpoints and various noise situations. We also provide the pre-trained baseline models for two tasks, audio-visual speech recognition and lip reading. We conducted experiments based on the models to verify the effectiveness of multi-modal and multi-view training over uni-modal and frontal-view-only training. We expect the OLKAVS dataset to facilitate multi-modal research in broader areas such as Korean speech recognition, speaker recognition, pronunciation level classification, and mouth motion analysis.","link":"http://arxiv.org/abs/2301.06375v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"OLKAVS: An Open Large-Scale Korean Audio-Visual Speech Dataset Inspired by humans comprehending speech in a multi-modal manner, various audio-visual datasets have been constructed. However, most existing datasets focus on English, induce dependencies with various prediction models during dataset preparation, and have only a small number of multi-view videos. To mitigate the limitations, we recently developed the Open Large-scale Korean Audio-Visual Speech (OLKAVS) dataset, which is the largest among publicly available audio-visual speech datasets. The dataset contains 1,150 hours of transcribed audio from 1,107 Korean speakers in a studio setup with nine different viewpoints and various noise situations. We also provide the pre-trained baseline models for two tasks, audio-visual speech recognition and lip reading. We conducted experiments based on the models to verify the effectiveness of multi-modal and multi-view training over uni-modal and frontal-view-only training. We expect the OLKAVS dataset to facilitate multi-modal research in broader areas such as Korean speech recognition, speaker recognition, pronunciation level classification, and mouth motion analysis.","classes":{"dataset":0.0545328744}}
{"title":"LYSTO: The Lymphocyte Assessment Hackathon and Benchmark Dataset","description":"We introduce LYSTO, the Lymphocyte Assessment Hackathon, which was held in conjunction with the MICCAI 2019 Conference in Shenzen (China). The competition required participants to automatically assess the number of lymphocytes, in particular T-cells, in histopathological images of colon, breast, and prostate cancer stained with CD3 and CD8 immunohistochemistry. Differently from other challenges setup in medical image analysis, LYSTO participants were solely given a few hours to address this problem. In this paper, we describe the goal and the multi-phase organization of the hackathon; we describe the proposed methods and the on-site results. Additionally, we present post-competition results where we show how the presented methods perform on an independent set of lung cancer slides, which was not part of the initial competition, as well as a comparison on lymphocyte assessment between presented methods and a panel of pathologists. We show that some of the participants were capable to achieve pathologist-level performance at lymphocyte assessment. After the hackathon, LYSTO was left as a lightweight plug-and-play benchmark dataset on grand-challenge website, together with an automatic evaluation platform. LYSTO has supported a number of research in lymphocyte assessment in oncology. LYSTO will be a long-lasting educational challenge for deep learning and digital pathology, it is available at https://lysto.grand-challenge.org/.","link":"http://arxiv.org/abs/2301.06304v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"LYSTO: The Lymphocyte Assessment Hackathon and Benchmark Dataset We introduce LYSTO, the Lymphocyte Assessment Hackathon, which was held in conjunction with the MICCAI 2019 Conference in Shenzen (China). The competition required participants to automatically assess the number of lymphocytes, in particular T-cells, in histopathological images of colon, breast, and prostate cancer stained with CD3 and CD8 immunohistochemistry. Differently from other challenges setup in medical image analysis, LYSTO participants were solely given a few hours to address this problem. In this paper, we describe the goal and the multi-phase organization of the hackathon; we describe the proposed methods and the on-site results. Additionally, we present post-competition results where we show how the presented methods perform on an independent set of lung cancer slides, which was not part of the initial competition, as well as a comparison on lymphocyte assessment between presented methods and a panel of pathologists. We show that some of the participants were capable to achieve pathologist-level performance at lymphocyte assessment. After the hackathon, LYSTO was left as a lightweight plug-and-play benchmark dataset on grand-challenge website, together with an automatic evaluation platform. LYSTO has supported a number of research in lymphocyte assessment in oncology. LYSTO will be a long-lasting educational challenge for deep learning and digital pathology, it is available at https://lysto.grand-challenge.org/.","classes":{"dataset":0.9435684085}}
{"title":"Collaborative Perception in Autonomous Driving: Methods, Datasets and Challenges","description":"Collaborative perception is essential to address occlusion and sensor failure issues in autonomous driving. In recent years, deep learning on collaborative perception has become even thriving, with numerous methods have been proposed. Although some works have reviewed and analyzed the basic architecture and key components in this field, there is still a lack of reviews on systematical collaboration modules in perception networks and large-scale collaborative perception datasets. The primary goal of this work is to address the abovementioned issues and provide a comprehensive review of recent achievements in this field. First, we introduce fundamental technologies and collaboration schemes. Following that, we provide an overview of practical collaborative perception methods and systematically summarize the collaboration modules in networks to improve collaboration efficiency and performance while also ensuring collaboration robustness and safety. Then, we present large-scale public datasets and summarize quantitative results on these benchmarks. Finally, we discuss the remaining challenges and promising future research directions.","link":"http://arxiv.org/abs/2301.06262v1","created":"2023-01-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Collaborative Perception in Autonomous Driving: Methods, Datasets and Challenges Collaborative perception is essential to address occlusion and sensor failure issues in autonomous driving. In recent years, deep learning on collaborative perception has become even thriving, with numerous methods have been proposed. Although some works have reviewed and analyzed the basic architecture and key components in this field, there is still a lack of reviews on systematical collaboration modules in perception networks and large-scale collaborative perception datasets. The primary goal of this work is to address the abovementioned issues and provide a comprehensive review of recent achievements in this field. First, we introduce fundamental technologies and collaboration schemes. Following that, we provide an overview of practical collaborative perception methods and systematically summarize the collaboration modules in networks to improve collaboration efficiency and performance while also ensuring collaboration robustness and safety. Then, we present large-scale public datasets and summarize quantitative results on these benchmarks. Finally, we discuss the remaining challenges and promising future research directions.","classes":{"dataset":0.0233828016}}
{"title":"TextileNet: A Material Taxonomy-based Fashion Textile Dataset","description":"The rise of Machine Learning (ML) is gradually digitalizing and reshaping the fashion industry. Recent years have witnessed a number of fashion AI applications, for example, virtual try-ons. Textile material identification and categorization play a crucial role in the fashion textile sector, including fashion design, retails, and recycling. At the same time, Net Zero is a global goal and the fashion industry is undergoing a significant change so that textile materials can be reused, repaired and recycled in a sustainable manner. There is still a challenge in identifying textile materials automatically for garments, as we lack a low-cost and effective technique for identifying them. In light of this, we build the first fashion textile dataset, TextileNet, based on textile material taxonomies - a fibre taxonomy and a fabric taxonomy generated in collaboration with material scientists. TextileNet can be used to train and evaluate the state-of-the-art Deep Learning models for textile materials. We hope to standardize textile related datasets through the use of taxonomies. TextileNet contains 33 fibres labels and 27 fabrics labels, and has in total 760,949 images. We use standard Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) to establish baselines for this dataset. Future applications for this dataset range from textile classification to optimization of the textile supply chain and interactive design for consumers. We envision that this can contribute to the development of a new AI-based fashion platform.","link":"http://arxiv.org/abs/2301.06160v1","created":"2023-01-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"TextileNet: A Material Taxonomy-based Fashion Textile Dataset The rise of Machine Learning (ML) is gradually digitalizing and reshaping the fashion industry. Recent years have witnessed a number of fashion AI applications, for example, virtual try-ons. Textile material identification and categorization play a crucial role in the fashion textile sector, including fashion design, retails, and recycling. At the same time, Net Zero is a global goal and the fashion industry is undergoing a significant change so that textile materials can be reused, repaired and recycled in a sustainable manner. There is still a challenge in identifying textile materials automatically for garments, as we lack a low-cost and effective technique for identifying them. In light of this, we build the first fashion textile dataset, TextileNet, based on textile material taxonomies - a fibre taxonomy and a fabric taxonomy generated in collaboration with material scientists. TextileNet can be used to train and evaluate the state-of-the-art Deep Learning models for textile materials. We hope to standardize textile related datasets through the use of taxonomies. TextileNet contains 33 fibres labels and 27 fabrics labels, and has in total 760,949 images. We use standard Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) to establish baselines for this dataset. Future applications for this dataset range from textile classification to optimization of the textile supply chain and interactive design for consumers. We envision that this can contribute to the development of a new AI-based fashion platform.","classes":{"dataset":0.0086623076}}
{"title":"$\\texttt{tasksource}$: Structured Dataset Preprocessing Annotations for Frictionless Extreme Multi-Task Learning and Evaluation","description":"The HuggingFace Datasets Hub hosts thousands of datasets. This provides exciting opportunities for language model training and evaluation. However, the datasets for a given type of task are stored with different schemas, and harmonization is harder than it seems (https://xkcd.com/927/). Multi-task training or evaluation requires manual work to fit data into task templates. Various initiatives independently address this problem by releasing the harmonized datasets or harmonization codes to preprocess datasets to the same format. We identify patterns across previous preprocessings, e.g. mapping of column names, and extraction of a specific sub-field from structured data in a column, and propose a structured annotation framework that makes our annotations fully exposed and not buried in unstructured code. We release a dataset annotation framework and dataset annotations for more than 400 English tasks (https://github.com/sileod/tasksource). These annotations provide metadata, like the name of the columns that should be used as input or labels for all datasets, and can save time for future dataset preprocessings, even if they do not use our framework. We fine-tune a multi-task text encoder on all tasksource tasks, outperforming every publicly available text encoder of comparable size on an external evaluation https://hf.co/sileod/deberta-v3-base-tasksource-nli.","link":"http://arxiv.org/abs/2301.05948v1","created":"2023-01-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"$\\texttt{tasksource}$: Structured Dataset Preprocessing Annotations for Frictionless Extreme Multi-Task Learning and Evaluation The HuggingFace Datasets Hub hosts thousands of datasets. This provides exciting opportunities for language model training and evaluation. However, the datasets for a given type of task are stored with different schemas, and harmonization is harder than it seems (https://xkcd.com/927/). Multi-task training or evaluation requires manual work to fit data into task templates. Various initiatives independently address this problem by releasing the harmonized datasets or harmonization codes to preprocess datasets to the same format. We identify patterns across previous preprocessings, e.g. mapping of column names, and extraction of a specific sub-field from structured data in a column, and propose a structured annotation framework that makes our annotations fully exposed and not buried in unstructured code. We release a dataset annotation framework and dataset annotations for more than 400 English tasks (https://github.com/sileod/tasksource). These annotations provide metadata, like the name of the columns that should be used as input or labels for all datasets, and can save time for future dataset preprocessings, even if they do not use our framework. We fine-tune a multi-task text encoder on all tasksource tasks, outperforming every publicly available text encoder of comparable size on an external evaluation https://hf.co/sileod/deberta-v3-base-tasksource-nli.","classes":{"dataset":0.4209194481}}
{"title":"TikTalk: A Multi-Modal Dialogue Dataset for Real-World Chitchat","description":"We present a novel multi-modal chitchat dialogue dataset-TikTalk aimed at facilitating the research of intelligent chatbots. It consists of the videos and corresponding dialogues users generate on video social applications. In contrast to existing multi-modal dialogue datasets, we construct dialogue corpora based on video comment-reply pairs, which is more similar to chitchat in real-world dialogue scenarios. Our dialogue context includes three modalities: text, vision, and audio. Compared with previous image-based dialogue datasets, the richer sources of context in TikTalk lead to a greater diversity of conversations. TikTalk contains over 38K videos and 367K dialogues. Data analysis shows that responses in TikTalk are in correlation with various contexts and external knowledge. It poses a great challenge for the deep understanding of multi-modal information and the generation of responses. We evaluate several baselines on three types of automatic metrics and conduct case studies. Experimental results demonstrate that there is still a large room for future improvement on TikTalk. Our dataset is available at \\url{https://github.com/RUC-AIMind/TikTalk}.","link":"http://arxiv.org/abs/2301.05880v1","created":"2023-01-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"TikTalk: A Multi-Modal Dialogue Dataset for Real-World Chitchat We present a novel multi-modal chitchat dialogue dataset-TikTalk aimed at facilitating the research of intelligent chatbots. It consists of the videos and corresponding dialogues users generate on video social applications. In contrast to existing multi-modal dialogue datasets, we construct dialogue corpora based on video comment-reply pairs, which is more similar to chitchat in real-world dialogue scenarios. Our dialogue context includes three modalities: text, vision, and audio. Compared with previous image-based dialogue datasets, the richer sources of context in TikTalk lead to a greater diversity of conversations. TikTalk contains over 38K videos and 367K dialogues. Data analysis shows that responses in TikTalk are in correlation with various contexts and external knowledge. It poses a great challenge for the deep understanding of multi-modal information and the generation of responses. We evaluate several baselines on three types of automatic metrics and conduct case studies. Experimental results demonstrate that there is still a large room for future improvement on TikTalk. Our dataset is available at \\url{https://github.com/RUC-AIMind/TikTalk}.","classes":{"dataset":0.0401867442}}
{"title":"RxRx1: A Dataset for Evaluating Experimental Batch Correction Methods","description":"High-throughput screening techniques are commonly used to obtain large quantities of data in many fields of biology. It is well known that artifacts arising from variability in the technical execution of different experimental batches within such screens confound these observations and can lead to invalid biological conclusions. It is therefore necessary to account for these batch effects when analyzing outcomes. In this paper we describe RxRx1, a biological dataset designed specifically for the systematic study of batch effect correction methods. The dataset consists of 125,510 high-resolution fluorescence microscopy images of human cells under 1,138 genetic perturbations in 51 experimental batches across 4 cell types. Visual inspection of the images alone clearly demonstrates significant batch effects. We propose a classification task designed to evaluate the effectiveness of experimental batch correction methods on these images and examine the performance of a number of correction methods on this task. Our goal in releasing RxRx1 is to encourage the development of effective experimental batch correction methods that generalize well to unseen experimental batches. The dataset can be downloaded at https://rxrx.ai.","link":"http://arxiv.org/abs/2301.05768v1","created":"2023-01-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"RxRx1: A Dataset for Evaluating Experimental Batch Correction Methods High-throughput screening techniques are commonly used to obtain large quantities of data in many fields of biology. It is well known that artifacts arising from variability in the technical execution of different experimental batches within such screens confound these observations and can lead to invalid biological conclusions. It is therefore necessary to account for these batch effects when analyzing outcomes. In this paper we describe RxRx1, a biological dataset designed specifically for the systematic study of batch effect correction methods. The dataset consists of 125,510 high-resolution fluorescence microscopy images of human cells under 1,138 genetic perturbations in 51 experimental batches across 4 cell types. Visual inspection of the images alone clearly demonstrates significant batch effects. We propose a classification task designed to evaluate the effectiveness of experimental batch correction methods on these images and examine the performance of a number of correction methods on this task. Our goal in releasing RxRx1 is to encourage the development of effective experimental batch correction methods that generalize well to unseen experimental batches. The dataset can be downloaded at https://rxrx.ai.","classes":{"dataset":0.9691508412}}
{"title":"Data Quality for Software Vulnerability Datasets","description":"The use of learning-based techniques to achieve automated software vulnerability detection has been of longstanding interest within the software security domain. These data-driven solutions are enabled by large software vulnerability datasets used for training and benchmarking. However, we observe that the quality of the data powering these solutions is currently ill-considered, hindering the reliability and value of produced outcomes. Whilst awareness of software vulnerability data preparation challenges is growing, there has been little investigation into the potential negative impacts of software vulnerability data quality. For instance, we lack confirmation that vulnerability labels are correct or consistent. Our study seeks to address such shortcomings by inspecting five inherent data quality attributes for four state-of-the-art software vulnerability datasets and the subsequent impacts that issues can have on software vulnerability prediction models. Surprisingly, we found that all the analyzed datasets exhibit some data quality problems. In particular, we found 20-71% of vulnerability labels to be inaccurate in real-world datasets, and 17-99% of data points were duplicated. We observed that these issues could cause significant impacts on downstream models, either preventing effective model training or inflating benchmark performance. We advocate for the need to overcome such challenges. Our findings will enable better consideration and assessment of software vulnerability data quality in the future.","link":"http://arxiv.org/abs/2301.05456v1","created":"2023-01-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Data Quality for Software Vulnerability Datasets The use of learning-based techniques to achieve automated software vulnerability detection has been of longstanding interest within the software security domain. These data-driven solutions are enabled by large software vulnerability datasets used for training and benchmarking. However, we observe that the quality of the data powering these solutions is currently ill-considered, hindering the reliability and value of produced outcomes. Whilst awareness of software vulnerability data preparation challenges is growing, there has been little investigation into the potential negative impacts of software vulnerability data quality. For instance, we lack confirmation that vulnerability labels are correct or consistent. Our study seeks to address such shortcomings by inspecting five inherent data quality attributes for four state-of-the-art software vulnerability datasets and the subsequent impacts that issues can have on software vulnerability prediction models. Surprisingly, we found that all the analyzed datasets exhibit some data quality problems. In particular, we found 20-71% of vulnerability labels to be inaccurate in real-world datasets, and 17-99% of data points were duplicated. We observed that these issues could cause significant impacts on downstream models, either preventing effective model training or inflating benchmark performance. We advocate for the need to overcome such challenges. Our findings will enable better consideration and assessment of software vulnerability data quality in the future.","classes":{"dataset":0.3355031908}}
{"title":"ITA-ELECTION-2022: A multi-platform dataset of social media conversations around the 2022 Italian general election","description":"Online social media play a major role in shaping public discourse and opinion, especially during political events. We present the first public multi-platform dataset of Italian-language political conversations, focused on the 2022 Italian general election taking place on September 25th. Leveraging public APIs and a keyword-based search, we collected millions of posts published by users, pages and groups on Facebook, Instagram and Twitter, along with metadata of TikTok and YouTube videos shared on these platforms, over a period of four months. We augmented the dataset with a collection of political ads sponsored on Meta platforms, and a list of social media handles associated with political representatives. Our data resource will allow researchers and academics to further our understanding of the role of social media in the democratic process.","link":"http://arxiv.org/abs/2301.05119v1","created":"2023-01-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"ITA-ELECTION-2022: A multi-platform dataset of social media conversations around the 2022 Italian general election Online social media play a major role in shaping public discourse and opinion, especially during political events. We present the first public multi-platform dataset of Italian-language political conversations, focused on the 2022 Italian general election taking place on September 25th. Leveraging public APIs and a keyword-based search, we collected millions of posts published by users, pages and groups on Facebook, Instagram and Twitter, along with metadata of TikTok and YouTube videos shared on these platforms, over a period of four months. We augmented the dataset with a collection of political ads sponsored on Meta platforms, and a list of social media handles associated with political representatives. Our data resource will allow researchers and academics to further our understanding of the role of social media in the democratic process.","classes":{"dataset":0.245308131}}
{"title":"SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images","description":"Visual question answering on document images that contain textual, visual, and layout information, called document VQA, has received much attention recently. Although many datasets have been proposed for developing document VQA systems, most of the existing datasets focus on understanding the content relationships within a single image and not across multiple images. In this study, we propose a new multi-image document VQA dataset, SlideVQA, containing 2.6k+ slide decks composed of 52k+ slide images and 14.5k questions about a slide deck. SlideVQA requires complex reasoning, including single-hop, multi-hop, and numerical reasoning, and also provides annotated arithmetic expressions of numerical answers for enhancing the ability of numerical reasoning. Moreover, we developed a new end-to-end document VQA model that treats evidence selection and question answering in a unified sequence-to-sequence format. Experiments on SlideVQA show that our model outperformed existing state-of-the-art QA models, but that it still has a large gap behind human performance. We believe that our dataset will facilitate research on document VQA.","link":"http://arxiv.org/abs/2301.04883v1","created":"2023-01-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images Visual question answering on document images that contain textual, visual, and layout information, called document VQA, has received much attention recently. Although many datasets have been proposed for developing document VQA systems, most of the existing datasets focus on understanding the content relationships within a single image and not across multiple images. In this study, we propose a new multi-image document VQA dataset, SlideVQA, containing 2.6k+ slide decks composed of 52k+ slide images and 14.5k questions about a slide deck. SlideVQA requires complex reasoning, including single-hop, multi-hop, and numerical reasoning, and also provides annotated arithmetic expressions of numerical answers for enhancing the ability of numerical reasoning. Moreover, we developed a new end-to-end document VQA model that treats evidence selection and question answering in a unified sequence-to-sequence format. Experiments on SlideVQA show that our model outperformed existing state-of-the-art QA models, but that it still has a large gap behind human performance. We believe that our dataset will facilitate research on document VQA.","classes":{"dataset":0.9771953225}}
{"title":"Dynamic Data Assimilation of MPAS-O and the Global Drifter Dataset","description":"In this study, we propose a new method for combining in situ buoy measurements with Earth system models (ESMs) to improve the accuracy of temperature predictions in the ocean. The technique utilizes the dynamics and modes identified in ESMs to improve the accuracy of buoy measurements while still preserving features such as seasonality. Using this technique, errors in localized temperature predictions made by the MPAS-O model can be corrected. We demonstrate that our approach improves accuracy compared to other interpolation and data assimilation methods. We apply our method to assimilate the Model for Prediction Across Scales Ocean component (MPAS-O) with the Global Drifter Program's in-situ ocean buoy dataset.","link":"http://arxiv.org/abs/2301.05551v1","created":"2023-01-11","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Dynamic Data Assimilation of MPAS-O and the Global Drifter Dataset In this study, we propose a new method for combining in situ buoy measurements with Earth system models (ESMs) to improve the accuracy of temperature predictions in the ocean. The technique utilizes the dynamics and modes identified in ESMs to improve the accuracy of buoy measurements while still preserving features such as seasonality. Using this technique, errors in localized temperature predictions made by the MPAS-O model can be corrected. We demonstrate that our approach improves accuracy compared to other interpolation and data assimilation methods. We apply our method to assimilate the Model for Prediction Across Scales Ocean component (MPAS-O) with the Global Drifter Program's in-situ ocean buoy dataset.","classes":{"dataset":0.0298652854}}
{"title":"MotorFactory: A Blender Add-on for Large Dataset Generation of Small Electric Motors","description":"To enable automatic disassembly of different product types with uncertain conditions and degrees of wear in remanufacturing, agile production systems that can adapt dynamically to changing requirements are needed. Machine learning algorithms can be employed due to their generalization capabilities of learning from various types and variants of products. However, in reality, datasets with a diversity of samples that can be used to train models are difficult to obtain in the initial period. This may cause bad performances when the system tries to adapt to new unseen input data in the future. In order to generate large datasets for different learning purposes, in our project, we present a Blender add-on named MotorFactory to generate customized mesh models of various motor instances. MotorFactory allows to create mesh models which, complemented with additional add-ons, can be further used to create synthetic RGB images, depth images, normal images, segmentation ground truth masks, and 3D point cloud datasets with point-wise semantic labels. The created synthetic datasets may be used for various tasks including motor type classification, object detection for decentralized material transfer tasks, part segmentation for disassembly and handling tasks, or even reinforcement learning-based robotics control or view-planning.","link":"http://arxiv.org/abs/2301.05028v1","created":"2023-01-11","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"MotorFactory: A Blender Add-on for Large Dataset Generation of Small Electric Motors To enable automatic disassembly of different product types with uncertain conditions and degrees of wear in remanufacturing, agile production systems that can adapt dynamically to changing requirements are needed. Machine learning algorithms can be employed due to their generalization capabilities of learning from various types and variants of products. However, in reality, datasets with a diversity of samples that can be used to train models are difficult to obtain in the initial period. This may cause bad performances when the system tries to adapt to new unseen input data in the future. In order to generate large datasets for different learning purposes, in our project, we present a Blender add-on named MotorFactory to generate customized mesh models of various motor instances. MotorFactory allows to create mesh models which, complemented with additional add-ons, can be further used to create synthetic RGB images, depth images, normal images, segmentation ground truth masks, and 3D point cloud datasets with point-wise semantic labels. The created synthetic datasets may be used for various tasks including motor type classification, object detection for decentralized material transfer tasks, part segmentation for disassembly and handling tasks, or even reinforcement learning-based robotics control or view-planning.","classes":{"dataset":0.0306166448}}
{"title":"Order-Preserving Database Encryption with Secret Sharing","description":"The order-preserving encryption (OPE) problem was initially formulated by the database community in 2004 soon after the paradigm database-as-a-service (DaaS) was coined in 2002. Over the past two decades, OPE has drawn tremendous research interest from communities of databases, cryptography, and security; we have witnessed significant advances in OPE schemes both theoretically and systematically. All existing OPE schemes assume that the outsourced database is modeled as a single semi-honest adversary who should learn nothing more than the order information of plaintext messages up to a negligible probability. This paper addresses the OPE problem from a new perspective: instead of modeling the outsourced database as a single semi-honest adversary, we assume the outsourced database \\textit{service} compromises a cluster of non-colluding servers, which is a practical assumption as all major cloud vendors support multiple database instances deployed to exclusive sub-networks or even to distinct data centers. This assumption allows us to design a new stateless OPE protocol, namely order-preserving database encryption with secret sharing (ODES), by employing secret-sharing schemes among those presumably non-colluding servers. We will demonstrate that ODES guarantees the latest security level, namely IND-FAOCPA, and outperforms the state-of-the-art scheme by orders of magnitude.","link":"http://arxiv.org/abs/2301.04370v1","created":"2023-01-11","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Order-Preserving Database Encryption with Secret Sharing The order-preserving encryption (OPE) problem was initially formulated by the database community in 2004 soon after the paradigm database-as-a-service (DaaS) was coined in 2002. Over the past two decades, OPE has drawn tremendous research interest from communities of databases, cryptography, and security; we have witnessed significant advances in OPE schemes both theoretically and systematically. All existing OPE schemes assume that the outsourced database is modeled as a single semi-honest adversary who should learn nothing more than the order information of plaintext messages up to a negligible probability. This paper addresses the OPE problem from a new perspective: instead of modeling the outsourced database as a single semi-honest adversary, we assume the outsourced database \\textit{service} compromises a cluster of non-colluding servers, which is a practical assumption as all major cloud vendors support multiple database instances deployed to exclusive sub-networks or even to distinct data centers. This assumption allows us to design a new stateless OPE protocol, namely order-preserving database encryption with secret sharing (ODES), by employing secret-sharing schemes among those presumably non-colluding servers. We will demonstrate that ODES guarantees the latest security level, namely IND-FAOCPA, and outperforms the state-of-the-art scheme by orders of magnitude.","classes":{"dataset":0.923738122}}
{"title":"Analysis of Arrhythmia Classification on ECG Dataset","description":"The heart is one of the most vital organs in the human body. It supplies blood and nutrients in other parts of the body. Therefore, maintaining a healthy heart is essential. As a heart disorder, arrhythmia is a condition in which the heart's pumping mechanism becomes aberrant. The Electrocardiogram is used to analyze the arrhythmia problem from the ECG signals because of its fewer difficulties and cheapness. The heart peaks shown in the ECG graph are used to detect heart diseases, and the R peak is used to analyze arrhythmia disease. Arrhythmia is grouped into two groups - Tachycardia and Bradycardia for detection. In this paper, we discussed many different techniques such as Deep CNNs, LSTM, SVM, NN classifier, Wavelet, TQWT, etc., that have been used for detecting arrhythmia using various datasets throughout the previous decade. This work shows the analysis of some arrhythmia classification on the ECG dataset. Here, Data preprocessing, feature extraction, classification processes were applied on most research work and achieved better performance for classifying ECG signals to detect arrhythmia. Automatic arrhythmia detection can help cardiologists make the right decisions immediately to save human life. In addition, this research presents various previous research limitations with some challenges in detecting arrhythmia that will help in future research.","link":"http://arxiv.org/abs/2301.10174v1","created":"2023-01-10","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Analysis of Arrhythmia Classification on ECG Dataset The heart is one of the most vital organs in the human body. It supplies blood and nutrients in other parts of the body. Therefore, maintaining a healthy heart is essential. As a heart disorder, arrhythmia is a condition in which the heart's pumping mechanism becomes aberrant. The Electrocardiogram is used to analyze the arrhythmia problem from the ECG signals because of its fewer difficulties and cheapness. The heart peaks shown in the ECG graph are used to detect heart diseases, and the R peak is used to analyze arrhythmia disease. Arrhythmia is grouped into two groups - Tachycardia and Bradycardia for detection. In this paper, we discussed many different techniques such as Deep CNNs, LSTM, SVM, NN classifier, Wavelet, TQWT, etc., that have been used for detecting arrhythmia using various datasets throughout the previous decade. This work shows the analysis of some arrhythmia classification on the ECG dataset. Here, Data preprocessing, feature extraction, classification processes were applied on most research work and achieved better performance for classifying ECG signals to detect arrhythmia. Automatic arrhythmia detection can help cardiologists make the right decisions immediately to save human life. In addition, this research presents various previous research limitations with some challenges in detecting arrhythmia that will help in future research.","classes":{"dataset":0.9574384093}}
{"title":"A Dietary Nutrition-aided Healthcare Platform via Effective Food Recognition on a Localized Singaporean Food Dataset","description":"Localized food datasets have profound meaning in revealing a country's special cuisines to explore people's dietary behaviors, which will shed light on their health conditions and disease development. In this paper, revolving around the demand for accurate food recognition in Singapore, we develop the FoodSG platform to incubate diverse healthcare-oriented applications as a service in Singapore, taking into account their shared requirements. We release a localized Singaporean food dataset FoodSG-233 with a systematic cleaning and curation pipeline for promoting future data management research in food computing. To overcome the hurdle in recognition performance brought by Singaporean multifarious food dishes, we propose to integrate supervised contrastive learning into our food recognition model FoodSG-SCL for the intrinsic capability to mine hard positive/negative samples and therefore boost the accuracy. Through a comprehensive evaluation, we share the insightful experience with practitioners in the data management community regarding food-related data-intensive healthcare applications.   The FoodSG-233 dataset can be accessed via: https://foodlg.comp.nus.edu.sg/.","link":"http://arxiv.org/abs/2301.03829v1","created":"2023-01-10","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A Dietary Nutrition-aided Healthcare Platform via Effective Food Recognition on a Localized Singaporean Food Dataset Localized food datasets have profound meaning in revealing a country's special cuisines to explore people's dietary behaviors, which will shed light on their health conditions and disease development. In this paper, revolving around the demand for accurate food recognition in Singapore, we develop the FoodSG platform to incubate diverse healthcare-oriented applications as a service in Singapore, taking into account their shared requirements. We release a localized Singaporean food dataset FoodSG-233 with a systematic cleaning and curation pipeline for promoting future data management research in food computing. To overcome the hurdle in recognition performance brought by Singaporean multifarious food dishes, we propose to integrate supervised contrastive learning into our food recognition model FoodSG-SCL for the intrinsic capability to mine hard positive/negative samples and therefore boost the accuracy. Through a comprehensive evaluation, we share the insightful experience with practitioners in the data management community regarding food-related data-intensive healthcare applications.   The FoodSG-233 dataset can be accessed via: https://foodlg.comp.nus.edu.sg/.","classes":{"dataset":0.9759280682}}
{"title":"Safer Together: Machine Learning Models Trained on Shared Accident Datasets Predict Construction Injuries Better than Company-Specific Models","description":"In this study, we capitalized on a collective dataset repository of 57k accidents from 9 companies belonging to 3 domains and tested whether models trained on multiple datasets (generic models) predicted safety outcomes better than the company-specific models. We experimented with full generic models (trained on all data), per-domain generic models (construction, electric T&D, oil & gas), and with ensembles of generic and specific models. Results are very positive, with generic models outperforming the company-specific models in most cases while also generating finer-grained, hence more useful, forecasts. Successful generic models remove the needs for training company-specific models, saving a lot of time and resources, and give small companies, whose accident datasets are too limited to train their own models, access to safety outcome predictions. It may still however be advantageous to train specific models to get an extra boost in performance through ensembling with the generic models. Overall, by learning lessons from a pool of datasets whose accumulated experience far exceeds that of any single company, and making these lessons easily accessible in the form of simple forecasts, generic models tackle the holy grail of safety cross-organizational learning and dissemination in the construction industry.","link":"http://arxiv.org/abs/2301.03567v1","created":"2023-01-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Safer Together: Machine Learning Models Trained on Shared Accident Datasets Predict Construction Injuries Better than Company-Specific Models In this study, we capitalized on a collective dataset repository of 57k accidents from 9 companies belonging to 3 domains and tested whether models trained on multiple datasets (generic models) predicted safety outcomes better than the company-specific models. We experimented with full generic models (trained on all data), per-domain generic models (construction, electric T&D, oil & gas), and with ensembles of generic and specific models. Results are very positive, with generic models outperforming the company-specific models in most cases while also generating finer-grained, hence more useful, forecasts. Successful generic models remove the needs for training company-specific models, saving a lot of time and resources, and give small companies, whose accident datasets are too limited to train their own models, access to safety outcome predictions. It may still however be advantageous to train specific models to get an extra boost in performance through ensembling with the generic models. Overall, by learning lessons from a pool of datasets whose accumulated experience far exceeds that of any single company, and making these lessons easily accessible in the form of simple forecasts, generic models tackle the holy grail of safety cross-organizational learning and dissemination in the construction industry.","classes":{"dataset":0.5494478941}}
{"title":"EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset","description":"Visual object tracking is a key component to many egocentric vision problems. However, the full spectrum of challenges of egocentric tracking faced by an embodied AI is underrepresented in many existing datasets; these tend to focus on relatively short, third-person videos. Egocentric video has several distinguishing characteristics from those commonly found in past datasets: frequent large camera motions and hand interactions with objects commonly lead to occlusions or objects exiting the frame, and object appearance can change rapidly due to widely different points of view, scale, or object states. Embodied tracking is also naturally long-term, and being able to consistently (re-)associate objects to their appearances and disappearances over as long as a lifetime is critical. Previous datasets under-emphasize this re-detection problem, and their \"framed\" nature has led to adoption of various spatiotemporal priors that we find do not necessarily generalize to egocentric video. We thus introduce EgoTracks, a new dataset for long-term egocentric visual object tracking. Sourced from the Ego4D dataset, this new dataset presents a significant challenge to recent state-of-the-art single-object tracking models, which we find score poorly on traditional tracking metrics for our new dataset, compared to popular benchmarks. We further show improvements that can be made to a STARK tracker to significantly increase its performance on egocentric data, resulting in a baseline model we call EgoSTARK. We publicly release our annotations and benchmark, hoping our dataset leads to further advancements in tracking.","link":"http://arxiv.org/abs/2301.03213v2","created":"2023-01-09","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset Visual object tracking is a key component to many egocentric vision problems. However, the full spectrum of challenges of egocentric tracking faced by an embodied AI is underrepresented in many existing datasets; these tend to focus on relatively short, third-person videos. Egocentric video has several distinguishing characteristics from those commonly found in past datasets: frequent large camera motions and hand interactions with objects commonly lead to occlusions or objects exiting the frame, and object appearance can change rapidly due to widely different points of view, scale, or object states. Embodied tracking is also naturally long-term, and being able to consistently (re-)associate objects to their appearances and disappearances over as long as a lifetime is critical. Previous datasets under-emphasize this re-detection problem, and their \"framed\" nature has led to adoption of various spatiotemporal priors that we find do not necessarily generalize to egocentric video. We thus introduce EgoTracks, a new dataset for long-term egocentric visual object tracking. Sourced from the Ego4D dataset, this new dataset presents a significant challenge to recent state-of-the-art single-object tracking models, which we find score poorly on traditional tracking metrics for our new dataset, compared to popular benchmarks. We further show improvements that can be made to a STARK tracker to significantly increase its performance on egocentric data, resulting in a baseline model we call EgoSTARK. We publicly release our annotations and benchmark, hoping our dataset leads to further advancements in tracking.","classes":{"dataset":0.9808964729}}
{"title":"Predictions of photophysical properties of phosphorescent platinum(II) complexes based on ensemble machine learning approach","description":"Phosphorescent metal complexes have been under intense investigations as emissive dopants for energy efficient organic light emitting diodes (OLEDs). Among them, cyclometalated Pt(II) complexes are widespread triplet emitters with color-tunable emissions. To render their practical applications as OLED emitters, it is in great need to develop Pt(II) complexes with high radiative decay rate constant ($k_r$) and photoluminescence (PL) quantum yield. Thus, an efficient and accurate prediction tool is highly desirable. Here, we develop a general protocol for accurate predictions of emission wavelength, radiative decay rate constant, and PL quantum yield for phosphorescent Pt(II) emitters based on the combination of first-principles quantum mechanical method, machine learning (ML) and experimental calibration. A new dataset concerning phosphorescent Pt(II) emitters is constructed, with more than two hundred samples collected from the literature. Features containing pertinent electronic properties of the complexes are chosen. Our results demonstrate that ensemble learning models combined with stacking-based approaches exhibit the best performance, where the values of squared correlation coefficients ($R^2$), mean absolute error (MAE), and root mean square error (RMSE) are 0.96, 7.21 nm and 13.00 nm for emission wavelength prediction, and 0.81, 0.11 and 0.15 for PL quantum yield prediction. For radiative decay rate constant ($k_r$), the obtained value of $R^2$ is 0.67 while MAE and RMSE are 0.21 and 0.25 (both in log scale), respectively. The accuracy of the protocol is further confirmed using 24 recently reported Pt(II) complexes, which demonstrates its reliability for a broad palette of Pt(II) emitters.We expect this protocol will become a valuable tool, accelerating the rational design of novel OLED materials with desired properties.","link":"http://arxiv.org/abs/2301.05639v1","created":"2023-01-08","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Predictions of photophysical properties of phosphorescent platinum(II) complexes based on ensemble machine learning approach Phosphorescent metal complexes have been under intense investigations as emissive dopants for energy efficient organic light emitting diodes (OLEDs). Among them, cyclometalated Pt(II) complexes are widespread triplet emitters with color-tunable emissions. To render their practical applications as OLED emitters, it is in great need to develop Pt(II) complexes with high radiative decay rate constant ($k_r$) and photoluminescence (PL) quantum yield. Thus, an efficient and accurate prediction tool is highly desirable. Here, we develop a general protocol for accurate predictions of emission wavelength, radiative decay rate constant, and PL quantum yield for phosphorescent Pt(II) emitters based on the combination of first-principles quantum mechanical method, machine learning (ML) and experimental calibration. A new dataset concerning phosphorescent Pt(II) emitters is constructed, with more than two hundred samples collected from the literature. Features containing pertinent electronic properties of the complexes are chosen. Our results demonstrate that ensemble learning models combined with stacking-based approaches exhibit the best performance, where the values of squared correlation coefficients ($R^2$), mean absolute error (MAE), and root mean square error (RMSE) are 0.96, 7.21 nm and 13.00 nm for emission wavelength prediction, and 0.81, 0.11 and 0.15 for PL quantum yield prediction. For radiative decay rate constant ($k_r$), the obtained value of $R^2$ is 0.67 while MAE and RMSE are 0.21 and 0.25 (both in log scale), respectively. The accuracy of the protocol is further confirmed using 24 recently reported Pt(II) complexes, which demonstrates its reliability for a broad palette of Pt(II) emitters.We expect this protocol will become a valuable tool, accelerating the rational design of novel OLED materials with desired properties.","classes":{"dataset":0.0161678921}}
{"title":"Augmenting Ego-Vehicle for Traffic Near-Miss and Accident Classification Dataset using Manipulating Conditional Style Translation","description":"To develop the advanced self-driving systems, many researchers are focusing to alert all possible traffic risk cases from closed-circuit television (CCTV) and dashboard-mounted cameras. Most of these methods focused on identifying frame-by-frame in which an anomaly has occurred, but they are unrealized, which road traffic participant can cause ego-vehicle leading into collision because of available annotation dataset only to detect anomaly on traffic video. Near-miss is one type of accident and can be defined as a narrowly avoided accident. However, there is no difference between accident and near-miss at the time before the accident happened, so our contribution is to redefine the accident definition and re-annotate the accident inconsistency on DADA-2000 dataset together with near-miss. By extending the start and end time of accident duration, our annotation can precisely cover all ego-motions during an incident and consistently classify all possible traffic risk accidents including near-miss to give more critical information for real-world driving assistance systems. The proposed method integrates two different components: conditional style translation (CST) and separable 3-dimensional convolutional neural network (S3D). CST architecture is derived by unsupervised image-to-image translation networks (UNIT) used for augmenting the re-annotation DADA-2000 dataset to increase the number of traffic risk accident videos and to generalize the performance of video classification model on different types of conditions while S3D is useful for video classification to prove dataset re-annotation consistency. In evaluation, the proposed method achieved a significant improvement result by 10.25% positive margin from the baseline model for accuracy on cross-validation analysis.","link":"http://arxiv.org/abs/2301.02726v1","created":"2023-01-06","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Augmenting Ego-Vehicle for Traffic Near-Miss and Accident Classification Dataset using Manipulating Conditional Style Translation To develop the advanced self-driving systems, many researchers are focusing to alert all possible traffic risk cases from closed-circuit television (CCTV) and dashboard-mounted cameras. Most of these methods focused on identifying frame-by-frame in which an anomaly has occurred, but they are unrealized, which road traffic participant can cause ego-vehicle leading into collision because of available annotation dataset only to detect anomaly on traffic video. Near-miss is one type of accident and can be defined as a narrowly avoided accident. However, there is no difference between accident and near-miss at the time before the accident happened, so our contribution is to redefine the accident definition and re-annotate the accident inconsistency on DADA-2000 dataset together with near-miss. By extending the start and end time of accident duration, our annotation can precisely cover all ego-motions during an incident and consistently classify all possible traffic risk accidents including near-miss to give more critical information for real-world driving assistance systems. The proposed method integrates two different components: conditional style translation (CST) and separable 3-dimensional convolutional neural network (S3D). CST architecture is derived by unsupervised image-to-image translation networks (UNIT) used for augmenting the re-annotation DADA-2000 dataset to increase the number of traffic risk accident videos and to generalize the performance of video classification model on different types of conditions while S3D is useful for video classification to prove dataset re-annotation consistency. In evaluation, the proposed method achieved a significant improvement result by 10.25% positive margin from the baseline model for accuracy on cross-validation analysis.","classes":{"dataset":0.9475057125}}
{"title":"Deep-learning models in medical image analysis: Detection of esophagitis from the Kvasir Dataset","description":"Early detection of esophagitis is important because this condition can progress to cancer if left untreated. However, the accuracies of different deep learning models in detecting esophagitis have yet to be compared. Thus, this study aimed to compare the accuracies of convolutional neural network models (GoogLeNet, ResNet-50, MobileNet V2, and MobileNet V3) in detecting esophagitis from the open Kvasir dataset of endoscopic images. Results showed that among the models, GoogLeNet achieved the highest F1-scores. Based on the average of true positive rate, MobileNet V3 predicted esophagitis more confidently than the other models. The results obtained using the models were also compared with those obtained using SHapley Additive exPlanations and Gradient-weighted Class Activation Mapping.","link":"http://arxiv.org/abs/2301.02390v1","created":"2023-01-06","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Deep-learning models in medical image analysis: Detection of esophagitis from the Kvasir Dataset Early detection of esophagitis is important because this condition can progress to cancer if left untreated. However, the accuracies of different deep learning models in detecting esophagitis have yet to be compared. Thus, this study aimed to compare the accuracies of convolutional neural network models (GoogLeNet, ResNet-50, MobileNet V2, and MobileNet V3) in detecting esophagitis from the open Kvasir dataset of endoscopic images. Results showed that among the models, GoogLeNet achieved the highest F1-scores. Based on the average of true positive rate, MobileNet V3 predicted esophagitis more confidently than the other models. The results obtained using the models were also compared with those obtained using SHapley Additive exPlanations and Gradient-weighted Class Activation Mapping.","classes":{"dataset":0.0429639556}}
{"title":"Impact, Attention, Influence: Early Assessment of Autonomous Driving Datasets","description":"Autonomous Driving (AD), the area of robotics with the greatest potential impact on society, has gained a lot of momentum in the last decade. As a result of this, the number of datasets in AD has increased rapidly. Creators and users of datasets can benefit from a better understanding of developments in the field. While scientometric analysis has been conducted in other fields, it rarely revolves around datasets. Thus, the impact, attention, and influence of datasets on autonomous driving remains a rarely investigated field. In this work, we provide a scientometric analysis for over 200 datasets in AD. We perform a rigorous evaluation of relations between available metadata and citation counts based on linear regression. Subsequently, we propose an Influence Score to assess a dataset already early on without the need for a track-record of citations, which is only available with a certain delay.","link":"http://arxiv.org/abs/2301.02200v1","created":"2023-01-05","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Impact, Attention, Influence: Early Assessment of Autonomous Driving Datasets Autonomous Driving (AD), the area of robotics with the greatest potential impact on society, has gained a lot of momentum in the last decade. As a result of this, the number of datasets in AD has increased rapidly. Creators and users of datasets can benefit from a better understanding of developments in the field. While scientometric analysis has been conducted in other fields, it rarely revolves around datasets. Thus, the impact, attention, and influence of datasets on autonomous driving remains a rarely investigated field. In this work, we provide a scientometric analysis for over 200 datasets in AD. We perform a rigorous evaluation of relations between available metadata and citation counts based on linear regression. Subsequently, we propose an Influence Score to assess a dataset already early on without the need for a track-record of citations, which is only available with a certain delay.","classes":{"dataset":0.9666934609}}
{"title":"A Database of Modular Forms on Noncongruence Subgroups","description":"We present a database of several hundred modular forms up to and including weight six on noncongruence subgroups of index $\\leq 17$. In addition, our database contains expressions for the Belyi map for genus zero subgroups and equations of the corresponding elliptic curves for genus one subgroups and numerical approximations of noncongruence Eisenstein series to 1500 digits precision.","link":"http://arxiv.org/abs/2301.02135v1","created":"2023-01-05","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A Database of Modular Forms on Noncongruence Subgroups We present a database of several hundred modular forms up to and including weight six on noncongruence subgroups of index $\\leq 17$. In addition, our database contains expressions for the Belyi map for genus zero subgroups and equations of the corresponding elliptic curves for genus one subgroups and numerical approximations of noncongruence Eisenstein series to 1500 digits precision.","classes":{"dataset":0.9568195343}}
{"title":"MSCDA: Multi-level Semantic-guided Contrast Improves Unsupervised Domain Adaptation for Breast MRI Segmentation in Small Datasets","description":"Deep learning (DL) applied to breast tissue segmentation in magnetic resonance imaging (MRI) has received increased attention in the last decade, however, the domain shift which arises from different vendors, acquisition protocols, and biological heterogeneity, remains an important but challenging obstacle on the path towards clinical implementation. Recently, unsupervised domain adaptation (UDA) methods have attempted to mitigate this problem by incorporating self-training with contrastive learning. To better exploit the underlying semantic information of the image at different levels, we propose a Multi-level Semantic-guided Contrastive Domain Adaptation (MSCDA) framework to align the feature representation between domains. In particular, we extend the contrastive loss by incorporating pixel-to-pixel, pixel-to-centroid, and centroid-to-centroid contrasts to integrate semantic information of images. We utilize a category-wise cross-domain sampling strategy to sample anchors from target images and build a hybrid memory bank to store samples from source images. Two breast MRI datasets were retrospectively collected: The source dataset contains non-contrast MRI examinations from 11 healthy volunteers and the target dataset contains contrast-enhanced MRI examinations of 134 invasive breast cancer patients. We set up experiments from source T2W image to target dynamic contrast-enhanced (DCE)-T1W image (T2W-to-T1W) and from source T1W image to target T2W image (T1W-to-T2W). The proposed method achieved Dice similarity coefficient (DSC) of 89.2\\% and 84.0\\% in T2W-to-T1W and T1W-to-T2W, respectively, outperforming state-of-the-art methods. Notably, good performance is still achieved with a smaller source dataset, proving that our framework is label-efficient.","link":"http://arxiv.org/abs/2301.02554v1","created":"2023-01-04","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"MSCDA: Multi-level Semantic-guided Contrast Improves Unsupervised Domain Adaptation for Breast MRI Segmentation in Small Datasets Deep learning (DL) applied to breast tissue segmentation in magnetic resonance imaging (MRI) has received increased attention in the last decade, however, the domain shift which arises from different vendors, acquisition protocols, and biological heterogeneity, remains an important but challenging obstacle on the path towards clinical implementation. Recently, unsupervised domain adaptation (UDA) methods have attempted to mitigate this problem by incorporating self-training with contrastive learning. To better exploit the underlying semantic information of the image at different levels, we propose a Multi-level Semantic-guided Contrastive Domain Adaptation (MSCDA) framework to align the feature representation between domains. In particular, we extend the contrastive loss by incorporating pixel-to-pixel, pixel-to-centroid, and centroid-to-centroid contrasts to integrate semantic information of images. We utilize a category-wise cross-domain sampling strategy to sample anchors from target images and build a hybrid memory bank to store samples from source images. Two breast MRI datasets were retrospectively collected: The source dataset contains non-contrast MRI examinations from 11 healthy volunteers and the target dataset contains contrast-enhanced MRI examinations of 134 invasive breast cancer patients. We set up experiments from source T2W image to target dynamic contrast-enhanced (DCE)-T1W image (T2W-to-T1W) and from source T1W image to target T2W image (T1W-to-T2W). The proposed method achieved Dice similarity coefficient (DSC) of 89.2\\% and 84.0\\% in T2W-to-T1W and T1W-to-T2W, respectively, outperforming state-of-the-art methods. Notably, good performance is still achieved with a smaller source dataset, proving that our framework is label-efficient.","classes":{"dataset":0.9209913015}}
{"title":"Backdoor Attacks Against Dataset Distillation","description":"Dataset distillation has emerged as a prominent technique to improve data efficiency when training machine learning models. It encapsulates the knowledge from a large dataset into a smaller synthetic dataset. A model trained on this smaller distilled dataset can attain comparable performance to a model trained on the original training dataset. However, the existing dataset distillation techniques mainly aim at achieving the best trade-off between resource usage efficiency and model utility. The security risks stemming from them have not been explored. This study performs the first backdoor attack against the models trained on the data distilled by dataset distillation models in the image domain. Concretely, we inject triggers into the synthetic data during the distillation procedure rather than during the model training stage, where all previous attacks are performed. We propose two types of backdoor attacks, namely NAIVEATTACK and DOORPING. NAIVEATTACK simply adds triggers to the raw data at the initial distillation phase, while DOORPING iteratively updates the triggers during the entire distillation procedure. We conduct extensive evaluations on multiple datasets, architectures, and dataset distillation techniques. Empirical evaluation shows that NAIVEATTACK achieves decent attack success rate (ASR) scores in some cases, while DOORPING reaches higher ASR scores (close to 1.0) in all cases. Furthermore, we conduct a comprehensive ablation study to analyze the factors that may affect the attack performance. Finally, we evaluate multiple defense mechanisms against our backdoor attacks and show that our attacks can practically circumvent these defense mechanisms.","link":"http://arxiv.org/abs/2301.01197v1","created":"2023-01-03","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Backdoor Attacks Against Dataset Distillation Dataset distillation has emerged as a prominent technique to improve data efficiency when training machine learning models. It encapsulates the knowledge from a large dataset into a smaller synthetic dataset. A model trained on this smaller distilled dataset can attain comparable performance to a model trained on the original training dataset. However, the existing dataset distillation techniques mainly aim at achieving the best trade-off between resource usage efficiency and model utility. The security risks stemming from them have not been explored. This study performs the first backdoor attack against the models trained on the data distilled by dataset distillation models in the image domain. Concretely, we inject triggers into the synthetic data during the distillation procedure rather than during the model training stage, where all previous attacks are performed. We propose two types of backdoor attacks, namely NAIVEATTACK and DOORPING. NAIVEATTACK simply adds triggers to the raw data at the initial distillation phase, while DOORPING iteratively updates the triggers during the entire distillation procedure. We conduct extensive evaluations on multiple datasets, architectures, and dataset distillation techniques. Empirical evaluation shows that NAIVEATTACK achieves decent attack success rate (ASR) scores in some cases, while DOORPING reaches higher ASR scores (close to 1.0) in all cases. Furthermore, we conduct a comprehensive ablation study to analyze the factors that may affect the attack performance. Finally, we evaluate multiple defense mechanisms against our backdoor attacks and show that our attacks can practically circumvent these defense mechanisms.","classes":{"dataset":0.037477348}}
{"title":"Database management system performance comparisons: A systematic survey","description":"Efficiency has been a pivotal aspect of the software industry since its inception, as a system that serves the end-user fast, and the service provider cost-efficiently benefits all parties. A database management system (DBMS) is an integral part of effectively all software systems, and therefore it is logical that different studies have compared the performance of different DBMSs in hopes of finding the most efficient one. This survey systematically synthesizes the results and approaches of studies that compare DBMS performance and provides recommendations for industry and research. The results show that performance is usually tested in a way that does not reflect real-world use cases, and that tests are typically reported in insufficient detail for replication or for drawing conclusions from the stated results.","link":"http://arxiv.org/abs/2301.01095v1","created":"2023-01-03","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Database management system performance comparisons: A systematic survey Efficiency has been a pivotal aspect of the software industry since its inception, as a system that serves the end-user fast, and the service provider cost-efficiently benefits all parties. A database management system (DBMS) is an integral part of effectively all software systems, and therefore it is logical that different studies have compared the performance of different DBMSs in hopes of finding the most efficient one. This survey systematically synthesizes the results and approaches of studies that compare DBMS performance and provides recommendations for industry and research. The results show that performance is usually tested in a way that does not reflect real-world use cases, and that tests are typically reported in insufficient detail for replication or for drawing conclusions from the stated results.","classes":{"dataset":0.353053391}}
{"title":"More is Better: A Database for Spontaneous Micro-Expression with High Frame Rates","description":"As one of the most important psychic stress reactions, micro-expressions (MEs), are spontaneous and transient facial expressions that can reveal the genuine emotions of human beings. Thus, recognizing MEs (MER) automatically is becoming increasingly crucial in the field of affective computing, and provides essential technical support in lie detection, psychological analysis and other areas. However, the lack of abundant ME data seriously restricts the development of cutting-edge data-driven MER models. Despite the recent efforts of several spontaneous ME datasets to alleviate this problem, it is still a tiny amount of work. To solve the problem of ME data hunger, we construct a dynamic spontaneous ME dataset with the largest current ME data scale, called DFME (Dynamic Facial Micro-expressions), which includes 7,526 well-labeled ME videos induced by 671 participants and annotated by more than 20 annotators throughout three years. Afterwards, we adopt four classical spatiotemporal feature learning models on DFME to perform MER experiments to objectively verify the validity of DFME dataset. In addition, we explore different solutions to the class imbalance and key-frame sequence sampling problems in dynamic MER respectively on DFME, so as to provide a valuable reference for future research. The comprehensive experimental results show that our DFME dataset can facilitate the research of automatic MER, and provide a new benchmark for MER. DFME will be published via https://mea-lab-421.github.io.","link":"http://arxiv.org/abs/2301.00985v1","created":"2023-01-03","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"More is Better: A Database for Spontaneous Micro-Expression with High Frame Rates As one of the most important psychic stress reactions, micro-expressions (MEs), are spontaneous and transient facial expressions that can reveal the genuine emotions of human beings. Thus, recognizing MEs (MER) automatically is becoming increasingly crucial in the field of affective computing, and provides essential technical support in lie detection, psychological analysis and other areas. However, the lack of abundant ME data seriously restricts the development of cutting-edge data-driven MER models. Despite the recent efforts of several spontaneous ME datasets to alleviate this problem, it is still a tiny amount of work. To solve the problem of ME data hunger, we construct a dynamic spontaneous ME dataset with the largest current ME data scale, called DFME (Dynamic Facial Micro-expressions), which includes 7,526 well-labeled ME videos induced by 671 participants and annotated by more than 20 annotators throughout three years. Afterwards, we adopt four classical spatiotemporal feature learning models on DFME to perform MER experiments to objectively verify the validity of DFME dataset. In addition, we explore different solutions to the class imbalance and key-frame sequence sampling problems in dynamic MER respectively on DFME, so as to provide a valuable reference for future research. The comprehensive experimental results show that our DFME dataset can facilitate the research of automatic MER, and provide a new benchmark for MER. DFME will be published via https://mea-lab-421.github.io.","classes":{"dataset":0.0237914994}}
{"title":"MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement Understanding","description":"Reading comprehension of legal text can be a particularly challenging task due to the length and complexity of legal clauses and a shortage of expert-annotated datasets. To address this challenge, we introduce the Merger Agreement Understanding Dataset (MAUD), an expert-annotated reading comprehension dataset based on the American Bar Association's 2021 Public Target Deal Points Study, with over 39,000 examples and over 47,000 total annotations. Our fine-tuned Transformer baselines show promising results, with models performing well above random on most questions. However, on a large subset of questions, there is still room for significant improvement. As the only expert-annotated merger agreement dataset, MAUD is valuable as a benchmark for both the legal profession and the NLP community.","link":"http://arxiv.org/abs/2301.00876v2","created":"2023-01-02","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement Understanding Reading comprehension of legal text can be a particularly challenging task due to the length and complexity of legal clauses and a shortage of expert-annotated datasets. To address this challenge, we introduce the Merger Agreement Understanding Dataset (MAUD), an expert-annotated reading comprehension dataset based on the American Bar Association's 2021 Public Target Deal Points Study, with over 39,000 examples and over 47,000 total annotations. Our fine-tuned Transformer baselines show promising results, with models performing well above random on most questions. However, on a large subset of questions, there is still room for significant improvement. As the only expert-annotated merger agreement dataset, MAUD is valuable as a benchmark for both the legal profession and the NLP community.","classes":{"dataset":0.4846895337}}
{"title":"Comparative analysis of observations of the selected exoplanet transits obtained at the Kyiv Comet station with the database of the orbital telescopes TESS and Kepler","description":"We present a comparative analysis of observations of the selected exoplanet transits obtained at the Kyiv Comet station with the database of the TESS (Transiting Exoplanet Survey Satellite) and Kepler space telescopes. The light curves obtained by the TESS and Kepler orbital telescopes were processed using a program based on the Python package Lightkurve 2.3v which is freely available in the MUST archive (Barbara A. Mikulski Archive for Space Telescopes). The ground-based observations were carried out with the 70-cm telescope AZT-8 (Lisnyky). Photometric processing of the ground-based observation was performed by using the Muniwin program. The light curves and parameters of the observed transits as well as the exoplanet orbital parameters obtained from ground-based observations were published in the ETD (Exoplanet Transit Database). Determined transit parameters were compared with the results of the TESS command, which are stored in the MUST archive. Here we present a comparison of the parameters of transit phenomena (period, depth, transit duration) and some orbital parameters were obtained from two independent sets of observations, terrestrial and orbital, performed in different epochs.","link":"http://arxiv.org/abs/2301.00689v2","created":"2023-01-02","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Comparative analysis of observations of the selected exoplanet transits obtained at the Kyiv Comet station with the database of the orbital telescopes TESS and Kepler We present a comparative analysis of observations of the selected exoplanet transits obtained at the Kyiv Comet station with the database of the TESS (Transiting Exoplanet Survey Satellite) and Kepler space telescopes. The light curves obtained by the TESS and Kepler orbital telescopes were processed using a program based on the Python package Lightkurve 2.3v which is freely available in the MUST archive (Barbara A. Mikulski Archive for Space Telescopes). The ground-based observations were carried out with the 70-cm telescope AZT-8 (Lisnyky). Photometric processing of the ground-based observation was performed by using the Muniwin program. The light curves and parameters of the observed transits as well as the exoplanet orbital parameters obtained from ground-based observations were published in the ETD (Exoplanet Transit Database). Determined transit parameters were compared with the results of the TESS command, which are stored in the MUST archive. Here we present a comparison of the parameters of transit phenomena (period, depth, transit duration) and some orbital parameters were obtained from two independent sets of observations, terrestrial and orbital, performed in different epochs.","classes":{"dataset":0.0600224994}}
{"title":"EmoGator: A New Open Source Vocal Burst Dataset with Baseline Machine Learning Classification Methodologies","description":"Vocal Bursts -- short, non-speech vocalizations that convey emotions, such as laughter, cries, sighs, moans, and groans -- are an often-overlooked aspect of speech emotion recognition, but an important aspect of human vocal communication. One barrier to study of these interesting vocalizations is a lack of large datasets. I am pleased to introduce the EmoGator dataset, which consists of 32,040 samples from 365 speakers, 16.91 hours of audio; each sample classified into one of 30 distinct emotion categories by the speaker. Several different approaches to construct classifiers to identify emotion categories will be discussed, and directions for future research will be suggested. Data set is available for download from https://github.com/fredbuhl/EmoGator.","link":"http://arxiv.org/abs/2301.00508v1","created":"2023-01-02","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"EmoGator: A New Open Source Vocal Burst Dataset with Baseline Machine Learning Classification Methodologies Vocal Bursts -- short, non-speech vocalizations that convey emotions, such as laughter, cries, sighs, moans, and groans -- are an often-overlooked aspect of speech emotion recognition, but an important aspect of human vocal communication. One barrier to study of these interesting vocalizations is a lack of large datasets. I am pleased to introduce the EmoGator dataset, which consists of 32,040 samples from 365 speakers, 16.91 hours of audio; each sample classified into one of 30 distinct emotion categories by the speaker. Several different approaches to construct classifiers to identify emotion categories will be discussed, and directions for future research will be suggested. Data set is available for download from https://github.com/fredbuhl/EmoGator.","classes":{"dataset":0.0159572419}}
{"title":"CORGI-PM: A Chinese Corpus For Gender Bias Probing and Mitigation","description":"As natural language processing (NLP) for gender bias becomes a significant interdisciplinary topic, the prevalent data-driven techniques such as large-scale language models suffer from data inadequacy and biased corpus, especially for languages with insufficient resources such as Chinese. To this end, we propose a Chinese cOrpus foR Gender bIas Probing and Mitigation CORGI-PM, which contains 32.9k sentences with high-quality labels derived by following an annotation scheme specifically developed for gender bias in the Chinese context. Moreover, we address three challenges for automatic textual gender bias mitigation, which requires the models to detect, classify, and mitigate textual gender bias. We also conduct experiments with state-of-the-art language models to provide baselines. To our best knowledge, CORGI-PM is the first sentence-level Chinese corpus for gender bias probing and mitigation.","link":"http://arxiv.org/abs/2301.00395v1","created":"2023-01-01","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"CORGI-PM: A Chinese Corpus For Gender Bias Probing and Mitigation As natural language processing (NLP) for gender bias becomes a significant interdisciplinary topic, the prevalent data-driven techniques such as large-scale language models suffer from data inadequacy and biased corpus, especially for languages with insufficient resources such as Chinese. To this end, we propose a Chinese cOrpus foR Gender bIas Probing and Mitigation CORGI-PM, which contains 32.9k sentences with high-quality labels derived by following an annotation scheme specifically developed for gender bias in the Chinese context. Moreover, we address three challenges for automatic textual gender bias mitigation, which requires the models to detect, classify, and mitigate textual gender bias. We also conduct experiments with state-of-the-art language models to provide baselines. To our best knowledge, CORGI-PM is the first sentence-level Chinese corpus for gender bias probing and mitigation.","classes":{"dataset":0.9861391187}}
{"title":"Knowledge-Based Dataset for Training PE Malware Detection Models","description":"Ontologies are a standard for semantic schemata in many knowledge-intensive domains of human interest. They are now becoming increasingly important also in areas until very recently dominated by subsymbolic representations and machine-learning-based data processing. One such area is information security, and more specifically malware detection. We propose PE Malware Ontology that offers a reusable semantic schema for Portable Executable (PE, Windows binary format) malware files. The ontology was inspired by the structure of the data in the EMBER dataset and it currently covers the data intended for static malware analysis. With this proposal, we hope to achieve: a) a unified semantic representation for PE malware datasets that are available or will be published in the future; (b) applicability of symbolic, neural-symbolic, or otherwise explainable approaches in the PE Malware domain that may lead to improved interpretability of results which may now be characterized by the terms defined in the ontology; and (c)by joint publishing of semantically treated EMBER data, including fractional datasets, also improved reproducibility of experiments.","link":"http://arxiv.org/abs/2301.00153v1","created":"2022-12-31","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Knowledge-Based Dataset for Training PE Malware Detection Models Ontologies are a standard for semantic schemata in many knowledge-intensive domains of human interest. They are now becoming increasingly important also in areas until very recently dominated by subsymbolic representations and machine-learning-based data processing. One such area is information security, and more specifically malware detection. We propose PE Malware Ontology that offers a reusable semantic schema for Portable Executable (PE, Windows binary format) malware files. The ontology was inspired by the structure of the data in the EMBER dataset and it currently covers the data intended for static malware analysis. With this proposal, we hope to achieve: a) a unified semantic representation for PE malware datasets that are available or will be published in the future; (b) applicability of symbolic, neural-symbolic, or otherwise explainable approaches in the PE Malware domain that may lead to improved interpretability of results which may now be characterized by the terms defined in the ontology; and (c)by joint publishing of semantically treated EMBER data, including fractional datasets, also improved reproducibility of experiments.","classes":{"dataset":0.9793703556}}
{"title":"A Fine-Grained Vehicle Detection (FGVD) Dataset for Unconstrained Roads","description":"The previous fine-grained datasets mainly focus on classification and are often captured in a controlled setup, with the camera focusing on the objects. We introduce the first Fine-Grained Vehicle Detection (FGVD) dataset in the wild, captured from a moving camera mounted on a car. It contains 5502 scene images with 210 unique fine-grained labels of multiple vehicle types organized in a three-level hierarchy. While previous classification datasets also include makes for different kinds of cars, the FGVD dataset introduces new class labels for categorizing two-wheelers, autorickshaws, and trucks. The FGVD dataset is challenging as it has vehicles in complex traffic scenarios with intra-class and inter-class variations in types, scale, pose, occlusion, and lighting conditions. The current object detectors like yolov5 and faster RCNN perform poorly on our dataset due to a lack of hierarchical modeling. Along with providing baseline results for existing object detectors on FGVD Dataset, we also present the results of a combination of an existing detector and the recent Hierarchical Residual Network (HRN) classifier for the FGVD task. Finally, we show that FGVD vehicle images are the most challenging to classify among the fine-grained datasets.","link":"http://arxiv.org/abs/2212.14569v1","created":"2022-12-30","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A Fine-Grained Vehicle Detection (FGVD) Dataset for Unconstrained Roads The previous fine-grained datasets mainly focus on classification and are often captured in a controlled setup, with the camera focusing on the objects. We introduce the first Fine-Grained Vehicle Detection (FGVD) dataset in the wild, captured from a moving camera mounted on a car. It contains 5502 scene images with 210 unique fine-grained labels of multiple vehicle types organized in a three-level hierarchy. While previous classification datasets also include makes for different kinds of cars, the FGVD dataset introduces new class labels for categorizing two-wheelers, autorickshaws, and trucks. The FGVD dataset is challenging as it has vehicles in complex traffic scenarios with intra-class and inter-class variations in types, scale, pose, occlusion, and lighting conditions. The current object detectors like yolov5 and faster RCNN perform poorly on our dataset due to a lack of hierarchical modeling. Along with providing baseline results for existing object detectors on FGVD Dataset, we also present the results of a combination of an existing detector and the recent Hierarchical Residual Network (HRN) classifier for the FGVD task. Finally, we show that FGVD vehicle images are the most challenging to classify among the fine-grained datasets.","classes":{"dataset":0.9639893174}}
{"title":"Synthetic dataset generation methodology for Recommender Systems using statistical sampling methods, a Multinomial Logit model, and a Fuzzy Inference System","description":"It is said that we live in the age of data, and that data is ubiquitous and readily available if one has the tools to harness it. That may well be true, but so is the opposite. It is ever more common to try to start a data science project only to find oneself without quality data. Be it due to just not having collected the needed features, or due to insufficient data, or even legality issues, the list goes on. When this happens, either the project is prematurely abandoned, or similar datasets are searched for and used. However, finding a dataset that answers your needs in terms of features, type of ratings, etc., may not be an easy task, this is particularly the case for recommender systems. In this work, a methodology for the generation of synthetic datasets for recommender systems is presented, thus allowing to overcome the obstacle of not having quality data in sufficient amount readily available. With this methodology, one can generate a synthetic dataset for recommendation composed by numerical/ordinal and nominal features. The dataset is built with Gaussian copulas, Dirichlet and Gaussian distributions, a Multinomial Logit model and a Fuzzy Logic Inference System that generates the ratings according to different user behavioural profiles and perceived item quality.","link":"http://arxiv.org/abs/2212.14350v1","created":"2022-12-29","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Synthetic dataset generation methodology for Recommender Systems using statistical sampling methods, a Multinomial Logit model, and a Fuzzy Inference System It is said that we live in the age of data, and that data is ubiquitous and readily available if one has the tools to harness it. That may well be true, but so is the opposite. It is ever more common to try to start a data science project only to find oneself without quality data. Be it due to just not having collected the needed features, or due to insufficient data, or even legality issues, the list goes on. When this happens, either the project is prematurely abandoned, or similar datasets are searched for and used. However, finding a dataset that answers your needs in terms of features, type of ratings, etc., may not be an easy task, this is particularly the case for recommender systems. In this work, a methodology for the generation of synthetic datasets for recommender systems is presented, thus allowing to overcome the obstacle of not having quality data in sufficient amount readily available. With this methodology, one can generate a synthetic dataset for recommendation composed by numerical/ordinal and nominal features. The dataset is built with Gaussian copulas, Dirichlet and Gaussian distributions, a Multinomial Logit model and a Fuzzy Logic Inference System that generates the ratings according to different user behavioural profiles and perceived item quality.","classes":{"dataset":0.1185964569}}
{"title":"Curator: Creating Large-Scale Curated Labelled Datasets using Self-Supervised Learning","description":"Applying Machine learning to domains like Earth Sciences is impeded by the lack of labeled data, despite a large corpus of raw data available in such domains. For instance, training a wildfire classifier on satellite imagery requires curating a massive and diverse dataset, which is an expensive and time-consuming process that can span from weeks to months. Searching for relevant examples in over 40 petabytes of unlabelled data requires researchers to manually hunt for such images, much like finding a needle in a haystack. We present a no-code end-to-end pipeline, Curator, which dramatically minimizes the time taken to curate an exhaustive labeled dataset. Curator is able to search massive amounts of unlabelled data by combining self-supervision, scalable nearest neighbor search, and active learning to learn and differentiate image representations. The pipeline can also be readily applied to solve problems across different domains. Overall, the pipeline makes it practical for researchers to go from just one reference image to a comprehensive dataset in a diminutive span of time.","link":"http://arxiv.org/abs/2212.14099v1","created":"2022-12-28","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Curator: Creating Large-Scale Curated Labelled Datasets using Self-Supervised Learning Applying Machine learning to domains like Earth Sciences is impeded by the lack of labeled data, despite a large corpus of raw data available in such domains. For instance, training a wildfire classifier on satellite imagery requires curating a massive and diverse dataset, which is an expensive and time-consuming process that can span from weeks to months. Searching for relevant examples in over 40 petabytes of unlabelled data requires researchers to manually hunt for such images, much like finding a needle in a haystack. We present a no-code end-to-end pipeline, Curator, which dramatically minimizes the time taken to curate an exhaustive labeled dataset. Curator is able to search massive amounts of unlabelled data by combining self-supervision, scalable nearest neighbor search, and active learning to learn and differentiate image representations. The pipeline can also be readily applied to solve problems across different domains. Overall, the pipeline makes it practical for researchers to go from just one reference image to a comprehensive dataset in a diminutive span of time.","classes":{"dataset":0.071910806}}
{"title":"Exploration of latent space of LOD2 GML dataset to identify similar buildings","description":"Explainable numerical representations of otherwise complex datasets are vital as they extract relevant information, which is more convenient to analyze and study. These latent representations help identify clusters and outliers and assess the similarity between data points. The 3-D model of buildings is one dataset that possesses inherent complexity given the variety in footprint shape, distinct roof types, walls, height, and volume. Traditionally, comparing building shapes requires matching their known properties and shape metrics with each other. However, this requires obtaining a plethora of such properties to calculate similarity. In contrast, this study utilizes an autoencoder-based method to compute the shape information in a fixed-size vector form that can be compared and grouped with the help of distance metrics. This study uses \"FoldingNet,\" a 3D autoencoder, to generate the latent representation of each building from the obtained LOD2 GML dataset of German cities and villages. The Cosine distance is calculated for each latent vector to determine the locations of similar buildings in the city. Further, a set of geospatial tools is utilized to iteratively find the geographical clusters of buildings with similar forms. The state of Brandenburg in Germany is taken as an example to test the methodology. The study introduces a novel approach to finding similar buildings and their geographical location, which can define the neighborhood's character, history, and social setting. Further, the process can be scaled to include multiple settlements where more regional insights can be made.","link":"http://arxiv.org/abs/2212.13965v1","created":"2022-12-28","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Exploration of latent space of LOD2 GML dataset to identify similar buildings Explainable numerical representations of otherwise complex datasets are vital as they extract relevant information, which is more convenient to analyze and study. These latent representations help identify clusters and outliers and assess the similarity between data points. The 3-D model of buildings is one dataset that possesses inherent complexity given the variety in footprint shape, distinct roof types, walls, height, and volume. Traditionally, comparing building shapes requires matching their known properties and shape metrics with each other. However, this requires obtaining a plethora of such properties to calculate similarity. In contrast, this study utilizes an autoencoder-based method to compute the shape information in a fixed-size vector form that can be compared and grouped with the help of distance metrics. This study uses \"FoldingNet,\" a 3D autoencoder, to generate the latent representation of each building from the obtained LOD2 GML dataset of German cities and villages. The Cosine distance is calculated for each latent vector to determine the locations of similar buildings in the city. Further, a set of geospatial tools is utilized to iteratively find the geographical clusters of buildings with similar forms. The state of Brandenburg in Germany is taken as an example to test the methodology. The study introduces a novel approach to finding similar buildings and their geographical location, which can define the neighborhood's character, history, and social setting. Further, the process can be scaled to include multiple settlements where more regional insights can be made.","classes":{"dataset":0.9583777785}}
{"title":"Swin MAE: Masked Autoencoders for Small Datasets","description":"The development of deep learning models in medical image analysis is majorly limited by the lack of large-sized and well-annotated datasets. Unsupervised learning does not require labels and is more suitable for solving medical image analysis problems. However, most of the current unsupervised learning methods need to be applied to large datasets. To make unsupervised learning applicable to small datasets, we proposed Swin MAE, which is a masked autoencoder with Swin Transformer as its backbone. Even on a dataset of only a few thousand medical images and without using any pre-trained models, Swin MAE is still able to learn useful semantic features purely from images. It can equal or even slightly outperform the supervised model obtained by Swin Transformer trained on ImageNet in terms of the transfer learning results of downstream tasks. The code is publicly available at https://github.com/Zian-Xu/Swin-MAE.","link":"http://arxiv.org/abs/2212.13805v2","created":"2022-12-28","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Swin MAE: Masked Autoencoders for Small Datasets The development of deep learning models in medical image analysis is majorly limited by the lack of large-sized and well-annotated datasets. Unsupervised learning does not require labels and is more suitable for solving medical image analysis problems. However, most of the current unsupervised learning methods need to be applied to large datasets. To make unsupervised learning applicable to small datasets, we proposed Swin MAE, which is a masked autoencoder with Swin Transformer as its backbone. Even on a dataset of only a few thousand medical images and without using any pre-trained models, Swin MAE is still able to learn useful semantic features purely from images. It can equal or even slightly outperform the supervised model obtained by Swin Transformer trained on ImageNet in terms of the transfer learning results of downstream tasks. The code is publicly available at https://github.com/Zian-Xu/Swin-MAE.","classes":{"dataset":0.1272187233}}
{"title":"Datasets on materials research of hard ferromagnet in TM-Fe-Si (TM=Ti, Zr, Hf, V, Nb, and Ta) ternary systems","description":"The datasets presented in this article are related to materials research on hard ferromagnet in TM-Fe-Si (TM=Ti, Zr, Hf, V, Nb, and Ta) ternary systems. The motivation for data collection is based on the research paper entitled \"Novel hard magnetic phase with Zr$_{11.5}$Fe$_{53}$Si$_{35.5}$ composition\". The datasets are composed of scanning electron microscope images, X-ray diffraction (XRD) patterns, and magnetization data for TM$_{7}$Fe$_{52}$Si$_{41}$ annealed at 1050 $^{\\circ}$C. The chemical compositions of constituent phases were determined by an energy dispersive X-ray spectrometer (EDS). The phase analysis was performed using XRD and EDS results. The Curie temperature of each sample was obtained using magnetization data, and the coercive field was determined for hard ferromagnet samples Zr$_{7}$Fe$_{52}$Si$_{41}$ and Hf$_{7}$Fe$_{52}$Si$_{41}$. The datasets would be useful for developing an Fe-based rare-earth-free permanent magnet, which is one of the central issues of materials science.","link":"http://arxiv.org/abs/2212.13595v1","created":"2022-12-27","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Datasets on materials research of hard ferromagnet in TM-Fe-Si (TM=Ti, Zr, Hf, V, Nb, and Ta) ternary systems The datasets presented in this article are related to materials research on hard ferromagnet in TM-Fe-Si (TM=Ti, Zr, Hf, V, Nb, and Ta) ternary systems. The motivation for data collection is based on the research paper entitled \"Novel hard magnetic phase with Zr$_{11.5}$Fe$_{53}$Si$_{35.5}$ composition\". The datasets are composed of scanning electron microscope images, X-ray diffraction (XRD) patterns, and magnetization data for TM$_{7}$Fe$_{52}$Si$_{41}$ annealed at 1050 $^{\\circ}$C. The chemical compositions of constituent phases were determined by an energy dispersive X-ray spectrometer (EDS). The phase analysis was performed using XRD and EDS results. The Curie temperature of each sample was obtained using magnetization data, and the coercive field was determined for hard ferromagnet samples Zr$_{7}$Fe$_{52}$Si$_{41}$ and Hf$_{7}$Fe$_{52}$Si$_{41}$. The datasets would be useful for developing an Fe-based rare-earth-free permanent magnet, which is one of the central issues of materials science.","classes":{"dataset":0.9750294089}}
{"title":"Audiovisual Database with 360 Video and Higher-Order Ambisonics Audio for Perception, Cognition, Behavior, and QoE Evaluation Research","description":"Research into multi-modal perception, human cognition, behavior, and attention can benefit from high-fidelity content that may recreate real-life-like scenes when rendered on head-mounted displays. Moreover, aspects of audiovisual perception, cognitive processes, and behavior may complement questionnaire-based Quality of Experience (QoE) evaluation of interactive virtual environments. Currently, there is a lack of high-quality open-source audiovisual databases that can be used to evaluate such aspects or systems capable of reproducing high-quality content. With this paper, we provide a publicly available audiovisual database consisting of twelve scenes capturing real-life nature and urban environments with a video resolution of 7680x3840 at 60 frames-per-second and with 4th-order Ambisonics audio. These 360 video sequences, with an average duration of 60 seconds, represent real-life settings for systematically evaluating various dimensions of uni-/multi-modal perception, cognition, behavior, and QoE. The paper provides details of the scene requirements, recording approach, and scene descriptions. The database provides high-quality reference material with a balanced focus on auditory and visual sensory information. The database will be continuously updated with additional scenes and further metadata such as human ratings and saliency information.","link":"http://arxiv.org/abs/2212.13442v1","created":"2022-12-27","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Audiovisual Database with 360 Video and Higher-Order Ambisonics Audio for Perception, Cognition, Behavior, and QoE Evaluation Research Research into multi-modal perception, human cognition, behavior, and attention can benefit from high-fidelity content that may recreate real-life-like scenes when rendered on head-mounted displays. Moreover, aspects of audiovisual perception, cognitive processes, and behavior may complement questionnaire-based Quality of Experience (QoE) evaluation of interactive virtual environments. Currently, there is a lack of high-quality open-source audiovisual databases that can be used to evaluate such aspects or systems capable of reproducing high-quality content. With this paper, we provide a publicly available audiovisual database consisting of twelve scenes capturing real-life nature and urban environments with a video resolution of 7680x3840 at 60 frames-per-second and with 4th-order Ambisonics audio. These 360 video sequences, with an average duration of 60 seconds, represent real-life settings for systematically evaluating various dimensions of uni-/multi-modal perception, cognition, behavior, and QoE. The paper provides details of the scene requirements, recording approach, and scene descriptions. The database provides high-quality reference material with a balanced focus on auditory and visual sensory information. The database will be continuously updated with additional scenes and further metadata such as human ratings and saliency information.","classes":{"dataset":0.9824038744}}
{"title":"Lab-scale Vibration Analysis Dataset and Baseline Methods for Machinery Fault Diagnosis with Machine Learning","description":"The monitoring of machine conditions in a plant is crucial for production in manufacturing. A sudden failure of a machine can stop production and cause a loss of revenue. The vibration signal of a machine is a good indicator of its condition. This paper presents a dataset of vibration signals from a lab-scale machine. The dataset contains four different types of machine conditions: normal, unbalance, misalignment, and bearing fault. Three machine learning methods (SVM, KNN, and GNB) evaluated the dataset, and a perfect result was obtained by one of the methods on a 1-fold test. The performance of the algorithms is evaluated using weighted accuracy (WA) since the data is balanced. The results show that the best-performing algorithm is the SVM with a WA of 99.75\\% on the 5-fold cross-validations. The dataset is provided in the form of CSV files in an open and free repository at https://zenodo.org/record/7006575.","link":"http://arxiv.org/abs/2212.14732v1","created":"2022-12-27","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Lab-scale Vibration Analysis Dataset and Baseline Methods for Machinery Fault Diagnosis with Machine Learning The monitoring of machine conditions in a plant is crucial for production in manufacturing. A sudden failure of a machine can stop production and cause a loss of revenue. The vibration signal of a machine is a good indicator of its condition. This paper presents a dataset of vibration signals from a lab-scale machine. The dataset contains four different types of machine conditions: normal, unbalance, misalignment, and bearing fault. Three machine learning methods (SVM, KNN, and GNB) evaluated the dataset, and a perfect result was obtained by one of the methods on a 1-fold test. The performance of the algorithms is evaluated using weighted accuracy (WA) since the data is balanced. The results show that the best-performing algorithm is the SVM with a WA of 99.75\\% on the 5-fold cross-validations. The dataset is provided in the form of CSV files in an open and free repository at https://zenodo.org/record/7006575.","classes":{"dataset":0.0397546776}}
{"title":"OMSN and FAROS: OCTA Microstructure Segmentation Network and Fully Annotated Retinal OCTA Segmentation Dataset","description":"The lack of efficient segmentation methods and fully-labeled datasets limits the comprehensive assessment of optical coherence tomography angiography (OCTA) microstructures like retinal vessel network (RVN) and foveal avascular zone (FAZ), which are of great value in ophthalmic and systematic diseases evaluation. Here, we introduce an innovative OCTA microstructure segmentation network (OMSN) by combining an encoder-decoder-based architecture with multi-scale skip connections and the split-attention-based residual network ResNeSt, paying specific attention to OCTA microstructural features while facilitating better model convergence and feature representations. The proposed OMSN achieves excellent single/multi-task performances for RVN or/and FAZ segmentation. Especially, the evaluation metrics on multi-task models outperform single-task models on the same dataset. On this basis, a fully annotated retinal OCTA segmentation (FAROS) dataset is constructed semi-automatically, filling the vacancy of a pixel-level fully-labeled OCTA dataset. OMSN multi-task segmentation model retrained with FAROS further certifies its outstanding accuracy for simultaneous RVN and FAZ segmentation.","link":"http://arxiv.org/abs/2212.13059v1","created":"2022-12-26","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"OMSN and FAROS: OCTA Microstructure Segmentation Network and Fully Annotated Retinal OCTA Segmentation Dataset The lack of efficient segmentation methods and fully-labeled datasets limits the comprehensive assessment of optical coherence tomography angiography (OCTA) microstructures like retinal vessel network (RVN) and foveal avascular zone (FAZ), which are of great value in ophthalmic and systematic diseases evaluation. Here, we introduce an innovative OCTA microstructure segmentation network (OMSN) by combining an encoder-decoder-based architecture with multi-scale skip connections and the split-attention-based residual network ResNeSt, paying specific attention to OCTA microstructural features while facilitating better model convergence and feature representations. The proposed OMSN achieves excellent single/multi-task performances for RVN or/and FAZ segmentation. Especially, the evaluation metrics on multi-task models outperform single-task models on the same dataset. On this basis, a fully annotated retinal OCTA segmentation (FAROS) dataset is constructed semi-automatically, filling the vacancy of a pixel-level fully-labeled OCTA dataset. OMSN multi-task segmentation model retrained with FAROS further certifies its outstanding accuracy for simultaneous RVN and FAZ segmentation.","classes":{"dataset":0.1989208758}}
{"title":"Skit-S2I: An Indian Accented Speech to Intent dataset","description":"Conventional conversation assistants extract text transcripts from the speech signal using automatic speech recognition (ASR) and then predict intent from the transcriptions. Using end-to-end spoken language understanding (SLU), the intents of the speaker are predicted directly from the speech signal without requiring intermediate text transcripts. As a result, the model can optimize directly for intent classification and avoid cascading errors from ASR. The end-to-end SLU system also helps in reducing the latency of the intent prediction model. Although many datasets are available publicly for text-to-intent tasks, the availability of labeled speech-to-intent datasets is limited, and there are no datasets available in the Indian accent. In this paper, we release the Skit-S2I dataset, the first publicly available Indian-accented SLU dataset in the banking domain in a conversational tonality. We experiment with multiple baselines, compare different pretrained speech encoder's representations, and find that SSL pretrained representations perform slightly better than ASR pretrained representations lacking prosodic features for speech-to-intent classification. The dataset and baseline code is available at \\url{https://github.com/skit-ai/speech-to-intent-dataset}","link":"http://arxiv.org/abs/2212.13015v1","created":"2022-12-26","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Skit-S2I: An Indian Accented Speech to Intent dataset Conventional conversation assistants extract text transcripts from the speech signal using automatic speech recognition (ASR) and then predict intent from the transcriptions. Using end-to-end spoken language understanding (SLU), the intents of the speaker are predicted directly from the speech signal without requiring intermediate text transcripts. As a result, the model can optimize directly for intent classification and avoid cascading errors from ASR. The end-to-end SLU system also helps in reducing the latency of the intent prediction model. Although many datasets are available publicly for text-to-intent tasks, the availability of labeled speech-to-intent datasets is limited, and there are no datasets available in the Indian accent. In this paper, we release the Skit-S2I dataset, the first publicly available Indian-accented SLU dataset in the banking domain in a conversational tonality. We experiment with multiple baselines, compare different pretrained speech encoder's representations, and find that SSL pretrained representations perform slightly better than ASR pretrained representations lacking prosodic features for speech-to-intent classification. The dataset and baseline code is available at \\url{https://github.com/skit-ai/speech-to-intent-dataset}","classes":{"dataset":0.0110984221}}
{"title":"HandsOff: Labeled Dataset Generation With No Additional Human Annotations","description":"Recent work leverages the expressive power of generative adversarial networks (GANs) to generate labeled synthetic datasets. These dataset generation methods often require new annotations of synthetic images, which forces practitioners to seek out annotators, curate a set of synthetic images, and ensure the quality of generated labels. We introduce the HandsOff framework, a technique capable of producing an unlimited number of synthetic images and corresponding labels after being trained on less than 50 pre-existing labeled images. Our framework avoids the practical drawbacks of prior work by unifying the field of GAN inversion with dataset generation. We generate datasets with rich pixel-wise labels in multiple challenging domains such as faces, cars, full-body human poses, and urban driving scenes. Our method achieves state-of-the-art performance in semantic segmentation, keypoint detection, and depth estimation compared to prior dataset generation approaches and transfer learning baselines. We additionally showcase its ability to address broad challenges in model development which stem from fixed, hand-annotated datasets, such as the long-tail problem in semantic segmentation.","link":"http://arxiv.org/abs/2212.12645v1","created":"2022-12-24","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"HandsOff: Labeled Dataset Generation With No Additional Human Annotations Recent work leverages the expressive power of generative adversarial networks (GANs) to generate labeled synthetic datasets. These dataset generation methods often require new annotations of synthetic images, which forces practitioners to seek out annotators, curate a set of synthetic images, and ensure the quality of generated labels. We introduce the HandsOff framework, a technique capable of producing an unlimited number of synthetic images and corresponding labels after being trained on less than 50 pre-existing labeled images. Our framework avoids the practical drawbacks of prior work by unifying the field of GAN inversion with dataset generation. We generate datasets with rich pixel-wise labels in multiple challenging domains such as faces, cars, full-body human poses, and urban driving scenes. Our method achieves state-of-the-art performance in semantic segmentation, keypoint detection, and depth estimation compared to prior dataset generation approaches and transfer learning baselines. We additionally showcase its ability to address broad challenges in model development which stem from fixed, hand-annotated datasets, such as the long-tail problem in semantic segmentation.","classes":{"dataset":0.8049973249}}
{"title":"Image Classification with Small Datasets: Overview and Benchmark","description":"Image classification with small datasets has been an active research area in the recent past. However, as research in this scope is still in its infancy, two key ingredients are missing for ensuring reliable and truthful progress: a systematic and extensive overview of the state of the art, and a common benchmark to allow for objective comparisons between published methods. This article addresses both issues. First, we systematically organize and connect past studies to consolidate a community that is currently fragmented and scattered. Second, we propose a common benchmark that allows for an objective comparison of approaches. It consists of five datasets spanning various domains (e.g., natural images, medical imagery, satellite data) and data types (RGB, grayscale, multispectral). We use this benchmark to re-evaluate the standard cross-entropy baseline and ten existing methods published between 2017 and 2021 at renowned venues. Surprisingly, we find that thorough hyper-parameter tuning on held-out validation data results in a highly competitive baseline and highlights a stunted growth of performance over the years. Indeed, only a single specialized method dating back to 2019 clearly wins our benchmark and outperforms the baseline classifier.","link":"http://arxiv.org/abs/2212.12478v1","created":"2022-12-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Image Classification with Small Datasets: Overview and Benchmark Image classification with small datasets has been an active research area in the recent past. However, as research in this scope is still in its infancy, two key ingredients are missing for ensuring reliable and truthful progress: a systematic and extensive overview of the state of the art, and a common benchmark to allow for objective comparisons between published methods. This article addresses both issues. First, we systematically organize and connect past studies to consolidate a community that is currently fragmented and scattered. Second, we propose a common benchmark that allows for an objective comparison of approaches. It consists of five datasets spanning various domains (e.g., natural images, medical imagery, satellite data) and data types (RGB, grayscale, multispectral). We use this benchmark to re-evaluate the standard cross-entropy baseline and ten existing methods published between 2017 and 2021 at renowned venues. Surprisingly, we find that thorough hyper-parameter tuning on held-out validation data results in a highly competitive baseline and highlights a stunted growth of performance over the years. Indeed, only a single specialized method dating back to 2019 clearly wins our benchmark and outperforms the baseline classifier.","classes":{"dataset":0.9750364423}}
{"title":"Large Raw Emotional Dataset with Aggregation Mechanism","description":"We present a new data set for speech emotion recognition (SER) tasks called Dusha. The corpus contains approximately 350 hours of data, more than 300 000 audio recordings with Russian speech and their transcripts. Therefore it is the biggest open bi-modal data collection for SER task nowadays. It is annotated using a crowd-sourcing platform and includes two subsets: acted and real-life. Acted subset has a more balanced class distribution than the unbalanced real-life part consisting of audio podcasts. So the first one is suitable for model pre-training, and the second is elaborated for fine-tuning purposes, model approbation, and validation. This paper describes pre-processing routine, annotation, and experiment with a baseline model to demonstrate some actual metrics which could be obtained with the Dusha data set.","link":"http://arxiv.org/abs/2212.12266v1","created":"2022-12-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Large Raw Emotional Dataset with Aggregation Mechanism We present a new data set for speech emotion recognition (SER) tasks called Dusha. The corpus contains approximately 350 hours of data, more than 300 000 audio recordings with Russian speech and their transcripts. Therefore it is the biggest open bi-modal data collection for SER task nowadays. It is annotated using a crowd-sourcing platform and includes two subsets: acted and real-life. Acted subset has a more balanced class distribution than the unbalanced real-life part consisting of audio podcasts. So the first one is suitable for model pre-training, and the second is elaborated for fine-tuning purposes, model approbation, and validation. This paper describes pre-processing routine, annotation, and experiment with a baseline model to demonstrate some actual metrics which could be obtained with the Dusha data set.","classes":{"dataset":0.0499825366}}
{"title":"EndoBoost: a plug-and-play module for false positive suppression during computer-aided polyp detection in real-world colonoscopy (with dataset)","description":"The advance of computer-aided detection systems using deep learning opened a new scope in endoscopic image analysis. However, the learning-based models developed on closed datasets are susceptible to unknown anomalies in complex clinical environments. In particular, the high false positive rate of polyp detection remains a major challenge in clinical practice. In this work, we release the FPPD-13 dataset, which provides a taxonomy and real-world cases of typical false positives during computer-aided polyp detection in real-world colonoscopy. We further propose a post-hoc module EndoBoost, which can be plugged into generic polyp detection models to filter out false positive predictions. This is realized by generative learning of the polyp manifold with normalizing flows and rejecting false positives through density estimation. Compared to supervised classification, this anomaly detection paradigm achieves better data efficiency and robustness in open-world settings. Extensive experiments demonstrate a promising false positive suppression in both retrospective and prospective validation. In addition, the released dataset can be used to perform 'stress' tests on established detection systems and encourages further research toward robust and reliable computer-aided endoscopic image analysis. The dataset and code will be publicly available at http://endoboost.miccai.cloud.","link":"http://arxiv.org/abs/2212.12204v1","created":"2022-12-23","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"EndoBoost: a plug-and-play module for false positive suppression during computer-aided polyp detection in real-world colonoscopy (with dataset) The advance of computer-aided detection systems using deep learning opened a new scope in endoscopic image analysis. However, the learning-based models developed on closed datasets are susceptible to unknown anomalies in complex clinical environments. In particular, the high false positive rate of polyp detection remains a major challenge in clinical practice. In this work, we release the FPPD-13 dataset, which provides a taxonomy and real-world cases of typical false positives during computer-aided polyp detection in real-world colonoscopy. We further propose a post-hoc module EndoBoost, which can be plugged into generic polyp detection models to filter out false positive predictions. This is realized by generative learning of the polyp manifold with normalizing flows and rejecting false positives through density estimation. Compared to supervised classification, this anomaly detection paradigm achieves better data efficiency and robustness in open-world settings. Extensive experiments demonstrate a promising false positive suppression in both retrospective and prospective validation. In addition, the released dataset can be used to perform 'stress' tests on established detection systems and encourages further research toward robust and reliable computer-aided endoscopic image analysis. The dataset and code will be publicly available at http://endoboost.miccai.cloud.","classes":{"dataset":0.0381644256}}
{"title":"MN-DS: A Multilabeled News Dataset for News Articles Hierarchical Classification","description":"This article presents a dataset of 10,917 news articles with hierarchical news categories collected between January 1st 2019, and December 31st 2019. We manually labelled the articles based on a hierarchical taxonomy with 17 first-level and 109 second-level categories. This dataset can be used to train machine learning models for automatically classifying news articles by topic. This dataset can be helpful for researchers working on news structuring, classification, and predicting future events based on released news.","link":"http://arxiv.org/abs/2212.12061v1","created":"2022-12-22","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"MN-DS: A Multilabeled News Dataset for News Articles Hierarchical Classification This article presents a dataset of 10,917 news articles with hierarchical news categories collected between January 1st 2019, and December 31st 2019. We manually labelled the articles based on a hierarchical taxonomy with 17 first-level and 109 second-level categories. This dataset can be used to train machine learning models for automatically classifying news articles by topic. This dataset can be helpful for researchers working on news structuring, classification, and predicting future events based on released news.","classes":{"dataset":0.0307827219}}
{"title":"Populations of the Kreutz Sungrazer System in a SOHO Database","description":"Discovery of nine populations in a set of 193 select SOHO Kreutz sungrazers (Sekanina 2021) is confirmed for the first time via a histogram of the true longitudes of the ascending node, constructed for a revised set of 220 select sungrazers imaged exclusively by the SOHO's C2 coronagraph. Marsden's orbits are approximately corrected for effects of the out-of-plane nongravitational force. Population I displays two peaks in the histogram, one presumably belonging to a side branch alike to Population Pe, but with no related naked-eye sungrazer known. Swarms/clusters of objects are commonplace, providing evidence on cascading fragmentation proceeding throughout the orbit. Augmentation to all C2-only SOHO Kreutz comets, aimed at removing deliberate bias against Populations I and Pe, reduces the appearance of Populations Ia and Pre-I to bulges along the slope of the histogram because of the swollen wings of Populations I and Pe, respectively. Populations II through IV change very little or not at all. The high Population I-to-II abundance ratio, of 14:1, may be a product of temporal limitations in fragment release. A drop in the number of fragments toward the ends of the nodal-longitude distribution, especially from Population II to IV, is in line with the contact-binary model.","link":"http://arxiv.org/abs/2212.11919v2","created":"2022-12-22","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Populations of the Kreutz Sungrazer System in a SOHO Database Discovery of nine populations in a set of 193 select SOHO Kreutz sungrazers (Sekanina 2021) is confirmed for the first time via a histogram of the true longitudes of the ascending node, constructed for a revised set of 220 select sungrazers imaged exclusively by the SOHO's C2 coronagraph. Marsden's orbits are approximately corrected for effects of the out-of-plane nongravitational force. Population I displays two peaks in the histogram, one presumably belonging to a side branch alike to Population Pe, but with no related naked-eye sungrazer known. Swarms/clusters of objects are commonplace, providing evidence on cascading fragmentation proceeding throughout the orbit. Augmentation to all C2-only SOHO Kreutz comets, aimed at removing deliberate bias against Populations I and Pe, reduces the appearance of Populations Ia and Pre-I to bulges along the slope of the histogram because of the swollen wings of Populations I and Pe, respectively. Populations II through IV change very little or not at all. The high Population I-to-II abundance ratio, of 14:1, may be a product of temporal limitations in fragment release. A drop in the number of fragments toward the ends of the nodal-longitude distribution, especially from Population II to IV, is in line with the contact-binary model.","classes":{"dataset":0.9607939124}}
{"title":"IPProtect: protecting the intellectual property of visual datasets during data valuation","description":"Data trading is essential to accelerate the development of data-driven machine learning pipelines. The central problem in data trading is to estimate the utility of a seller's dataset with respect to a given buyer's machine learning task, also known as data valuation. Typically, data valuation requires one or more participants to share their raw dataset with others, leading to potential risks of intellectual property (IP) violations. In this paper, we tackle the novel task of preemptively protecting the IP of datasets that need to be shared during data valuation. First, we identify and formalize two kinds of novel IP risks in visual datasets: data-item (image) IP and statistical (dataset) IP. Then, we propose a novel algorithm to convert the raw dataset into a sanitized version, that provides resistance to IP violations, while at the same time allowing accurate data valuation. The key idea is to limit the transfer of information from the raw dataset to the sanitized dataset, thereby protecting against potential intellectual property violations. Next, we analyze our method for the likely existence of a solution and immunity against reconstruction attacks. Finally, we conduct extensive experiments on three computer vision datasets demonstrating the advantages of our method in comparison to other baselines.","link":"http://arxiv.org/abs/2212.11468v1","created":"2022-12-22","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"IPProtect: protecting the intellectual property of visual datasets during data valuation Data trading is essential to accelerate the development of data-driven machine learning pipelines. The central problem in data trading is to estimate the utility of a seller's dataset with respect to a given buyer's machine learning task, also known as data valuation. Typically, data valuation requires one or more participants to share their raw dataset with others, leading to potential risks of intellectual property (IP) violations. In this paper, we tackle the novel task of preemptively protecting the IP of datasets that need to be shared during data valuation. First, we identify and formalize two kinds of novel IP risks in visual datasets: data-item (image) IP and statistical (dataset) IP. Then, we propose a novel algorithm to convert the raw dataset into a sanitized version, that provides resistance to IP violations, while at the same time allowing accurate data valuation. The key idea is to limit the transfer of information from the raw dataset to the sanitized dataset, thereby protecting against potential intellectual property violations. Next, we analyze our method for the likely existence of a solution and immunity against reconstruction attacks. Finally, we conduct extensive experiments on three computer vision datasets demonstrating the advantages of our method in comparison to other baselines.","classes":{"dataset":0.9616928101}}
{"title":"Esports Data-to-commentary Generation on Large-scale Data-to-text Dataset","description":"Esports, a sports competition using video games, has become one of the most important sporting events in recent years. Although the amount of esports data is increasing than ever, only a small fraction of those data accompanies text commentaries for the audience to retrieve and understand the plays. Therefore, in this study, we introduce a task of generating game commentaries from structured data records to address the problem. We first build a large-scale esports data-to-text dataset using structured data and commentaries from a popular esports game, League of Legends. On this dataset, we devise several data preprocessing methods including linearization and data splitting to augment its quality. We then introduce several baseline encoder-decoder models and propose a hierarchical model to generate game commentaries. Considering the characteristics of esports commentaries, we design evaluation metrics including three aspects of the output: correctness, fluency, and strategic depth. Experimental results on our large-scale esports dataset confirmed the advantage of the hierarchical model, and the results revealed several challenges of this novel task.","link":"http://arxiv.org/abs/2212.10935v1","created":"2022-12-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Esports Data-to-commentary Generation on Large-scale Data-to-text Dataset Esports, a sports competition using video games, has become one of the most important sporting events in recent years. Although the amount of esports data is increasing than ever, only a small fraction of those data accompanies text commentaries for the audience to retrieve and understand the plays. Therefore, in this study, we introduce a task of generating game commentaries from structured data records to address the problem. We first build a large-scale esports data-to-text dataset using structured data and commentaries from a popular esports game, League of Legends. On this dataset, we devise several data preprocessing methods including linearization and data splitting to augment its quality. We then introduce several baseline encoder-decoder models and propose a hierarchical model to generate game commentaries. Considering the characteristics of esports commentaries, we design evaluation metrics including three aspects of the output: correctness, fluency, and strategic depth. Experimental results on our large-scale esports dataset confirmed the advantage of the hierarchical model, and the results revealed several challenges of this novel task.","classes":{"dataset":0.0993943959}}
{"title":"PropSegmEnt: A Large-Scale Corpus for Proposition-Level Segmentation and Entailment Recognition","description":"The widely studied task of Natural Language Inference (NLI) requires a system to recognize whether one piece of text is textually entailed by another, i.e. whether the entirety of its meaning can be inferred from the other. In current NLI datasets and models, textual entailment relations are typically defined on the sentence- or paragraph-level. However, even a simple sentence often contains multiple propositions, i.e. distinct units of meaning conveyed by the sentence. As these propositions can carry different truth values in the context of a given premise, we argue for the need to recognize the textual entailment relation of each proposition in a sentence individually.   We propose PropSegmEnt, a corpus of over 35K propositions annotated by expert human raters. Our dataset structure resembles the tasks of (1) segmenting sentences within a document to the set of propositions, and (2) classifying the entailment relation of each proposition with respect to a different yet topically-aligned document, i.e. documents describing the same event or entity. We establish strong baselines for the segmentation and entailment tasks. Through case studies on summary hallucination detection and document-level NLI, we demonstrate that our conceptual framework is potentially useful for understanding and explaining the compositionality of NLI labels.","link":"http://arxiv.org/abs/2212.10750v1","created":"2022-12-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"PropSegmEnt: A Large-Scale Corpus for Proposition-Level Segmentation and Entailment Recognition The widely studied task of Natural Language Inference (NLI) requires a system to recognize whether one piece of text is textually entailed by another, i.e. whether the entirety of its meaning can be inferred from the other. In current NLI datasets and models, textual entailment relations are typically defined on the sentence- or paragraph-level. However, even a simple sentence often contains multiple propositions, i.e. distinct units of meaning conveyed by the sentence. As these propositions can carry different truth values in the context of a given premise, we argue for the need to recognize the textual entailment relation of each proposition in a sentence individually.   We propose PropSegmEnt, a corpus of over 35K propositions annotated by expert human raters. Our dataset structure resembles the tasks of (1) segmenting sentences within a document to the set of propositions, and (2) classifying the entailment relation of each proposition with respect to a different yet topically-aligned document, i.e. documents describing the same event or entity. We establish strong baselines for the segmentation and entailment tasks. Through case studies on summary hallucination detection and document-level NLI, we demonstrate that our conceptual framework is potentially useful for understanding and explaining the compositionality of NLI labels.","classes":{"dataset":0.8234074712}}
{"title":"Tracing and Removing Data Errors in Natural Language Generation Datasets","description":"Recent work has identified noisy and misannotated data as a core cause of hallucinations and unfaithful outputs in Natural Language Generation (NLG) tasks. Consequently, identifying and removing these examples is a key open challenge in creating reliable NLG systems. In this work, we introduce a framework to identify and remove low-quality training instances that lead to undesirable outputs, such as faithfulness errors in text summarization. We show that existing approaches for error tracing, such as gradient-based influence measures, do not perform reliably for detecting faithfulness errors in summarization. We overcome the drawbacks of existing error tracing methods through a new, contrast-based estimate that compares undesired generations to human-corrected outputs. Our proposed method can achieve a mean average precision of 0.91 across synthetic tasks with known ground truth and can achieve a two-fold reduction in hallucinations on a real entity hallucination evaluation on the NYT dataset.","link":"http://arxiv.org/abs/2212.10722v1","created":"2022-12-21","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Tracing and Removing Data Errors in Natural Language Generation Datasets Recent work has identified noisy and misannotated data as a core cause of hallucinations and unfaithful outputs in Natural Language Generation (NLG) tasks. Consequently, identifying and removing these examples is a key open challenge in creating reliable NLG systems. In this work, we introduce a framework to identify and remove low-quality training instances that lead to undesirable outputs, such as faithfulness errors in text summarization. We show that existing approaches for error tracing, such as gradient-based influence measures, do not perform reliably for detecting faithfulness errors in summarization. We overcome the drawbacks of existing error tracing methods through a new, contrast-based estimate that compares undesired generations to human-corrected outputs. Our proposed method can achieve a mean average precision of 0.91 across synthetic tasks with known ground truth and can achieve a two-fold reduction in hallucinations on a real entity hallucination evaluation on the NYT dataset.","classes":{"dataset":0.0424429402}}
{"title":"CausalDialogue: Modeling Utterance-level Causality in Conversations","description":"Despite their widespread adoption, neural conversation models have yet to exhibit natural chat capabilities with humans. In this research, we examine user utterances as causes and generated responses as effects, recognizing that changes in a cause should produce a different effect. To further explore this concept, we have compiled and expanded upon a new dataset called CausalDialogue through crowd-sourcing. This dataset includes multiple cause-effect pairs within a directed acyclic graph (DAG) structure. Our analysis reveals that traditional loss functions can struggle to effectively incorporate the DAG structure, leading us to propose a causality-enhanced method called Exponential Maximum Average Treatment Effect (ExMATE) to enhance the impact of causality at the utterance level in training neural conversation models. To evaluate the effectiveness of this approach, we have built a comprehensive benchmark using the CausalDialogue dataset leveraging large-scale pre-trained language models, and have assessed the results through both human and automatic evaluation metrics for coherence, diversity, and agility. Our findings show that current techniques are still unable to effectively address conversational DAGs, and that the ExMATE method can improve the diversity and agility of conventional loss functions while maintaining coherence.","link":"http://arxiv.org/abs/2212.10515v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"CausalDialogue: Modeling Utterance-level Causality in Conversations Despite their widespread adoption, neural conversation models have yet to exhibit natural chat capabilities with humans. In this research, we examine user utterances as causes and generated responses as effects, recognizing that changes in a cause should produce a different effect. To further explore this concept, we have compiled and expanded upon a new dataset called CausalDialogue through crowd-sourcing. This dataset includes multiple cause-effect pairs within a directed acyclic graph (DAG) structure. Our analysis reveals that traditional loss functions can struggle to effectively incorporate the DAG structure, leading us to propose a causality-enhanced method called Exponential Maximum Average Treatment Effect (ExMATE) to enhance the impact of causality at the utterance level in training neural conversation models. To evaluate the effectiveness of this approach, we have built a comprehensive benchmark using the CausalDialogue dataset leveraging large-scale pre-trained language models, and have assessed the results through both human and automatic evaluation metrics for coherence, diversity, and agility. Our findings show that current techniques are still unable to effectively address conversational DAGs, and that the ExMATE method can improve the diversity and agility of conventional loss functions while maintaining coherence.","classes":{"dataset":0.4581467211}}
{"title":"HouseCat6D -- A Large-Scale Multi-Modal Category Level 6D Object Pose Dataset with Household Objects in Realistic Scenarios","description":"Estimating the 6D pose of objects is one of the major fields in 3D computer vision. Since the promising outcomes from instance-level pose estimation, the research trends are heading towards category-level pose estimation for more practical application scenarios. However, unlike well-established instance-level pose datasets, available category-level datasets lack annotation quality and provided pose quantity. We propose the new category level 6D pose dataset HouseCat6D featuring 1) Multi-modality of Polarimetric RGB+P and Depth, 2) Highly diverse 194 objects of 10 household object categories including 2 photometrically challenging categories, 3) High-quality pose annotation with an error range of only 1.35 mm to 1.74 mm, 4) 41 large scale scenes with extensive viewpoint coverage, 5) Checkerboard-free environment throughout the entire scene. We also provide benchmark results of state-of-the-art category-level pose estimation networks.","link":"http://arxiv.org/abs/2212.10428v2","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"HouseCat6D -- A Large-Scale Multi-Modal Category Level 6D Object Pose Dataset with Household Objects in Realistic Scenarios Estimating the 6D pose of objects is one of the major fields in 3D computer vision. Since the promising outcomes from instance-level pose estimation, the research trends are heading towards category-level pose estimation for more practical application scenarios. However, unlike well-established instance-level pose datasets, available category-level datasets lack annotation quality and provided pose quantity. We propose the new category level 6D pose dataset HouseCat6D featuring 1) Multi-modality of Polarimetric RGB+P and Depth, 2) Highly diverse 194 objects of 10 household object categories including 2 photometrically challenging categories, 3) High-quality pose annotation with an error range of only 1.35 mm to 1.74 mm, 4) 41 large scale scenes with extensive viewpoint coverage, 5) Checkerboard-free environment throughout the entire scene. We also provide benchmark results of state-of-the-art category-level pose estimation networks.","classes":{"dataset":0.9781711698}}
{"title":"Berlin V2X: A Machine Learning Dataset from Multiple Vehicles and Radio Access Technologies","description":"The evolution of wireless communications into 6G and beyond is expected to rely on new machine learning (ML)-based capabilities. These can enable proactive decisions and actions from wireless-network components to sustain quality-of-service (QoS) and user experience. Moreover, new use cases in the area of vehicular and industrial communications will emerge. Specifically in the area of vehicle communication, vehicle-to-everything (V2X) schemes will benefit strongly from such advances. With this in mind, we have conducted a detailed measurement campaign with the purpose of enabling a plethora of diverse ML-based studies. The resulting datasets offer GPS-located wireless measurements across diverse urban environments for both cellular (with two different operators) and sidelink radio access technologies, thus enabling a variety of different studies towards V2X. The datasets are labeled and sampled with a high time resolution. Furthermore, we make the data publicly available with all the necessary information to support the on-boarding of new researchers. We provide an initial analysis of the data showing some of the challenges that ML needs to overcome and the features that ML can leverage, as well as some hints at potential research studies.","link":"http://arxiv.org/abs/2212.10343v2","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Berlin V2X: A Machine Learning Dataset from Multiple Vehicles and Radio Access Technologies The evolution of wireless communications into 6G and beyond is expected to rely on new machine learning (ML)-based capabilities. These can enable proactive decisions and actions from wireless-network components to sustain quality-of-service (QoS) and user experience. Moreover, new use cases in the area of vehicular and industrial communications will emerge. Specifically in the area of vehicle communication, vehicle-to-everything (V2X) schemes will benefit strongly from such advances. With this in mind, we have conducted a detailed measurement campaign with the purpose of enabling a plethora of diverse ML-based studies. The resulting datasets offer GPS-located wireless measurements across diverse urban environments for both cellular (with two different operators) and sidelink radio access technologies, thus enabling a variety of different studies towards V2X. The datasets are labeled and sampled with a high time resolution. Furthermore, we make the data publicly available with all the necessary information to support the on-boarding of new researchers. We provide an initial analysis of the data showing some of the challenges that ML needs to overcome and the features that ML can leverage, as well as some hints at potential research studies.","classes":{"dataset":0.0524640679}}
{"title":"Graph Neural Networks in Computer Vision -- Architectures, Datasets and Common Approaches","description":"Graph Neural Networks (GNNs) are a family of graph networks inspired by mechanisms existing between nodes on a graph. In recent years there has been an increased interest in GNN and their derivatives, i.e., Graph Attention Networks (GAT), Graph Convolutional Networks (GCN), and Graph Recurrent Networks (GRN). An increase in their usability in computer vision is also observed. The number of GNN applications in this field continues to expand; it includes video analysis and understanding, action and behavior recognition, computational photography, image and video synthesis from zero or few shots, and many more. This contribution aims to collect papers published about GNN-based approaches towards computer vision. They are described and summarized from three perspectives. Firstly, we investigate the architectures of Graph Neural Networks and their derivatives used in this area to provide accurate and explainable recommendations for the ensuing investigations. As for the other aspect, we also present datasets used in these works. Finally, using graph analysis, we also examine relations between GNN-based studies in computer vision and potential sources of inspiration identified outside of this field.","link":"http://arxiv.org/abs/2212.10207v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Graph Neural Networks in Computer Vision -- Architectures, Datasets and Common Approaches Graph Neural Networks (GNNs) are a family of graph networks inspired by mechanisms existing between nodes on a graph. In recent years there has been an increased interest in GNN and their derivatives, i.e., Graph Attention Networks (GAT), Graph Convolutional Networks (GCN), and Graph Recurrent Networks (GRN). An increase in their usability in computer vision is also observed. The number of GNN applications in this field continues to expand; it includes video analysis and understanding, action and behavior recognition, computational photography, image and video synthesis from zero or few shots, and many more. This contribution aims to collect papers published about GNN-based approaches towards computer vision. They are described and summarized from three perspectives. Firstly, we investigate the architectures of Graph Neural Networks and their derivatives used in this area to provide accurate and explainable recommendations for the ensuing investigations. As for the other aspect, we also present datasets used in these works. Finally, using graph analysis, we also examine relations between GNN-based studies in computer vision and potential sources of inspiration identified outside of this field.","classes":{"dataset":0.3415586054}}
{"title":"IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for Indian Languages","description":"The rapid growth of machine translation (MT) systems has necessitated comprehensive studies to meta-evaluate evaluation metrics being used, which enables a better selection of metrics that best reflect MT quality. Unfortunately, most of the research focuses on high-resource languages, mainly English, the observations for which may not always apply to other languages. Indian languages, having over a billion speakers, are linguistically different from English, and to date, there has not been a systematic study of evaluating MT systems from English into Indian languages. In this paper, we fill this gap by creating an MQM dataset consisting of 7000 fine-grained annotations, spanning 5 Indian languages and 7 MT systems, and use it to establish correlations between annotator scores and scores obtained using existing automatic metrics. Our results show that pre-trained metrics, such as COMET, have the highest correlations with annotator scores. Additionally, we find that the metrics do not adequately capture fluency-based errors in Indian languages, and there is a need to develop metrics focused on Indian languages. We hope that our dataset and analysis will help promote further research in this area.","link":"http://arxiv.org/abs/2212.10180v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for Indian Languages The rapid growth of machine translation (MT) systems has necessitated comprehensive studies to meta-evaluate evaluation metrics being used, which enables a better selection of metrics that best reflect MT quality. Unfortunately, most of the research focuses on high-resource languages, mainly English, the observations for which may not always apply to other languages. Indian languages, having over a billion speakers, are linguistically different from English, and to date, there has not been a systematic study of evaluating MT systems from English into Indian languages. In this paper, we fill this gap by creating an MQM dataset consisting of 7000 fine-grained annotations, spanning 5 Indian languages and 7 MT systems, and use it to establish correlations between annotator scores and scores obtained using existing automatic metrics. Our results show that pre-trained metrics, such as COMET, have the highest correlations with annotator scores. Additionally, we find that the metrics do not adequately capture fluency-based errors in Indian languages, and there is a need to develop metrics focused on Indian languages. We hope that our dataset and analysis will help promote further research in this area.","classes":{"dataset":0.9702904224}}
{"title":"Efficient aggregation of face embeddings for decentralized face recognition deployments (extended version)","description":"Biometrics are one of the most privacy-sensitive data. Ubiquitous authentication systems with a focus on privacy favor decentralized approaches as they reduce potential attack vectors, both on a technical and organizational level. The gold standard is to let the user be in control of where their own data is stored, which consequently leads to a high variety of devices used. Moreover, in comparison with a centralized system, designs with higher end-user freedom often incur additional network overhead. Therefore, when using face recognition for biometric authentication, an efficient way to compare faces is important in practical deployments, because it reduces both network and hardware requirements that are essential to encourage device diversity. This paper proposes an efficient way to aggregate embeddings used for face recognition based on an extensive analysis on different datasets and the use of different aggregation strategies. As part of this analysis, a new dataset has been collected, which is available for research purposes. Our proposed method supports the construction of massively scalable, decentralized face recognition systems with a focus on both privacy and long-term usability.","link":"http://arxiv.org/abs/2212.10108v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Efficient aggregation of face embeddings for decentralized face recognition deployments (extended version) Biometrics are one of the most privacy-sensitive data. Ubiquitous authentication systems with a focus on privacy favor decentralized approaches as they reduce potential attack vectors, both on a technical and organizational level. The gold standard is to let the user be in control of where their own data is stored, which consequently leads to a high variety of devices used. Moreover, in comparison with a centralized system, designs with higher end-user freedom often incur additional network overhead. Therefore, when using face recognition for biometric authentication, an efficient way to compare faces is important in practical deployments, because it reduces both network and hardware requirements that are essential to encourage device diversity. This paper proposes an efficient way to aggregate embeddings used for face recognition based on an extensive analysis on different datasets and the use of different aggregation strategies. As part of this analysis, a new dataset has been collected, which is available for research purposes. Our proposed method supports the construction of massively scalable, decentralized face recognition systems with a focus on both privacy and long-term usability.","classes":{"dataset":0.965739131}}
{"title":"Benchmarking person re-identification datasets and approaches for practical real-world implementations","description":"Recently, Person Re-Identification (Re-ID) has received a lot of attention. Large datasets containing labeled images of various individuals have been released, allowing researchers to develop and test many successful approaches. However, when such Re-ID models are deployed in new cities or environments, the task of searching for people within a network of security cameras is likely to face an important domain shift, thus resulting in decreased performance. Indeed, while most public datasets were collected in a limited geographic area, images from a new city present different features (e.g., people's ethnicity and clothing style, weather, architecture, etc.). In addition, the whole frames of the video streams must be converted into cropped images of people using pedestrian detection models, which behave differently from the human annotators who created the dataset used for training. To better understand the extent of this issue, this paper introduces a complete methodology to evaluate Re-ID approaches and training datasets with respect to their suitability for unsupervised deployment for live operations. This method is used to benchmark four Re-ID approaches on three datasets, providing insight and guidelines that can help to design better Re-ID pipelines in the future.","link":"http://arxiv.org/abs/2212.09981v1","created":"2022-12-20","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Benchmarking person re-identification datasets and approaches for practical real-world implementations Recently, Person Re-Identification (Re-ID) has received a lot of attention. Large datasets containing labeled images of various individuals have been released, allowing researchers to develop and test many successful approaches. However, when such Re-ID models are deployed in new cities or environments, the task of searching for people within a network of security cameras is likely to face an important domain shift, thus resulting in decreased performance. Indeed, while most public datasets were collected in a limited geographic area, images from a new city present different features (e.g., people's ethnicity and clothing style, weather, architecture, etc.). In addition, the whole frames of the video streams must be converted into cropped images of people using pedestrian detection models, which behave differently from the human annotators who created the dataset used for training. To better understand the extent of this issue, this paper introduces a complete methodology to evaluate Re-ID approaches and training datasets with respect to their suitability for unsupervised deployment for live operations. This method is used to benchmark four Re-ID approaches on three datasets, providing insight and guidelines that can help to design better Re-ID pipelines in the future.","classes":{"dataset":0.03063103}}
{"title":"A Physically-Consistent Chemical Dataset for the Simulation of N$_2$-CH$_4$ Shocked Flows Up to T=100,000K","description":"In the previous work carried out in the scope of the \\emph{Validation of Aerothermochemistry Models for Re-Entry Applications}, it was verified that the G\\\"{o}k\\c{c}en chemical dataset provided increasingly diverging results from experiments, as one considered shock speeds in excess of 5\\kilo\\metre\\per\\second. Namely, for shock velocities between 7 and 9\\kilo\\metre\\per\\second, more than one temporal peak in CN Violet radiation were predicted by models considering this kinetic dataset, in contradiction with experiments. This hinted at several of the rates from the dataset not being directly applicable in the temperature range of interest for such applications, often in excess of 10,000\\kelvin. Indeed, it has been found that several macroscopic rates from the G\\\"{o}k\\c{c}en chemical dataset reached unphysical values at very high temperatures. Furthermore, many of the ionization rates have been found to be inadequate for the simulation of high-temperature N$_{2}$--CH$_{4}$ shocked flows. Here, we have carried an extensive update of the G\\\"{o}k\\c{c}en chemical dataset, with the aim of at least reaching physically consistent rates for the whole T=100-100,000\\kelvin\\ temperature range. While it cannot really be claimed that such improved dataset is validated in such an extended temperature range (due to the scarcely available experimental data for such high temperature ranges), it is capable of providing more accurate simulations of high-speed shocked flows for this mixture, when compared to the G\\\"{o}k\\c{c}en chemical dataset.","link":"http://arxiv.org/abs/2212.09911v1","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A Physically-Consistent Chemical Dataset for the Simulation of N$_2$-CH$_4$ Shocked Flows Up to T=100,000K In the previous work carried out in the scope of the \\emph{Validation of Aerothermochemistry Models for Re-Entry Applications}, it was verified that the G\\\"{o}k\\c{c}en chemical dataset provided increasingly diverging results from experiments, as one considered shock speeds in excess of 5\\kilo\\metre\\per\\second. Namely, for shock velocities between 7 and 9\\kilo\\metre\\per\\second, more than one temporal peak in CN Violet radiation were predicted by models considering this kinetic dataset, in contradiction with experiments. This hinted at several of the rates from the dataset not being directly applicable in the temperature range of interest for such applications, often in excess of 10,000\\kelvin. Indeed, it has been found that several macroscopic rates from the G\\\"{o}k\\c{c}en chemical dataset reached unphysical values at very high temperatures. Furthermore, many of the ionization rates have been found to be inadequate for the simulation of high-temperature N$_{2}$--CH$_{4}$ shocked flows. Here, we have carried an extensive update of the G\\\"{o}k\\c{c}en chemical dataset, with the aim of at least reaching physically consistent rates for the whole T=100-100,000\\kelvin\\ temperature range. While it cannot really be claimed that such improved dataset is validated in such an extended temperature range (due to the scarcely available experimental data for such high temperature ranges), it is capable of providing more accurate simulations of high-speed shocked flows for this mixture, when compared to the G\\\"{o}k\\c{c}en chemical dataset.","classes":{"dataset":0.0296069402}}
{"title":"Managing Large Dataset Gaps in Urban Air Quality Prediction: DCU-Insight-AQ at MediaEval 2022","description":"Calculating an Air Quality Index (AQI) typically uses data streams from air quality sensors deployed at fixed locations and the calculation is a real time process. If one or a number of sensors are broken or offline, then the real time AQI value cannot be computed. Estimating AQI values for some point in the future is a predictive process and uses historical AQI values to train and build models. In this work we focus on gap filling in air quality data where the task is to predict the AQI at 1, 5 and 7 days into the future. The scenario is where one or a number of air, weather and traffic sensors are offline and explores prediction accuracy under such situations. The work is part of the MediaEval'2022 Urban Air: Urban Life and Air Pollution task submitted by the DCU-Insight-AQ team and uses multimodal and crossmodal data consisting of AQI, weather and CCTV traffic images for air pollution prediction.","link":"http://arxiv.org/abs/2212.10273v1","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Managing Large Dataset Gaps in Urban Air Quality Prediction: DCU-Insight-AQ at MediaEval 2022 Calculating an Air Quality Index (AQI) typically uses data streams from air quality sensors deployed at fixed locations and the calculation is a real time process. If one or a number of sensors are broken or offline, then the real time AQI value cannot be computed. Estimating AQI values for some point in the future is a predictive process and uses historical AQI values to train and build models. In this work we focus on gap filling in air quality data where the task is to predict the AQI at 1, 5 and 7 days into the future. The scenario is where one or a number of air, weather and traffic sensors are offline and explores prediction accuracy under such situations. The work is part of the MediaEval'2022 Urban Air: Urban Life and Air Pollution task submitted by the DCU-Insight-AQ team and uses multimodal and crossmodal data consisting of AQI, weather and CCTV traffic images for air pollution prediction.","classes":{"dataset":0.9600949883}}
{"title":"E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text","description":"Identifying named entities such as a person, location or organization, in documents can highlight key information to readers. Training Named Entity Recognition (NER) models requires an annotated data set, which can be a time-consuming labour-intensive task. Nevertheless, there are publicly available NER data sets for general English. Recently there has been interest in developing NER for legal text. However, prior work and experimental results reported here indicate that there is a significant degradation in performance when NER methods trained on a general English data set are applied to legal text. We describe a publicly available legal NER data set, called E-NER, based on legal company filings available from the US Securities and Exchange Commission's EDGAR data set. Training a number of different NER algorithms on the general English CoNLL-2003 corpus but testing on our test collection confirmed significant degradations in accuracy, as measured by the F1-score, of between 29.4\\% and 60.4\\%, compared to training and testing on the E-NER collection.","link":"http://arxiv.org/abs/2212.09306v1","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text Identifying named entities such as a person, location or organization, in documents can highlight key information to readers. Training Named Entity Recognition (NER) models requires an annotated data set, which can be a time-consuming labour-intensive task. Nevertheless, there are publicly available NER data sets for general English. Recently there has been interest in developing NER for legal text. However, prior work and experimental results reported here indicate that there is a significant degradation in performance when NER methods trained on a general English data set are applied to legal text. We describe a publicly available legal NER data set, called E-NER, based on legal company filings available from the US Securities and Exchange Commission's EDGAR data set. Training a number of different NER algorithms on the general English CoNLL-2003 corpus but testing on our test collection confirmed significant degradations in accuracy, as measured by the F1-score, of between 29.4\\% and 60.4\\%, compared to training and testing on the E-NER collection.","classes":{"dataset":0.0508814938}}
{"title":"UAVCAN Dataset Description","description":"We collected attack data from unmanned vehicles using the UAVCAN protocol, and public and described technical documents. A testbed was built with a drone using PX4, and a total of three attacks, Flooding, Fuzzy, and Replay, were performed. The attack was carried out in a total of 10 scenarios. We expect that the attack data will help develop technologies such as anomaly detection to solve the security threat problem of drones.","link":"http://arxiv.org/abs/2212.09268v1","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"UAVCAN Dataset Description We collected attack data from unmanned vehicles using the UAVCAN protocol, and public and described technical documents. A testbed was built with a drone using PX4, and a total of three attacks, Flooding, Fuzzy, and Replay, were performed. The attack was carried out in a total of 10 scenarios. We expect that the attack data will help develop technologies such as anomaly detection to solve the security threat problem of drones.","classes":{"dataset":0.5280815363}}
{"title":"Modeling and Performance Analysis of Single-Server Database Over Quasi-static Rayleigh Fading Channel","description":"Cloud database is the key technology in cloud computing. The effective and efficient service quality of the cloud database is inseparable from communication technology, just as improving communication quality will reduce the concurrency phenomenon in the ticketing system. In order to visually observe the impact of communication on the cloud database, we propose a Communication-Database (C-D) Model with a single-server database over the quasi-static Rayleigh fading channel, which consists of three parts: CLIENTS SOURCE, COMMUNICATION SYSTEM and DATABASE SYSTEM. This paper uses the queuing model, M/G/1//K, to model the whole system. The C-D Model is analyzed in two cases: nonlinearity and linearity, which correspond to some instances of SISO and MIMO. The simulation results of average staying time, average number of transactions and other performance characteristics are basically consistent with the theoretical results, which verifies the validity of the C-D Model. The comparison of these experimental results also proves that poor communication quality does lead to the reduction in the quality of service.","link":"http://arxiv.org/abs/2212.09219v3","created":"2022-12-19","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Modeling and Performance Analysis of Single-Server Database Over Quasi-static Rayleigh Fading Channel Cloud database is the key technology in cloud computing. The effective and efficient service quality of the cloud database is inseparable from communication technology, just as improving communication quality will reduce the concurrency phenomenon in the ticketing system. In order to visually observe the impact of communication on the cloud database, we propose a Communication-Database (C-D) Model with a single-server database over the quasi-static Rayleigh fading channel, which consists of three parts: CLIENTS SOURCE, COMMUNICATION SYSTEM and DATABASE SYSTEM. This paper uses the queuing model, M/G/1//K, to model the whole system. The C-D Model is analyzed in two cases: nonlinearity and linearity, which correspond to some instances of SISO and MIMO. The simulation results of average staying time, average number of transactions and other performance characteristics are basically consistent with the theoretical results, which verifies the validity of the C-D Model. The comparison of these experimental results also proves that poor communication quality does lead to the reduction in the quality of service.","classes":{"dataset":0.9846540093}}
{"title":"A Better Choice: Entire-space Datasets for Aspect Sentiment Triplet Extraction","description":"Aspect sentiment triplet extraction (ASTE) aims to extract aspect term, sentiment and opinion term triplets from sentences. Since the initial datasets used to evaluate models on ASTE had flaws, several studies later corrected the initial datasets and released new versions of the datasets independently. As a result, different studies select different versions of datasets to evaluate their methods, which makes ASTE-related works hard to follow. In this paper, we analyze the relation between different versions of datasets and suggest that the entire-space version should be used for ASTE. Besides the sentences containing triplets and the triplets in the sentences, the entire-space version additionally includes the sentences without triplets and the aspect terms which do not belong to any triplets. Hence, the entire-space version is consistent with real-world scenarios and evaluating models on the entire-space version can better reflect the models' performance in real-world scenarios. In addition, experimental results show that evaluating models on non-entire-space datasets inflates the performance of existing models and models trained on the entire-space version can obtain better performance.","link":"http://arxiv.org/abs/2212.09052v1","created":"2022-12-18","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A Better Choice: Entire-space Datasets for Aspect Sentiment Triplet Extraction Aspect sentiment triplet extraction (ASTE) aims to extract aspect term, sentiment and opinion term triplets from sentences. Since the initial datasets used to evaluate models on ASTE had flaws, several studies later corrected the initial datasets and released new versions of the datasets independently. As a result, different studies select different versions of datasets to evaluate their methods, which makes ASTE-related works hard to follow. In this paper, we analyze the relation between different versions of datasets and suggest that the entire-space version should be used for ASTE. Besides the sentences containing triplets and the triplets in the sentences, the entire-space version additionally includes the sentences without triplets and the aspect terms which do not belong to any triplets. Hence, the entire-space version is consistent with real-world scenarios and evaluating models on the entire-space version can better reflect the models' performance in real-world scenarios. In addition, experimental results show that evaluating models on non-entire-space datasets inflates the performance of existing models and models trained on the entire-space version can obtain better performance.","classes":{"dataset":0.9795715809}}
{"title":"Balanced Split: A new train-test data splitting strategy for imbalanced datasets","description":"Classification data sets with skewed class proportions are called imbalanced. Class imbalance is a problem since most machine learning classification algorithms are built with an assumption of equal representation of all classes in the training dataset. Therefore to counter the class imbalance problem, many algorithm-level and data-level approaches have been developed. These mainly include ensemble learning and data augmentation techniques. This paper shows a new way to counter the class imbalance problem through a new data-splitting strategy called balanced split. Data splitting can play an important role in correctly classifying imbalanced datasets. We show that the commonly used data-splitting strategies have some disadvantages, and our proposed balanced split has solved those problems.","link":"http://arxiv.org/abs/2212.11116v1","created":"2022-12-17","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Balanced Split: A new train-test data splitting strategy for imbalanced datasets Classification data sets with skewed class proportions are called imbalanced. Class imbalance is a problem since most machine learning classification algorithms are built with an assumption of equal representation of all classes in the training dataset. Therefore to counter the class imbalance problem, many algorithm-level and data-level approaches have been developed. These mainly include ensemble learning and data augmentation techniques. This paper shows a new way to counter the class imbalance problem through a new data-splitting strategy called balanced split. Data splitting can play an important role in correctly classifying imbalanced datasets. We show that the commonly used data-splitting strategies have some disadvantages, and our proposed balanced split has solved those problems.","classes":{"dataset":0.910595715}}
{"title":"Fine-grained Czech News Article Dataset: An Interdisciplinary Approach to Trustworthiness Analysis","description":"We present the Verifee Dataset: a novel dataset of news articles with fine-grained trustworthiness annotations. We develop a detailed methodology that assesses the texts based on their parameters encompassing editorial transparency, journalist conventions, and objective reporting while penalizing manipulative techniques. We bring aboard a diverse set of researchers from social, media, and computer sciences to overcome barriers and limited framing of this interdisciplinary problem. We collect over $10,000$ unique articles from almost $60$ Czech online news sources. These are categorized into one of the $4$ classes across the credibility spectrum we propose, raging from entirely trustworthy articles all the way to the manipulative ones. We produce detailed statistics and study trends emerging throughout the set. Lastly, we fine-tune multiple popular sequence-to-sequence language models using our dataset on the trustworthiness classification task and report the best testing F-1 score of $0.52$. We open-source the dataset, annotation methodology, and annotators' instructions in full length at https://verifee.ai/research to enable easy build-up work. We believe similar methods can help prevent disinformation and educate in the realm of media literacy.","link":"http://arxiv.org/abs/2212.08550v1","created":"2022-12-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Fine-grained Czech News Article Dataset: An Interdisciplinary Approach to Trustworthiness Analysis We present the Verifee Dataset: a novel dataset of news articles with fine-grained trustworthiness annotations. We develop a detailed methodology that assesses the texts based on their parameters encompassing editorial transparency, journalist conventions, and objective reporting while penalizing manipulative techniques. We bring aboard a diverse set of researchers from social, media, and computer sciences to overcome barriers and limited framing of this interdisciplinary problem. We collect over $10,000$ unique articles from almost $60$ Czech online news sources. These are categorized into one of the $4$ classes across the credibility spectrum we propose, raging from entirely trustworthy articles all the way to the manipulative ones. We produce detailed statistics and study trends emerging throughout the set. Lastly, we fine-tune multiple popular sequence-to-sequence language models using our dataset on the trustworthiness classification task and report the best testing F-1 score of $0.52$. We open-source the dataset, annotation methodology, and annotators' instructions in full length at https://verifee.ai/research to enable easy build-up work. We believe similar methods can help prevent disinformation and educate in the realm of media literacy.","classes":{"dataset":0.234220162}}
{"title":"Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion Behaviors in Social Deduction Games","description":"Persuasion modeling is a key building block for conversational agents. Existing works in this direction are limited to analyzing textual dialogue corpus. We argue that visual signals also play an important role in understanding human persuasive behaviors. In this paper, we introduce the first multimodal dataset for modeling persuasion behaviors. Our dataset includes 199 dialogue transcriptions and videos captured in a multi-player social deduction game setting, 26,647 utterance level annotations of persuasion strategy, and game level annotations of deduction game outcomes. We provide extensive experiments to show how dialogue context and visual signals benefit persuasion strategy prediction. We also explore the generalization ability of language models for persuasion modeling and the role of persuasion strategies in predicting social deduction game outcomes. Our dataset, code, and models can be found at https://persuasion-deductiongame.socialai-data.org.","link":"http://arxiv.org/abs/2212.08279v1","created":"2022-12-16","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion Behaviors in Social Deduction Games Persuasion modeling is a key building block for conversational agents. Existing works in this direction are limited to analyzing textual dialogue corpus. We argue that visual signals also play an important role in understanding human persuasive behaviors. In this paper, we introduce the first multimodal dataset for modeling persuasion behaviors. Our dataset includes 199 dialogue transcriptions and videos captured in a multi-player social deduction game setting, 26,647 utterance level annotations of persuasion strategy, and game level annotations of deduction game outcomes. We provide extensive experiments to show how dialogue context and visual signals benefit persuasion strategy prediction. We also explore the generalization ability of language models for persuasion modeling and the role of persuasion strategies in predicting social deduction game outcomes. Our dataset, code, and models can be found at https://persuasion-deductiongame.socialai-data.org.","classes":{"dataset":0.9761613011}}
{"title":"An Analysis of Variance of the Pantheon+ Dataset: Systematics in the Covariance Matrix?","description":"We investigate the statistics of the available Pantheon+ dataset. Noticing that the $\\chi^2$ value for the best-fit $\\Lambda$CDM model to the real data is small, we quantify how significant its smallness is by calculating the distribution of $\\chi^2$ values for the best-fit $\\Lambda$CDM model fit to mock Pantheon+-like datasets, using the provided covariance matrix. We further investigate the distribution of the residuals of the Pantheon+ dataset, with respect to the best-fit $\\Lambda$CDM model, and notice they scatter smaller than would be expected from the covariance matrix but find no significant amount of kurtosis. These results point to the conclusion that the Pantheon+ covariance matrix is over-estimated. One simple interpretation of these results is a $\\sim$5\\% overestimation of errors on SN distances in Pantheon+ data. When the covariance matrix is reduced by subtracting an intrinsic scatter term from the diagonal terms of the covariance matrix, the best-fit $\\chi^2$ for the $\\Lambda$CDM model achieves a normal value of 1580 and no deviation from $\\Lambda$CDM is detected. We further quantify how consistent the $\\Lambda$CDM model is with respect to the modified data with the subtracted covariance matrix using model independent reconstruction techniques such as the iterative smoothing method and we find that the standard model is consistent with the data.","link":"http://arxiv.org/abs/2212.07917v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"An Analysis of Variance of the Pantheon+ Dataset: Systematics in the Covariance Matrix? We investigate the statistics of the available Pantheon+ dataset. Noticing that the $\\chi^2$ value for the best-fit $\\Lambda$CDM model to the real data is small, we quantify how significant its smallness is by calculating the distribution of $\\chi^2$ values for the best-fit $\\Lambda$CDM model fit to mock Pantheon+-like datasets, using the provided covariance matrix. We further investigate the distribution of the residuals of the Pantheon+ dataset, with respect to the best-fit $\\Lambda$CDM model, and notice they scatter smaller than would be expected from the covariance matrix but find no significant amount of kurtosis. These results point to the conclusion that the Pantheon+ covariance matrix is over-estimated. One simple interpretation of these results is a $\\sim$5\\% overestimation of errors on SN distances in Pantheon+ data. When the covariance matrix is reduced by subtracting an intrinsic scatter term from the diagonal terms of the covariance matrix, the best-fit $\\chi^2$ for the $\\Lambda$CDM model achieves a normal value of 1580 and no deviation from $\\Lambda$CDM is detected. We further quantify how consistent the $\\Lambda$CDM model is with respect to the modified data with the subtracted covariance matrix using model independent reconstruction techniques such as the iterative smoothing method and we find that the standard model is consistent with the data.","classes":{"dataset":0.8940566182}}
{"title":"Balanced Datasets for IoT IDS","description":"As the Internet of Things (IoT) continues to grow, cyberattacks are becoming increasingly common. The security of IoT networks relies heavily on intrusion detection systems (IDSs). The development of an IDS that is accurate and efficient is a challenging task. As a result, this challenge is made more challenging by the absence of balanced datasets for training and testing the proposed IDS. In this study, four commonly used datasets are visualized and analyzed visually. Moreover, it proposes a sampling algorithm that generates a sample that represents the original dataset. In addition, it proposes an algorithm to generate a balanced dataset. Researchers can use this paper as a starting point when investigating cybersecurity and machine learning. The proposed sampling algorithms showed reliability in generating well-representing and balanced samples from NSL-KDD, UNSW-NB15, BotNetIoT-01, and BoTIoT datasets.","link":"http://arxiv.org/abs/2301.04008v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Balanced Datasets for IoT IDS As the Internet of Things (IoT) continues to grow, cyberattacks are becoming increasingly common. The security of IoT networks relies heavily on intrusion detection systems (IDSs). The development of an IDS that is accurate and efficient is a challenging task. As a result, this challenge is made more challenging by the absence of balanced datasets for training and testing the proposed IDS. In this study, four commonly used datasets are visualized and analyzed visually. Moreover, it proposes a sampling algorithm that generates a sample that represents the original dataset. In addition, it proposes an algorithm to generate a balanced dataset. Researchers can use this paper as a starting point when investigating cybersecurity and machine learning. The proposed sampling algorithms showed reliability in generating well-representing and balanced samples from NSL-KDD, UNSW-NB15, BotNetIoT-01, and BoTIoT datasets.","classes":{"dataset":0.0746815354}}
{"title":"A large-scale and PCR-referenced vocal audio dataset for COVID-19","description":"The UK COVID-19 Vocal Audio Dataset is designed for the training and evaluation of machine learning models that classify SARS-CoV-2 infection status or associated respiratory symptoms using vocal audio. The UK Health Security Agency recruited voluntary participants through the national Test and Trace programme and the REACT-1 survey in England from March 2021 to March 2022, during dominant transmission of the Alpha and Delta SARS-CoV-2 variants and some Omicron variant sublineages. Audio recordings of volitional coughs, exhalations, and speech were collected in the 'Speak up to help beat coronavirus' digital survey alongside demographic, self-reported symptom and respiratory condition data, and linked to SARS-CoV-2 test results. The UK COVID-19 Vocal Audio Dataset represents the largest collection of SARS-CoV-2 PCR-referenced audio recordings to date. PCR results were linked to 70,794 of 72,999 participants and 24,155 of 25,776 positive cases. Respiratory symptoms were reported by 45.62% of participants. This dataset has additional potential uses for bioacoustics research, with 11.30% participants reporting asthma, and 27.20% with linked influenza PCR test results.","link":"http://arxiv.org/abs/2212.07738v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A large-scale and PCR-referenced vocal audio dataset for COVID-19 The UK COVID-19 Vocal Audio Dataset is designed for the training and evaluation of machine learning models that classify SARS-CoV-2 infection status or associated respiratory symptoms using vocal audio. The UK Health Security Agency recruited voluntary participants through the national Test and Trace programme and the REACT-1 survey in England from March 2021 to March 2022, during dominant transmission of the Alpha and Delta SARS-CoV-2 variants and some Omicron variant sublineages. Audio recordings of volitional coughs, exhalations, and speech were collected in the 'Speak up to help beat coronavirus' digital survey alongside demographic, self-reported symptom and respiratory condition data, and linked to SARS-CoV-2 test results. The UK COVID-19 Vocal Audio Dataset represents the largest collection of SARS-CoV-2 PCR-referenced audio recordings to date. PCR results were linked to 70,794 of 72,999 participants and 24,155 of 25,776 positive cases. Respiratory symptoms were reported by 45.62% of participants. This dataset has additional potential uses for bioacoustics research, with 11.30% participants reporting asthma, and 27.20% with linked influenza PCR test results.","classes":{"dataset":0.2614074051}}
{"title":"The negligible impact of experimental inconsistencies in the NNPDF4.0 global dataset","description":"As both predictions and measurements of high-energy physics observables become more precise, controlling all sources of uncertainties in determinations of parton distribution functions (PDFs) becomes increasingly important. One source of PDF uncertainty is the result of data not being consistent under a chosen theoretical framework. In these proceedings we investigate the impact these inconsistencies present in the global NNPDF4.0 dataset. We show that, when accounting for missing higher order uncertainties, the missing contribution to the PDF uncertainty due to data inconsistencies are at the level of statistical fluctuations.","link":"http://arxiv.org/abs/2212.07703v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"The negligible impact of experimental inconsistencies in the NNPDF4.0 global dataset As both predictions and measurements of high-energy physics observables become more precise, controlling all sources of uncertainties in determinations of parton distribution functions (PDFs) becomes increasingly important. One source of PDF uncertainty is the result of data not being consistent under a chosen theoretical framework. In these proceedings we investigate the impact these inconsistencies present in the global NNPDF4.0 dataset. We show that, when accounting for missing higher order uncertainties, the missing contribution to the PDF uncertainty due to data inconsistencies are at the level of statistical fluctuations.","classes":{"dataset":0.5330231786}}
{"title":"TED: Towards Discovering Top-k Edge-Diversified Patterns in a Graph Database","description":"With an exponentially growing number of graphs from disparate repositories, there is a strong need to analyze a graph database containing an extensive collection of small- or medium-sized data graphs (e.g., chemical compounds). Although subgraph enumeration and subgraph mining have been proposed to bring insights into a graph database by a set of subgraph structures, they often end up with similar or homogenous topologies, which is undesirable in many graph applications. To address this limitation, we propose the Top-k Edge-Diversified Patterns Discovery problem to retrieve a set of subgraphs that cover the maximum number of edges in a database. To efficiently process such query, we present a generic and extensible framework called Ted which achieves a guaranteed approximation ratio to the optimal result. Two optimization strategies are further developed to improve the performance. Experimental studies on real-world datasets demonstrate the superiority of Ted to traditional techniques.","link":"http://arxiv.org/abs/2212.07612v1","created":"2022-12-15","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"TED: Towards Discovering Top-k Edge-Diversified Patterns in a Graph Database With an exponentially growing number of graphs from disparate repositories, there is a strong need to analyze a graph database containing an extensive collection of small- or medium-sized data graphs (e.g., chemical compounds). Although subgraph enumeration and subgraph mining have been proposed to bring insights into a graph database by a set of subgraph structures, they often end up with similar or homogenous topologies, which is undesirable in many graph applications. To address this limitation, we propose the Top-k Edge-Diversified Patterns Discovery problem to retrieve a set of subgraphs that cover the maximum number of edges in a database. To efficiently process such query, we present a generic and extensible framework called Ted which achieves a guaranteed approximation ratio to the optimal result. Two optimization strategies are further developed to improve the performance. Experimental studies on real-world datasets demonstrate the superiority of Ted to traditional techniques.","classes":{"dataset":0.0579474792}}
{"title":"Building and Evaluating Universal Named-Entity Recognition English corpus","description":"This article presents the application of the Universal Named Entity framework to generate automatically annotated corpora. By using a workflow that extracts Wikipedia data and meta-data and DBpedia information, we generated an English dataset which is described and evaluated. Furthermore, we conducted a set of experiments to improve the annotations in terms of precision, recall, and F1-measure. The final dataset is available and the established workflow can be applied to any language with existing Wikipedia and DBpedia. As part of future research, we intend to continue improving the annotation process and extend it to other languages.","link":"http://arxiv.org/abs/2212.07162v1","created":"2022-12-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Building and Evaluating Universal Named-Entity Recognition English corpus This article presents the application of the Universal Named Entity framework to generate automatically annotated corpora. By using a workflow that extracts Wikipedia data and meta-data and DBpedia information, we generated an English dataset which is described and evaluated. Furthermore, we conducted a set of experiments to improve the annotations in terms of precision, recall, and F1-measure. The final dataset is available and the established workflow can be applied to any language with existing Wikipedia and DBpedia. As part of future research, we intend to continue improving the annotation process and extend it to other languages.","classes":{"dataset":0.9575579762}}
{"title":"Decoding Multi-class Motor-related Intentions with User-optimized and Robust BCI System Based on Multimodal Dataset","description":"A brain-computer interface (BCI) based on electroencephalography (EEG) can be useful for rehabilitation and the control of external devices. Five grasping tasks were decoded for motor execution (ME) and motor imagery (MI). During this experiment, eight healthy subjects were asked to imagine and grasp five objects. Analysis of EEG signals was performed after detecting muscle signals on electromyograms (EMG) with a time interval selection technique on data taken from these ME and MI experiments. By refining only data corresponding to the exact time when the users performed the motor intention, the proposed method can train the decoding model using only the EEG data generated by various motor intentions with strong correlation with a specific class. There was an accuracy of 70.73% for ME and 47.95% for MI for the five offline tasks. This method may be applied to future applications, such as controlling robot hands with BCIs.","link":"http://arxiv.org/abs/2212.07083v1","created":"2022-12-14","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Decoding Multi-class Motor-related Intentions with User-optimized and Robust BCI System Based on Multimodal Dataset A brain-computer interface (BCI) based on electroencephalography (EEG) can be useful for rehabilitation and the control of external devices. Five grasping tasks were decoded for motor execution (ME) and motor imagery (MI). During this experiment, eight healthy subjects were asked to imagine and grasp five objects. Analysis of EEG signals was performed after detecting muscle signals on electromyograms (EMG) with a time interval selection technique on data taken from these ME and MI experiments. By refining only data corresponding to the exact time when the users performed the motor intention, the proposed method can train the decoding model using only the EEG data generated by various motor intentions with strong correlation with a specific class. There was an accuracy of 70.73% for ME and 47.95% for MI for the five offline tasks. This method may be applied to future applications, such as controlling robot hands with BCIs.","classes":{"dataset":0.0035116}}
{"title":"Paraphrase Identification with Deep Learning: A Review of Datasets and Methods","description":"The rapid advancement of AI technology has made text generation tools like GPT-3 and ChatGPT increasingly accessible, scalable, and effective. This can pose serious threat to the credibility of various forms of media if these technologies are used for plagiarism, including scientific literature and news sources. Despite the development of automated methods for paraphrase identification, detecting this type of plagiarism remains a challenge due to the disparate nature of the datasets on which these methods are trained. In this study, we review traditional and current approaches to paraphrase identification and propose a refined typology of paraphrases. We also investigate how this typology is represented in popular datasets and how under-representation of certain types of paraphrases impacts detection capabilities. Finally, we outline new directions for future research and datasets in the pursuit of more effective paraphrase detection using AI.","link":"http://arxiv.org/abs/2212.06933v1","created":"2022-12-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Paraphrase Identification with Deep Learning: A Review of Datasets and Methods The rapid advancement of AI technology has made text generation tools like GPT-3 and ChatGPT increasingly accessible, scalable, and effective. This can pose serious threat to the credibility of various forms of media if these technologies are used for plagiarism, including scientific literature and news sources. Despite the development of automated methods for paraphrase identification, detecting this type of plagiarism remains a challenge due to the disparate nature of the datasets on which these methods are trained. In this study, we review traditional and current approaches to paraphrase identification and propose a refined typology of paraphrases. We also investigate how this typology is represented in popular datasets and how under-representation of certain types of paraphrases impacts detection capabilities. Finally, we outline new directions for future research and datasets in the pursuit of more effective paraphrase detection using AI.","classes":{"dataset":0.0201662127}}
{"title":"A Comprehensive Dataset of Grains for Granular Jamming in Soft Robotics: Grip Strength and Shock Absorption","description":"We test grip strength and shock absorption properties of various granular material in granular jamming robotic components. The granular material comprises a range of natural, manufactured, and 3D printed material encompassing a wide range of shapes, sizes, and Shore hardness. Two main experiments are considered, both representing compelling use cases for granular jamming in soft robotics. The first experiment measures grip strength (retention force measured in Newtons) when we fill a latex balloon with the chosen grain type and use it as a granular jamming gripper to pick up a range of test objects. The second experiment measures shock absorption properties recorded by an Inertial Measurement Unit which is suspended in an envelope of granular material and dropped from a set height. Our results highlight a range of shape, size and softness effects, including that grain deformability is a key determinant of grip strength, and interestingly, that larger grain sizes in 3D printed grains create better shock absorbing materials.","link":"http://arxiv.org/abs/2212.06511v1","created":"2022-12-13","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"A Comprehensive Dataset of Grains for Granular Jamming in Soft Robotics: Grip Strength and Shock Absorption We test grip strength and shock absorption properties of various granular material in granular jamming robotic components. The granular material comprises a range of natural, manufactured, and 3D printed material encompassing a wide range of shapes, sizes, and Shore hardness. Two main experiments are considered, both representing compelling use cases for granular jamming in soft robotics. The first experiment measures grip strength (retention force measured in Newtons) when we fill a latex balloon with the chosen grain type and use it as a granular jamming gripper to pick up a range of test objects. The second experiment measures shock absorption properties recorded by an Inertial Measurement Unit which is suspended in an envelope of granular material and dropped from a set height. Our results highlight a range of shape, size and softness effects, including that grain deformability is a key determinant of grip strength, and interestingly, that larger grain sizes in 3D printed grains create better shock absorbing materials.","classes":{"dataset":0.0873023495}}
{"title":"Comparison Of Deep Object Detectors On A New Vulnerable Pedestrian Dataset","description":"Pedestrian safety is one primary concern in autonomous driving. The under-representation of vulnerable groups in today's pedestrian datasets points to an urgent need for a dataset of vulnerable road users. In this paper, we first introduce a new vulnerable pedestrian detection dataset, BG Vulnerable Pedestrian (BGVP) dataset to help train well-rounded models and thus induce research to increase the efficacy of vulnerable pedestrian detection. The dataset includes four classes, i.e., Children Without Disability, Elderly without Disability, With Disability, and Non-Vulnerable. This dataset consists of images collected from the public domain and manually-annotated bounding boxes. In addition, on the proposed dataset, we have trained and tested five state-of-the-art object detection models, i.e., YOLOv4, YOLOv5, YOLOX, Faster R-CNN, and EfficientDet. Our results indicate that YOLOX and YOLOv4 perform the best on our dataset, YOLOv4 scoring 0.7999 and YOLOX scoring 0.7779 on the mAP 0.5 metric, while YOLOX outperforms YOLOv4 by 3.8 percent on the mAP 0.5:0.95 metric. Generally speaking, all five detectors do well predicting the With Disability class and perform poorly in the Elderly Without Disability class. YOLOX consistently outperforms all other detectors on the mAP (0.5:0.95) per class metric, obtaining 0.5644, 0.5242, 0.4781, and 0.6796 for Children Without Disability, Elderly Without Disability, Non-vulnerable, and With Disability, respectively. Our dataset and codes are available at https://github.com/devvansh1997/BGVP.","link":"http://arxiv.org/abs/2212.06218v1","created":"2022-12-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Comparison Of Deep Object Detectors On A New Vulnerable Pedestrian Dataset Pedestrian safety is one primary concern in autonomous driving. The under-representation of vulnerable groups in today's pedestrian datasets points to an urgent need for a dataset of vulnerable road users. In this paper, we first introduce a new vulnerable pedestrian detection dataset, BG Vulnerable Pedestrian (BGVP) dataset to help train well-rounded models and thus induce research to increase the efficacy of vulnerable pedestrian detection. The dataset includes four classes, i.e., Children Without Disability, Elderly without Disability, With Disability, and Non-Vulnerable. This dataset consists of images collected from the public domain and manually-annotated bounding boxes. In addition, on the proposed dataset, we have trained and tested five state-of-the-art object detection models, i.e., YOLOv4, YOLOv5, YOLOX, Faster R-CNN, and EfficientDet. Our results indicate that YOLOX and YOLOv4 perform the best on our dataset, YOLOv4 scoring 0.7999 and YOLOX scoring 0.7779 on the mAP 0.5 metric, while YOLOX outperforms YOLOv4 by 3.8 percent on the mAP 0.5:0.95 metric. Generally speaking, all five detectors do well predicting the With Disability class and perform poorly in the Elderly Without Disability class. YOLOX consistently outperforms all other detectors on the mAP (0.5:0.95) per class metric, obtaining 0.5644, 0.5242, 0.4781, and 0.6796 for Children Without Disability, Elderly Without Disability, Non-vulnerable, and With Disability, respectively. Our dataset and codes are available at https://github.com/devvansh1997/BGVP.","classes":{"dataset":0.985740006}}
{"title":"Siamese Neural Networks for Skin Cancer Classification and New Class Detection using Clinical and Dermoscopic Image Datasets","description":"Skin cancer is the most common malignancy in the world. Automated skin cancer detection would significantly improve early detection rates and prevent deaths. To help with this aim, a number of datasets have been released which can be used to train Deep Learning systems - these have produced impressive results for classification. However, this only works for the classes they are trained on whilst they are incapable of identifying skin lesions from previously unseen classes, making them unconducive for clinical use. We could look to massively increase the datasets by including all possible skin lesions, though this would always leave out some classes. Instead, we evaluate Siamese Neural Networks (SNNs), which not only allows us to classify images of skin lesions, but also allow us to identify those images which are different from the trained classes - allowing us to determine that an image is not an example of our training classes. We evaluate SNNs on both dermoscopic and clinical images of skin lesions. We obtain top-1 classification accuracy levels of 74.33% and 85.61% on clinical and dermoscopic datasets, respectively. Although this is slightly lower than the state-of-the-art results, the SNN approach has the advantage that it can detect out-of-class examples. Our results highlight the potential of an SNN approach as well as pathways towards future clinical deployment.","link":"http://arxiv.org/abs/2212.06130v1","created":"2022-12-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"Siamese Neural Networks for Skin Cancer Classification and New Class Detection using Clinical and Dermoscopic Image Datasets Skin cancer is the most common malignancy in the world. Automated skin cancer detection would significantly improve early detection rates and prevent deaths. To help with this aim, a number of datasets have been released which can be used to train Deep Learning systems - these have produced impressive results for classification. However, this only works for the classes they are trained on whilst they are incapable of identifying skin lesions from previously unseen classes, making them unconducive for clinical use. We could look to massively increase the datasets by including all possible skin lesions, though this would always leave out some classes. Instead, we evaluate Siamese Neural Networks (SNNs), which not only allows us to classify images of skin lesions, but also allow us to identify those images which are different from the trained classes - allowing us to determine that an image is not an example of our training classes. We evaluate SNNs on both dermoscopic and clinical images of skin lesions. We obtain top-1 classification accuracy levels of 74.33% and 85.61% on clinical and dermoscopic datasets, respectively. Although this is slightly lower than the state-of-the-art results, the SNN approach has the advantage that it can detect out-of-class examples. Our results highlight the potential of an SNN approach as well as pathways towards future clinical deployment.","classes":{"dataset":0.0423814319}}
{"title":"3DSC - A New Dataset of Superconductors Including Crystal Structures","description":"Data-driven methods, in particular machine learning, can help to speed up the discovery of new materials by finding hidden patterns in existing data and using them to identify promising candidate materials. In the case of superconductors, which are a highly interesting but also a complex class of materials with many relevant applications, the use of data science tools is to date slowed down by a lack of accessible data. In this work, we present a new and publicly available superconductivity dataset ('3DSC'), featuring the critical temperature $T_\\mathrm{c}$ of superconducting materials additionally to tested non-superconductors. In contrast to existing databases such as the SuperCon database which contains information on the chemical composition, the 3DSC is augmented by the approximate three-dimensional crystal structure of each material. We perform a statistical analysis and machine learning experiments to show that access to this structural information improves the prediction of the critical temperature $T_\\mathrm{c}$ of materials. Furthermore, we see the 3DSC not as a finished dataset, but we provide ideas and directions for further research to improve the 3DSC in multiple ways. We are confident that this database will be useful in applying state-of-the-art machine learning methods to eventually find new superconductors.","link":"http://arxiv.org/abs/2212.06071v2","created":"2022-12-12","tags":["arxiv","dataset"],"meta":{"query":"ti:dataset OR ti:corpus OR ti:database OR abs:\"a new dataset\""},"text":"3DSC - A New Dataset of Superconductors Including Crystal Structures Data-driven methods, in particular machine learning, can help to speed up the discovery of new materials by finding hidden patterns in existing data and using them to identify promising candidate materials. In the case of superconductors, which are a highly interesting but also a complex class of materials with many relevant applications, the use of data science tools is to date slowed down by a lack of accessible data. In this work, we present a new and publicly available superconductivity dataset ('3DSC'), featuring the critical temperature $T_\\mathrm{c}$ of superconducting materials additionally to tested non-superconductors. In contrast to existing databases such as the SuperCon database which contains information on the chemical composition, the 3DSC is augmented by the approximate three-dimensional crystal structure of each material. We perform a statistical analysis and machine learning experiments to show that access to this structural information improves the prediction of the critical temperature $T_\\mathrm{c}$ of materials. Furthermore, we see the 3DSC not as a finished dataset, but we provide ideas and directions for further research to improve the 3DSC in multiple ways. We are confident that this database will be useful in applying state-of-the-art machine learning methods to eventually find new superconductors.","classes":{"dataset":0.2034481615}}
{"title":"Efficient Flow-Guided Multi-frame De-fencing","description":"Taking photographs ''in-the-wild'' is often hindered by fence obstructions that stand between the camera user and the scene of interest, and which are hard or impossible to avoid. De-fencing is the algorithmic process of automatically removing such obstructions from images, revealing the invisible parts of the scene. While this problem can be formulated as a combination of fence segmentation and image inpainting, this often leads to implausible hallucinations of the occluded regions. Existing multi-frame approaches rely on propagating information to a selected keyframe from its temporal neighbors, but they are often inefficient and struggle with alignment of severely obstructed images. In this work we draw inspiration from the video completion literature and develop a simplified framework for multi-frame de-fencing that computes high quality flow maps directly from obstructed frames and uses them to accurately align frames. Our primary focus is efficiency and practicality in a real-world setting: the input to our algorithm is a short image burst (5 frames) - a data modality commonly available in modern smartphones - and the output is a single reconstructed keyframe, with the fence removed. Our approach leverages simple yet effective CNN modules, trained on carefully generated synthetic data, and outperforms more complicated alternatives real bursts, both quantitatively and qualitatively, while running real-time.","link":"http://arxiv.org/abs/2301.10759v1","created":"2023-01-25","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Efficient Flow-Guided Multi-frame De-fencing Taking photographs ''in-the-wild'' is often hindered by fence obstructions that stand between the camera user and the scene of interest, and which are hard or impossible to avoid. De-fencing is the algorithmic process of automatically removing such obstructions from images, revealing the invisible parts of the scene. While this problem can be formulated as a combination of fence segmentation and image inpainting, this often leads to implausible hallucinations of the occluded regions. Existing multi-frame approaches rely on propagating information to a selected keyframe from its temporal neighbors, but they are often inefficient and struggle with alignment of severely obstructed images. In this work we draw inspiration from the video completion literature and develop a simplified framework for multi-frame de-fencing that computes high quality flow maps directly from obstructed frames and uses them to accurately align frames. Our primary focus is efficiency and practicality in a real-world setting: the input to our algorithm is a short image burst (5 frames) - a data modality commonly available in modern smartphones - and the output is a single reconstructed keyframe, with the fence removed. Our approach leverages simple yet effective CNN modules, trained on carefully generated synthetic data, and outperforms more complicated alternatives real bursts, both quantitatively and qualitatively, while running real-time.","classes":{"dataset":0.0587842278}}
{"title":"Towards Mobility Management with Multi-Objective Bayesian Optimization","description":"One of the consequences of network densification is more frequent handovers (HO). HO failures have a direct impact on the quality of service and are undesirable, especially in scenarios with strict latency, reliability, and robustness constraints. In traditional networks, HO-related parameters are usually tuned by the network operator, and automated techniques are still based on past experience. In this paper, we propose an approach for optimizing HO thresholds using Bayesian Optimization (BO). We formulate a multi-objective optimization problem for selecting the HO thresholds that minimize HOs too early and too late in indoor factory scenarios, and we use multi-objective BO (MOBO) for finding the optimal values. Our results show that MOBO reaches Pareto optimal solutions with few samples and ensures service continuation through safe exploration of new data points.","link":"http://arxiv.org/abs/2301.10635v1","created":"2023-01-25","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Towards Mobility Management with Multi-Objective Bayesian Optimization One of the consequences of network densification is more frequent handovers (HO). HO failures have a direct impact on the quality of service and are undesirable, especially in scenarios with strict latency, reliability, and robustness constraints. In traditional networks, HO-related parameters are usually tuned by the network operator, and automated techniques are still based on past experience. In this paper, we propose an approach for optimizing HO thresholds using Bayesian Optimization (BO). We formulate a multi-objective optimization problem for selecting the HO thresholds that minimize HOs too early and too late in indoor factory scenarios, and we use multi-objective BO (MOBO) for finding the optimal values. Our results show that MOBO reaches Pareto optimal solutions with few samples and ensures service continuation through safe exploration of new data points.","classes":{"dataset":0.0195339546}}
{"title":"Multilingual Multiaccented Multispeaker TTS with RADTTS","description":"We work to create a multilingual speech synthesis system which can generate speech with the proper accent while retaining the characteristics of an individual voice. This is challenging to do because it is expensive to obtain bilingual training data in multiple languages, and the lack of such data results in strong correlations that entangle speaker, language, and accent, resulting in poor transfer capabilities. To overcome this, we present a multilingual, multiaccented, multispeaker speech synthesis model based on RADTTS with explicit control over accent, language, speaker and fine-grained $F_0$ and energy features. Our proposed model does not rely on bilingual training data. We demonstrate an ability to control synthesized accent for any speaker in an open-source dataset comprising of 7 accents. Human subjective evaluation demonstrates that our model can better retain a speaker's voice and accent quality than controlled baselines while synthesizing fluent speech in all target languages and accents in our dataset.","link":"http://arxiv.org/abs/2301.10335v1","created":"2023-01-24","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Multilingual Multiaccented Multispeaker TTS with RADTTS We work to create a multilingual speech synthesis system which can generate speech with the proper accent while retaining the characteristics of an individual voice. This is challenging to do because it is expensive to obtain bilingual training data in multiple languages, and the lack of such data results in strong correlations that entangle speaker, language, and accent, resulting in poor transfer capabilities. To overcome this, we present a multilingual, multiaccented, multispeaker speech synthesis model based on RADTTS with explicit control over accent, language, speaker and fine-grained $F_0$ and energy features. Our proposed model does not rely on bilingual training data. We demonstrate an ability to control synthesized accent for any speaker in an open-source dataset comprising of 7 accents. Human subjective evaluation demonstrates that our model can better retain a speaker's voice and accent quality than controlled baselines while synthesizing fluent speech in all target languages and accents in our dataset.","classes":{"dataset":0.2108109146}}
{"title":"Database Reconstruction Is Not So Easy and Is Different from Reidentification","description":"In recent years, it has been claimed that releasing accurate statistical information on a database is likely to allow its complete reconstruction. Differential privacy has been suggested as the appropriate methodology to prevent these attacks. These claims have recently been taken very seriously by the U.S. Census Bureau and led them to adopt differential privacy for releasing U.S. Census data. This in turn has caused consternation among users of the Census data due to the lack of accuracy of the protected outputs. It has also brought legal action against the U.S. Department of Commerce. In this paper, we trace the origins of the claim that releasing information on a database automatically makes it vulnerable to being exposed by reconstruction attacks and we show that this claim is, in fact, incorrect. We also show that reconstruction can be averted by properly using traditional statistical disclosure control (SDC) techniques. We further show that the geographic level at which exact counts are released is even more relevant to protection than the actual SDC method employed. Finally, we caution against confusing reconstruction and reidentification: using the quality of reconstruction as a metric of reidentification results in exaggerated reidentification risk figures.","link":"http://arxiv.org/abs/2301.10213v1","created":"2023-01-24","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Database Reconstruction Is Not So Easy and Is Different from Reidentification In recent years, it has been claimed that releasing accurate statistical information on a database is likely to allow its complete reconstruction. Differential privacy has been suggested as the appropriate methodology to prevent these attacks. These claims have recently been taken very seriously by the U.S. Census Bureau and led them to adopt differential privacy for releasing U.S. Census data. This in turn has caused consternation among users of the Census data due to the lack of accuracy of the protected outputs. It has also brought legal action against the U.S. Department of Commerce. In this paper, we trace the origins of the claim that releasing information on a database automatically makes it vulnerable to being exposed by reconstruction attacks and we show that this claim is, in fact, incorrect. We also show that reconstruction can be averted by properly using traditional statistical disclosure control (SDC) techniques. We further show that the geographic level at which exact counts are released is even more relevant to protection than the actual SDC method employed. Finally, we caution against confusing reconstruction and reidentification: using the quality of reconstruction as a metric of reidentification results in exaggerated reidentification risk figures.","classes":{"dataset":0.2972775102}}
{"title":"Enhanced Sharp-GAN For Histopathology Image Synthesis","description":"Histopathology image synthesis aims to address the data shortage issue in training deep learning approaches for accurate cancer detection. However, existing methods struggle to produce realistic images that have accurate nuclei boundaries and less artifacts, which limits the application in downstream tasks. To address the challenges, we propose a novel approach that enhances the quality of synthetic images by using nuclei topology and contour regularization. The proposed approach uses the skeleton map of nuclei to integrate nuclei topology and separate touching nuclei. In the loss function, we propose two new contour regularization terms that enhance the contrast between contour and non-contour pixels and increase the similarity between contour pixels. We evaluate the proposed approach on the two datasets using image quality metrics and a downstream task (nuclei segmentation). The proposed approach outperforms Sharp-GAN in all four image quality metrics on two datasets. By integrating 6k synthetic images from the proposed approach into training, a nuclei segmentation model achieves the state-of-the-art segmentation performance on TNBC dataset and its detection quality (DQ), segmentation quality (SQ), panoptic quality (PQ), and aggregated Jaccard index (AJI) is 0.855, 0.863, 0.691, and 0.683, respectively.","link":"http://arxiv.org/abs/2301.10187v1","created":"2023-01-24","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Enhanced Sharp-GAN For Histopathology Image Synthesis Histopathology image synthesis aims to address the data shortage issue in training deep learning approaches for accurate cancer detection. However, existing methods struggle to produce realistic images that have accurate nuclei boundaries and less artifacts, which limits the application in downstream tasks. To address the challenges, we propose a novel approach that enhances the quality of synthetic images by using nuclei topology and contour regularization. The proposed approach uses the skeleton map of nuclei to integrate nuclei topology and separate touching nuclei. In the loss function, we propose two new contour regularization terms that enhance the contrast between contour and non-contour pixels and increase the similarity between contour pixels. We evaluate the proposed approach on the two datasets using image quality metrics and a downstream task (nuclei segmentation). The proposed approach outperforms Sharp-GAN in all four image quality metrics on two datasets. By integrating 6k synthetic images from the proposed approach into training, a nuclei segmentation model achieves the state-of-the-art segmentation performance on TNBC dataset and its detection quality (DQ), segmentation quality (SQ), panoptic quality (PQ), and aggregated Jaccard index (AJI) is 0.855, 0.863, 0.691, and 0.683, respectively.","classes":{"dataset":0.5504825115}}
{"title":"Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism","description":"The loss function for bounding box regression (BBR) is essential to object detection. Its good definition will bring significant performance improvement to the model. Most existing works assume that the examples in the training data are high-quality and focus on strengthening the fitting ability of BBR loss. If we blindly strengthen BBR on low-quality examples, it will jeopardize localization performance. Focal-EIoU v1 was proposed to solve this problem, but due to its static focusing mechanism (FM), the potential of non-monotonic FM was not fully exploited. Based on this idea, we propose an IoU-based loss with a dynamic non-monotonic FM named Wise-IoU (WIoU). When WIoU is applied to the state-of-the-art real-time detector YOLOv7, the AP-75 on the MS-COCO dataset is improved from 53.03% to 54.50%.","link":"http://arxiv.org/abs/2301.10051v1","created":"2023-01-24","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism The loss function for bounding box regression (BBR) is essential to object detection. Its good definition will bring significant performance improvement to the model. Most existing works assume that the examples in the training data are high-quality and focus on strengthening the fitting ability of BBR loss. If we blindly strengthen BBR on low-quality examples, it will jeopardize localization performance. Focal-EIoU v1 was proposed to solve this problem, but due to its static focusing mechanism (FM), the potential of non-monotonic FM was not fully exploited. Based on this idea, we propose an IoU-based loss with a dynamic non-monotonic FM named Wise-IoU (WIoU). When WIoU is applied to the state-of-the-art real-time detector YOLOv7, the AP-75 on the MS-COCO dataset is improved from 53.03% to 54.50%.","classes":{"dataset":0.168855384}}
{"title":"Truveta Mapper: A Zero-shot Ontology Alignment Framework","description":"In this paper, a new perspective is suggested for unsupervised Ontology Matching (OM) or Ontology Alignment (OA) by treating it as a translation task. Ontologies are represented as graphs, and the translation is performed from a node in the source ontology graph to a path in the target ontology graph. The proposed framework, Truveta Mapper (TM), leverages a multi-task sequence-to-sequence transformer model to perform alignment across multiple ontologies in a zero-shot, unified and end-to-end manner. Multi-tasking enables the model to implicitly learn the relationship between different ontologies via transfer-learning without requiring any explicit cross-ontology manually labeled data. This also enables the formulated framework to outperform existing solutions for both runtime latency and alignment quality. The model is pre-trained and fine-tuned only on publicly available text corpus and inner-ontologies data. The proposed solution outperforms state-of-the-art approaches, Edit-Similarity, LogMap, AML, BERTMap, and the recently presented new OM frameworks in Ontology Alignment Evaluation Initiative (OAEI22), offers log-linear complexity in contrast to quadratic in the existing end-to-end methods, and overall makes the OM task efficient and more straightforward without much post-processing involving mapping extension or mapping repair.","link":"http://arxiv.org/abs/2301.09767v1","created":"2023-01-24","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Truveta Mapper: A Zero-shot Ontology Alignment Framework In this paper, a new perspective is suggested for unsupervised Ontology Matching (OM) or Ontology Alignment (OA) by treating it as a translation task. Ontologies are represented as graphs, and the translation is performed from a node in the source ontology graph to a path in the target ontology graph. The proposed framework, Truveta Mapper (TM), leverages a multi-task sequence-to-sequence transformer model to perform alignment across multiple ontologies in a zero-shot, unified and end-to-end manner. Multi-tasking enables the model to implicitly learn the relationship between different ontologies via transfer-learning without requiring any explicit cross-ontology manually labeled data. This also enables the formulated framework to outperform existing solutions for both runtime latency and alignment quality. The model is pre-trained and fine-tuned only on publicly available text corpus and inner-ontologies data. The proposed solution outperforms state-of-the-art approaches, Edit-Similarity, LogMap, AML, BERTMap, and the recently presented new OM frameworks in Ontology Alignment Evaluation Initiative (OAEI22), offers log-linear complexity in contrast to quadratic in the existing end-to-end methods, and overall makes the OM task efficient and more straightforward without much post-processing involving mapping extension or mapping repair.","classes":{"dataset":0.2328293324}}
{"title":"Illumination Variation Correction Using Image Synthesis For Unsupervised Domain Adaptive Person Re-Identification","description":"Unsupervised domain adaptive (UDA) person re-identification (re-ID) aims to learn identity information from labeled images in source domains and apply it to unlabeled images in a target domain. One major issue with many unsupervised re-identification methods is that they do not perform well relative to large domain variations such as illumination, viewpoint, and occlusions. In this paper, we propose a Synthesis Model Bank (SMB) to deal with illumination variation in unsupervised person re-ID. The proposed SMB consists of several convolutional neural networks (CNN) for feature extraction and Mahalanobis matrices for distance metrics. They are trained using synthetic data with different illumination conditions such that their synergistic effect makes the SMB robust against illumination variation. To better quantify the illumination intensity and improve the quality of synthetic images, we introduce a new 3D virtual-human dataset for GAN-based image synthesis. From our experiments, the proposed SMB outperforms other synthesis methods on several re-ID benchmarks.","link":"http://arxiv.org/abs/2301.09702v1","created":"2023-01-23","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Illumination Variation Correction Using Image Synthesis For Unsupervised Domain Adaptive Person Re-Identification Unsupervised domain adaptive (UDA) person re-identification (re-ID) aims to learn identity information from labeled images in source domains and apply it to unlabeled images in a target domain. One major issue with many unsupervised re-identification methods is that they do not perform well relative to large domain variations such as illumination, viewpoint, and occlusions. In this paper, we propose a Synthesis Model Bank (SMB) to deal with illumination variation in unsupervised person re-ID. The proposed SMB consists of several convolutional neural networks (CNN) for feature extraction and Mahalanobis matrices for distance metrics. They are trained using synthetic data with different illumination conditions such that their synergistic effect makes the SMB robust against illumination variation. To better quantify the illumination intensity and improve the quality of synthetic images, we introduce a new 3D virtual-human dataset for GAN-based image synthesis. From our experiments, the proposed SMB outperforms other synthesis methods on several re-ID benchmarks.","classes":{"dataset":0.3138262928}}
{"title":"ECGAN: Self-supervised generative adversarial network for electrocardiography","description":"High-quality synthetic data can support the development of effective predictive models for biomedical tasks, especially in rare diseases or when subject to compelling privacy constraints. These limitations, for instance, negatively impact open access to electrocardiography datasets about arrhythmias. This work introduces a self-supervised approach to the generation of synthetic electrocardiography time series which is shown to promote morphological plausibility. Our model (ECGAN) allows conditioning the generative process for specific rhythm abnormalities, enhancing synchronization and diversity across samples with respect to literature models. A dedicated sample quality assessment framework is also defined, leveraging arrhythmia classifiers. The empirical results highlight a substantial improvement against state-of-the-art generative models for sequences and audio synthesis.","link":"http://arxiv.org/abs/2301.09496v1","created":"2023-01-23","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"ECGAN: Self-supervised generative adversarial network for electrocardiography High-quality synthetic data can support the development of effective predictive models for biomedical tasks, especially in rare diseases or when subject to compelling privacy constraints. These limitations, for instance, negatively impact open access to electrocardiography datasets about arrhythmias. This work introduces a self-supervised approach to the generation of synthetic electrocardiography time series which is shown to promote morphological plausibility. Our model (ECGAN) allows conditioning the generative process for specific rhythm abnormalities, enhancing synchronization and diversity across samples with respect to literature models. A dedicated sample quality assessment framework is also defined, leveraging arrhythmia classifiers. The empirical results highlight a substantial improvement against state-of-the-art generative models for sequences and audio synthesis.","classes":{"dataset":0.3670710325}}
{"title":"Multi-domain stain normalization for digital pathology: A cycle-consistent adversarial network for whole slide images","description":"The variation in histologic staining between different medical centers is one of the most profound challenges in the field of computer-aided diagnosis. The appearance disparity of pathological whole slide images causes algorithms to become less reliable, which in turn impedes the wide-spread applicability of downstream tasks like cancer diagnosis. Furthermore, different stainings lead to biases in the training which in case of domain shifts negatively affect the test performance. Therefore, in this paper we propose MultiStain-CycleGAN, a multi-domain approach to stain normalization based on CycleGAN. Our modifications to CycleGAN allow us to normalize images of different origins without retraining or using different models. We perform an extensive evaluation of our method using various metrics and compare it to commonly used methods that are multi-domain capable. First, we evaluate how well our method fools a domain classifier that tries to assign a medical center to an image. Then, we test our normalization on the tumor classification performance of a downstream classifier. Furthermore, we evaluate the image quality of the normalized images using the Structural similarity index and the ability to reduce the domain shift using the Fr\\'echet inception distance. We show that our method proves to be multi-domain capable, provides the highest image quality among the compared methods, and can most reliably fool the domain classifier while keeping the tumor classifier performance high. By reducing the domain influence, biases in the data can be removed on the one hand and the origin of the whole slide image can be disguised on the other, thus enhancing patient data privacy.","link":"http://arxiv.org/abs/2301.09431v1","created":"2023-01-23","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Multi-domain stain normalization for digital pathology: A cycle-consistent adversarial network for whole slide images The variation in histologic staining between different medical centers is one of the most profound challenges in the field of computer-aided diagnosis. The appearance disparity of pathological whole slide images causes algorithms to become less reliable, which in turn impedes the wide-spread applicability of downstream tasks like cancer diagnosis. Furthermore, different stainings lead to biases in the training which in case of domain shifts negatively affect the test performance. Therefore, in this paper we propose MultiStain-CycleGAN, a multi-domain approach to stain normalization based on CycleGAN. Our modifications to CycleGAN allow us to normalize images of different origins without retraining or using different models. We perform an extensive evaluation of our method using various metrics and compare it to commonly used methods that are multi-domain capable. First, we evaluate how well our method fools a domain classifier that tries to assign a medical center to an image. Then, we test our normalization on the tumor classification performance of a downstream classifier. Furthermore, we evaluate the image quality of the normalized images using the Structural similarity index and the ability to reduce the domain shift using the Fr\\'echet inception distance. We show that our method proves to be multi-domain capable, provides the highest image quality among the compared methods, and can most reliably fool the domain classifier while keeping the tumor classifier performance high. By reducing the domain influence, biases in the data can be removed on the one hand and the origin of the whole slide image can be disguised on the other, thus enhancing patient data privacy.","classes":{"dataset":0.1822619736}}
{"title":"Velocity-Based LOD Reduction in Virtual Reality: A Psychometric Approach","description":"Virtual Reality headsets enable users to explore the environment by performing self-induced movements. The retinal velocity produced by such motion reduces the visual system's ability to resolve fine detail. We measured the impact of self-induced head rotations on the ability to detect quality changes of a realistic 3D model in an immersive virtual reality environment. We varied the Level-of-Detail (LOD) as a function of rotational head velocity with different degrees of severity. Using a psychophysical method, we asked 17 participants to identify which of the two presented intervals contained the higher quality model under two different maximum velocity conditions. After fitting psychometric functions to data relating the percentage of correct responses to the aggressiveness of LOD manipulations, we identified the threshold severity for which participants could reliably (75\\%) detect the lower LOD model. Participants accepted an approximately four-fold LOD reduction even in the low maximum velocity condition without a significant impact on perceived quality, which suggests that there is considerable potential for optimisation when users are moving (increased range of perceptual uncertainty). Moreover, LOD could be degraded significantly more in the maximum head velocity condition, suggesting these effects are indeed speed dependent.","link":"http://arxiv.org/abs/2301.09394v1","created":"2023-01-23","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Velocity-Based LOD Reduction in Virtual Reality: A Psychometric Approach Virtual Reality headsets enable users to explore the environment by performing self-induced movements. The retinal velocity produced by such motion reduces the visual system's ability to resolve fine detail. We measured the impact of self-induced head rotations on the ability to detect quality changes of a realistic 3D model in an immersive virtual reality environment. We varied the Level-of-Detail (LOD) as a function of rotational head velocity with different degrees of severity. Using a psychophysical method, we asked 17 participants to identify which of the two presented intervals contained the higher quality model under two different maximum velocity conditions. After fitting psychometric functions to data relating the percentage of correct responses to the aggressiveness of LOD manipulations, we identified the threshold severity for which participants could reliably (75\\%) detect the lower LOD model. Participants accepted an approximately four-fold LOD reduction even in the low maximum velocity condition without a significant impact on perceived quality, which suggests that there is considerable potential for optimisation when users are moving (increased range of perceptual uncertainty). Moreover, LOD could be degraded significantly more in the maximum head velocity condition, suggesting these effects are indeed speed dependent.","classes":{"dataset":0.185961023}}
{"title":"Proactive and Reactive Engagement of Artificial Intelligence Methods for Education: A Review","description":"Quality education, one of the seventeen sustainable development goals (SDGs) identified by the United Nations General Assembly, stands to benefit enormously from the adoption of artificial intelligence (AI) driven tools and technologies. The concurrent boom of necessary infrastructure, digitized data and general social awareness has propelled massive research and development efforts in the artificial intelligence for education (AIEd) sector. In this review article, we investigate how artificial intelligence, machine learning and deep learning methods are being utilized to support students, educators and administrative staff. We do this through the lens of a novel categorization approach. We consider the involvement of AI-driven methods in the education process in its entirety - from students admissions, course scheduling etc. in the proactive planning phase to knowledge delivery, performance assessment etc. in the reactive execution phase. We outline and analyze the major research directions under proactive and reactive engagement of AI in education using a representative group of 194 original research articles published in the past two decades i.e., 2003 - 2022. We discuss the paradigm shifts in the solution approaches proposed, i.e., in the choice of data and algorithms used over this time. We further dive into how the COVID-19 pandemic challenged and reshaped the education landscape at the fag end of this time period. Finally, we pinpoint existing limitations in adopting artificial intelligence for education and reflect on the path forward.","link":"http://arxiv.org/abs/2301.10231v1","created":"2023-01-23","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Proactive and Reactive Engagement of Artificial Intelligence Methods for Education: A Review Quality education, one of the seventeen sustainable development goals (SDGs) identified by the United Nations General Assembly, stands to benefit enormously from the adoption of artificial intelligence (AI) driven tools and technologies. The concurrent boom of necessary infrastructure, digitized data and general social awareness has propelled massive research and development efforts in the artificial intelligence for education (AIEd) sector. In this review article, we investigate how artificial intelligence, machine learning and deep learning methods are being utilized to support students, educators and administrative staff. We do this through the lens of a novel categorization approach. We consider the involvement of AI-driven methods in the education process in its entirety - from students admissions, course scheduling etc. in the proactive planning phase to knowledge delivery, performance assessment etc. in the reactive execution phase. We outline and analyze the major research directions under proactive and reactive engagement of AI in education using a representative group of 194 original research articles published in the past two decades i.e., 2003 - 2022. We discuss the paradigm shifts in the solution approaches proposed, i.e., in the choice of data and algorithms used over this time. We further dive into how the COVID-19 pandemic challenged and reshaped the education landscape at the fag end of this time period. Finally, we pinpoint existing limitations in adopting artificial intelligence for education and reflect on the path forward.","classes":{"dataset":0.0478881672}}
{"title":"The Pipeline for the Continuous Development of Artificial Intelligence Models -- Current State of Research and Practice","description":"Companies struggle to continuously develop and deploy AI models to complex production systems due to AI characteristics while assuring quality. To ease the development process, continuous pipelines for AI have become an active research area where consolidated and in-depth analysis regarding the terminology, triggers, tasks, and challenges is required. This paper includes a Multivocal Literature Review where we consolidated 151 relevant formal and informal sources. In addition, nine-semi structured interviews with participants from academia and industry verified and extended the obtained information. Based on these sources, this paper provides and compares terminologies for DevOps and CI/CD for AI, MLOps, (end-to-end) lifecycle management, and CD4ML. Furthermore, the paper provides an aggregated list of potential triggers for reiterating the pipeline, such as alert systems or schedules. In addition, this work uses a taxonomy creation strategy to present a consolidated pipeline comprising tasks regarding the continuous development of AI. This pipeline consists of four stages: Data Handling, Model Learning, Software Development and System Operations. Moreover, we map challenges regarding pipeline implementation, adaption, and usage for the continuous development of AI to these four stages.","link":"http://arxiv.org/abs/2301.09001v1","created":"2023-01-21","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"The Pipeline for the Continuous Development of Artificial Intelligence Models -- Current State of Research and Practice Companies struggle to continuously develop and deploy AI models to complex production systems due to AI characteristics while assuring quality. To ease the development process, continuous pipelines for AI have become an active research area where consolidated and in-depth analysis regarding the terminology, triggers, tasks, and challenges is required. This paper includes a Multivocal Literature Review where we consolidated 151 relevant formal and informal sources. In addition, nine-semi structured interviews with participants from academia and industry verified and extended the obtained information. Based on these sources, this paper provides and compares terminologies for DevOps and CI/CD for AI, MLOps, (end-to-end) lifecycle management, and CD4ML. Furthermore, the paper provides an aggregated list of potential triggers for reiterating the pipeline, such as alert systems or schedules. In addition, this work uses a taxonomy creation strategy to present a consolidated pipeline comprising tasks regarding the continuous development of AI. This pipeline consists of four stages: Data Handling, Model Learning, Software Development and System Operations. Moreover, we map challenges regarding pipeline implementation, adaption, and usage for the continuous development of AI to these four stages.","classes":{"dataset":0.1392096877}}
{"title":"Soft Sensing Regression Model: from Sensor to Wafer Metrology Forecasting","description":"The semiconductor industry is one of the most technology-evolving and capital-intensive market sectors. Effective inspection and metrology are necessary to improve product yield, increase product quality and reduce costs. In recent years, many semiconductor manufacturing equipments are equipped with sensors to facilitate real-time monitoring of the production process. These production-state and equipment-state sensor data provide an opportunity to practice machine-learning technologies in various domains, such as anomaly/fault detection, maintenance scheduling, quality prediction, etc. In this work, we focus on the task of soft sensing regression, which uses sensor data to predict impending inspection measurements that used to be measured in wafer inspection and metrology systems. We proposed an LSTM-based regressor and designed two loss functions for model training. Although engineers may look at our prediction errors in a subjective manner, a new piece-wise evaluation metric was proposed for assessing model accuracy in a mathematical way. The experimental results demonstrated that the proposed model can achieve accurate and early prediction of various types of inspections in complicated manufacturing processes.","link":"http://arxiv.org/abs/2301.08974v1","created":"2023-01-21","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Soft Sensing Regression Model: from Sensor to Wafer Metrology Forecasting The semiconductor industry is one of the most technology-evolving and capital-intensive market sectors. Effective inspection and metrology are necessary to improve product yield, increase product quality and reduce costs. In recent years, many semiconductor manufacturing equipments are equipped with sensors to facilitate real-time monitoring of the production process. These production-state and equipment-state sensor data provide an opportunity to practice machine-learning technologies in various domains, such as anomaly/fault detection, maintenance scheduling, quality prediction, etc. In this work, we focus on the task of soft sensing regression, which uses sensor data to predict impending inspection measurements that used to be measured in wafer inspection and metrology systems. We proposed an LSTM-based regressor and designed two loss functions for model training. Although engineers may look at our prediction errors in a subjective manner, a new piece-wise evaluation metric was proposed for assessing model accuracy in a mathematical way. The experimental results demonstrated that the proposed model can achieve accurate and early prediction of various types of inspections in complicated manufacturing processes.","classes":{"dataset":0.3151297867}}
{"title":"A fast and flexible machine learning approach to data quality monitoring","description":"We present a machine learning based approach for real-time monitoring of particle detectors. The proposed strategy evaluates the compatibility between incoming batches of experimental data and a reference sample representing the data behavior in normal conditions by implementing a likelihood-ratio hypothesis test. The core model is powered by recent large-scale implementations of kernel methods, nonparametric learning algorithms that can approximate any continuous function given enough data. The resulting algorithm is fast, efficient and agnostic about the type of potential anomaly in the data. We show the performance of the model on multivariate data from a drift tube chambers muon detector.","link":"http://arxiv.org/abs/2301.08917v1","created":"2023-01-21","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"A fast and flexible machine learning approach to data quality monitoring We present a machine learning based approach for real-time monitoring of particle detectors. The proposed strategy evaluates the compatibility between incoming batches of experimental data and a reference sample representing the data behavior in normal conditions by implementing a likelihood-ratio hypothesis test. The core model is powered by recent large-scale implementations of kernel methods, nonparametric learning algorithms that can approximate any continuous function given enough data. The resulting algorithm is fast, efficient and agnostic about the type of potential anomaly in the data. We show the performance of the model on multivariate data from a drift tube chambers muon detector.","classes":{"dataset":0.4756151438}}
{"title":"In-situ Water quality monitoring in Oil and Gas operations","description":"From agriculture to mining, to energy, surface water quality monitoring is an essential task. As oil and gas operators work to reduce the consumption of freshwater, it is increasingly important to actively manage fresh and non-fresh water resources over the long term. For large-scale monitoring, manual sampling at many sites has become too time-consuming and unsustainable, given the sheer number of dispersed ponds, small lakes, playas, and wetlands over a large area. Therefore, satellite-based environmental monitoring presents great potential. Many existing satellite-based monitoring studies utilize index-based methods to monitor large water bodies such as rivers and oceans. However, these existing methods fail when monitoring small ponds-the reflectance signal received from small water bodies is too weak to detect. To address this challenge, we propose a new Water Quality Enhanced Index (WQEI) Model, which is designed to enable users to determine contamination levels in water bodies with weak reflectance patterns. Our results show that 1) WQEI is a good indicator of water turbidity validated with 1200 water samples measured in the laboratory, and 2) by applying our method to commonly available satellite data (e.g. LandSat8), one can achieve high accuracy water quality monitoring efficiently in large regions. This provides a tool for operators to optimize the quality of water stored within surface storage ponds and increasing the readiness and availability of non-fresh water.","link":"http://arxiv.org/abs/2301.08800v1","created":"2023-01-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"In-situ Water quality monitoring in Oil and Gas operations From agriculture to mining, to energy, surface water quality monitoring is an essential task. As oil and gas operators work to reduce the consumption of freshwater, it is increasingly important to actively manage fresh and non-fresh water resources over the long term. For large-scale monitoring, manual sampling at many sites has become too time-consuming and unsustainable, given the sheer number of dispersed ponds, small lakes, playas, and wetlands over a large area. Therefore, satellite-based environmental monitoring presents great potential. Many existing satellite-based monitoring studies utilize index-based methods to monitor large water bodies such as rivers and oceans. However, these existing methods fail when monitoring small ponds-the reflectance signal received from small water bodies is too weak to detect. To address this challenge, we propose a new Water Quality Enhanced Index (WQEI) Model, which is designed to enable users to determine contamination levels in water bodies with weak reflectance patterns. Our results show that 1) WQEI is a good indicator of water turbidity validated with 1200 water samples measured in the laboratory, and 2) by applying our method to commonly available satellite data (e.g. LandSat8), one can achieve high accuracy water quality monitoring efficiently in large regions. This provides a tool for operators to optimize the quality of water stored within surface storage ponds and increasing the readiness and availability of non-fresh water.","classes":{"dataset":0.1895453781}}
{"title":"An Asynchronous Intensity Representation for Framed and Event Video Sources","description":"Neuromorphic \"event\" cameras, designed to mimic the human vision system with asynchronous sensing, unlock a new realm of high-speed and high dynamic range applications. However, researchers often either revert to a framed representation of event data for applications, or build bespoke applications for a particular camera's event data type. To usher in the next era of video systems, accommodate new event camera designs, and explore the benefits to asynchronous video in classical applications, we argue that there is a need for an asynchronous, source-agnostic video representation. In this paper, we introduce a novel, asynchronous intensity representation for both framed and non-framed data sources. We show that our representation can increase intensity precision and greatly reduce the number of samples per pixel compared to grid-based representations. With framed sources, we demonstrate that by permitting a small amount of loss through the temporal averaging of similar pixel values, we can reduce our representational sample rate by more than half, while incurring a drop in VMAF quality score of only 4.5. We also demonstrate lower latency than the state-of-the-art method for fusing and transcoding framed and event camera data to an intensity representation, while maintaining $2000\\times$ the temporal resolution. We argue that our method provides the computational efficiency and temporal granularity necessary to build real-time intensity-based applications for event cameras.","link":"http://arxiv.org/abs/2301.08783v1","created":"2023-01-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"An Asynchronous Intensity Representation for Framed and Event Video Sources Neuromorphic \"event\" cameras, designed to mimic the human vision system with asynchronous sensing, unlock a new realm of high-speed and high dynamic range applications. However, researchers often either revert to a framed representation of event data for applications, or build bespoke applications for a particular camera's event data type. To usher in the next era of video systems, accommodate new event camera designs, and explore the benefits to asynchronous video in classical applications, we argue that there is a need for an asynchronous, source-agnostic video representation. In this paper, we introduce a novel, asynchronous intensity representation for both framed and non-framed data sources. We show that our representation can increase intensity precision and greatly reduce the number of samples per pixel compared to grid-based representations. With framed sources, we demonstrate that by permitting a small amount of loss through the temporal averaging of similar pixel values, we can reduce our representational sample rate by more than half, while incurring a drop in VMAF quality score of only 4.5. We also demonstrate lower latency than the state-of-the-art method for fusing and transcoding framed and event camera data to an intensity representation, while maintaining $2000\\times$ the temporal resolution. We argue that our method provides the computational efficiency and temporal granularity necessary to build real-time intensity-based applications for event cameras.","classes":{"dataset":0.2175284475}}
{"title":"Data Augmentation for Modeling Human Personality: The Dexter Machine","description":"Modeling human personality is important for several AI challenges, from the engineering of artificial psychotherapists to the design of persona bots. However, the field of computational personality analysis heavily relies on labeled data, which may be expensive, difficult or impossible to get. This problem is amplified when dealing with rare personality types or disorders (e.g., the anti-social psychopathic personality disorder). In this context, we developed a text-based data augmentation approach for human personality (PEDANT). PEDANT doesn't rely on the common type of labeled data but on the generative pre-trained model (GPT) combined with domain expertise. Testing the methodology on three different datasets, provides results that support the quality of the generated data.","link":"http://arxiv.org/abs/2301.08606v1","created":"2023-01-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Data Augmentation for Modeling Human Personality: The Dexter Machine Modeling human personality is important for several AI challenges, from the engineering of artificial psychotherapists to the design of persona bots. However, the field of computational personality analysis heavily relies on labeled data, which may be expensive, difficult or impossible to get. This problem is amplified when dealing with rare personality types or disorders (e.g., the anti-social psychopathic personality disorder). In this context, we developed a text-based data augmentation approach for human personality (PEDANT). PEDANT doesn't rely on the common type of labeled data but on the generative pre-trained model (GPT) combined with domain expertise. Testing the methodology on three different datasets, provides results that support the quality of the generated data.","classes":{"dataset":0.4097661376}}
{"title":"Language Agnostic Data-Driven Inverse Text Normalization","description":"With the emergence of automatic speech recognition (ASR) models, converting the spoken form text (from ASR) to the written form is in urgent need. This inverse text normalization (ITN) problem attracts the attention of researchers from various fields. Recently, several works show that data-driven ITN methods can output high-quality written form text. Due to the scarcity of labeled spoken-written datasets, the studies on non-English data-driven ITN are quite limited. In this work, we propose a language-agnostic data-driven ITN framework to fill this gap. Specifically, we leverage the data augmentation in conjunction with neural machine translated data for low resource languages. Moreover, we design an evaluation method for language agnostic ITN model when only English data is available. Our empirical evaluation shows this language agnostic modeling approach is effective for low resource languages while preserving the performance for high resource languages.","link":"http://arxiv.org/abs/2301.08506v2","created":"2023-01-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Language Agnostic Data-Driven Inverse Text Normalization With the emergence of automatic speech recognition (ASR) models, converting the spoken form text (from ASR) to the written form is in urgent need. This inverse text normalization (ITN) problem attracts the attention of researchers from various fields. Recently, several works show that data-driven ITN methods can output high-quality written form text. Due to the scarcity of labeled spoken-written datasets, the studies on non-English data-driven ITN are quite limited. In this work, we propose a language-agnostic data-driven ITN framework to fill this gap. Specifically, we leverage the data augmentation in conjunction with neural machine translated data for low resource languages. Moreover, we design an evaluation method for language agnostic ITN model when only English data is available. Our empirical evaluation shows this language agnostic modeling approach is effective for low resource languages while preserving the performance for high resource languages.","classes":{"dataset":0.1937856823}}
{"title":"On Retrospective k-space Subsampling schemes For Deep MRI Reconstruction","description":"$\\textbf{Purpose:}$ The MRI $k$-space acquisition is time consuming. Traditional techniques aim to acquire accelerated data, which in conjunction with recent DL methods, aid in producing high-fidelity images in truncated times. Conventionally, subsampling the $k$-space is performed by utilizing Cartesian-rectilinear trajectories, which even with the use of DL, provide imprecise reconstructions, though, a plethora of non-rectilinear or non-Cartesian trajectories can be implemented in modern MRI scanners. This work investigates the effect of the $k$-space subsampling scheme on the quality of reconstructed accelerated MRI measurements produced by trained DL models.   $\\textbf{Methods:}$ The RecurrentVarNet was used as the DL-based MRI-reconstruction architecture. Cartesian fully-sampled multi-coil $k$-space measurements from three datasets with different accelerations were retrospectively subsampled using eight distinct subsampling schemes (four Cartesian-rectilinear, two Cartesian non-rectilinear, two non-Cartesian). Experiments were conducted in two frameworks: Scheme-specific, where a distinct model was trained and evaluated for each dataset-subsampling scheme pair, and multi-scheme, where for each dataset a single model was trained on data randomly subsampled by any of the eight schemes and evaluated on data subsampled by all schemes.   $\\textbf{Results:}$ In the scheme-specific setting RecurrentVarNets trained and evaluated on non-rectilinearly subsampled data demonstrated superior performance especially for high accelerations, whilst in the multi-scheme setting, reconstruction performance on rectilinearly subsampled data improved when compared to the scheme-specific experiments.   $\\textbf{Conclusion:}$ Training DL-based MRI reconstruction algorithms on non-rectilinearly subsampled measurements can produce more faithful reconstructions.","link":"http://arxiv.org/abs/2301.08365v2","created":"2023-01-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"On Retrospective k-space Subsampling schemes For Deep MRI Reconstruction $\\textbf{Purpose:}$ The MRI $k$-space acquisition is time consuming. Traditional techniques aim to acquire accelerated data, which in conjunction with recent DL methods, aid in producing high-fidelity images in truncated times. Conventionally, subsampling the $k$-space is performed by utilizing Cartesian-rectilinear trajectories, which even with the use of DL, provide imprecise reconstructions, though, a plethora of non-rectilinear or non-Cartesian trajectories can be implemented in modern MRI scanners. This work investigates the effect of the $k$-space subsampling scheme on the quality of reconstructed accelerated MRI measurements produced by trained DL models.   $\\textbf{Methods:}$ The RecurrentVarNet was used as the DL-based MRI-reconstruction architecture. Cartesian fully-sampled multi-coil $k$-space measurements from three datasets with different accelerations were retrospectively subsampled using eight distinct subsampling schemes (four Cartesian-rectilinear, two Cartesian non-rectilinear, two non-Cartesian). Experiments were conducted in two frameworks: Scheme-specific, where a distinct model was trained and evaluated for each dataset-subsampling scheme pair, and multi-scheme, where for each dataset a single model was trained on data randomly subsampled by any of the eight schemes and evaluated on data subsampled by all schemes.   $\\textbf{Results:}$ In the scheme-specific setting RecurrentVarNets trained and evaluated on non-rectilinearly subsampled data demonstrated superior performance especially for high accelerations, whilst in the multi-scheme setting, reconstruction performance on rectilinearly subsampled data improved when compared to the scheme-specific experiments.   $\\textbf{Conclusion:}$ Training DL-based MRI reconstruction algorithms on non-rectilinearly subsampled measurements can produce more faithful reconstructions.","classes":{"dataset":0.1122689471}}
{"title":"Learning ultrasound plane pose regression: assessing generalized pose coordinates in the fetal brain","description":"In obstetric ultrasound (US) scanning, the learner's ability to mentally build a three-dimensional (3D) map of the fetus from a two-dimensional (2D) US image represents a significant challenge in skill acquisition. We aim to build a US plane localization system for 3D visualization, training, and guidance without integrating additional sensors. This work builds on top of our previous work, which predicts the six-dimensional (6D) pose of arbitrarily-oriented US planes slicing the fetal brain with respect to a normalized reference frame using a convolutional neural network (CNN) regression network. Here, we analyze in detail the assumptions of the normalized fetal brain reference frame and quantify its accuracy with respect to the acquisition of transventricular (TV) standard plane (SP) for fetal biometry. We investigate the impact of registration quality in the training and testing data and its subsequent effect on trained models. Finally, we introduce data augmentations and larger training sets that improve the results of our previous work, achieving median errors of 3.53 mm and 6.42 degrees for translation and rotation, respectively.","link":"http://arxiv.org/abs/2301.08317v1","created":"2023-01-19","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Learning ultrasound plane pose regression: assessing generalized pose coordinates in the fetal brain In obstetric ultrasound (US) scanning, the learner's ability to mentally build a three-dimensional (3D) map of the fetus from a two-dimensional (2D) US image represents a significant challenge in skill acquisition. We aim to build a US plane localization system for 3D visualization, training, and guidance without integrating additional sensors. This work builds on top of our previous work, which predicts the six-dimensional (6D) pose of arbitrarily-oriented US planes slicing the fetal brain with respect to a normalized reference frame using a convolutional neural network (CNN) regression network. Here, we analyze in detail the assumptions of the normalized fetal brain reference frame and quantify its accuracy with respect to the acquisition of transventricular (TV) standard plane (SP) for fetal biometry. We investigate the impact of registration quality in the training and testing data and its subsequent effect on trained models. Finally, we introduce data augmentations and larger training sets that improve the results of our previous work, achieving median errors of 3.53 mm and 6.42 degrees for translation and rotation, respectively.","classes":{"dataset":0.1647608876}}
{"title":"Diffusion-based Conditional ECG Generation with Structured State Space Models","description":"Synthetic data generation is a promising solution to address privacy issues with the distribution of sensitive health data. Recently, diffusion models have set new standards for generative models for different data modalities. Also very recently, structured state space models emerged as a powerful modeling paradigm to capture long-term dependencies in time series. We put forward SSSD-ECG, as the combination of these two technologies, for the generation of synthetic 12-lead electrocardiograms conditioned on more than 70 ECG statements. Due to a lack of reliable baselines, we also propose conditional variants of two state-of-the-art unconditional generative models. We thoroughly evaluate the quality of the generated samples, by evaluating pretrained classifiers on the generated data and by evaluating the performance of a classifier trained only on synthetic data, where SSSD-ECG clearly outperforms its GAN-based competitors. We demonstrate the soundness of our approach through further experiments, including conditional class interpolation and a clinical Turing test demonstrating the high quality of the SSSD-ECG samples across a wide range of conditions.","link":"http://arxiv.org/abs/2301.08227v1","created":"2023-01-19","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Diffusion-based Conditional ECG Generation with Structured State Space Models Synthetic data generation is a promising solution to address privacy issues with the distribution of sensitive health data. Recently, diffusion models have set new standards for generative models for different data modalities. Also very recently, structured state space models emerged as a powerful modeling paradigm to capture long-term dependencies in time series. We put forward SSSD-ECG, as the combination of these two technologies, for the generation of synthetic 12-lead electrocardiograms conditioned on more than 70 ECG statements. Due to a lack of reliable baselines, we also propose conditional variants of two state-of-the-art unconditional generative models. We thoroughly evaluate the quality of the generated samples, by evaluating pretrained classifiers on the generated data and by evaluating the performance of a classifier trained only on synthetic data, where SSSD-ECG clearly outperforms its GAN-based competitors. We demonstrate the soundness of our approach through further experiments, including conditional class interpolation and a clinical Turing test demonstrating the high quality of the SSSD-ECG samples across a wide range of conditions.","classes":{"dataset":0.3290871084}}
{"title":"A Meta-Learning Approach for Software Refactoring","description":"Software refactoring is the process of changing the structure of software without any alteration in its behavior and functionality. Presuming it is carried out in appropriate opportunities, refactoring enhances software quality characteristics such as maintainability and extensibility. Thus far, various studies have addressed the problem of detecting proper opportunities for refactoring. Most of them are based on human expertise and are prone to error and non-meticulous. Fortunately, in recent efforts, machine learning methods have produced outstanding results in finding appropriate opportunities for refactoring. Sad to say, Machine learning methods mostly need plenty of data and, consequently, long processing time. Furthermore, there needs to be more annotated data for many types of refactoring, and data collection is time-consuming and costly. Accordingly, in this paper, we have formulated the problem of detecting appropriate opportunities for refactoring as a few-shot classification problem. We have utilized model-agnostic meta-learning (MAML), a recognized meta-learning algorithm, to learn a neural network on tasks from high-resource data. The trained model, then, is adapted to a model with high accuracy for tasks from low-resource data. Experimental results revealed 91% accuracy, which illustrates the effectiveness and competitiveness of our proposed meta-learning model.","link":"http://arxiv.org/abs/2301.08061v1","created":"2023-01-19","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"A Meta-Learning Approach for Software Refactoring Software refactoring is the process of changing the structure of software without any alteration in its behavior and functionality. Presuming it is carried out in appropriate opportunities, refactoring enhances software quality characteristics such as maintainability and extensibility. Thus far, various studies have addressed the problem of detecting proper opportunities for refactoring. Most of them are based on human expertise and are prone to error and non-meticulous. Fortunately, in recent efforts, machine learning methods have produced outstanding results in finding appropriate opportunities for refactoring. Sad to say, Machine learning methods mostly need plenty of data and, consequently, long processing time. Furthermore, there needs to be more annotated data for many types of refactoring, and data collection is time-consuming and costly. Accordingly, in this paper, we have formulated the problem of detecting appropriate opportunities for refactoring as a few-shot classification problem. We have utilized model-agnostic meta-learning (MAML), a recognized meta-learning algorithm, to learn a neural network on tasks from high-resource data. The trained model, then, is adapted to a model with high accuracy for tasks from low-resource data. Experimental results revealed 91% accuracy, which illustrates the effectiveness and competitiveness of our proposed meta-learning model.","classes":{"dataset":0.1834896207}}
{"title":"Characterising fast-time variations in the hard X-ray time profiles of solar flares using Solar Orbiter's STIX","description":"Aims: The aim of this work is to develop a method to systematically detect and characterise fast-time variations ($\\gtrsim 1$s) in the non-thermal hard X-ray (HXR) time profiles of solar flares using high-resolution data from Solar Orbiter's Spectrometer/Telescope for Imaging X-rays (STIX).   Methods: The HXR time profiles were smoothed using Gaussian Process (GP) regression. The time profiles were then fitted with a linear combination of Gaussians to decompose the time profile. From the Gaussian decomposition, key characteristics such as the periodicity, full width at half maximum (FWHM), time evolution, and amplitude can be derived.   Results: We present the outcome of applying this method to four M and X GOES-class flares from the first year of Solar Orbiter science operations. The HXR time profiles of these flares were decomposed into individual Gaussians and their periods were derived. The quality of fit is quantified by the standard deviation of the residuals (difference between observed and fitted curve, normalised by the error on the observed data), for which we obtain $\\leq 1.8$ for all flares presented. In this work, the first detection of fast-time variations with Solar Orbiter's STIX instrument has been made on timescales across the range of 4-128s.   Conclusions: A new method for identifying and characterising fast-time variations in the non-thermal HXR profiles of solar flares has been developed, in which the time profiles are fit with a linear combination of Gaussian bursts. The opportunity to study time variations in flares has greatly improved with the new observations from STIX on Solar Orbiter.","link":"http://arxiv.org/abs/2301.08040v1","created":"2023-01-19","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Characterising fast-time variations in the hard X-ray time profiles of solar flares using Solar Orbiter's STIX Aims: The aim of this work is to develop a method to systematically detect and characterise fast-time variations ($\\gtrsim 1$s) in the non-thermal hard X-ray (HXR) time profiles of solar flares using high-resolution data from Solar Orbiter's Spectrometer/Telescope for Imaging X-rays (STIX).   Methods: The HXR time profiles were smoothed using Gaussian Process (GP) regression. The time profiles were then fitted with a linear combination of Gaussians to decompose the time profile. From the Gaussian decomposition, key characteristics such as the periodicity, full width at half maximum (FWHM), time evolution, and amplitude can be derived.   Results: We present the outcome of applying this method to four M and X GOES-class flares from the first year of Solar Orbiter science operations. The HXR time profiles of these flares were decomposed into individual Gaussians and their periods were derived. The quality of fit is quantified by the standard deviation of the residuals (difference between observed and fitted curve, normalised by the error on the observed data), for which we obtain $\\leq 1.8$ for all flares presented. In this work, the first detection of fast-time variations with Solar Orbiter's STIX instrument has been made on timescales across the range of 4-128s.   Conclusions: A new method for identifying and characterising fast-time variations in the non-thermal HXR profiles of solar flares has been developed, in which the time profiles are fit with a linear combination of Gaussian bursts. The opportunity to study time variations in flares has greatly improved with the new observations from STIX on Solar Orbiter.","classes":{"dataset":0.0383725688}}
{"title":"The Effects of Spatial Interpolation on a Novel, Dual-Doppler 3D Wind Retrieval Technique","description":"Three-dimensional wind retrievals from ground-based Doppler radars have played an important role in meteorological research and nowcasting over the past four decades. However, in recent years, the proliferation of open-source software and increased demands from applications such as convective parameterizations in numerical weather prediction models has led to a renewed interest in these analyses. In this study, we analyze how a major, yet often-overlooked, error source effects the quality of retrieved 3D wind fields. Namely, we investigate the effects of spatial interpolation, and show how the common practice of pre-gridding radial velocity data can degrade the accuracy of the results. Alternatively, we show that assimilating radar data directly at their observation locations improves the retrieval of important dynamic features such as the rear flank downdraft and mesocyclone within a simulated supercell, while also reducing errors in vertical vorticity, horizontal divergence, and all three velocity components. Based on these results, we recommend that analysts assimilate radial velocities directly, and avoid pre-gridding prior to analysis.","link":"http://arxiv.org/abs/2301.07913v1","created":"2023-01-19","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"The Effects of Spatial Interpolation on a Novel, Dual-Doppler 3D Wind Retrieval Technique Three-dimensional wind retrievals from ground-based Doppler radars have played an important role in meteorological research and nowcasting over the past four decades. However, in recent years, the proliferation of open-source software and increased demands from applications such as convective parameterizations in numerical weather prediction models has led to a renewed interest in these analyses. In this study, we analyze how a major, yet often-overlooked, error source effects the quality of retrieved 3D wind fields. Namely, we investigate the effects of spatial interpolation, and show how the common practice of pre-gridding radial velocity data can degrade the accuracy of the results. Alternatively, we show that assimilating radar data directly at their observation locations improves the retrieval of important dynamic features such as the rear flank downdraft and mesocyclone within a simulated supercell, while also reducing errors in vertical vorticity, horizontal divergence, and all three velocity components. Based on these results, we recommend that analysts assimilate radial velocities directly, and avoid pre-gridding prior to analysis.","classes":{"dataset":0.0612562411}}
{"title":"Reconstructing Rayleigh-Benard flows out of temperature-only measurements using Physics-Informed Neural Networks","description":"We investigate the capabilities of Physics-Informed Neural Networks (PINNs) to reconstruct turbulent Rayleigh-Benard flows using only temperature information. We perform a quantitative analysis of the quality of the reconstructions at various amounts of low-passed-filtered information and turbulent intensities. We compare our results with those obtained via nudging, a classical equation-informed data assimilation technique. At low Rayleigh numbers, PINNs are able to reconstruct with high precision, comparable to the one achieved with nudging. At high Rayleigh numbers, PINNs outperform nudging and are able to achieve satisfactory reconstruction of the velocity fields only when data for temperature is provided with high spatial and temporal density. When data becomes sparse, the PINNs performance worsens, not only in a point-to-point error sense but also, and contrary to nudging, in a statistical sense, as can be seen in the probability density functions and energy spectra.","link":"http://arxiv.org/abs/2301.07769v1","created":"2023-01-18","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Reconstructing Rayleigh-Benard flows out of temperature-only measurements using Physics-Informed Neural Networks We investigate the capabilities of Physics-Informed Neural Networks (PINNs) to reconstruct turbulent Rayleigh-Benard flows using only temperature information. We perform a quantitative analysis of the quality of the reconstructions at various amounts of low-passed-filtered information and turbulent intensities. We compare our results with those obtained via nudging, a classical equation-informed data assimilation technique. At low Rayleigh numbers, PINNs are able to reconstruct with high precision, comparable to the one achieved with nudging. At high Rayleigh numbers, PINNs outperform nudging and are able to achieve satisfactory reconstruction of the velocity fields only when data for temperature is provided with high spatial and temporal density. When data becomes sparse, the PINNs performance worsens, not only in a point-to-point error sense but also, and contrary to nudging, in a statistical sense, as can be seen in the probability density functions and energy spectra.","classes":{"dataset":0.3658176363}}
{"title":"HMDO: Markerless Multi-view Hand Manipulation Capture with Deformable Objects","description":"We construct the first markerless deformable interaction dataset recording interactive motions of the hands and deformable objects, called HMDO (Hand Manipulation with Deformable Objects). With our built multi-view capture system, it captures the deformable interactions with multiple perspectives, various object shapes, and diverse interactive forms. Our motivation is the current lack of hand and deformable object interaction datasets, as 3D hand and deformable object reconstruction is challenging. Mainly due to mutual occlusion, the interaction area is difficult to observe, the visual features between the hand and the object are entangled, and the reconstruction of the interaction area deformation is difficult. To tackle this challenge, we propose a method to annotate our captured data. Our key idea is to collaborate with estimated hand features to guide the object global pose estimation, and then optimize the deformation process of the object by analyzing the relationship between the hand and the object. Through comprehensive evaluation, the proposed method can reconstruct interactive motions of hands and deformable objects with high quality. HMDO currently consists of 21600 frames over 12 sequences. In the future, this dataset could boost the research of learning-based reconstruction of deformable interaction scenes.","link":"http://arxiv.org/abs/2301.07652v1","created":"2023-01-18","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"HMDO: Markerless Multi-view Hand Manipulation Capture with Deformable Objects We construct the first markerless deformable interaction dataset recording interactive motions of the hands and deformable objects, called HMDO (Hand Manipulation with Deformable Objects). With our built multi-view capture system, it captures the deformable interactions with multiple perspectives, various object shapes, and diverse interactive forms. Our motivation is the current lack of hand and deformable object interaction datasets, as 3D hand and deformable object reconstruction is challenging. Mainly due to mutual occlusion, the interaction area is difficult to observe, the visual features between the hand and the object are entangled, and the reconstruction of the interaction area deformation is difficult. To tackle this challenge, we propose a method to annotate our captured data. Our key idea is to collaborate with estimated hand features to guide the object global pose estimation, and then optimize the deformation process of the object by analyzing the relationship between the hand and the object. Through comprehensive evaluation, the proposed method can reconstruct interactive motions of hands and deformable objects with high quality. HMDO currently consists of 21600 frames over 12 sequences. In the future, this dataset could boost the research of learning-based reconstruction of deformable interaction scenes.","classes":{"dataset":0.5834814906}}
{"title":"The orbits of visual binary and multiple stars obtained by the Apparent Motion Parameters method during the last 40 years","description":"Summed many years of work at Pulkovo, the orbits of 67 wide pairs of visual double and multiple stars (included in 64 systems) which were obtained by the Apparent Motion Parameters (AMP) method are presented. This short arc determination orbit method is based on the most reliable astrometric and astrophysical data corresponding to one instant of time. The rest of the observations accumulated in the world serve to control the quality of the orbit and refine some parameters. All early determined AMP-orbits were compared with new observations, some of them were recalculated, new ones were added. For the stars of Pulkovo program of observations with a 26-inch refractor, the Gaia DR2 data were analised. Based on these data, the orbits of 16 stars were calculated. In 20 cases from 67, the quasi-instant motion according to the Gaia DR2 data at the instant 2015.5 contradicts the motion according to all-world observations. A possible reason is the presence of inner subsystems. The orientation of the obtained orbits in the galactic coordinate system is also given.","link":"http://arxiv.org/abs/2301.07602v2","created":"2023-01-18","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"The orbits of visual binary and multiple stars obtained by the Apparent Motion Parameters method during the last 40 years Summed many years of work at Pulkovo, the orbits of 67 wide pairs of visual double and multiple stars (included in 64 systems) which were obtained by the Apparent Motion Parameters (AMP) method are presented. This short arc determination orbit method is based on the most reliable astrometric and astrophysical data corresponding to one instant of time. The rest of the observations accumulated in the world serve to control the quality of the orbit and refine some parameters. All early determined AMP-orbits were compared with new observations, some of them were recalculated, new ones were added. For the stars of Pulkovo program of observations with a 26-inch refractor, the Gaia DR2 data were analised. Based on these data, the orbits of 16 stars were calculated. In 20 cases from 67, the quasi-instant motion according to the Gaia DR2 data at the instant 2015.5 contradicts the motion according to all-world observations. A possible reason is the presence of inner subsystems. The orientation of the obtained orbits in the galactic coordinate system is also given.","classes":{"dataset":0.2516676188}}
{"title":"Relaxed Graph Color Bound for the Maximum k-plex Problem","description":"As a relaxation of the clique, a k-plex of a graph is a vertex set that each vertex is not connected with at most k vertices of this set. Given an undirected graph, the Maximum k-plex Problem (MkP) aims to find its largest k-plex. Branch and bound algorithms are a type of well-studied and effective method for exact MkP solving, whose performance depends heavily on the quality of the upper bounds. In this paper, we investigate the relaxation properties of k-plex and propose an effective upper bound called Relaxed Graph color Bound (RGB) for the MkP. To describe and calculate RGB, we propose a new quasi-independent set structure that focuses on the number of conflict vertices. We combine RGB with two of the state-of-the-art branch and bound MkP algorithms, Maplex and KpLeX. Extensive experiments on real-world benchmarks, DIMACS benchmarks, and random graphs show the excellent performance of our proposed method over the state-of-the-art algorithms.","link":"http://arxiv.org/abs/2301.07300v1","created":"2023-01-18","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Relaxed Graph Color Bound for the Maximum k-plex Problem As a relaxation of the clique, a k-plex of a graph is a vertex set that each vertex is not connected with at most k vertices of this set. Given an undirected graph, the Maximum k-plex Problem (MkP) aims to find its largest k-plex. Branch and bound algorithms are a type of well-studied and effective method for exact MkP solving, whose performance depends heavily on the quality of the upper bounds. In this paper, we investigate the relaxation properties of k-plex and propose an effective upper bound called Relaxed Graph color Bound (RGB) for the MkP. To describe and calculate RGB, we propose a new quasi-independent set structure that focuses on the number of conflict vertices. We combine RGB with two of the state-of-the-art branch and bound MkP algorithms, Maplex and KpLeX. Extensive experiments on real-world benchmarks, DIMACS benchmarks, and random graphs show the excellent performance of our proposed method over the state-of-the-art algorithms.","classes":{"dataset":0.4788770974}}
{"title":"The JWST Resolved Stellar Populations Early Release Science Program III: Photometric Star-Galaxy Separations for NIRCam","description":"We present criteria for separately classifying stars and unresolved background galaxies in photometric catalogs generated with the point spread function (PSF) fitting photometry software DOLPHOT from images taken of Draco II, WLM, and M92 with the Near Infrared Camera (NIRCam) on JWST. Photometric quality metrics from DOLPHOT in one or two filters can recover a pure sample of stars. Conversely, colors formed between short-wavelength (SW) and long-wavelength (LW) filters can be used to effectively identify pure samples of galaxies. Our results highlight that the existing DOLPHOT output parameters can be used to reliably classify stars in our NIRCam data without the need to resort to external tools or more complex heuristics.","link":"http://arxiv.org/abs/2301.07218v1","created":"2023-01-17","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"The JWST Resolved Stellar Populations Early Release Science Program III: Photometric Star-Galaxy Separations for NIRCam We present criteria for separately classifying stars and unresolved background galaxies in photometric catalogs generated with the point spread function (PSF) fitting photometry software DOLPHOT from images taken of Draco II, WLM, and M92 with the Near Infrared Camera (NIRCam) on JWST. Photometric quality metrics from DOLPHOT in one or two filters can recover a pure sample of stars. Conversely, colors formed between short-wavelength (SW) and long-wavelength (LW) filters can be used to effectively identify pure samples of galaxies. Our results highlight that the existing DOLPHOT output parameters can be used to reliably classify stars in our NIRCam data without the need to resort to external tools or more complex heuristics.","classes":{"dataset":0.4090856612}}
{"title":"Prompting Large Language Model for Machine Translation: A Case Study","description":"Research on prompting has shown excellent performance with little or even no supervised training across many tasks. However, prompting for machine translation is still under-explored in the literature. We fill this gap by offering a systematic study on prompting strategies for translation, examining various factors for prompt template and demonstration example selection. We further explore the use of monolingual data and the feasibility of cross-lingual, cross-domain, and sentence-to-document transfer learning in prompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the testbed show that 1) the number and the quality of prompt examples matter, where using suboptimal examples degenerates translation; 2) several features of prompt examples, such as semantic similarity, show significant Spearman correlation with their prompting performance; yet, none of the correlations are strong enough; 3) using pseudo parallel prompt examples constructed from monolingual data via zero-shot prompting could improve translation; and 4) improved performance is achievable by transferring knowledge from prompt examples selected in other settings. We finally provide an analysis on the model outputs and discuss several problems that prompting still suffers from.","link":"http://arxiv.org/abs/2301.07069v2","created":"2023-01-17","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Prompting Large Language Model for Machine Translation: A Case Study Research on prompting has shown excellent performance with little or even no supervised training across many tasks. However, prompting for machine translation is still under-explored in the literature. We fill this gap by offering a systematic study on prompting strategies for translation, examining various factors for prompt template and demonstration example selection. We further explore the use of monolingual data and the feasibility of cross-lingual, cross-domain, and sentence-to-document transfer learning in prompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the testbed show that 1) the number and the quality of prompt examples matter, where using suboptimal examples degenerates translation; 2) several features of prompt examples, such as semantic similarity, show significant Spearman correlation with their prompting performance; yet, none of the correlations are strong enough; 3) using pseudo parallel prompt examples constructed from monolingual data via zero-shot prompting could improve translation; and 4) improved performance is achievable by transferring knowledge from prompt examples selected in other settings. We finally provide an analysis on the model outputs and discuss several problems that prompting still suffers from.","classes":{"dataset":0.1514106989}}
{"title":"Sleep Activity Recognition and Characterization from Multi-Source Passively Sensed Data","description":"Sleep constitutes a key indicator of human health, performance, and quality of life. Sleep deprivation has long been related to the onset, development, and worsening of several mental and metabolic disorders, constituting an essential marker for preventing, evaluating, and treating different health conditions. Sleep Activity Recognition methods can provide indicators to assess, monitor, and characterize subjects' sleep-wake cycles and detect behavioral changes. In this work, we propose a general method that continuously operates on passively sensed data from smartphones to characterize sleep and identify significant sleep episodes. Thanks to their ubiquity, these devices constitute an excellent alternative data source to profile subjects' biorhythms in a continuous, objective, and non-invasive manner, in contrast to traditional sleep assessment methods that usually rely on intrusive and subjective procedures. A Heterogeneous Hidden Markov Model is used to model a discrete latent variable process associated with the Sleep Activity Recognition task in a self-supervised way. We validate our results against sleep metrics reported by tested wearables, proving the effectiveness of the proposed approach and advocating its use to assess sleep without more reliable sources.","link":"http://arxiv.org/abs/2301.10156v1","created":"2023-01-17","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Sleep Activity Recognition and Characterization from Multi-Source Passively Sensed Data Sleep constitutes a key indicator of human health, performance, and quality of life. Sleep deprivation has long been related to the onset, development, and worsening of several mental and metabolic disorders, constituting an essential marker for preventing, evaluating, and treating different health conditions. Sleep Activity Recognition methods can provide indicators to assess, monitor, and characterize subjects' sleep-wake cycles and detect behavioral changes. In this work, we propose a general method that continuously operates on passively sensed data from smartphones to characterize sleep and identify significant sleep episodes. Thanks to their ubiquity, these devices constitute an excellent alternative data source to profile subjects' biorhythms in a continuous, objective, and non-invasive manner, in contrast to traditional sleep assessment methods that usually rely on intrusive and subjective procedures. A Heterogeneous Hidden Markov Model is used to model a discrete latent variable process associated with the Sleep Activity Recognition task in a self-supervised way. We validate our results against sleep metrics reported by tested wearables, proving the effectiveness of the proposed approach and advocating its use to assess sleep without more reliable sources.","classes":{"dataset":0.0770208314}}
{"title":"A Semi-supervised Sensing Rate Learning based CMAB Scheme to Combat COVID-19 by Trustful Data Collection in the Crowd","description":"Mobile CrowdSensing (MCS), through employing considerable workers to sense and collect data in a participatory manner, has been recognized as a promising paradigm for building many large-scale applications in a cost-effective way, such as combating COVID-19. The recruitment of trustworthy and high-quality workers is an important research issue for MCS. Previous studies assume that the qualities of workers are known in advance, or the platform knows the qualities of workers once it receives their collected data. In reality, to reduce their costs and thus maximize revenue, many strategic workers do not perform their sensing tasks honestly and report fake data to the platform. So, it is very hard for the platform to evaluate the authenticity of the received data. In this paper, an incentive mechanism named Semi-supervision based Combinatorial Multi-Armed Bandit reverse Auction (SCMABA) is proposed to solve the recruitment problem of multiple unknown and strategic workers in MCS. First, we model the worker recruitment as a multi-armed bandit reverse auction problem, and design an UCB-based algorithm to separate the exploration and exploitation, considering the Sensing Rates (SRs) of recruited workers as the gain of the bandit. Next, a Semi-supervised Sensing Rate Learning (SSRL) approach is proposed to quickly and accurately obtain the workers' SRs, which consists of two phases, supervision and self-supervision. Last, SCMABA is designed organically combining the SRs acquisition mechanism with multi-armed bandit reverse auction, where supervised SR learning is used in the exploration, and the self-supervised one is used in the exploitation. We prove that our SCMABA achieves truthfulness and individual rationality. Additionally, we exhibit outstanding performances of the SCMABA mechanism through in-depth simulations of real-world data traces.","link":"http://arxiv.org/abs/2301.08563v1","created":"2023-01-17","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"A Semi-supervised Sensing Rate Learning based CMAB Scheme to Combat COVID-19 by Trustful Data Collection in the Crowd Mobile CrowdSensing (MCS), through employing considerable workers to sense and collect data in a participatory manner, has been recognized as a promising paradigm for building many large-scale applications in a cost-effective way, such as combating COVID-19. The recruitment of trustworthy and high-quality workers is an important research issue for MCS. Previous studies assume that the qualities of workers are known in advance, or the platform knows the qualities of workers once it receives their collected data. In reality, to reduce their costs and thus maximize revenue, many strategic workers do not perform their sensing tasks honestly and report fake data to the platform. So, it is very hard for the platform to evaluate the authenticity of the received data. In this paper, an incentive mechanism named Semi-supervision based Combinatorial Multi-Armed Bandit reverse Auction (SCMABA) is proposed to solve the recruitment problem of multiple unknown and strategic workers in MCS. First, we model the worker recruitment as a multi-armed bandit reverse auction problem, and design an UCB-based algorithm to separate the exploration and exploitation, considering the Sensing Rates (SRs) of recruited workers as the gain of the bandit. Next, a Semi-supervised Sensing Rate Learning (SSRL) approach is proposed to quickly and accurately obtain the workers' SRs, which consists of two phases, supervision and self-supervision. Last, SCMABA is designed organically combining the SRs acquisition mechanism with multi-armed bandit reverse auction, where supervised SR learning is used in the exploration, and the self-supervised one is used in the exploitation. We prove that our SCMABA achieves truthfulness and individual rationality. Additionally, we exhibit outstanding performances of the SCMABA mechanism through in-depth simulations of real-world data traces.","classes":{"dataset":0.9937800765}}
{"title":"SwinDepth: Unsupervised Depth Estimation using Monocular Sequences via Swin Transformer and Densely Cascaded Network","description":"Monocular depth estimation plays a critical role in various computer vision and robotics applications such as localization, mapping, and 3D object detection. Recently, learning-based algorithms achieve huge success in depth estimation by training models with a large amount of data in a supervised manner. However, it is challenging to acquire dense ground truth depth labels for supervised training, and the unsupervised depth estimation using monocular sequences emerges as a promising alternative. Unfortunately, most studies on unsupervised depth estimation explore loss functions or occlusion masks, and there is little change in model architecture in that ConvNet-based encoder-decoder structure becomes a de-facto standard for depth estimation. In this paper, we employ a convolution-free Swin Transformer as an image feature extractor so that the network can capture both local geometric features and global semantic features for depth estimation. Also, we propose a Densely Cascaded Multi-scale Network (DCMNet) that connects every feature map directly with another from different scales via a top-down cascade pathway. This densely cascaded connectivity reinforces the interconnection between decoding layers and produces high-quality multi-scale depth outputs. The experiments on two different datasets, KITTI and Make3D, demonstrate that our proposed method outperforms existing state-of-the-art unsupervised algorithms.","link":"http://arxiv.org/abs/2301.06715v1","created":"2023-01-17","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"SwinDepth: Unsupervised Depth Estimation using Monocular Sequences via Swin Transformer and Densely Cascaded Network Monocular depth estimation plays a critical role in various computer vision and robotics applications such as localization, mapping, and 3D object detection. Recently, learning-based algorithms achieve huge success in depth estimation by training models with a large amount of data in a supervised manner. However, it is challenging to acquire dense ground truth depth labels for supervised training, and the unsupervised depth estimation using monocular sequences emerges as a promising alternative. Unfortunately, most studies on unsupervised depth estimation explore loss functions or occlusion masks, and there is little change in model architecture in that ConvNet-based encoder-decoder structure becomes a de-facto standard for depth estimation. In this paper, we employ a convolution-free Swin Transformer as an image feature extractor so that the network can capture both local geometric features and global semantic features for depth estimation. Also, we propose a Densely Cascaded Multi-scale Network (DCMNet) that connects every feature map directly with another from different scales via a top-down cascade pathway. This densely cascaded connectivity reinforces the interconnection between decoding layers and produces high-quality multi-scale depth outputs. The experiments on two different datasets, KITTI and Make3D, demonstrate that our proposed method outperforms existing state-of-the-art unsupervised algorithms.","classes":{"dataset":0.1753929406}}
{"title":"Sparsity based morphological identification of heartbeats","description":"The electrocardiogram (ECG) is one of the most common primary tests to evaluate the health of the heart. Reliable automatic interpretation of ECG records is crucial to the goal of improving public health. It can enable a safe inexpensive monitoring. This work presents a new methodology for morphological identification of heartbeats, which is placed outside the usual machine learning framework. The proposal considers the sparsity of the representation of a heartbeat as a parameter for morphological identification. The approach involves greedy algorithms for selecting elements from redundant dictionaries, which should be previously learnt from examples of the classes to be identified. Using different metrics of sparsity, the dictionary rendering the smallest sparsity value, for the equivalent approximation quality of a new heartbeat, classifies the morphology of that beat. This study focuses on a procedure of learning the dictionaries for representing heartbeats and compares several metrics of sparsity for morphological identification on the basis of those metrics. The suitability of the method is illustrated by binary differentiation of Normal and Ventricular heartbeats in the MIT-BIH Arrhythmia data set. In general classification 99.7% of the Normal beats and 97.6% of the Ventricular beats in the testing sets are correctly identified. In interpatient assessment 91.8% of the Normal beats and 91.0% of Ventricular beats are correctly identified. Even more important than these scores is the fact that they are produced on the bases of a single parameter. The numerical tests, designed to emphasise the interpretability and reliability of the approach, demonstrate the potential of the method to contribute towards the development of a well grounded expert system for classification of heartbeats in ECG records.","link":"http://arxiv.org/abs/2301.06538v1","created":"2023-01-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Sparsity based morphological identification of heartbeats The electrocardiogram (ECG) is one of the most common primary tests to evaluate the health of the heart. Reliable automatic interpretation of ECG records is crucial to the goal of improving public health. It can enable a safe inexpensive monitoring. This work presents a new methodology for morphological identification of heartbeats, which is placed outside the usual machine learning framework. The proposal considers the sparsity of the representation of a heartbeat as a parameter for morphological identification. The approach involves greedy algorithms for selecting elements from redundant dictionaries, which should be previously learnt from examples of the classes to be identified. Using different metrics of sparsity, the dictionary rendering the smallest sparsity value, for the equivalent approximation quality of a new heartbeat, classifies the morphology of that beat. This study focuses on a procedure of learning the dictionaries for representing heartbeats and compares several metrics of sparsity for morphological identification on the basis of those metrics. The suitability of the method is illustrated by binary differentiation of Normal and Ventricular heartbeats in the MIT-BIH Arrhythmia data set. In general classification 99.7% of the Normal beats and 97.6% of the Ventricular beats in the testing sets are correctly identified. In interpatient assessment 91.8% of the Normal beats and 91.0% of Ventricular beats are correctly identified. Even more important than these scores is the fact that they are produced on the bases of a single parameter. The numerical tests, designed to emphasise the interpretability and reliability of the approach, demonstrate the potential of the method to contribute towards the development of a well grounded expert system for classification of heartbeats in ECG records.","classes":{"dataset":0.0893687084}}
{"title":"PlasmoFAB: A Benchmark to Foster Machine Learning for Plasmodium falciparum Protein Antigen Candidate Prediction","description":"Motivation: Machine learning methods can be used to support scientific discovery in healthcare-related research fields. However, these methods can only be reliably used if they can be trained on high-quality and curated datasets. Currently, no such dataset for the exploration of Plasmodium falciparum protein antigen candidates exists. The parasite Plasmodium falciparum causes the infectious disease malaria. Thus, identifying potential antigens is of utmost importance for the development of antimalarial drugs and vaccines. Since exploring antigen candidates experimentally is an expensive and time-consuming process, applying machine learning methods to support this process has the potential to accelerate the development of drugs and vaccines which are needed for fighting and controlling malaria.   Results: We developed PlasmoFAB, a curated benchmark that can be used to train machine learning methods for the exploration of Plasmodium falciparum protein antigen candidates. We combined an extensive literature search with domain expertise to create high-quality labels for Plasmodium falciparum specific proteins that distinguish between antigen candidates and intracellular proteins. Additionally, we used our benchmark to compare different well-known prediction models and available protein localization prediction services on the task of identifying protein antigen candidates. We show that available general-purpose services are unable to provide sufficient performance on identifying protein antigen candidates and are outperformed by models that were trained on specialized data.","link":"http://arxiv.org/abs/2301.06454v1","created":"2023-01-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"PlasmoFAB: A Benchmark to Foster Machine Learning for Plasmodium falciparum Protein Antigen Candidate Prediction Motivation: Machine learning methods can be used to support scientific discovery in healthcare-related research fields. However, these methods can only be reliably used if they can be trained on high-quality and curated datasets. Currently, no such dataset for the exploration of Plasmodium falciparum protein antigen candidates exists. The parasite Plasmodium falciparum causes the infectious disease malaria. Thus, identifying potential antigens is of utmost importance for the development of antimalarial drugs and vaccines. Since exploring antigen candidates experimentally is an expensive and time-consuming process, applying machine learning methods to support this process has the potential to accelerate the development of drugs and vaccines which are needed for fighting and controlling malaria.   Results: We developed PlasmoFAB, a curated benchmark that can be used to train machine learning methods for the exploration of Plasmodium falciparum protein antigen candidates. We combined an extensive literature search with domain expertise to create high-quality labels for Plasmodium falciparum specific proteins that distinguish between antigen candidates and intracellular proteins. Additionally, we used our benchmark to compare different well-known prediction models and available protein localization prediction services on the task of identifying protein antigen candidates. We show that available general-purpose services are unable to provide sufficient performance on identifying protein antigen candidates and are outperformed by models that were trained on specialized data.","classes":{"dataset":0.1859767735}}
{"title":"DarkVision: A Benchmark for Low-light Image/Video Perception","description":"Imaging and perception in photon-limited scenarios is necessary for various applications, e.g., night surveillance or photography, high-speed photography, and autonomous driving. In these cases, cameras suffer from low signal-to-noise ratio, which degrades the image quality severely and poses challenges for downstream high-level vision tasks like object detection and recognition. Data-driven methods have achieved enormous success in both image restoration and high-level vision tasks. However, the lack of high-quality benchmark dataset with task-specific accurate annotations for photon-limited images/videos delays the research progress heavily. In this paper, we contribute the first multi-illuminance, multi-camera, and low-light dataset, named DarkVision, serving for both image enhancement and object detection. We provide bright and dark pairs with pixel-wise registration, in which the bright counterpart provides reliable reference for restoration and annotation. The dataset consists of bright-dark pairs of 900 static scenes with objects from 15 categories, and 32 dynamic scenes with 4-category objects. For each scene, images/videos were captured at 5 illuminance levels using three cameras of different grades, and average photons can be reliably estimated from the calibration data for quantitative studies. The static-scene images and dynamic videos respectively contain around 7,344 and 320,667 instances in total. With DarkVision, we established baselines for image/video enhancement and object detection by representative algorithms. To demonstrate an exemplary application of DarkVision, we propose two simple yet effective approaches for improving performance in video enhancement and object detection respectively. We believe DarkVision would advance the state-of-the-arts in both imaging and related computer vision tasks in low-light environment.","link":"http://arxiv.org/abs/2301.06269v1","created":"2023-01-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"DarkVision: A Benchmark for Low-light Image/Video Perception Imaging and perception in photon-limited scenarios is necessary for various applications, e.g., night surveillance or photography, high-speed photography, and autonomous driving. In these cases, cameras suffer from low signal-to-noise ratio, which degrades the image quality severely and poses challenges for downstream high-level vision tasks like object detection and recognition. Data-driven methods have achieved enormous success in both image restoration and high-level vision tasks. However, the lack of high-quality benchmark dataset with task-specific accurate annotations for photon-limited images/videos delays the research progress heavily. In this paper, we contribute the first multi-illuminance, multi-camera, and low-light dataset, named DarkVision, serving for both image enhancement and object detection. We provide bright and dark pairs with pixel-wise registration, in which the bright counterpart provides reliable reference for restoration and annotation. The dataset consists of bright-dark pairs of 900 static scenes with objects from 15 categories, and 32 dynamic scenes with 4-category objects. For each scene, images/videos were captured at 5 illuminance levels using three cameras of different grades, and average photons can be reliably estimated from the calibration data for quantitative studies. The static-scene images and dynamic videos respectively contain around 7,344 and 320,667 instances in total. With DarkVision, we established baselines for image/video enhancement and object detection by representative algorithms. To demonstrate an exemplary application of DarkVision, we propose two simple yet effective approaches for improving performance in video enhancement and object detection respectively. We believe DarkVision would advance the state-of-the-arts in both imaging and related computer vision tasks in low-light environment.","classes":{"dataset":0.3474093378}}
{"title":"BuildSeg: A General Framework for the Segmentation of Buildings","description":"Building segmentation from aerial images and 3D laser scanning (LiDAR) is a challenging task due to the diversity of backgrounds, building textures, and image quality. While current research using different types of convolutional and transformer networks has considerably improved the performance on this task, even more accurate segmentation methods for buildings are desirable for applications such as automatic mapping. In this study, we propose a general framework termed \\emph{BuildSeg} employing a generic approach that can be quickly applied to segment buildings. Different data sources were combined to increase generalization performance. The approach yields good results for different data sources as shown by experiments on high-resolution multi-spectral and LiDAR imagery of cities in Norway, Denmark and France. We applied ConvNeXt and SegFormer based models on the high resolution aerial image dataset from the MapAI-competition. The methods achieved an IOU of 0.7902 and a boundary IOU of 0.6185. We used post-processing to account for the rectangular shape of the objects. This increased the boundary IOU from 0.6185 to 0.6189.","link":"http://arxiv.org/abs/2301.06190v1","created":"2023-01-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"BuildSeg: A General Framework for the Segmentation of Buildings Building segmentation from aerial images and 3D laser scanning (LiDAR) is a challenging task due to the diversity of backgrounds, building textures, and image quality. While current research using different types of convolutional and transformer networks has considerably improved the performance on this task, even more accurate segmentation methods for buildings are desirable for applications such as automatic mapping. In this study, we propose a general framework termed \\emph{BuildSeg} employing a generic approach that can be quickly applied to segment buildings. Different data sources were combined to increase generalization performance. The approach yields good results for different data sources as shown by experiments on high-resolution multi-spectral and LiDAR imagery of cities in Norway, Denmark and France. We applied ConvNeXt and SegFormer based models on the high resolution aerial image dataset from the MapAI-competition. The methods achieved an IOU of 0.7902 and a boundary IOU of 0.6185. We used post-processing to account for the rectangular shape of the objects. This increased the boundary IOU from 0.6185 to 0.6189.","classes":{"dataset":0.2276040614}}
{"title":"Learning to Compress Unmanned Aerial Vehicle (UAV) Captured Video: Benchmark and Analysis","description":"During the past decade, the Unmanned-Aerial-Vehicles (UAVs) have attracted increasing attention due to their flexible, extensive, and dynamic space-sensing capabilities. The volume of video captured by UAVs is exponentially growing along with the increased bitrate generated by the advancement of the sensors mounted on UAVs, bringing new challenges for on-device UAV storage and air-ground data transmission. Most existing video compression schemes were designed for natural scenes without consideration of specific texture and view characteristics of UAV videos. In this work, we first contribute a detailed analysis of the current state of the field of UAV video coding. Then we propose to establish a novel task for learned UAV video coding and construct a comprehensive and systematic benchmark for such a task, present a thorough review of high quality UAV video datasets and benchmarks, and contribute extensive rate-distortion efficiency comparison of learned and conventional codecs after. Finally, we discuss the challenges of encoding UAV videos. It is expected that the benchmark will accelerate the research and development in video coding on drone platforms.","link":"http://arxiv.org/abs/2301.06115v1","created":"2023-01-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Learning to Compress Unmanned Aerial Vehicle (UAV) Captured Video: Benchmark and Analysis During the past decade, the Unmanned-Aerial-Vehicles (UAVs) have attracted increasing attention due to their flexible, extensive, and dynamic space-sensing capabilities. The volume of video captured by UAVs is exponentially growing along with the increased bitrate generated by the advancement of the sensors mounted on UAVs, bringing new challenges for on-device UAV storage and air-ground data transmission. Most existing video compression schemes were designed for natural scenes without consideration of specific texture and view characteristics of UAV videos. In this work, we first contribute a detailed analysis of the current state of the field of UAV video coding. Then we propose to establish a novel task for learned UAV video coding and construct a comprehensive and systematic benchmark for such a task, present a thorough review of high quality UAV video datasets and benchmarks, and contribute extensive rate-distortion efficiency comparison of learned and conventional codecs after. Finally, we discuss the challenges of encoding UAV videos. It is expected that the benchmark will accelerate the research and development in video coding on drone platforms.","classes":{"dataset":0.4700861871}}
{"title":"Rethinking Precision of Pseudo Label: Test-Time Adaptation via Complementary Learning","description":"In this work, we propose a novel complementary learning approach to enhance test-time adaptation (TTA), which has been proven to exhibit good performance on testing data with distribution shifts such as corruptions. In test-time adaptation tasks, information from the source domain is typically unavailable and the model has to be optimized without supervision for test-time samples. Hence, usual methods assign labels for unannotated data with the prediction by a well-trained source model in an unsupervised learning framework. Previous studies have employed unsupervised objectives, such as the entropy of model predictions, as optimization targets to effectively learn features for test-time samples. However, the performance of the model is easily compromised by the quality of pseudo-labels, since inaccuracies in pseudo-labels introduce noise to the model. Therefore, we propose to leverage the \"less probable categories\" to decrease the risk of incorrect pseudo-labeling. The complementary label is introduced to designate these categories. We highlight that the risk function of complementary labels agrees with their Vanilla loss formula under the conventional true label distribution. Experiments show that the proposed learning algorithm achieves state-of-the-art performance on different datasets and experiment settings.","link":"http://arxiv.org/abs/2301.06013v1","created":"2023-01-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Rethinking Precision of Pseudo Label: Test-Time Adaptation via Complementary Learning In this work, we propose a novel complementary learning approach to enhance test-time adaptation (TTA), which has been proven to exhibit good performance on testing data with distribution shifts such as corruptions. In test-time adaptation tasks, information from the source domain is typically unavailable and the model has to be optimized without supervision for test-time samples. Hence, usual methods assign labels for unannotated data with the prediction by a well-trained source model in an unsupervised learning framework. Previous studies have employed unsupervised objectives, such as the entropy of model predictions, as optimization targets to effectively learn features for test-time samples. However, the performance of the model is easily compromised by the quality of pseudo-labels, since inaccuracies in pseudo-labels introduce noise to the model. Therefore, we propose to leverage the \"less probable categories\" to decrease the risk of incorrect pseudo-labeling. The complementary label is introduced to designate these categories. We highlight that the risk function of complementary labels agrees with their Vanilla loss formula under the conventional true label distribution. Experiments show that the proposed learning algorithm achieves state-of-the-art performance on different datasets and experiment settings.","classes":{"dataset":0.3636454344}}
{"title":"Conceptual Framework and Documentation Standards of Cystoscopic Media Content for Artificial Intelligence","description":"Background: The clinical documentation of cystoscopy includes visual and textual materials. However, the secondary use of visual cystoscopic data for educational and research purposes remains limited due to inefficient data management in routine clinical practice. Methods: A conceptual framework was designed to document cystoscopy in a standardized manner with three major sections: data management, annotation management, and utilization management. A Swiss-cheese model was proposed for quality control and root cause analyses. We defined the infrastructure required to implement the framework with respect to FAIR (findable, accessible, interoperable, re-usable) principles. We applied two scenarios exemplifying data sharing for research and educational projects to ensure the compliance with FAIR principles. Results: The framework was successfully implemented while following FAIR principles. The cystoscopy atlas produced from the framework could be presented in an educational web portal; a total of 68 full-length qualitative videos and corresponding annotation data were sharable for artificial intelligence projects covering frame classification and segmentation problems at case, lesion and frame levels. Conclusion: Our study shows that the proposed framework facilitates the storage of the visual documentation in a standardized manner and enables FAIR data for education and artificial intelligence research.","link":"http://arxiv.org/abs/2301.05991v2","created":"2023-01-14","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Conceptual Framework and Documentation Standards of Cystoscopic Media Content for Artificial Intelligence Background: The clinical documentation of cystoscopy includes visual and textual materials. However, the secondary use of visual cystoscopic data for educational and research purposes remains limited due to inefficient data management in routine clinical practice. Methods: A conceptual framework was designed to document cystoscopy in a standardized manner with three major sections: data management, annotation management, and utilization management. A Swiss-cheese model was proposed for quality control and root cause analyses. We defined the infrastructure required to implement the framework with respect to FAIR (findable, accessible, interoperable, re-usable) principles. We applied two scenarios exemplifying data sharing for research and educational projects to ensure the compliance with FAIR principles. Results: The framework was successfully implemented while following FAIR principles. The cystoscopy atlas produced from the framework could be presented in an educational web portal; a total of 68 full-length qualitative videos and corresponding annotation data were sharable for artificial intelligence projects covering frame classification and segmentation problems at case, lesion and frame levels. Conclusion: Our study shows that the proposed framework facilitates the storage of the visual documentation in a standardized manner and enables FAIR data for education and artificial intelligence research.","classes":{"dataset":0.3231391907}}
{"title":"Model-based Transfer Learning for Automatic Optical Inspection based on domain discrepancy","description":"Transfer learning is a promising method for AOI applications since it can significantly shorten sample collection time and improve efficiency in today's smart manufacturing. However, related research enhanced the network models by applying TL without considering the domain similarity among datasets, the data long-tailedness of a source dataset, and mainly used linear transformations to mitigate the lack of samples. This research applies model-based TL via domain similarity to improve the overall performance and data augmentation in both target and source domains to enrich the data quality and reduce the imbalance. Given a group of source datasets from similar industrial processes, we define which group is the most related to the target through the domain discrepancy score and the number of samples each has. Then, we transfer the chosen pre-trained backbone weights to train and fine-tune the target network. Our research suggests increases in the F1 score and the PR curve up to 20% compared with TL using benchmark datasets.","link":"http://arxiv.org/abs/2301.05897v1","created":"2023-01-14","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Model-based Transfer Learning for Automatic Optical Inspection based on domain discrepancy Transfer learning is a promising method for AOI applications since it can significantly shorten sample collection time and improve efficiency in today's smart manufacturing. However, related research enhanced the network models by applying TL without considering the domain similarity among datasets, the data long-tailedness of a source dataset, and mainly used linear transformations to mitigate the lack of samples. This research applies model-based TL via domain similarity to improve the overall performance and data augmentation in both target and source domains to enrich the data quality and reduce the imbalance. Given a group of source datasets from similar industrial processes, we define which group is the most related to the target through the domain discrepancy score and the number of samples each has. Then, we transfer the chosen pre-trained backbone weights to train and fine-tune the target network. Our research suggests increases in the F1 score and the PR curve up to 20% compared with TL using benchmark datasets.","classes":{"dataset":0.3457558751}}
{"title":"Safe Control Transitions: Machine Vision Based Observable Readiness Index and Data-Driven Takeover Time Prediction","description":"To make safe transitions from autonomous to manual control, a vehicle must have a representation of the awareness of driver state; two metrics which quantify this state are the Observable Readiness Index and Takeover Time. In this work, we show that machine learning models which predict these two metrics are robust to multiple camera views, expanding from the limited view angles in prior research. Importantly, these models take as input feature vectors corresponding to hand location and activity as well as gaze location, and we explore the tradeoffs of different views in generating these feature vectors. Further, we introduce two metrics to evaluate the quality of control transitions following the takeover event (the maximal lateral deviation and velocity deviation) and compute correlations of these post-takeover metrics to the pre-takeover predictive metrics.","link":"http://arxiv.org/abs/2301.05805v2","created":"2023-01-14","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Safe Control Transitions: Machine Vision Based Observable Readiness Index and Data-Driven Takeover Time Prediction To make safe transitions from autonomous to manual control, a vehicle must have a representation of the awareness of driver state; two metrics which quantify this state are the Observable Readiness Index and Takeover Time. In this work, we show that machine learning models which predict these two metrics are robust to multiple camera views, expanding from the limited view angles in prior research. Importantly, these models take as input feature vectors corresponding to hand location and activity as well as gaze location, and we explore the tradeoffs of different views in generating these feature vectors. Further, we introduce two metrics to evaluate the quality of control transitions following the takeover event (the maximal lateral deviation and velocity deviation) and compute correlations of these post-takeover metrics to the pre-takeover predictive metrics.","classes":{"dataset":0.1499511153}}
{"title":"Price impact in equity auctions: zero, then linear","description":"Using high-quality data, we report several statistical regularities of equity auctions in the Paris stock exchange. First, the average order book density is linear around the auction price at the time of auction clearing and has a large peak at the auction price. The linear part comes from fast traders, while the peak is due to slow traders. The impact of a new market order or cancellation at the auction time can be decomposed into three parts as a function of the size of the additional order: (1) zero impact because of the discrete nature of prices; this holds for surprisingly large orders relative to the auction volume (2) linear impact for additional orders up to a large fraction of the auction volume (3) for even larger orders price impact is non-linear, frequently superlinear.","link":"http://arxiv.org/abs/2301.05677v1","created":"2023-01-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Price impact in equity auctions: zero, then linear Using high-quality data, we report several statistical regularities of equity auctions in the Paris stock exchange. First, the average order book density is linear around the auction price at the time of auction clearing and has a large peak at the auction price. The linear part comes from fast traders, while the peak is due to slow traders. The impact of a new market order or cancellation at the auction time can be decomposed into three parts as a function of the size of the additional order: (1) zero impact because of the discrete nature of prices; this holds for surprisingly large orders relative to the auction volume (2) linear impact for additional orders up to a large fraction of the auction volume (3) for even larger orders price impact is non-linear, frequently superlinear.","classes":{"dataset":0.9691508412}}
{"title":"Understanding Concept Identification as Consistent Data Clustering Across Multiple Feature Spaces","description":"Identifying meaningful concepts in large data sets can provide valuable insights into engineering design problems. Concept identification aims at identifying non-overlapping groups of design instances that are similar in a joint space of all features, but which are also similar when considering only subsets of features. These subsets usually comprise features that characterize a design with respect to one specific context, for example, constructive design parameters, performance values, or operation modes. It is desirable to evaluate the quality of design concepts by considering several of these feature subsets in isolation. In particular, meaningful concepts should not only identify dense, well separated groups of data instances, but also provide non-overlapping groups of data that persist when considering pre-defined feature subsets separately. In this work, we propose to view concept identification as a special form of clustering algorithm with a broad range of potential applications beyond engineering design. To illustrate the differences between concept identification and classical clustering algorithms, we apply a recently proposed concept identification algorithm to two synthetic data sets and show the differences in identified solutions. In addition, we introduce the mutual information measure as a metric to evaluate whether solutions return consistent clusters across relevant subsets. To support the novel understanding of concept identification, we consider a simulated data set from a decision-making problem in the energy management domain and show that the identified clusters are more interpretable with respect to relevant feature subsets than clusters found by common clustering algorithms and are thus more suitable to support a decision maker.","link":"http://arxiv.org/abs/2301.05525v1","created":"2023-01-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Understanding Concept Identification as Consistent Data Clustering Across Multiple Feature Spaces Identifying meaningful concepts in large data sets can provide valuable insights into engineering design problems. Concept identification aims at identifying non-overlapping groups of design instances that are similar in a joint space of all features, but which are also similar when considering only subsets of features. These subsets usually comprise features that characterize a design with respect to one specific context, for example, constructive design parameters, performance values, or operation modes. It is desirable to evaluate the quality of design concepts by considering several of these feature subsets in isolation. In particular, meaningful concepts should not only identify dense, well separated groups of data instances, but also provide non-overlapping groups of data that persist when considering pre-defined feature subsets separately. In this work, we propose to view concept identification as a special form of clustering algorithm with a broad range of potential applications beyond engineering design. To illustrate the differences between concept identification and classical clustering algorithms, we apply a recently proposed concept identification algorithm to two synthetic data sets and show the differences in identified solutions. In addition, we introduce the mutual information measure as a metric to evaluate whether solutions return consistent clusters across relevant subsets. To support the novel understanding of concept identification, we consider a simulated data set from a decision-making problem in the energy management domain and show that the identified clusters are more interpretable with respect to relevant feature subsets than clusters found by common clustering algorithms and are thus more suitable to support a decision maker.","classes":{"dataset":0.2182114571}}
{"title":"Scalable Batch Acquisition for Deep Bayesian Active Learning","description":"In deep active learning, it is especially important to choose multiple examples to markup at each step to work efficiently, especially on large datasets. At the same time, existing solutions to this problem in the Bayesian setup, such as BatchBALD, have significant limitations in selecting a large number of examples, associated with the exponential complexity of computing mutual information for joint random variables. We, therefore, present the Large BatchBALD algorithm, which gives a well-grounded approximation to the BatchBALD method that aims to achieve comparable quality while being more computationally efficient. We provide a complexity analysis of the algorithm, showing a reduction in computation time, especially for large batches. Furthermore, we present an extensive set of experimental results on image and text data, both on toy datasets and larger ones such as CIFAR-100.","link":"http://arxiv.org/abs/2301.05490v1","created":"2023-01-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Scalable Batch Acquisition for Deep Bayesian Active Learning In deep active learning, it is especially important to choose multiple examples to markup at each step to work efficiently, especially on large datasets. At the same time, existing solutions to this problem in the Bayesian setup, such as BatchBALD, have significant limitations in selecting a large number of examples, associated with the exponential complexity of computing mutual information for joint random variables. We, therefore, present the Large BatchBALD algorithm, which gives a well-grounded approximation to the BatchBALD method that aims to achieve comparable quality while being more computationally efficient. We provide a complexity analysis of the algorithm, showing a reduction in computation time, especially for large batches. Furthermore, we present an extensive set of experimental results on image and text data, both on toy datasets and larger ones such as CIFAR-100.","classes":{"dataset":0.0917095318}}
{"title":"Explicit Temporal Embedding in Deep Generative Latent Models for Longitudinal Medical Image Synthesis","description":"Medical imaging plays a vital role in modern diagnostics and treatment. The temporal nature of disease or treatment progression often results in longitudinal data. Due to the cost and potential harm, acquiring large medical datasets necessary for deep learning can be difficult. Medical image synthesis could help mitigate this problem. However, until now, the availability of GANs capable of synthesizing longitudinal volumetric data has been limited. To address this, we use the recent advances in latent space-based image editing to propose a novel joint learning scheme to explicitly embed temporal dependencies in the latent space of GANs. This, in contrast to previous methods, allows us to synthesize continuous, smooth, and high-quality longitudinal volumetric data with limited supervision. We show the effectiveness of our approach on three datasets containing different longitudinal dependencies. Namely, modeling a simple image transformation, breathing motion, and tumor regression, all while showing minimal disentanglement. The implementation is made available online at https://github.com/julschoen/Temp-GAN.","link":"http://arxiv.org/abs/2301.05465v1","created":"2023-01-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Explicit Temporal Embedding in Deep Generative Latent Models for Longitudinal Medical Image Synthesis Medical imaging plays a vital role in modern diagnostics and treatment. The temporal nature of disease or treatment progression often results in longitudinal data. Due to the cost and potential harm, acquiring large medical datasets necessary for deep learning can be difficult. Medical image synthesis could help mitigate this problem. However, until now, the availability of GANs capable of synthesizing longitudinal volumetric data has been limited. To address this, we use the recent advances in latent space-based image editing to propose a novel joint learning scheme to explicitly embed temporal dependencies in the latent space of GANs. This, in contrast to previous methods, allows us to synthesize continuous, smooth, and high-quality longitudinal volumetric data with limited supervision. We show the effectiveness of our approach on three datasets containing different longitudinal dependencies. Namely, modeling a simple image transformation, breathing motion, and tumor regression, all while showing minimal disentanglement. The implementation is made available online at https://github.com/julschoen/Temp-GAN.","classes":{"dataset":0.3360233009}}
{"title":"LVRNet: Lightweight Image Restoration for Aerial Images under Low Visibility","description":"Learning to recover clear images from images having a combination of degrading factors is a challenging task. That being said, autonomous surveillance in low visibility conditions caused by high pollution/smoke, poor air quality index, low light, atmospheric scattering, and haze during a blizzard becomes even more important to prevent accidents. It is thus crucial to form a solution that can result in a high-quality image and is efficient enough to be deployed for everyday use. However, the lack of proper datasets available to tackle this task limits the performance of the previous methods proposed. To this end, we generate the LowVis-AFO dataset, containing 3647 paired dark-hazy and clear images. We also introduce a lightweight deep learning model called Low-Visibility Restoration Network (LVRNet). It outperforms previous image restoration methods with low latency, achieving a PSNR value of 25.744 and an SSIM of 0.905, making our approach scalable and ready for practical use. The code and data can be found at https://github.com/Achleshwar/LVRNet.","link":"http://arxiv.org/abs/2301.05434v1","created":"2023-01-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"LVRNet: Lightweight Image Restoration for Aerial Images under Low Visibility Learning to recover clear images from images having a combination of degrading factors is a challenging task. That being said, autonomous surveillance in low visibility conditions caused by high pollution/smoke, poor air quality index, low light, atmospheric scattering, and haze during a blizzard becomes even more important to prevent accidents. It is thus crucial to form a solution that can result in a high-quality image and is efficient enough to be deployed for everyday use. However, the lack of proper datasets available to tackle this task limits the performance of the previous methods proposed. To this end, we generate the LowVis-AFO dataset, containing 3647 paired dark-hazy and clear images. We also introduce a lightweight deep learning model called Low-Visibility Restoration Network (LVRNet). It outperforms previous image restoration methods with low latency, achieving a PSNR value of 25.744 and an SSIM of 0.905, making our approach scalable and ready for practical use. The code and data can be found at https://github.com/Achleshwar/LVRNet.","classes":{"dataset":0.0130396783}}
{"title":"Surface magnetic field of the A-type metallic-line star omicron Pegasi revisited","description":"The bright A-type metallic-line star o Peg was reported in the early 1990s to have a surface magnetic field of ~2kG by analyzing the widths and strengths of spectral lines. In respect that those old studies were of rather empirical or approximate nature and the quality of observational data was not sufficient, this problem has been newly reinvestigated based on physically more rigorous simulations of line flux profiles, along with the observed equivalent widths (W) and full-widths at half-maximum (h) of 198 Fe I and 182 Fe II lines measured from the high-quality spectra. Given the Fe abundance derived from the conventional analysis, theoretical W and h values calculated for various sets of parameters were compared with the observed ones, which lead to the following conclusion regarding <H> (mean field strength). (1) An analysis of W yielded <H>~1-1.5kG from Fe II lines with the microturbulence of vt~1.5km/s. (2) A comparison of h resulted in <H>~1.5-2kG as well as the projected rotational velocity of vsini~5km/s. (3) Accordingly, the existence of mean magnetic field on the order of <H>~1-2kG in o Peg was confirmed, which is almost consistent with the consequence of the previous work.","link":"http://arxiv.org/abs/2301.05367v1","created":"2023-01-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Surface magnetic field of the A-type metallic-line star omicron Pegasi revisited The bright A-type metallic-line star o Peg was reported in the early 1990s to have a surface magnetic field of ~2kG by analyzing the widths and strengths of spectral lines. In respect that those old studies were of rather empirical or approximate nature and the quality of observational data was not sufficient, this problem has been newly reinvestigated based on physically more rigorous simulations of line flux profiles, along with the observed equivalent widths (W) and full-widths at half-maximum (h) of 198 Fe I and 182 Fe II lines measured from the high-quality spectra. Given the Fe abundance derived from the conventional analysis, theoretical W and h values calculated for various sets of parameters were compared with the observed ones, which lead to the following conclusion regarding <H> (mean field strength). (1) An analysis of W yielded <H>~1-1.5kG from Fe II lines with the microturbulence of vt~1.5km/s. (2) A comparison of h resulted in <H>~1.5-2kG as well as the projected rotational velocity of vsini~5km/s. (3) Accordingly, the existence of mean magnetic field on the order of <H>~1-2kG in o Peg was confirmed, which is almost consistent with the consequence of the previous work.","classes":{"dataset":0.1006327569}}
{"title":"Modeling Strong Lenses from Wide-Field Ground-Based Observations in KiDS and GAMA","description":"Despite the success of galaxy-scale strong gravitational lens studies with Hubble-quality imaging, the number of well-studied strong lenses remains small. As a result, robust comparisons of the lens models to theoretical predictions are difficult. This motivates our application of automated Bayesian lens modeling methods to observations from public data releases of overlapping large ground-based imaging and spectroscopic surveys: Kilo-Degree Survey (KiDS) and Galaxy and Mass Assembly (GAMA), respectively. We use the open-source lens modeling software PyAutoLens to perform our analysis. We demonstrate the feasibility of strong lens modeling with large-survey data at lower resolution as a complementary avenue to studies that utilize more time-consuming and expensive observations of individual lenses at higher resolution. We discuss advantages and challenges, with special consideration given to determining background source redshifts from single-aperture spectra and to disentangling foreground lens and background source light. High uncertainties in the best-fit parameters for the models due to the limits of optical resolution in ground-based observatories and the small sample size can be improved with future study. We give broadly applicable recommendations for future efforts, and with proper application this approach could yield measurements in the quantities needed for robust statistical inference.","link":"http://arxiv.org/abs/2301.05320v2","created":"2023-01-12","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Modeling Strong Lenses from Wide-Field Ground-Based Observations in KiDS and GAMA Despite the success of galaxy-scale strong gravitational lens studies with Hubble-quality imaging, the number of well-studied strong lenses remains small. As a result, robust comparisons of the lens models to theoretical predictions are difficult. This motivates our application of automated Bayesian lens modeling methods to observations from public data releases of overlapping large ground-based imaging and spectroscopic surveys: Kilo-Degree Survey (KiDS) and Galaxy and Mass Assembly (GAMA), respectively. We use the open-source lens modeling software PyAutoLens to perform our analysis. We demonstrate the feasibility of strong lens modeling with large-survey data at lower resolution as a complementary avenue to studies that utilize more time-consuming and expensive observations of individual lenses at higher resolution. We discuss advantages and challenges, with special consideration given to determining background source redshifts from single-aperture spectra and to disentangling foreground lens and background source light. High uncertainties in the best-fit parameters for the models due to the limits of optical resolution in ground-based observatories and the small sample size can be improved with future study. We give broadly applicable recommendations for future efforts, and with proper application this approach could yield measurements in the quantities needed for robust statistical inference.","classes":{"dataset":0.3392943144}}
{"title":"Efficient Flow-Guided Multi-frame De-fencing","description":"Taking photographs ''in-the-wild'' is often hindered by fence obstructions that stand between the camera user and the scene of interest, and which are hard or impossible to avoid. De-fencing is the algorithmic process of automatically removing such obstructions from images, revealing the invisible parts of the scene. While this problem can be formulated as a combination of fence segmentation and image inpainting, this often leads to implausible hallucinations of the occluded regions. Existing multi-frame approaches rely on propagating information to a selected keyframe from its temporal neighbors, but they are often inefficient and struggle with alignment of severely obstructed images. In this work we draw inspiration from the video completion literature and develop a simplified framework for multi-frame de-fencing that computes high quality flow maps directly from obstructed frames and uses them to accurately align frames. Our primary focus is efficiency and practicality in a real-world setting: the input to our algorithm is a short image burst (5 frames) - a data modality commonly available in modern smartphones - and the output is a single reconstructed keyframe, with the fence removed. Our approach leverages simple yet effective CNN modules, trained on carefully generated synthetic data, and outperforms more complicated alternatives real bursts, both quantitatively and qualitatively, while running real-time.","link":"http://arxiv.org/abs/2301.10759v1","created":"2023-01-25","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Efficient Flow-Guided Multi-frame De-fencing Taking photographs ''in-the-wild'' is often hindered by fence obstructions that stand between the camera user and the scene of interest, and which are hard or impossible to avoid. De-fencing is the algorithmic process of automatically removing such obstructions from images, revealing the invisible parts of the scene. While this problem can be formulated as a combination of fence segmentation and image inpainting, this often leads to implausible hallucinations of the occluded regions. Existing multi-frame approaches rely on propagating information to a selected keyframe from its temporal neighbors, but they are often inefficient and struggle with alignment of severely obstructed images. In this work we draw inspiration from the video completion literature and develop a simplified framework for multi-frame de-fencing that computes high quality flow maps directly from obstructed frames and uses them to accurately align frames. Our primary focus is efficiency and practicality in a real-world setting: the input to our algorithm is a short image burst (5 frames) - a data modality commonly available in modern smartphones - and the output is a single reconstructed keyframe, with the fence removed. Our approach leverages simple yet effective CNN modules, trained on carefully generated synthetic data, and outperforms more complicated alternatives real bursts, both quantitatively and qualitatively, while running real-time.","classes":{"dataset":0.2381349951}}
{"title":"Towards Mobility Management with Multi-Objective Bayesian Optimization","description":"One of the consequences of network densification is more frequent handovers (HO). HO failures have a direct impact on the quality of service and are undesirable, especially in scenarios with strict latency, reliability, and robustness constraints. In traditional networks, HO-related parameters are usually tuned by the network operator, and automated techniques are still based on past experience. In this paper, we propose an approach for optimizing HO thresholds using Bayesian Optimization (BO). We formulate a multi-objective optimization problem for selecting the HO thresholds that minimize HOs too early and too late in indoor factory scenarios, and we use multi-objective BO (MOBO) for finding the optimal values. Our results show that MOBO reaches Pareto optimal solutions with few samples and ensures service continuation through safe exploration of new data points.","link":"http://arxiv.org/abs/2301.10635v1","created":"2023-01-25","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Towards Mobility Management with Multi-Objective Bayesian Optimization One of the consequences of network densification is more frequent handovers (HO). HO failures have a direct impact on the quality of service and are undesirable, especially in scenarios with strict latency, reliability, and robustness constraints. In traditional networks, HO-related parameters are usually tuned by the network operator, and automated techniques are still based on past experience. In this paper, we propose an approach for optimizing HO thresholds using Bayesian Optimization (BO). We formulate a multi-objective optimization problem for selecting the HO thresholds that minimize HOs too early and too late in indoor factory scenarios, and we use multi-objective BO (MOBO) for finding the optimal values. Our results show that MOBO reaches Pareto optimal solutions with few samples and ensures service continuation through safe exploration of new data points.","classes":{"dataset":0.0195339546}}
{"title":"Multilingual Multiaccented Multispeaker TTS with RADTTS","description":"We work to create a multilingual speech synthesis system which can generate speech with the proper accent while retaining the characteristics of an individual voice. This is challenging to do because it is expensive to obtain bilingual training data in multiple languages, and the lack of such data results in strong correlations that entangle speaker, language, and accent, resulting in poor transfer capabilities. To overcome this, we present a multilingual, multiaccented, multispeaker speech synthesis model based on RADTTS with explicit control over accent, language, speaker and fine-grained $F_0$ and energy features. Our proposed model does not rely on bilingual training data. We demonstrate an ability to control synthesized accent for any speaker in an open-source dataset comprising of 7 accents. Human subjective evaluation demonstrates that our model can better retain a speaker's voice and accent quality than controlled baselines while synthesizing fluent speech in all target languages and accents in our dataset.","link":"http://arxiv.org/abs/2301.10335v1","created":"2023-01-24","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Multilingual Multiaccented Multispeaker TTS with RADTTS We work to create a multilingual speech synthesis system which can generate speech with the proper accent while retaining the characteristics of an individual voice. This is challenging to do because it is expensive to obtain bilingual training data in multiple languages, and the lack of such data results in strong correlations that entangle speaker, language, and accent, resulting in poor transfer capabilities. To overcome this, we present a multilingual, multiaccented, multispeaker speech synthesis model based on RADTTS with explicit control over accent, language, speaker and fine-grained $F_0$ and energy features. Our proposed model does not rely on bilingual training data. We demonstrate an ability to control synthesized accent for any speaker in an open-source dataset comprising of 7 accents. Human subjective evaluation demonstrates that our model can better retain a speaker's voice and accent quality than controlled baselines while synthesizing fluent speech in all target languages and accents in our dataset.","classes":{"dataset":0.2108109146}}
{"title":"Database Reconstruction Is Not So Easy and Is Different from Reidentification","description":"In recent years, it has been claimed that releasing accurate statistical information on a database is likely to allow its complete reconstruction. Differential privacy has been suggested as the appropriate methodology to prevent these attacks. These claims have recently been taken very seriously by the U.S. Census Bureau and led them to adopt differential privacy for releasing U.S. Census data. This in turn has caused consternation among users of the Census data due to the lack of accuracy of the protected outputs. It has also brought legal action against the U.S. Department of Commerce. In this paper, we trace the origins of the claim that releasing information on a database automatically makes it vulnerable to being exposed by reconstruction attacks and we show that this claim is, in fact, incorrect. We also show that reconstruction can be averted by properly using traditional statistical disclosure control (SDC) techniques. We further show that the geographic level at which exact counts are released is even more relevant to protection than the actual SDC method employed. Finally, we caution against confusing reconstruction and reidentification: using the quality of reconstruction as a metric of reidentification results in exaggerated reidentification risk figures.","link":"http://arxiv.org/abs/2301.10213v1","created":"2023-01-24","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Database Reconstruction Is Not So Easy and Is Different from Reidentification In recent years, it has been claimed that releasing accurate statistical information on a database is likely to allow its complete reconstruction. Differential privacy has been suggested as the appropriate methodology to prevent these attacks. These claims have recently been taken very seriously by the U.S. Census Bureau and led them to adopt differential privacy for releasing U.S. Census data. This in turn has caused consternation among users of the Census data due to the lack of accuracy of the protected outputs. It has also brought legal action against the U.S. Department of Commerce. In this paper, we trace the origins of the claim that releasing information on a database automatically makes it vulnerable to being exposed by reconstruction attacks and we show that this claim is, in fact, incorrect. We also show that reconstruction can be averted by properly using traditional statistical disclosure control (SDC) techniques. We further show that the geographic level at which exact counts are released is even more relevant to protection than the actual SDC method employed. Finally, we caution against confusing reconstruction and reidentification: using the quality of reconstruction as a metric of reidentification results in exaggerated reidentification risk figures.","classes":{"dataset":0.2972775102}}
{"title":"Enhanced Sharp-GAN For Histopathology Image Synthesis","description":"Histopathology image synthesis aims to address the data shortage issue in training deep learning approaches for accurate cancer detection. However, existing methods struggle to produce realistic images that have accurate nuclei boundaries and less artifacts, which limits the application in downstream tasks. To address the challenges, we propose a novel approach that enhances the quality of synthetic images by using nuclei topology and contour regularization. The proposed approach uses the skeleton map of nuclei to integrate nuclei topology and separate touching nuclei. In the loss function, we propose two new contour regularization terms that enhance the contrast between contour and non-contour pixels and increase the similarity between contour pixels. We evaluate the proposed approach on the two datasets using image quality metrics and a downstream task (nuclei segmentation). The proposed approach outperforms Sharp-GAN in all four image quality metrics on two datasets. By integrating 6k synthetic images from the proposed approach into training, a nuclei segmentation model achieves the state-of-the-art segmentation performance on TNBC dataset and its detection quality (DQ), segmentation quality (SQ), panoptic quality (PQ), and aggregated Jaccard index (AJI) is 0.855, 0.863, 0.691, and 0.683, respectively.","link":"http://arxiv.org/abs/2301.10187v1","created":"2023-01-24","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Enhanced Sharp-GAN For Histopathology Image Synthesis Histopathology image synthesis aims to address the data shortage issue in training deep learning approaches for accurate cancer detection. However, existing methods struggle to produce realistic images that have accurate nuclei boundaries and less artifacts, which limits the application in downstream tasks. To address the challenges, we propose a novel approach that enhances the quality of synthetic images by using nuclei topology and contour regularization. The proposed approach uses the skeleton map of nuclei to integrate nuclei topology and separate touching nuclei. In the loss function, we propose two new contour regularization terms that enhance the contrast between contour and non-contour pixels and increase the similarity between contour pixels. We evaluate the proposed approach on the two datasets using image quality metrics and a downstream task (nuclei segmentation). The proposed approach outperforms Sharp-GAN in all four image quality metrics on two datasets. By integrating 6k synthetic images from the proposed approach into training, a nuclei segmentation model achieves the state-of-the-art segmentation performance on TNBC dataset and its detection quality (DQ), segmentation quality (SQ), panoptic quality (PQ), and aggregated Jaccard index (AJI) is 0.855, 0.863, 0.691, and 0.683, respectively.","classes":{"dataset":0.5504825115}}
{"title":"Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism","description":"The loss function for bounding box regression (BBR) is essential to object detection. Its good definition will bring significant performance improvement to the model. Most existing works assume that the examples in the training data are high-quality and focus on strengthening the fitting ability of BBR loss. If we blindly strengthen BBR on low-quality examples, it will jeopardize localization performance. Focal-EIoU v1 was proposed to solve this problem, but due to its static focusing mechanism (FM), the potential of non-monotonic FM was not fully exploited. Based on this idea, we propose an IoU-based loss with a dynamic non-monotonic FM named Wise-IoU (WIoU). When WIoU is applied to the state-of-the-art real-time detector YOLOv7, the AP-75 on the MS-COCO dataset is improved from 53.03% to 54.50%.","link":"http://arxiv.org/abs/2301.10051v1","created":"2023-01-24","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism The loss function for bounding box regression (BBR) is essential to object detection. Its good definition will bring significant performance improvement to the model. Most existing works assume that the examples in the training data are high-quality and focus on strengthening the fitting ability of BBR loss. If we blindly strengthen BBR on low-quality examples, it will jeopardize localization performance. Focal-EIoU v1 was proposed to solve this problem, but due to its static focusing mechanism (FM), the potential of non-monotonic FM was not fully exploited. Based on this idea, we propose an IoU-based loss with a dynamic non-monotonic FM named Wise-IoU (WIoU). When WIoU is applied to the state-of-the-art real-time detector YOLOv7, the AP-75 on the MS-COCO dataset is improved from 53.03% to 54.50%.","classes":{"dataset":0.168855384}}
{"title":"Truveta Mapper: A Zero-shot Ontology Alignment Framework","description":"In this paper, a new perspective is suggested for unsupervised Ontology Matching (OM) or Ontology Alignment (OA) by treating it as a translation task. Ontologies are represented as graphs, and the translation is performed from a node in the source ontology graph to a path in the target ontology graph. The proposed framework, Truveta Mapper (TM), leverages a multi-task sequence-to-sequence transformer model to perform alignment across multiple ontologies in a zero-shot, unified and end-to-end manner. Multi-tasking enables the model to implicitly learn the relationship between different ontologies via transfer-learning without requiring any explicit cross-ontology manually labeled data. This also enables the formulated framework to outperform existing solutions for both runtime latency and alignment quality. The model is pre-trained and fine-tuned only on publicly available text corpus and inner-ontologies data. The proposed solution outperforms state-of-the-art approaches, Edit-Similarity, LogMap, AML, BERTMap, and the recently presented new OM frameworks in Ontology Alignment Evaluation Initiative (OAEI22), offers log-linear complexity in contrast to quadratic in the existing end-to-end methods, and overall makes the OM task efficient and more straightforward without much post-processing involving mapping extension or mapping repair.","link":"http://arxiv.org/abs/2301.09767v1","created":"2023-01-24","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Truveta Mapper: A Zero-shot Ontology Alignment Framework In this paper, a new perspective is suggested for unsupervised Ontology Matching (OM) or Ontology Alignment (OA) by treating it as a translation task. Ontologies are represented as graphs, and the translation is performed from a node in the source ontology graph to a path in the target ontology graph. The proposed framework, Truveta Mapper (TM), leverages a multi-task sequence-to-sequence transformer model to perform alignment across multiple ontologies in a zero-shot, unified and end-to-end manner. Multi-tasking enables the model to implicitly learn the relationship between different ontologies via transfer-learning without requiring any explicit cross-ontology manually labeled data. This also enables the formulated framework to outperform existing solutions for both runtime latency and alignment quality. The model is pre-trained and fine-tuned only on publicly available text corpus and inner-ontologies data. The proposed solution outperforms state-of-the-art approaches, Edit-Similarity, LogMap, AML, BERTMap, and the recently presented new OM frameworks in Ontology Alignment Evaluation Initiative (OAEI22), offers log-linear complexity in contrast to quadratic in the existing end-to-end methods, and overall makes the OM task efficient and more straightforward without much post-processing involving mapping extension or mapping repair.","classes":{"dataset":0.2328293324}}
{"title":"Illumination Variation Correction Using Image Synthesis For Unsupervised Domain Adaptive Person Re-Identification","description":"Unsupervised domain adaptive (UDA) person re-identification (re-ID) aims to learn identity information from labeled images in source domains and apply it to unlabeled images in a target domain. One major issue with many unsupervised re-identification methods is that they do not perform well relative to large domain variations such as illumination, viewpoint, and occlusions. In this paper, we propose a Synthesis Model Bank (SMB) to deal with illumination variation in unsupervised person re-ID. The proposed SMB consists of several convolutional neural networks (CNN) for feature extraction and Mahalanobis matrices for distance metrics. They are trained using synthetic data with different illumination conditions such that their synergistic effect makes the SMB robust against illumination variation. To better quantify the illumination intensity and improve the quality of synthetic images, we introduce a new 3D virtual-human dataset for GAN-based image synthesis. From our experiments, the proposed SMB outperforms other synthesis methods on several re-ID benchmarks.","link":"http://arxiv.org/abs/2301.09702v1","created":"2023-01-23","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Illumination Variation Correction Using Image Synthesis For Unsupervised Domain Adaptive Person Re-Identification Unsupervised domain adaptive (UDA) person re-identification (re-ID) aims to learn identity information from labeled images in source domains and apply it to unlabeled images in a target domain. One major issue with many unsupervised re-identification methods is that they do not perform well relative to large domain variations such as illumination, viewpoint, and occlusions. In this paper, we propose a Synthesis Model Bank (SMB) to deal with illumination variation in unsupervised person re-ID. The proposed SMB consists of several convolutional neural networks (CNN) for feature extraction and Mahalanobis matrices for distance metrics. They are trained using synthetic data with different illumination conditions such that their synergistic effect makes the SMB robust against illumination variation. To better quantify the illumination intensity and improve the quality of synthetic images, we introduce a new 3D virtual-human dataset for GAN-based image synthesis. From our experiments, the proposed SMB outperforms other synthesis methods on several re-ID benchmarks.","classes":{"dataset":0.3138262928}}
{"title":"ECGAN: Self-supervised generative adversarial network for electrocardiography","description":"High-quality synthetic data can support the development of effective predictive models for biomedical tasks, especially in rare diseases or when subject to compelling privacy constraints. These limitations, for instance, negatively impact open access to electrocardiography datasets about arrhythmias. This work introduces a self-supervised approach to the generation of synthetic electrocardiography time series which is shown to promote morphological plausibility. Our model (ECGAN) allows conditioning the generative process for specific rhythm abnormalities, enhancing synchronization and diversity across samples with respect to literature models. A dedicated sample quality assessment framework is also defined, leveraging arrhythmia classifiers. The empirical results highlight a substantial improvement against state-of-the-art generative models for sequences and audio synthesis.","link":"http://arxiv.org/abs/2301.09496v1","created":"2023-01-23","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"ECGAN: Self-supervised generative adversarial network for electrocardiography High-quality synthetic data can support the development of effective predictive models for biomedical tasks, especially in rare diseases or when subject to compelling privacy constraints. These limitations, for instance, negatively impact open access to electrocardiography datasets about arrhythmias. This work introduces a self-supervised approach to the generation of synthetic electrocardiography time series which is shown to promote morphological plausibility. Our model (ECGAN) allows conditioning the generative process for specific rhythm abnormalities, enhancing synchronization and diversity across samples with respect to literature models. A dedicated sample quality assessment framework is also defined, leveraging arrhythmia classifiers. The empirical results highlight a substantial improvement against state-of-the-art generative models for sequences and audio synthesis.","classes":{"dataset":0.3670710325}}
{"title":"Multi-domain stain normalization for digital pathology: A cycle-consistent adversarial network for whole slide images","description":"The variation in histologic staining between different medical centers is one of the most profound challenges in the field of computer-aided diagnosis. The appearance disparity of pathological whole slide images causes algorithms to become less reliable, which in turn impedes the wide-spread applicability of downstream tasks like cancer diagnosis. Furthermore, different stainings lead to biases in the training which in case of domain shifts negatively affect the test performance. Therefore, in this paper we propose MultiStain-CycleGAN, a multi-domain approach to stain normalization based on CycleGAN. Our modifications to CycleGAN allow us to normalize images of different origins without retraining or using different models. We perform an extensive evaluation of our method using various metrics and compare it to commonly used methods that are multi-domain capable. First, we evaluate how well our method fools a domain classifier that tries to assign a medical center to an image. Then, we test our normalization on the tumor classification performance of a downstream classifier. Furthermore, we evaluate the image quality of the normalized images using the Structural similarity index and the ability to reduce the domain shift using the Fr\\'echet inception distance. We show that our method proves to be multi-domain capable, provides the highest image quality among the compared methods, and can most reliably fool the domain classifier while keeping the tumor classifier performance high. By reducing the domain influence, biases in the data can be removed on the one hand and the origin of the whole slide image can be disguised on the other, thus enhancing patient data privacy.","link":"http://arxiv.org/abs/2301.09431v1","created":"2023-01-23","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Multi-domain stain normalization for digital pathology: A cycle-consistent adversarial network for whole slide images The variation in histologic staining between different medical centers is one of the most profound challenges in the field of computer-aided diagnosis. The appearance disparity of pathological whole slide images causes algorithms to become less reliable, which in turn impedes the wide-spread applicability of downstream tasks like cancer diagnosis. Furthermore, different stainings lead to biases in the training which in case of domain shifts negatively affect the test performance. Therefore, in this paper we propose MultiStain-CycleGAN, a multi-domain approach to stain normalization based on CycleGAN. Our modifications to CycleGAN allow us to normalize images of different origins without retraining or using different models. We perform an extensive evaluation of our method using various metrics and compare it to commonly used methods that are multi-domain capable. First, we evaluate how well our method fools a domain classifier that tries to assign a medical center to an image. Then, we test our normalization on the tumor classification performance of a downstream classifier. Furthermore, we evaluate the image quality of the normalized images using the Structural similarity index and the ability to reduce the domain shift using the Fr\\'echet inception distance. We show that our method proves to be multi-domain capable, provides the highest image quality among the compared methods, and can most reliably fool the domain classifier while keeping the tumor classifier performance high. By reducing the domain influence, biases in the data can be removed on the one hand and the origin of the whole slide image can be disguised on the other, thus enhancing patient data privacy.","classes":{"dataset":0.1822619736}}
{"title":"Velocity-Based LOD Reduction in Virtual Reality: A Psychometric Approach","description":"Virtual Reality headsets enable users to explore the environment by performing self-induced movements. The retinal velocity produced by such motion reduces the visual system's ability to resolve fine detail. We measured the impact of self-induced head rotations on the ability to detect quality changes of a realistic 3D model in an immersive virtual reality environment. We varied the Level-of-Detail (LOD) as a function of rotational head velocity with different degrees of severity. Using a psychophysical method, we asked 17 participants to identify which of the two presented intervals contained the higher quality model under two different maximum velocity conditions. After fitting psychometric functions to data relating the percentage of correct responses to the aggressiveness of LOD manipulations, we identified the threshold severity for which participants could reliably (75\\%) detect the lower LOD model. Participants accepted an approximately four-fold LOD reduction even in the low maximum velocity condition without a significant impact on perceived quality, which suggests that there is considerable potential for optimisation when users are moving (increased range of perceptual uncertainty). Moreover, LOD could be degraded significantly more in the maximum head velocity condition, suggesting these effects are indeed speed dependent.","link":"http://arxiv.org/abs/2301.09394v1","created":"2023-01-23","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Velocity-Based LOD Reduction in Virtual Reality: A Psychometric Approach Virtual Reality headsets enable users to explore the environment by performing self-induced movements. The retinal velocity produced by such motion reduces the visual system's ability to resolve fine detail. We measured the impact of self-induced head rotations on the ability to detect quality changes of a realistic 3D model in an immersive virtual reality environment. We varied the Level-of-Detail (LOD) as a function of rotational head velocity with different degrees of severity. Using a psychophysical method, we asked 17 participants to identify which of the two presented intervals contained the higher quality model under two different maximum velocity conditions. After fitting psychometric functions to data relating the percentage of correct responses to the aggressiveness of LOD manipulations, we identified the threshold severity for which participants could reliably (75\\%) detect the lower LOD model. Participants accepted an approximately four-fold LOD reduction even in the low maximum velocity condition without a significant impact on perceived quality, which suggests that there is considerable potential for optimisation when users are moving (increased range of perceptual uncertainty). Moreover, LOD could be degraded significantly more in the maximum head velocity condition, suggesting these effects are indeed speed dependent.","classes":{"dataset":0.185961023}}
{"title":"Proactive and Reactive Engagement of Artificial Intelligence Methods for Education: A Review","description":"Quality education, one of the seventeen sustainable development goals (SDGs) identified by the United Nations General Assembly, stands to benefit enormously from the adoption of artificial intelligence (AI) driven tools and technologies. The concurrent boom of necessary infrastructure, digitized data and general social awareness has propelled massive research and development efforts in the artificial intelligence for education (AIEd) sector. In this review article, we investigate how artificial intelligence, machine learning and deep learning methods are being utilized to support students, educators and administrative staff. We do this through the lens of a novel categorization approach. We consider the involvement of AI-driven methods in the education process in its entirety - from students admissions, course scheduling etc. in the proactive planning phase to knowledge delivery, performance assessment etc. in the reactive execution phase. We outline and analyze the major research directions under proactive and reactive engagement of AI in education using a representative group of 194 original research articles published in the past two decades i.e., 2003 - 2022. We discuss the paradigm shifts in the solution approaches proposed, i.e., in the choice of data and algorithms used over this time. We further dive into how the COVID-19 pandemic challenged and reshaped the education landscape at the fag end of this time period. Finally, we pinpoint existing limitations in adopting artificial intelligence for education and reflect on the path forward.","link":"http://arxiv.org/abs/2301.10231v1","created":"2023-01-23","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Proactive and Reactive Engagement of Artificial Intelligence Methods for Education: A Review Quality education, one of the seventeen sustainable development goals (SDGs) identified by the United Nations General Assembly, stands to benefit enormously from the adoption of artificial intelligence (AI) driven tools and technologies. The concurrent boom of necessary infrastructure, digitized data and general social awareness has propelled massive research and development efforts in the artificial intelligence for education (AIEd) sector. In this review article, we investigate how artificial intelligence, machine learning and deep learning methods are being utilized to support students, educators and administrative staff. We do this through the lens of a novel categorization approach. We consider the involvement of AI-driven methods in the education process in its entirety - from students admissions, course scheduling etc. in the proactive planning phase to knowledge delivery, performance assessment etc. in the reactive execution phase. We outline and analyze the major research directions under proactive and reactive engagement of AI in education using a representative group of 194 original research articles published in the past two decades i.e., 2003 - 2022. We discuss the paradigm shifts in the solution approaches proposed, i.e., in the choice of data and algorithms used over this time. We further dive into how the COVID-19 pandemic challenged and reshaped the education landscape at the fag end of this time period. Finally, we pinpoint existing limitations in adopting artificial intelligence for education and reflect on the path forward.","classes":{"dataset":0.0478881672}}
{"title":"The Pipeline for the Continuous Development of Artificial Intelligence Models -- Current State of Research and Practice","description":"Companies struggle to continuously develop and deploy AI models to complex production systems due to AI characteristics while assuring quality. To ease the development process, continuous pipelines for AI have become an active research area where consolidated and in-depth analysis regarding the terminology, triggers, tasks, and challenges is required. This paper includes a Multivocal Literature Review where we consolidated 151 relevant formal and informal sources. In addition, nine-semi structured interviews with participants from academia and industry verified and extended the obtained information. Based on these sources, this paper provides and compares terminologies for DevOps and CI/CD for AI, MLOps, (end-to-end) lifecycle management, and CD4ML. Furthermore, the paper provides an aggregated list of potential triggers for reiterating the pipeline, such as alert systems or schedules. In addition, this work uses a taxonomy creation strategy to present a consolidated pipeline comprising tasks regarding the continuous development of AI. This pipeline consists of four stages: Data Handling, Model Learning, Software Development and System Operations. Moreover, we map challenges regarding pipeline implementation, adaption, and usage for the continuous development of AI to these four stages.","link":"http://arxiv.org/abs/2301.09001v1","created":"2023-01-21","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"The Pipeline for the Continuous Development of Artificial Intelligence Models -- Current State of Research and Practice Companies struggle to continuously develop and deploy AI models to complex production systems due to AI characteristics while assuring quality. To ease the development process, continuous pipelines for AI have become an active research area where consolidated and in-depth analysis regarding the terminology, triggers, tasks, and challenges is required. This paper includes a Multivocal Literature Review where we consolidated 151 relevant formal and informal sources. In addition, nine-semi structured interviews with participants from academia and industry verified and extended the obtained information. Based on these sources, this paper provides and compares terminologies for DevOps and CI/CD for AI, MLOps, (end-to-end) lifecycle management, and CD4ML. Furthermore, the paper provides an aggregated list of potential triggers for reiterating the pipeline, such as alert systems or schedules. In addition, this work uses a taxonomy creation strategy to present a consolidated pipeline comprising tasks regarding the continuous development of AI. This pipeline consists of four stages: Data Handling, Model Learning, Software Development and System Operations. Moreover, we map challenges regarding pipeline implementation, adaption, and usage for the continuous development of AI to these four stages.","classes":{"dataset":0.1392096877}}
{"title":"Soft Sensing Regression Model: from Sensor to Wafer Metrology Forecasting","description":"The semiconductor industry is one of the most technology-evolving and capital-intensive market sectors. Effective inspection and metrology are necessary to improve product yield, increase product quality and reduce costs. In recent years, many semiconductor manufacturing equipments are equipped with sensors to facilitate real-time monitoring of the production process. These production-state and equipment-state sensor data provide an opportunity to practice machine-learning technologies in various domains, such as anomaly/fault detection, maintenance scheduling, quality prediction, etc. In this work, we focus on the task of soft sensing regression, which uses sensor data to predict impending inspection measurements that used to be measured in wafer inspection and metrology systems. We proposed an LSTM-based regressor and designed two loss functions for model training. Although engineers may look at our prediction errors in a subjective manner, a new piece-wise evaluation metric was proposed for assessing model accuracy in a mathematical way. The experimental results demonstrated that the proposed model can achieve accurate and early prediction of various types of inspections in complicated manufacturing processes.","link":"http://arxiv.org/abs/2301.08974v1","created":"2023-01-21","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Soft Sensing Regression Model: from Sensor to Wafer Metrology Forecasting The semiconductor industry is one of the most technology-evolving and capital-intensive market sectors. Effective inspection and metrology are necessary to improve product yield, increase product quality and reduce costs. In recent years, many semiconductor manufacturing equipments are equipped with sensors to facilitate real-time monitoring of the production process. These production-state and equipment-state sensor data provide an opportunity to practice machine-learning technologies in various domains, such as anomaly/fault detection, maintenance scheduling, quality prediction, etc. In this work, we focus on the task of soft sensing regression, which uses sensor data to predict impending inspection measurements that used to be measured in wafer inspection and metrology systems. We proposed an LSTM-based regressor and designed two loss functions for model training. Although engineers may look at our prediction errors in a subjective manner, a new piece-wise evaluation metric was proposed for assessing model accuracy in a mathematical way. The experimental results demonstrated that the proposed model can achieve accurate and early prediction of various types of inspections in complicated manufacturing processes.","classes":{"dataset":0.3151297867}}
{"title":"A fast and flexible machine learning approach to data quality monitoring","description":"We present a machine learning based approach for real-time monitoring of particle detectors. The proposed strategy evaluates the compatibility between incoming batches of experimental data and a reference sample representing the data behavior in normal conditions by implementing a likelihood-ratio hypothesis test. The core model is powered by recent large-scale implementations of kernel methods, nonparametric learning algorithms that can approximate any continuous function given enough data. The resulting algorithm is fast, efficient and agnostic about the type of potential anomaly in the data. We show the performance of the model on multivariate data from a drift tube chambers muon detector.","link":"http://arxiv.org/abs/2301.08917v1","created":"2023-01-21","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"A fast and flexible machine learning approach to data quality monitoring We present a machine learning based approach for real-time monitoring of particle detectors. The proposed strategy evaluates the compatibility between incoming batches of experimental data and a reference sample representing the data behavior in normal conditions by implementing a likelihood-ratio hypothesis test. The core model is powered by recent large-scale implementations of kernel methods, nonparametric learning algorithms that can approximate any continuous function given enough data. The resulting algorithm is fast, efficient and agnostic about the type of potential anomaly in the data. We show the performance of the model on multivariate data from a drift tube chambers muon detector.","classes":{"dataset":0.4756151438}}
{"title":"In-situ Water quality monitoring in Oil and Gas operations","description":"From agriculture to mining, to energy, surface water quality monitoring is an essential task. As oil and gas operators work to reduce the consumption of freshwater, it is increasingly important to actively manage fresh and non-fresh water resources over the long term. For large-scale monitoring, manual sampling at many sites has become too time-consuming and unsustainable, given the sheer number of dispersed ponds, small lakes, playas, and wetlands over a large area. Therefore, satellite-based environmental monitoring presents great potential. Many existing satellite-based monitoring studies utilize index-based methods to monitor large water bodies such as rivers and oceans. However, these existing methods fail when monitoring small ponds-the reflectance signal received from small water bodies is too weak to detect. To address this challenge, we propose a new Water Quality Enhanced Index (WQEI) Model, which is designed to enable users to determine contamination levels in water bodies with weak reflectance patterns. Our results show that 1) WQEI is a good indicator of water turbidity validated with 1200 water samples measured in the laboratory, and 2) by applying our method to commonly available satellite data (e.g. LandSat8), one can achieve high accuracy water quality monitoring efficiently in large regions. This provides a tool for operators to optimize the quality of water stored within surface storage ponds and increasing the readiness and availability of non-fresh water.","link":"http://arxiv.org/abs/2301.08800v1","created":"2023-01-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"In-situ Water quality monitoring in Oil and Gas operations From agriculture to mining, to energy, surface water quality monitoring is an essential task. As oil and gas operators work to reduce the consumption of freshwater, it is increasingly important to actively manage fresh and non-fresh water resources over the long term. For large-scale monitoring, manual sampling at many sites has become too time-consuming and unsustainable, given the sheer number of dispersed ponds, small lakes, playas, and wetlands over a large area. Therefore, satellite-based environmental monitoring presents great potential. Many existing satellite-based monitoring studies utilize index-based methods to monitor large water bodies such as rivers and oceans. However, these existing methods fail when monitoring small ponds-the reflectance signal received from small water bodies is too weak to detect. To address this challenge, we propose a new Water Quality Enhanced Index (WQEI) Model, which is designed to enable users to determine contamination levels in water bodies with weak reflectance patterns. Our results show that 1) WQEI is a good indicator of water turbidity validated with 1200 water samples measured in the laboratory, and 2) by applying our method to commonly available satellite data (e.g. LandSat8), one can achieve high accuracy water quality monitoring efficiently in large regions. This provides a tool for operators to optimize the quality of water stored within surface storage ponds and increasing the readiness and availability of non-fresh water.","classes":{"dataset":0.1895453781}}
{"title":"An Asynchronous Intensity Representation for Framed and Event Video Sources","description":"Neuromorphic \"event\" cameras, designed to mimic the human vision system with asynchronous sensing, unlock a new realm of high-speed and high dynamic range applications. However, researchers often either revert to a framed representation of event data for applications, or build bespoke applications for a particular camera's event data type. To usher in the next era of video systems, accommodate new event camera designs, and explore the benefits to asynchronous video in classical applications, we argue that there is a need for an asynchronous, source-agnostic video representation. In this paper, we introduce a novel, asynchronous intensity representation for both framed and non-framed data sources. We show that our representation can increase intensity precision and greatly reduce the number of samples per pixel compared to grid-based representations. With framed sources, we demonstrate that by permitting a small amount of loss through the temporal averaging of similar pixel values, we can reduce our representational sample rate by more than half, while incurring a drop in VMAF quality score of only 4.5. We also demonstrate lower latency than the state-of-the-art method for fusing and transcoding framed and event camera data to an intensity representation, while maintaining $2000\\times$ the temporal resolution. We argue that our method provides the computational efficiency and temporal granularity necessary to build real-time intensity-based applications for event cameras.","link":"http://arxiv.org/abs/2301.08783v1","created":"2023-01-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"An Asynchronous Intensity Representation for Framed and Event Video Sources Neuromorphic \"event\" cameras, designed to mimic the human vision system with asynchronous sensing, unlock a new realm of high-speed and high dynamic range applications. However, researchers often either revert to a framed representation of event data for applications, or build bespoke applications for a particular camera's event data type. To usher in the next era of video systems, accommodate new event camera designs, and explore the benefits to asynchronous video in classical applications, we argue that there is a need for an asynchronous, source-agnostic video representation. In this paper, we introduce a novel, asynchronous intensity representation for both framed and non-framed data sources. We show that our representation can increase intensity precision and greatly reduce the number of samples per pixel compared to grid-based representations. With framed sources, we demonstrate that by permitting a small amount of loss through the temporal averaging of similar pixel values, we can reduce our representational sample rate by more than half, while incurring a drop in VMAF quality score of only 4.5. We also demonstrate lower latency than the state-of-the-art method for fusing and transcoding framed and event camera data to an intensity representation, while maintaining $2000\\times$ the temporal resolution. We argue that our method provides the computational efficiency and temporal granularity necessary to build real-time intensity-based applications for event cameras.","classes":{"dataset":0.2175284475}}
{"title":"Data Augmentation for Modeling Human Personality: The Dexter Machine","description":"Modeling human personality is important for several AI challenges, from the engineering of artificial psychotherapists to the design of persona bots. However, the field of computational personality analysis heavily relies on labeled data, which may be expensive, difficult or impossible to get. This problem is amplified when dealing with rare personality types or disorders (e.g., the anti-social psychopathic personality disorder). In this context, we developed a text-based data augmentation approach for human personality (PEDANT). PEDANT doesn't rely on the common type of labeled data but on the generative pre-trained model (GPT) combined with domain expertise. Testing the methodology on three different datasets, provides results that support the quality of the generated data.","link":"http://arxiv.org/abs/2301.08606v1","created":"2023-01-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Data Augmentation for Modeling Human Personality: The Dexter Machine Modeling human personality is important for several AI challenges, from the engineering of artificial psychotherapists to the design of persona bots. However, the field of computational personality analysis heavily relies on labeled data, which may be expensive, difficult or impossible to get. This problem is amplified when dealing with rare personality types or disorders (e.g., the anti-social psychopathic personality disorder). In this context, we developed a text-based data augmentation approach for human personality (PEDANT). PEDANT doesn't rely on the common type of labeled data but on the generative pre-trained model (GPT) combined with domain expertise. Testing the methodology on three different datasets, provides results that support the quality of the generated data.","classes":{"dataset":0.4097661376}}
{"title":"Language Agnostic Data-Driven Inverse Text Normalization","description":"With the emergence of automatic speech recognition (ASR) models, converting the spoken form text (from ASR) to the written form is in urgent need. This inverse text normalization (ITN) problem attracts the attention of researchers from various fields. Recently, several works show that data-driven ITN methods can output high-quality written form text. Due to the scarcity of labeled spoken-written datasets, the studies on non-English data-driven ITN are quite limited. In this work, we propose a language-agnostic data-driven ITN framework to fill this gap. Specifically, we leverage the data augmentation in conjunction with neural machine translated data for low resource languages. Moreover, we design an evaluation method for language agnostic ITN model when only English data is available. Our empirical evaluation shows this language agnostic modeling approach is effective for low resource languages while preserving the performance for high resource languages.","link":"http://arxiv.org/abs/2301.08506v2","created":"2023-01-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Language Agnostic Data-Driven Inverse Text Normalization With the emergence of automatic speech recognition (ASR) models, converting the spoken form text (from ASR) to the written form is in urgent need. This inverse text normalization (ITN) problem attracts the attention of researchers from various fields. Recently, several works show that data-driven ITN methods can output high-quality written form text. Due to the scarcity of labeled spoken-written datasets, the studies on non-English data-driven ITN are quite limited. In this work, we propose a language-agnostic data-driven ITN framework to fill this gap. Specifically, we leverage the data augmentation in conjunction with neural machine translated data for low resource languages. Moreover, we design an evaluation method for language agnostic ITN model when only English data is available. Our empirical evaluation shows this language agnostic modeling approach is effective for low resource languages while preserving the performance for high resource languages.","classes":{"dataset":0.1937856823}}
{"title":"On Retrospective k-space Subsampling schemes For Deep MRI Reconstruction","description":"$\\textbf{Purpose:}$ The MRI $k$-space acquisition is time consuming. Traditional techniques aim to acquire accelerated data, which in conjunction with recent DL methods, aid in producing high-fidelity images in truncated times. Conventionally, subsampling the $k$-space is performed by utilizing Cartesian-rectilinear trajectories, which even with the use of DL, provide imprecise reconstructions, though, a plethora of non-rectilinear or non-Cartesian trajectories can be implemented in modern MRI scanners. This work investigates the effect of the $k$-space subsampling scheme on the quality of reconstructed accelerated MRI measurements produced by trained DL models.   $\\textbf{Methods:}$ The RecurrentVarNet was used as the DL-based MRI-reconstruction architecture. Cartesian fully-sampled multi-coil $k$-space measurements from three datasets with different accelerations were retrospectively subsampled using eight distinct subsampling schemes (four Cartesian-rectilinear, two Cartesian non-rectilinear, two non-Cartesian). Experiments were conducted in two frameworks: Scheme-specific, where a distinct model was trained and evaluated for each dataset-subsampling scheme pair, and multi-scheme, where for each dataset a single model was trained on data randomly subsampled by any of the eight schemes and evaluated on data subsampled by all schemes.   $\\textbf{Results:}$ In the scheme-specific setting RecurrentVarNets trained and evaluated on non-rectilinearly subsampled data demonstrated superior performance especially for high accelerations, whilst in the multi-scheme setting, reconstruction performance on rectilinearly subsampled data improved when compared to the scheme-specific experiments.   $\\textbf{Conclusion:}$ Training DL-based MRI reconstruction algorithms on non-rectilinearly subsampled measurements can produce more faithful reconstructions.","link":"http://arxiv.org/abs/2301.08365v2","created":"2023-01-20","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"On Retrospective k-space Subsampling schemes For Deep MRI Reconstruction $\\textbf{Purpose:}$ The MRI $k$-space acquisition is time consuming. Traditional techniques aim to acquire accelerated data, which in conjunction with recent DL methods, aid in producing high-fidelity images in truncated times. Conventionally, subsampling the $k$-space is performed by utilizing Cartesian-rectilinear trajectories, which even with the use of DL, provide imprecise reconstructions, though, a plethora of non-rectilinear or non-Cartesian trajectories can be implemented in modern MRI scanners. This work investigates the effect of the $k$-space subsampling scheme on the quality of reconstructed accelerated MRI measurements produced by trained DL models.   $\\textbf{Methods:}$ The RecurrentVarNet was used as the DL-based MRI-reconstruction architecture. Cartesian fully-sampled multi-coil $k$-space measurements from three datasets with different accelerations were retrospectively subsampled using eight distinct subsampling schemes (four Cartesian-rectilinear, two Cartesian non-rectilinear, two non-Cartesian). Experiments were conducted in two frameworks: Scheme-specific, where a distinct model was trained and evaluated for each dataset-subsampling scheme pair, and multi-scheme, where for each dataset a single model was trained on data randomly subsampled by any of the eight schemes and evaluated on data subsampled by all schemes.   $\\textbf{Results:}$ In the scheme-specific setting RecurrentVarNets trained and evaluated on non-rectilinearly subsampled data demonstrated superior performance especially for high accelerations, whilst in the multi-scheme setting, reconstruction performance on rectilinearly subsampled data improved when compared to the scheme-specific experiments.   $\\textbf{Conclusion:}$ Training DL-based MRI reconstruction algorithms on non-rectilinearly subsampled measurements can produce more faithful reconstructions.","classes":{"dataset":0.1122689471}}
{"title":"Learning ultrasound plane pose regression: assessing generalized pose coordinates in the fetal brain","description":"In obstetric ultrasound (US) scanning, the learner's ability to mentally build a three-dimensional (3D) map of the fetus from a two-dimensional (2D) US image represents a significant challenge in skill acquisition. We aim to build a US plane localization system for 3D visualization, training, and guidance without integrating additional sensors. This work builds on top of our previous work, which predicts the six-dimensional (6D) pose of arbitrarily-oriented US planes slicing the fetal brain with respect to a normalized reference frame using a convolutional neural network (CNN) regression network. Here, we analyze in detail the assumptions of the normalized fetal brain reference frame and quantify its accuracy with respect to the acquisition of transventricular (TV) standard plane (SP) for fetal biometry. We investigate the impact of registration quality in the training and testing data and its subsequent effect on trained models. Finally, we introduce data augmentations and larger training sets that improve the results of our previous work, achieving median errors of 3.53 mm and 6.42 degrees for translation and rotation, respectively.","link":"http://arxiv.org/abs/2301.08317v1","created":"2023-01-19","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Learning ultrasound plane pose regression: assessing generalized pose coordinates in the fetal brain In obstetric ultrasound (US) scanning, the learner's ability to mentally build a three-dimensional (3D) map of the fetus from a two-dimensional (2D) US image represents a significant challenge in skill acquisition. We aim to build a US plane localization system for 3D visualization, training, and guidance without integrating additional sensors. This work builds on top of our previous work, which predicts the six-dimensional (6D) pose of arbitrarily-oriented US planes slicing the fetal brain with respect to a normalized reference frame using a convolutional neural network (CNN) regression network. Here, we analyze in detail the assumptions of the normalized fetal brain reference frame and quantify its accuracy with respect to the acquisition of transventricular (TV) standard plane (SP) for fetal biometry. We investigate the impact of registration quality in the training and testing data and its subsequent effect on trained models. Finally, we introduce data augmentations and larger training sets that improve the results of our previous work, achieving median errors of 3.53 mm and 6.42 degrees for translation and rotation, respectively.","classes":{"dataset":0.1647608876}}
{"title":"Diffusion-based Conditional ECG Generation with Structured State Space Models","description":"Synthetic data generation is a promising solution to address privacy issues with the distribution of sensitive health data. Recently, diffusion models have set new standards for generative models for different data modalities. Also very recently, structured state space models emerged as a powerful modeling paradigm to capture long-term dependencies in time series. We put forward SSSD-ECG, as the combination of these two technologies, for the generation of synthetic 12-lead electrocardiograms conditioned on more than 70 ECG statements. Due to a lack of reliable baselines, we also propose conditional variants of two state-of-the-art unconditional generative models. We thoroughly evaluate the quality of the generated samples, by evaluating pretrained classifiers on the generated data and by evaluating the performance of a classifier trained only on synthetic data, where SSSD-ECG clearly outperforms its GAN-based competitors. We demonstrate the soundness of our approach through further experiments, including conditional class interpolation and a clinical Turing test demonstrating the high quality of the SSSD-ECG samples across a wide range of conditions.","link":"http://arxiv.org/abs/2301.08227v1","created":"2023-01-19","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Diffusion-based Conditional ECG Generation with Structured State Space Models Synthetic data generation is a promising solution to address privacy issues with the distribution of sensitive health data. Recently, diffusion models have set new standards for generative models for different data modalities. Also very recently, structured state space models emerged as a powerful modeling paradigm to capture long-term dependencies in time series. We put forward SSSD-ECG, as the combination of these two technologies, for the generation of synthetic 12-lead electrocardiograms conditioned on more than 70 ECG statements. Due to a lack of reliable baselines, we also propose conditional variants of two state-of-the-art unconditional generative models. We thoroughly evaluate the quality of the generated samples, by evaluating pretrained classifiers on the generated data and by evaluating the performance of a classifier trained only on synthetic data, where SSSD-ECG clearly outperforms its GAN-based competitors. We demonstrate the soundness of our approach through further experiments, including conditional class interpolation and a clinical Turing test demonstrating the high quality of the SSSD-ECG samples across a wide range of conditions.","classes":{"dataset":0.3290871084}}
{"title":"A Meta-Learning Approach for Software Refactoring","description":"Software refactoring is the process of changing the structure of software without any alteration in its behavior and functionality. Presuming it is carried out in appropriate opportunities, refactoring enhances software quality characteristics such as maintainability and extensibility. Thus far, various studies have addressed the problem of detecting proper opportunities for refactoring. Most of them are based on human expertise and are prone to error and non-meticulous. Fortunately, in recent efforts, machine learning methods have produced outstanding results in finding appropriate opportunities for refactoring. Sad to say, Machine learning methods mostly need plenty of data and, consequently, long processing time. Furthermore, there needs to be more annotated data for many types of refactoring, and data collection is time-consuming and costly. Accordingly, in this paper, we have formulated the problem of detecting appropriate opportunities for refactoring as a few-shot classification problem. We have utilized model-agnostic meta-learning (MAML), a recognized meta-learning algorithm, to learn a neural network on tasks from high-resource data. The trained model, then, is adapted to a model with high accuracy for tasks from low-resource data. Experimental results revealed 91% accuracy, which illustrates the effectiveness and competitiveness of our proposed meta-learning model.","link":"http://arxiv.org/abs/2301.08061v1","created":"2023-01-19","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"A Meta-Learning Approach for Software Refactoring Software refactoring is the process of changing the structure of software without any alteration in its behavior and functionality. Presuming it is carried out in appropriate opportunities, refactoring enhances software quality characteristics such as maintainability and extensibility. Thus far, various studies have addressed the problem of detecting proper opportunities for refactoring. Most of them are based on human expertise and are prone to error and non-meticulous. Fortunately, in recent efforts, machine learning methods have produced outstanding results in finding appropriate opportunities for refactoring. Sad to say, Machine learning methods mostly need plenty of data and, consequently, long processing time. Furthermore, there needs to be more annotated data for many types of refactoring, and data collection is time-consuming and costly. Accordingly, in this paper, we have formulated the problem of detecting appropriate opportunities for refactoring as a few-shot classification problem. We have utilized model-agnostic meta-learning (MAML), a recognized meta-learning algorithm, to learn a neural network on tasks from high-resource data. The trained model, then, is adapted to a model with high accuracy for tasks from low-resource data. Experimental results revealed 91% accuracy, which illustrates the effectiveness and competitiveness of our proposed meta-learning model.","classes":{"dataset":0.1834896207}}
{"title":"Characterising fast-time variations in the hard X-ray time profiles of solar flares using Solar Orbiter's STIX","description":"Aims: The aim of this work is to develop a method to systematically detect and characterise fast-time variations ($\\gtrsim 1$s) in the non-thermal hard X-ray (HXR) time profiles of solar flares using high-resolution data from Solar Orbiter's Spectrometer/Telescope for Imaging X-rays (STIX).   Methods: The HXR time profiles were smoothed using Gaussian Process (GP) regression. The time profiles were then fitted with a linear combination of Gaussians to decompose the time profile. From the Gaussian decomposition, key characteristics such as the periodicity, full width at half maximum (FWHM), time evolution, and amplitude can be derived.   Results: We present the outcome of applying this method to four M and X GOES-class flares from the first year of Solar Orbiter science operations. The HXR time profiles of these flares were decomposed into individual Gaussians and their periods were derived. The quality of fit is quantified by the standard deviation of the residuals (difference between observed and fitted curve, normalised by the error on the observed data), for which we obtain $\\leq 1.8$ for all flares presented. In this work, the first detection of fast-time variations with Solar Orbiter's STIX instrument has been made on timescales across the range of 4-128s.   Conclusions: A new method for identifying and characterising fast-time variations in the non-thermal HXR profiles of solar flares has been developed, in which the time profiles are fit with a linear combination of Gaussian bursts. The opportunity to study time variations in flares has greatly improved with the new observations from STIX on Solar Orbiter.","link":"http://arxiv.org/abs/2301.08040v1","created":"2023-01-19","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Characterising fast-time variations in the hard X-ray time profiles of solar flares using Solar Orbiter's STIX Aims: The aim of this work is to develop a method to systematically detect and characterise fast-time variations ($\\gtrsim 1$s) in the non-thermal hard X-ray (HXR) time profiles of solar flares using high-resolution data from Solar Orbiter's Spectrometer/Telescope for Imaging X-rays (STIX).   Methods: The HXR time profiles were smoothed using Gaussian Process (GP) regression. The time profiles were then fitted with a linear combination of Gaussians to decompose the time profile. From the Gaussian decomposition, key characteristics such as the periodicity, full width at half maximum (FWHM), time evolution, and amplitude can be derived.   Results: We present the outcome of applying this method to four M and X GOES-class flares from the first year of Solar Orbiter science operations. The HXR time profiles of these flares were decomposed into individual Gaussians and their periods were derived. The quality of fit is quantified by the standard deviation of the residuals (difference between observed and fitted curve, normalised by the error on the observed data), for which we obtain $\\leq 1.8$ for all flares presented. In this work, the first detection of fast-time variations with Solar Orbiter's STIX instrument has been made on timescales across the range of 4-128s.   Conclusions: A new method for identifying and characterising fast-time variations in the non-thermal HXR profiles of solar flares has been developed, in which the time profiles are fit with a linear combination of Gaussian bursts. The opportunity to study time variations in flares has greatly improved with the new observations from STIX on Solar Orbiter.","classes":{"dataset":0.0383725688}}
{"title":"The Effects of Spatial Interpolation on a Novel, Dual-Doppler 3D Wind Retrieval Technique","description":"Three-dimensional wind retrievals from ground-based Doppler radars have played an important role in meteorological research and nowcasting over the past four decades. However, in recent years, the proliferation of open-source software and increased demands from applications such as convective parameterizations in numerical weather prediction models has led to a renewed interest in these analyses. In this study, we analyze how a major, yet often-overlooked, error source effects the quality of retrieved 3D wind fields. Namely, we investigate the effects of spatial interpolation, and show how the common practice of pre-gridding radial velocity data can degrade the accuracy of the results. Alternatively, we show that assimilating radar data directly at their observation locations improves the retrieval of important dynamic features such as the rear flank downdraft and mesocyclone within a simulated supercell, while also reducing errors in vertical vorticity, horizontal divergence, and all three velocity components. Based on these results, we recommend that analysts assimilate radial velocities directly, and avoid pre-gridding prior to analysis.","link":"http://arxiv.org/abs/2301.07913v1","created":"2023-01-19","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"The Effects of Spatial Interpolation on a Novel, Dual-Doppler 3D Wind Retrieval Technique Three-dimensional wind retrievals from ground-based Doppler radars have played an important role in meteorological research and nowcasting over the past four decades. However, in recent years, the proliferation of open-source software and increased demands from applications such as convective parameterizations in numerical weather prediction models has led to a renewed interest in these analyses. In this study, we analyze how a major, yet often-overlooked, error source effects the quality of retrieved 3D wind fields. Namely, we investigate the effects of spatial interpolation, and show how the common practice of pre-gridding radial velocity data can degrade the accuracy of the results. Alternatively, we show that assimilating radar data directly at their observation locations improves the retrieval of important dynamic features such as the rear flank downdraft and mesocyclone within a simulated supercell, while also reducing errors in vertical vorticity, horizontal divergence, and all three velocity components. Based on these results, we recommend that analysts assimilate radial velocities directly, and avoid pre-gridding prior to analysis.","classes":{"dataset":0.0612562411}}
{"title":"Reconstructing Rayleigh-Benard flows out of temperature-only measurements using Physics-Informed Neural Networks","description":"We investigate the capabilities of Physics-Informed Neural Networks (PINNs) to reconstruct turbulent Rayleigh-Benard flows using only temperature information. We perform a quantitative analysis of the quality of the reconstructions at various amounts of low-passed-filtered information and turbulent intensities. We compare our results with those obtained via nudging, a classical equation-informed data assimilation technique. At low Rayleigh numbers, PINNs are able to reconstruct with high precision, comparable to the one achieved with nudging. At high Rayleigh numbers, PINNs outperform nudging and are able to achieve satisfactory reconstruction of the velocity fields only when data for temperature is provided with high spatial and temporal density. When data becomes sparse, the PINNs performance worsens, not only in a point-to-point error sense but also, and contrary to nudging, in a statistical sense, as can be seen in the probability density functions and energy spectra.","link":"http://arxiv.org/abs/2301.07769v1","created":"2023-01-18","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Reconstructing Rayleigh-Benard flows out of temperature-only measurements using Physics-Informed Neural Networks We investigate the capabilities of Physics-Informed Neural Networks (PINNs) to reconstruct turbulent Rayleigh-Benard flows using only temperature information. We perform a quantitative analysis of the quality of the reconstructions at various amounts of low-passed-filtered information and turbulent intensities. We compare our results with those obtained via nudging, a classical equation-informed data assimilation technique. At low Rayleigh numbers, PINNs are able to reconstruct with high precision, comparable to the one achieved with nudging. At high Rayleigh numbers, PINNs outperform nudging and are able to achieve satisfactory reconstruction of the velocity fields only when data for temperature is provided with high spatial and temporal density. When data becomes sparse, the PINNs performance worsens, not only in a point-to-point error sense but also, and contrary to nudging, in a statistical sense, as can be seen in the probability density functions and energy spectra.","classes":{"dataset":0.3658176363}}
{"title":"HMDO: Markerless Multi-view Hand Manipulation Capture with Deformable Objects","description":"We construct the first markerless deformable interaction dataset recording interactive motions of the hands and deformable objects, called HMDO (Hand Manipulation with Deformable Objects). With our built multi-view capture system, it captures the deformable interactions with multiple perspectives, various object shapes, and diverse interactive forms. Our motivation is the current lack of hand and deformable object interaction datasets, as 3D hand and deformable object reconstruction is challenging. Mainly due to mutual occlusion, the interaction area is difficult to observe, the visual features between the hand and the object are entangled, and the reconstruction of the interaction area deformation is difficult. To tackle this challenge, we propose a method to annotate our captured data. Our key idea is to collaborate with estimated hand features to guide the object global pose estimation, and then optimize the deformation process of the object by analyzing the relationship between the hand and the object. Through comprehensive evaluation, the proposed method can reconstruct interactive motions of hands and deformable objects with high quality. HMDO currently consists of 21600 frames over 12 sequences. In the future, this dataset could boost the research of learning-based reconstruction of deformable interaction scenes.","link":"http://arxiv.org/abs/2301.07652v1","created":"2023-01-18","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"HMDO: Markerless Multi-view Hand Manipulation Capture with Deformable Objects We construct the first markerless deformable interaction dataset recording interactive motions of the hands and deformable objects, called HMDO (Hand Manipulation with Deformable Objects). With our built multi-view capture system, it captures the deformable interactions with multiple perspectives, various object shapes, and diverse interactive forms. Our motivation is the current lack of hand and deformable object interaction datasets, as 3D hand and deformable object reconstruction is challenging. Mainly due to mutual occlusion, the interaction area is difficult to observe, the visual features between the hand and the object are entangled, and the reconstruction of the interaction area deformation is difficult. To tackle this challenge, we propose a method to annotate our captured data. Our key idea is to collaborate with estimated hand features to guide the object global pose estimation, and then optimize the deformation process of the object by analyzing the relationship between the hand and the object. Through comprehensive evaluation, the proposed method can reconstruct interactive motions of hands and deformable objects with high quality. HMDO currently consists of 21600 frames over 12 sequences. In the future, this dataset could boost the research of learning-based reconstruction of deformable interaction scenes.","classes":{"dataset":0.5834814906}}
{"title":"The orbits of visual binary and multiple stars obtained by the Apparent Motion Parameters method during the last 40 years","description":"Summed many years of work at Pulkovo, the orbits of 67 wide pairs of visual double and multiple stars (included in 64 systems) which were obtained by the Apparent Motion Parameters (AMP) method are presented. This short arc determination orbit method is based on the most reliable astrometric and astrophysical data corresponding to one instant of time. The rest of the observations accumulated in the world serve to control the quality of the orbit and refine some parameters. All early determined AMP-orbits were compared with new observations, some of them were recalculated, new ones were added. For the stars of Pulkovo program of observations with a 26-inch refractor, the Gaia DR2 data were analised. Based on these data, the orbits of 16 stars were calculated. In 20 cases from 67, the quasi-instant motion according to the Gaia DR2 data at the instant 2015.5 contradicts the motion according to all-world observations. A possible reason is the presence of inner subsystems. The orientation of the obtained orbits in the galactic coordinate system is also given.","link":"http://arxiv.org/abs/2301.07602v2","created":"2023-01-18","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"The orbits of visual binary and multiple stars obtained by the Apparent Motion Parameters method during the last 40 years Summed many years of work at Pulkovo, the orbits of 67 wide pairs of visual double and multiple stars (included in 64 systems) which were obtained by the Apparent Motion Parameters (AMP) method are presented. This short arc determination orbit method is based on the most reliable astrometric and astrophysical data corresponding to one instant of time. The rest of the observations accumulated in the world serve to control the quality of the orbit and refine some parameters. All early determined AMP-orbits were compared with new observations, some of them were recalculated, new ones were added. For the stars of Pulkovo program of observations with a 26-inch refractor, the Gaia DR2 data were analised. Based on these data, the orbits of 16 stars were calculated. In 20 cases from 67, the quasi-instant motion according to the Gaia DR2 data at the instant 2015.5 contradicts the motion according to all-world observations. A possible reason is the presence of inner subsystems. The orientation of the obtained orbits in the galactic coordinate system is also given.","classes":{"dataset":0.2516676188}}
{"title":"Relaxed Graph Color Bound for the Maximum k-plex Problem","description":"As a relaxation of the clique, a k-plex of a graph is a vertex set that each vertex is not connected with at most k vertices of this set. Given an undirected graph, the Maximum k-plex Problem (MkP) aims to find its largest k-plex. Branch and bound algorithms are a type of well-studied and effective method for exact MkP solving, whose performance depends heavily on the quality of the upper bounds. In this paper, we investigate the relaxation properties of k-plex and propose an effective upper bound called Relaxed Graph color Bound (RGB) for the MkP. To describe and calculate RGB, we propose a new quasi-independent set structure that focuses on the number of conflict vertices. We combine RGB with two of the state-of-the-art branch and bound MkP algorithms, Maplex and KpLeX. Extensive experiments on real-world benchmarks, DIMACS benchmarks, and random graphs show the excellent performance of our proposed method over the state-of-the-art algorithms.","link":"http://arxiv.org/abs/2301.07300v1","created":"2023-01-18","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Relaxed Graph Color Bound for the Maximum k-plex Problem As a relaxation of the clique, a k-plex of a graph is a vertex set that each vertex is not connected with at most k vertices of this set. Given an undirected graph, the Maximum k-plex Problem (MkP) aims to find its largest k-plex. Branch and bound algorithms are a type of well-studied and effective method for exact MkP solving, whose performance depends heavily on the quality of the upper bounds. In this paper, we investigate the relaxation properties of k-plex and propose an effective upper bound called Relaxed Graph color Bound (RGB) for the MkP. To describe and calculate RGB, we propose a new quasi-independent set structure that focuses on the number of conflict vertices. We combine RGB with two of the state-of-the-art branch and bound MkP algorithms, Maplex and KpLeX. Extensive experiments on real-world benchmarks, DIMACS benchmarks, and random graphs show the excellent performance of our proposed method over the state-of-the-art algorithms.","classes":{"dataset":0.4788770974}}
{"title":"The JWST Resolved Stellar Populations Early Release Science Program III: Photometric Star-Galaxy Separations for NIRCam","description":"We present criteria for separately classifying stars and unresolved background galaxies in photometric catalogs generated with the point spread function (PSF) fitting photometry software DOLPHOT from images taken of Draco II, WLM, and M92 with the Near Infrared Camera (NIRCam) on JWST. Photometric quality metrics from DOLPHOT in one or two filters can recover a pure sample of stars. Conversely, colors formed between short-wavelength (SW) and long-wavelength (LW) filters can be used to effectively identify pure samples of galaxies. Our results highlight that the existing DOLPHOT output parameters can be used to reliably classify stars in our NIRCam data without the need to resort to external tools or more complex heuristics.","link":"http://arxiv.org/abs/2301.07218v1","created":"2023-01-17","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"The JWST Resolved Stellar Populations Early Release Science Program III: Photometric Star-Galaxy Separations for NIRCam We present criteria for separately classifying stars and unresolved background galaxies in photometric catalogs generated with the point spread function (PSF) fitting photometry software DOLPHOT from images taken of Draco II, WLM, and M92 with the Near Infrared Camera (NIRCam) on JWST. Photometric quality metrics from DOLPHOT in one or two filters can recover a pure sample of stars. Conversely, colors formed between short-wavelength (SW) and long-wavelength (LW) filters can be used to effectively identify pure samples of galaxies. Our results highlight that the existing DOLPHOT output parameters can be used to reliably classify stars in our NIRCam data without the need to resort to external tools or more complex heuristics.","classes":{"dataset":0.4090856612}}
{"title":"Prompting Large Language Model for Machine Translation: A Case Study","description":"Research on prompting has shown excellent performance with little or even no supervised training across many tasks. However, prompting for machine translation is still under-explored in the literature. We fill this gap by offering a systematic study on prompting strategies for translation, examining various factors for prompt template and demonstration example selection. We further explore the use of monolingual data and the feasibility of cross-lingual, cross-domain, and sentence-to-document transfer learning in prompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the testbed show that 1) the number and the quality of prompt examples matter, where using suboptimal examples degenerates translation; 2) several features of prompt examples, such as semantic similarity, show significant Spearman correlation with their prompting performance; yet, none of the correlations are strong enough; 3) using pseudo parallel prompt examples constructed from monolingual data via zero-shot prompting could improve translation; and 4) improved performance is achievable by transferring knowledge from prompt examples selected in other settings. We finally provide an analysis on the model outputs and discuss several problems that prompting still suffers from.","link":"http://arxiv.org/abs/2301.07069v2","created":"2023-01-17","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Prompting Large Language Model for Machine Translation: A Case Study Research on prompting has shown excellent performance with little or even no supervised training across many tasks. However, prompting for machine translation is still under-explored in the literature. We fill this gap by offering a systematic study on prompting strategies for translation, examining various factors for prompt template and demonstration example selection. We further explore the use of monolingual data and the feasibility of cross-lingual, cross-domain, and sentence-to-document transfer learning in prompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the testbed show that 1) the number and the quality of prompt examples matter, where using suboptimal examples degenerates translation; 2) several features of prompt examples, such as semantic similarity, show significant Spearman correlation with their prompting performance; yet, none of the correlations are strong enough; 3) using pseudo parallel prompt examples constructed from monolingual data via zero-shot prompting could improve translation; and 4) improved performance is achievable by transferring knowledge from prompt examples selected in other settings. We finally provide an analysis on the model outputs and discuss several problems that prompting still suffers from.","classes":{"dataset":0.1514106989}}
{"title":"Sleep Activity Recognition and Characterization from Multi-Source Passively Sensed Data","description":"Sleep constitutes a key indicator of human health, performance, and quality of life. Sleep deprivation has long been related to the onset, development, and worsening of several mental and metabolic disorders, constituting an essential marker for preventing, evaluating, and treating different health conditions. Sleep Activity Recognition methods can provide indicators to assess, monitor, and characterize subjects' sleep-wake cycles and detect behavioral changes. In this work, we propose a general method that continuously operates on passively sensed data from smartphones to characterize sleep and identify significant sleep episodes. Thanks to their ubiquity, these devices constitute an excellent alternative data source to profile subjects' biorhythms in a continuous, objective, and non-invasive manner, in contrast to traditional sleep assessment methods that usually rely on intrusive and subjective procedures. A Heterogeneous Hidden Markov Model is used to model a discrete latent variable process associated with the Sleep Activity Recognition task in a self-supervised way. We validate our results against sleep metrics reported by tested wearables, proving the effectiveness of the proposed approach and advocating its use to assess sleep without more reliable sources.","link":"http://arxiv.org/abs/2301.10156v1","created":"2023-01-17","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Sleep Activity Recognition and Characterization from Multi-Source Passively Sensed Data Sleep constitutes a key indicator of human health, performance, and quality of life. Sleep deprivation has long been related to the onset, development, and worsening of several mental and metabolic disorders, constituting an essential marker for preventing, evaluating, and treating different health conditions. Sleep Activity Recognition methods can provide indicators to assess, monitor, and characterize subjects' sleep-wake cycles and detect behavioral changes. In this work, we propose a general method that continuously operates on passively sensed data from smartphones to characterize sleep and identify significant sleep episodes. Thanks to their ubiquity, these devices constitute an excellent alternative data source to profile subjects' biorhythms in a continuous, objective, and non-invasive manner, in contrast to traditional sleep assessment methods that usually rely on intrusive and subjective procedures. A Heterogeneous Hidden Markov Model is used to model a discrete latent variable process associated with the Sleep Activity Recognition task in a self-supervised way. We validate our results against sleep metrics reported by tested wearables, proving the effectiveness of the proposed approach and advocating its use to assess sleep without more reliable sources.","classes":{"dataset":0.0770208314}}
{"title":"A Semi-supervised Sensing Rate Learning based CMAB Scheme to Combat COVID-19 by Trustful Data Collection in the Crowd","description":"Mobile CrowdSensing (MCS), through employing considerable workers to sense and collect data in a participatory manner, has been recognized as a promising paradigm for building many large-scale applications in a cost-effective way, such as combating COVID-19. The recruitment of trustworthy and high-quality workers is an important research issue for MCS. Previous studies assume that the qualities of workers are known in advance, or the platform knows the qualities of workers once it receives their collected data. In reality, to reduce their costs and thus maximize revenue, many strategic workers do not perform their sensing tasks honestly and report fake data to the platform. So, it is very hard for the platform to evaluate the authenticity of the received data. In this paper, an incentive mechanism named Semi-supervision based Combinatorial Multi-Armed Bandit reverse Auction (SCMABA) is proposed to solve the recruitment problem of multiple unknown and strategic workers in MCS. First, we model the worker recruitment as a multi-armed bandit reverse auction problem, and design an UCB-based algorithm to separate the exploration and exploitation, considering the Sensing Rates (SRs) of recruited workers as the gain of the bandit. Next, a Semi-supervised Sensing Rate Learning (SSRL) approach is proposed to quickly and accurately obtain the workers' SRs, which consists of two phases, supervision and self-supervision. Last, SCMABA is designed organically combining the SRs acquisition mechanism with multi-armed bandit reverse auction, where supervised SR learning is used in the exploration, and the self-supervised one is used in the exploitation. We prove that our SCMABA achieves truthfulness and individual rationality. Additionally, we exhibit outstanding performances of the SCMABA mechanism through in-depth simulations of real-world data traces.","link":"http://arxiv.org/abs/2301.08563v1","created":"2023-01-17","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"A Semi-supervised Sensing Rate Learning based CMAB Scheme to Combat COVID-19 by Trustful Data Collection in the Crowd Mobile CrowdSensing (MCS), through employing considerable workers to sense and collect data in a participatory manner, has been recognized as a promising paradigm for building many large-scale applications in a cost-effective way, such as combating COVID-19. The recruitment of trustworthy and high-quality workers is an important research issue for MCS. Previous studies assume that the qualities of workers are known in advance, or the platform knows the qualities of workers once it receives their collected data. In reality, to reduce their costs and thus maximize revenue, many strategic workers do not perform their sensing tasks honestly and report fake data to the platform. So, it is very hard for the platform to evaluate the authenticity of the received data. In this paper, an incentive mechanism named Semi-supervision based Combinatorial Multi-Armed Bandit reverse Auction (SCMABA) is proposed to solve the recruitment problem of multiple unknown and strategic workers in MCS. First, we model the worker recruitment as a multi-armed bandit reverse auction problem, and design an UCB-based algorithm to separate the exploration and exploitation, considering the Sensing Rates (SRs) of recruited workers as the gain of the bandit. Next, a Semi-supervised Sensing Rate Learning (SSRL) approach is proposed to quickly and accurately obtain the workers' SRs, which consists of two phases, supervision and self-supervision. Last, SCMABA is designed organically combining the SRs acquisition mechanism with multi-armed bandit reverse auction, where supervised SR learning is used in the exploration, and the self-supervised one is used in the exploitation. We prove that our SCMABA achieves truthfulness and individual rationality. Additionally, we exhibit outstanding performances of the SCMABA mechanism through in-depth simulations of real-world data traces.","classes":{"dataset":0.9937800765}}
{"title":"SwinDepth: Unsupervised Depth Estimation using Monocular Sequences via Swin Transformer and Densely Cascaded Network","description":"Monocular depth estimation plays a critical role in various computer vision and robotics applications such as localization, mapping, and 3D object detection. Recently, learning-based algorithms achieve huge success in depth estimation by training models with a large amount of data in a supervised manner. However, it is challenging to acquire dense ground truth depth labels for supervised training, and the unsupervised depth estimation using monocular sequences emerges as a promising alternative. Unfortunately, most studies on unsupervised depth estimation explore loss functions or occlusion masks, and there is little change in model architecture in that ConvNet-based encoder-decoder structure becomes a de-facto standard for depth estimation. In this paper, we employ a convolution-free Swin Transformer as an image feature extractor so that the network can capture both local geometric features and global semantic features for depth estimation. Also, we propose a Densely Cascaded Multi-scale Network (DCMNet) that connects every feature map directly with another from different scales via a top-down cascade pathway. This densely cascaded connectivity reinforces the interconnection between decoding layers and produces high-quality multi-scale depth outputs. The experiments on two different datasets, KITTI and Make3D, demonstrate that our proposed method outperforms existing state-of-the-art unsupervised algorithms.","link":"http://arxiv.org/abs/2301.06715v1","created":"2023-01-17","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"SwinDepth: Unsupervised Depth Estimation using Monocular Sequences via Swin Transformer and Densely Cascaded Network Monocular depth estimation plays a critical role in various computer vision and robotics applications such as localization, mapping, and 3D object detection. Recently, learning-based algorithms achieve huge success in depth estimation by training models with a large amount of data in a supervised manner. However, it is challenging to acquire dense ground truth depth labels for supervised training, and the unsupervised depth estimation using monocular sequences emerges as a promising alternative. Unfortunately, most studies on unsupervised depth estimation explore loss functions or occlusion masks, and there is little change in model architecture in that ConvNet-based encoder-decoder structure becomes a de-facto standard for depth estimation. In this paper, we employ a convolution-free Swin Transformer as an image feature extractor so that the network can capture both local geometric features and global semantic features for depth estimation. Also, we propose a Densely Cascaded Multi-scale Network (DCMNet) that connects every feature map directly with another from different scales via a top-down cascade pathway. This densely cascaded connectivity reinforces the interconnection between decoding layers and produces high-quality multi-scale depth outputs. The experiments on two different datasets, KITTI and Make3D, demonstrate that our proposed method outperforms existing state-of-the-art unsupervised algorithms.","classes":{"dataset":0.1753929406}}
{"title":"Sparsity based morphological identification of heartbeats","description":"The electrocardiogram (ECG) is one of the most common primary tests to evaluate the health of the heart. Reliable automatic interpretation of ECG records is crucial to the goal of improving public health. It can enable a safe inexpensive monitoring. This work presents a new methodology for morphological identification of heartbeats, which is placed outside the usual machine learning framework. The proposal considers the sparsity of the representation of a heartbeat as a parameter for morphological identification. The approach involves greedy algorithms for selecting elements from redundant dictionaries, which should be previously learnt from examples of the classes to be identified. Using different metrics of sparsity, the dictionary rendering the smallest sparsity value, for the equivalent approximation quality of a new heartbeat, classifies the morphology of that beat. This study focuses on a procedure of learning the dictionaries for representing heartbeats and compares several metrics of sparsity for morphological identification on the basis of those metrics. The suitability of the method is illustrated by binary differentiation of Normal and Ventricular heartbeats in the MIT-BIH Arrhythmia data set. In general classification 99.7% of the Normal beats and 97.6% of the Ventricular beats in the testing sets are correctly identified. In interpatient assessment 91.8% of the Normal beats and 91.0% of Ventricular beats are correctly identified. Even more important than these scores is the fact that they are produced on the bases of a single parameter. The numerical tests, designed to emphasise the interpretability and reliability of the approach, demonstrate the potential of the method to contribute towards the development of a well grounded expert system for classification of heartbeats in ECG records.","link":"http://arxiv.org/abs/2301.06538v1","created":"2023-01-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Sparsity based morphological identification of heartbeats The electrocardiogram (ECG) is one of the most common primary tests to evaluate the health of the heart. Reliable automatic interpretation of ECG records is crucial to the goal of improving public health. It can enable a safe inexpensive monitoring. This work presents a new methodology for morphological identification of heartbeats, which is placed outside the usual machine learning framework. The proposal considers the sparsity of the representation of a heartbeat as a parameter for morphological identification. The approach involves greedy algorithms for selecting elements from redundant dictionaries, which should be previously learnt from examples of the classes to be identified. Using different metrics of sparsity, the dictionary rendering the smallest sparsity value, for the equivalent approximation quality of a new heartbeat, classifies the morphology of that beat. This study focuses on a procedure of learning the dictionaries for representing heartbeats and compares several metrics of sparsity for morphological identification on the basis of those metrics. The suitability of the method is illustrated by binary differentiation of Normal and Ventricular heartbeats in the MIT-BIH Arrhythmia data set. In general classification 99.7% of the Normal beats and 97.6% of the Ventricular beats in the testing sets are correctly identified. In interpatient assessment 91.8% of the Normal beats and 91.0% of Ventricular beats are correctly identified. Even more important than these scores is the fact that they are produced on the bases of a single parameter. The numerical tests, designed to emphasise the interpretability and reliability of the approach, demonstrate the potential of the method to contribute towards the development of a well grounded expert system for classification of heartbeats in ECG records.","classes":{"dataset":0.0893687084}}
{"title":"PlasmoFAB: A Benchmark to Foster Machine Learning for Plasmodium falciparum Protein Antigen Candidate Prediction","description":"Motivation: Machine learning methods can be used to support scientific discovery in healthcare-related research fields. However, these methods can only be reliably used if they can be trained on high-quality and curated datasets. Currently, no such dataset for the exploration of Plasmodium falciparum protein antigen candidates exists. The parasite Plasmodium falciparum causes the infectious disease malaria. Thus, identifying potential antigens is of utmost importance for the development of antimalarial drugs and vaccines. Since exploring antigen candidates experimentally is an expensive and time-consuming process, applying machine learning methods to support this process has the potential to accelerate the development of drugs and vaccines which are needed for fighting and controlling malaria.   Results: We developed PlasmoFAB, a curated benchmark that can be used to train machine learning methods for the exploration of Plasmodium falciparum protein antigen candidates. We combined an extensive literature search with domain expertise to create high-quality labels for Plasmodium falciparum specific proteins that distinguish between antigen candidates and intracellular proteins. Additionally, we used our benchmark to compare different well-known prediction models and available protein localization prediction services on the task of identifying protein antigen candidates. We show that available general-purpose services are unable to provide sufficient performance on identifying protein antigen candidates and are outperformed by models that were trained on specialized data.","link":"http://arxiv.org/abs/2301.06454v1","created":"2023-01-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"PlasmoFAB: A Benchmark to Foster Machine Learning for Plasmodium falciparum Protein Antigen Candidate Prediction Motivation: Machine learning methods can be used to support scientific discovery in healthcare-related research fields. However, these methods can only be reliably used if they can be trained on high-quality and curated datasets. Currently, no such dataset for the exploration of Plasmodium falciparum protein antigen candidates exists. The parasite Plasmodium falciparum causes the infectious disease malaria. Thus, identifying potential antigens is of utmost importance for the development of antimalarial drugs and vaccines. Since exploring antigen candidates experimentally is an expensive and time-consuming process, applying machine learning methods to support this process has the potential to accelerate the development of drugs and vaccines which are needed for fighting and controlling malaria.   Results: We developed PlasmoFAB, a curated benchmark that can be used to train machine learning methods for the exploration of Plasmodium falciparum protein antigen candidates. We combined an extensive literature search with domain expertise to create high-quality labels for Plasmodium falciparum specific proteins that distinguish between antigen candidates and intracellular proteins. Additionally, we used our benchmark to compare different well-known prediction models and available protein localization prediction services on the task of identifying protein antigen candidates. We show that available general-purpose services are unable to provide sufficient performance on identifying protein antigen candidates and are outperformed by models that were trained on specialized data.","classes":{"dataset":0.1859767735}}
{"title":"DarkVision: A Benchmark for Low-light Image/Video Perception","description":"Imaging and perception in photon-limited scenarios is necessary for various applications, e.g., night surveillance or photography, high-speed photography, and autonomous driving. In these cases, cameras suffer from low signal-to-noise ratio, which degrades the image quality severely and poses challenges for downstream high-level vision tasks like object detection and recognition. Data-driven methods have achieved enormous success in both image restoration and high-level vision tasks. However, the lack of high-quality benchmark dataset with task-specific accurate annotations for photon-limited images/videos delays the research progress heavily. In this paper, we contribute the first multi-illuminance, multi-camera, and low-light dataset, named DarkVision, serving for both image enhancement and object detection. We provide bright and dark pairs with pixel-wise registration, in which the bright counterpart provides reliable reference for restoration and annotation. The dataset consists of bright-dark pairs of 900 static scenes with objects from 15 categories, and 32 dynamic scenes with 4-category objects. For each scene, images/videos were captured at 5 illuminance levels using three cameras of different grades, and average photons can be reliably estimated from the calibration data for quantitative studies. The static-scene images and dynamic videos respectively contain around 7,344 and 320,667 instances in total. With DarkVision, we established baselines for image/video enhancement and object detection by representative algorithms. To demonstrate an exemplary application of DarkVision, we propose two simple yet effective approaches for improving performance in video enhancement and object detection respectively. We believe DarkVision would advance the state-of-the-arts in both imaging and related computer vision tasks in low-light environment.","link":"http://arxiv.org/abs/2301.06269v1","created":"2023-01-16","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"DarkVision: A Benchmark for Low-light Image/Video Perception Imaging and perception in photon-limited scenarios is necessary for various applications, e.g., night surveillance or photography, high-speed photography, and autonomous driving. In these cases, cameras suffer from low signal-to-noise ratio, which degrades the image quality severely and poses challenges for downstream high-level vision tasks like object detection and recognition. Data-driven methods have achieved enormous success in both image restoration and high-level vision tasks. However, the lack of high-quality benchmark dataset with task-specific accurate annotations for photon-limited images/videos delays the research progress heavily. In this paper, we contribute the first multi-illuminance, multi-camera, and low-light dataset, named DarkVision, serving for both image enhancement and object detection. We provide bright and dark pairs with pixel-wise registration, in which the bright counterpart provides reliable reference for restoration and annotation. The dataset consists of bright-dark pairs of 900 static scenes with objects from 15 categories, and 32 dynamic scenes with 4-category objects. For each scene, images/videos were captured at 5 illuminance levels using three cameras of different grades, and average photons can be reliably estimated from the calibration data for quantitative studies. The static-scene images and dynamic videos respectively contain around 7,344 and 320,667 instances in total. With DarkVision, we established baselines for image/video enhancement and object detection by representative algorithms. To demonstrate an exemplary application of DarkVision, we propose two simple yet effective approaches for improving performance in video enhancement and object detection respectively. We believe DarkVision would advance the state-of-the-arts in both imaging and related computer vision tasks in low-light environment.","classes":{"dataset":0.3474093378}}
{"title":"BuildSeg: A General Framework for the Segmentation of Buildings","description":"Building segmentation from aerial images and 3D laser scanning (LiDAR) is a challenging task due to the diversity of backgrounds, building textures, and image quality. While current research using different types of convolutional and transformer networks has considerably improved the performance on this task, even more accurate segmentation methods for buildings are desirable for applications such as automatic mapping. In this study, we propose a general framework termed \\emph{BuildSeg} employing a generic approach that can be quickly applied to segment buildings. Different data sources were combined to increase generalization performance. The approach yields good results for different data sources as shown by experiments on high-resolution multi-spectral and LiDAR imagery of cities in Norway, Denmark and France. We applied ConvNeXt and SegFormer based models on the high resolution aerial image dataset from the MapAI-competition. The methods achieved an IOU of 0.7902 and a boundary IOU of 0.6185. We used post-processing to account for the rectangular shape of the objects. This increased the boundary IOU from 0.6185 to 0.6189.","link":"http://arxiv.org/abs/2301.06190v1","created":"2023-01-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"BuildSeg: A General Framework for the Segmentation of Buildings Building segmentation from aerial images and 3D laser scanning (LiDAR) is a challenging task due to the diversity of backgrounds, building textures, and image quality. While current research using different types of convolutional and transformer networks has considerably improved the performance on this task, even more accurate segmentation methods for buildings are desirable for applications such as automatic mapping. In this study, we propose a general framework termed \\emph{BuildSeg} employing a generic approach that can be quickly applied to segment buildings. Different data sources were combined to increase generalization performance. The approach yields good results for different data sources as shown by experiments on high-resolution multi-spectral and LiDAR imagery of cities in Norway, Denmark and France. We applied ConvNeXt and SegFormer based models on the high resolution aerial image dataset from the MapAI-competition. The methods achieved an IOU of 0.7902 and a boundary IOU of 0.6185. We used post-processing to account for the rectangular shape of the objects. This increased the boundary IOU from 0.6185 to 0.6189.","classes":{"dataset":0.2276040614}}
{"title":"Learning to Compress Unmanned Aerial Vehicle (UAV) Captured Video: Benchmark and Analysis","description":"During the past decade, the Unmanned-Aerial-Vehicles (UAVs) have attracted increasing attention due to their flexible, extensive, and dynamic space-sensing capabilities. The volume of video captured by UAVs is exponentially growing along with the increased bitrate generated by the advancement of the sensors mounted on UAVs, bringing new challenges for on-device UAV storage and air-ground data transmission. Most existing video compression schemes were designed for natural scenes without consideration of specific texture and view characteristics of UAV videos. In this work, we first contribute a detailed analysis of the current state of the field of UAV video coding. Then we propose to establish a novel task for learned UAV video coding and construct a comprehensive and systematic benchmark for such a task, present a thorough review of high quality UAV video datasets and benchmarks, and contribute extensive rate-distortion efficiency comparison of learned and conventional codecs after. Finally, we discuss the challenges of encoding UAV videos. It is expected that the benchmark will accelerate the research and development in video coding on drone platforms.","link":"http://arxiv.org/abs/2301.06115v1","created":"2023-01-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Learning to Compress Unmanned Aerial Vehicle (UAV) Captured Video: Benchmark and Analysis During the past decade, the Unmanned-Aerial-Vehicles (UAVs) have attracted increasing attention due to their flexible, extensive, and dynamic space-sensing capabilities. The volume of video captured by UAVs is exponentially growing along with the increased bitrate generated by the advancement of the sensors mounted on UAVs, bringing new challenges for on-device UAV storage and air-ground data transmission. Most existing video compression schemes were designed for natural scenes without consideration of specific texture and view characteristics of UAV videos. In this work, we first contribute a detailed analysis of the current state of the field of UAV video coding. Then we propose to establish a novel task for learned UAV video coding and construct a comprehensive and systematic benchmark for such a task, present a thorough review of high quality UAV video datasets and benchmarks, and contribute extensive rate-distortion efficiency comparison of learned and conventional codecs after. Finally, we discuss the challenges of encoding UAV videos. It is expected that the benchmark will accelerate the research and development in video coding on drone platforms.","classes":{"dataset":0.4700861871}}
{"title":"Rethinking Precision of Pseudo Label: Test-Time Adaptation via Complementary Learning","description":"In this work, we propose a novel complementary learning approach to enhance test-time adaptation (TTA), which has been proven to exhibit good performance on testing data with distribution shifts such as corruptions. In test-time adaptation tasks, information from the source domain is typically unavailable and the model has to be optimized without supervision for test-time samples. Hence, usual methods assign labels for unannotated data with the prediction by a well-trained source model in an unsupervised learning framework. Previous studies have employed unsupervised objectives, such as the entropy of model predictions, as optimization targets to effectively learn features for test-time samples. However, the performance of the model is easily compromised by the quality of pseudo-labels, since inaccuracies in pseudo-labels introduce noise to the model. Therefore, we propose to leverage the \"less probable categories\" to decrease the risk of incorrect pseudo-labeling. The complementary label is introduced to designate these categories. We highlight that the risk function of complementary labels agrees with their Vanilla loss formula under the conventional true label distribution. Experiments show that the proposed learning algorithm achieves state-of-the-art performance on different datasets and experiment settings.","link":"http://arxiv.org/abs/2301.06013v1","created":"2023-01-15","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Rethinking Precision of Pseudo Label: Test-Time Adaptation via Complementary Learning In this work, we propose a novel complementary learning approach to enhance test-time adaptation (TTA), which has been proven to exhibit good performance on testing data with distribution shifts such as corruptions. In test-time adaptation tasks, information from the source domain is typically unavailable and the model has to be optimized without supervision for test-time samples. Hence, usual methods assign labels for unannotated data with the prediction by a well-trained source model in an unsupervised learning framework. Previous studies have employed unsupervised objectives, such as the entropy of model predictions, as optimization targets to effectively learn features for test-time samples. However, the performance of the model is easily compromised by the quality of pseudo-labels, since inaccuracies in pseudo-labels introduce noise to the model. Therefore, we propose to leverage the \"less probable categories\" to decrease the risk of incorrect pseudo-labeling. The complementary label is introduced to designate these categories. We highlight that the risk function of complementary labels agrees with their Vanilla loss formula under the conventional true label distribution. Experiments show that the proposed learning algorithm achieves state-of-the-art performance on different datasets and experiment settings.","classes":{"dataset":0.3636454344}}
{"title":"Conceptual Framework and Documentation Standards of Cystoscopic Media Content for Artificial Intelligence","description":"Background: The clinical documentation of cystoscopy includes visual and textual materials. However, the secondary use of visual cystoscopic data for educational and research purposes remains limited due to inefficient data management in routine clinical practice. Methods: A conceptual framework was designed to document cystoscopy in a standardized manner with three major sections: data management, annotation management, and utilization management. A Swiss-cheese model was proposed for quality control and root cause analyses. We defined the infrastructure required to implement the framework with respect to FAIR (findable, accessible, interoperable, re-usable) principles. We applied two scenarios exemplifying data sharing for research and educational projects to ensure the compliance with FAIR principles. Results: The framework was successfully implemented while following FAIR principles. The cystoscopy atlas produced from the framework could be presented in an educational web portal; a total of 68 full-length qualitative videos and corresponding annotation data were sharable for artificial intelligence projects covering frame classification and segmentation problems at case, lesion and frame levels. Conclusion: Our study shows that the proposed framework facilitates the storage of the visual documentation in a standardized manner and enables FAIR data for education and artificial intelligence research.","link":"http://arxiv.org/abs/2301.05991v2","created":"2023-01-14","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Conceptual Framework and Documentation Standards of Cystoscopic Media Content for Artificial Intelligence Background: The clinical documentation of cystoscopy includes visual and textual materials. However, the secondary use of visual cystoscopic data for educational and research purposes remains limited due to inefficient data management in routine clinical practice. Methods: A conceptual framework was designed to document cystoscopy in a standardized manner with three major sections: data management, annotation management, and utilization management. A Swiss-cheese model was proposed for quality control and root cause analyses. We defined the infrastructure required to implement the framework with respect to FAIR (findable, accessible, interoperable, re-usable) principles. We applied two scenarios exemplifying data sharing for research and educational projects to ensure the compliance with FAIR principles. Results: The framework was successfully implemented while following FAIR principles. The cystoscopy atlas produced from the framework could be presented in an educational web portal; a total of 68 full-length qualitative videos and corresponding annotation data were sharable for artificial intelligence projects covering frame classification and segmentation problems at case, lesion and frame levels. Conclusion: Our study shows that the proposed framework facilitates the storage of the visual documentation in a standardized manner and enables FAIR data for education and artificial intelligence research.","classes":{"dataset":0.3231391907}}
{"title":"Model-based Transfer Learning for Automatic Optical Inspection based on domain discrepancy","description":"Transfer learning is a promising method for AOI applications since it can significantly shorten sample collection time and improve efficiency in today's smart manufacturing. However, related research enhanced the network models by applying TL without considering the domain similarity among datasets, the data long-tailedness of a source dataset, and mainly used linear transformations to mitigate the lack of samples. This research applies model-based TL via domain similarity to improve the overall performance and data augmentation in both target and source domains to enrich the data quality and reduce the imbalance. Given a group of source datasets from similar industrial processes, we define which group is the most related to the target through the domain discrepancy score and the number of samples each has. Then, we transfer the chosen pre-trained backbone weights to train and fine-tune the target network. Our research suggests increases in the F1 score and the PR curve up to 20% compared with TL using benchmark datasets.","link":"http://arxiv.org/abs/2301.05897v1","created":"2023-01-14","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Model-based Transfer Learning for Automatic Optical Inspection based on domain discrepancy Transfer learning is a promising method for AOI applications since it can significantly shorten sample collection time and improve efficiency in today's smart manufacturing. However, related research enhanced the network models by applying TL without considering the domain similarity among datasets, the data long-tailedness of a source dataset, and mainly used linear transformations to mitigate the lack of samples. This research applies model-based TL via domain similarity to improve the overall performance and data augmentation in both target and source domains to enrich the data quality and reduce the imbalance. Given a group of source datasets from similar industrial processes, we define which group is the most related to the target through the domain discrepancy score and the number of samples each has. Then, we transfer the chosen pre-trained backbone weights to train and fine-tune the target network. Our research suggests increases in the F1 score and the PR curve up to 20% compared with TL using benchmark datasets.","classes":{"dataset":0.3457558751}}
{"title":"Safe Control Transitions: Machine Vision Based Observable Readiness Index and Data-Driven Takeover Time Prediction","description":"To make safe transitions from autonomous to manual control, a vehicle must have a representation of the awareness of driver state; two metrics which quantify this state are the Observable Readiness Index and Takeover Time. In this work, we show that machine learning models which predict these two metrics are robust to multiple camera views, expanding from the limited view angles in prior research. Importantly, these models take as input feature vectors corresponding to hand location and activity as well as gaze location, and we explore the tradeoffs of different views in generating these feature vectors. Further, we introduce two metrics to evaluate the quality of control transitions following the takeover event (the maximal lateral deviation and velocity deviation) and compute correlations of these post-takeover metrics to the pre-takeover predictive metrics.","link":"http://arxiv.org/abs/2301.05805v2","created":"2023-01-14","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Safe Control Transitions: Machine Vision Based Observable Readiness Index and Data-Driven Takeover Time Prediction To make safe transitions from autonomous to manual control, a vehicle must have a representation of the awareness of driver state; two metrics which quantify this state are the Observable Readiness Index and Takeover Time. In this work, we show that machine learning models which predict these two metrics are robust to multiple camera views, expanding from the limited view angles in prior research. Importantly, these models take as input feature vectors corresponding to hand location and activity as well as gaze location, and we explore the tradeoffs of different views in generating these feature vectors. Further, we introduce two metrics to evaluate the quality of control transitions following the takeover event (the maximal lateral deviation and velocity deviation) and compute correlations of these post-takeover metrics to the pre-takeover predictive metrics.","classes":{"dataset":0.1499511153}}
{"title":"Price impact in equity auctions: zero, then linear","description":"Using high-quality data, we report several statistical regularities of equity auctions in the Paris stock exchange. First, the average order book density is linear around the auction price at the time of auction clearing and has a large peak at the auction price. The linear part comes from fast traders, while the peak is due to slow traders. The impact of a new market order or cancellation at the auction time can be decomposed into three parts as a function of the size of the additional order: (1) zero impact because of the discrete nature of prices; this holds for surprisingly large orders relative to the auction volume (2) linear impact for additional orders up to a large fraction of the auction volume (3) for even larger orders price impact is non-linear, frequently superlinear.","link":"http://arxiv.org/abs/2301.05677v1","created":"2023-01-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Price impact in equity auctions: zero, then linear Using high-quality data, we report several statistical regularities of equity auctions in the Paris stock exchange. First, the average order book density is linear around the auction price at the time of auction clearing and has a large peak at the auction price. The linear part comes from fast traders, while the peak is due to slow traders. The impact of a new market order or cancellation at the auction time can be decomposed into three parts as a function of the size of the additional order: (1) zero impact because of the discrete nature of prices; this holds for surprisingly large orders relative to the auction volume (2) linear impact for additional orders up to a large fraction of the auction volume (3) for even larger orders price impact is non-linear, frequently superlinear.","classes":{"dataset":0.9691508412}}
{"title":"Understanding Concept Identification as Consistent Data Clustering Across Multiple Feature Spaces","description":"Identifying meaningful concepts in large data sets can provide valuable insights into engineering design problems. Concept identification aims at identifying non-overlapping groups of design instances that are similar in a joint space of all features, but which are also similar when considering only subsets of features. These subsets usually comprise features that characterize a design with respect to one specific context, for example, constructive design parameters, performance values, or operation modes. It is desirable to evaluate the quality of design concepts by considering several of these feature subsets in isolation. In particular, meaningful concepts should not only identify dense, well separated groups of data instances, but also provide non-overlapping groups of data that persist when considering pre-defined feature subsets separately. In this work, we propose to view concept identification as a special form of clustering algorithm with a broad range of potential applications beyond engineering design. To illustrate the differences between concept identification and classical clustering algorithms, we apply a recently proposed concept identification algorithm to two synthetic data sets and show the differences in identified solutions. In addition, we introduce the mutual information measure as a metric to evaluate whether solutions return consistent clusters across relevant subsets. To support the novel understanding of concept identification, we consider a simulated data set from a decision-making problem in the energy management domain and show that the identified clusters are more interpretable with respect to relevant feature subsets than clusters found by common clustering algorithms and are thus more suitable to support a decision maker.","link":"http://arxiv.org/abs/2301.05525v1","created":"2023-01-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Understanding Concept Identification as Consistent Data Clustering Across Multiple Feature Spaces Identifying meaningful concepts in large data sets can provide valuable insights into engineering design problems. Concept identification aims at identifying non-overlapping groups of design instances that are similar in a joint space of all features, but which are also similar when considering only subsets of features. These subsets usually comprise features that characterize a design with respect to one specific context, for example, constructive design parameters, performance values, or operation modes. It is desirable to evaluate the quality of design concepts by considering several of these feature subsets in isolation. In particular, meaningful concepts should not only identify dense, well separated groups of data instances, but also provide non-overlapping groups of data that persist when considering pre-defined feature subsets separately. In this work, we propose to view concept identification as a special form of clustering algorithm with a broad range of potential applications beyond engineering design. To illustrate the differences between concept identification and classical clustering algorithms, we apply a recently proposed concept identification algorithm to two synthetic data sets and show the differences in identified solutions. In addition, we introduce the mutual information measure as a metric to evaluate whether solutions return consistent clusters across relevant subsets. To support the novel understanding of concept identification, we consider a simulated data set from a decision-making problem in the energy management domain and show that the identified clusters are more interpretable with respect to relevant feature subsets than clusters found by common clustering algorithms and are thus more suitable to support a decision maker.","classes":{"dataset":0.2182114571}}
{"title":"Scalable Batch Acquisition for Deep Bayesian Active Learning","description":"In deep active learning, it is especially important to choose multiple examples to markup at each step to work efficiently, especially on large datasets. At the same time, existing solutions to this problem in the Bayesian setup, such as BatchBALD, have significant limitations in selecting a large number of examples, associated with the exponential complexity of computing mutual information for joint random variables. We, therefore, present the Large BatchBALD algorithm, which gives a well-grounded approximation to the BatchBALD method that aims to achieve comparable quality while being more computationally efficient. We provide a complexity analysis of the algorithm, showing a reduction in computation time, especially for large batches. Furthermore, we present an extensive set of experimental results on image and text data, both on toy datasets and larger ones such as CIFAR-100.","link":"http://arxiv.org/abs/2301.05490v1","created":"2023-01-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Scalable Batch Acquisition for Deep Bayesian Active Learning In deep active learning, it is especially important to choose multiple examples to markup at each step to work efficiently, especially on large datasets. At the same time, existing solutions to this problem in the Bayesian setup, such as BatchBALD, have significant limitations in selecting a large number of examples, associated with the exponential complexity of computing mutual information for joint random variables. We, therefore, present the Large BatchBALD algorithm, which gives a well-grounded approximation to the BatchBALD method that aims to achieve comparable quality while being more computationally efficient. We provide a complexity analysis of the algorithm, showing a reduction in computation time, especially for large batches. Furthermore, we present an extensive set of experimental results on image and text data, both on toy datasets and larger ones such as CIFAR-100.","classes":{"dataset":0.0917095318}}
{"title":"Explicit Temporal Embedding in Deep Generative Latent Models for Longitudinal Medical Image Synthesis","description":"Medical imaging plays a vital role in modern diagnostics and treatment. The temporal nature of disease or treatment progression often results in longitudinal data. Due to the cost and potential harm, acquiring large medical datasets necessary for deep learning can be difficult. Medical image synthesis could help mitigate this problem. However, until now, the availability of GANs capable of synthesizing longitudinal volumetric data has been limited. To address this, we use the recent advances in latent space-based image editing to propose a novel joint learning scheme to explicitly embed temporal dependencies in the latent space of GANs. This, in contrast to previous methods, allows us to synthesize continuous, smooth, and high-quality longitudinal volumetric data with limited supervision. We show the effectiveness of our approach on three datasets containing different longitudinal dependencies. Namely, modeling a simple image transformation, breathing motion, and tumor regression, all while showing minimal disentanglement. The implementation is made available online at https://github.com/julschoen/Temp-GAN.","link":"http://arxiv.org/abs/2301.05465v1","created":"2023-01-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Explicit Temporal Embedding in Deep Generative Latent Models for Longitudinal Medical Image Synthesis Medical imaging plays a vital role in modern diagnostics and treatment. The temporal nature of disease or treatment progression often results in longitudinal data. Due to the cost and potential harm, acquiring large medical datasets necessary for deep learning can be difficult. Medical image synthesis could help mitigate this problem. However, until now, the availability of GANs capable of synthesizing longitudinal volumetric data has been limited. To address this, we use the recent advances in latent space-based image editing to propose a novel joint learning scheme to explicitly embed temporal dependencies in the latent space of GANs. This, in contrast to previous methods, allows us to synthesize continuous, smooth, and high-quality longitudinal volumetric data with limited supervision. We show the effectiveness of our approach on three datasets containing different longitudinal dependencies. Namely, modeling a simple image transformation, breathing motion, and tumor regression, all while showing minimal disentanglement. The implementation is made available online at https://github.com/julschoen/Temp-GAN.","classes":{"dataset":0.3360233009}}
{"title":"LVRNet: Lightweight Image Restoration for Aerial Images under Low Visibility","description":"Learning to recover clear images from images having a combination of degrading factors is a challenging task. That being said, autonomous surveillance in low visibility conditions caused by high pollution/smoke, poor air quality index, low light, atmospheric scattering, and haze during a blizzard becomes even more important to prevent accidents. It is thus crucial to form a solution that can result in a high-quality image and is efficient enough to be deployed for everyday use. However, the lack of proper datasets available to tackle this task limits the performance of the previous methods proposed. To this end, we generate the LowVis-AFO dataset, containing 3647 paired dark-hazy and clear images. We also introduce a lightweight deep learning model called Low-Visibility Restoration Network (LVRNet). It outperforms previous image restoration methods with low latency, achieving a PSNR value of 25.744 and an SSIM of 0.905, making our approach scalable and ready for practical use. The code and data can be found at https://github.com/Achleshwar/LVRNet.","link":"http://arxiv.org/abs/2301.05434v1","created":"2023-01-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"LVRNet: Lightweight Image Restoration for Aerial Images under Low Visibility Learning to recover clear images from images having a combination of degrading factors is a challenging task. That being said, autonomous surveillance in low visibility conditions caused by high pollution/smoke, poor air quality index, low light, atmospheric scattering, and haze during a blizzard becomes even more important to prevent accidents. It is thus crucial to form a solution that can result in a high-quality image and is efficient enough to be deployed for everyday use. However, the lack of proper datasets available to tackle this task limits the performance of the previous methods proposed. To this end, we generate the LowVis-AFO dataset, containing 3647 paired dark-hazy and clear images. We also introduce a lightweight deep learning model called Low-Visibility Restoration Network (LVRNet). It outperforms previous image restoration methods with low latency, achieving a PSNR value of 25.744 and an SSIM of 0.905, making our approach scalable and ready for practical use. The code and data can be found at https://github.com/Achleshwar/LVRNet.","classes":{"dataset":0.0130396783}}
{"title":"Surface magnetic field of the A-type metallic-line star omicron Pegasi revisited","description":"The bright A-type metallic-line star o Peg was reported in the early 1990s to have a surface magnetic field of ~2kG by analyzing the widths and strengths of spectral lines. In respect that those old studies were of rather empirical or approximate nature and the quality of observational data was not sufficient, this problem has been newly reinvestigated based on physically more rigorous simulations of line flux profiles, along with the observed equivalent widths (W) and full-widths at half-maximum (h) of 198 Fe I and 182 Fe II lines measured from the high-quality spectra. Given the Fe abundance derived from the conventional analysis, theoretical W and h values calculated for various sets of parameters were compared with the observed ones, which lead to the following conclusion regarding <H> (mean field strength). (1) An analysis of W yielded <H>~1-1.5kG from Fe II lines with the microturbulence of vt~1.5km/s. (2) A comparison of h resulted in <H>~1.5-2kG as well as the projected rotational velocity of vsini~5km/s. (3) Accordingly, the existence of mean magnetic field on the order of <H>~1-2kG in o Peg was confirmed, which is almost consistent with the consequence of the previous work.","link":"http://arxiv.org/abs/2301.05367v1","created":"2023-01-13","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Surface magnetic field of the A-type metallic-line star omicron Pegasi revisited The bright A-type metallic-line star o Peg was reported in the early 1990s to have a surface magnetic field of ~2kG by analyzing the widths and strengths of spectral lines. In respect that those old studies were of rather empirical or approximate nature and the quality of observational data was not sufficient, this problem has been newly reinvestigated based on physically more rigorous simulations of line flux profiles, along with the observed equivalent widths (W) and full-widths at half-maximum (h) of 198 Fe I and 182 Fe II lines measured from the high-quality spectra. Given the Fe abundance derived from the conventional analysis, theoretical W and h values calculated for various sets of parameters were compared with the observed ones, which lead to the following conclusion regarding <H> (mean field strength). (1) An analysis of W yielded <H>~1-1.5kG from Fe II lines with the microturbulence of vt~1.5km/s. (2) A comparison of h resulted in <H>~1.5-2kG as well as the projected rotational velocity of vsini~5km/s. (3) Accordingly, the existence of mean magnetic field on the order of <H>~1-2kG in o Peg was confirmed, which is almost consistent with the consequence of the previous work.","classes":{"dataset":0.1006327569}}
{"title":"Modeling Strong Lenses from Wide-Field Ground-Based Observations in KiDS and GAMA","description":"Despite the success of galaxy-scale strong gravitational lens studies with Hubble-quality imaging, the number of well-studied strong lenses remains small. As a result, robust comparisons of the lens models to theoretical predictions are difficult. This motivates our application of automated Bayesian lens modeling methods to observations from public data releases of overlapping large ground-based imaging and spectroscopic surveys: Kilo-Degree Survey (KiDS) and Galaxy and Mass Assembly (GAMA), respectively. We use the open-source lens modeling software PyAutoLens to perform our analysis. We demonstrate the feasibility of strong lens modeling with large-survey data at lower resolution as a complementary avenue to studies that utilize more time-consuming and expensive observations of individual lenses at higher resolution. We discuss advantages and challenges, with special consideration given to determining background source redshifts from single-aperture spectra and to disentangling foreground lens and background source light. High uncertainties in the best-fit parameters for the models due to the limits of optical resolution in ground-based observatories and the small sample size can be improved with future study. We give broadly applicable recommendations for future efforts, and with proper application this approach could yield measurements in the quantities needed for robust statistical inference.","link":"http://arxiv.org/abs/2301.05320v2","created":"2023-01-12","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Modeling Strong Lenses from Wide-Field Ground-Based Observations in KiDS and GAMA Despite the success of galaxy-scale strong gravitational lens studies with Hubble-quality imaging, the number of well-studied strong lenses remains small. As a result, robust comparisons of the lens models to theoretical predictions are difficult. This motivates our application of automated Bayesian lens modeling methods to observations from public data releases of overlapping large ground-based imaging and spectroscopic surveys: Kilo-Degree Survey (KiDS) and Galaxy and Mass Assembly (GAMA), respectively. We use the open-source lens modeling software PyAutoLens to perform our analysis. We demonstrate the feasibility of strong lens modeling with large-survey data at lower resolution as a complementary avenue to studies that utilize more time-consuming and expensive observations of individual lenses at higher resolution. We discuss advantages and challenges, with special consideration given to determining background source redshifts from single-aperture spectra and to disentangling foreground lens and background source light. High uncertainties in the best-fit parameters for the models due to the limits of optical resolution in ground-based observatories and the small sample size can be improved with future study. We give broadly applicable recommendations for future efforts, and with proper application this approach could yield measurements in the quantities needed for robust statistical inference.","classes":{"dataset":0.3392943144}}
{"title":"Heuristic for Diverse Kemeny Rank Aggregation based on Quantum Annealing","description":"The Kemeny Rank Aggregation (KRA) problem is a well-studied problem in the field of Social Choice with a variety of applications in many different areas like databases and search engines. Intuitively, given a set of votes over a set of candidates, the problem asks to find an aggregated ranking of candidates that minimizes the overall dissatisfaction concerning the votes. Recently, a diverse version of KRA was considered which asks for a sufficiently diverse set of sufficiently good solutions. The framework of diversity of solutions is a young and thriving topic in the field of artificial intelligence. The main idea is to provide the user with not just one, but with a set of different solutions, enabling her to pick a sufficiently good solution that satisfies additional subjective criteria that are hard or impossible to model.   In this work, we use a quantum annealer to solve the KRA problem and to compute a representative set of solutions. Quantum annealing is a meta search heuristic that does not only show promising runtime behavior on currently existing prototypes but also samples the solutions space in an inherently different way, making use of quantum effects. We describe how KRA instances can be solved by a quantum annealer and provide an implementation as well as experimental evaluations. As existing quantum annealers are still restricted in their number of qubits, we further implement two different data reduction rules that can split an instance into a set of smaller instances. In our evaluation, we compare classical heuristics that allow to sample multiple solutions such as simulated annealing and local search with quantum annealing performed on a physical quantum annealer. We compare runtime, quality of solution, and diversity of solutions, with and without applying preceding data reduction rules.","link":"http://arxiv.org/abs/2301.05146v1","created":"2023-01-12","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Heuristic for Diverse Kemeny Rank Aggregation based on Quantum Annealing The Kemeny Rank Aggregation (KRA) problem is a well-studied problem in the field of Social Choice with a variety of applications in many different areas like databases and search engines. Intuitively, given a set of votes over a set of candidates, the problem asks to find an aggregated ranking of candidates that minimizes the overall dissatisfaction concerning the votes. Recently, a diverse version of KRA was considered which asks for a sufficiently diverse set of sufficiently good solutions. The framework of diversity of solutions is a young and thriving topic in the field of artificial intelligence. The main idea is to provide the user with not just one, but with a set of different solutions, enabling her to pick a sufficiently good solution that satisfies additional subjective criteria that are hard or impossible to model.   In this work, we use a quantum annealer to solve the KRA problem and to compute a representative set of solutions. Quantum annealing is a meta search heuristic that does not only show promising runtime behavior on currently existing prototypes but also samples the solutions space in an inherently different way, making use of quantum effects. We describe how KRA instances can be solved by a quantum annealer and provide an implementation as well as experimental evaluations. As existing quantum annealers are still restricted in their number of qubits, we further implement two different data reduction rules that can split an instance into a set of smaller instances. In our evaluation, we compare classical heuristics that allow to sample multiple solutions such as simulated annealing and local search with quantum annealing performed on a physical quantum annealer. We compare runtime, quality of solution, and diversity of solutions, with and without applying preceding data reduction rules.","classes":{"dataset":0.2381349951}}
{"title":"Equivariant Representations for Non-Free Group Actions","description":"We introduce a method for learning representations that are equivariant with respect to general group actions over data. Differently from existing equivariant representation learners, our method is suitable for actions that are not free i.e., that stabilize data via nontrivial symmetries. Our method is grounded in the orbit-stabilizer theorem from group theory, which guarantees that an ideal learner infers an isomorphic representation. Finally, we provide an empirical investigation on image datasets with rotational symmetries and show that taking stabilizers into account improves the quality of the representations.","link":"http://arxiv.org/abs/2301.05231v1","created":"2023-01-12","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Equivariant Representations for Non-Free Group Actions We introduce a method for learning representations that are equivariant with respect to general group actions over data. Differently from existing equivariant representation learners, our method is suitable for actions that are not free i.e., that stabilize data via nontrivial symmetries. Our method is grounded in the orbit-stabilizer theorem from group theory, which guarantees that an ideal learner infers an isomorphic representation. Finally, we provide an empirical investigation on image datasets with rotational symmetries and show that taking stabilizers into account improves the quality of the representations.","classes":{"dataset":0.7307534218}}
{"title":"Grant-Free Random Access of IoT devices in Massive MIMO with Partial CSI","description":"The number of wireless devices is drastically increasing, resulting in many devices contending for radio resources. In this work, we present an algorithm to detect active devices for unsourced random access, i.e., the devices are uncoordinated. The devices use a unique, but non-orthogonal preamble, known to the network, prior to sending the payload data. They do not employ any carrier sensing technique and blindly transmit the preamble and data. To detect the active users, we exploit partial channel state information (CSI), which could have been obtained through a previous channel estimate. For static devices, e.g., Internet of Things nodes, it is shown that CSI is less time-variant than assumed in many theoretical works. The presented iterative algorithm uses a maximum likelihood approach to estimate both the activity and a potential phase offset of each known device. The convergence of the proposed algorithm is evaluated. The performance in terms of probability of miss detection and false alarm is assessed for different qualities of partial CSI and different signal-to-noise ratio.","link":"http://arxiv.org/abs/2301.04861v1","created":"2023-01-12","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Grant-Free Random Access of IoT devices in Massive MIMO with Partial CSI The number of wireless devices is drastically increasing, resulting in many devices contending for radio resources. In this work, we present an algorithm to detect active devices for unsourced random access, i.e., the devices are uncoordinated. The devices use a unique, but non-orthogonal preamble, known to the network, prior to sending the payload data. They do not employ any carrier sensing technique and blindly transmit the preamble and data. To detect the active users, we exploit partial channel state information (CSI), which could have been obtained through a previous channel estimate. For static devices, e.g., Internet of Things nodes, it is shown that CSI is less time-variant than assumed in many theoretical works. The presented iterative algorithm uses a maximum likelihood approach to estimate both the activity and a potential phase offset of each known device. The convergence of the proposed algorithm is evaluated. The performance in terms of probability of miss detection and false alarm is assessed for different qualities of partial CSI and different signal-to-noise ratio.","classes":{"dataset":0.3185227215}}
{"title":"Graph-based compensated wavelet lifting for 3-D+t medical CT data","description":"An efficient scalable data representation is an important task especially in the medical area, e.g. for volumes from Computed Tomography (CT) or Magnetic Resonance Tomography (MRT), when a downscaled version of the original signal is needed. Image and video coders based on wavelet transforms provide an adequate way to naturally achieve scalability. This paper presents a new approach for improving the visual quality of the lowpass band by using a novel graph-based method for motion compensation, which is an important step considering data compression. We compare different kinds of neighborhoods for graph construction and demonstrate that a higher amount of referenced nodes increases the quality of the lowpass band while the mean energy of the highpass band decreases. We show that for cardiac CT data the proposed method outperforms a traditional mesh-based approach of motion compensation by approximately 11 dB in terms of PSNR of the lowpass band. Also the mean energy of the highpass band decreases by around 30%.","link":"http://arxiv.org/abs/2301.04839v1","created":"2023-01-12","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Graph-based compensated wavelet lifting for 3-D+t medical CT data An efficient scalable data representation is an important task especially in the medical area, e.g. for volumes from Computed Tomography (CT) or Magnetic Resonance Tomography (MRT), when a downscaled version of the original signal is needed. Image and video coders based on wavelet transforms provide an adequate way to naturally achieve scalability. This paper presents a new approach for improving the visual quality of the lowpass band by using a novel graph-based method for motion compensation, which is an important step considering data compression. We compare different kinds of neighborhoods for graph construction and demonstrate that a higher amount of referenced nodes increases the quality of the lowpass band while the mean energy of the highpass band decreases. We show that for cardiac CT data the proposed method outperforms a traditional mesh-based approach of motion compensation by approximately 11 dB in terms of PSNR of the lowpass band. Also the mean energy of the highpass band decreases by around 30%.","classes":{"dataset":0.1976571828}}
{"title":"Data-centric AI: Perspectives and Challenges","description":"The role of data in building AI systems has recently been significantly magnified by the emerging concept of data-centric AI (DCAI), which advocates a fundamental shift from model advancements to ensuring data quality and reliability. Although our community has continuously invested efforts into enhancing data in different aspects, they are often isolated initiatives on specific tasks. To facilitate the collective initiative in our community and push forward DCAI, we draw a big picture and bring together three general missions: training data development, evaluation data development, and data maintenance. We provide a top-level discussion on representative DCAI tasks and share perspectives. Finally, we list open challenges to motivate future exploration.","link":"http://arxiv.org/abs/2301.04819v1","created":"2023-01-12","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Data-centric AI: Perspectives and Challenges The role of data in building AI systems has recently been significantly magnified by the emerging concept of data-centric AI (DCAI), which advocates a fundamental shift from model advancements to ensuring data quality and reliability. Although our community has continuously invested efforts into enhancing data in different aspects, they are often isolated initiatives on specific tasks. To facilitate the collective initiative in our community and push forward DCAI, we draw a big picture and bring together three general missions: training data development, evaluation data development, and data maintenance. We provide a top-level discussion on representative DCAI tasks and share perspectives. Finally, we list open challenges to motivate future exploration.","classes":{"dataset":0.2168916017}}
{"title":"QoS Based Contract Design for Profit Maximization in IoT-Enabled Data Markets","description":"The massive deployment of Internet of Things (IoT) devices, including sensors and actuators, is ushering in smart and connected communities of the future. The massive deployment of Internet of Things (IoT) devices, including sensors and actuators, is ushering in smart and connected communities of the future. The availability of real-time and high-quality sensor data is crucial for various IoT applications, particularly in healthcare, energy, transportation, etc. However, data collection may have to be outsourced to external service providers (SPs) due to cost considerations or lack of specialized equipment. Hence, the data market plays a critical role in such scenarios where SPs have different quality levels of available data, and IoT users have different application-specific data needs. The pairing between data available to the SP and users in the data market requires an effective mechanism design that considers the SPs' profitability and the quality-of-service (QoS) needs of the users. We develop a generic framework to analyze and enable such interactions efficiently, leveraging tools from contract theory and mechanism design theory. It can enable and empower emerging data sharing paradigms such as Sensing-as-a-Service (SaaS). The contract design creates a pricing structure for on-demand sensing data for IoT users. By considering a continuum of user types, we capture a diverse range of application requirements and propose optimal pricing and allocation rules that ensure QoS provisioning and maximum profitability for the SP. Furthermore, we provide analytical solutions for fixed distributions of user types to analyze the developed approach. For comparison, we consider the benchmark case assuming complete information of the user types and obtain optimal contract solutions. Finally, a case study is presented to demonstrate the efficacy of the proposed contract design framework.","link":"http://arxiv.org/abs/2301.04691v1","created":"2023-01-11","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"QoS Based Contract Design for Profit Maximization in IoT-Enabled Data Markets The massive deployment of Internet of Things (IoT) devices, including sensors and actuators, is ushering in smart and connected communities of the future. The massive deployment of Internet of Things (IoT) devices, including sensors and actuators, is ushering in smart and connected communities of the future. The availability of real-time and high-quality sensor data is crucial for various IoT applications, particularly in healthcare, energy, transportation, etc. However, data collection may have to be outsourced to external service providers (SPs) due to cost considerations or lack of specialized equipment. Hence, the data market plays a critical role in such scenarios where SPs have different quality levels of available data, and IoT users have different application-specific data needs. The pairing between data available to the SP and users in the data market requires an effective mechanism design that considers the SPs' profitability and the quality-of-service (QoS) needs of the users. We develop a generic framework to analyze and enable such interactions efficiently, leveraging tools from contract theory and mechanism design theory. It can enable and empower emerging data sharing paradigms such as Sensing-as-a-Service (SaaS). The contract design creates a pricing structure for on-demand sensing data for IoT users. By considering a continuum of user types, we capture a diverse range of application requirements and propose optimal pricing and allocation rules that ensure QoS provisioning and maximum profitability for the SP. Furthermore, we provide analytical solutions for fixed distributions of user types to analyze the developed approach. For comparison, we consider the benchmark case assuming complete information of the user types and obtain optimal contract solutions. Finally, a case study is presented to demonstrate the efficacy of the proposed contract design framework.","classes":{"dataset":0.0298652854}}
{"title":"Learning to Exploit Temporal Structure for Biomedical Vision-Language Processing","description":"Self-supervised learning in vision-language processing exploits semantic alignment between imaging and text modalities. Prior work in biomedical VLP has mostly relied on the alignment of single image and report pairs even though clinical notes commonly refer to prior images. This does not only introduce poor alignment between the modalities but also a missed opportunity to exploit rich self-supervision through existing temporal content in the data. In this work, we explicitly account for prior images and reports when available during both training and fine-tuning. Our approach, named BioViL-T, uses a CNN-Transformer hybrid multi-image encoder trained jointly with a text model. It is designed to be versatile to arising challenges such as pose variations and missing input images across time. The resulting model excels on downstream tasks both in single- and multi-image setups, achieving state-of-the-art performance on (I) progression classification, (II) phrase grounding, and (III) report generation, whilst offering consistent improvements on disease classification and sentence-similarity tasks. We release a novel multi-modal temporal benchmark dataset, MS-CXR-T, to quantify the quality of vision-language representations in terms of temporal semantics. Our experimental results show the advantages of incorporating prior images and reports to make most use of the data.","link":"http://arxiv.org/abs/2301.04558v1","created":"2023-01-11","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Learning to Exploit Temporal Structure for Biomedical Vision-Language Processing Self-supervised learning in vision-language processing exploits semantic alignment between imaging and text modalities. Prior work in biomedical VLP has mostly relied on the alignment of single image and report pairs even though clinical notes commonly refer to prior images. This does not only introduce poor alignment between the modalities but also a missed opportunity to exploit rich self-supervision through existing temporal content in the data. In this work, we explicitly account for prior images and reports when available during both training and fine-tuning. Our approach, named BioViL-T, uses a CNN-Transformer hybrid multi-image encoder trained jointly with a text model. It is designed to be versatile to arising challenges such as pose variations and missing input images across time. The resulting model excels on downstream tasks both in single- and multi-image setups, achieving state-of-the-art performance on (I) progression classification, (II) phrase grounding, and (III) report generation, whilst offering consistent improvements on disease classification and sentence-similarity tasks. We release a novel multi-modal temporal benchmark dataset, MS-CXR-T, to quantify the quality of vision-language representations in terms of temporal semantics. Our experimental results show the advantages of incorporating prior images and reports to make most use of the data.","classes":{"dataset":0.1582448632}}
{"title":"GPT as Knowledge Worker: A Zero-Shot Evaluation of (AI)CPA Capabilities","description":"The global economy is increasingly dependent on knowledge workers to meet the needs of public and private organizations. While there is no single definition of knowledge work, organizations and industry groups still attempt to measure individuals' capability to engage in it. The most comprehensive assessment of capability readiness for professional knowledge workers is the Uniform CPA Examination developed by the American Institute of Certified Public Accountants (AICPA). In this paper, we experimentally evaluate OpenAI's `text-davinci-003` and prior versions of GPT on both a sample Regulation (REG) exam and an assessment of over 200 multiple-choice questions based on the AICPA Blueprints for legal, financial, accounting, technology, and ethical tasks. First, we find that `text-davinci-003` achieves a correct rate of 14.4% on a sample REG exam section, significantly underperforming human capabilities on quantitative reasoning in zero-shot prompts. Second, `text-davinci-003` appears to be approaching human-level performance on the Remembering & Understanding and Application skill levels in the Exam absent calculation. For best prompt and parameters, the model answers 57.6% of questions correctly, significantly better than the 25% guessing rate, and its top two answers are correct 82.1% of the time, indicating strong non-entailment. Finally, we find that recent generations of GPT-3 demonstrate material improvements on this assessment, rising from 30% for `text-davinci-001` to 57% for `text-davinci-003`. These findings strongly suggest that large language models have the potential to transform the quality and efficiency of future knowledge work.","link":"http://arxiv.org/abs/2301.04408v1","created":"2023-01-11","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"GPT as Knowledge Worker: A Zero-Shot Evaluation of (AI)CPA Capabilities The global economy is increasingly dependent on knowledge workers to meet the needs of public and private organizations. While there is no single definition of knowledge work, organizations and industry groups still attempt to measure individuals' capability to engage in it. The most comprehensive assessment of capability readiness for professional knowledge workers is the Uniform CPA Examination developed by the American Institute of Certified Public Accountants (AICPA). In this paper, we experimentally evaluate OpenAI's `text-davinci-003` and prior versions of GPT on both a sample Regulation (REG) exam and an assessment of over 200 multiple-choice questions based on the AICPA Blueprints for legal, financial, accounting, technology, and ethical tasks. First, we find that `text-davinci-003` achieves a correct rate of 14.4% on a sample REG exam section, significantly underperforming human capabilities on quantitative reasoning in zero-shot prompts. Second, `text-davinci-003` appears to be approaching human-level performance on the Remembering & Understanding and Application skill levels in the Exam absent calculation. For best prompt and parameters, the model answers 57.6% of questions correctly, significantly better than the 25% guessing rate, and its top two answers are correct 82.1% of the time, indicating strong non-entailment. Finally, we find that recent generations of GPT-3 demonstrate material improvements on this assessment, rising from 30% for `text-davinci-001` to 57% for `text-davinci-003`. These findings strongly suggest that large language models have the potential to transform the quality and efficiency of future knowledge work.","classes":{"dataset":0.1827892065}}
{"title":"Application of machine learning to gas flaring","description":"Currently in the petroleum industry, operators often flare the produced gas instead of commodifying it. The flaring magnitudes are large in some states, which constitute problems with energy waste and CO2 emissions. In North Dakota, operators are required to estimate and report the volume flared. The questions are, how good is the quality of this reporting, and what insights can be drawn from it? Apart from the company-reported statistics, which are available from the North Dakota Industrial Commission (NDIC), flared volumes can be estimated via satellite remote sensing, serving as an unbiased benchmark. Since interpretation of the Landsat 8 imagery is hindered by artifacts due to glow, the estimated volumes based on the Visible Infrared Imaging Radiometer Suite (VIIRS) are used. Reverse geocoding is performed for comparing and contrasting the NDIC and VIIRS data at different levels, such as county and oilfield. With all the data gathered and preprocessed, Bayesian learning implemented by MCMC methods is performed to address three problems: county level model development, flaring time series analytics, and distribution estimation. First, there is heterogeneity among the different counties, in the associations between the NDIC and VIIRS volumes. In light of such, models are developed for each county by exploiting hierarchical models. Second, the flaring time series, albeit noisy, contains information regarding trends and patterns, which provide some insights into operator approaches. Gaussian processes are found to be effective in many different pattern recognition scenarios. Third, distributional insights are obtained through unsupervised learning. The negative binomial and GMMs are found to effectively describe the oilfield flare count and flared volume distributions, respectively. Finally, a nearest-neighbor-based approach for operator level monitoring and analytics is introduced.","link":"http://arxiv.org/abs/2301.04141v1","created":"2023-01-11","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Application of machine learning to gas flaring Currently in the petroleum industry, operators often flare the produced gas instead of commodifying it. The flaring magnitudes are large in some states, which constitute problems with energy waste and CO2 emissions. In North Dakota, operators are required to estimate and report the volume flared. The questions are, how good is the quality of this reporting, and what insights can be drawn from it? Apart from the company-reported statistics, which are available from the North Dakota Industrial Commission (NDIC), flared volumes can be estimated via satellite remote sensing, serving as an unbiased benchmark. Since interpretation of the Landsat 8 imagery is hindered by artifacts due to glow, the estimated volumes based on the Visible Infrared Imaging Radiometer Suite (VIIRS) are used. Reverse geocoding is performed for comparing and contrasting the NDIC and VIIRS data at different levels, such as county and oilfield. With all the data gathered and preprocessed, Bayesian learning implemented by MCMC methods is performed to address three problems: county level model development, flaring time series analytics, and distribution estimation. First, there is heterogeneity among the different counties, in the associations between the NDIC and VIIRS volumes. In light of such, models are developed for each county by exploiting hierarchical models. Second, the flaring time series, albeit noisy, contains information regarding trends and patterns, which provide some insights into operator approaches. Gaussian processes are found to be effective in many different pattern recognition scenarios. Third, distributional insights are obtained through unsupervised learning. The negative binomial and GMMs are found to effectively describe the oilfield flare count and flared volume distributions, respectively. Finally, a nearest-neighbor-based approach for operator level monitoring and analytics is introduced.","classes":{"dataset":0.3543471098}}
{"title":"Pixelated Reconstruction of Foreground Density and Background Surface Brightness in Gravitational Lensing Systems using Recurrent Inference Machines","description":"Modeling strong gravitational lenses in order to quantify the distortions in the images of background sources and to reconstruct the mass density in the foreground lenses has been a difficult computational challenge. As the quality of gravitational lens images increases, the task of fully exploiting the information they contain becomes computationally and algorithmically more difficult. In this work, we use a neural network based on the Recurrent Inference Machine (RIM) to simultaneously reconstruct an undistorted image of the background source and the lens mass density distribution as pixelated maps. The method iteratively reconstructs the model parameters (the image of the source and a pixelated density map) by learning the process of optimizing the likelihood given the data using the physical model (a ray-tracing simulation), regularized by a prior implicitly learned by the neural network through its training data. When compared to more traditional parametric models, the proposed method is significantly more expressive and can reconstruct complex mass distributions, which we demonstrate by using realistic lensing galaxies taken from the IllustrisTNG cosmological hydrodynamic simulation.","link":"http://arxiv.org/abs/2301.04168v1","created":"2023-01-10","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Pixelated Reconstruction of Foreground Density and Background Surface Brightness in Gravitational Lensing Systems using Recurrent Inference Machines Modeling strong gravitational lenses in order to quantify the distortions in the images of background sources and to reconstruct the mass density in the foreground lenses has been a difficult computational challenge. As the quality of gravitational lens images increases, the task of fully exploiting the information they contain becomes computationally and algorithmically more difficult. In this work, we use a neural network based on the Recurrent Inference Machine (RIM) to simultaneously reconstruct an undistorted image of the background source and the lens mass density distribution as pixelated maps. The method iteratively reconstructs the model parameters (the image of the source and a pixelated density map) by learning the process of optimizing the likelihood given the data using the physical model (a ray-tracing simulation), regularized by a prior implicitly learned by the neural network through its training data. When compared to more traditional parametric models, the proposed method is significantly more expressive and can reconstruct complex mass distributions, which we demonstrate by using realistic lensing galaxies taken from the IllustrisTNG cosmological hydrodynamic simulation.","classes":{"dataset":0.2030499279}}
{"title":"Functional observability and subspace reconstruction in nonlinear systems","description":"Time-series analysis is fundamental for modeling and predicting dynamical behaviors from time-ordered data, with applications in many disciplines such as physics, biology, finance, and engineering. Measured time-series data, however, are often low dimensional or even univariate, thus requiring embedding methods to reconstruct the original system's state space. The observability of a system establishes fundamental conditions under which such reconstruction is possible. However, complete observability is too restrictive in applications where reconstructing the entire state space is not necessary and only a specific subspace is relevant. Here, we establish the theoretic condition to reconstruct a nonlinear functional of state variables from measurement processes, generalizing the concept of functional observability to nonlinear systems. When the functional observability condition holds, we show how to construct a map from the embedding space to the desired functional of state variables, characterizing the quality of such reconstruction. The theoretical results are then illustrated numerically using chaotic systems with contrasting observability properties. By exploring the presence of functionally unobservable regions in embedded attractors, we also apply our theory for the early warning of seizure-like events in simulated and empirical data. The studies demonstrate that the proposed functional observability condition can be assessed a priori to guide time-series analysis and experimental design for the dynamical characterization of complex systems.","link":"http://arxiv.org/abs/2301.04108v1","created":"2023-01-10","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Functional observability and subspace reconstruction in nonlinear systems Time-series analysis is fundamental for modeling and predicting dynamical behaviors from time-ordered data, with applications in many disciplines such as physics, biology, finance, and engineering. Measured time-series data, however, are often low dimensional or even univariate, thus requiring embedding methods to reconstruct the original system's state space. The observability of a system establishes fundamental conditions under which such reconstruction is possible. However, complete observability is too restrictive in applications where reconstructing the entire state space is not necessary and only a specific subspace is relevant. Here, we establish the theoretic condition to reconstruct a nonlinear functional of state variables from measurement processes, generalizing the concept of functional observability to nonlinear systems. When the functional observability condition holds, we show how to construct a map from the embedding space to the desired functional of state variables, characterizing the quality of such reconstruction. The theoretical results are then illustrated numerically using chaotic systems with contrasting observability properties. By exploring the presence of functionally unobservable regions in embedded attractors, we also apply our theory for the early warning of seizure-like events in simulated and empirical data. The studies demonstrate that the proposed functional observability condition can be assessed a priori to guide time-series analysis and experimental design for the dynamical characterization of complex systems.","classes":{"dataset":0.431333214}}
{"title":"The Thousand-Pulsar-Array programme on MeerKAT -- VIII. The subpulse modulation of 1198 pulsars","description":"We report on the subpulse modulation properties of 1198 pulsars using the Thousand-Pulsar-Array programme on MeerKAT. About 35% of the analysed pulsars exhibit drifting subpulses which are more pronounced towards the deathline, consistent with previous studies. We estimate that this common phenomenon is detectable in 60% of the overall pulsar population if high quality data were available for all. This large study reveals the evolution of drifting subpulses across the pulsar population in unprecedented detail. In particular, we find that the modulation period $P_3$ follows a V-shaped evolution with respect to the characteristic age $\\tau_c$, such that the smallest $P_3$ values, corresponding to the Nyquist period $P_3>\\sim2$, are found at $\\tau_c>\\sim10^{7.5}$ yr. The V-shaped evolution can be interpreted and reproduced if young pulsars possess aliased fast intrinsic $P_3$, which monotonically increase, ultimately achieving a slow unaliased $P_3$. Enhancement of irregularities in intrinsic subpulse modulation by aliasing in small $\\tau_c$ pulsars would explain their observed less well defined $P_3$'s and weaker spectral features. Modelling these results as rotating subbeams, their circulation must slow down as the pulsar evolves. This is the opposite to that expected if circulation is driven by ExB drift. This can be resolved if the observed $P_3$ periodicity is due to a beat between an ExB system and the pulsar period. As a by-product, we identify the correct periods and spin-down rates for 12 pulsars, for which harmonically related values were reported in the literature.","link":"http://arxiv.org/abs/2301.04067v1","created":"2023-01-10","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"The Thousand-Pulsar-Array programme on MeerKAT -- VIII. The subpulse modulation of 1198 pulsars We report on the subpulse modulation properties of 1198 pulsars using the Thousand-Pulsar-Array programme on MeerKAT. About 35% of the analysed pulsars exhibit drifting subpulses which are more pronounced towards the deathline, consistent with previous studies. We estimate that this common phenomenon is detectable in 60% of the overall pulsar population if high quality data were available for all. This large study reveals the evolution of drifting subpulses across the pulsar population in unprecedented detail. In particular, we find that the modulation period $P_3$ follows a V-shaped evolution with respect to the characteristic age $\\tau_c$, such that the smallest $P_3$ values, corresponding to the Nyquist period $P_3>\\sim2$, are found at $\\tau_c>\\sim10^{7.5}$ yr. The V-shaped evolution can be interpreted and reproduced if young pulsars possess aliased fast intrinsic $P_3$, which monotonically increase, ultimately achieving a slow unaliased $P_3$. Enhancement of irregularities in intrinsic subpulse modulation by aliasing in small $\\tau_c$ pulsars would explain their observed less well defined $P_3$'s and weaker spectral features. Modelling these results as rotating subbeams, their circulation must slow down as the pulsar evolves. This is the opposite to that expected if circulation is driven by ExB drift. This can be resolved if the observed $P_3$ periodicity is due to a beat between an ExB system and the pulsar period. As a by-product, we identify the correct periods and spin-down rates for 12 pulsars, for which harmonically related values were reported in the literature.","classes":{"dataset":0.1380276531}}
{"title":"Actor-Director-Critic: A Novel Deep Reinforcement Learning Framework","description":"In this paper, we propose actor-director-critic, a new framework for deep reinforcement learning. Compared with the actor-critic framework, the director role is added, and action classification and action evaluation are applied simultaneously to improve the decision-making performance of the agent. Firstly, the actions of the agent are divided into high quality actions and low quality actions according to the rewards returned from the environment. Then, the director network is trained to have the ability to discriminate high and low quality actions and guide the actor network to reduce the repetitive exploration of low quality actions in the early stage of training. In addition, we propose an improved double estimator method to better solve the problem of overestimation in the field of reinforcement learning. For the two critic networks used, we design two target critic networks for each critic network instead of one. In this way, the target value of each critic network can be calculated by taking the average of the outputs of the two target critic networks, which is more stable and accurate than using only one target critic network to obtain the target value. In order to verify the performance of the actor-director-critic framework and the improved double estimator method, we applied them to the TD3 algorithm to improve the TD3 algorithm. Then, we carried out experiments in multiple environments in MuJoCo and compared the experimental data before and after the algorithm improvement. The final experimental results show that the improved algorithm can achieve faster convergence speed and higher total return.","link":"http://arxiv.org/abs/2301.03887v1","created":"2023-01-10","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Actor-Director-Critic: A Novel Deep Reinforcement Learning Framework In this paper, we propose actor-director-critic, a new framework for deep reinforcement learning. Compared with the actor-critic framework, the director role is added, and action classification and action evaluation are applied simultaneously to improve the decision-making performance of the agent. Firstly, the actions of the agent are divided into high quality actions and low quality actions according to the rewards returned from the environment. Then, the director network is trained to have the ability to discriminate high and low quality actions and guide the actor network to reduce the repetitive exploration of low quality actions in the early stage of training. In addition, we propose an improved double estimator method to better solve the problem of overestimation in the field of reinforcement learning. For the two critic networks used, we design two target critic networks for each critic network instead of one. In this way, the target value of each critic network can be calculated by taking the average of the outputs of the two target critic networks, which is more stable and accurate than using only one target critic network to obtain the target value. In order to verify the performance of the actor-director-critic framework and the improved double estimator method, we applied them to the TD3 algorithm to improve the TD3 algorithm. Then, we carried out experiments in multiple environments in MuJoCo and compared the experimental data before and after the algorithm improvement. The final experimental results show that the improved algorithm can achieve faster convergence speed and higher total return.","classes":{"dataset":0.2543659508}}
{"title":"Dataset of Fluorescence Spectra and Chemical Parameters of Olive Oils","description":"This dataset encompasses fluorescence spectra and chemical parameters of 24 olive oil samples from the 2019-2020 harvest provided by the producer Conde de Benalua, Granada, Spain. The oils are characterized by different qualities: 10 extra virgin olive oil (EVOO), 8 virgin olive oil (VOO), and 6 lampante olive oil (LOO) samples. For each sample, the dataset includes fluorescence spectra obtained with two excitation wavelengths, oil quality, and five chemical parameters necessary for the quality assessment of olive oil. The fluorescence spectra were obtained by exciting the samples at 365 nm and 395 nm under identical conditions. The dataset includes the values of the following chemical parameters for each olive oil sample: acidity, peroxide value, K270, K232, ethyl esters, and the quality of the samples (EVOO, VOO, or LOO). The dataset offers a unique possibility for researchers in food technology to develop machine learning models based on fluorescence data for the quality assessment of olive oil due to the availability of both spectroscopic and chemical data. The dataset can be used, for example, to predict one or multiple chemical parameters or to classify samples based on their quality from fluorescence spectra.","link":"http://arxiv.org/abs/2301.04471v1","created":"2023-01-10","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Dataset of Fluorescence Spectra and Chemical Parameters of Olive Oils This dataset encompasses fluorescence spectra and chemical parameters of 24 olive oil samples from the 2019-2020 harvest provided by the producer Conde de Benalua, Granada, Spain. The oils are characterized by different qualities: 10 extra virgin olive oil (EVOO), 8 virgin olive oil (VOO), and 6 lampante olive oil (LOO) samples. For each sample, the dataset includes fluorescence spectra obtained with two excitation wavelengths, oil quality, and five chemical parameters necessary for the quality assessment of olive oil. The fluorescence spectra were obtained by exciting the samples at 365 nm and 395 nm under identical conditions. The dataset includes the values of the following chemical parameters for each olive oil sample: acidity, peroxide value, K270, K232, ethyl esters, and the quality of the samples (EVOO, VOO, or LOO). The dataset offers a unique possibility for researchers in food technology to develop machine learning models based on fluorescence data for the quality assessment of olive oil due to the availability of both spectroscopic and chemical data. The dataset can be used, for example, to predict one or multiple chemical parameters or to classify samples based on their quality from fluorescence spectra.","classes":{"dataset":0.2987174988}}
{"title":"Evaluating the Performance of Low-Cost PM2.5 Sensors in Mobile Settings","description":"Low-cost sensors (LCS) for measuring air pollution are increasingly being deployed in mobile applications but questions concerning the quality of the measurements remain unanswered. For example, what is the best way to correct LCS data in a mobile setting? Which factors most significantly contribute to differences between mobile LCS data and higher-quality instruments? Can data from LCS be used to identify hotspots and generate generalizable pollutant concentration maps? To help address these questions we deployed low-cost PM2.5 sensors (Alphasense OPC-N3) and a research-grade instrument (TSI DustTrak) in a mobile laboratory in Boston, MA, USA. We first collocated these instruments with stationary PM2.5 reference monitors at nearby regulatory sites. Next, using the reference measurements, we developed different models to correct the OPC-N3 and DustTrak measurements, and then transferred the corrections to the mobile setting. We observed that more complex correction models appeared to perform better than simpler models in the stationary setting; however, when transferred to the mobile setting, corrected OPC-N3 measurements agreed less well with corrected DustTrak data. In general, corrections developed using minute-level collocation measurements transferred better to the mobile setting than corrections developed using hourly-averaged data. Mobile laboratory speed, OPC-N3 orientation relative to the direction of travel, date, hour-of-the-day, and road class together explain a small but significant amount of variation between corrected OPC-N3 and DustTrak measurements during the mobile deployment. Persistent hotspots identified by the OPC-N3s agreed with those identified by the DustTrak. Similarly, maps of PM2.5 distribution produced from the mobile corrected OPC-N3 and DustTrak measurements agreed well.","link":"http://arxiv.org/abs/2301.03847v1","created":"2023-01-10","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Evaluating the Performance of Low-Cost PM2.5 Sensors in Mobile Settings Low-cost sensors (LCS) for measuring air pollution are increasingly being deployed in mobile applications but questions concerning the quality of the measurements remain unanswered. For example, what is the best way to correct LCS data in a mobile setting? Which factors most significantly contribute to differences between mobile LCS data and higher-quality instruments? Can data from LCS be used to identify hotspots and generate generalizable pollutant concentration maps? To help address these questions we deployed low-cost PM2.5 sensors (Alphasense OPC-N3) and a research-grade instrument (TSI DustTrak) in a mobile laboratory in Boston, MA, USA. We first collocated these instruments with stationary PM2.5 reference monitors at nearby regulatory sites. Next, using the reference measurements, we developed different models to correct the OPC-N3 and DustTrak measurements, and then transferred the corrections to the mobile setting. We observed that more complex correction models appeared to perform better than simpler models in the stationary setting; however, when transferred to the mobile setting, corrected OPC-N3 measurements agreed less well with corrected DustTrak data. In general, corrections developed using minute-level collocation measurements transferred better to the mobile setting than corrections developed using hourly-averaged data. Mobile laboratory speed, OPC-N3 orientation relative to the direction of travel, date, hour-of-the-day, and road class together explain a small but significant amount of variation between corrected OPC-N3 and DustTrak measurements during the mobile deployment. Persistent hotspots identified by the OPC-N3s agreed with those identified by the DustTrak. Similarly, maps of PM2.5 distribution produced from the mobile corrected OPC-N3 and DustTrak measurements agreed well.","classes":{"dataset":0.0659626722}}
{"title":"High-resolution Power Doppler Using Null Subtraction Imaging","description":"To improve the spatial resolution of power Doppler (PD) imaging, we explored null subtraction imaging (NSI) as an alternative beamforming technique to delay-and-sum (DAS). NSI is a nonlinear beamforming approach that uses three different apodizations on receive and incoherently sums the beamformed envelopes. NSI uses a null in the beam pattern to improve the lateral resolution, which we apply here for improving PD spatial resolution both with and without contrast microbubbles. In this study, we used NSI with singular value decomposition (SVD)-based clutter filtering and noise equalization to generate high-resolution PD images. An element sensitivity correction scheme was also performed to further improve the image quality of PD images using NSI. First, a microbubble trace experiment was performed to quantitatively evaluate the performance of NSI based PD. Then, both contrast-enhanced and contrast free ultrasound data were collected from a rat brain. Higher spatial resolution and image quality were observed from the NSI-based PD microvessel images compared to microvessel images generated by traditional DAS-based beamforming.","link":"http://arxiv.org/abs/2301.03719v1","created":"2023-01-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"High-resolution Power Doppler Using Null Subtraction Imaging To improve the spatial resolution of power Doppler (PD) imaging, we explored null subtraction imaging (NSI) as an alternative beamforming technique to delay-and-sum (DAS). NSI is a nonlinear beamforming approach that uses three different apodizations on receive and incoherently sums the beamformed envelopes. NSI uses a null in the beam pattern to improve the lateral resolution, which we apply here for improving PD spatial resolution both with and without contrast microbubbles. In this study, we used NSI with singular value decomposition (SVD)-based clutter filtering and noise equalization to generate high-resolution PD images. An element sensitivity correction scheme was also performed to further improve the image quality of PD images using NSI. First, a microbubble trace experiment was performed to quantitatively evaluate the performance of NSI based PD. Then, both contrast-enhanced and contrast free ultrasound data were collected from a rat brain. Higher spatial resolution and image quality were observed from the NSI-based PD microvessel images compared to microvessel images generated by traditional DAS-based beamforming.","classes":{"dataset":0.1304215491}}
{"title":"SatNetOps: Toward Multi-Layer Networking for Satellite Network Operations","description":"Recent advancements in low-Earth-orbit (LEO) satellites aim to bring resilience, ubiquitous, and high-quality service to future Internet infrastructure. However, the soaring number of space assets, increasing dynamics of LEO satellites and expanding dimensions of network threats call for an enhanced approach to efficient satellite operations. To address these pressing challenges, we propose an approach for satellite network operations based on multi-layer satellite networking (MLSN), called \"SatNetOps\". Two SatNetOps schemes are proposed, referred to as LEO-LEO MLSN (LLM) and GEO-LEO MLSN (GLM). The performance of the proposed schemes is evaluated in 24-hr satellite scenarios with typical payload setups in simulations, where the key metrics such as latency and reliability are discussed with the consideration of the Consultative Committee for Space Data Systems (CCSDS) standard-compliant telemetry and telecommand missions. Although the SatNetOps approach is promising, we analyze the factors affecting the performance of the LLM and GLM schemes. The discussions on the results and conclusive remarks are made in the end.","link":"http://arxiv.org/abs/2301.03641v1","created":"2023-01-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"SatNetOps: Toward Multi-Layer Networking for Satellite Network Operations Recent advancements in low-Earth-orbit (LEO) satellites aim to bring resilience, ubiquitous, and high-quality service to future Internet infrastructure. However, the soaring number of space assets, increasing dynamics of LEO satellites and expanding dimensions of network threats call for an enhanced approach to efficient satellite operations. To address these pressing challenges, we propose an approach for satellite network operations based on multi-layer satellite networking (MLSN), called \"SatNetOps\". Two SatNetOps schemes are proposed, referred to as LEO-LEO MLSN (LLM) and GEO-LEO MLSN (GLM). The performance of the proposed schemes is evaluated in 24-hr satellite scenarios with typical payload setups in simulations, where the key metrics such as latency and reliability are discussed with the consideration of the Consultative Committee for Space Data Systems (CCSDS) standard-compliant telemetry and telecommand missions. Although the SatNetOps approach is promising, we analyze the factors affecting the performance of the LLM and GLM schemes. The discussions on the results and conclusive remarks are made in the end.","classes":{"dataset":0.5494478941}}
{"title":"Latent Autoregressive Source Separation","description":"Autoregressive models have achieved impressive results over a wide range of domains in terms of generation quality and downstream task performance. In the continuous domain, a key factor behind this success is the usage of quantized latent spaces (e.g., obtained via VQ-VAE autoencoders), which allow for dimensionality reduction and faster inference times. However, using existing pre-trained models to perform new non-trivial tasks is difficult since it requires additional fine-tuning or extensive training to elicit prompting. This paper introduces LASS as a way to perform vector-quantized Latent Autoregressive Source Separation (i.e., de-mixing an input signal into its constituent sources) without requiring additional gradient-based optimization or modifications of existing models. Our separation method relies on the Bayesian formulation in which the autoregressive models are the priors, and a discrete (non-parametric) likelihood function is constructed by performing frequency counts over latent sums of addend tokens. We test our method on images and audio with several sampling strategies (e.g., ancestral, beam search) showing competitive results with existing approaches in terms of separation quality while offering at the same time significant speedups in terms of inference time and scalability to higher dimensional data.","link":"http://arxiv.org/abs/2301.08562v1","created":"2023-01-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Latent Autoregressive Source Separation Autoregressive models have achieved impressive results over a wide range of domains in terms of generation quality and downstream task performance. In the continuous domain, a key factor behind this success is the usage of quantized latent spaces (e.g., obtained via VQ-VAE autoencoders), which allow for dimensionality reduction and faster inference times. However, using existing pre-trained models to perform new non-trivial tasks is difficult since it requires additional fine-tuning or extensive training to elicit prompting. This paper introduces LASS as a way to perform vector-quantized Latent Autoregressive Source Separation (i.e., de-mixing an input signal into its constituent sources) without requiring additional gradient-based optimization or modifications of existing models. Our separation method relies on the Bayesian formulation in which the autoregressive models are the priors, and a discrete (non-parametric) likelihood function is constructed by performing frequency counts over latent sums of addend tokens. We test our method on images and audio with several sampling strategies (e.g., ancestral, beam search) showing competitive results with existing approaches in terms of separation quality while offering at the same time significant speedups in terms of inference time and scalability to higher dimensional data.","classes":{"dataset":0.0463312827}}
{"title":"High-Resolution Cloud Removal with Multi-Modal and Multi-Resolution Data Fusion: A New Baseline and Benchmark","description":"In this paper, we introduce Planet-CR, a benchmark dataset for high-resolution cloud removal with multi-modal and multi-resolution data fusion. Planet-CR is the first public dataset for cloud removal to feature globally sampled high resolution optical observations, in combination with paired radar measurements as well as pixel-level land cover annotations. It provides solid basis for exhaustive evaluation in terms of generating visually pleasing textures and semantically meaningful structures. With this dataset, we consider the problem of cloud removal in high resolution optical remote sensing imagery by integrating multi-modal and multi-resolution information. Existing multi-modal data fusion based methods, which assume the image pairs are aligned pixel-to-pixel, are hence not appropriate for this problem. To this end, we design a new baseline named Align-CR to perform the low-resolution SAR image guided high-resolution optical image cloud removal. It implicitly aligns the multi-modal and multi-resolution data during the reconstruction process to promote the cloud removal performance. The experimental results demonstrate that the proposed Align-CR method gives the best performance in both visual recovery quality and semantic recovery quality. The project is available at https://github.com/zhu-xlab/Planet-CR, and hope this will inspire future research.","link":"http://arxiv.org/abs/2301.03432v1","created":"2023-01-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"High-Resolution Cloud Removal with Multi-Modal and Multi-Resolution Data Fusion: A New Baseline and Benchmark In this paper, we introduce Planet-CR, a benchmark dataset for high-resolution cloud removal with multi-modal and multi-resolution data fusion. Planet-CR is the first public dataset for cloud removal to feature globally sampled high resolution optical observations, in combination with paired radar measurements as well as pixel-level land cover annotations. It provides solid basis for exhaustive evaluation in terms of generating visually pleasing textures and semantically meaningful structures. With this dataset, we consider the problem of cloud removal in high resolution optical remote sensing imagery by integrating multi-modal and multi-resolution information. Existing multi-modal data fusion based methods, which assume the image pairs are aligned pixel-to-pixel, are hence not appropriate for this problem. To this end, we design a new baseline named Align-CR to perform the low-resolution SAR image guided high-resolution optical image cloud removal. It implicitly aligns the multi-modal and multi-resolution data during the reconstruction process to promote the cloud removal performance. The experimental results demonstrate that the proposed Align-CR method gives the best performance in both visual recovery quality and semantic recovery quality. The project is available at https://github.com/zhu-xlab/Planet-CR, and hope this will inspire future research.","classes":{"dataset":0.1994209141}}
{"title":"Utilising nanosecond sources in diffuse optical tomography","description":"Diffuse optical tomography (DOT) use near-infrared light for imaging optical properties of biological tissues. Time-domain DOT systems use pulsed lasers and measure time-varying temporal point spread function (TPSF), carrying information from both superficial and deep layers of imaged target. In this work, feasibility of nanosecond scale light pulses as sources for time-domain DOT is studied. Nanosecond sources enable using relatively robust measurement setups with standard analog-to-digital converter waveform digitizers, such as digital oscilloscopes. However, this type of systems have variations in source pulses and limited temporal sampling, that could limit their usage. In this work, these different aspects and possible limitations were studied with simulations and experiments.   Simulations showed that information carried by time-domain data of diffuse medium is on low frequencies. This enables usage of relatively slow response time measurement electronics, and image processing using Fourier-transformed time-domain data. Furthermore, the temporal sampling in measurements needs to be high enough to capture the TPSF, but this rate can be achieved with standard digital oscilloscopes. It was shown that, although variations in light pulses of nanosecond lasers are larger than those of picosecond sources, they do not affect significantly on image quality. In this work, a prototype time-domain DOT experimental system utilising a high-energy nanosecond laser was constructed. The system consisted of a nanosecond Nd-YAG laser combined with optical parametric oscillator for light input, and avalanche photodetector and high-bandwidth oscilloscope for TPSF measurements. The system was used in both absolute and difference imaging of two phantoms. The experiments verified that both absorbing and scattering objects can be reconstructed with time-domain DOT using a nanosecond laser.","link":"http://arxiv.org/abs/2301.03269v1","created":"2023-01-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Utilising nanosecond sources in diffuse optical tomography Diffuse optical tomography (DOT) use near-infrared light for imaging optical properties of biological tissues. Time-domain DOT systems use pulsed lasers and measure time-varying temporal point spread function (TPSF), carrying information from both superficial and deep layers of imaged target. In this work, feasibility of nanosecond scale light pulses as sources for time-domain DOT is studied. Nanosecond sources enable using relatively robust measurement setups with standard analog-to-digital converter waveform digitizers, such as digital oscilloscopes. However, this type of systems have variations in source pulses and limited temporal sampling, that could limit their usage. In this work, these different aspects and possible limitations were studied with simulations and experiments.   Simulations showed that information carried by time-domain data of diffuse medium is on low frequencies. This enables usage of relatively slow response time measurement electronics, and image processing using Fourier-transformed time-domain data. Furthermore, the temporal sampling in measurements needs to be high enough to capture the TPSF, but this rate can be achieved with standard digital oscilloscopes. It was shown that, although variations in light pulses of nanosecond lasers are larger than those of picosecond sources, they do not affect significantly on image quality. In this work, a prototype time-domain DOT experimental system utilising a high-energy nanosecond laser was constructed. The system consisted of a nanosecond Nd-YAG laser combined with optical parametric oscillator for light input, and avalanche photodetector and high-bandwidth oscilloscope for TPSF measurements. The system was used in both absolute and difference imaging of two phantoms. The experiments verified that both absorbing and scattering objects can be reconstructed with time-domain DOT using a nanosecond laser.","classes":{"dataset":0.2484627068}}
{"title":"Reservoir Prediction by Machine Learning Methods on The Well Data and Seismic Attributes for Complex Coastal Conditions","description":"The aim of this work was to predict the probability of the spread of rock formations with hydrocarbon-collecting properties in the studied coastal area using a stack of machine learning algorithms and data augmentation and modification methods. This research develops the direction of machine learning where training is conducted on well data and spatial attributes. Methods for overcoming the limitations of this direction are shown, two methods - augmentation and modification of the well data sample: Spindle and Revers-Calibration. Considering the difficulties for seismic data interpretation in coastal area conditions, the proposed approach is a tool which is able to work with the whole totality of geological and geophysical data, extract the knowledge from 159-dimensional space spatial attributes and make facies spreading prediction with acceptable quality - F1 measure for reservoir class 0.798 on average for evaluation of \"drilling\" results of different geological conditions. It was shown that consistent application of the proposed augmentation methods in the implemented technology stack improves the quality of reservoir prediction by a factor of 1.56 relative to the original dataset.","link":"http://arxiv.org/abs/2301.03216v1","created":"2023-01-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Reservoir Prediction by Machine Learning Methods on The Well Data and Seismic Attributes for Complex Coastal Conditions The aim of this work was to predict the probability of the spread of rock formations with hydrocarbon-collecting properties in the studied coastal area using a stack of machine learning algorithms and data augmentation and modification methods. This research develops the direction of machine learning where training is conducted on well data and spatial attributes. Methods for overcoming the limitations of this direction are shown, two methods - augmentation and modification of the well data sample: Spindle and Revers-Calibration. Considering the difficulties for seismic data interpretation in coastal area conditions, the proposed approach is a tool which is able to work with the whole totality of geological and geophysical data, extract the knowledge from 159-dimensional space spatial attributes and make facies spreading prediction with acceptable quality - F1 measure for reservoir class 0.798 on average for evaluation of \"drilling\" results of different geological conditions. It was shown that consistent application of the proposed augmentation methods in the implemented technology stack improves the quality of reservoir prediction by a factor of 1.56 relative to the original dataset.","classes":{"dataset":0.3580987751}}
{"title":"Negative Results of Fusing Code and Documentation for Learning to Accurately Identify Sensitive Source and Sink Methods An Application to the Android Framework for Data Leak Detection","description":"Apps on mobile phones manipulate all sorts of data, including sensitive data, leading to privacy-related concerns. Recent regulations like the European GDPR provide rules for the processing of personal and sensitive data, like that no such data may be leaked without the consent of the user.   Researchers have proposed sophisticated approaches to track sensitive data within mobile apps, all of which rely on specific lists of sensitive source and sink API methods. The data flow analysis results greatly depend on these lists' quality. Previous approaches either used incomplete hand-written lists that quickly became outdated or relied on machine learning. The latter, however, leads to numerous false positives, as we show.   This paper introduces CoDoC, a tool that aims to revive the machine-learning approach to precisely identify privacy-related source and sink API methods. In contrast to previous approaches, CoDoC uses deep learning techniques and combines the source code with the documentation of API methods. Firstly, we propose novel definitions that clarify the concepts of sensitive source and sink methods. Secondly, based on these definitions, we build a new ground truth of Android methods representing sensitive source, sink, and neither (i.e., no source or sink) methods that will be used to train our classifier.   We evaluate CoDoC and show that, on our validation dataset, it achieves a precision, recall, and F1 score of 91% in 10-fold cross-validation, outperforming the state-of-the-art SuSi when used on the same dataset. However, similarly to existing tools, we show that in the wild, i.e., with unseen data, CoDoC performs poorly and generates many false positive results. Our findings, together with time-tested results of previous approaches, suggest that machine-learning models for abstract concepts such as privacy fail in practice despite good lab results.","link":"http://arxiv.org/abs/2301.03207v2","created":"2023-01-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Negative Results of Fusing Code and Documentation for Learning to Accurately Identify Sensitive Source and Sink Methods An Application to the Android Framework for Data Leak Detection Apps on mobile phones manipulate all sorts of data, including sensitive data, leading to privacy-related concerns. Recent regulations like the European GDPR provide rules for the processing of personal and sensitive data, like that no such data may be leaked without the consent of the user.   Researchers have proposed sophisticated approaches to track sensitive data within mobile apps, all of which rely on specific lists of sensitive source and sink API methods. The data flow analysis results greatly depend on these lists' quality. Previous approaches either used incomplete hand-written lists that quickly became outdated or relied on machine learning. The latter, however, leads to numerous false positives, as we show.   This paper introduces CoDoC, a tool that aims to revive the machine-learning approach to precisely identify privacy-related source and sink API methods. In contrast to previous approaches, CoDoC uses deep learning techniques and combines the source code with the documentation of API methods. Firstly, we propose novel definitions that clarify the concepts of sensitive source and sink methods. Secondly, based on these definitions, we build a new ground truth of Android methods representing sensitive source, sink, and neither (i.e., no source or sink) methods that will be used to train our classifier.   We evaluate CoDoC and show that, on our validation dataset, it achieves a precision, recall, and F1 score of 91% in 10-fold cross-validation, outperforming the state-of-the-art SuSi when used on the same dataset. However, similarly to existing tools, we show that in the wild, i.e., with unseen data, CoDoC performs poorly and generates many false positive results. Our findings, together with time-tested results of previous approaches, suggest that machine-learning models for abstract concepts such as privacy fail in practice despite good lab results.","classes":{"dataset":0.1806848496}}
{"title":"Privacy-Preserving Record Linkage for Cardinality Counting","description":"Several applications require counting the number of distinct items in the data, which is known as the cardinality counting problem. Example applications include health applications such as rare disease patients counting for adequate awareness and funding, and counting the number of cases of a new disease for outbreak detection, marketing applications such as counting the visibility reached for a new product, and cybersecurity applications such as tracking the number of unique views of social media posts. The data needed for the counting is however often personal and sensitive, and need to be processed using privacy-preserving techniques. The quality of data in different databases, for example typos, errors and variations, poses additional challenges for accurate cardinality estimation. While privacy-preserving cardinality counting has gained much attention in the recent times and a few privacy-preserving algorithms have been developed for cardinality estimation, no work has so far been done on privacy-preserving cardinality counting using record linkage techniques with fuzzy matching and provable privacy guarantees. We propose a novel privacy-preserving record linkage algorithm using unsupervised clustering techniques to link and count the cardinality of individuals in multiple datasets without compromising their privacy or identity. In addition, existing Elbow methods to find the optimal number of clusters as the cardinality are far from accurate as they do not take into account the purity and completeness of generated clusters. We propose a novel method to find the optimal number of clusters in unsupervised learning. Our experimental results on real and synthetic datasets are highly promising in terms of significantly smaller error rate of less than 0.1 with a privacy budget {\\epsilon} = 1.0 compared to the state-of-the-art fuzzy matching and clustering method.","link":"http://arxiv.org/abs/2301.04000v1","created":"2023-01-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Privacy-Preserving Record Linkage for Cardinality Counting Several applications require counting the number of distinct items in the data, which is known as the cardinality counting problem. Example applications include health applications such as rare disease patients counting for adequate awareness and funding, and counting the number of cases of a new disease for outbreak detection, marketing applications such as counting the visibility reached for a new product, and cybersecurity applications such as tracking the number of unique views of social media posts. The data needed for the counting is however often personal and sensitive, and need to be processed using privacy-preserving techniques. The quality of data in different databases, for example typos, errors and variations, poses additional challenges for accurate cardinality estimation. While privacy-preserving cardinality counting has gained much attention in the recent times and a few privacy-preserving algorithms have been developed for cardinality estimation, no work has so far been done on privacy-preserving cardinality counting using record linkage techniques with fuzzy matching and provable privacy guarantees. We propose a novel privacy-preserving record linkage algorithm using unsupervised clustering techniques to link and count the cardinality of individuals in multiple datasets without compromising their privacy or identity. In addition, existing Elbow methods to find the optimal number of clusters as the cardinality are far from accurate as they do not take into account the purity and completeness of generated clusters. We propose a novel method to find the optimal number of clusters in unsupervised learning. Our experimental results on real and synthetic datasets are highly promising in terms of significantly smaller error rate of less than 0.1 with a privacy budget {\\epsilon} = 1.0 compared to the state-of-the-art fuzzy matching and clustering method.","classes":{"dataset":0.7175478339}}
{"title":"Scholar Ranking 2023: Ranking of Computer Science Departments Based on Faculty Citations","description":"Scholar Ranking 2023 is the second edition of U.S. Computer Science (CS) departments ranking based on faculty citation measures. Using Google Scholar, we gathered data about publication citations for 5,574 tenure-track faculty from 185 U.S. universities. For each faculty, we extracted their t10 index, defined as the number of citations received by their 10th highest cited paper. For each department, we calculated four quality metrics: median t10 (m10), the geometric mean of t10 (g10), and the number of well-cited faculty with t10 above 40% (c40) and 60% (c60) of the national average. We fitted a linear regression model using those four measures to match the 2022 U.S. News ranking scores of CS doctoral programs. The resulting model provides Scholar Ranking 2023, which can be found at https://chi.temple.edu/csranking.","link":"http://arxiv.org/abs/2301.03140v2","created":"2023-01-09","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Scholar Ranking 2023: Ranking of Computer Science Departments Based on Faculty Citations Scholar Ranking 2023 is the second edition of U.S. Computer Science (CS) departments ranking based on faculty citation measures. Using Google Scholar, we gathered data about publication citations for 5,574 tenure-track faculty from 185 U.S. universities. For each faculty, we extracted their t10 index, defined as the number of citations received by their 10th highest cited paper. For each department, we calculated four quality metrics: median t10 (m10), the geometric mean of t10 (g10), and the number of well-cited faculty with t10 above 40% (c40) and 60% (c60) of the national average. We fitted a linear regression model using those four measures to match the 2022 U.S. News ranking scores of CS doctoral programs. The resulting model provides Scholar Ranking 2023, which can be found at https://chi.temple.edu/csranking.","classes":{"dataset":0.2704642117}}
{"title":"Annealed Score-Based Diffusion Model for MR Motion Artifact Reduction","description":"Motion artifact reduction is one of the important research topics in MR imaging, as the motion artifact degrades image quality and makes diagnosis difficult. Recently, many deep learning approaches have been studied for motion artifact reduction. Unfortunately, most existing models are trained in a supervised manner, requiring paired motion-corrupted and motion-free images, or are based on a strict motion-corruption model, which limits their use for real-world situations. To address this issue, here we present an annealed score-based diffusion model for MRI motion artifact reduction. Specifically, we train a score-based model using only motion-free images, and then motion artifacts are removed by applying forward and reverse diffusion processes repeatedly to gradually impose a low-frequency data consistency. Experimental results verify that the proposed method successfully reduces both simulated and in vivo motion artifacts, outperforming the state-of-the-art deep learning methods.","link":"http://arxiv.org/abs/2301.03027v1","created":"2023-01-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Annealed Score-Based Diffusion Model for MR Motion Artifact Reduction Motion artifact reduction is one of the important research topics in MR imaging, as the motion artifact degrades image quality and makes diagnosis difficult. Recently, many deep learning approaches have been studied for motion artifact reduction. Unfortunately, most existing models are trained in a supervised manner, requiring paired motion-corrupted and motion-free images, or are based on a strict motion-corruption model, which limits their use for real-world situations. To address this issue, here we present an annealed score-based diffusion model for MRI motion artifact reduction. Specifically, we train a score-based model using only motion-free images, and then motion artifacts are removed by applying forward and reverse diffusion processes repeatedly to gradually impose a low-frequency data consistency. Experimental results verify that the proposed method successfully reduces both simulated and in vivo motion artifacts, outperforming the state-of-the-art deep learning methods.","classes":{"dataset":0.0161678921}}
{"title":"CameraPose: Weakly-Supervised Monocular 3D Human Pose Estimation by Leveraging In-the-wild 2D Annotations","description":"To improve the generalization of 3D human pose estimators, many existing deep learning based models focus on adding different augmentations to training poses. However, data augmentation techniques are limited to the \"seen\" pose combinations and hard to infer poses with rare \"unseen\" joint positions. To address this problem, we present CameraPose, a weakly-supervised framework for 3D human pose estimation from a single image, which can not only be applied on 2D-3D pose pairs but also on 2D alone annotations. By adding a camera parameter branch, any in-the-wild 2D annotations can be fed into our pipeline to boost the training diversity and the 3D poses can be implicitly learned by reprojecting back to 2D. Moreover, CameraPose introduces a refinement network module with confidence-guided loss to further improve the quality of noisy 2D keypoints extracted by 2D pose estimators. Experimental results demonstrate that the CameraPose brings in clear improvements on cross-scenario datasets. Notably, it outperforms the baseline method by 3mm on the most challenging dataset 3DPW. In addition, by combining our proposed refinement network module with existing 3D pose estimators, their performance can be improved in cross-scenario evaluation.","link":"http://arxiv.org/abs/2301.02979v1","created":"2023-01-08","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"CameraPose: Weakly-Supervised Monocular 3D Human Pose Estimation by Leveraging In-the-wild 2D Annotations To improve the generalization of 3D human pose estimators, many existing deep learning based models focus on adding different augmentations to training poses. However, data augmentation techniques are limited to the \"seen\" pose combinations and hard to infer poses with rare \"unseen\" joint positions. To address this problem, we present CameraPose, a weakly-supervised framework for 3D human pose estimation from a single image, which can not only be applied on 2D-3D pose pairs but also on 2D alone annotations. By adding a camera parameter branch, any in-the-wild 2D annotations can be fed into our pipeline to boost the training diversity and the 3D poses can be implicitly learned by reprojecting back to 2D. Moreover, CameraPose introduces a refinement network module with confidence-guided loss to further improve the quality of noisy 2D keypoints extracted by 2D pose estimators. Experimental results demonstrate that the CameraPose brings in clear improvements on cross-scenario datasets. Notably, it outperforms the baseline method by 3mm on the most challenging dataset 3DPW. In addition, by combining our proposed refinement network module with existing 3D pose estimators, their performance can be improved in cross-scenario evaluation.","classes":{"dataset":0.1574887335}}
{"title":"k-Means SubClustering: A Differentially Private Algorithm with Improved Clustering Quality","description":"In today's data-driven world, the sensitivity of information has been a significant concern. With this data and additional information on the person's background, one can easily infer an individual's private data. Many differentially private iterative algorithms have been proposed in interactive settings to protect an individual's privacy from these inference attacks. The existing approaches adapt the method to compute differentially private(DP) centroids by iterative Llyod's algorithm and perturbing the centroid with various DP mechanisms. These DP mechanisms do not guarantee convergence of differentially private iterative algorithms and degrade the quality of the cluster. Thus, in this work, we further extend the previous work on 'Differentially Private k-Means Clustering With Convergence Guarantee' by taking it as our baseline. The novelty of our approach is to sub-cluster the clusters and then select the centroid which has a higher probability of moving in the direction of the future centroid. At every Lloyd's step, the centroids are injected with the noise using the exponential DP mechanism. The results of the experiments indicate that our approach outperforms the current state-of-the-art method, i.e., the baseline algorithm, in terms of clustering quality while maintaining the same differential privacy requirements. The clustering quality significantly improved by 4.13 and 2.83 times than baseline for the Wine and Breast_Cancer dataset, respectively.","link":"http://arxiv.org/abs/2301.02896v1","created":"2023-01-07","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"k-Means SubClustering: A Differentially Private Algorithm with Improved Clustering Quality In today's data-driven world, the sensitivity of information has been a significant concern. With this data and additional information on the person's background, one can easily infer an individual's private data. Many differentially private iterative algorithms have been proposed in interactive settings to protect an individual's privacy from these inference attacks. The existing approaches adapt the method to compute differentially private(DP) centroids by iterative Llyod's algorithm and perturbing the centroid with various DP mechanisms. These DP mechanisms do not guarantee convergence of differentially private iterative algorithms and degrade the quality of the cluster. Thus, in this work, we further extend the previous work on 'Differentially Private k-Means Clustering With Convergence Guarantee' by taking it as our baseline. The novelty of our approach is to sub-cluster the clusters and then select the centroid which has a higher probability of moving in the direction of the future centroid. At every Lloyd's step, the centroids are injected with the noise using the exponential DP mechanism. The results of the experiments indicate that our approach outperforms the current state-of-the-art method, i.e., the baseline algorithm, in terms of clustering quality while maintaining the same differential privacy requirements. The clustering quality significantly improved by 4.13 and 2.83 times than baseline for the Wine and Breast_Cancer dataset, respectively.","classes":{"dataset":0.2691984475}}
{"title":"Randomized Greedy Algorithms and Composable Coreset for k-Center Clustering with Outliers","description":"In this paper, we study the problem of {\\em $k$-center clustering with outliers}. The problem has many important applications in real world, but the presence of outliers can significantly increase the computational complexity. Though a number of methods have been developed in the past decades, it is still quite challenging to design quality guaranteed algorithm with low complexity for this problem. Our idea is inspired by the greedy method, Gonzalez's algorithm, that was developed for solving the ordinary $k$-center clustering problem. Based on some novel observations, we show that a simple randomized version of this greedy strategy actually can handle outliers efficiently. We further show that this randomized greedy approach also yields small coreset for the problem in doubling metrics (even if the doubling dimension is not given), which can greatly reduce the computational complexity. Moreover, together with the partial clustering framework proposed in arXiv:1703.01539 , we prove that our coreset method can be applied to distributed data with a low communication complexity. The experimental results suggest that our algorithms can achieve near optimal solutions and yield lower complexities comparing with the existing methods.","link":"http://arxiv.org/abs/2301.02814v1","created":"2023-01-07","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Randomized Greedy Algorithms and Composable Coreset for k-Center Clustering with Outliers In this paper, we study the problem of {\\em $k$-center clustering with outliers}. The problem has many important applications in real world, but the presence of outliers can significantly increase the computational complexity. Though a number of methods have been developed in the past decades, it is still quite challenging to design quality guaranteed algorithm with low complexity for this problem. Our idea is inspired by the greedy method, Gonzalez's algorithm, that was developed for solving the ordinary $k$-center clustering problem. Based on some novel observations, we show that a simple randomized version of this greedy strategy actually can handle outliers efficiently. We further show that this randomized greedy approach also yields small coreset for the problem in doubling metrics (even if the doubling dimension is not given), which can greatly reduce the computational complexity. Moreover, together with the partial clustering framework proposed in arXiv:1703.01539 , we prove that our coreset method can be applied to distributed data with a low communication complexity. The experimental results suggest that our algorithms can achieve near optimal solutions and yield lower complexities comparing with the existing methods.","classes":{"dataset":0.2052448988}}
{"title":"KomaMRI.jl: An Open-Source Framework for General MRI Simulations with GPU Acceleration","description":"Purpose: To develop an open-source, high-performance, easy-to-use, extensible, cross-platform, and general MRI simulation framework (Koma).   Methods: Koma was developed using the Julia programming language. Like other MRI simulators, it solves the Bloch equations with CPU and GPU parallelization. The inputs are the scanner parameters, the phantom, and the pulse sequence that is Pulseq-compatible. The raw data is stored in the ISMRMRD format. For the reconstruction, MRIReco.jl is used. A graphical user interface utilizing web technologies was also designed. Two types of experiments were performed: one to compare the quality of the results and the execution speed, and the second to compare its usability. Finally, the use of Koma in quantitative imaging was demonstrated by simulating Magnetic Resonance Fingerprinting (MRF) acquisitions.   Results: Koma was compared to two well-known open-source MRI simulators, JEMRIS and MRiLab. Highly accurate results (with MAEs below 0.1% compared to JEMRIS) and better GPU performance than MRiLab were demonstrated. In an experiment with students, Koma was proved to be easy to use, eight times faster on personal computers than JEMRIS, and 65% of them recommended it. The potential for designing acquisition and reconstruction techniques was also shown through the simulation of MRF acquisitions, with conclusions that agree with the literature.   Conclusions: Koma's speed and flexibility have the potential to make simulations more accessible for education and research. Koma is expected to be used for designing and testing novel pulse sequences before implementing them in the scanner with Pulseq files, and for creating synthetic data to train machine learning models.","link":"http://arxiv.org/abs/2301.02702v1","created":"2023-01-06","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"KomaMRI.jl: An Open-Source Framework for General MRI Simulations with GPU Acceleration Purpose: To develop an open-source, high-performance, easy-to-use, extensible, cross-platform, and general MRI simulation framework (Koma).   Methods: Koma was developed using the Julia programming language. Like other MRI simulators, it solves the Bloch equations with CPU and GPU parallelization. The inputs are the scanner parameters, the phantom, and the pulse sequence that is Pulseq-compatible. The raw data is stored in the ISMRMRD format. For the reconstruction, MRIReco.jl is used. A graphical user interface utilizing web technologies was also designed. Two types of experiments were performed: one to compare the quality of the results and the execution speed, and the second to compare its usability. Finally, the use of Koma in quantitative imaging was demonstrated by simulating Magnetic Resonance Fingerprinting (MRF) acquisitions.   Results: Koma was compared to two well-known open-source MRI simulators, JEMRIS and MRiLab. Highly accurate results (with MAEs below 0.1% compared to JEMRIS) and better GPU performance than MRiLab were demonstrated. In an experiment with students, Koma was proved to be easy to use, eight times faster on personal computers than JEMRIS, and 65% of them recommended it. The potential for designing acquisition and reconstruction techniques was also shown through the simulation of MRF acquisitions, with conclusions that agree with the literature.   Conclusions: Koma's speed and flexibility have the potential to make simulations more accessible for education and research. Koma is expected to be used for designing and testing novel pulse sequences before implementing them in the scanner with Pulseq files, and for creating synthetic data to train machine learning models.","classes":{"dataset":0.458218962}}
{"title":"3D dose prediction for Gamma Knife radiosurgery using deep learning and data modification","description":"Purpose: To develop a machine learning-based, 3D dose prediction methodology for Gamma Knife (GK) radiosurgery. The methodology accounts for cases involving targets of any number, size, and shape. Methods: Data from 322 GK treatment plans was modified by isolating and cropping the contoured MRI and clinical dose distributions based on tumor location, then scaling the resulting tumor spaces to a standard size. An accompanying 3D tensor was created for each instance to account for tumor size. The modified dataset for 272 patients was used to train both a generative adversarial network (GAN-GK) and a 3D U-Net model (U-Net-GK). Unmodified data was used to train equivalent baseline models. All models were used to predict the dose distribution of 50 out-of-sample patients. Prediction accuracy was evaluated using gamma, with criteria of 4%/2mm, 3%/3mm, 3%/1mm and 1%/1mm. Prediction quality was assessed using coverage, selectivity, and conformity indices. Results: The predictions resulting from GAN-GK and U-Net-GK were similar to their clinical counterparts, with average gamma (4%/2mm) passing rates of 84.9 and 83.1, respectively. In contrast, the gamma passing rate of baseline models were significantly worse than their respective GK-specific models (p < 0.001) at all criterion levels. The quality of GK-specific predictions was also similar to that of clinical plans. Conclusion: Deep learning models can use GK-specific data modification to predict 3D dose distributions for GKRS plans with a large range in size, shape, or number of targets. Standard deep learning models applied to unmodified GK data generated poorer predictions.","link":"http://arxiv.org/abs/2301.02640v1","created":"2023-01-06","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"3D dose prediction for Gamma Knife radiosurgery using deep learning and data modification Purpose: To develop a machine learning-based, 3D dose prediction methodology for Gamma Knife (GK) radiosurgery. The methodology accounts for cases involving targets of any number, size, and shape. Methods: Data from 322 GK treatment plans was modified by isolating and cropping the contoured MRI and clinical dose distributions based on tumor location, then scaling the resulting tumor spaces to a standard size. An accompanying 3D tensor was created for each instance to account for tumor size. The modified dataset for 272 patients was used to train both a generative adversarial network (GAN-GK) and a 3D U-Net model (U-Net-GK). Unmodified data was used to train equivalent baseline models. All models were used to predict the dose distribution of 50 out-of-sample patients. Prediction accuracy was evaluated using gamma, with criteria of 4%/2mm, 3%/3mm, 3%/1mm and 1%/1mm. Prediction quality was assessed using coverage, selectivity, and conformity indices. Results: The predictions resulting from GAN-GK and U-Net-GK were similar to their clinical counterparts, with average gamma (4%/2mm) passing rates of 84.9 and 83.1, respectively. In contrast, the gamma passing rate of baseline models were significantly worse than their respective GK-specific models (p < 0.001) at all criterion levels. The quality of GK-specific predictions was also similar to that of clinical plans. Conclusion: Deep learning models can use GK-specific data modification to predict 3D dose distributions for GKRS plans with a large range in size, shape, or number of targets. Standard deep learning models applied to unmodified GK data generated poorer predictions.","classes":{"dataset":0.3558076024}}
{"title":"Early Insights for Atmospheric Retrievals of Exoplanets using JWST Transit Spectroscopy","description":"We have entered the era of the James Webb Space Telescope (JWST). We use the first JWST transmission spectrum of the hot Saturn-mass exoplanet, WASP-39 b, obtained with the NIRSpec instrument in the 3-5 $\\mu$m range to investigate (a) what atmospheric constraints are possible with JWST-quality data in this spectral range, (b) requirements for atmospheric models used in retrievals, (c) effect of differences between data reduction pipelines on retrieved atmospheric properties, and (d) complementarity between JWST data in the 3-5 $\\mu$m range and HST observations at shorter wavelengths. JWST spectra in the 3-5 $\\mu$m range provide a promising avenue for chemical detections while encompassing a window in cloud opacity for several prominent aerosols. We confirm recent inferences of CO$_2$, SO$_2$, H$_2$O, and CO in WASP-39 b, report tentative evidence for H$_2$S, and retrieve elemental abundances consistent with Saturn's metallicity. We retrieve molecular abundances with $\\sim$0.3-0.6 dex precision with this relatively limited spectral range. When considering the 3-5 $\\mu$m data alone, reported differences in spectra with different reduction pipelines can affect abundance estimates by up to $\\sim$1 dex and the detectability of less prominent species. Complementing with data at shorter wavelengths, e.g. with other JWST instruments or HST WFC3 ($\\sim$0.8-1.7 $\\mu$m), can significantly improve the accuracy and precision of the abundance estimates. The high data quality enables constraints on aerosol properties, including their composition, modal size and extent, motivating their consideration in retrievals. Our results highlight the promise of JWST exoplanet spectroscopy, while underscoring the importance of robust data reduction and atmospheric retrieval approaches in the JWST era.","link":"http://arxiv.org/abs/2301.02564v1","created":"2023-01-06","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Early Insights for Atmospheric Retrievals of Exoplanets using JWST Transit Spectroscopy We have entered the era of the James Webb Space Telescope (JWST). We use the first JWST transmission spectrum of the hot Saturn-mass exoplanet, WASP-39 b, obtained with the NIRSpec instrument in the 3-5 $\\mu$m range to investigate (a) what atmospheric constraints are possible with JWST-quality data in this spectral range, (b) requirements for atmospheric models used in retrievals, (c) effect of differences between data reduction pipelines on retrieved atmospheric properties, and (d) complementarity between JWST data in the 3-5 $\\mu$m range and HST observations at shorter wavelengths. JWST spectra in the 3-5 $\\mu$m range provide a promising avenue for chemical detections while encompassing a window in cloud opacity for several prominent aerosols. We confirm recent inferences of CO$_2$, SO$_2$, H$_2$O, and CO in WASP-39 b, report tentative evidence for H$_2$S, and retrieve elemental abundances consistent with Saturn's metallicity. We retrieve molecular abundances with $\\sim$0.3-0.6 dex precision with this relatively limited spectral range. When considering the 3-5 $\\mu$m data alone, reported differences in spectra with different reduction pipelines can affect abundance estimates by up to $\\sim$1 dex and the detectability of less prominent species. Complementing with data at shorter wavelengths, e.g. with other JWST instruments or HST WFC3 ($\\sim$0.8-1.7 $\\mu$m), can significantly improve the accuracy and precision of the abundance estimates. The high data quality enables constraints on aerosol properties, including their composition, modal size and extent, motivating their consideration in retrievals. Our results highlight the promise of JWST exoplanet spectroscopy, while underscoring the importance of robust data reduction and atmospheric retrieval approaches in the JWST era.","classes":{"dataset":0.3647781014}}
{"title":"Text2Poster: Laying out Stylized Texts on Retrieved Images","description":"Poster generation is a significant task for a wide range of applications, which is often time-consuming and requires lots of manual editing and artistic experience. In this paper, we propose a novel data-driven framework, called \\textit{Text2Poster}, to automatically generate visually-effective posters from textual information. Imitating the process of manual poster editing, our framework leverages a large-scale pretrained visual-textual model to retrieve background images from given texts, lays out the texts on the images iteratively by cascaded auto-encoders, and finally, stylizes the texts by a matching-based method. We learn the modules of the framework by weakly- and self-supervised learning strategies, mitigating the demand for labeled data. Both objective and subjective experiments demonstrate that our Text2Poster outperforms state-of-the-art methods, including academic research and commercial software, on the quality of generated posters.","link":"http://arxiv.org/abs/2301.02363v1","created":"2023-01-06","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Text2Poster: Laying out Stylized Texts on Retrieved Images Poster generation is a significant task for a wide range of applications, which is often time-consuming and requires lots of manual editing and artistic experience. In this paper, we propose a novel data-driven framework, called \\textit{Text2Poster}, to automatically generate visually-effective posters from textual information. Imitating the process of manual poster editing, our framework leverages a large-scale pretrained visual-textual model to retrieve background images from given texts, lays out the texts on the images iteratively by cascaded auto-encoders, and finally, stylizes the texts by a matching-based method. We learn the modules of the framework by weakly- and self-supervised learning strategies, mitigating the demand for labeled data. Both objective and subjective experiments demonstrate that our Text2Poster outperforms state-of-the-art methods, including academic research and commercial software, on the quality of generated posters.","classes":{"dataset":0.6579781175}}
{"title":"ANNA: Abstractive Text-to-Image Synthesis with Filtered News Captions","description":"Advancements in Text-to-Image synthesis over recent years have focused more on improving the quality of generated samples on datasets with descriptive captions. However, real-world image-caption pairs present in domains such as news data do not use simple and directly descriptive captions. With captions containing information on both the image content and underlying contextual cues, they become abstractive in nature. In this paper, we launch ANNA, an Abstractive News captioNs dAtaset extracted from online news articles in a variety of different contexts. We explore the capabilities of current Text-to-Image synthesis models to generate news domain-specific images using abstractive captions by benchmarking them on ANNA, in both standard training and transfer learning settings. The generated images are judged on the basis of contextual relevance, visual quality, and perceptual similarity to ground-truth image-caption pairs. Through our experiments, we show that techniques such as transfer learning achieve limited success in understanding abstractive captions but still fail to consistently learn the relationships between content and context features.","link":"http://arxiv.org/abs/2301.02160v1","created":"2023-01-05","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"ANNA: Abstractive Text-to-Image Synthesis with Filtered News Captions Advancements in Text-to-Image synthesis over recent years have focused more on improving the quality of generated samples on datasets with descriptive captions. However, real-world image-caption pairs present in domains such as news data do not use simple and directly descriptive captions. With captions containing information on both the image content and underlying contextual cues, they become abstractive in nature. In this paper, we launch ANNA, an Abstractive News captioNs dAtaset extracted from online news articles in a variety of different contexts. We explore the capabilities of current Text-to-Image synthesis models to generate news domain-specific images using abstractive captions by benchmarking them on ANNA, in both standard training and transfer learning settings. The generated images are judged on the basis of contextual relevance, visual quality, and perceptual similarity to ground-truth image-caption pairs. Through our experiments, we show that techniques such as transfer learning achieve limited success in understanding abstractive captions but still fail to consistently learn the relationships between content and context features.","classes":{"dataset":0.2656772733}}
{"title":"On the Influence of Gradient Reconstruction Procedures Over the Accuracy of Finite Volume Based Schemes","description":"In the context of the cell centered finite volume approach, care must be taken when performing the reconstruction of property gradients at cell interfaces. The present work analyzes three different gradient reconstruction procedures, using three different turbulent simulation test cases, namely the zero-gradient flat plate, the subsonic NACA 0012 airfoil and the transonic OAT15A airfoil. The analysis is concerned mainly with the usage of quadrilateral meshes. The gas dynamics equations are solved using an implicit implementation of Roe's second-order upwind scheme. The RANS closure problem is solved by using the negative Spalart-Allmaras turbulence model. The solution quality of each gradient discretization procedure is analyzed and compared to experimental data and other numerical solutions available in the literature. For the cases considered here, excellent agreement is obtained between the computed solutions and the expected results, regardless of which gradient reconstruction scheme is used.","link":"http://arxiv.org/abs/2301.02046v1","created":"2023-01-05","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"On the Influence of Gradient Reconstruction Procedures Over the Accuracy of Finite Volume Based Schemes In the context of the cell centered finite volume approach, care must be taken when performing the reconstruction of property gradients at cell interfaces. The present work analyzes three different gradient reconstruction procedures, using three different turbulent simulation test cases, namely the zero-gradient flat plate, the subsonic NACA 0012 airfoil and the transonic OAT15A airfoil. The analysis is concerned mainly with the usage of quadrilateral meshes. The gas dynamics equations are solved using an implicit implementation of Roe's second-order upwind scheme. The RANS closure problem is solved by using the negative Spalart-Allmaras turbulence model. The solution quality of each gradient discretization procedure is analyzed and compared to experimental data and other numerical solutions available in the literature. For the cases considered here, excellent agreement is obtained between the computed solutions and the expected results, regardless of which gradient reconstruction scheme is used.","classes":{"dataset":0.398632437}}
{"title":"Theory of shallow and deep boron defects in 4H-SiC","description":"Abstract Despite advances toward improving the quality of $p$-type 4H-SiC substrates and layers, we still have no model capable of accounting for the multitude of boron-related optical, junction, and paramagnetic resonance experiments available in the literature. A conspicuous puzzle is the observation of two shallow boron defects with rather distinct axial orientations as found by electron paramagnetic resonance (EPR) and electron nuclear double resonance (ENDOR) data. This feature is not observed in material doped with other group-III elements. Another open issue involves conflicting conclusions from photoluminescence and EPR studies of a deeper boron center, which has been linked to rather distinct models, either based on substitutional or vacancy-related boron defects. We unlock these and other problems by means of first-principles calculations, where the temperature-dependent stability, the electronic activity, and the paramagnetic response of boron defects in 4H-SiC are investigated.","link":"http://arxiv.org/abs/2301.01979v1","created":"2023-01-05","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Theory of shallow and deep boron defects in 4H-SiC Abstract Despite advances toward improving the quality of $p$-type 4H-SiC substrates and layers, we still have no model capable of accounting for the multitude of boron-related optical, junction, and paramagnetic resonance experiments available in the literature. A conspicuous puzzle is the observation of two shallow boron defects with rather distinct axial orientations as found by electron paramagnetic resonance (EPR) and electron nuclear double resonance (ENDOR) data. This feature is not observed in material doped with other group-III elements. Another open issue involves conflicting conclusions from photoluminescence and EPR studies of a deeper boron center, which has been linked to rather distinct models, either based on substitutional or vacancy-related boron defects. We unlock these and other problems by means of first-principles calculations, where the temperature-dependent stability, the electronic activity, and the paramagnetic response of boron defects in 4H-SiC are investigated.","classes":{"dataset":0.3175480366}}
{"title":"A comprehensive review of automatic text summarization techniques: method, data, evaluation and coding","description":"We provide a literature review about Automatic Text Summarization (ATS) systems. We consider a citation-based approach. We start with some popular and well-known papers that we have in hand about each topic we want to cover and we have tracked the \"backward citations\" (papers that are cited by the set of papers we knew beforehand) and the \"forward citations\" (newer papers that cite the set of papers we knew beforehand). In order to organize the different methods, we present the diverse approaches to ATS guided by the mechanisms they use to generate a summary. Besides presenting the methods, we also present an extensive review of the datasets available for summarization tasks and the methods used to evaluate the quality of the summaries. Finally, we present an empirical exploration of these methods using the CNN Corpus dataset that provides golden summaries for extractive and abstractive methods.","link":"http://arxiv.org/abs/2301.03403v2","created":"2023-01-04","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"A comprehensive review of automatic text summarization techniques: method, data, evaluation and coding We provide a literature review about Automatic Text Summarization (ATS) systems. We consider a citation-based approach. We start with some popular and well-known papers that we have in hand about each topic we want to cover and we have tracked the \"backward citations\" (papers that are cited by the set of papers we knew beforehand) and the \"forward citations\" (newer papers that cite the set of papers we knew beforehand). In order to organize the different methods, we present the diverse approaches to ATS guided by the mechanisms they use to generate a summary. Besides presenting the methods, we also present an extensive review of the datasets available for summarization tasks and the methods used to evaluate the quality of the summaries. Finally, we present an empirical exploration of these methods using the CNN Corpus dataset that provides golden summaries for extractive and abstractive methods.","classes":{"dataset":0.0528567955}}
{"title":"Augmenting data-driven models for energy systems through feature engineering: A Python framework for feature engineering","description":"Data-driven modeling is an approach in energy systems modeling that has been gaining popularity. In data-driven modeling, machine learning methods such as linear regression, neural networks or decision-tree based methods are being applied. While these methods do not require domain knowledge, they are sensitive to data quality. Therefore, improving data quality in a dataset is beneficial for creating machine learning-based models. The improvement of data quality can be implemented through preprocessing methods. A selected type of preprocessing is feature engineering, which focuses on evaluating and improving the quality of certain features inside the dataset. Feature engineering methods include methods such as feature creation, feature expansion, or feature selection. In this work, a Python framework containing different feature engineering methods is presented. This framework contains different methods for feature creation, expansion and selection; in addition, methods for transforming or filtering data are implemented. The implementation of the framework is based on the Python library scikit-learn. The framework is demonstrated on a case study of a use case from energy demand prediction. A data-driven model is created including selected feature engineering methods. The results show an improvement in prediction accuracy through the engineered features.","link":"http://arxiv.org/abs/2301.01720v1","created":"2023-01-04","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Augmenting data-driven models for energy systems through feature engineering: A Python framework for feature engineering Data-driven modeling is an approach in energy systems modeling that has been gaining popularity. In data-driven modeling, machine learning methods such as linear regression, neural networks or decision-tree based methods are being applied. While these methods do not require domain knowledge, they are sensitive to data quality. Therefore, improving data quality in a dataset is beneficial for creating machine learning-based models. The improvement of data quality can be implemented through preprocessing methods. A selected type of preprocessing is feature engineering, which focuses on evaluating and improving the quality of certain features inside the dataset. Feature engineering methods include methods such as feature creation, feature expansion, or feature selection. In this work, a Python framework containing different feature engineering methods is presented. This framework contains different methods for feature creation, expansion and selection; in addition, methods for transforming or filtering data are implemented. The implementation of the framework is based on the Python library scikit-learn. The framework is demonstrated on a case study of a use case from energy demand prediction. A data-driven model is created including selected feature engineering methods. The results show an improvement in prediction accuracy through the engineered features.","classes":{"dataset":0.1047001109}}
{"title":"KIDS: kinematics-based (in)activity detection and segmentation in a sleep case study","description":"Sleep behaviour and in-bed movements contain rich information on the neurophysiological health of people, and have a direct link to the general well-being and quality of life. Standard clinical practices rely on polysomnography for sleep assessment; however, it is intrusive, performed in unfamiliar environments and requires trained personnel. Progress has been made on less invasive sensor technologies, such as actigraphy, but clinical validation raises concerns over their reliability and precision. Additionally, the field lacks a widely acceptable algorithm, with proposed approaches ranging from raw signal or feature thresholding to data-hungry classification models, many of which are unfamiliar to medical staff. This paper proposes an online Bayesian probabilistic framework for objective (in)activity detection and segmentation based on clinically meaningful joint kinematics, measured by a custom-made wearable sensor. Intuitive three-dimensional visualisations of kinematic timeseries were accomplished through dimension reduction based preprocessing, offering out-of-the-box framework explainability potentially useful for clinical monitoring and diagnosis. The proposed framework attained up to 99.2\\% $F_1$-score and 0.96 Pearson's correlation coefficient in, respectively, the posture change detection and inactivity segmentation tasks. The work paves the way for a reliable home-based analysis of movements during sleep which would serve patient-centred longitudinal care plans.","link":"http://arxiv.org/abs/2301.03469v1","created":"2023-01-04","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"KIDS: kinematics-based (in)activity detection and segmentation in a sleep case study Sleep behaviour and in-bed movements contain rich information on the neurophysiological health of people, and have a direct link to the general well-being and quality of life. Standard clinical practices rely on polysomnography for sleep assessment; however, it is intrusive, performed in unfamiliar environments and requires trained personnel. Progress has been made on less invasive sensor technologies, such as actigraphy, but clinical validation raises concerns over their reliability and precision. Additionally, the field lacks a widely acceptable algorithm, with proposed approaches ranging from raw signal or feature thresholding to data-hungry classification models, many of which are unfamiliar to medical staff. This paper proposes an online Bayesian probabilistic framework for objective (in)activity detection and segmentation based on clinically meaningful joint kinematics, measured by a custom-made wearable sensor. Intuitive three-dimensional visualisations of kinematic timeseries were accomplished through dimension reduction based preprocessing, offering out-of-the-box framework explainability potentially useful for clinical monitoring and diagnosis. The proposed framework attained up to 99.2\\% $F_1$-score and 0.96 Pearson's correlation coefficient in, respectively, the posture change detection and inactivity segmentation tasks. The work paves the way for a reliable home-based analysis of movements during sleep which would serve patient-centred longitudinal care plans.","classes":{"dataset":0.0998970047}}
{"title":"Fast Absolute 3D CGO-Based Electrical Impedance Tomography on Experimental Tank Data","description":"Objective: To present the first 3D CGO-based absolute EIT reconstructions from experimental tank data. Approach: CGO-based methods for absolute EIT imaging are compared to traditional TV regularized non-linear least squares reconstruction methods. Additional robustness testing is performed by considering incorrect model\\textbf{}ing of domain shape. Main Results: The CGO-based methods are fast, and show strong robustness to incorrect domain modeling comparable to classic difference EIT imaging and fewer boundary artefacts than the TV regularized non-linear least squares reference reconstructions. Significance: This work is the first to demonstrate fully 3D CGO-based absolute EIT reconstruction on experimental data and also compares to TV-regularized absolute reconstruction. The speed (1-5 seconds) and quality of the reconstructions is encouraging for future work in absolute EIT.","link":"http://arxiv.org/abs/2301.01655v1","created":"2023-01-04","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Fast Absolute 3D CGO-Based Electrical Impedance Tomography on Experimental Tank Data Objective: To present the first 3D CGO-based absolute EIT reconstructions from experimental tank data. Approach: CGO-based methods for absolute EIT imaging are compared to traditional TV regularized non-linear least squares reconstruction methods. Additional robustness testing is performed by considering incorrect model\\textbf{}ing of domain shape. Main Results: The CGO-based methods are fast, and show strong robustness to incorrect domain modeling comparable to classic difference EIT imaging and fewer boundary artefacts than the TV regularized non-linear least squares reference reconstructions. Significance: This work is the first to demonstrate fully 3D CGO-based absolute EIT reconstruction on experimental data and also compares to TV-regularized absolute reconstruction. The speed (1-5 seconds) and quality of the reconstructions is encouraging for future work in absolute EIT.","classes":{"dataset":0.1632312983}}
{"title":"Identifying Personal Data Processing for Code Review","description":"Code review is a critical step in the software development life cycle, which assesses and boosts the code's effectiveness and correctness, pinpoints security issues, and raises its quality by adhering to best practices. Due to the increased need for personal data protection motivated by legislation, code reviewers need to understand where personal data is located in software systems and how it is handled. Although most recent work on code review focuses on security vulnerabilities, privacy-related techniques are not easy for code reviewers to implement, making their inclusion in the code review process challenging. In this paper, we present ongoing work on a new approach to identifying personal data processing, enabling developers and code reviewers in drafting privacy analyses and complying with regulations such as the General Data Protection Regulation (GDPR).","link":"http://arxiv.org/abs/2301.01568v1","created":"2023-01-04","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Identifying Personal Data Processing for Code Review Code review is a critical step in the software development life cycle, which assesses and boosts the code's effectiveness and correctness, pinpoints security issues, and raises its quality by adhering to best practices. Due to the increased need for personal data protection motivated by legislation, code reviewers need to understand where personal data is located in software systems and how it is handled. Although most recent work on code review focuses on security vulnerabilities, privacy-related techniques are not easy for code reviewers to implement, making their inclusion in the code review process challenging. In this paper, we present ongoing work on a new approach to identifying personal data processing, enabling developers and code reviewers in drafting privacy analyses and complying with regulations such as the General Data Protection Regulation (GDPR).","classes":{"dataset":0.4377044737}}
{"title":"Machine Learning-based Signal Quality Assessment for Cardiac Volume Monitoring in Electrical Impedance Tomography","description":"Owing to recent advances in thoracic electrical impedance tomography, a patient's hemodynamic function can be noninvasively and continuously estimated in real-time by surveilling a cardiac volume signal associated with stroke volume and cardiac output. In clinical applications, however, a cardiac volume signal is often of low quality, mainly because of the patient's deliberate movements or inevitable motions during clinical interventions. This study aims to develop a signal quality indexing method that assesses the influence of motion artifacts on transient cardiac volume signals. The assessment is performed on each cardiac cycle to take advantage of the periodicity and regularity in cardiac volume changes. Time intervals are identified using the synchronized electrocardiography system. We apply divergent machine-learning methods, which can be sorted into discriminative-model and manifold-learning approaches. The use of machine-learning could be suitable for our real-time monitoring application that requires fast inference and automation as well as high accuracy. In the clinical environment, the proposed method can be utilized to provide immediate warnings so that clinicians can minimize confusion regarding patients' conditions, reduce clinical resource utilization, and improve the confidence level of the monitoring system. Numerous experiments using actual EIT data validate the capability of cardiac volume signals degraded by motion artifacts to be accurately and automatically assessed in real-time by machine learning. The best model achieved an accuracy of 0.95, positive and negative predictive values of 0.96 and 0.86, sensitivity of 0.98, specificity of 0.77, and AUC of 0.96.","link":"http://arxiv.org/abs/2301.01469v1","created":"2023-01-04","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Machine Learning-based Signal Quality Assessment for Cardiac Volume Monitoring in Electrical Impedance Tomography Owing to recent advances in thoracic electrical impedance tomography, a patient's hemodynamic function can be noninvasively and continuously estimated in real-time by surveilling a cardiac volume signal associated with stroke volume and cardiac output. In clinical applications, however, a cardiac volume signal is often of low quality, mainly because of the patient's deliberate movements or inevitable motions during clinical interventions. This study aims to develop a signal quality indexing method that assesses the influence of motion artifacts on transient cardiac volume signals. The assessment is performed on each cardiac cycle to take advantage of the periodicity and regularity in cardiac volume changes. Time intervals are identified using the synchronized electrocardiography system. We apply divergent machine-learning methods, which can be sorted into discriminative-model and manifold-learning approaches. The use of machine-learning could be suitable for our real-time monitoring application that requires fast inference and automation as well as high accuracy. In the clinical environment, the proposed method can be utilized to provide immediate warnings so that clinicians can minimize confusion regarding patients' conditions, reduce clinical resource utilization, and improve the confidence level of the monitoring system. Numerous experiments using actual EIT data validate the capability of cardiac volume signals degraded by motion artifacts to be accurately and automatically assessed in real-time by machine learning. The best model achieved an accuracy of 0.95, positive and negative predictive values of 0.96 and 0.86, sensitivity of 0.98, specificity of 0.77, and AUC of 0.96.","classes":{"dataset":0.8061935902}}
{"title":"Attribute-Centric Compositional Text-to-Image Generation","description":"Despite the recent impressive breakthroughs in text-to-image generation, generative models have difficulty in capturing the data distribution of underrepresented attribute compositions while over-memorizing overrepresented attribute compositions, which raises public concerns about their robustness and fairness. To tackle this challenge, we propose ACTIG, an attribute-centric compositional text-to-image generation framework. We present an attribute-centric feature augmentation and a novel image-free training scheme, which greatly improves model's ability to generate images with underrepresented attributes. We further propose an attribute-centric contrastive loss to avoid overfitting to overrepresented attribute compositions. We validate our framework on the CelebA-HQ and CUB datasets. Extensive experiments show that the compositional generalization of ACTIG is outstanding, and our framework outperforms previous works in terms of image quality and text-image consistency.","link":"http://arxiv.org/abs/2301.01413v1","created":"2023-01-04","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Attribute-Centric Compositional Text-to-Image Generation Despite the recent impressive breakthroughs in text-to-image generation, generative models have difficulty in capturing the data distribution of underrepresented attribute compositions while over-memorizing overrepresented attribute compositions, which raises public concerns about their robustness and fairness. To tackle this challenge, we propose ACTIG, an attribute-centric compositional text-to-image generation framework. We present an attribute-centric feature augmentation and a novel image-free training scheme, which greatly improves model's ability to generate images with underrepresented attributes. We further propose an attribute-centric contrastive loss to avoid overfitting to overrepresented attribute compositions. We validate our framework on the CelebA-HQ and CUB datasets. Extensive experiments show that the compositional generalization of ACTIG is outstanding, and our framework outperforms previous works in terms of image quality and text-image consistency.","classes":{"dataset":0.2387413234}}
{"title":"Identifying Exoplanets with Deep Learning. V. Improved Light Curve Classification for TESS Full Frame Image Observations","description":"The TESS mission produces a large amount of time series data, only a small fraction of which contain detectable exoplanetary transit signals. Deep learning techniques such as neural networks have proved effective at differentiating promising astrophysical eclipsing candidates from other phenomena such as stellar variability and systematic instrumental effects in an efficient, unbiased and sustainable manner. This paper presents a high quality dataset containing light curves from the Primary Mission and 1st Extended Mission full frame images and periodic signals detected via Box Least Squares (Kov\\'acs et al. 2002; Hartman 2012). The dataset was curated using a thorough manual review process then used to train a neural network called Astronet-Triage-v2. On our test set, for transiting/eclipsing events we achieve a 99.6% recall (true positives over all data with positive labels) at a precision of 75.7% (true positives over all predicted positives). Since 90% of our training data is from the Primary Mission, we also test our ability to generalize on held-out 1st Extended Mission data. Here, we find an area under the precision-recall curve of 0.965, a 4% improvement over Astronet-Triage (Yu et al. 2019). On the TESS Object of Interest (TOI) Catalog through April 2022, a shortlist of planets and planet candidates, Astronet-Triage-v2 is able to recover 3577 out of 4140 TOIs, while Astronet-Triage only recovers 3349 targets at an equal level of precision. In other words, upgrading to Astronet-Triage-v2 helps save at least 200 planet candidates from being lost. The new model is currently used for planet candidate triage in the Quick-Look Pipeline (Huang et al. 2020a,b; Kunimoto et al. 2021).","link":"http://arxiv.org/abs/2301.01371v1","created":"2023-01-03","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Identifying Exoplanets with Deep Learning. V. Improved Light Curve Classification for TESS Full Frame Image Observations The TESS mission produces a large amount of time series data, only a small fraction of which contain detectable exoplanetary transit signals. Deep learning techniques such as neural networks have proved effective at differentiating promising astrophysical eclipsing candidates from other phenomena such as stellar variability and systematic instrumental effects in an efficient, unbiased and sustainable manner. This paper presents a high quality dataset containing light curves from the Primary Mission and 1st Extended Mission full frame images and periodic signals detected via Box Least Squares (Kov\\'acs et al. 2002; Hartman 2012). The dataset was curated using a thorough manual review process then used to train a neural network called Astronet-Triage-v2. On our test set, for transiting/eclipsing events we achieve a 99.6% recall (true positives over all data with positive labels) at a precision of 75.7% (true positives over all predicted positives). Since 90% of our training data is from the Primary Mission, we also test our ability to generalize on held-out 1st Extended Mission data. Here, we find an area under the precision-recall curve of 0.965, a 4% improvement over Astronet-Triage (Yu et al. 2019). On the TESS Object of Interest (TOI) Catalog through April 2022, a shortlist of planets and planet candidates, Astronet-Triage-v2 is able to recover 3577 out of 4140 TOIs, while Astronet-Triage only recovers 3349 targets at an equal level of precision. In other words, upgrading to Astronet-Triage-v2 helps save at least 200 planet candidates from being lost. The new model is currently used for planet candidate triage in the Quick-Look Pipeline (Huang et al. 2020a,b; Kunimoto et al. 2021).","classes":{"dataset":0.0768252164}}
{"title":"An Empirical Investigation into the Use of Image Captioning for Automated Software Documentation","description":"Existing automated techniques for software documentation typically attempt to reason between two main sources of information: code and natural language. However, this reasoning process is often complicated by the lexical gap between more abstract natural language and more structured programming languages. One potential bridge for this gap is the Graphical User Interface (GUI), as GUIs inherently encode salient information about underlying program functionality into rich, pixel-based data representations. This paper offers one of the first comprehensive empirical investigations into the connection between GUIs and functional, natural language descriptions of software. First, we collect, analyze, and open source a large dataset of functional GUI descriptions consisting of 45,998 descriptions for 10,204 screenshots from popular Android applications. The descriptions were obtained from human labelers and underwent several quality control mechanisms. To gain insight into the representational potential of GUIs, we investigate the ability of four Neural Image Captioning models to predict natural language descriptions of varying granularity when provided a screenshot as input. We evaluate these models quantitatively, using common machine translation metrics, and qualitatively through a large-scale user study. Finally, we offer learned lessons and a discussion of the potential shown by multimodal models to enhance future techniques for automated software documentation.","link":"http://arxiv.org/abs/2301.01224v1","created":"2023-01-03","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"An Empirical Investigation into the Use of Image Captioning for Automated Software Documentation Existing automated techniques for software documentation typically attempt to reason between two main sources of information: code and natural language. However, this reasoning process is often complicated by the lexical gap between more abstract natural language and more structured programming languages. One potential bridge for this gap is the Graphical User Interface (GUI), as GUIs inherently encode salient information about underlying program functionality into rich, pixel-based data representations. This paper offers one of the first comprehensive empirical investigations into the connection between GUIs and functional, natural language descriptions of software. First, we collect, analyze, and open source a large dataset of functional GUI descriptions consisting of 45,998 descriptions for 10,204 screenshots from popular Android applications. The descriptions were obtained from human labelers and underwent several quality control mechanisms. To gain insight into the representational potential of GUIs, we investigate the ability of four Neural Image Captioning models to predict natural language descriptions of varying granularity when provided a screenshot as input. We evaluate these models quantitatively, using common machine translation metrics, and qualitatively through a large-scale user study. Finally, we offer learned lessons and a discussion of the potential shown by multimodal models to enhance future techniques for automated software documentation.","classes":{"dataset":0.1951537132}}
{"title":"MGTAB: A Multi-Relational Graph-Based Twitter Account Detection Benchmark","description":"The development of social media user stance detection and bot detection methods rely heavily on large-scale and high-quality benchmarks. However, in addition to low annotation quality, existing benchmarks generally have incomplete user relationships, suppressing graph-based account detection research. To address these issues, we propose a Multi-Relational Graph-Based Twitter Account Detection Benchmark (MGTAB), the first standardized graph-based benchmark for account detection. To our knowledge, MGTAB was built based on the largest original data in the field, with over 1.55 million users and 130 million tweets. MGTAB contains 10,199 expert-annotated users and 7 types of relationships, ensuring high-quality annotation and diversified relations. In MGTAB, we extracted the 20 user property features with the greatest information gain and user tweet features as the user features. In addition, we performed a thorough evaluation of MGTAB and other public datasets. Our experiments found that graph-based approaches are generally more effective than feature-based approaches and perform better when introducing multiple relations. By analyzing experiment results, we identify effective approaches for account detection and provide potential future research directions in this field. Our benchmark and standardized evaluation procedures are freely available at: https://github.com/GraphDetec/MGTAB.","link":"http://arxiv.org/abs/2301.01123v1","created":"2023-01-03","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"MGTAB: A Multi-Relational Graph-Based Twitter Account Detection Benchmark The development of social media user stance detection and bot detection methods rely heavily on large-scale and high-quality benchmarks. However, in addition to low annotation quality, existing benchmarks generally have incomplete user relationships, suppressing graph-based account detection research. To address these issues, we propose a Multi-Relational Graph-Based Twitter Account Detection Benchmark (MGTAB), the first standardized graph-based benchmark for account detection. To our knowledge, MGTAB was built based on the largest original data in the field, with over 1.55 million users and 130 million tweets. MGTAB contains 10,199 expert-annotated users and 7 types of relationships, ensuring high-quality annotation and diversified relations. In MGTAB, we extracted the 20 user property features with the greatest information gain and user tweet features as the user features. In addition, we performed a thorough evaluation of MGTAB and other public datasets. Our experiments found that graph-based approaches are generally more effective than feature-based approaches and perform better when introducing multiple relations. By analyzing experiment results, we identify effective approaches for account detection and provide potential future research directions in this field. Our benchmark and standardized evaluation procedures are freely available at: https://github.com/GraphDetec/MGTAB.","classes":{"dataset":0.0945384875}}
{"title":"Heterogeneous Domain Adaptation and Equipment Matching: DANN-based Alignment with Cyclic Supervision (DBACS)","description":"Process monitoring and control are essential in modern industries for ensuring high quality standards and optimizing production performance. These technologies have a long history of application in production and have had numerous positive impacts, but also hold great potential when integrated with Industry 4.0 and advanced machine learning, particularly deep learning, solutions. However, in order to implement these solutions in production and enable widespread adoption, the scalability and transferability of deep learning methods have become a focus of research. While transfer learning has proven successful in many cases, particularly with computer vision and homogenous data inputs, it can be challenging to apply to heterogeneous data. Motivated by the need to transfer and standardize established processes to different, non-identical environments and by the challenge of adapting to heterogeneous data representations, this work introduces the Domain Adaptation Neural Network with Cyclic Supervision (DBACS) approach. DBACS addresses the issue of model generalization through domain adaptation, specifically for heterogeneous data, and enables the transfer and scalability of deep learning-based statistical control methods in a general manner. Additionally, the cyclic interactions between the different parts of the model enable DBACS to not only adapt to the domains, but also match them. To the best of our knowledge, DBACS is the first deep learning approach to combine adaptation and matching for heterogeneous data settings. For comparison, this work also includes subspace alignment and a multi-view learning that deals with heterogeneous representations by mapping data into correlated latent feature spaces. Finally, DBACS with its ability to adapt and match, is applied to a virtual metrology use case for an etching process run on different machine types in semiconductor manufacturing.","link":"http://arxiv.org/abs/2301.01038v1","created":"2023-01-03","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Heterogeneous Domain Adaptation and Equipment Matching: DANN-based Alignment with Cyclic Supervision (DBACS) Process monitoring and control are essential in modern industries for ensuring high quality standards and optimizing production performance. These technologies have a long history of application in production and have had numerous positive impacts, but also hold great potential when integrated with Industry 4.0 and advanced machine learning, particularly deep learning, solutions. However, in order to implement these solutions in production and enable widespread adoption, the scalability and transferability of deep learning methods have become a focus of research. While transfer learning has proven successful in many cases, particularly with computer vision and homogenous data inputs, it can be challenging to apply to heterogeneous data. Motivated by the need to transfer and standardize established processes to different, non-identical environments and by the challenge of adapting to heterogeneous data representations, this work introduces the Domain Adaptation Neural Network with Cyclic Supervision (DBACS) approach. DBACS addresses the issue of model generalization through domain adaptation, specifically for heterogeneous data, and enables the transfer and scalability of deep learning-based statistical control methods in a general manner. Additionally, the cyclic interactions between the different parts of the model enable DBACS to not only adapt to the domains, but also match them. To the best of our knowledge, DBACS is the first deep learning approach to combine adaptation and matching for heterogeneous data settings. For comparison, this work also includes subspace alignment and a multi-view learning that deals with heterogeneous representations by mapping data into correlated latent feature spaces. Finally, DBACS with its ability to adapt and match, is applied to a virtual metrology use case for an etching process run on different machine types in semiconductor manufacturing.","classes":{"dataset":0.1015374586}}
{"title":"Data Augmentation and Classification of Sea-Land Clutter for Over-the-Horizon Radar Using AC-VAEGAN","description":"In the sea-land clutter classification of sky-wave over-the-horizon-radar (OTHR), the imbalanced and scarce data leads to a poor performance of the deep learning-based classification model. To solve this problem, this paper proposes an improved auxiliary classifier generative adversarial network~(AC-GAN) architecture, namely auxiliary classifier variational autoencoder generative adversarial network (AC-VAEGAN). AC-VAEGAN can synthesize higher quality sea-land clutter samples than AC-GAN and serve as an effective tool for data augmentation. Specifically, a 1-dimensional convolutional AC-VAEGAN architecture is designed to synthesize sea-land clutter samples. Additionally, an evaluation method combining both traditional evaluation of GAN domain and statistical evaluation of signal domain is proposed to evaluate the quality of synthetic samples. Using a dataset of OTHR sea-land clutter, both the quality of the synthetic samples and the performance of data augmentation of AC-VAEGAN are verified. Further, the effect of AC-VAEGAN as a data augmentation method on the classification performance of imbalanced and scarce sea-land clutter samples is validated. The experiment results show that the quality of samples synthesized by AC-VAEGAN is better than that of AC-GAN, and the data augmentation method with AC-VAEGAN is able to improve the classification performance in the case of imbalanced and scarce sea-land clutter samples.","link":"http://arxiv.org/abs/2301.00947v1","created":"2023-01-03","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Data Augmentation and Classification of Sea-Land Clutter for Over-the-Horizon Radar Using AC-VAEGAN In the sea-land clutter classification of sky-wave over-the-horizon-radar (OTHR), the imbalanced and scarce data leads to a poor performance of the deep learning-based classification model. To solve this problem, this paper proposes an improved auxiliary classifier generative adversarial network~(AC-GAN) architecture, namely auxiliary classifier variational autoencoder generative adversarial network (AC-VAEGAN). AC-VAEGAN can synthesize higher quality sea-land clutter samples than AC-GAN and serve as an effective tool for data augmentation. Specifically, a 1-dimensional convolutional AC-VAEGAN architecture is designed to synthesize sea-land clutter samples. Additionally, an evaluation method combining both traditional evaluation of GAN domain and statistical evaluation of signal domain is proposed to evaluate the quality of synthetic samples. Using a dataset of OTHR sea-land clutter, both the quality of the synthetic samples and the performance of data augmentation of AC-VAEGAN are verified. Further, the effect of AC-VAEGAN as a data augmentation method on the classification performance of imbalanced and scarce sea-land clutter samples is validated. The experiment results show that the quality of samples synthesized by AC-VAEGAN is better than that of AC-GAN, and the data augmentation method with AC-VAEGAN is able to improve the classification performance in the case of imbalanced and scarce sea-land clutter samples.","classes":{"dataset":0.070362106}}
{"title":"Gaussian Blur and Relative Edge Response","description":"It is often convenient to use Gaussian blur in studying image quality or in data augmentation pipelines for training convoluional neural networks. Because of their convenience, Guassians are sometimes used as first order approximations of optical point spread functions. Here, we derive and evaluate closed form relationships between Gaussian blur parameters and relative edge response, finding good agreement with measured results. Additionally, we evaluate the extent to which Gaussian approximations of optical point spread functions can be used to predict relative edge response, finding that Gaussian relationships provide a reasonable approximation in limited circumstances but not across a wide range of optical parameters.","link":"http://arxiv.org/abs/2301.00856v1","created":"2023-01-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Gaussian Blur and Relative Edge Response It is often convenient to use Gaussian blur in studying image quality or in data augmentation pipelines for training convoluional neural networks. Because of their convenience, Guassians are sometimes used as first order approximations of optical point spread functions. Here, we derive and evaluate closed form relationships between Gaussian blur parameters and relative edge response, finding good agreement with measured results. Additionally, we evaluate the extent to which Gaussian approximations of optical point spread functions can be used to predict relative edge response, finding that Gaussian relationships provide a reasonable approximation in limited circumstances but not across a wide range of optical parameters.","classes":{"dataset":0.0813779905}}
{"title":"IRT2: Inductive Linking and Ranking in Knowledge Graphs of Varying Scale","description":"We address the challenge of building domain-specific knowledge models for industrial use cases, where labelled data and taxonomic information is initially scarce. Our focus is on inductive link prediction models as a basis for practical tools that support knowledge engineers with exploring text collections and discovering and linking new (so-called open-world) entities to the knowledge graph. We argue that - though neural approaches to text mining have yielded impressive results in the past years - current benchmarks do not reflect the typical challenges encountered in the industrial wild properly. Therefore, our first contribution is an open benchmark coined IRT2 (inductive reasoning with text) that (1) covers knowledge graphs of varying sizes (including very small ones), (2) comes with incidental, low-quality text mentions, and (3) includes not only triple completion but also ranking, which is relevant for supporting experts with discovery tasks.   We investigate two neural models for inductive link prediction, one based on end-to-end learning and one that learns from the knowledge graph and text data in separate steps. These models compete with a strong bag-of-words baseline. The results show a significant advance in performance for the neural approaches as soon as the available graph data decreases for linking. For ranking, the results are promising, and the neural approaches outperform the sparse retriever by a wide margin.","link":"http://arxiv.org/abs/2301.00716v1","created":"2023-01-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"IRT2: Inductive Linking and Ranking in Knowledge Graphs of Varying Scale We address the challenge of building domain-specific knowledge models for industrial use cases, where labelled data and taxonomic information is initially scarce. Our focus is on inductive link prediction models as a basis for practical tools that support knowledge engineers with exploring text collections and discovering and linking new (so-called open-world) entities to the knowledge graph. We argue that - though neural approaches to text mining have yielded impressive results in the past years - current benchmarks do not reflect the typical challenges encountered in the industrial wild properly. Therefore, our first contribution is an open benchmark coined IRT2 (inductive reasoning with text) that (1) covers knowledge graphs of varying sizes (including very small ones), (2) comes with incidental, low-quality text mentions, and (3) includes not only triple completion but also ranking, which is relevant for supporting experts with discovery tasks.   We investigate two neural models for inductive link prediction, one based on end-to-end learning and one that learns from the knowledge graph and text data in separate steps. These models compete with a strong bag-of-words baseline. The results show a significant advance in performance for the neural approaches as soon as the available graph data decreases for linking. For ranking, the results are promising, and the neural approaches outperform the sparse retriever by a wide margin.","classes":{"dataset":0.0513058081}}
{"title":"Chains of Autoreplicative Random Forests for missing value imputation in high-dimensional datasets","description":"Missing values are a common problem in data science and machine learning. Removing instances with missing values can adversely affect the quality of further data analysis. This is exacerbated when there are relatively many more features than instances, and thus the proportion of affected instances is high. Such a scenario is common in many important domains, for example, single nucleotide polymorphism (SNP) datasets provide a large number of features over a genome for a relatively small number of individuals. To preserve as much information as possible prior to modeling, a rigorous imputation scheme is acutely needed. While Denoising Autoencoders is a state-of-the-art method for imputation in high-dimensional data, they still require enough complete cases to be trained on which is often not available in real-world problems. In this paper, we consider missing value imputation as a multi-label classification problem and propose Chains of Autoreplicative Random Forests. Using multi-label Random Forests instead of neural networks works well for low-sampled data as there are fewer parameters to optimize. Experiments on several SNP datasets show that our algorithm effectively imputes missing values based only on information from the dataset and exhibits better performance than standard algorithms that do not require any additional information. In this paper, the algorithm is implemented specifically for SNP data, but it can easily be adapted for other cases of missing value imputation.","link":"http://arxiv.org/abs/2301.00595v1","created":"2023-01-02","tags":["arxiv","data-quality"],"meta":{"query":"data AND quality"},"text":"Chains of Autoreplicative Random Forests for missing value imputation in high-dimensional datasets Missing values are a common problem in data science and machine learning. Removing instances with missing values can adversely affect the quality of further data analysis. This is exacerbated when there are relatively many more features than instances, and thus the proportion of affected instances is high. Such a scenario is common in many important domains, for example, single nucleotide polymorphism (SNP) datasets provide a large number of features over a genome for a relatively small number of individuals. To preserve as much information as possible prior to modeling, a rigorous imputation scheme is acutely needed. While Denoising Autoencoders is a state-of-the-art method for imputation in high-dimensional data, they still require enough complete cases to be trained on which is often not available in real-world problems. In this paper, we consider missing value imputation as a multi-label classification problem and propose Chains of Autoreplicative Random Forests. Using multi-label Random Forests instead of neural networks works well for low-sampled data as there are fewer parameters to optimize. Experiments on several SNP datasets show that our algorithm effectively imputes missing values based only on information from the dataset and exhibits better performance than standard algorithms that do not require any additional information. In this paper, the algorithm is implemented specifically for SNP data, but it can easily be adapted for other cases of missing value imputation.","classes":{"dataset":0.1017905995}}
{"title":"Realistic Computer-Generated Handwriting","description":"https://www.calligrapher.ai/","link":"https://www.calligrapher.ai/","created":"2023-01-26","tags":["hackernews"],"meta":{"score":322},"text":"Realistic Computer-Generated Handwriting https://www.calligrapher.ai/","classes":{"dataset":0.2570916116}}
{"title":"PayPal Data Breach Notification","description":"https://apps.web.maine.gov/online/aeviewer/ME/40/766753f1-f9c7-4dc5-9a5c-fe0f3ff51c06.shtml","link":"https://apps.web.maine.gov/online/aeviewer/ME/40/766753f1-f9c7-4dc5-9a5c-fe0f3ff51c06.shtml","created":"2023-01-26","tags":["hackernews"],"meta":{"score":149},"text":"PayPal Data Breach Notification https://apps.web.maine.gov/online/aeviewer/ME/40/766753f1-f9c7-4dc5-9a5c-fe0f3ff51c06.shtml","classes":{"dataset":0.4974877238}}
{"title":"An IP Attorney\u2019s Reading of the Stable Diffusion Class Action Lawsuit","description":"https://katedowninglaw.com/2023/01/26/an-ip-attorneys-reading-of-the-stable-diffusion-class-action-lawsuit/","link":"https://katedowninglaw.com/2023/01/26/an-ip-attorneys-reading-of-the-stable-diffusion-class-action-lawsuit/","created":"2023-01-26","tags":["hackernews"],"meta":{"score":10},"text":"An IP Attorney\u2019s Reading of the Stable Diffusion Class Action Lawsuit https://katedowninglaw.com/2023/01/26/an-ip-attorneys-reading-of-the-stable-diffusion-class-action-lawsuit/","classes":{"dataset":0.5038042068}}
{"title":"NYSE Tuesday opening mayhem traced to a staffer who left a backup system running","description":"https://www.bloomberg.com/news/articles/2023-01-25/nyse-mayhem-traced-to-a-staffer-who-left-a-backup-system-running","link":"https://www.bloomberg.com/news/articles/2023-01-25/nyse-mayhem-traced-to-a-staffer-who-left-a-backup-system-running","created":"2023-01-26","tags":["hackernews"],"meta":{"score":175},"text":"NYSE Tuesday opening mayhem traced to a staffer who left a backup system running https://www.bloomberg.com/news/articles/2023-01-25/nyse-mayhem-traced-to-a-staffer-who-left-a-backup-system-running","classes":{"dataset":0.4936075807}}
{"title":"What if AI didn't make you a bad writer, but a better thinker?","description":"https://slite.com/blog/gpt-knowledge-revolution-is-coming","link":"https://slite.com/blog/gpt-knowledge-revolution-is-coming","created":"2023-01-26","tags":["hackernews"],"meta":{"score":71},"text":"What if AI didn't make you a bad writer, but a better thinker? https://slite.com/blog/gpt-knowledge-revolution-is-coming","classes":{"dataset":0.4925903082}}
{"title":"IBM to cut about 3,900 workers while still hiring in \u2018higher growth\u2019 areas","description":"https://www.latimes.com/business/story/2023-01-25/ibm-layoff-3900-workers-still-hiring","link":"https://www.latimes.com/business/story/2023-01-25/ibm-layoff-3900-workers-still-hiring","created":"2023-01-26","tags":["hackernews"],"meta":{"score":20},"text":"IBM to cut about 3,900 workers while still hiring in \u2018higher growth\u2019 areas https://www.latimes.com/business/story/2023-01-25/ibm-layoff-3900-workers-still-hiring","classes":{"dataset":0.5264145732}}
{"title":"Imitating Human Behaviour with Diffusion Models","description":"https://arxiv.org/abs/2301.10677","link":"https://arxiv.org/abs/2301.10677","created":"2023-01-26","tags":["hackernews"],"meta":{"score":55},"text":"Imitating Human Behaviour with Diffusion Models https://arxiv.org/abs/2301.10677","classes":{"dataset":0.5392807722}}
{"title":"Surviving without a superuser in Postgres 16","description":"http://rhaas.blogspot.com/2023/01/surviving-without-superuser-coming-to.html","link":"http://rhaas.blogspot.com/2023/01/surviving-without-superuser-coming-to.html","created":"2023-01-26","tags":["hackernews"],"meta":{"score":22},"text":"Surviving without a superuser in Postgres 16 http://rhaas.blogspot.com/2023/01/surviving-without-superuser-coming-to.html","classes":{"dataset":0.4783449471}}
{"title":"Show HN: GPT Joke Writer","description":"https://punchlines.ai","link":"https://punchlines.ai","created":"2023-01-26","tags":["hackernews"],"meta":{"score":24},"text":"Show HN: GPT Joke Writer https://punchlines.ai","classes":{"dataset":0.5251471996}}
{"title":"Airframes.io an aircraft-related aggregator for ACARS, VDL, HFDL and SATCOM data","description":"https://app.airframes.io","link":"https://app.airframes.io","created":"2023-01-26","tags":["hackernews"],"meta":{"score":114},"text":"Airframes.io an aircraft-related aggregator for ACARS, VDL, HFDL and SATCOM data https://app.airframes.io","classes":{"dataset":0.4764446318}}
{"title":"Blogging is not dying anytime soon","description":"https://dariusforoux.com/blogging-not-dying/","link":"https://dariusforoux.com/blogging-not-dying/","created":"2023-01-26","tags":["hackernews"],"meta":{"score":64},"text":"Blogging is not dying anytime soon https://dariusforoux.com/blogging-not-dying/","classes":{"dataset":0.541641593}}
{"title":"NASA predicts asteroid to make one of closest approaches to Earth ever recorded","description":"https://www.jpl.nasa.gov/news/nasa-system-predicts-small-asteroid-to-pass-close-by-earth-this-week","link":"https://www.jpl.nasa.gov/news/nasa-system-predicts-small-asteroid-to-pass-close-by-earth-this-week","created":"2023-01-26","tags":["hackernews"],"meta":{"score":61},"text":"NASA predicts asteroid to make one of closest approaches to Earth ever recorded https://www.jpl.nasa.gov/news/nasa-system-predicts-small-asteroid-to-pass-close-by-earth-this-week","classes":{"dataset":0.504814446}}
{"title":"The Vast Humanity of Anton Chekhov","description":"https://newrepublic.com/article/170133/vast-humanity-anton-chekhov-blaisdell-biography-review","link":"https://newrepublic.com/article/170133/vast-humanity-anton-chekhov-blaisdell-biography-review","created":"2023-01-25","tags":["hackernews"],"meta":{"score":50},"text":"The Vast Humanity of Anton Chekhov https://newrepublic.com/article/170133/vast-humanity-anton-chekhov-blaisdell-biography-review","classes":{"dataset":0.5009970069}}
{"title":"Disassembly of the Asteroids arcade game firmware","description":"https://github.com/nmikstas/asteroids-disassembly","link":"https://github.com/nmikstas/asteroids-disassembly","created":"2023-01-26","tags":["hackernews"],"meta":{"score":49},"text":"Disassembly of the Asteroids arcade game firmware https://github.com/nmikstas/asteroids-disassembly","classes":{"dataset":0.5193474889}}
{"title":"Ugly Gerry \u2013 Gerrymandering font","description":"https://fontsarena.com/ugly-gerry/","link":"https://fontsarena.com/ugly-gerry/","created":"2023-01-26","tags":["hackernews"],"meta":{"score":296},"text":"Ugly Gerry \u2013 Gerrymandering font https://fontsarena.com/ugly-gerry/","classes":{"dataset":0.4897724986}}
{"title":"Replacing a SQL analyst with 26 recursive GPT prompts","description":"https://www.patterns.app/blog/2023/01/18/crunchbot-sql-analyst-gpt/","link":"https://www.patterns.app/blog/2023/01/18/crunchbot-sql-analyst-gpt/","created":"2023-01-25","tags":["hackernews"],"meta":{"score":725},"text":"Replacing a SQL analyst with 26 recursive GPT prompts https://www.patterns.app/blog/2023/01/18/crunchbot-sql-analyst-gpt/","classes":{"dataset":0.5434504747}}
{"title":"OpenJourney: Midjourney, but Open Source","description":"https://open-journey.github.io/","link":"https://open-journey.github.io/","created":"2023-01-25","tags":["hackernews"],"meta":{"score":555},"text":"OpenJourney: Midjourney, but Open Source https://open-journey.github.io/","classes":{"dataset":0.4673772752}}
{"title":"Tesla reports record revenue and beats on earnings","description":"https://www.cnbc.com/2023/01/25/tesla-tsla-earnings-q4-2022.html","link":"https://www.cnbc.com/2023/01/25/tesla-tsla-earnings-q4-2022.html","created":"2023-01-26","tags":["hackernews"],"meta":{"score":12},"text":"Tesla reports record revenue and beats on earnings https://www.cnbc.com/2023/01/25/tesla-tsla-earnings-q4-2022.html","classes":{"dataset":0.5226481557}}
{"title":"Two Supreme Court cases that could break the internet","description":"https://www.newyorker.com/news/q-and-a/two-supreme-court-cases-that-could-break-the-internet","link":"https://www.newyorker.com/news/q-and-a/two-supreme-court-cases-that-could-break-the-internet","created":"2023-01-26","tags":["hackernews"],"meta":{"score":37},"text":"Two Supreme Court cases that could break the internet https://www.newyorker.com/news/q-and-a/two-supreme-court-cases-that-could-break-the-internet","classes":{"dataset":0.5073384643}}
{"title":"Earth\u2019s inner core stopped turning and could go into reverse, study suggests","description":"https://www.cnn.com/2023/01/25/world/earth-core-turning-scli-scn-intl/index.html","link":"https://www.cnn.com/2023/01/25/world/earth-core-turning-scli-scn-intl/index.html","created":"2023-01-26","tags":["hackernews"],"meta":{"score":22},"text":"Earth\u2019s inner core stopped turning and could go into reverse, study suggests https://www.cnn.com/2023/01/25/world/earth-core-turning-scli-scn-intl/index.html","classes":{"dataset":0.4645644128}}
{"title":"Show HN: I've built a C# IDE, Runtime, and AppStore inside Excel","description":"https://querystorm.com/csharp-in-excel/","link":"https://querystorm.com/csharp-in-excel/","created":"2023-01-25","tags":["hackernews"],"meta":{"score":635},"text":"Show HN: I've built a C# IDE, Runtime, and AppStore inside Excel https://querystorm.com/csharp-in-excel/","classes":{"dataset":0.467111975}}
{"title":"12 Years Without Advertisements","description":"https://willfennel.com/posts/2023/01/26/12-years-without-advertisements.html","link":"https://willfennel.com/posts/2023/01/26/12-years-without-advertisements.html","created":"2023-01-26","tags":["hackernews"],"meta":{"score":8},"text":"12 Years Without Advertisements https://willfennel.com/posts/2023/01/26/12-years-without-advertisements.html","classes":{"dataset":0.4757987559}}
{"title":"On Alec Baldwin\u2019s Shooting","description":"https://www.schneier.com/blog/archives/2023/01/on-alec-baldwins-shooting.html","link":"https://www.schneier.com/blog/archives/2023/01/on-alec-baldwins-shooting.html","created":"2023-01-26","tags":["hackernews"],"meta":{"score":7},"text":"On Alec Baldwin\u2019s Shooting https://www.schneier.com/blog/archives/2023/01/on-alec-baldwins-shooting.html","classes":{"dataset":0.4878337085}}
{"title":"Sound travels further in cold weather (2019)","description":"https://blog.weatherops.com/sound-travels-further-in-cold-weather-heres-why","link":"https://blog.weatherops.com/sound-travels-further-in-cold-weather-heres-why","created":"2023-01-26","tags":["hackernews"],"meta":{"score":28},"text":"Sound travels further in cold weather (2019) https://blog.weatherops.com/sound-travels-further-in-cold-weather-heres-why","classes":{"dataset":0.4547149241}}
{"title":"Jetnet Acquires ADS-B Exchange, a community-fed ADSB aggregator","description":"https://www.jetnet.com/news/jetnet-acquires-ads-b-exchange.html","link":"https://www.jetnet.com/news/jetnet-acquires-ads-b-exchange.html","created":"2023-01-25","tags":["hackernews"],"meta":{"score":266},"text":"Jetnet Acquires ADS-B Exchange, a community-fed ADSB aggregator https://www.jetnet.com/news/jetnet-acquires-ads-b-exchange.html","classes":{"dataset":0.5105008483}}
{"title":"Aliens haven't contacted Earth because there's no sign of intelligence here","description":"https://iopscience.iop.org/article/10.3847/1538-4357/ac9e00","link":"https://iopscience.iop.org/article/10.3847/1538-4357/ac9e00","created":"2023-01-26","tags":["hackernews"],"meta":{"score":5},"text":"Aliens haven't contacted Earth because there's no sign of intelligence here https://iopscience.iop.org/article/10.3847/1538-4357/ac9e00","classes":{"dataset":0.4713360071}}
{"title":"Antidepressants help bacteria resist antibiotics: study","description":"https://www.nature.com/articles/d41586-023-00186-y","link":"https://www.nature.com/articles/d41586-023-00186-y","created":"2023-01-25","tags":["hackernews"],"meta":{"score":303},"text":"Antidepressants help bacteria resist antibiotics: study https://www.nature.com/articles/d41586-023-00186-y","classes":{"dataset":0.460072577}}
{"title":"Show HN: Automatisch \u2013 Open source workflow automation, an alternative to Zapier","description":"https://automatisch.io","link":"https://automatisch.io","created":"2023-01-25","tags":["hackernews"],"meta":{"score":296},"text":"Show HN: Automatisch \u2013 Open source workflow automation, an alternative to Zapier https://automatisch.io","classes":{"dataset":0.4827950895}}
{"title":"What we look for in a resume","description":"https://huyenchip.com/2023/01/24/what-we-look-for-in-a-candidate.html","link":"https://huyenchip.com/2023/01/24/what-we-look-for-in-a-candidate.html","created":"2023-01-25","tags":["hackernews"],"meta":{"score":349},"text":"What we look for in a resume https://huyenchip.com/2023/01/24/what-we-look-for-in-a-candidate.html","classes":{"dataset":0.5216377974}}
{"title":"Mjolnir","description":"https://fabiensanglard.net/mjolnir/index.html","link":"https://fabiensanglard.net/mjolnir/index.html","created":"2023-01-25","tags":["hackernews"],"meta":{"score":347},"text":"Mjolnir https://fabiensanglard.net/mjolnir/index.html","classes":{"dataset":0.5076003075}}
{"title":"The Night Watch (2013) [pdf]","description":"https://www.usenix.org/system/files/1311_05-08_mickens.pdf","link":"https://www.usenix.org/system/files/1311_05-08_mickens.pdf","created":"2023-01-25","tags":["hackernews"],"meta":{"score":128},"text":"The Night Watch (2013) [pdf] https://www.usenix.org/system/files/1311_05-08_mickens.pdf","classes":{"dataset":0.5155987144}}
{"title":"Amazon has radically transformed small businesses in both the U.S. and China","description":"https://www.semafor.com/article/01/25/2023/how-amazon-turned-small-businesses-into-day-traders","link":"https://www.semafor.com/article/01/25/2023/how-amazon-turned-small-businesses-into-day-traders","created":"2023-01-25","tags":["hackernews"],"meta":{"score":178},"text":"Amazon has radically transformed small businesses in both the U.S. and China https://www.semafor.com/article/01/25/2023/how-amazon-turned-small-businesses-into-day-traders","classes":{"dataset":0.507349968}}
{"title":"Show HN: A tool to design and run user state machines","description":"https://www.dopt.com/","link":"https://www.dopt.com/","created":"2023-01-26","tags":["hackernews"],"meta":{"score":55},"text":"Show HN: A tool to design and run user state machines https://www.dopt.com/","classes":{"dataset":0.4817399383}}
{"title":"Building the perfect memory bandwidth beast","description":"https://www.nextplatform.com/2023/01/24/building-the-perfect-memory-bandwidth-beast/","link":"https://www.nextplatform.com/2023/01/24/building-the-perfect-memory-bandwidth-beast/","created":"2023-01-25","tags":["hackernews"],"meta":{"score":38},"text":"Building the perfect memory bandwidth beast https://www.nextplatform.com/2023/01/24/building-the-perfect-memory-bandwidth-beast/","classes":{"dataset":0.4649565816}}
{"title":"Magnetoactive liquid-solid phase transitional matter","description":"https://www.cell.com/matter/fulltext/S2590-2385(22)00693-2","link":"https://www.cell.com/matter/fulltext/S2590-2385(22)00693-2","created":"2023-01-25","tags":["hackernews"],"meta":{"score":31},"text":"Magnetoactive liquid-solid phase transitional matter https://www.cell.com/matter/fulltext/S2590-2385(22)00693-2","classes":{"dataset":0.4792929292}}
{"title":"CamelCase vs. underscores revisited (2013)","description":"https://whatheco.de/2013/02/16/camelcase-vs-underscores-revisited/","link":"https://whatheco.de/2013/02/16/camelcase-vs-underscores-revisited/","created":"2023-01-25","tags":["hackernews"],"meta":{"score":93},"text":"CamelCase vs. underscores revisited (2013) https://whatheco.de/2013/02/16/camelcase-vs-underscores-revisited/","classes":{"dataset":0.5233071446}}
{"title":"Show HN: A simple world flags game, my first web dev project as a beginner","description":"https://billywojcicki.github.io/vexillologist/","link":"https://billywojcicki.github.io/vexillologist/","created":"2023-01-25","tags":["hackernews"],"meta":{"score":231},"text":"Show HN: A simple world flags game, my first web dev project as a beginner https://billywojcicki.github.io/vexillologist/","classes":{"dataset":0.543756187}}
{"title":"Pixel watch charger burned and melted my watch","description":"https://old.reddit.com/r/PixelWatch/comments/10l808u/pixel_watch_charger_burned_and_melted_my_watch/","link":"https://old.reddit.com/r/PixelWatch/comments/10l808u/pixel_watch_charger_burned_and_melted_my_watch/","created":"2023-01-26","tags":["hackernews"],"meta":{"score":19},"text":"Pixel watch charger burned and melted my watch https://old.reddit.com/r/PixelWatch/comments/10l808u/pixel_watch_charger_burned_and_melted_my_watch/","classes":{"dataset":0.4652583599}}
{"title":"The audacity of Apple Podcasts","description":"https://basta.substack.com/p/the-absolute-audacity-of-apple-podcasts","link":"https://basta.substack.com/p/the-absolute-audacity-of-apple-podcasts","created":"2023-01-25","tags":["hackernews"],"meta":{"score":384},"text":"The audacity of Apple Podcasts https://basta.substack.com/p/the-absolute-audacity-of-apple-podcasts","classes":{"dataset":0.5209096074}}
{"title":"The Subtle Art of the Changelog","description":"https://www.commandbar.com/blog/the-art-of-the-changelog","link":"https://www.commandbar.com/blog/the-art-of-the-changelog","created":"2023-01-25","tags":["hackernews"],"meta":{"score":91},"text":"The Subtle Art of the Changelog https://www.commandbar.com/blog/the-art-of-the-changelog","classes":{"dataset":0.4962885082}}
{"title":"The Gaucho Western","description":"https://www.laphamsquarterly.org/roundtable/gaucho-western","link":"https://www.laphamsquarterly.org/roundtable/gaucho-western","created":"2023-01-24","tags":["hackernews"],"meta":{"score":17},"text":"The Gaucho Western https://www.laphamsquarterly.org/roundtable/gaucho-western","classes":{"dataset":0.5268070102}}
{"title":"ASML Q4 2022 financial results","description":"https://www.asml.com/en/news/press-releases/2023/q4-2022-financial-results","link":"https://www.asml.com/en/news/press-releases/2023/q4-2022-financial-results","created":"2023-01-25","tags":["hackernews"],"meta":{"score":78},"text":"ASML Q4 2022 financial results https://www.asml.com/en/news/press-releases/2023/q4-2022-financial-results","classes":{"dataset":0.507349968}}
{"title":"Calling Ruby Methods in C: Avoid Memory Leaks","description":"https://blog.appsignal.com/2023/01/25/calling-ruby-methods-in-c-avoid-memory-leaks.html","link":"https://blog.appsignal.com/2023/01/25/calling-ruby-methods-in-c-avoid-memory-leaks.html","created":"2023-01-25","tags":["hackernews"],"meta":{"score":61},"text":"Calling Ruby Methods in C: Avoid Memory Leaks https://blog.appsignal.com/2023/01/25/calling-ruby-methods-in-c-avoid-memory-leaks.html","classes":{"dataset":0.5083708167}}
{"title":"What literature do we study from the 90s?","description":"https://pudding.cool/2023/01/lit-canon/","link":"https://pudding.cool/2023/01/lit-canon/","created":"2023-01-25","tags":["hackernews"],"meta":{"score":20},"text":"What literature do we study from the 90s? https://pudding.cool/2023/01/lit-canon/","classes":{"dataset":0.5242416859}}
{"title":"Similar Image Search (2021)","description":"https://blog.qwertyforce.dev/posts/similar_image_search","link":"https://blog.qwertyforce.dev/posts/similar_image_search","created":"2023-01-25","tags":["hackernews"],"meta":{"score":26},"text":"Similar Image Search (2021) https://blog.qwertyforce.dev/posts/similar_image_search","classes":{"dataset":0.5212213397}}
{"title":"Amazon warehouse workers stage first-ever strike in the UK","description":"https://www.cnbc.com/2023/01/25/amazon-workers-stage-first-ever-strike-in-the-uk-over-pay-working-conditions.html","link":"https://www.cnbc.com/2023/01/25/amazon-workers-stage-first-ever-strike-in-the-uk-over-pay-working-conditions.html","created":"2023-01-25","tags":["hackernews"],"meta":{"score":251},"text":"Amazon warehouse workers stage first-ever strike in the UK https://www.cnbc.com/2023/01/25/amazon-workers-stage-first-ever-strike-in-the-uk-over-pay-working-conditions.html","classes":{"dataset":0.500867784}}
{"title":"How do you test efficacy of prompts?","description":"Hello,\n\nI have been playing around with GPT-3 and am getting to the point where I want to optimize my prompts for the best results. I waffle between different versions and don't know whether my results are actually better or not with each tweak. How do people go about assessing this?\n\nThank you!","link":"https://www.reddit.com/r/PromptDesign/comments/10jw6c2/how_do_you_test_efficacy_of_prompts/","created":"2023-01-24","tags":["prompteng","reddit","promptdesign"],"meta":{"num_comments":2},"text":"How do you test efficacy of prompts? Hello,\n\nI have been playing around with GPT-3 and am getting to the point where I want to optimize my prompts for the best results. I waffle between different versions and don't know whether my results are actually better or not with each tweak. How do people go about assessing this?\n\nThank you!","classes":{"dataset":0.4569429457}}
{"title":"Thursday Daily Thread: Python Careers, Courses, and Furthering Education!","description":"Discussion of using Python in a professional environment, getting jobs in Python as well as ask questions about courses to further your python education!\n\n**This thread is not for recruitment, please see** r/PythonJobs **or the thread in the sidebar for that.**","link":"https://www.reddit.com/r/Python/comments/10ldw83/thursday_daily_thread_python_careers_courses_and/","created":"2023-01-26","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Thursday Daily Thread: Python Careers, Courses, and Furthering Education! Discussion of using Python in a professional environment, getting jobs in Python as well as ask questions about courses to further your python education!\n\n**This thread is not for recruitment, please see** r/PythonJobs **or the thread in the sidebar for that.**","classes":{"dataset":0.3617350757}}
{"title":"The Ultimate Coding Pal","description":"Hey fellas \ud83d\udc4b\n\nI wrote [CodePal.ai](https://CodePal.ai) \\- A free AI-powered service that provides many coding tools for coders and non-coders to make their life easier. It can [code](https://codepal.ai/), [review code](https://codepal.ai/code-reviewer), [simplify code](https://codepal.ai/code-simplifier), [find bugs](https://codepal.ai/bug-detector), and many more cool features.\n\nMy mission is to make coding easier, more accessible and fun for coders and non-coders.\n\nI use this myself to perfect my code pretty often and I find it handy in many cases.\n\nI've put many hours into this and would love to hear your feedback on it \u2764\ufe0f\n\nThank you!","link":"https://www.reddit.com/r/Python/comments/10lt530/the_ultimate_coding_pal/","created":"2023-01-26","tags":["reddit","python"],"meta":{"num_comments":6},"text":"The Ultimate Coding Pal Hey fellas \ud83d\udc4b\n\nI wrote [CodePal.ai](https://CodePal.ai) \\- A free AI-powered service that provides many coding tools for coders and non-coders to make their life easier. It can [code](https://codepal.ai/), [review code](https://codepal.ai/code-reviewer), [simplify code](https://codepal.ai/code-simplifier), [find bugs](https://codepal.ai/bug-detector), and many more cool features.\n\nMy mission is to make coding easier, more accessible and fun for coders and non-coders.\n\nI use this myself to perfect my code pretty often and I find it handy in many cases.\n\nI've put many hours into this and would love to hear your feedback on it \u2764\ufe0f\n\nThank you!","classes":{"dataset":0.3312750757}}
{"title":"Interactive plots","description":"I've been using seaborn to generate visualizations for various datasets and can say I absolutely love it.  There's really very few things I cannot visualize with it.  I've recently had a need for interactive visualizations, like a dashboard.  I went pretty far into the usage of dash and plotly.  It's ok, but is very awkward in how it handles cascading/dependent drop downs and it's also annoying I cannot re-use my seaborn code to generate plots, so I basically re-write everything.  What I'm wondering is if there's a way to utilize seaborn code to generate visualizations that can be interacted with?  The closest thing I've found (or read about) is creating a jupyter notebook and embedding that as a web page which can have sliders, buttons, etc... through ipywidgets.  Just reaching out to this community to see if I'm missing something or if anyone has had any experience with ipywidgets or other similar solutions.","link":"https://www.reddit.com/r/Python/comments/10lq9h0/interactive_plots/","created":"2023-01-26","tags":["reddit","python"],"meta":{"num_comments":8},"text":"Interactive plots I've been using seaborn to generate visualizations for various datasets and can say I absolutely love it.  There's really very few things I cannot visualize with it.  I've recently had a need for interactive visualizations, like a dashboard.  I went pretty far into the usage of dash and plotly.  It's ok, but is very awkward in how it handles cascading/dependent drop downs and it's also annoying I cannot re-use my seaborn code to generate plots, so I basically re-write everything.  What I'm wondering is if there's a way to utilize seaborn code to generate visualizations that can be interacted with?  The closest thing I've found (or read about) is creating a jupyter notebook and embedding that as a web page which can have sliders, buttons, etc... through ipywidgets.  Just reaching out to this community to see if I'm missing something or if anyone has had any experience with ipywidgets or other similar solutions.","classes":{"dataset":0.3690190613}}
{"title":"Earth Moon Model Tabletop Digital Art Python Project Combines a Raspberry Pi Computer with Sensors and Actuators to Create a Realistic Model of the Earth and the Moon in their orbits.","description":"GitHub repo: [https://github.com/ebarlas/earth-moon-model](https://github.com/ebarlas/earth-moon-model)\n\nhttps://reddit.com/link/10lsra6/video/hnhh3t01beea1/player","link":"https://www.reddit.com/r/Python/comments/10lsra6/earth_moon_model_tabletop_digital_art_python/","created":"2023-01-26","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Earth Moon Model Tabletop Digital Art Python Project Combines a Raspberry Pi Computer with Sensors and Actuators to Create a Realistic Model of the Earth and the Moon in their orbits. GitHub repo: [https://github.com/ebarlas/earth-moon-model](https://github.com/ebarlas/earth-moon-model)\n\nhttps://reddit.com/link/10lsra6/video/hnhh3t01beea1/player","classes":{"dataset":0.3545807004}}
{"title":"Replace JupyterHub with a simple FastAPI app to manage notebooks on Kubernetes","description":"Hello,  \n\n\nI just open-sourced a tool to manage Jupyter notebooks on Kubernetes without JupyterHub and its burden.\n\nnotebook-on-kube is a straightforward FeastAPI application that relies on existing tools/features of the Kubernetes ecosystem (Helm, RBAC, ingress-nginx, HPA, Prometheus metrics), learn more about it at https://github.com/machine424/notebook-on-kube, give it a try and let me know :)","link":"https://www.reddit.com/r/Python/comments/10ltpbe/replace_jupyterhub_with_a_simple_fastapi_app_to/","created":"2023-01-26","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Replace JupyterHub with a simple FastAPI app to manage notebooks on Kubernetes Hello,  \n\n\nI just open-sourced a tool to manage Jupyter notebooks on Kubernetes without JupyterHub and its burden.\n\nnotebook-on-kube is a straightforward FeastAPI application that relies on existing tools/features of the Kubernetes ecosystem (Helm, RBAC, ingress-nginx, HPA, Prometheus metrics), learn more about it at https://github.com/machine424/notebook-on-kube, give it a try and let me know :)","classes":{"dataset":0.3987555504}}
{"title":"JSON Database","description":"Hi! I've worked on a simple Key-Value database, it uses JSON. It accepts threads and it's fail-safe... also it's only 103 lines of code.\n\nIt's based on SonaDB, which was a Key-Value database but based on Pickle (Which is insecure, so Sona was). Also accepts queries, using callables, which are faster than evals and let more complex queries.\n\n[https://github.com/ZSendokame/LiliDB](https://github.com/ZSendokame/LiliDB)\n\n    import lilidb\n    \n    database = lilidb.Database('database.json')\n    \n    database.set('key', 'value', algo='md5')  # Accepts encryption algorithms to hash values.\n    database.get('key')  # 2063c1608d6e0baf80249c42e2be5804\n    database.rename('renamed_key')\n    database.remove('renamed_key')\n    database.query(lambda key, value: value == 'value')  # Returns iterable.\n    \n    with database:\n        database.set('with', 'it has \"Context Manager\", it will close and dump data.')\n    \n    database.dump()  # If you want to save manually.\n    database.close()  # If you also wants to close it manually.","link":"https://www.reddit.com/r/Python/comments/10lrw3q/json_database/","created":"2023-01-26","tags":["reddit","python"],"meta":{"num_comments":1},"text":"JSON Database Hi! I've worked on a simple Key-Value database, it uses JSON. It accepts threads and it's fail-safe... also it's only 103 lines of code.\n\nIt's based on SonaDB, which was a Key-Value database but based on Pickle (Which is insecure, so Sona was). Also accepts queries, using callables, which are faster than evals and let more complex queries.\n\n[https://github.com/ZSendokame/LiliDB](https://github.com/ZSendokame/LiliDB)\n\n    import lilidb\n    \n    database = lilidb.Database('database.json')\n    \n    database.set('key', 'value', algo='md5')  # Accepts encryption algorithms to hash values.\n    database.get('key')  # 2063c1608d6e0baf80249c42e2be5804\n    database.rename('renamed_key')\n    database.remove('renamed_key')\n    database.query(lambda key, value: value == 'value')  # Returns iterable.\n    \n    with database:\n        database.set('with', 'it has \"Context Manager\", it will close and dump data.')\n    \n    database.dump()  # If you want to save manually.\n    database.close()  # If you also wants to close it manually.","classes":{"dataset":0.4277117848}}
{"title":"Alternatives to Makefile for Python","description":"What are some good Makefile alternatives for python projects?\n\nI am mainly using make in my python projects to (1) have a shortcut to longer commands like installing dependencies or formatting the code (2) running scripts in order and only from a point where its required. For example I might have three scripts that run on top of each other each producing an output file. However, if the source code for the first script has not changed, it would not need to be run again. Using make dependencies that works quite nicely. However, what is quite annoying in make is that there seems to be no nice way of passing command line arguments to a script. Therefore, I am looking for an alternative. What tools do you use in your python project for similar usecases?","link":"https://www.reddit.com/r/Python/comments/10kvfat/alternatives_to_makefile_for_python/","created":"2023-01-25","tags":["reddit","python"],"meta":{"num_comments":53},"text":"Alternatives to Makefile for Python What are some good Makefile alternatives for python projects?\n\nI am mainly using make in my python projects to (1) have a shortcut to longer commands like installing dependencies or formatting the code (2) running scripts in order and only from a point where its required. For example I might have three scripts that run on top of each other each producing an output file. However, if the source code for the first script has not changed, it would not need to be run again. Using make dependencies that works quite nicely. However, what is quite annoying in make is that there seems to be no nice way of passing command line arguments to a script. Therefore, I am looking for an alternative. What tools do you use in your python project for similar usecases?","classes":{"dataset":0.438382566}}
{"title":"Free python course needed for beginners\u2026.plz tell where I can find one?","description":"","link":"https://www.reddit.com/r/Python/comments/10ls9n9/free_python_course_needed_for_beginnersplz_tell/","created":"2023-01-26","tags":["reddit","python"],"meta":{"num_comments":19},"text":"Free python course needed for beginners\u2026.plz tell where I can find one? ","classes":{"dataset":0.4110485017}}
{"title":"Made a generator tool of these 3D-Print-ready models","description":"I made a tool allows you to easily convert any image into a 3D print-ready STL model. The surface of the model will display the image when illuminated from the left side.\n\nsource: https://github.com/CreepyMemes/ImageToSTL\n\n[All made in python as a single easy to use tool with UI](https://i.redd.it/qkdqg3gxk6ea1.gif)","link":"https://www.reddit.com/r/Python/comments/10kxa9o/made_a_generator_tool_of_these_3dprintready_models/","created":"2023-01-25","tags":["reddit","python"],"meta":{"num_comments":0},"text":"Made a generator tool of these 3D-Print-ready models I made a tool allows you to easily convert any image into a 3D print-ready STL model. The surface of the model will display the image when illuminated from the left side.\n\nsource: https://github.com/CreepyMemes/ImageToSTL\n\n[All made in python as a single easy to use tool with UI](https://i.redd.it/qkdqg3gxk6ea1.gif)","classes":{"dataset":0.3451646268}}
{"title":"Which is your go to framework for deep learning, in python","description":"Just trying to see people's opinions. Both are good frameworks and I find both have their own pros and cons.\n\nEven though ultimately it's about the concepts/architecture/methodologies of the model that's key, what's your preferred implementation tool ?\n\n[View Poll](https://www.reddit.com/poll/10ludw6)","link":"https://www.reddit.com/r/deeplearning/comments/10ludw6/which_is_your_go_to_framework_for_deep_learning/","created":"2023-01-26","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"Which is your go to framework for deep learning, in python Just trying to see people's opinions. Both are good frameworks and I find both have their own pros and cons.\n\nEven though ultimately it's about the concepts/architecture/methodologies of the model that's key, what's your preferred implementation tool ?\n\n[View Poll](https://www.reddit.com/poll/10ludw6)","classes":{"dataset":0.3041584194}}
{"title":"ImageNet Advise","description":"I've gotten to the point in my PhD career to where I have some really good CNN model variants, on CIFAR10, CIFAR100, and some other datasets (Flowers,Cars, Caltech). We wish to apply to NeurIPS this Spring, deadline around May 13. However, it seems that to have a chance at getting accepted at top conferences, NeurIPS, ICCV, etc, reviewers are looking at results on ImageNet2012.\n\nThe problem being, my university does not have a lot of resources available. Granted, we have 2 40GB A100 GPUs available, but these are shared within the entire university. From my estimate, using both A100 GPUs will allow us to use a batch size around 256 when testing our final model, containing 22 million parameters, at a max image size of 300. I do not know how long this will take to train, but I expect it to take about 4 days for 300 epochs at a total of 105,000 steps. Unfortunately, we have about 6 of these models (variants) to test (no way to cut it down). Equating to roughly 24 full days worth of computation on 2 A100 GPUS (which has about a 50/50% chance of finishing by May, given wait times in queue). We definitely don't have the computation to run each one 3 times to obtain a mean, so our results will be based off one training session.\n\nI know there are ImageNet derivative datasets, such as TinyImageNet (which scales all images to 64x64) or  ImageNet100 (which only contains 100 classes). I believe I can definitely obtain results for either of these datasets within the given time frame.\n\n&amp;#x200B;\n\nQuestion: For top conferences focused on CNNs and deep learning, are ImageNet results that influential? Are these smaller ImageNet derivative datasets even worth training upon rather than testing upon standard ImageNet (Note: these smaller datasets still take a long time to train)?","link":"https://www.reddit.com/r/deeplearning/comments/10lkgwp/imagenet_advise/","created":"2023-01-26","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":4},"text":"ImageNet Advise I've gotten to the point in my PhD career to where I have some really good CNN model variants, on CIFAR10, CIFAR100, and some other datasets (Flowers,Cars, Caltech). We wish to apply to NeurIPS this Spring, deadline around May 13. However, it seems that to have a chance at getting accepted at top conferences, NeurIPS, ICCV, etc, reviewers are looking at results on ImageNet2012.\n\nThe problem being, my university does not have a lot of resources available. Granted, we have 2 40GB A100 GPUs available, but these are shared within the entire university. From my estimate, using both A100 GPUs will allow us to use a batch size around 256 when testing our final model, containing 22 million parameters, at a max image size of 300. I do not know how long this will take to train, but I expect it to take about 4 days for 300 epochs at a total of 105,000 steps. Unfortunately, we have about 6 of these models (variants) to test (no way to cut it down). Equating to roughly 24 full days worth of computation on 2 A100 GPUS (which has about a 50/50% chance of finishing by May, given wait times in queue). We definitely don't have the computation to run each one 3 times to obtain a mean, so our results will be based off one training session.\n\nI know there are ImageNet derivative datasets, such as TinyImageNet (which scales all images to 64x64) or  ImageNet100 (which only contains 100 classes). I believe I can definitely obtain results for either of these datasets within the given time frame.\n\n&amp;#x200B;\n\nQuestion: For top conferences focused on CNNs and deep learning, are ImageNet results that influential? Are these smaller ImageNet derivative datasets even worth training upon rather than testing upon standard ImageNet (Note: these smaller datasets still take a long time to train)?","classes":{"dataset":0.4410823286}}
{"title":"best deep learning reference","description":"Hi! I am an aspiring deep learning engineer and I'm looking for best/highly recommended courses/reference in studying deep learning from basic to advanced topics.","link":"https://www.reddit.com/r/deeplearning/comments/10lh5yr/best_deep_learning_reference/","created":"2023-01-26","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"best deep learning reference Hi! I am an aspiring deep learning engineer and I'm looking for best/highly recommended courses/reference in studying deep learning from basic to advanced topics.","classes":{"dataset":0.4513377249}}
{"title":"Classify dataset with only 100 images?","description":"Hello Guys,\n\ni am writing a thesis in a company about Image Classification with Convolutional neural networks. The Images Contain a part of a microship, where a crack is visible or if the microchip is okay, then not. How can i build a CNN with such a small dataset? Is that even possible? I thought about maybe using datasets with cracks from the internet, add a image threshold and train my network with them. But i also read about pre-trained neural networks.. Are they maybe a option too?","link":"https://www.reddit.com/r/deeplearning/comments/10l06xg/classify_dataset_with_only_100_images/","created":"2023-01-25","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":10},"text":"Classify dataset with only 100 images? Hello Guys,\n\ni am writing a thesis in a company about Image Classification with Convolutional neural networks. The Images Contain a part of a microship, where a crack is visible or if the microchip is okay, then not. How can i build a CNN with such a small dataset? Is that even possible? I thought about maybe using datasets with cracks from the internet, add a image threshold and train my network with them. But i also read about pre-trained neural networks.. Are they maybe a option too?","classes":{"dataset":0.4970943332}}
{"title":"Best cloud to train models with 100-200 GB of data?","description":"So I've been wondering for a while if maybe I should get a 4090, or if I should just use AWS or something.\n\nFor context: I work at a tech company and we use tensorflow/pytorch so I have a decent experience with that. I have used mostly AWS  to train and test things. The problem is, in my experience, moving data from S3 to Sagemaker is a pain in the ass, and I have only used like 1-2 GB of data, mostly tabular data.\n\nNow I want to test a few things myself, train some image models. I've been playing with some models and I got 100 GB of data that I want to fit a model with. I have tried with Colab and the data in google drive, but drive gets confused with multiple files so it's really annoying.\n\nAny suggestions on how to do this in the cloud? I also have some experience with GCP and Azure, but AWS is the provider I have the most experience with. Can I do this without suffering too much when handling data around or should I just buy a 4090 and train stuff locally?","link":"https://www.reddit.com/r/deeplearning/comments/10khmxo/best_cloud_to_train_models_with_100200_gb_of_data/","created":"2023-01-24","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":11},"text":"Best cloud to train models with 100-200 GB of data? So I've been wondering for a while if maybe I should get a 4090, or if I should just use AWS or something.\n\nFor context: I work at a tech company and we use tensorflow/pytorch so I have a decent experience with that. I have used mostly AWS  to train and test things. The problem is, in my experience, moving data from S3 to Sagemaker is a pain in the ass, and I have only used like 1-2 GB of data, mostly tabular data.\n\nNow I want to test a few things myself, train some image models. I've been playing with some models and I got 100 GB of data that I want to fit a model with. I have tried with Colab and the data in google drive, but drive gets confused with multiple files so it's really annoying.\n\nAny suggestions on how to do this in the cloud? I also have some experience with GCP and Azure, but AWS is the provider I have the most experience with. Can I do this without suffering too much when handling data around or should I just buy a 4090 and train stuff locally?","classes":{"dataset":0.3671212196}}
{"title":"What are the best ways to learn about deep learning?","description":"Starting a group project in college about \"Brain tumor segmentation using deep learning\" and searching for a summer internship in the subject. I usually approach a new area by looking at youtube videos, looking at some slides from teachers, and perhaps testing simpler code examples. We were now told to research the field for two weeks prior to starting and hence I'm searching for recommendations to effectively learn to be able to contribute to the project. \n\nLooking for any tips like websites (just found Kaggle for an example), threads, code, channels, methods, topics to focus/prioritize, frameworks to prefer/avoid,  articles, books etc.\n\n**Skills:** Intermediate Python/c++, 3rd year MSc, little-to-no knowledge about machine learning.\n\n**Resources:** Slides, An \"expert\" (PhD from college), eight group members, RTX 3060 Ti (and Azure hours later).","link":"https://www.reddit.com/r/deeplearning/comments/10k2cnt/what_are_the_best_ways_to_learn_about_deep/","created":"2023-01-24","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":13},"text":"What are the best ways to learn about deep learning? Starting a group project in college about \"Brain tumor segmentation using deep learning\" and searching for a summer internship in the subject. I usually approach a new area by looking at youtube videos, looking at some slides from teachers, and perhaps testing simpler code examples. We were now told to research the field for two weeks prior to starting and hence I'm searching for recommendations to effectively learn to be able to contribute to the project. \n\nLooking for any tips like websites (just found Kaggle for an example), threads, code, channels, methods, topics to focus/prioritize, frameworks to prefer/avoid,  articles, books etc.\n\n**Skills:** Intermediate Python/c++, 3rd year MSc, little-to-no knowledge about machine learning.\n\n**Resources:** Slides, An \"expert\" (PhD from college), eight group members, RTX 3060 Ti (and Azure hours later).","classes":{"dataset":0.4966168106}}
{"title":"Neural Rendering: Tumwater, WA Reconstructed By a Beta Tester!","description":"Video shows 3D reconstruction and a neural render created by a beta tester who captured the city of Tumwater, WA.\n\nLearn more and apply for beta: [https://www.citysynth.ai/](https://www.citysynth.ai/)\n\nhttps://reddit.com/link/10jnz34/video/jwcfbu0p1vda1/player","link":"https://www.reddit.com/r/deeplearning/comments/10jnz34/neural_rendering_tumwater_wa_reconstructed_by_a/","created":"2023-01-23","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"Neural Rendering: Tumwater, WA Reconstructed By a Beta Tester! Video shows 3D reconstruction and a neural render created by a beta tester who captured the city of Tumwater, WA.\n\nLearn more and apply for beta: [https://www.citysynth.ai/](https://www.citysynth.ai/)\n\nhttps://reddit.com/link/10jnz34/video/jwcfbu0p1vda1/player","classes":{"dataset":0.1807208955}}
{"title":"What is the difference between Causal LM and Text Generation?","description":"Hi,\n\nI am new to DL. I see on Hugging Face that it separates text generation and causal LM. But it seems both are similar in that they accept a prompt that starts you off and finishes it for you depending on how many more tokens you would like. \n\nIs the difference purely an issue of one being more creative than the other? What does that mean for training?\n\nAlso, do the dataset structure for something like GPT-J typically differ between the two and say, question-answering models?","link":"https://www.reddit.com/r/deeplearning/comments/10jkz9k/what_is_the_difference_between_causal_lm_and_text/","created":"2023-01-23","tags":["reddit","ml","deeplearning"],"meta":{"num_comments":0},"text":"What is the difference between Causal LM and Text Generation? Hi,\n\nI am new to DL. I see on Hugging Face that it separates text generation and causal LM. But it seems both are similar in that they accept a prompt that starts you off and finishes it for you depending on how many more tokens you would like. \n\nIs the difference purely an issue of one being more creative than the other? What does that mean for training?\n\nAlso, do the dataset structure for something like GPT-J typically differ between the two and say, question-answering models?","classes":{"dataset":0.5272496939}}
{"title":"[R] Blogpost on comparing Chatbots like ChatGPT, LaMDA, Sparrow, BlenderBot 3, and Claude","description":"[https://huggingface.co/blog/dialog-agents](https://huggingface.co/blog/dialog-agents) breaks down the techniques behind ChatGPT -- instruction fine-tuning, supervised fine-tuning, chain-of-thought, read teaming, and more.\n\nhttps://preview.redd.it/fv16fsemd9ea1.png?width=889&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=bc723c4cc71ec0457bb1c2ac07f5fa6e4a3a4ccf","link":"https://www.reddit.com/r/MachineLearning/comments/10l9tet/r_blogpost_on_comparing_chatbots_like_chatgpt/","created":"2023-01-25","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":4},"text":"[R] Blogpost on comparing Chatbots like ChatGPT, LaMDA, Sparrow, BlenderBot 3, and Claude [https://huggingface.co/blog/dialog-agents](https://huggingface.co/blog/dialog-agents) breaks down the techniques behind ChatGPT -- instruction fine-tuning, supervised fine-tuning, chain-of-thought, read teaming, and more.\n\nhttps://preview.redd.it/fv16fsemd9ea1.png?width=889&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=bc723c4cc71ec0457bb1c2ac07f5fa6e4a3a4ccf","classes":{"dataset":0.63974154}}
{"title":"Are there any projects working at an open source version of Constitutional AI? [D]","description":"I'm looking into projects which augment the RLHF training approach of chatGPT with explicit rules, such as in [https://paperswithcode.com/paper/constitutional-ai-harmlessness-from-ai](https://paperswithcode.com/paper/constitutional-ai-harmlessness-from-ai). \n\nIdeally there would be both rules and priority levels between the rules, similarly to the Asimov laws of robotics. \n\nThe Open-Assistant project ([https://github.com/LAION-AI/Open-Assistant](https://github.com/LAION-AI/Open-Assistant)) captures the spirit, but it is looking to replicate chatGPT at the moment.","link":"https://www.reddit.com/r/MachineLearning/comments/10lui3i/are_there_any_projects_working_at_an_open_source/","created":"2023-01-26","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0},"text":"Are there any projects working at an open source version of Constitutional AI? [D] I'm looking into projects which augment the RLHF training approach of chatGPT with explicit rules, such as in [https://paperswithcode.com/paper/constitutional-ai-harmlessness-from-ai](https://paperswithcode.com/paper/constitutional-ai-harmlessness-from-ai). \n\nIdeally there would be both rules and priority levels between the rules, similarly to the Asimov laws of robotics. \n\nThe Open-Assistant project ([https://github.com/LAION-AI/Open-Assistant](https://github.com/LAION-AI/Open-Assistant)) captures the spirit, but it is looking to replicate chatGPT at the moment.","classes":{"dataset":0.0962002575}}
{"title":"[D] What are some of your favorite ML research posters?","description":"And what are your own best practices when creating one (e.g. adding a QR code that links to the GitHub project or paper PDF)?","link":"https://www.reddit.com/r/MachineLearning/comments/10lsirk/d_what_are_some_of_your_favorite_ml_research/","created":"2023-01-26","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0},"text":"[D] What are some of your favorite ML research posters? And what are your own best practices when creating one (e.g. adding a QR code that links to the GitHub project or paper PDF)?","classes":{"dataset":0.1675935239}}
{"title":"[D] Fastest and most accurate model for casing","description":"What is the state of the art regarding freely available casing models, i.e. DNNs, that try to restore the original casing of a text with uniform (either lowercase or capital letters) casing? I value both speed and accuracy, as I have to process a large corpus of text.","link":"https://www.reddit.com/r/MachineLearning/comments/10lqd34/d_fastest_and_most_accurate_model_for_casing/","created":"2023-01-26","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0},"text":"[D] Fastest and most accurate model for casing What is the state of the art regarding freely available casing models, i.e. DNNs, that try to restore the original casing of a text with uniform (either lowercase or capital letters) casing? I value both speed and accuracy, as I have to process a large corpus of text.","classes":{"dataset":0.3268289864}}
{"title":"Machine learning and black box numerical solver[D]","description":"Anybody know some methods and techniques for integrating a numerical solver with the neural network .. how do you calculate the gradients of the solver when you don\u2019t know the details of such solver- black box solver.","link":"https://www.reddit.com/r/MachineLearning/comments/10lka00/machine_learning_and_black_box_numerical_solverd/","created":"2023-01-26","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":5},"text":"Machine learning and black box numerical solver[D] Anybody know some methods and techniques for integrating a numerical solver with the neural network .. how do you calculate the gradients of the solver when you don\u2019t know the details of such solver- black box solver.","classes":{"dataset":0.303475976}}
{"title":"[D] Efficient retrieval of research information for graduate research","description":"I have lot of notes about research papers in a particular directory and the number of files has started to become larger than what I can remember off the top of my head. It will continue to keep growing and I have begun to wonder the most efficient way to retrieve the information. I could use ripgrep and regular expressions to find the notes efficiently, but I imagine that if the database is very huge and I don't have the correct regular expression in use, then I might not retrieve the correct files.\n\nInspired by chatGPT, I was impressed at how it presents info from the internet and speeds up my time for finding information even when I do not know the correct keywords. I figured a NLP model primarily trained on my database would be an easier task and I was wondering if someone had already created something like this as open source or how would they go about it?","link":"https://www.reddit.com/r/MachineLearning/comments/10l1a5s/d_efficient_retrieval_of_research_information_for/","created":"2023-01-25","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":9},"text":"[D] Efficient retrieval of research information for graduate research I have lot of notes about research papers in a particular directory and the number of files has started to become larger than what I can remember off the top of my head. It will continue to keep growing and I have begun to wonder the most efficient way to retrieve the information. I could use ripgrep and regular expressions to find the notes efficiently, but I imagine that if the database is very huge and I don't have the correct regular expression in use, then I might not retrieve the correct files.\n\nInspired by chatGPT, I was impressed at how it presents info from the internet and speeds up my time for finding information even when I do not know the correct keywords. I figured a NLP model primarily trained on my database would be an easier task and I was wondering if someone had already created something like this as open source or how would they go about it?","classes":{"dataset":0.2722572684}}
{"title":"[D] Alphatensor benchmark code in Colab","description":"Hello everybody\n\nI was wondering if anybody tried to run the main factorisation code [https://github.com/deepmind/alphatensor/blob/main/benchmarking/factorizations.py](https://github.com/deepmind/alphatensor/blob/main/benchmarking/factorizations.py) from alpha tensor on Google Colab, with Colab's GPUs ( Tesla T4).\n\nI know that Tesla T4 is not as the same as the V100 used in Deep Mind's paper, however, I can see that the tensor formulation for the matrix multiplication is highly inefficient, compared to standard JAX matrix multiplication.\n\nAny suggestion where am I wrong?","link":"https://www.reddit.com/r/MachineLearning/comments/10lc538/d_alphatensor_benchmark_code_in_colab/","created":"2023-01-25","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0},"text":"[D] Alphatensor benchmark code in Colab Hello everybody\n\nI was wondering if anybody tried to run the main factorisation code [https://github.com/deepmind/alphatensor/blob/main/benchmarking/factorizations.py](https://github.com/deepmind/alphatensor/blob/main/benchmarking/factorizations.py) from alpha tensor on Google Colab, with Colab's GPUs ( Tesla T4).\n\nI know that Tesla T4 is not as the same as the V100 used in Deep Mind's paper, however, I can see that the tensor formulation for the matrix multiplication is highly inefficient, compared to standard JAX matrix multiplication.\n\nAny suggestion where am I wrong?","classes":{"dataset":0.430142045}}
{"title":"[R] INSTRUCTOR One Embedder , Any Task: Instruction-Finetuned Text Embeddings Paper Explanation and Collab Demo","description":"In this video  I   explain about INSTRUCTOR, an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves sota on 70 diverse embedding tasks! I also show a google collab demo of instructor\n\nhttps://youtu.be/vg38cq3KJ6M","link":"https://www.reddit.com/r/MachineLearning/comments/10ksetd/r_instructor_one_embedder_any_task/","created":"2023-01-25","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":0},"text":"[R] INSTRUCTOR One Embedder , Any Task: Instruction-Finetuned Text Embeddings Paper Explanation and Collab Demo In this video  I   explain about INSTRUCTOR, an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves sota on 70 diverse embedding tasks! I also show a google collab demo of instructor\n\nhttps://youtu.be/vg38cq3KJ6M","classes":{"dataset":0.4717048109}}
{"title":"[D] CVPR Reviews are out","description":"Don't post about your cool papers or you'll get rejected lol","link":"https://www.reddit.com/r/MachineLearning/comments/10kbey9/d_cvpr_reviews_are_out/","created":"2023-01-24","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":63},"text":"[D] CVPR Reviews are out Don't post about your cool papers or you'll get rejected lol","classes":{"dataset":0.1212189868}}
{"title":"Can an AI model licensed under the BigScience RAIL License v1.0 such as BLOOM be used in a program that is useful for any domain? [D]","description":"Example: the AI model [BLOOM](https://en.wikipedia.org/wiki/BLOOM_(language_model)) is licensed under the [BigScience RAIL License v1.0](https://huggingface.co/spaces/bigscience/license). The BigScience RAIL License v1.0 forbids that some types of usages:\n\n&gt; You agree not to use the Model or Derivatives of the Model:\n&gt;\n&gt;  [...]\n&gt;\n&gt; - To provide medical advice and medical results interpretation;\n&gt; - To generate or disseminate information for the purpose to be used for administration of justice, law enforcement, immigration or asylum processes, such as predicting an individual will commit fraud/crime commitment (e.g. by text profiling, drawing causal relationships between assertions made in documents, indiscriminate and arbitrarily-targeted use).\n\nAm I allowed to use BLOOM in a program that is useful for any domain (e.g., a program to summarize or paraphrase some text, or perform question-answer on a text, or generate questions and their answers based on the text)? \n\nSince people could use the program for any domain, they could technically, for example, use the program to summarize a medical report or generate questions and their answers based on some asylum process to distribute to potential applicants.","link":"https://www.reddit.com/r/MachineLearning/comments/10kl8y9/can_an_ai_model_licensed_under_the_bigscience/","created":"2023-01-25","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":3},"text":"Can an AI model licensed under the BigScience RAIL License v1.0 such as BLOOM be used in a program that is useful for any domain? [D] Example: the AI model [BLOOM](https://en.wikipedia.org/wiki/BLOOM_(language_model)) is licensed under the [BigScience RAIL License v1.0](https://huggingface.co/spaces/bigscience/license). The BigScience RAIL License v1.0 forbids that some types of usages:\n\n&gt; You agree not to use the Model or Derivatives of the Model:\n&gt;\n&gt;  [...]\n&gt;\n&gt; - To provide medical advice and medical results interpretation;\n&gt; - To generate or disseminate information for the purpose to be used for administration of justice, law enforcement, immigration or asylum processes, such as predicting an individual will commit fraud/crime commitment (e.g. by text profiling, drawing causal relationships between assertions made in documents, indiscriminate and arbitrarily-targeted use).\n\nAm I allowed to use BLOOM in a program that is useful for any domain (e.g., a program to summarize or paraphrase some text, or perform question-answer on a text, or generate questions and their answers based on the text)? \n\nSince people could use the program for any domain, they could technically, for example, use the program to summarize a medical report or generate questions and their answers based on some asylum process to distribute to potential applicants.","classes":{"dataset":0.2245922834}}
{"title":"[P] tsdownsample: extremely fast time series downsampling for visualization","description":"tsdownsample brings highly optimized time series downsampling to Python! The downsampling algorithms are written and optimized in Rust, which are made available in Python through the use of PyO3 bindings.\n\nCode: [https://github.com/predict-idlab/tsdownsample](https://github.com/predict-idlab/tsdownsample)\n\n# Features\n\n* **Fast**: leverages the optimized [argminmax crate](https://github.com/jvdd/argminmax) which is SIMD accelerated with runtime feature detection (matches or even outperforms numpy's speed)\n* **Efficient**: operates on views of the data, eliminating the need for unnecessary data copies and avoiding the creation of intermediate data structures\n* **Flexible**: supports a wide range of datatypes, including [f16 which is 200-300x faster than numpy's implementation](https://github.com/jvdd/argminmax/pull/1).\n* **Easy to use**: simple and flexible API\n\n# Installation\n\n    pip install tsdownsample\n\n# Example\n\nWhen using multi-threading, tsdownsample can downsample 500 MILLION datapoints (f32) in 0.05s! \u2b07\ufe0f\n\nhttps://preview.redd.it/frqh8o2bezda1.png?width=1650&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0674cd6b681210d70d8f2e7a81b12415c880ea50\n\n&amp;#x200B;\n\nI would love to hear your feedback on this!","link":"https://www.reddit.com/r/MachineLearning/comments/10k48bz/p_tsdownsample_extremely_fast_time_series/","created":"2023-01-24","tags":["ml","machinelearning","reddit"],"meta":{"num_comments":3},"text":"[P] tsdownsample: extremely fast time series downsampling for visualization tsdownsample brings highly optimized time series downsampling to Python! The downsampling algorithms are written and optimized in Rust, which are made available in Python through the use of PyO3 bindings.\n\nCode: [https://github.com/predict-idlab/tsdownsample](https://github.com/predict-idlab/tsdownsample)\n\n# Features\n\n* **Fast**: leverages the optimized [argminmax crate](https://github.com/jvdd/argminmax) which is SIMD accelerated with runtime feature detection (matches or even outperforms numpy's speed)\n* **Efficient**: operates on views of the data, eliminating the need for unnecessary data copies and avoiding the creation of intermediate data structures\n* **Flexible**: supports a wide range of datatypes, including [f16 which is 200-300x faster than numpy's implementation](https://github.com/jvdd/argminmax/pull/1).\n* **Easy to use**: simple and flexible API\n\n# Installation\n\n    pip install tsdownsample\n\n# Example\n\nWhen using multi-threading, tsdownsample can downsample 500 MILLION datapoints (f32) in 0.05s! \u2b07\ufe0f\n\nhttps://preview.redd.it/frqh8o2bezda1.png?width=1650&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=0674cd6b681210d70d8f2e7a81b12415c880ea50\n\n&amp;#x200B;\n\nI would love to hear your feedback on this!","classes":{"dataset":0.3506318033}}
{"title":"How would you approach this kind of Info/Entity extraction problem?","description":"Training dataset is as follows:\nThree columns:\nText (unstructured)\nLeads counts (integer)\nConversion counts (integer)\n(That\u2019s not an actual case, it\u2019s an example.)\n\nFor a given article, either could be zero, or not present.\n\nLooking to train a model that, when given a new text, extracts Leads count and Conversion count.\n\nThose are not counted one by one, they should be extracted from sentences.\n\nFor instance, text may be:\n\n\n```\nOn Tuesday, there was a large industry convention. We spoke with 12 people who were interested in the product. Out of them, three people decided to buy it. All in all, it was a ten out of ten event. There is another one on February 23 that I\u2019m looking forward to.\n```\n\nModel should return leads=12, conversions=3.\n\n\nI think how I want it to function is something like:\nWhen encountered a number \nCheck that sentence and sentence before and after\nClassify as leads number, conversions number or neither.\n\nI started on doing fine tuned BERT similar to named entity recognition, but that feels like an overkill, feels like I should be able to go a little lighter.\n\nWhat do you think?","link":"https://www.reddit.com/r/LanguageTechnology/comments/10ldqyp/how_would_you_approach_this_kind_of_infoentity/","created":"2023-01-26","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":2},"text":"How would you approach this kind of Info/Entity extraction problem? Training dataset is as follows:\nThree columns:\nText (unstructured)\nLeads counts (integer)\nConversion counts (integer)\n(That\u2019s not an actual case, it\u2019s an example.)\n\nFor a given article, either could be zero, or not present.\n\nLooking to train a model that, when given a new text, extracts Leads count and Conversion count.\n\nThose are not counted one by one, they should be extracted from sentences.\n\nFor instance, text may be:\n\n\n```\nOn Tuesday, there was a large industry convention. We spoke with 12 people who were interested in the product. Out of them, three people decided to buy it. All in all, it was a ten out of ten event. There is another one on February 23 that I\u2019m looking forward to.\n```\n\nModel should return leads=12, conversions=3.\n\n\nI think how I want it to function is something like:\nWhen encountered a number \nCheck that sentence and sentence before and after\nClassify as leads number, conversions number or neither.\n\nI started on doing fine tuned BERT similar to named entity recognition, but that feels like an overkill, feels like I should be able to go a little lighter.\n\nWhat do you think?","classes":{"dataset":0.2072684765}}
{"title":"What is the largest model that can be feasibly trained on a RTX 4090 24GB?","description":"I am interested to hear what the largest model is that I can feasibly train on a single RTX 4090 24GB card. For sure the upper bound is a model of 24GB max. If we additionally take into account the additional RAM memory needed to do inference, loss back propagation etc, how large can we go? I understand this will also depend on the batch size, so let's fix that to 16 to have an explicit example. Does anyone have experience with training such a model and this card? What is the largest model you reached?\n\nAdditionally, if I have two RTX 4090 24GB cards, is it feasible to split the model over these two cards? Would this allow me to fit a model roughly twice as big as on one card, or is there significant overhead?\n\nI would appreciate any insight you have.","link":"https://www.reddit.com/r/LanguageTechnology/comments/10kxc0k/what_is_the_largest_model_that_can_be_feasibly/","created":"2023-01-25","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":6},"text":"What is the largest model that can be feasibly trained on a RTX 4090 24GB? I am interested to hear what the largest model is that I can feasibly train on a single RTX 4090 24GB card. For sure the upper bound is a model of 24GB max. If we additionally take into account the additional RAM memory needed to do inference, loss back propagation etc, how large can we go? I understand this will also depend on the batch size, so let's fix that to 16 to have an explicit example. Does anyone have experience with training such a model and this card? What is the largest model you reached?\n\nAdditionally, if I have two RTX 4090 24GB cards, is it feasible to split the model over these two cards? Would this allow me to fit a model roughly twice as big as on one card, or is there significant overhead?\n\nI would appreciate any insight you have.","classes":{"dataset":0.3456093371}}
{"title":"INSTRUCTOR instruction fine-tuned text embeddings","description":"In this video  I   explain about INSTRUCTOR, an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves sota on 70 diverse embedding tasks! I also show a google collab demo of instructor\n\nhttps://youtu.be/vg38cq3KJ6M","link":"https://www.reddit.com/r/LanguageTechnology/comments/10ksfhg/instructor_instruction_finetuned_text_embeddings/","created":"2023-01-25","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"INSTRUCTOR instruction fine-tuned text embeddings In this video  I   explain about INSTRUCTOR, an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves sota on 70 diverse embedding tasks! I also show a google collab demo of instructor\n\nhttps://youtu.be/vg38cq3KJ6M","classes":{"dataset":0.2934449911}}
{"title":"How to create a caption from the question-answer pair?","description":"I was wondering if it is possible to create a caption or a sentence from the given question-answer pair.\n\nSo given any question-answer pair, I want a caption. Is there any existing work on this? How can I achieve this?\n\nFor example :\n\n1)\n\nQ: What is on the table?\n\nA: A bottle\n\nI want to get something like: \"A bottle is on the table.\"\n\n&amp;#x200B;\n\n2) \n\nQ: What is the man doing?\n\nA: jumping\n\nI want to get something like: \"The man is jumping.\"\n\n&amp;#x200B;","link":"https://www.reddit.com/r/LanguageTechnology/comments/10kvb72/how_to_create_a_caption_from_the_questionanswer/","created":"2023-01-25","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"How to create a caption from the question-answer pair? I was wondering if it is possible to create a caption or a sentence from the given question-answer pair.\n\nSo given any question-answer pair, I want a caption. Is there any existing work on this? How can I achieve this?\n\nFor example :\n\n1)\n\nQ: What is on the table?\n\nA: A bottle\n\nI want to get something like: \"A bottle is on the table.\"\n\n&amp;#x200B;\n\n2) \n\nQ: What is the man doing?\n\nA: jumping\n\nI want to get something like: \"The man is jumping.\"\n\n&amp;#x200B;","classes":{"dataset":0.4504224956}}
{"title":"Data preparation for embedding","description":"I need to improve the quality of embeddings for a specific task. \nI have a huge Text corpus but it doesn\u2019t have any labels or similarity indicators attached to it \n Can somebody point we into the right direction where to get started ?","link":"https://www.reddit.com/r/LanguageTechnology/comments/10kusq2/data_preparation_for_embedding/","created":"2023-01-25","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":2},"text":"Data preparation for embedding I need to improve the quality of embeddings for a specific task. \nI have a huge Text corpus but it doesn\u2019t have any labels or similarity indicators attached to it \n Can somebody point we into the right direction where to get started ?","classes":{"dataset":0.28101179}}
{"title":"Debiasing GPT-3 model output: any idea as to what that process looks like at OpenAI?","description":"Last year's inverse scaling contest revealed some interesting trends in de-biasing / bias mitigation attempts by OpenAI in its GPT-3 models (`ada` ---&gt; `babbage`---&gt; `curie`---&gt; `davinci`). Prompts in which inverse scaling phenomena were most apparent included topics such as race, gender, ethnicity, class, religion, etc. \n\nDoes anyone have any idea as to what OpenAI's bias mitigation process looks like for the various sizes of GPT-3? I'd imagine that GPT-3 was trained on the large dataset (bigger than the Pile by quite a lot) and then, after the fact, the various models were put through the 'de-bias' fine-tuning wringer. And then those models were deployed as Models as a Service: `ada`, `babbage`, `curie`, `davinci`, etc. \n\nI'm wondering if anyone knows what the distillation process looked / looks like? Or if anyone knows anything about the debiasing process at OpenAI for the GPT-3 variants?","link":"https://www.reddit.com/r/LanguageTechnology/comments/10kgbpl/debiasing_gpt3_model_output_any_idea_as_to_what/","created":"2023-01-24","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"Debiasing GPT-3 model output: any idea as to what that process looks like at OpenAI? Last year's inverse scaling contest revealed some interesting trends in de-biasing / bias mitigation attempts by OpenAI in its GPT-3 models (`ada` ---&gt; `babbage`---&gt; `curie`---&gt; `davinci`). Prompts in which inverse scaling phenomena were most apparent included topics such as race, gender, ethnicity, class, religion, etc. \n\nDoes anyone have any idea as to what OpenAI's bias mitigation process looks like for the various sizes of GPT-3? I'd imagine that GPT-3 was trained on the large dataset (bigger than the Pile by quite a lot) and then, after the fact, the various models were put through the 'de-bias' fine-tuning wringer. And then those models were deployed as Models as a Service: `ada`, `babbage`, `curie`, `davinci`, etc. \n\nI'm wondering if anyone knows what the distillation process looked / looks like? Or if anyone knows anything about the debiasing process at OpenAI for the GPT-3 variants?","classes":{"dataset":0.3265741169}}
{"title":"Need help with a project.","description":"I have a text and a reason and I need predict if **text** satisfies the **reason**. But the catch here is the training dataset only has positive examples, where reason satisfies the text. Can someone help me how to train a model?","link":"https://www.reddit.com/r/LanguageTechnology/comments/10k71ad/need_help_with_a_project/","created":"2023-01-24","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":0},"text":"Need help with a project. I have a text and a reason and I need predict if **text** satisfies the **reason**. But the catch here is the training dataset only has positive examples, where reason satisfies the text. Can someone help me how to train a model?","classes":{"dataset":0.3926389217}}
{"title":"Word2Vec for code analyzation","description":"So recently me and a long-time partner of mine has gotten into NLPs and we wanted to try and use a model to pretty much find similarity between functions and package names. \n\nThe goal would be to create a program which through the NLP models can see if the code structure makes sense. For example if given a program with the file with functions car, audi, bmw and cat, with the package names car, it should see that cat doesn\u2019t belong there and tell the user to move it to a new package, maybe even give it a hint on package name. It would be used to test code structure logic, to aid in maintainability and readability of code. \n\nWe\u2019re very early in our development and we\u2019re still not sure if word2vec is the best choice, or even how we\u2019re supposed to represent their similarities. Anyone got an idea if there are improvements to our idea or does it sound fair?","link":"https://www.reddit.com/r/LanguageTechnology/comments/10jsjsd/word2vec_for_code_analyzation/","created":"2023-01-24","tags":["languagetechnology","reddit","ml"],"meta":{"num_comments":1},"text":"Word2Vec for code analyzation So recently me and a long-time partner of mine has gotten into NLPs and we wanted to try and use a model to pretty much find similarity between functions and package names. \n\nThe goal would be to create a program which through the NLP models can see if the code structure makes sense. For example if given a program with the file with functions car, audi, bmw and cat, with the package names car, it should see that cat doesn\u2019t belong there and tell the user to move it to a new package, maybe even give it a hint on package name. It would be used to test code structure logic, to aid in maintainability and readability of code. \n\nWe\u2019re very early in our development and we\u2019re still not sure if word2vec is the best choice, or even how we\u2019re supposed to represent their similarities. Anyone got an idea if there are improvements to our idea or does it sound fair?","classes":{"dataset":0.2507911623}}
